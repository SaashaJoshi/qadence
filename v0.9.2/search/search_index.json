{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Qadence","text":"<p>Qadence is a Python package that provides a simple interface to build digital-analog quantum programs with tunable qubit interaction defined on arbitrary register topologies realizable on neutral atom devices.</p>"},{"location":"#feature-highlights","title":"Feature highlights","text":"<ul> <li> <p>A block-based system for composing complex digital-analog   programs in a flexible and scalable manner, inspired by the Julia quantum SDK   Yao.jl and functional programming concepts.</p> </li> <li> <p>A simple interface to work with interacting neutral-atom qubit systems   using arbitrary registers topologies.</p> </li> <li> <p>An intuitive expression-based system developed on top of the symbolic library Sympy to construct parametric quantum programs easily.</p> </li> <li> <p>High-order generalized parameter shift rules for differentiating parametrized quantum operations.</p> </li> <li> <p>Out-of-the-box automatic differentiability of quantum programs with PyTorch integration.</p> </li> <li> <p>Efficient execution on a variety of different purpose backends: from state vector simulators to tensor network emulators and real devices.</p> </li> </ul> <p>In following are some examples of Qadence possibilites in the digital, analog and digital-analog paradigms.</p>"},{"location":"#sampling-the-canonical-bell-state","title":"Sampling the canonical Bell state","text":"<p>This example illustrates how to prepare a Bell state using digital gates and sampling from the outcome bitstring distribution:</p> <pre><code>from qadence import CNOT, H, chain, sample\n# Preparing a Bell state by composing a Hadamard and CNOT gates in sequence.\nbell_state = chain(H(0), CNOT(0,1))\n# Sample with 100 shots.\nsamples = sample(bell_state, n_shots=100)\n</code></pre> <pre><code>samples = [Counter({'00': 53, '11': 47})]\n</code></pre>"},{"location":"#analog-emulation-of-a-perfect-state-transfer","title":"Analog emulation of a perfect state transfer","text":"<p>This next example showcases the construction and sampling of a system that admits a perfect state transfer between the two edge qubits of a three qubit register laid out in a line. This relies on time-evolving a Hamiltonian for a custom defined qubit interation until \\(t=\\frac{\\pi}{\\sqrt 2}\\).</p> <pre><code>from torch import pi\nfrom qadence import X, Y, HamEvo, Register, product_state, sample, add\n# Define the qubit-qubit interaction term.\ndef interaction(i, j):\nreturn 0.5 * (X(i) @ X(j) + Y(i) @ Y(j))  # Compose gates in parallel and sum their contribution.\n# Initial state with left-most qubit in the 1 state.\ninit_state = product_state(\"100\")\n# Define a register of 3 qubits laid out in a line.\nregister = Register.line(n_qubits=3)\n# Define an interaction Hamiltonian by summing interactions on indexed qubits.\n# hamiltonian = interaction(0, 1) + interaction(1, 2)\nhamiltonian = add(interaction(*edge) for edge in register.edges)\n# Define and time-evolve the Hamiltonian until t=pi/sqrt(2).\nt = pi/(2**0.5)  # Dimensionless.\nevolution = HamEvo(hamiltonian, t)\n# Sample with 100 shots.\nsamples = sample(register, evolution, state=init_state, n_shots=100)\n</code></pre> <pre><code>samples = [Counter({'001': 100})]\n</code></pre>"},{"location":"#digital-analog-example","title":"Digital-analog example","text":"<p>This final example deals with the construction and sampling of an Ising Hamiltonian that includes a distance-based interaction between qubits and a global analog block of rotations around the \\(X\\)-axis. Here, global has to be understood as applied to the whole register for qubits.</p> <pre><code>from torch import pi\nfrom qadence import Register, AnalogRX, sample\n# Global analog RX block.\nblock = AnalogRX(pi)\n# Almost non-interacting qubits as too far apart.\nregister = Register.from_coordinates([(0,0), (0,15)])  # Dimensionless.\nsamples = sample(register, block)\n# Interacting qubits as close together.\nregister = Register.from_coordinates([(0,0), (0,5)])\nsamples = sample(register, AnalogRX(pi))\n</code></pre> <pre><code>distance = 15: samples = [Counter({'11': 100})]\ndistance =  5: samples = [Counter({'01': 40, '00': 34, '10': 26})]\n</code></pre>"},{"location":"#further-resources","title":"Further resources","text":"<p>For a more comprehensive introduction and advanced topics, please have a look at the following tutorials:</p> <ul> <li>Quantum state conventions used throughout Qadence.</li> <li>Basic tutorials for first hands-on.</li> <li>Digital-analog basics to build quantum programs in the digital-analog paradigm.</li> <li>Parametric quantum circuits for the generation and manipulation of parametric programs.</li> <li>Advanced features about low-level backend interface and differentiablity.</li> <li><code>QuantumModel</code> for defining custom models.</li> </ul>"},{"location":"#installation-guide","title":"Installation guide","text":"<p>Qadence can be installed from PyPI with <code>pip</code> as follows:</p> <pre><code>pip install qadence\n</code></pre> <p>The default backend for Qadence is PyQTorch, a differentiable state vector simulator for digital-analog simulation. It is possible to install additional backends and the circuit visualization library using the following extras:</p> <ul> <li><code>braket</code>: the Braket backend.</li> <li><code>pulser</code>: the Pulser backend for composing, simulating and executing pulse sequences for neutral-atom quantum devices.</li> <li><code>visualization</code>: to display diagrammatically quantum circuits.</li> </ul> <p>by running:</p> <pre><code>pip install qadence[braket, pulser, visualization]\n</code></pre> <p>Warning</p> <p>In order to correctly install the <code>visualization</code> extra, the <code>graphviz</code> package needs to be installed in your system:</p> <pre><code># on Ubuntu\nsudo apt install graphviz\n\n# on MacOS\nbrew install graphviz\n\n# via conda\nconda install python-graphviz\n</code></pre>"},{"location":"#citation","title":"Citation","text":"<p>If you use Qadence for a publication, we kindly ask you to cite our work using the following BibTex entry:</p> <pre><code>@misc{qadence2023pasqal,\n  url = {https://github.com/pasqal-io/qadence},\n  title = {Qadence: {A} {D}igital-analog quantum programming interface.},\n  year = {2023}\n}\n</code></pre>"},{"location":"models/","title":"Quantum Models","text":""},{"location":"models/#qadence.models.quantum_model.QuantumModel","title":"<code>QuantumModel(circuit, observable=None, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, protocol=None, configuration=None)</code>","text":"<p>             Bases: <code>Module</code></p> <p>The central class of qadence that executes <code>QuantumCircuit</code>s and make them differentiable.</p> <p>This class should be used as base class for any new quantum model supported in the qadence framework for information on the implementation of custom models see here.</p> <p>Initialize a generic QuantumModel instance.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>The circuit that is executed.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>observable</code> <p>Optional observable(s) that are used only in the <code>expectation</code> method. You can also provide observables on the fly to the expectation call directly.</p> <p> TYPE: <code>list[AbstractBlock] | AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>A backend for circuit execution.</p> <p> TYPE: <code>BackendName | str</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>A differentiability mode. Parameter shift based modes work on all backends. AD based modes only on PyTorch based backends.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>protocol</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>Configuration for the backend.</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if the <code>diff_mode</code> argument is set to None</p> Source code in <code>qadence/models/quantum_model.py</code> <pre><code>def __init__(\nself,\ncircuit: QuantumCircuit,\nobservable: list[AbstractBlock] | AbstractBlock | None = None,\nbackend: BackendName | str = BackendName.PYQTORCH,\ndiff_mode: DiffMode = DiffMode.AD,\nprotocol: Measurements | None = None,\nconfiguration: BackendConfiguration | dict | None = None,\n):\n\"\"\"Initialize a generic QuantumModel instance.\n    Arguments:\n        circuit: The circuit that is executed.\n        observable: Optional observable(s) that are used only in the `expectation` method. You\n            can also provide observables on the fly to the expectation call directly.\n        backend: A backend for circuit execution.\n        diff_mode: A differentiability mode. Parameter shift based modes work on all backends.\n            AD based modes only on PyTorch based backends.\n        protocol: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        configuration: Configuration for the backend.\n    Raises:\n        ValueError: if the `diff_mode` argument is set to None\n    \"\"\"\nsuper().__init__()\nif not isinstance(circuit, QuantumCircuit):\nTypeError(\nf\"The circuit should be of type '&lt;class QuantumCircuit&gt;'. Got {type(circuit)}.\"\n)\nself.inputs = [p for p in circuit.unique_parameters if not p.trainable and not p.is_number]\nif diff_mode is None:\nraise ValueError(\"`diff_mode` cannot be `None` in a `QuantumModel`.\")\nself.backend = backend_factory(\nbackend=backend, diff_mode=diff_mode, configuration=configuration\n)\nif isinstance(observable, list) or observable is None:\nobservable = observable\nelse:\nobservable = [observable]\nconv = self.backend.convert(circuit, observable)\nself.embedding_fn = conv.embedding_fn\nself._circuit = conv.circuit\nself._observable = conv.observable\nself._backend_name = backend\nself._diff_mode = diff_mode\nself._protocol = protocol\nself._params = nn.ParameterDict(\n{\nstr(key): nn.Parameter(val, requires_grad=val.requires_grad)\nfor key, val in conv.params.items()\n}\n)\n</code></pre>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.in_features","title":"<code>in_features: int</code>  <code>property</code>","text":"<p>Number of inputs.</p>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.num_vparams","title":"<code>num_vparams: int</code>  <code>property</code>","text":"<p>The number of variational parameters</p>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.out_features","title":"<code>out_features: int | None</code>  <code>property</code>","text":"<p>Number of outputs</p>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.vals_vparams","title":"<code>vals_vparams: Tensor</code>  <code>property</code>","text":"<p>Dictionary with parameters which are actually updated during optimization</p>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.assign_parameters","title":"<code>assign_parameters(values)</code>","text":"<p>Return the final, assigned circuit that is used in e.g. <code>backend.run</code></p> Source code in <code>qadence/models/quantum_model.py</code> <pre><code>def assign_parameters(self, values: dict[str, Tensor]) -&gt; Any:\n\"\"\"Return the final, assigned circuit that is used in e.g. `backend.run`\"\"\"\nparams = self.embedding_fn(self._params, values)\nreturn self.backend.assign_parameters(self._circuit, params)\n</code></pre>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.expectation","title":"<code>expectation(values={}, observable=None, state=None, protocol=None, endianness=Endianness.BIG)</code>","text":"<p>Compute expectation using the given backend.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor of shape n_batches x n_obs</p> Source code in <code>qadence/models/quantum_model.py</code> <pre><code>def expectation(\nself,\nvalues: dict[str, Tensor] = {},\nobservable: list[ConvertedObservable] | ConvertedObservable | None = None,\nstate: Optional[Tensor] = None,\nprotocol: Measurements | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Compute expectation using the given backend.\n    Returns:\n        A torch.Tensor of shape n_batches x n_obs\n    \"\"\"\nif observable is None:\nif self._observable is None:\nraise ValueError(\n\"Provide an AbstractBlock as the observable to compute expectation.\"\n\"Either pass a 'native_observable' directly to 'QuantumModel.expectation'\"\n\"or pass a (non-native) '&lt;class AbstractBlock&gt;' to the 'QuantumModel.__init__'.\"\n)\nobservable = self._observable\nparams = self.embedding_fn(self._params, values)\nif protocol is None:\nprotocol = self._protocol\nreturn self.backend.expectation(\ncircuit=self._circuit,\nobservable=observable,\nparam_values=params,\nstate=state,\nprotocol=protocol,\nendianness=endianness,\n)\n</code></pre>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.reset_vparams","title":"<code>reset_vparams(values)</code>","text":"<p>Reset all the variational parameters with a given list of values</p> Source code in <code>qadence/models/quantum_model.py</code> <pre><code>def reset_vparams(self, values: Sequence) -&gt; None:\n\"\"\"Reset all the variational parameters with a given list of values\"\"\"\ncurrent_vparams = OrderedDict({k: v for k, v in self._params.items() if v.requires_grad})\nassert (\nlen(values) == self.num_vparams\n), \"Pass an iterable with the values of all variational parameters\"\nfor i, k in enumerate(current_vparams.keys()):\ncurrent_vparams[k].data = torch.tensor([values[i]])\n</code></pre>"},{"location":"models/#qadence.models.qnn.QNN","title":"<code>QNN(circuit, observable, transform=None, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, protocol=None, configuration=None)</code>","text":"<p>             Bases: <code>QuantumModel</code></p> <p>Quantum neural network model for n-dimensional inputs</p> <p>Examples: <pre><code>import torch\nfrom qadence import QuantumCircuit, QNN\nfrom qadence import hea, feature_map, hamiltonian_factory, Z\n# create the circuit\nn_qubits, depth = 2, 4\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nobs_base = hamiltonian_factory(n_qubits, detuning = Z)\n# the QNN will yield two outputs\nobs = [2.0 * obs_base, 4.0 * obs_base]\n# initialize and use the model\nqnn = QNN(circuit, obs, diff_mode=\"ad\", backend=\"pyqtorch\")\ny = qnn.expectation({\"phi\": torch.rand(3)})\n</code></pre> <pre><code>tensor([[0.2435, 0.4871],\n[0.3692, 0.7385],\n[0.3679, 0.7357]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> </p> <p>Initialize the QNN</p> <p>The number of inputs is determined by the feature parameters in the input quantum circuit while the number of outputs is determined by how many observables are provided as input</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>The quantum circuit to use for the QNN.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>transform</code> <p>A transformation applied to the output of the QNN.</p> <p> TYPE: <code>Callable[[Tensor], Tensor]</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>protocol</code> <p>optional measurement protocol. If None, use exact expectation value with a statevector simulator</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>optional configuration for the backend</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/models/qnn.py</code> <pre><code>def __init__(\nself,\ncircuit: QuantumCircuit,\nobservable: list[AbstractBlock] | AbstractBlock,\ntransform: Callable[[Tensor], Tensor] = None,  # transform output of the QNN\nbackend: BackendName = BackendName.PYQTORCH,\ndiff_mode: DiffMode = DiffMode.AD,\nprotocol: Measurements | None = None,\nconfiguration: BackendConfiguration | dict | None = None,\n):\n\"\"\"Initialize the QNN\n    The number of inputs is determined by the feature parameters in the input\n    quantum circuit while the number of outputs is determined by how many\n    observables are provided as input\n    Args:\n        circuit: The quantum circuit to use for the QNN.\n        transform: A transformation applied to the output of the QNN.\n        backend: The chosen quantum backend.\n        diff_mode: The differentiation engine to use. Choices 'gpsr' or 'ad'.\n        protocol: optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator\n        configuration: optional configuration for the backend\n    \"\"\"\nsuper().__init__(\ncircuit=circuit,\nobservable=observable,\nbackend=backend,\ndiff_mode=diff_mode,\nprotocol=protocol,\nconfiguration=configuration,\n)\nif self.out_features is None:\nraise ValueError(\"You need to provide at least one observable in the QNN constructor\")\nself.transform = transform if transform else lambda x: x\n</code></pre>"},{"location":"models/#qadence.models.qnn.QNN.forward","title":"<code>forward(values=None, state=None, protocol=None, endianness=Endianness.BIG)</code>","text":"<p>Forward pass of the model</p> <p>This returns the (differentiable) expectation value of the given observable operator defined in the constructor. Differently from the base QuantumModel class, the QNN accepts also a tensor as input for the forward pass. The tensor is expected to have shape: <code>n_batches x in_features</code> where <code>n_batches</code> is the number of data points and <code>in_features</code> is the dimensionality of the problem</p> <p>The output of the forward pass is the expectation value of the input observable(s). If a single observable is given, the output shape is <code>n_batches</code> while if multiple observables are given the output shape is instead <code>n_batches x n_observables</code></p> PARAMETER  DESCRIPTION <code>values</code> <p>the values of the feature parameters</p> <p> TYPE: <code>dict[str, Tensor] | Tensor</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a tensor with the expectation value of the observables passed in the constructor of the model</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/models/qnn.py</code> <pre><code>def forward(\nself,\nvalues: dict[str, Tensor] | Tensor = None,\nstate: Tensor | None = None,\nprotocol: Measurements | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Forward pass of the model\n    This returns the (differentiable) expectation value of the given observable\n    operator defined in the constructor. Differently from the base QuantumModel\n    class, the QNN accepts also a tensor as input for the forward pass. The\n    tensor is expected to have shape: `n_batches x in_features` where `n_batches`\n    is the number of data points and `in_features` is the dimensionality of the problem\n    The output of the forward pass is the expectation value of the input\n    observable(s). If a single observable is given, the output shape is\n    `n_batches` while if multiple observables are given the output shape\n    is instead `n_batches x n_observables`\n    Args:\n        values (dict[str, Tensor] | Tensor): the values of the feature parameters\n    Returns:\n        Tensor: a tensor with the expectation value of the observables passed\n            in the constructor of the model\n    \"\"\"\nif values is None:\nvalues = {}\nif not isinstance(values, dict):\nvalues = self._format_to_dict(values)\nif protocol is None:\nprotocol = self._protocol\nreturn self.transform(\nself.expectation(values=values, state=state, protocol=protocol, endianness=endianness)\n)\n</code></pre>"},{"location":"advanced_tutorials/custom-models/","title":"Custom QuantumModels","text":"<p>In <code>qadence</code>, the <code>QuantumModel</code> is the central class point for executing <code>QuantumCircuit</code>s.  The idea of a <code>QuantumModel</code> is to decouple the backend execution from the management of circuit parameters and desired quantum computation output.</p> <p>In the following, we create a custom <code>QuantumModel</code> instance which introduces some additional optimizable parameters: *  an adjustable scaling factor in front of the observable to measured *  adjustable scale and shift factors to be applied to the model output before returning the result</p> <p>This can be easily done using PyTorch flexible model definition, and it will automatically work with the rest of <code>qadence</code> infrastructure.</p> <pre><code>import torch\nfrom qadence import QuantumModel, QuantumCircuit\nclass CustomQuantumModel(QuantumModel):\ndef __init__(self, circuit: QuantumCircuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\"):\nsuper().__init__(circuit, observable=observable, backend=backend, diff_mode=diff_mode)\nself.n_qubits = circuit.n_qubits\n# define some additional parameters which will scale and shift (variationally) the\n# output of the QuantumModel\n# you can use all torch machinery for building those\nself.scale_out = torch.nn.Parameter(torch.ones(1))\nself.shift_out = torch.nn.Parameter(torch.ones(1))\n# override the forward pass of the model\n# the forward pass is the output of your QuantumModel and in this case\n# it's the (scaled) expectation value of the total magnetization with\n# a variable coefficient in front\ndef forward(self, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\n# scale the observable\nres = self.expectation(values)\n# scale and shift the result before returning\nreturn self.shift_out + res * self.scale_out\n</code></pre> <p>The custom model can be used like any other <code>QuantumModel</code>: <pre><code>from qadence import Parameter, RX, CNOT, QuantumCircuit\nfrom qadence import chain, kron, hamiltonian_factory, Z\nfrom sympy import acos\ndef quantum_circuit(n_qubits):\nx = Parameter(\"x\", trainable=False)\nfm = kron(RX(i, acos(x) * (i+1)) for i in range(n_qubits))\nansatz = kron(RX(i, f\"theta{i}\") for i in range(n_qubits))\nansatz = chain(ansatz, CNOT(0, n_qubits-1))\nblock = chain(fm, ansatz)\nblock.tag = \"circuit\"\nreturn QuantumCircuit(n_qubits, block)\nn_qubits = 4\nbatch_size = 10\ncircuit = quantum_circuit(n_qubits)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)  # Total magnetization\nmodel = CustomQuantumModel(circuit, observable, backend=\"pyqtorch\")\nvalues = {\"x\": torch.rand(batch_size)}\nres = model(values)\nprint(\"Model output: \", res)\nassert len(res) == batch_size\n</code></pre> <pre><code>Model output:  tensor([[-0.4141],\n[-0.7079],\n[-0.6309],\n[-0.1402],\n[ 0.5185],\n[-0.3482],\n[-0.5084],\n[-0.7341],\n[-0.4160],\n[-0.7420]], grad_fn=&lt;AddBackward0&gt;)\n</code></pre> </p>"},{"location":"advanced_tutorials/custom-models/#quantum-model-with-wavefunction-overlaps","title":"Quantum model with wavefunction overlaps","text":"<p><code>QuantumModel</code>'s can also use different quantum operations in their forward pass, such as wavefunction overlaps described here. Beware that the resulting overlap tensor has to be differentiable to apply gradient-based optimization. This is only applicable to the <code>\"EXACT\"</code> overlap method.</p> <p>Here we show how to use overlap calculation when fitting a parameterized quantum circuit to act as a standard Hadamard gate.</p> <pre><code>from qadence import RY, RX, H, Overlap\n# create a quantum model which acts as an Hadamard gate after training\nclass LearnHadamard(QuantumModel):\ndef __init__(\nself,\ntrain_circuit: QuantumCircuit,\ntarget_circuit: QuantumCircuit,\nbackend=\"pyqtorch\",\n):\nsuper().__init__(circuit=train_circuit, backend=backend)\nself.overlap_fn = Overlap(train_circuit, target_circuit, backend=backend, method=\"exact\", diff_mode='ad')\ndef forward(self):\nreturn self.overlap_fn()\n# compute the wavefunction of the associated train circuit\ndef wavefunction(self):\nreturn model.overlap_fn.run({})\ntrain_circuit = QuantumCircuit(1, chain(RX(0, \"phi\"), RY(0, \"theta\")))\ntarget_circuit = QuantumCircuit(1, H(0))\nmodel = LearnHadamard(train_circuit, target_circuit)\n# get the overlap between model and target circuit wavefunctions\nprint(model())\n</code></pre> <pre><code>tensor([[0.6989]], grad_fn=&lt;UnsqueezeBackward0&gt;)\n</code></pre> <p>This model can then be trained with the standard Qadence helper functions.</p> <pre><code>from qadence import run\nfrom qadence.ml_tools import train_with_grad, TrainConfig\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\ndef loss_fn(model: LearnHadamard, _unused) -&gt; tuple[torch.Tensor, dict]:\nloss = criterion(torch.tensor([[1.0]]), model())\nreturn loss, {}\nconfig = TrainConfig(max_iter=2500)\nmodel, optimizer = train_with_grad(\nmodel, None, optimizer, config, loss_fn=loss_fn\n)\nwf_target = run(target_circuit)\nassert torch.allclose(wf_target, model.wavefunction(), atol=1e-2)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"advanced_tutorials/differentiability/","title":"Differentiability","text":"<p>Many application in quantum computing and quantum machine learning more specifically requires the differentiation of a quantum circuit with respect to its parameters.</p> <p>In Qadence, we perform quantum computations via the <code>QuantumModel</code> interface. The derivative of the outputs of quantum models with respect to feature and variational parameters in the quantum circuit can be implemented in Qadence with two different modes:</p> <ul> <li>Automatic differentiation (AD) mode <sup>1</sup>. This mode allows to differentiation both <code>run()</code> and <code>expectation()</code> methods of the <code>QuantumModel</code> and it is the fastest available differentiation method. Under the hood, it is based on the PyTorch autograd engine wrapped by the <code>DifferentiableBackend</code> class. This mode is not working on quantum devices.</li> <li>Generalized parameter shift rule (GPSR) mode. This is general implementation of the well known parameter  shift rule algorithm <sup>2</sup> which works for arbitrary quantum operations <sup>3</sup>. This mode is only applicable to  the <code>expectation()</code> method of <code>QuantumModel</code> but it is compatible with execution or quantum devices.</li> </ul>"},{"location":"advanced_tutorials/differentiability/#automatic-differentiation","title":"Automatic differentiation","text":"<p>Automatic differentiation <sup>1</sup> is a procedure to derive a complex function defined as a sequence of elementary mathematical operations in the form of a computer program. Automatic differentiation is a cornerstone of modern machine learning and a crucial ingredient of its recent successes. In its so-called reverse mode, it follows this sequence of operations in reverse order by systematically applying the chain rule to recover the exact value of derivative. Reverse mode automatic differentiation is implemented in Qadence leveraging the PyTorch <code>autograd</code> engine.</p> <p>Only available with PyQTorch backend</p> <p>Currently, automatic differentiation mode is only available when the <code>pyqtorch</code> backend is selected.</p>"},{"location":"advanced_tutorials/differentiability/#generalized-parameter-shift-rule","title":"Generalized parameter shift rule","text":"<p>The generalized parameter shift rule implementation in Qadence was introduced in <sup>3</sup>. Here the standard parameter shift rules, which only works for quantum operations whose generator has a single gap in its eigenvalue spectrum, was generalized to work with arbitrary generators of quantum operations.</p> <p>For this, we define the differentiable function as quantum expectation value</p> \\[ f(x) = \\left\\langle 0\\right|\\hat{U}^{\\dagger}(x)\\hat{C}\\hat{U}(x)\\left|0\\right\\rangle \\] <p>where \\(\\hat{U}(x)={\\rm exp}{\\left( -i\\frac{x}{2}\\hat{G}\\right)}\\) is the quantum evolution operator with generator \\(\\hat{G}\\) representing the structure of the underlying quantum circuit and \\(\\hat{C}\\) is the cost operator. Then using the eigenvalue spectrum \\(\\left\\{ \\lambda_n\\right\\}\\) of the generator \\(\\hat{G}\\) we calculate the full set of corresponding unique non-zero spectral gaps \\(\\left\\{ \\Delta_s\\right\\}\\) (differences between eigenvalues). It can be shown that the final expression of derivative of \\(f(x)\\) is then given by the following expression:</p> <p>\\(\\begin{equation} \\frac{{\\rm d}f\\left(x\\right)}{{\\rm d}x}=\\overset{S}{\\underset{s=1}{\\sum}}\\Delta_{s}R_{s}, \\end{equation}\\)</p> <p>where \\(S\\) is the number of unique non-zero spectral gaps and \\(R_s\\) are real quantities that are solutions of a system of linear equations</p> <p>\\(\\begin{equation} \\begin{cases} F_{1} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{1}\\Delta_{s}}{2}\\right)R_{s},\\\\ F_{2} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{2}\\Delta_{s}}{2}\\right)R_{s},\\\\  &amp; ...\\\\ F_{S} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{M}\\Delta_{s}}{2}\\right)R_{s}. \\end{cases} \\end{equation}\\)</p> <p>Here \\(F_s=f(x+\\delta_s)-f(x-\\delta_s)\\) denotes the difference between values of functions evaluated at shifted arguments \\(x\\pm\\delta_s\\).</p>"},{"location":"advanced_tutorials/differentiability/#usage","title":"Usage","text":""},{"location":"advanced_tutorials/differentiability/#basics","title":"Basics","text":"<p>In Qadence, the GPSR differentiation engine can be selected by passing <code>diff_mode=\"gpsr\"</code> or, equivalently, <code>diff_mode=DiffMode.GPSR</code> to a <code>QuantumModel</code> instance. The code in the box below shows how to create <code>QuantumModel</code> instances with both AD and GPSR engines.</p> <pre><code>from qadence import (FeatureParameter, HamEvo, X, I, Z,\nhamiltonian_factory, QuantumCircuit,\nQuantumModel, BackendName, DiffMode)\nimport torch\nn_qubits = 2\n# define differentiation parameter\nx = FeatureParameter(\"x\")\n# define generator and HamEvo block\ngenerator = X(0) + X(1) + 0.2 * (Z(0) + I(1)) * (I(0) + Z(1))\nblock = HamEvo(generator, x)\n# create quantum circuit\ncircuit = QuantumCircuit(n_qubits, block)\n# create total magnetization cost operator\nobs = hamiltonian_factory(n_qubits, detuning=Z)\n# create models with AD and GPSR differentiation engines\nmodel_ad = QuantumModel(circuit, obs,\nbackend=BackendName.PYQTORCH,\ndiff_mode=DiffMode.AD)\nmodel_gpsr = QuantumModel(circuit, obs,\nbackend=BackendName.PYQTORCH,\ndiff_mode=DiffMode.GPSR)\n# generate value for circuit's parameter\nxs = torch.linspace(0, 2*torch.pi, 100, requires_grad=True)\nvalues = {\"x\": xs}\n# calculate function f(x)\nexp_val_ad = model_ad.expectation(values)\nexp_val_gpsr = model_gpsr.expectation(values)\n# calculate derivative df/dx using the PyTorch\n# autograd engine\ndexpval_x_ad = torch.autograd.grad(\nexp_val_ad, values[\"x\"], torch.ones_like(exp_val_ad), create_graph=True\n)[0]\ndexpval_x_gpsr = torch.autograd.grad(\nexp_val_gpsr, values[\"x\"], torch.ones_like(exp_val_gpsr), create_graph=True\n)[0]\n</code></pre> <p>We can plot the resulting derivatives and see that in both cases they coincide.</p> <pre><code>import matplotlib.pyplot as plt\n# plot f(x) and df/dx derivatives calculated using AD and GPSR\n# differentiation engines\nfig, ax = plt.subplots()\nax.scatter(xs.detach().numpy(),\nexp_val_ad.detach().numpy(),\nlabel=\"f(x)\")\nax.scatter(xs.detach().numpy(),\ndexpval_x_ad.detach().numpy(),\nlabel=\"df/dx AD\")\nax.scatter(xs.detach().numpy(),\ndexpval_x_gpsr.detach().numpy(),\ns=5,\nlabel=\"df/dx GPSR\")\nplt.legend()\n</code></pre> 2023-10-10T21:36:11.633477 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"advanced_tutorials/differentiability/#low-level-control-on-the-shift-values","title":"Low-level control on the shift values","text":"<p>In order to get a finer control over the GPSR differentiation engine we can use the low-level Qadence API to define a <code>DifferentiableBackend</code>.</p> <pre><code>from qadence import DifferentiableBackend\nfrom qadence.backends.pyqtorch import Backend as PyQBackend\n# define differentiable quantum backend\nquantum_backend = PyQBackend()\nconv = quantum_backend.convert(circuit, obs)\npyq_circ, pyq_obs, embedding_fn, params = conv\ndiff_backend = DifferentiableBackend(quantum_backend, diff_mode=DiffMode.GPSR, shift_prefac=0.2)\n# calculate function f(x)\nexpval = diff_backend.expectation(pyq_circ, pyq_obs, embedding_fn(params, values))\n</code></pre> <p>Here we passed an additional argument <code>shift_prefac</code> to the <code>DifferentiableBackend</code> instance that governs the magnitude of shifts \\(\\delta\\equiv\\alpha\\delta^\\prime\\) shown in equation (2) above. In this relation \\(\\delta^\\prime\\) is set internally and \\(\\alpha\\) is the value passed by <code>shift_prefac</code> and the resulting shift value \\(\\delta\\) is then used in all the following GPSR calculations.</p> <p>Tuning parameter \\(\\alpha\\) is useful to improve results when the generator \\(\\hat{G}\\) or the quantum operation is a dense matrix, for example a complex <code>HamEvo</code> operation; if many entries of this matrix are sufficiently larger than 0 the operation is equivalent to a strongly interacting system. In such case parameter \\(\\alpha\\) should be gradually lowered in order to achieve exact derivative values.</p>"},{"location":"advanced_tutorials/differentiability/#references","title":"References","text":"<ol> <li> <p>A. G. Baydin et al., Automatic Differentiation in Machine Learning: a Survey \u21a9\u21a9</p> </li> <li> <p>Schuld et al., Evaluating analytic gradients on quantum hardware (2018). \u21a9</p> </li> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9\u21a9</p> </li> </ol>"},{"location":"advanced_tutorials/vqe/","title":"Ground-state VQE","text":""},{"location":"advanced_tutorials/vqe/#restricted-hamiltonian","title":"Restricted Hamiltonian","text":"<p>Simple implementation of the UCC ansatz for computing the ground state of the H2 molecule. The Hamiltonian coefficients are taken from the following paper: https://arxiv.org/pdf/1512.06860.pdf.</p> <p>Simple 2 qubits unitary coupled cluster ansatz for H2 molecule <pre><code>import torch\nfrom qadence import X, RX, RY, RZ, CNOT, chain, kron\ndef UCC_ansatz_H2():\nansatz=chain(\nkron(chain(X(0), RX(0, -torch.pi/2)), RY(1, torch.pi/2)),\nCNOT(1,0),\nRZ(0, f\"theta\"),\nCNOT(1,0),\nkron(RX(0, torch.pi/2), RY(1, -torch.pi/2))\n)\nreturn ansatz\n</code></pre> %3 6ab8998bf22341aca7ef1370d5c5dbba 0 6e76a9e9a3d1494fb310a0c8fec57be1 X 6ab8998bf22341aca7ef1370d5c5dbba--6e76a9e9a3d1494fb310a0c8fec57be1 4b12db8ca3f048478027da40cc6dfa14 1 73a79f3d1b3c478695f1ef4d12e63816 RX(-1.571) 6e76a9e9a3d1494fb310a0c8fec57be1--73a79f3d1b3c478695f1ef4d12e63816 2d0c82ace50b4115a0b5cb92e48a621c X 73a79f3d1b3c478695f1ef4d12e63816--2d0c82ace50b4115a0b5cb92e48a621c c1500c7436f74ce1a26d0971d630948c RZ(theta) 2d0c82ace50b4115a0b5cb92e48a621c--c1500c7436f74ce1a26d0971d630948c c1522b1f837d4d9d89f0c6a64fa30110 2d0c82ace50b4115a0b5cb92e48a621c--c1522b1f837d4d9d89f0c6a64fa30110 e18a21c7922945bc9563ee4113663096 X c1500c7436f74ce1a26d0971d630948c--e18a21c7922945bc9563ee4113663096 9a124b5d99b1416c856c15f97294a19e RX(1.571) e18a21c7922945bc9563ee4113663096--9a124b5d99b1416c856c15f97294a19e 8aaed91401c7424bbb296bd9d254f09d e18a21c7922945bc9563ee4113663096--8aaed91401c7424bbb296bd9d254f09d c56db029bed54cb8b010444c4b2d1d1c 9a124b5d99b1416c856c15f97294a19e--c56db029bed54cb8b010444c4b2d1d1c f63fcf39626e478bbb6c11defd2e6443 d99fd81b903346079bc47cf0e341cbd8 RY(1.571) 4b12db8ca3f048478027da40cc6dfa14--d99fd81b903346079bc47cf0e341cbd8 f4ae22006ef24280b0be828d7f935fbc d99fd81b903346079bc47cf0e341cbd8--f4ae22006ef24280b0be828d7f935fbc f4ae22006ef24280b0be828d7f935fbc--c1522b1f837d4d9d89f0c6a64fa30110 28b21ef1fd354b6491964f87b74b53ea c1522b1f837d4d9d89f0c6a64fa30110--28b21ef1fd354b6491964f87b74b53ea 28b21ef1fd354b6491964f87b74b53ea--8aaed91401c7424bbb296bd9d254f09d 02ef7047ca604bafba64759a7850266d RY(-1.571) 8aaed91401c7424bbb296bd9d254f09d--02ef7047ca604bafba64759a7850266d 02ef7047ca604bafba64759a7850266d--f63fcf39626e478bbb6c11defd2e6443 </p> <p>Let's define the Hamiltonian of the problem in the following form: hamilt = [list of coefficients, list of Pauli operators, list of qubits]. For example: <code>hamilt=[[3,4],[[X,X],[Y]],[[0,1],[3]]]</code>.</p> <p>In the following function we generate the Hamiltonian with the format above.</p> <pre><code>from typing import Iterable\nfrom qadence import X, Y, Z, I, add\ndef make_hamiltonian(hamilt: Iterable, nqubits: int):\nnb_terms = len(hamilt[0])\nblocks = []\nfor iter in range(nb_terms):\nblock = kron(gate(qubit) for gate,qubit in zip(hamilt[1][iter], hamilt[2][iter]))\nblocks.append(hamilt[0][iter] * block)\nreturn add(*blocks)\nnqbits = 2\n# Hamiltonian definition using the convention outlined above\nhamilt_R07 = [\n[0.2976, 0.3593, -0.4826,0.5818, 0.0896, 0.0896],\n[[I,I],[Z],[Z],[Z,Z],[X,X],[Y,Y]],\n[[0,1],[0],[1],[0,1],[0,1],[0,1]]\n]\nhamiltonian = make_hamiltonian(hamilt_R07, nqbits)\n</code></pre> %3 cluster_8a2069be0f634837909d31ae7102eaba 0cd3ec89dcdc49abaa4901b2440146cd 0 f3d2f41c031c4493af97844d8456e8fb AddBlock 0cd3ec89dcdc49abaa4901b2440146cd--f3d2f41c031c4493af97844d8456e8fb f9ab8aae13ce4bbca9b8ca77577f2e52 1 7de6ada6f2734da7829c254a83524770 f3d2f41c031c4493af97844d8456e8fb--7de6ada6f2734da7829c254a83524770 521aa40ff85142e8b17fcbf67a3551a3 588c25e43cd94439bbf4922adf730522 f9ab8aae13ce4bbca9b8ca77577f2e52--588c25e43cd94439bbf4922adf730522 588c25e43cd94439bbf4922adf730522--521aa40ff85142e8b17fcbf67a3551a3 <p>Let's now create a <code>QuantumCircuit</code> representing the variational ansatz and plug it into a <code>QuantumModel</code> instance. From there, it is very easy to compute the energy by simply evaluating the expectation value of the Hamiltonian operator.</p> <p><pre><code>from qadence import QuantumCircuit, QuantumModel\nansatz = QuantumCircuit(nqbits, UCC_ansatz_H2())\nmodel = QuantumModel(ansatz, observable=hamiltonian, backend=\"pyqtorch\", diff_mode=\"ad\")\nvalues={}\nout = model.expectation(values)\nprint(out)\n</code></pre> <pre><code>tensor([[-1.1424]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre>  Let's now resent the parameters and set them randomly before starting the optimization loop.</p> <pre><code>init_params = torch.rand(model.num_vparams)\nmodel.reset_vparams(init_params)\nn_epochs = 100\nlr = 0.05\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nfor i in range(n_epochs):\noptimizer.zero_grad()\nout=model.expectation({})\nout.backward()\noptimizer.step()\nprint(\"Ground state energy =\", out.item(), \"Hatree\")\n</code></pre> <pre><code>Ground state energy = -1.1449597119944634 Hatree\n</code></pre>"},{"location":"advanced_tutorials/vqe/#unrestricted-hamiltonian","title":"Unrestricted Hamiltonian","text":"<p>This result is in line with what obtained in the reference paper. Let's now perform the same calculations but with a standard hardware efficient ansatz (i.e. not specifically tailored for the H2 molecule) and with an unrestricted Hamiltonian on 4 qubits. The values of the coefficients are taken from BK Hamiltonian, page 28[^2].</p> <p><pre><code>from qadence import hea\nnqbits = 4\ngates = [[I,I,I,I],[Z],[Z],[Z],[Z,Z],[Z,Z],[Z,Z],[X,Z,X],[Y,Z,Y],[Z,Z,Z],[Z,Z,Z],[Z,Z,Z],[Z,X,Z,X],[Z,Y,Z,Y],[Z,Z,Z,Z]]\nqubits = [[0,1,2,3],[0],[1],[2],[0,1],[0,2],[1,3],[2,1,0],[2,1,0],[2,1,0],[3,2,0],[3,2,1],[3,2,1,0],[3,2,1,0],[3,2,1,0]]\ncoeffs = [\n-0.81261,0.171201,0.16862325,- 0.2227965,0.171201,0.12054625,0.17434925  ,0.04532175,0.04532175,0.165868 ,\n0.12054625,-0.2227965 ,0.04532175 ,0.04532175,0.165868\n]\nhamilt_R074_bis = [coeffs,gates,qubits]\nHamiltonian_bis = make_hamiltonian(hamilt_R074_bis, nqbits)\nansatz_bis = QuantumCircuit(4, hea(nqbits))\n</code></pre> %3 9e2c7fffed7c4f4b82a8ff6bd1c5cb0c 0 155dfc1efd8640a5a90ce98b21dc3a20 RX(theta\u2080) 9e2c7fffed7c4f4b82a8ff6bd1c5cb0c--155dfc1efd8640a5a90ce98b21dc3a20 5ed5b5ffd4e9450b859ee98ca62ec92d 1 750bf1243b9f4533bd08f2eb92115feb RY(theta\u2084) 155dfc1efd8640a5a90ce98b21dc3a20--750bf1243b9f4533bd08f2eb92115feb 2c09731d063245669bcd8782f711696d RX(theta\u2088) 750bf1243b9f4533bd08f2eb92115feb--2c09731d063245669bcd8782f711696d dbbd54205f674f928bd6736f8d62ef3f 2c09731d063245669bcd8782f711696d--dbbd54205f674f928bd6736f8d62ef3f dde36d08aaa84c68905cef18d20b26c6 dbbd54205f674f928bd6736f8d62ef3f--dde36d08aaa84c68905cef18d20b26c6 d7fa7dcbfc5e44dc971ac2824be54a30 dde36d08aaa84c68905cef18d20b26c6--d7fa7dcbfc5e44dc971ac2824be54a30 be690caa97354689afe5b9dd05987ee6 1e68b377fc0c41bea10b2fc870c12018 RX(theta\u2081) 5ed5b5ffd4e9450b859ee98ca62ec92d--1e68b377fc0c41bea10b2fc870c12018 db8be7ebde1f458987ad75570b1e009f 2 e5949fb757b84bbcb724b15d409012ac RY(theta\u2085) 1e68b377fc0c41bea10b2fc870c12018--e5949fb757b84bbcb724b15d409012ac 66728acff123451aa645def337fc04df RX(theta\u2089) e5949fb757b84bbcb724b15d409012ac--66728acff123451aa645def337fc04df e4c954f02fda46b78c53ce3d4eb85661 X 66728acff123451aa645def337fc04df--e4c954f02fda46b78c53ce3d4eb85661 e4c954f02fda46b78c53ce3d4eb85661--dbbd54205f674f928bd6736f8d62ef3f 5c0b8c910e0c4e57add7ab90523dcd25 e4c954f02fda46b78c53ce3d4eb85661--5c0b8c910e0c4e57add7ab90523dcd25 5c0b8c910e0c4e57add7ab90523dcd25--be690caa97354689afe5b9dd05987ee6 dc334bfc00d140b0a506547d3d13716c 45c773c45a1a4c06ae953c95d8f292b8 RX(theta\u2082) db8be7ebde1f458987ad75570b1e009f--45c773c45a1a4c06ae953c95d8f292b8 0f21b0afc7f34b2e97194df681fab66d 3 e0b3db40288f48988b76ddf0f220baab RY(theta\u2086) 45c773c45a1a4c06ae953c95d8f292b8--e0b3db40288f48988b76ddf0f220baab 3b3a1a873ce94aa39a92c1351d816e64 RX(theta\u2081\u2080) e0b3db40288f48988b76ddf0f220baab--3b3a1a873ce94aa39a92c1351d816e64 da2b0b5ede344fdf8e18bcc83c89afbe 3b3a1a873ce94aa39a92c1351d816e64--da2b0b5ede344fdf8e18bcc83c89afbe 8a0d36dd9a604fffa4a5ad23f7b027dd X da2b0b5ede344fdf8e18bcc83c89afbe--8a0d36dd9a604fffa4a5ad23f7b027dd 8a0d36dd9a604fffa4a5ad23f7b027dd--5c0b8c910e0c4e57add7ab90523dcd25 8a0d36dd9a604fffa4a5ad23f7b027dd--dc334bfc00d140b0a506547d3d13716c 99896b37906c488db829f47cda696571 064aac6a10664503bf6a4e8ca4132cb0 RX(theta\u2083) 0f21b0afc7f34b2e97194df681fab66d--064aac6a10664503bf6a4e8ca4132cb0 750a9f4e8d8a4114b8bc7e08664055a5 RY(theta\u2087) 064aac6a10664503bf6a4e8ca4132cb0--750a9f4e8d8a4114b8bc7e08664055a5 8aafadb8e3ae443bb865deec21fd0ef1 RX(theta\u2081\u2081) 750a9f4e8d8a4114b8bc7e08664055a5--8aafadb8e3ae443bb865deec21fd0ef1 b9c127e3892847db84d780696a7f402b X 8aafadb8e3ae443bb865deec21fd0ef1--b9c127e3892847db84d780696a7f402b b9c127e3892847db84d780696a7f402b--da2b0b5ede344fdf8e18bcc83c89afbe 201602e830d74d7b998a34f69b1ab012 b9c127e3892847db84d780696a7f402b--201602e830d74d7b998a34f69b1ab012 201602e830d74d7b998a34f69b1ab012--99896b37906c488db829f47cda696571 <pre><code>model = QuantumModel(ansatz_bis, observable=Hamiltonian_bis, backend=\"pyqtorch\", diff_mode=\"ad\")\nvalues={}\nout=model.expectation(values)\n# initialize some random initial parameters\ninit_params = torch.rand(model.num_vparams)\nmodel.reset_vparams(init_params)\nn_epochs = 100\nlr = 0.05\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nfor i in range(n_epochs):\noptimizer.zero_grad()\nout=model.expectation(values)\nout.backward()\noptimizer.step()\nif (i+1) % 10 == 0:\nprint(f\"Epoch {i+1} - Loss: {out.item()}\")\nprint(\"Ground state energy =\", out.item(),\"a.u\")\n</code></pre> <pre><code>Epoch 10 - Loss: -1.1329324443124502\nEpoch 20 - Loss: -1.405209968460553\nEpoch 30 - Loss: -1.765939961559965\nEpoch 40 - Loss: -1.8019699954319166\nEpoch 50 - Loss: -1.8181175217139227\nEpoch 60 - Loss: -1.8264773402663725\nEpoch 70 - Loss: -1.8294418234023306\nEpoch 80 - Loss: -1.8296881789023665\nEpoch 90 - Loss: -1.8303925469664442\nEpoch 100 - Loss: -1.8303628675056682\nGround state energy = -1.8303628675056682 a.u\n</code></pre> </p> <p>In a.u, the final ground state energy is a bit higher the expected -1.851 a.u (see page 33 of the reference paper mentioned above). Increasing the ansatz depth is enough to reach the desired accuracy.</p>"},{"location":"advanced_tutorials/vqe/#references","title":"References","text":"<ol> <li> <p>Seeley et al. - The Bravyi-Kitaev transformation for quantum computation of electronic structure\u00a0\u21a9</p> </li> </ol>"},{"location":"backends/backend/","title":"Abstract Backend","text":""},{"location":"backends/backend/#qadence.backend.Backend","title":"<code>Backend</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ABC</code></p> <p>The abstract class that defines the interface for the backends</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>backend unique string identifier</p> <p> TYPE: <code>BackendName</code> </p> <code>supports_ad</code> <p>whether or not the backend has a native autograd</p> <p> TYPE: <code>bool</code> </p> <code>supports_bp</code> <p>whether or not the backend has a native backprop</p> <p> TYPE: <code>bool</code> </p> <code>is_remote</code> <p>whether computations are executed locally or remotely on this backend, useful when using cloud platforms where credentials are needed for example.</p> <p> TYPE: <code>bool</code> </p> <code>with_measurements</code> <p>whether it supports counts or not</p> <p> TYPE: <code>bool</code> </p> <code>with_noise</code> <p>whether to add realistic noise or not</p> <p> TYPE: <code>bool</code> </p>"},{"location":"backends/backend/#qadence.backend.Backend.circuit","title":"<code>circuit(circuit)</code>  <code>abstractmethod</code>","text":"<p>Converts an abstract <code>QuantumCircuit</code> to the native backend representation.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A circuit, for example: <code>QuantumCircuit(2, X(0))</code></p> <p> TYPE: <code>QuantumCircuit</code> </p> RETURNS DESCRIPTION <code>ConvertedCircuit</code> <p>A converted circuit <code>c</code>. You can access the original, arbstract circuit via <code>c.abstract</code></p> <code>ConvertedCircuit</code> <p>and the converted (or backend native) circuit via <code>c.native</code>.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef circuit(self, circuit: QuantumCircuit) -&gt; ConvertedCircuit:\n\"\"\"Converts an abstract `QuantumCircuit` to the native backend representation.\n    Arguments:\n        circuit: A circuit, for example: `QuantumCircuit(2, X(0))`\n    Returns:\n        A converted circuit `c`. You can access the original, arbstract circuit via `c.abstract`\n        and the converted (or backend *native*) circuit via `c.native`.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.convert","title":"<code>convert(circuit, observable=None)</code>","text":"<p>Convert an abstract circuit (and optionally and observable) to their native representation. Additionally this function constructs an embedding function which maps from user-facing parameters to device parameters (read more on parameter embedding here).</p> Source code in <code>qadence/backend.py</code> <pre><code>def convert(\nself, circuit: QuantumCircuit, observable: list[AbstractBlock] | AbstractBlock | None = None\n) -&gt; Converted:\n\"\"\"Convert an abstract circuit (and optionally and observable) to their native\n    representation. Additionally this function constructs an embedding function which maps from\n    user-facing parameters to device parameters (read more on parameter embedding\n    [here][qadence.blocks.embedding.embedding]).\n    \"\"\"\ndef check_observable(obs_obj: Any) -&gt; AbstractBlock:\nif isinstance(obs_obj, QubitOperator):\nfrom qadence.blocks.manipulate import from_openfermion\nassert len(obs_obj.terms) &gt; 0, \"Make sure to give a non-empty qubit hamiltonian\"\nreturn from_openfermion(obs_obj)\nelif isinstance(obs_obj, (CompositeBlock, PrimitiveBlock, ScaleBlock)):\nfrom qadence.blocks.utils import block_is_qubit_hamiltonian\nassert block_is_qubit_hamiltonian(\nobs_obj\n), \"Make sure the QubitHamiltonian consists only of Pauli operators X, Y, Z, I\"\nreturn obs_obj\nraise TypeError(\n\"qubit_hamiltonian should be a Pauli-like AbstractBlock or a QubitOperator\"\n)\nconv_circ = self.circuit(circuit)\ncirc_params, circ_embedding_fn = embedding(\nconv_circ.abstract.block, self.config._use_gate_params\n)\nparams = circ_params\nif observable is not None:\nobservable = observable if isinstance(observable, list) else [observable]\nconv_obs = []\nobs_embedding_fn_list = []\nfor obs in observable:\nobs = check_observable(obs)\nc_obs = self.observable(obs, max(circuit.n_qubits, obs.n_qubits))\nobs_params, obs_embedding_fn = embedding(\nc_obs.abstract, self.config._use_gate_params\n)\nparams.update(obs_params)\nobs_embedding_fn_list.append(obs_embedding_fn)\nconv_obs.append(c_obs)\ndef embedding_fn_dict(a: dict, b: dict) -&gt; dict:\nembedding_dict = circ_embedding_fn(a, b)\nfor o in obs_embedding_fn_list:\nembedding_dict.update(o(a, b))\nreturn embedding_dict\nreturn Converted(conv_circ, conv_obs, embedding_fn_dict, params)\ndef embedding_fn(a: dict, b: dict) -&gt; dict:\nreturn circ_embedding_fn(a, b)\nreturn Converted(conv_circ, None, embedding_fn, params)\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, protocol=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Compute the expectation value of the <code>circuit</code> with the given <code>observable</code>.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bitstrings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef expectation(\nself,\ncircuit: ConvertedCircuit,\nobservable: list[ConvertedObservable] | ConvertedObservable,\nparam_values: dict[str, Tensor] = {},\nstate: Tensor | None = None,\nprotocol: Measurements | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Compute the expectation value of the `circuit` with the given `observable`.\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        endianness: Endianness of the resulting bitstrings.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.observable","title":"<code>observable(observable, n_qubits)</code>  <code>abstractmethod</code>","text":"<p>Converts an abstract observable (which is just an <code>AbstractBlock</code>) to the native backend representation.</p> PARAMETER  DESCRIPTION <code>observable</code> <p>An observable.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>n_qubits</code> <p>Number of qubits the observable covers. This is typically <code>circuit.n_qubits</code>.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ConvertedObservable</code> <p>A converted observable <code>o</code>. You can access the original, arbstract observable via</p> <code>ConvertedObservable</code> <p><code>o.abstract</code> and the converted (or backend native) observable via <code>o.native</code>.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef observable(self, observable: AbstractBlock, n_qubits: int) -&gt; ConvertedObservable:\n\"\"\"Converts an abstract observable (which is just an `AbstractBlock`) to the native backend\n    representation.\n    Arguments:\n        observable: An observable.\n        n_qubits: Number of qubits the observable covers. This is typically `circuit.n_qubits`.\n    Returns:\n        A converted observable `o`. You can access the original, arbstract observable via\n        `o.abstract` and the converted (or backend *native*) observable via `o.native`.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.run","title":"<code>run(circuit, param_values={}, state=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Run a circuit and return the resulting wave function.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting samples.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A list of Counter objects where each key represents a bitstring</p> <code>Tensor</code> <p>and its value the number of times it has been sampled from the given wave function.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef run(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor] = {},\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Run a circuit and return the resulting wave function.\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        endianness: Endianness of the resulting samples.\n    Returns:\n        A list of Counter objects where each key represents a bitstring\n        and its value the number of times it has been sampled from the given wave function.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.sample","title":"<code>sample(circuit, param_values={}, n_shots=1000, state=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Sample bit strings.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>n_shots</code> <p>Number of shots to sample.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bitstrings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef sample(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor] = {},\nn_shots: int = 1000,\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n\"\"\"Sample bit strings.\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        n_shots: Number of shots to sample.\n        state: Initial state.\n        endianness: Endianness of the resulting bitstrings.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.BackendConfiguration","title":"<code>BackendConfiguration</code>  <code>dataclass</code>","text":""},{"location":"backends/backend/#qadence.backend.BackendConfiguration.available_options","title":"<code>available_options()</code>","text":"<p>Return as a string the available fields with types of the configuration</p> RETURNS DESCRIPTION <code>str</code> <p>a string with all the available fields, one per line</p> <p> TYPE: <code>str</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>def available_options(self) -&gt; str:\n\"\"\"Return as a string the available fields with types of the configuration\n    Returns:\n        str: a string with all the available fields, one per line\n    \"\"\"\nconf_msg = \"\"\nfor field in fields(self):\nif not field.name.startswith(\"_\"):\nconf_msg += (\nf\"Name: {field.name} - Type: {field.type} - Default value: {field.default}\\n\"\n)\nreturn conf_msg\n</code></pre>"},{"location":"backends/backend/#qadence.backend.BackendConfiguration.get_param_name","title":"<code>get_param_name(blk)</code>","text":"<p>Return parameter names for the current backend. Depending on which backend is in use this function returns either UUIDs or expressions of parameters.</p> Source code in <code>qadence/backend.py</code> <pre><code>def get_param_name(self, blk: AbstractBlock) -&gt; Tuple[str, ...]:\n\"\"\"Return parameter names for the current backend. Depending on which backend is in use this\n    function returns either UUIDs or expressions of parameters.\"\"\"\nparam_ids: Tuple\n# FIXME: better type hiearchy?\ntypes = (TimeEvolutionBlock, ParametricBlock, ConstantAnalogRotation, WaitBlock)\nif not isinstance(blk, types):\nraise TypeError(f\"Can not infer param name from {type(blk)}\")\nelse:\nif self._use_gate_params:\nparam_ids = tuple(blk.parameters.uuids())\nelse:\nparam_ids = tuple(map(stringify, blk.parameters.expressions()))\nreturn param_ids\n</code></pre>"},{"location":"backends/braket/","title":"Amazon Braket","text":""},{"location":"backends/braket/#braket-digital-backend","title":"Braket Digital backend","text":""},{"location":"backends/braket/#qadence.backends.braket.backend.Backend","title":"<code>Backend</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Backend</code></p>"},{"location":"backends/braket/#qadence.backends.braket.backend.Backend.assign_parameters","title":"<code>assign_parameters(circuit, param_values)</code>","text":"<p>Assign numerical values to the circuit parameters</p> Source code in <code>qadence/backends/braket/backend.py</code> <pre><code>def assign_parameters(\nself, circuit: ConvertedCircuit, param_values: dict[str, Tensor | float]\n) -&gt; BraketCircuit:\n\"\"\"Assign numerical values to the circuit parameters\"\"\"\nif param_values is None:\nreturn circuit.native()\nparams_copy = param_values.copy()\npnames = [p.name for p in circuit.native.parameters]\n# account for fixed parameters\nfor name in param_values.keys():\nif name not in pnames:\nparams_copy.pop(name)\n# make sure that all the parameters are single floats\n# otherwise it won't be accepted by Braket\nnative_params = promote_parameters(params_copy)\n# assign the parameters to the circuit\nassigned_circuit = circuit.native(**native_params)\nreturn assigned_circuit\n</code></pre>"},{"location":"backends/braket/#qadence.backends.braket.backend.Backend.run","title":"<code>run(circuit, param_values={}, state=None, endianness=Endianness.BIG)</code>","text":"<p>Execute the circuit and return a wavefunction in form of a statevector.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>The circuit that is executed.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Parameters of the circuit (after calling the embedding function on the user-facing parameters).</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>The endianness of the wave function.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backends/braket/backend.py</code> <pre><code>def run(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor] = {},\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"\n    Execute the circuit and return a wavefunction in form of a statevector.\n    Arguments:\n        circuit: The circuit that is executed.\n        param_values: Parameters of the circuit (after calling the embedding\n            function on the user-facing parameters).\n        state: Initial state.\n        endianness: The endianness of the wave function.\n    \"\"\"\nif state is not None:\nraise NotImplementedError\nif self.is_remote:\n# handle here, or different backends?\nraise NotImplementedError\n# loop over all values in the batch\nresults = []\nfor vals in to_list_of_dicts(param_values):\nfinal_circuit = self.assign_parameters(circuit, vals)\nfinal_circuit.state_vector()  # set simulation type\ntask = self._device.run(final_circuit, 0)\nresults.append(task.result().values[0])\nstates = torch.tensor(np.array(results))\nn_qubits = circuit.abstract.n_qubits\nif endianness != self.native_endianness and n_qubits &gt; 1:\nfrom qadence.transpile import invert_endianness\nstates = invert_endianness(states)\nreturn states\n</code></pre>"},{"location":"backends/braket/#qadence.backends.braket.backend.Backend.sample","title":"<code>sample(circuit, param_values={}, n_shots=1, state=None, endianness=Endianness.BIG)</code>","text":"<p>Execute the circuit and return samples of the resulting wavefunction.</p> Source code in <code>qadence/backends/braket/backend.py</code> <pre><code>def sample(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor] = {},\nn_shots: int = 1,\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n\"\"\"Execute the circuit and return samples of the resulting wavefunction.\"\"\"\nif state is not None:\nraise NotImplementedError(\"Braket cannot handle a custom initial state.\")\nif n_shots &lt; 1:\nraise ValueError(\"You can only call sample with n_shots&gt;0.\")\nif self.is_remote:\n# handle here, or different backends?\nraise NotImplementedError\n# loop over all values in the batch\nsamples = []\nfor vals in to_list_of_dicts(param_values):\nfinal_circuit = self.assign_parameters(circuit, vals)\ntask = self._device.run(final_circuit, n_shots)\nsamples.append(task.result().measurement_counts)\nif endianness != self.native_endianness:\nfrom qadence.transpile import invert_endianness\nsamples = invert_endianness(samples)\nreturn samples\n</code></pre>"},{"location":"backends/differentiable/","title":"DifferentiableBackend","text":""},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableBackend","title":"<code>DifferentiableBackend(backend, diff_mode=DiffMode.AD, **psr_args)</code>","text":"<p>             Bases: <code>Module</code></p> <p>A class to abstract the operations done by the autodiff engine</p> PARAMETER  DESCRIPTION <code>backend</code> <p>An instance of the QuantumBackend type perform execution.</p> <p> TYPE: <code>Backend</code> </p> <code>diff_mode</code> <p>A differentiable mode supported by the differentiation engine.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>**psr_args</code> <p>Arguments that will be passed on to <code>DifferentiableExpectation</code>.</p> <p> TYPE: <code>int | float | None</code> DEFAULT: <code>{}</code> </p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>def __init__(\nself,\nbackend: QuantumBackend,\ndiff_mode: DiffMode = DiffMode.AD,\n**psr_args: int | float | None,\n) -&gt; None:\nsuper().__init__()\nself.backend = backend\nself.diff_mode = diff_mode\nself.psr_args = psr_args\n# TODO: Add differentiable overlap calculation\nself._overlap: Callable = None  # type: ignore [assignment]\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableBackend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, protocol=None, endianness=Endianness.BIG)</code>","text":"<p>Compute the expectation value of a given observable.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A backend native quantum circuit to be executed.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>observable</code> <p>A backend native observable to compute the expectation value from.</p> <p> TYPE: <code>list[ConvertedObservable] | ConvertedObservable</code> </p> <code>param_values</code> <p>A dict of values for symbolic substitution.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>An initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>protocol</code> <p>A shot-based measurement protocol.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the state.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A tensor of expectation values.</p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>def expectation(\nself,\ncircuit: ConvertedCircuit,\nobservable: list[ConvertedObservable] | ConvertedObservable,\nparam_values: dict[str, Tensor] = {},\nstate: Tensor | None = None,\nprotocol: Measurements | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Compute the expectation value of a given observable.\n    Arguments:\n        circuit: A backend native quantum circuit to be executed.\n        observable: A backend native observable to compute the expectation value from.\n        param_values: A dict of values for symbolic substitution.\n        state: An initial state.\n        protocol: A shot-based measurement protocol.\n        endianness: Endianness of the state.\n    Returns:\n        A tensor of expectation values.\n    \"\"\"\nobservable = observable if isinstance(observable, list) else [observable]\ndifferentiable_expectation = DifferentiableExpectation(\nbackend=self.backend,\ncircuit=circuit,\nobservable=observable,\nparam_values=param_values,\nstate=state,\nprotocol=protocol,\nendianness=endianness,\n)\nif self.diff_mode == DiffMode.AD:\nexpectation = differentiable_expectation.ad\nelse:\ntry:\nfns = get_gpsr_fns()\npsr_fn = fns[self.diff_mode]\nexcept KeyError:\nraise ValueError(f\"{self.diff_mode} differentiation mode is not supported\")\nexpectation = partial(differentiable_expectation.psr, psr_fn=psr_fn, **self.psr_args)\nreturn expectation()\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableBackend.run","title":"<code>run(circuit, param_values={}, state=None, endianness=Endianness.BIG)</code>","text":"<p>Run on the underlying backend.</p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>def run(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict = {},\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Run on the underlying backend.\"\"\"\nreturn self.backend.run(\ncircuit=circuit, param_values=param_values, state=state, endianness=endianness\n)\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableBackend.sample","title":"<code>sample(circuit, param_values, state=None, n_shots=1, endianness=Endianness.BIG)</code>","text":"<p>Sample bitstring from the registered circuit.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A backend native quantum circuit to be executed.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>The values of the parameters after embedding</p> <p> TYPE: <code>dict[str, Tensor]</code> </p> <code>n_shots</code> <p>The number of shots. Defaults to 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>list[Counter]</code> <p>An iterable with all the sampled bitstrings</p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>def sample(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor],\nstate: Tensor | None = None,\nn_shots: int = 1,\nendianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n\"\"\"Sample bitstring from the registered circuit.\n    Arguments:\n        circuit: A backend native quantum circuit to be executed.\n        param_values: The values of the parameters after embedding\n        n_shots: The number of shots. Defaults to 1.\n    Returns:\n        An iterable with all the sampled bitstrings\n    \"\"\"\nwith torch.no_grad():\nreturn self.backend.sample(\ncircuit=circuit,\nparam_values=param_values,\nstate=state,\nn_shots=n_shots,\nendianness=endianness,\n)\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableExpectation","title":"<code>DifferentiableExpectation</code>  <code>dataclass</code>","text":"<p>A handler for differentiating expectation estimation using various engines.</p>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableExpectation.construct_rules","title":"<code>construct_rules(circuit, observable, psr_fn, **psr_args)</code>  <code>staticmethod</code>","text":"<p>Create a mapping between parameters and PSR functions.</p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>@staticmethod\ndef construct_rules(\ncircuit: QuantumCircuit,\nobservable: list[AbstractBlock],\npsr_fn: Callable,\n**psr_args: int | float | None,\n) -&gt; dict[str, Callable]:\n\"\"\"Create a mapping between parameters and PSR functions.\"\"\"\nuuid_to_eigs = uuid_to_eigen(circuit.block)\n# We currently rely on implicit ordering to match the PSR to the parameter,\n# because we want to cache PSRs.\nparam_to_psr = OrderedDict()\nfor param_id, eigenvalues in uuid_to_eigs.items():\nif eigenvalues is None:\nraise ValueError(\nf\"Eigenvalues are not defined for param_id {param_id}\\n\"\n# f\"of type {type(block)}.\\n\"\n\"PSR cannot be defined in that case.\"\n)\nparam_to_psr[param_id] = psr_fn(eigenvalues, **psr_args)\nfor obs in observable:\nfor param_id, _ in uuid_to_eigen(obs).items():\n# We need the embedded fixed params of the observable in the param_values dict\n# to be able to call expectation. Since torch backward requires\n# a list of param_ids and values of equal length, we need to pass them to PSR too.\n# Since they are constants their gradients are 0.\nparam_to_psr[param_id] = lambda x: torch.tensor([0.0], requires_grad=False)\nreturn param_to_psr\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.PSRExpectation","title":"<code>PSRExpectation</code>","text":"<p>             Bases: <code>Function</code></p> <p>Overloads the PyTorch AD system to perform parameter shift rule on quantum circuits.</p>"},{"location":"backends/pulser/","title":"Pulser","text":"<p>The Pulser backend features a basic integration with the pulse-level programming interface Pulser. This backend offers for now few simple operations which are translated into a valid, non time-dependent pulse sequence. In particular, one has access to:</p> <ul> <li>analog rotations: <code>AnalogRx</code> and <code>AnalogRy</code> blocks</li> <li>free evolution blocks (basically no pulse, just interaction): <code>AnalogWait</code> block</li> <li>a block for creating entangled states: <code>AnalogEntanglement</code></li> <li>digital rotation <code>Rx</code> and <code>Ry</code></li> </ul>"},{"location":"backends/pulser/#qadence.backends.pulser.backend.Backend","title":"<code>Backend</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Backend</code></p> <p>The Pulser backend</p>"},{"location":"backends/pulser/#qadence.backends.pulser.backend.create_register","title":"<code>create_register(register, spacing=DEFAULT_SPACING)</code>","text":"<p>Create Pulser register instance.</p> PARAMETER  DESCRIPTION <code>register</code> <p>graph representing a register with accompanying coordinate data</p> <p> TYPE: <code>Register</code> </p> <code>spacing</code> <p>distance between qubits in micrometers</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_SPACING</code> </p> RETURNS DESCRIPTION <code>Register</code> <p>Pulser register</p> <p> TYPE: <code>Register</code> </p> Source code in <code>qadence/backends/pulser/backend.py</code> <pre><code>def create_register(register: Register, spacing: float = DEFAULT_SPACING) -&gt; PulserRegister:\n\"\"\"Create Pulser register instance.\n    Args:\n        register (Register): graph representing a register with accompanying coordinate data\n        spacing (float): distance between qubits in micrometers\n    Returns:\n        Register: Pulser register\n    \"\"\"\n# create register from coordinates\ncoords = np.array(list(register.coords.values()))\nreturn PulserRegister.from_coordinates(coords * spacing)\n</code></pre>"},{"location":"backends/pulser/#qadence.backends.pulser.devices.Device","title":"<code>Device</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Supported types of devices for Pulser backend</p>"},{"location":"backends/pulser/#qadence.backends.pulser.devices.Device.IDEALIZED","title":"<code>IDEALIZED = IdealDevice</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>idealized device, least realistic</p>"},{"location":"backends/pulser/#qadence.backends.pulser.devices.Device.REALISTIC","title":"<code>REALISTIC = RealisticDevice</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>device with realistic specs</p>"},{"location":"backends/pyqtorch/","title":"PyQTorch","text":"<p>Fast differentiable statevector emulator based on PyTorch. The code is open source, hosted on Github and maintained by Pasqal.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend","title":"<code>Backend</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Backend</code></p> <p>PyQTorch backend.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend.convert","title":"<code>convert(circuit, observable=None)</code>","text":"<p>Convert an abstract circuit (and optionally and observable) to their native representation. Additionally this function constructs an embedding function which maps from user-facing parameters to device parameters (read more on parameter embedding here).</p> Source code in <code>qadence/backend.py</code> <pre><code>def convert(\nself, circuit: QuantumCircuit, observable: list[AbstractBlock] | AbstractBlock | None = None\n) -&gt; Converted:\n\"\"\"Convert an abstract circuit (and optionally and observable) to their native\n    representation. Additionally this function constructs an embedding function which maps from\n    user-facing parameters to device parameters (read more on parameter embedding\n    [here][qadence.blocks.embedding.embedding]).\n    \"\"\"\ndef check_observable(obs_obj: Any) -&gt; AbstractBlock:\nif isinstance(obs_obj, QubitOperator):\nfrom qadence.blocks.manipulate import from_openfermion\nassert len(obs_obj.terms) &gt; 0, \"Make sure to give a non-empty qubit hamiltonian\"\nreturn from_openfermion(obs_obj)\nelif isinstance(obs_obj, (CompositeBlock, PrimitiveBlock, ScaleBlock)):\nfrom qadence.blocks.utils import block_is_qubit_hamiltonian\nassert block_is_qubit_hamiltonian(\nobs_obj\n), \"Make sure the QubitHamiltonian consists only of Pauli operators X, Y, Z, I\"\nreturn obs_obj\nraise TypeError(\n\"qubit_hamiltonian should be a Pauli-like AbstractBlock or a QubitOperator\"\n)\nconv_circ = self.circuit(circuit)\ncirc_params, circ_embedding_fn = embedding(\nconv_circ.abstract.block, self.config._use_gate_params\n)\nparams = circ_params\nif observable is not None:\nobservable = observable if isinstance(observable, list) else [observable]\nconv_obs = []\nobs_embedding_fn_list = []\nfor obs in observable:\nobs = check_observable(obs)\nc_obs = self.observable(obs, max(circuit.n_qubits, obs.n_qubits))\nobs_params, obs_embedding_fn = embedding(\nc_obs.abstract, self.config._use_gate_params\n)\nparams.update(obs_params)\nobs_embedding_fn_list.append(obs_embedding_fn)\nconv_obs.append(c_obs)\ndef embedding_fn_dict(a: dict, b: dict) -&gt; dict:\nembedding_dict = circ_embedding_fn(a, b)\nfor o in obs_embedding_fn_list:\nembedding_dict.update(o(a, b))\nreturn embedding_dict\nreturn Converted(conv_circ, conv_obs, embedding_fn_dict, params)\ndef embedding_fn(a: dict, b: dict) -&gt; dict:\nreturn circ_embedding_fn(a, b)\nreturn Converted(conv_circ, None, embedding_fn, params)\n</code></pre>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration","title":"<code>Configuration</code>  <code>dataclass</code>","text":"<p>             Bases: <code>BackendConfiguration</code></p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.interaction","title":"<code>interaction: Callable | Interaction | str = Interaction.NN</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Digital-analog emulation interaction that is used for <code>AnalogBlock</code>s.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.loop_expectation","title":"<code>loop_expectation: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>When computing batches of expectation values, only allocate one wavefunction and loop over the batch of parameters to only allocate a single wavefunction at any given time.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.use_gradient_checkpointing","title":"<code>use_gradient_checkpointing: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use gradient checkpointing. Recommended for higher-order optimization tasks.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.use_single_qubit_composition","title":"<code>use_single_qubit_composition: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Composes chains of single qubit gates into a single matmul if possible.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.supported_gates","title":"<code>supported_gates = list(set(OpName.list()) - set([OpName.TDAGGER]))</code>  <code>module-attribute</code>","text":"<p>The set of supported gates. Tdagger is currently not supported.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.PyQComposedBlock","title":"<code>PyQComposedBlock(ops, qubits, n_qubits, config=None)</code>","text":"<p>             Bases: <code>Module</code></p> <p>Compose a chain of single qubit operations on the same qubit into a single call to _apply_batch_gate.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def __init__(\nself,\nops: list[Module],\nqubits: list[int] | tuple,\nn_qubits: int,\nconfig: Configuration = None,\n):\n\"\"\"Compose a chain of single qubit operations on the same qubit into a single\n    call to _apply_batch_gate.\"\"\"\nsuper().__init__()\nself.operations = ops\nself.qubits = qubits\nself.n_qubits = n_qubits\n</code></pre>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.ScalePyQOperation","title":"<code>ScalePyQOperation(n_qubits, block, config)</code>","text":"<p>             Bases: <code>Module</code></p> <p>Computes:</p> <pre><code>M = matrix(op, theta)\nscale * matmul(M, state)\n</code></pre> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def __init__(self, n_qubits: int, block: ScaleBlock, config: Configuration):\nsuper().__init__()\n(self.param_name,) = config.get_param_name(block)\nif not isinstance(block.block, PrimitiveBlock):\nraise NotImplementedError(\n\"The pyqtorch backend can currently only scale `PrimitiveBlock` types.\\\n            Please use the following transpile function on your circuit first:\\\n            from qadence.transpile import scale_primitive_blocks_only\"\n)\nself.operation = convert_block(block.block, n_qubits, config)[0]\ndef _fwd(state: torch.Tensor, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\nreturn values[self.param_name] * self.operation(state, values)\nif config.use_gradient_checkpointing:\ndef _forward(state: torch.Tensor, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\nreturn checkpoint(_fwd, state, values, use_reentrant=False)\nelse:\ndef _forward(state: torch.Tensor, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\nreturn _fwd(state, values)\nself._forward = _forward\n</code></pre>"},{"location":"development/architecture/","title":"Architecture and Sharp Bits","text":"<p>Qadence as a software library mixes functional and object-oriented programming. We do that by maintaining core objects and operating on them with functions.</p> <p>Furthermore, Qadence strives at keeping the lower level abstraction layers for automatic differentiation and quantum computation fully stateless while only the frontend layer which is the main user-facing interface is stateful.</p> <p>Code design philosopy</p> <p>Functional, stateless core with object-oriented, stateful user interface.</p>"},{"location":"development/architecture/#abstraction-layers","title":"Abstraction layers","text":"<p>In Qadence there are 4 main objects spread across 3 different levels of abstraction:</p> <ul> <li> <p>Frontend layer: The user facing layer and encompasses two objects:</p> <ul> <li><code>QuantumCircuit</code>: A class representing an abstract quantum   circuit not tight not any particular framework. Parameters are represented symbolically using   <code>sympy</code> expressions.</li> <li><code>QuantumModel</code>: The models are higher-level abstraction   providing an interface for executing different kinds of common quantum computing models such   quantum neural networks (QNNs), quantum kernels etc.</li> </ul> </li> <li> <p>Differentiation layer: Intermediate layer has the purpose of integrating quantum   computation with a given automatic differentiation engine. It is meant to be purely stateless and   contains one object:</p> <ul> <li><code>DifferentiableBackend</code>:   An abstract class whose concrete implementation wraps a quantum backend and make it   automatically differentiable using different engines (e.g. PyTorch or Jax).   Note, that today only PyTorch is supported but there is plan to add also a Jax   differentiable backend which will require some changes in the base class implementation.</li> </ul> </li> <li> <p>Quantum layer: The lower-level layer which directly interfaces with quantum emulators   and processing units. It is meant to be purely stateless and it contains one base object which is   specialized for each supported backend:</p> <ul> <li><code>Backend</code>: An abstract class whose concrete implementation   enables the execution of quantum circuit with a variety of quantum backends (normally non   automatically differentiable by default) such as PyQTorch, Pulser or Braket.</li> </ul> </li> </ul>"},{"location":"development/architecture/#main-components","title":"Main components","text":""},{"location":"development/architecture/#quantumcircuit","title":"<code>QuantumCircuit</code>","text":"<p>We consider <code>QuantumCircuit</code> to be an abstract object, i.e. it is not tied to any backend. However, it blocks are even more abstract. This is because we consider <code>QuantumCircuit</code>s \"real\", whereas the blocks are largely considered just syntax.</p> <p>Unitary <code>QuantumCircuits</code> (this encompasses digital, or gate-based, circuits as well as analog circuits) are constructed by [<code>PrimitiveBlocks</code>] using a syntax that allows you to execute them in sequence, dubbed <code>ChainBlock</code> in the code, or in parallel (i.e. at the same time) where applicable, dubbed <code>KronBlock</code> in the code. Notice that this differs from other packages by providing more control of the layout of the circuit than conventional packages like Qiskit, and from Yao where the blocks are the primary type.</p>"},{"location":"development/architecture/#quantummodel","title":"<code>QuantumModel</code>","text":"<p><code>QuantumModel</code>s are meant to be the main entry point for quantum computations in <code>qadence</code>. In general, they take one or more quantum circuit as input and they wrap all the necessary boiler plate code to make the circuit executable and differentiable on the chosen backend.</p> <p>Models are meant to be specific for a certain kind of quantum problem or algorithm and you can easily create new ones starting from the base class <code>QuantumModel</code>, as explained in the custom model tutorial. Currently, Qadence offers a <code>QNN</code> model class which provides convenient methods to work with quantum neural networks with multi-dimensional inputs and outputs.</p>"},{"location":"development/architecture/#differentiablebackend","title":"<code>DifferentiableBackend</code>","text":"<p>The differentiable backend is a thin wrapper which takes as input a <code>QuantumCircuit</code> instance and a chosen quantum backend and make the circuit execution routines (expectation value, overalap, etc.) differentiable. Currently, the only implemented differentiation engine is PyTorch but it is easy to add support to another one like Jax.</p>"},{"location":"development/architecture/#quantum-backend","title":"Quantum <code>Backend</code>","text":"<p>For execution the primary object is the <code>Backend</code>. Backends maintain the same user-facing interface, and internally connects to other libraries to execute circuits. Those other libraries can execute the code on QPUs and local or cloud-based emulators. The <code>Backends</code> use PyTorch tensors to represent data and leverages PyTorchs autograd to help compute derivatives of circuits.</p>"},{"location":"development/architecture/#symbolic-parameters","title":"Symbolic parameters","text":"<p>To illustrate how parameters work in Qadence, let's consider the following simple block composed of just two rotations:</p> <pre><code>import sympy\nfrom qadence import Parameter, RX\nparam = Parameter(\"phi\", trainable=False)\nblock = RX(0, param) * RX(1, sympy.acos(param))\n</code></pre> <p>The rotation angles assigned to <code>RX</code> (and to any Qadence quantum operation) are defined as arbitrary expressions of <code>Parameter</code>'s. <code>Parameter</code> is a subclass of <code>sympy.Symbol</code>, thus fully interoperable with it.</p> <p>To assign values of the parameter <code>phi</code> in a quantum model, one should use a dictionary containing the a key with parameter name and the corresponding values values:</p> <pre><code>import torch\nfrom qadence import run\nvalues = {\"phi\": torch.rand(10)}\nwf = run(block, values=values)\n</code></pre> <p>This is the only interface for parameter assignment exposed to the user. Under the hood, parameters applied to every quantum operation are identified in different ways:</p> <ul> <li> <p>By default, with a stringified version of the <code>sympy</code> expression supplied to the quantum operation. Notice that multiple operations can have the same expression.</p> </li> <li> <p>In certain case, e.g. for constructing parameter shift rules, one must access a unique identifier of the parameter for each quantum operation. Therefore, Qadence also creates unique identifiers for each parametrized operation (see the <code>ParamMap</code> class).</p> </li> </ul> <p>By default, when one constructs a new backend, the parameter identifiers are the <code>sympy</code> expressions which are used when converting an abstract block into a native circuit for the chosen backend. However, one can use the unique identifiers as parameter names by setting the private flag <code>_use_gate_params</code> to <code>True</code> in the backend configuration <code>BackendConfiguration</code>. This is automatically set when PSR differentiation is selected (see next section for more details).</p> <p>You can see the logic for choosing the parameter identifier in <code>get_param_name</code>.</p>"},{"location":"development/architecture/#differentiation-with-parameter-shift-rules-psr","title":"Differentiation with parameter shift rules (PSR)","text":"<p>In Qadence, parameter shift rules are implemented by extending the PyTorch autograd engine using custom <code>Function</code> objects. The implementation is based on this PyTorch guide.</p> <p>A custom PyTorch <code>Function</code> looks like this:</p> <pre><code>import torch\nfrom torch.autograd import Function\nclass CustomFunction(Function):\n# forward pass implementation giving the output of the module\n@staticmethod\ndef forward(ctx, inputs: torch.Tensor, params: torch.Tensor):\nctx.save_for_backward(inputs, params)\n...\n# backward pass implementation giving the derivative of the module\n# with respect to the parameters. This must return the whole vector-jacobian\n# product to integrate within the autograd engine\n@staticmethod\ndef backward(ctx, grad_output: torch.Tensor):\ninputs, params = ctx.saved_tensors\n...\n</code></pre> <p>The class <code>PSRExpectation</code> implements parameter shift rules for all parameters using a custom function as the one above. There are a few implementation details to keep in mind if you want to modify the PSR code:</p> <ul> <li> <p>PyTorch <code>Function</code> only works with tensor arguments. Parameters in Qadence are passed around as   dictionaries with parameter names as keys and current parameter values (tensors)   as values. This works for both variational and feature parameters. However, the <code>Function</code> class   only work with PyTorch tensors as input, not dictionaries. Therefore, the forward pass of   <code>PSRExpectation</code> accepts one argument <code>param_keys</code> with the   parameter keys and a variadic positional argument <code>param_values</code> with the parameter values one by   one. The dictionary is reconstructed within the <code>forward()</code> pass body.</p> </li> <li> <p>Higher-order derivatives with PSR. Higher-order PSR derivatives can be tricky. Parameter shift   rules calls, under the hood, the <code>QuantumBackend</code> expectation value routine that usually yield a   non-differentiable output. Therefore, a second call to the backward pass would not work. However,   Qadence employs a very simple trick to make higher-order derivatives work: instead of using   directly the expectation value of the quantum backend, the PSR backward pass uses the PSR forward   pass itself as expectation value function (see the code below). In this way, multiple calls to the   backward pass are allowed since the <code>expectation_fn</code> routine is always differentiable by   definition. Notice that this implementation is simple but suboptimal since, in some corner cases,   higher-order derivates might include some repeated terms that, with this implementation, are   always recomputed.</p> </li> </ul> <pre><code># expectation value used in the PSR backward pass\ndef expectation_fn(params: dict[str, Tensor]) -&gt; Tensor:\nreturn PSRExpectation.apply(\nctx.expectation_fn,\nctx.param_psrs,\nparams.keys(),\n*params.values(),\n)\n</code></pre> <ul> <li> <p>Operation parameters must be uniquely identified for PSR to work. Parameter shift rules work at the level of individual quantum operations. This means that, given a parameter <code>x</code>, one needs to sum the contributions from shifting the parameter values of all the operation where the parameter <code>x</code> appears. When constructing the PSR rules, one must access a unique parameter identifier for each operation even if the corresponding user-facing parameter is the same. Therefore, when PSR differentiation is selected, the flag <code>_use_gate_params</code> is automatically set to <code>True</code> in the backend configuration <code>BackendConfiguration</code> (see previous section).</p> </li> <li> <p>PSR must not be applied to observable parameters. In Qadence, Pauli observables can also be parametrized. However, the tunable parameters of observables are purely classical and should not be included in the differentiation with PSRs. However, the quantum expectation value depends on them, thus they still need to enter into the PSR evaluation. To solve this issue, the code sets the <code>requires_grad</code> attribute of all observable parameters to <code>False</code> when constructing the PSRs for the circuit as in the snippet below:</p> </li> </ul> <pre><code>for obs in observable:\nfor param_id, _ in uuid_to_eigen(obs).items():\nparam_to_psr[param_id] = lambda x: torch.tensor([0.0], requires_grad=False)\n</code></pre>"},{"location":"development/contributing/","title":"How to contribute","text":"<p>We're grateful for your interest in participating in Qadence. Please follow our guidelines to ensure a smooth contribution process.</p>"},{"location":"development/contributing/#reporting-an-issue-or-proposing-a-feature","title":"Reporting an issue or proposing a feature","text":"<p>Your course of action will depend on your objective, but generally, you should start by creating an issue. If you've discovered a bug or have a feature you'd like to see added to qadence, feel free to create an issue on qadence's GitHub issue tracker. Here are some steps to take:</p> <ol> <li>Quickly search the existing issues using relevant keywords to ensure your issue hasn't been addressed already.</li> <li> <p>If your issue is not listed, create a new one. Try to be as detailed and clear as possible in your description.</p> </li> <li> <p>If you're merely suggesting an improvement or reporting a bug, that's already excellent! We thank you for it. Your issue will be listed and, hopefully, addressed at some point.</p> </li> <li>However, if you're willing to be the one solving the issue, that would be even better! In such instances, you would proceed by preparing a Pull Request.</li> </ol>"},{"location":"development/contributing/#submitting-a-pull-request","title":"Submitting a pull request","text":"<p>We're excited that you're eager to contribute to Qadence. To contribute, fork the <code>main</code> branch of qadence repository and once you are satisfied with your feature and all the tests pass create a Pull Request.</p> <p>Here's the process for making a contribution:</p> <p>Click the \"Fork\" button at the upper right corner of the repo page to create a new GitHub repo at <code>https://github.com/USERNAME/qadence</code>, where <code>USERNAME</code> is your GitHub ID. Then, <code>cd</code> into the directory where you want to place your new fork and clone it:</p> <pre><code>git clone https://github.com/USERNAME/qadence.git\n</code></pre> <p>Next, navigate to your new qadence fork directory and mark the main qadence repository as the <code>upstream</code>:</p> <pre><code>git remote add upstream https://github.com/pasqal-io/qadence.git\n</code></pre>"},{"location":"development/contributing/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>We recommended to use <code>hatch</code> for managing environments:</p> <p>To develop within qadence, use: <pre><code>pip install hatch\nhatch -v shell\n</code></pre></p> <p>To run qadence tests, use:</p> <pre><code>hatch -e tests run test\n</code></pre> <p>If you don't want to use <code>hatch</code>, you can use the environment manager of your choice (e.g. Conda) and execute the following:</p> <pre><code>pip install pytest\npip install -e .\npytest\n</code></pre>"},{"location":"development/contributing/#useful-things-for-your-workflow-linting-and-testing","title":"Useful things for your workflow: linting and testing","text":"<p>Use <code>pre-commit</code> to lint your code and run the unit tests before pushing a new commit.</p> <p>Using <code>hatch</code>, it's simply:</p> <pre><code>hatch -e tests run pre-commit run --all-files\nhatch -e tests run test\n</code></pre> <p>Our CI/CD pipeline will also test if the documentation can be built correctly. To test it locally, please run:</p> <pre><code>hatch -e docs run mkdocs build --clean --strict\n</code></pre> <p>Without <code>hatch</code>, <code>pip</code> install those libraries first: \"mkdocs\", \"mkdocs-material\", \"mkdocstrings\", \"mkdocstrings-python\", \"mkdocs-section-index\", \"mkdocs-jupyter\", \"mkdocs-exclude\", \"markdown-exec\"</p> <p>And then:</p> <pre><code> mkdocs build --clean --strict\n</code></pre>"},{"location":"development/draw/","title":"<code>qadence.draw</code> example plots","text":"<p>Mostly for quick, manual checking of correct plotting output.</p> <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\nb = kron(X(0), Y(1))\n</code></pre> %3 109ad1a1bce94013ba33d35d43b6748d 0 d0fc010d03374a42b60a3fcab624df67 X 109ad1a1bce94013ba33d35d43b6748d--d0fc010d03374a42b60a3fcab624df67 fd6701e38d444436be30eb0b569b94ff 1 8d70fc34ccf74933bd24b8aecae9cb45 d0fc010d03374a42b60a3fcab624df67--8d70fc34ccf74933bd24b8aecae9cb45 54a0507f485243fd92f96871321d2bfa a9c7c33e017e4843af71e1489735f6ab Y fd6701e38d444436be30eb0b569b94ff--a9c7c33e017e4843af71e1489735f6ab a9c7c33e017e4843af71e1489735f6ab--54a0507f485243fd92f96871321d2bfa <pre><code>from qadence import X, Y, chain\nfrom qadence.draw import display\nb = chain(X(0), Y(0))\n</code></pre> %3 eb11e535b6614bb286ab8956a6f77eb8 0 8437a1700a244814a34a7e9a9bc263ef X eb11e535b6614bb286ab8956a6f77eb8--8437a1700a244814a34a7e9a9bc263ef 04d733a382b84474b0ac095155476552 Y 8437a1700a244814a34a7e9a9bc263ef--04d733a382b84474b0ac095155476552 380d223b97c1430995798acf14626c7f 04d733a382b84474b0ac095155476552--380d223b97c1430995798acf14626c7f <pre><code>from qadence import X, Y, chain\nfrom qadence.draw import display\nb = chain(X(0), Y(1))\n</code></pre> %3 0fe8355ead264aa8aad4435b5c10f426 0 cc8e845c079c4366ad7e7e635f6bbe3a X 0fe8355ead264aa8aad4435b5c10f426--cc8e845c079c4366ad7e7e635f6bbe3a 113b47574e3b422f917bfdae17e1ce14 1 04b47de7854946599353edb55d224bd4 cc8e845c079c4366ad7e7e635f6bbe3a--04b47de7854946599353edb55d224bd4 1098207122b640c5b499d8b229f0c8ba 04b47de7854946599353edb55d224bd4--1098207122b640c5b499d8b229f0c8ba 2c524d14d7b24f01a6a023aa0a882ef1 768b1035bb6f49cca0eff8ee48125f66 113b47574e3b422f917bfdae17e1ce14--768b1035bb6f49cca0eff8ee48125f66 4596c897da7945209b3fc620cfd9039f Y 768b1035bb6f49cca0eff8ee48125f66--4596c897da7945209b3fc620cfd9039f 4596c897da7945209b3fc620cfd9039f--2c524d14d7b24f01a6a023aa0a882ef1 <pre><code>from qadence import X, Y, add\nfrom qadence.draw import display\nb = add(X(0), Y(1), X(2))\n</code></pre> %3 cluster_3e2cf219df1349f4a9223c5745977e3d b0ca98326c1f4376a648b3771aa92738 0 736190a11fd24e5d988b61d06961c011 b0ca98326c1f4376a648b3771aa92738--736190a11fd24e5d988b61d06961c011 d3c3a9ce3ce14dc0a235ca83f2f16171 1 a152301d75c24de08db0e58712d3dee0 736190a11fd24e5d988b61d06961c011--a152301d75c24de08db0e58712d3dee0 6729d81aaf9743a0a2cbe22b82adf6e9 01a37f3493e0441ca8b4d69225ab7533 AddBlock d3c3a9ce3ce14dc0a235ca83f2f16171--01a37f3493e0441ca8b4d69225ab7533 f2173a1301b44467b72b5b8dd7690557 2 01a37f3493e0441ca8b4d69225ab7533--6729d81aaf9743a0a2cbe22b82adf6e9 f9c67049f80f4ff69e91fa4f49c83869 775f1282106b4aed94475424f0c4be71 f2173a1301b44467b72b5b8dd7690557--775f1282106b4aed94475424f0c4be71 775f1282106b4aed94475424f0c4be71--f9c67049f80f4ff69e91fa4f49c83869 <pre><code>from qadence import CNOT, RX, HamEvo, X, Y, Z, chain, kron\nrx = kron(RX(3,0.5), RX(2, \"x\"))\nrx.tag = \"rx\"\ngen = chain(Z(i) for i in range(4))\n# `chain` puts things in sequence\nblock = chain(\nkron(X(0), Y(1), rx),\nCNOT(2,3),\nHamEvo(gen, 10)\n)\n</code></pre> %3 cluster_a3c2157180d94fefb8b17527bef4e8ed cluster_5c5256e65cb4419ea97f5a4198ce0a83 rx 9791abd453e44b68bc8e7d73ed5eac12 0 78fe4ceec8894cefb72b4f5683a88c52 X 9791abd453e44b68bc8e7d73ed5eac12--78fe4ceec8894cefb72b4f5683a88c52 2587ba0a3e6c410a9640109d19fa4a0b 1 08dc8b8c921b468b9b81c1f071fbada9 78fe4ceec8894cefb72b4f5683a88c52--08dc8b8c921b468b9b81c1f071fbada9 c9d4579ef8ea47238979c3cb8ac00ffe 08dc8b8c921b468b9b81c1f071fbada9--c9d4579ef8ea47238979c3cb8ac00ffe 4f6aded2f6094bb9b06a1f7724660015 c9d4579ef8ea47238979c3cb8ac00ffe--4f6aded2f6094bb9b06a1f7724660015 07007ec8a1444c0d96bb4a198bce8deb 2bc2c5df6621400e91ed531ec8247d66 Y 2587ba0a3e6c410a9640109d19fa4a0b--2bc2c5df6621400e91ed531ec8247d66 8a544687da6a494db2237583e6c56780 2 2fecb4a05191481ca8c57a47eedf842c 2bc2c5df6621400e91ed531ec8247d66--2fecb4a05191481ca8c57a47eedf842c 35d2188ce79840139ff4db1c3d12ecc7 HamEvo 2fecb4a05191481ca8c57a47eedf842c--35d2188ce79840139ff4db1c3d12ecc7 35d2188ce79840139ff4db1c3d12ecc7--07007ec8a1444c0d96bb4a198bce8deb 5e0abc0184ac4bc5a27108d82bc20e25 87caddc9c7324d01bd909743b339133c RX(x) 8a544687da6a494db2237583e6c56780--87caddc9c7324d01bd909743b339133c 625ea252d483459f98353b038d78d14b 3 b6ef37b9bc834cebb380fa9de064021b 87caddc9c7324d01bd909743b339133c--b6ef37b9bc834cebb380fa9de064021b f51a2caa8d824b329e036b609360568b t = 10 b6ef37b9bc834cebb380fa9de064021b--f51a2caa8d824b329e036b609360568b f51a2caa8d824b329e036b609360568b--5e0abc0184ac4bc5a27108d82bc20e25 4478451489d840769ac5caad36ebbe15 56e67fde613945a9ad1ebb32f99d292e RX(0.5) 625ea252d483459f98353b038d78d14b--56e67fde613945a9ad1ebb32f99d292e e771cd2fd063461ba515f6b4e0db445a X 56e67fde613945a9ad1ebb32f99d292e--e771cd2fd063461ba515f6b4e0db445a e771cd2fd063461ba515f6b4e0db445a--b6ef37b9bc834cebb380fa9de064021b dd42ab52932c451cbd992087e344c8b4 e771cd2fd063461ba515f6b4e0db445a--dd42ab52932c451cbd992087e344c8b4 dd42ab52932c451cbd992087e344c8b4--4478451489d840769ac5caad36ebbe15 <pre><code>from qadence import feature_map, hea, chain\nblock = chain(feature_map(4, fm_type=\"tower\"), hea(4,2))\n</code></pre> %3 cluster_70ce1e429549474986a336ae4a84e5e9 HEA cluster_186dda4d94a84d6dbf89c7bff83e3abd FM 4b16a31900174cdabb2a9e30fc020d55 0 5f6d338a40664c8896c54830835481cd RX(2*acos(phi)) 4b16a31900174cdabb2a9e30fc020d55--5f6d338a40664c8896c54830835481cd e9f5815442ac45c7aceb37d85f227178 1 f568dc091d6d4aa3b7fa7a19fa2aaab7 RX(theta\u2080) 5f6d338a40664c8896c54830835481cd--f568dc091d6d4aa3b7fa7a19fa2aaab7 ea8c27a26a7f4e21b4b6fca208ca3b52 RY(theta\u2084) f568dc091d6d4aa3b7fa7a19fa2aaab7--ea8c27a26a7f4e21b4b6fca208ca3b52 d28990e8dc6540808098d6f58001e008 RX(theta\u2088) ea8c27a26a7f4e21b4b6fca208ca3b52--d28990e8dc6540808098d6f58001e008 4fa0409ce5504a2db5dafe160eb466f3 d28990e8dc6540808098d6f58001e008--4fa0409ce5504a2db5dafe160eb466f3 775a9f63128145528e699793f88b9f65 4fa0409ce5504a2db5dafe160eb466f3--775a9f63128145528e699793f88b9f65 21e4275d1ed0402e991624081a09aa6d RX(theta\u2081\u2082) 775a9f63128145528e699793f88b9f65--21e4275d1ed0402e991624081a09aa6d ba0f85670e154d8daaf46a0e4611c2a7 RY(theta\u2081\u2086) 21e4275d1ed0402e991624081a09aa6d--ba0f85670e154d8daaf46a0e4611c2a7 5efc87a8e38f4ddc8c2255e135dd7295 RX(theta\u2082\u2080) ba0f85670e154d8daaf46a0e4611c2a7--5efc87a8e38f4ddc8c2255e135dd7295 a677f5a396574bdfac0c3a2e66d412a7 5efc87a8e38f4ddc8c2255e135dd7295--a677f5a396574bdfac0c3a2e66d412a7 76b3a5ff7aa14258980a0303e961c1bc a677f5a396574bdfac0c3a2e66d412a7--76b3a5ff7aa14258980a0303e961c1bc ff1d2fa0956e4b539fa67a94dcf1233c 76b3a5ff7aa14258980a0303e961c1bc--ff1d2fa0956e4b539fa67a94dcf1233c 5fe6a417e96a4e9d9e6e7e4c0b3caa3e 7bb34908008c40b3998c6a13bb0eb7e5 RX(4*acos(phi)) e9f5815442ac45c7aceb37d85f227178--7bb34908008c40b3998c6a13bb0eb7e5 d8a4596e48de46f5a18964d0f32fab38 2 e90ae3ef11794785ab549b214f48e970 RX(theta\u2081) 7bb34908008c40b3998c6a13bb0eb7e5--e90ae3ef11794785ab549b214f48e970 0ddeb94d384c4e59812d156d88ae7ed7 RY(theta\u2085) e90ae3ef11794785ab549b214f48e970--0ddeb94d384c4e59812d156d88ae7ed7 78a65398ff564967b68432d55bacee14 RX(theta\u2089) 0ddeb94d384c4e59812d156d88ae7ed7--78a65398ff564967b68432d55bacee14 117a8ee5f1b24fec92e217d1620cc254 X 78a65398ff564967b68432d55bacee14--117a8ee5f1b24fec92e217d1620cc254 117a8ee5f1b24fec92e217d1620cc254--4fa0409ce5504a2db5dafe160eb466f3 d37b4771f469405c999fd9d017fba773 117a8ee5f1b24fec92e217d1620cc254--d37b4771f469405c999fd9d017fba773 b229add32771423684748515922a391f RX(theta\u2081\u2083) d37b4771f469405c999fd9d017fba773--b229add32771423684748515922a391f 08865c0138fa43cf8d91026a505a0ab9 RY(theta\u2081\u2087) b229add32771423684748515922a391f--08865c0138fa43cf8d91026a505a0ab9 abc8f61f59934becb5ec11a4ee0114b3 RX(theta\u2082\u2081) 08865c0138fa43cf8d91026a505a0ab9--abc8f61f59934becb5ec11a4ee0114b3 a5df8f8100564ba28fdbb0d8b156dd10 X abc8f61f59934becb5ec11a4ee0114b3--a5df8f8100564ba28fdbb0d8b156dd10 a5df8f8100564ba28fdbb0d8b156dd10--a677f5a396574bdfac0c3a2e66d412a7 d85310693da54fa5ba293f69c4f792c8 a5df8f8100564ba28fdbb0d8b156dd10--d85310693da54fa5ba293f69c4f792c8 d85310693da54fa5ba293f69c4f792c8--5fe6a417e96a4e9d9e6e7e4c0b3caa3e b1f6394f84be44a18bbf0e95b1422f88 5b48c9fdc95745c59fd0038f0f4c6e0b RX(6*acos(phi)) d8a4596e48de46f5a18964d0f32fab38--5b48c9fdc95745c59fd0038f0f4c6e0b 0b8da4d0846e4358a8b4c6f6ecbdd9d1 3 e89f8337da234297bdb70e801c7e48e0 RX(theta\u2082) 5b48c9fdc95745c59fd0038f0f4c6e0b--e89f8337da234297bdb70e801c7e48e0 de7f441b9dd94c9c9e387d2fe75511f9 RY(theta\u2086) e89f8337da234297bdb70e801c7e48e0--de7f441b9dd94c9c9e387d2fe75511f9 a2c2955d92094c8a82d16d80605a75d2 RX(theta\u2081\u2080) de7f441b9dd94c9c9e387d2fe75511f9--a2c2955d92094c8a82d16d80605a75d2 52c0992ffa0c404abe3624eb68853dc5 a2c2955d92094c8a82d16d80605a75d2--52c0992ffa0c404abe3624eb68853dc5 0e0bbbc583e640c291c0d72fe9d6e863 X 52c0992ffa0c404abe3624eb68853dc5--0e0bbbc583e640c291c0d72fe9d6e863 0e0bbbc583e640c291c0d72fe9d6e863--d37b4771f469405c999fd9d017fba773 49fc20d6865a4336a9ee53fd564385a7 RX(theta\u2081\u2084) 0e0bbbc583e640c291c0d72fe9d6e863--49fc20d6865a4336a9ee53fd564385a7 a4a7a13bcd3c495482ce4a3a4ada3fdf RY(theta\u2081\u2088) 49fc20d6865a4336a9ee53fd564385a7--a4a7a13bcd3c495482ce4a3a4ada3fdf edd6874a9ea8473f9076670fc13dd7bf RX(theta\u2082\u2082) a4a7a13bcd3c495482ce4a3a4ada3fdf--edd6874a9ea8473f9076670fc13dd7bf c1a76a6f54ab4cd09f94ea4059a13411 edd6874a9ea8473f9076670fc13dd7bf--c1a76a6f54ab4cd09f94ea4059a13411 21dbcd511f3b4ea3be9c00a8f5e8f971 X c1a76a6f54ab4cd09f94ea4059a13411--21dbcd511f3b4ea3be9c00a8f5e8f971 21dbcd511f3b4ea3be9c00a8f5e8f971--d85310693da54fa5ba293f69c4f792c8 21dbcd511f3b4ea3be9c00a8f5e8f971--b1f6394f84be44a18bbf0e95b1422f88 1f7e8ac0dc524d609af94f4a1d38c6b2 ab406fcd52364cd0835434d4e6055f53 RX(8*acos(phi)) 0b8da4d0846e4358a8b4c6f6ecbdd9d1--ab406fcd52364cd0835434d4e6055f53 e556031d1e7d4472a5e7261503d9a122 RX(theta\u2083) ab406fcd52364cd0835434d4e6055f53--e556031d1e7d4472a5e7261503d9a122 90a26f38af1c4ad4b6e98c28730734e0 RY(theta\u2087) e556031d1e7d4472a5e7261503d9a122--90a26f38af1c4ad4b6e98c28730734e0 2ed939d7794e42499e6b62aebc8b628e RX(theta\u2081\u2081) 90a26f38af1c4ad4b6e98c28730734e0--2ed939d7794e42499e6b62aebc8b628e feabb528dd3742f38127d312c956404f X 2ed939d7794e42499e6b62aebc8b628e--feabb528dd3742f38127d312c956404f feabb528dd3742f38127d312c956404f--52c0992ffa0c404abe3624eb68853dc5 19029927885649ceab0afb35f4f1f251 feabb528dd3742f38127d312c956404f--19029927885649ceab0afb35f4f1f251 bd25cab76b434a928b10587393fa84bd RX(theta\u2081\u2085) 19029927885649ceab0afb35f4f1f251--bd25cab76b434a928b10587393fa84bd 25c068e65aa542809816945cdb6f9033 RY(theta\u2081\u2089) bd25cab76b434a928b10587393fa84bd--25c068e65aa542809816945cdb6f9033 d612b14f72e24df98c3c7d0349f190fb RX(theta\u2082\u2083) 25c068e65aa542809816945cdb6f9033--d612b14f72e24df98c3c7d0349f190fb 9ca94b6419a446c59cecb96f20bd2650 X d612b14f72e24df98c3c7d0349f190fb--9ca94b6419a446c59cecb96f20bd2650 9ca94b6419a446c59cecb96f20bd2650--c1a76a6f54ab4cd09f94ea4059a13411 b565e36ab39d45bfb0aa2f3da3f629cf 9ca94b6419a446c59cecb96f20bd2650--b565e36ab39d45bfb0aa2f3da3f629cf b565e36ab39d45bfb0aa2f3da3f629cf--1f7e8ac0dc524d609af94f4a1d38c6b2"},{"location":"development/draw/#developer-documentation","title":"Developer documentation","text":"<p>This section contains examples in pure graphviz that can be used to understand roughly what is done in the actual drawing backend.</p> <pre><code>import graphviz\nfont_name = \"Sans-Serif\"\nfont_size = \"8\"\ngraph_attr = {\n\"rankdir\": \"LR\",  # LR = left to right, TB = top to bottom\n\"nodesep\": \"0.1\",  # In inches, tells distance between nodes without edges\n\"compound\": \"true\",  # Needed to draw properly edges in hamevo when content is hidden\n\"splines\": \"false\",  # Needed to draw control gates vertical lines one over the other\n}  # These are the default values for graphs\nnode_attr = {\n\"shape\": \"box\",  # 'box' for normal nodes, 'point' for control gates or 'plaintext' for starting nodes (the qubit label).\n\"style\": \"rounded\",  # Unfortunately we can't specify the radius of the rounded, at least for this version\n\"fontname\": font_name,\n\"fontsize\": font_size,\n\"width\": \"0.1\",  # In inches, it doesn't get tinier than the label font.\n\"height\": \"0.1\"  # In inches, it doesn't get tinier than the label font.\n}  # These are the defaults values that can be overridden at node declaration.\ndefault_cluster_attr = {\n\"fontname\": font_name,\n\"fontsize\": font_size,\n\"labelloc\": \"b\",  # location of cluster label. b as bottom, t as top\n\"style\": \"rounded\"\n} # These are the defaults values that can be overridden at sub graph declaration\nhamevo_cluster_attr = {\n\"label\": \"HamEvo(t=10)\"\n}\nhamevo_cluster_attr.update(default_cluster_attr)\nh = graphviz.Graph(graph_attr=graph_attr, node_attr=node_attr)\nh.node(\"Hello World!\")\nh\n</code></pre> <pre><code>\n</code></pre> <pre><code># Define graph\nh = graphviz.Graph(node_attr=node_attr, graph_attr=graph_attr)\n# Add start and end nodes\nfor i in range(4):\nh.node(f's{i}', shape=\"plaintext\", label=f'{i}', group=f\"{i}\")\nh.node(f'e{i}', style='invis', group=f\"{i}\")\n# Add nodes\nh.node('X', group=\"0\")\nh.node('Y', group=\"1\")\n# Add hamevo and its nodes\nhamevo = graphviz.Graph(name='cluster_hamevo', graph_attr=hamevo_cluster_attr)\nfor i in range(4):\nhamevo.node(f'z{i}', shape=\"box\", style=\"invis\", label=f'{i}', group=f\"{i}\")\nh.subgraph(hamevo)\n# Add rx gates cluster and its nodes\ncluster_attr = {\"label\": \"RX gates\"}\ncluster_attr.update(default_cluster_attr)\ncluster = graphviz.Graph(name=\"cluster_0\", graph_attr=cluster_attr)\ncluster.node('RX(x)', group=\"2\")\ncluster.node('RX(0.5)', group=\"3\")\nh.subgraph(cluster)\nh.node('cnot0', label='', shape='point', width='0.1', group='0')\nh.node('cnot1', label='X', group='1')\nh.node('cnot2', label='', shape='point', width='0.1', group='2')\nh.node('cnot3', label='', shape='point', width='0.1', group='3')\n# Add edges\nh.edge('s0', 'X')\nh.edge('X', 'cnot0')\nh.edge('cnot0', 'z0', lhead='cluster_hamevo')\nh.edge('z0', 'e0', ltail='cluster_hamevo')\nh.edge('s1', 'Y')\nh.edge('Y', 'cnot1')\nh.edge('cnot1', 'z1', lhead='cluster_hamevo')\nh.edge('z1', 'e1', ltail='cluster_hamevo')\nh.edge('s2', 'RX(x)')\nh.edge('RX(x)', 'cnot2')\nh.edge('cnot2', 'z2', lhead='cluster_hamevo')\nh.edge('z2', 'e2', ltail='cluster_hamevo')\nh.edge('s3', 'RX(0.5)')\nh.edge('RX(0.5)', 'cnot3')\nh.edge('cnot3', 'z3', lhead='cluster_hamevo')\nh.edge('z3', 'e3', ltail='cluster_hamevo')\nh.edge('cnot1', 'cnot0', constraint='false')  # constraint: false is needed to draw vertical edges\nh.edge('cnot1', 'cnot2', constraint='false')  # constraint: false is needed to draw vertical edges\nh.edge('cnot1', 'cnot3', constraint='false')  # constraint: false is needed to draw vertical edges\nh\n</code></pre> <pre><code>\n</code></pre>"},{"location":"development/draw/#example-of-cluster-of-clusters","title":"Example of cluster of clusters","text":"<pre><code># Define graph\nh = graphviz.Graph(node_attr=node_attr, graph_attr=graph_attr)\n# Define start and end nodes\nfor i in range(4):\nh.node(f's{i}', shape=\"plaintext\", label=f'{i}', group=f\"{i}\")\nh.node(f'e{i}', style='invis', group=f\"{i}\")\n# Define outer cluster\ncluster_attr = {\"label\": \"Outer cluster\"}\ncluster_attr.update(default_cluster_attr)\nouter_cluster = graphviz.Graph(name=\"cluster_outer\", graph_attr=cluster_attr)\n# Define inner cluster 1 and its nodes\ncluster_attr = {\"label\": \"Inner cluster 1\"}\ncluster_attr.update(default_cluster_attr)\ninner1_cluster = graphviz.Graph(name=\"cluster_inner1\", graph_attr=cluster_attr)\ninner1_cluster.node(\"a0\", group=\"0\")\ninner1_cluster.node(\"a1\", group=\"1\")\nouter_cluster.subgraph(inner1_cluster)\n# Define inner cluster 2 and its nodes\ncluster_attr = {\"label\": \"Inner cluster 2\"}\ncluster_attr.update(default_cluster_attr)\ninner2_cluster = graphviz.Graph(name=\"cluster_inner2\", graph_attr=cluster_attr)\ninner2_cluster.node(\"a2\", group=\"2\")\ninner2_cluster.node(\"a3\", group=\"3\")\nouter_cluster.subgraph(inner2_cluster)\n# This has to be done here, after inner clusters definitions\nh.subgraph(outer_cluster)\n# Define more nodes\nfor i in range(4):\nh.node(f\"b{i}\", group=f\"{i}\")\nfor i in range(4):\nh.edge(f's{i}', f'a{i}')\nh.edge(f'a{i}', f'b{i}')\nh.edge(f'b{i}', f'e{i}')\nh\n</code></pre> <pre><code>\n</code></pre>"},{"location":"digital_analog_qc/analog-basics/","title":"Digital-Analog Emulation","text":"<p>TL;DR: Automatic emulation in the <code>pyqtorch</code> backend</p> <p>All analog blocks are automatically translated to their emulated version when running them with the <code>pyqtorch</code> backend (by calling <code>add_interaction</code> on them under the hood):</p> <p><pre><code>import torch\nfrom qadence import Register, AnalogRX, sample\nreg = Register.from_coordinates([(0,0), (0,5)])\nprint(sample(reg, AnalogRX(torch.pi)))\n</code></pre> <pre><code>[Counter({'01': 35, '00': 33, '10': 32})]\n</code></pre> </p> <p>Qadence includes primitives for the simple construction of ising-like Hamiltonians to account for the interaction among qubits.  This allows to simulate systems closer to real quantum computing platforms such as neutral atoms. The constructed Hamiltonians are of the form</p> \\[ \\mathcal{H} = \\sum_{i} \\frac{\\hbar\\Omega}{2} \\hat\\sigma^x_i - \\sum_{i} \\hbar\\delta \\hat n_i  + \\mathcal{H}_{int}, \\] <p>where \\(\\hat n = \\frac{1-\\hat\\sigma_z}{2}\\), and \\(\\mathcal{H}_{int}\\) is a pair-wise interaction term.</p> <p>We currently have two central operations that can be used to compose analog programs.</p> <ul> <li><code>WaitBlock</code> for interactions</li> <li><code>ConstantAnalogRotation</code></li> </ul> <p>Both are time-independent and can be emulated by calling <code>add_interaction</code>.</p> <p>To compose analog blocks you can use <code>chain</code> and <code>kron</code> as usual with the following restrictions:</p> <ul> <li><code>AnalogChain</code>s can only be constructed from AnalogKron blocks   or globally supported primitive, analog blocks.</li> <li><code>AnalogKron</code>s can only be constructed from non-global,   analog blocks with the same duration.</li> </ul> <p>The <code>wait</code> operation can be emulated with an Ising or an \\(XY\\)-interaction:</p> <pre><code>from qadence import Register, wait, add_interaction, run\nblock = wait(duration=3000)\nprint(block)\nreg = Register.from_coordinates([(0,0), (0,5)])  # we need atomic distances\nemulated = add_interaction(reg, block, interaction=\"XY\")  # or: interaction=\"Ising\"\nprint(emulated.generator)\n</code></pre> <pre><code>WaitBlock(t=3000.0, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,))\nAddBlock(0,1)\n\u2514\u2500\u2500 [mul: 29.600] \u2514\u2500\u2500 AddBlock(0,1)\n\u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u251c\u2500\u2500 X(0)\n\u2502   \u2514\u2500\u2500 X(1)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u251c\u2500\u2500 Y(0)\n\u2514\u2500\u2500 Y(1)\n</code></pre> <p>The <code>AnalogRot</code> constructor can create any constant (in time), analog rotation.</p> <pre><code>import torch\nfrom qadence import AnalogRot, AnalogRX\n# implement a global RX rotation\nblock = AnalogRot(\nduration=1000.,  # [ns]\nomega=torch.pi, # [rad/\u03bcs]\ndelta=0,        # [rad/\u03bcs]\nphase=0,        # [rad]\n)\nprint(block)\n# or use the short hand\nblock = AnalogRX(torch.pi)\nprint(block)\n</code></pre> <pre><code>ConstantAnalogRotation(\u03b1=3.14159265358979, t=1000.00000000000, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,), \u03a9=3.14159265358979, \u03b4=0, \u03c6=0)\nConstantAnalogRotation(\u03b1=3.14159265358979, t=1000.00000000000, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,), \u03a9=3.14159265358979, \u03b4=0, \u03c6=0)\n</code></pre> <p>Analog blocks can also be <code>chain</code>ed, and <code>kron</code>ed like all other blocks, but with two small caveats:</p> <pre><code>import torch\nfrom qadence import AnalogRot, kron, chain, wait\n# only blocks with the same `duration` can be `kron`ed\nkron(\nwait(duration=1000, qubit_support=(0,1)),\nAnalogRot(duration=1000, omega=2.0, qubit_support=(2,3))\n)\n# only blocks with `\"global\"` or the same qubit support can be `chain`ed\nchain(wait(duration=200), AnalogRot(duration=300, omega=2.0))\n</code></pre> <p>Composing digital &amp; analog blocks</p> <p>You can also compose digital and analog blocks where the additional restrictions of <code>chain</code>/<code>kron</code> only apply to composite blocks which only contain analog blocks. For more details/examples, see <code>AnalogChain</code> and <code>AnalogKron</code>.</p>"},{"location":"digital_analog_qc/analog-basics/#fitting-a-simple-function","title":"Fitting a simple function","text":"<p>Just as most other blocks, analog blocks can be parametrized, and thus we can build a small ansatz which can fit a sine wave. When using the <code>pyqtorch</code> backend the <code>add_interaction</code> function is called automatically. As usual, we can choose which differentiation backend we want to use: autodiff or parameter shift rule (PSR).</p> <p>First we define an ansatz block and an observable <pre><code>import torch\nfrom qadence import Register, FeatureParameter, VariationalParameter\nfrom qadence import AnalogRX, AnalogRZ, Z\nfrom qadence import wait, chain, add\npi = torch.pi\n# two qubit register\nreg = Register.from_coordinates([(0, 0), (0, 12)])\n# analog ansatz with input parameter\nt = FeatureParameter(\"t\")\nblock = chain(\nAnalogRX(pi / 2),\nAnalogRZ(t),\nwait(1000 * VariationalParameter(\"theta\", value=0.5)),\nAnalogRX(pi / 2),\n)\n# observable\nobs = add(Z(i) for i in range(reg.n_qubits))\n</code></pre> </p> <p></p> <p>Then we define the dataset we want to train on and plot the initial prediction. <pre><code>import matplotlib.pyplot as plt\nfrom qadence import QuantumCircuit, QuantumModel\n# define quantum model; including digital-analog emulation\ncirc = QuantumCircuit(reg, block)\nmodel = QuantumModel(circ, obs, diff_mode=\"gpsr\")\nx_train = torch.linspace(0, 6, steps=30)\ny_train = -0.64 * torch.sin(x_train + 0.33) + 0.1\ny_pred_initial = model.expectation({\"t\": x_train})\nfig, ax = plt.subplots()\nscatter(ax, x_train, y_train, label=\"Training points\", marker=\"o\", color=\"green\")\nplot(ax, x_train, y_pred_initial, label=\"Initial prediction\")\nplt.legend()\n</code></pre> 2023-10-10T21:36:14.426865 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ </p> <p>The rest is the usual PyTorch training routine. <pre><code>mse_loss = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-2)\ndef loss_fn(x_train, y_train):\nreturn mse_loss(model.expectation({\"t\": x_train}).squeeze(), y_train)\n# train\nn_epochs = 200\nfor i in range(n_epochs):\noptimizer.zero_grad()\nloss = loss_fn(x_train, y_train)\nloss.backward()\noptimizer.step()\n# if (i + 1) % 10 == 0:\n#     print(f\"Epoch {i+1:0&gt;3} - Loss: {loss.item()}\\n\")\n# visualize\ny_pred = model.expectation({\"t\": x_train})\nfig, ax = plt.subplots()\nscatter(ax, x_train, y_train, label=\"Training points\", marker=\"o\", color=\"green\")\nplot(ax, x_train, y_pred_initial, label=\"Initial prediction\")\nplot(ax, x_train, y_pred, label=\"Final prediction\")\nplt.legend()\n</code></pre> 2023-10-10T21:36:22.723484 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ </p>"},{"location":"digital_analog_qc/analog-qubo/","title":"Solve a QUBO Problem","text":"<p>In this notebook we solve a quadratic unconstrained optimization problem with <code>qadence</code> emulated analog interface using the QAOA variational algorithm. The problem is detailed in the Pulser documentation here.</p> Construct QUBO register (defines <code>qubo_register_coords</code> function) <p>Before we start we have to define a register that fits into our device. <pre><code>import torch\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import pdist, squareform\nfrom pulser.devices import Chadoq2\nseed = 0\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ndef qubo_register_coords(Q):\n\"\"\"Compute coordinates for register.\"\"\"\nbitstrings = [np.binary_repr(i, len(Q)) for i in range(len(Q) ** 2)]\ncosts = []\n# this takes exponential time with the dimension of the QUBO\nfor b in bitstrings:\nz = np.array(list(b), dtype=int)\ncost = z.T @ Q @ z\ncosts.append(cost)\nzipped = zip(bitstrings, costs)\nsort_zipped = sorted(zipped, key=lambda x: x[1])\ndef evaluate_mapping(new_coords, *args):\n\"\"\"Cost function to minimize. Ideally, the pairwise\n        distances are conserved\"\"\"\nQ, shape = args\nnew_coords = np.reshape(new_coords, shape)\nnew_Q = squareform(Chadoq2.interaction_coeff / pdist(new_coords) ** 6)\nreturn np.linalg.norm(new_Q - Q)\nshape = (len(Q), 2)\ncosts = []\nnp.random.seed(0)\nx0 = np.random.random(shape).flatten()\nres = minimize(\nevaluate_mapping,\nx0,\nargs=(Q, shape),\nmethod=\"Nelder-Mead\",\ntol=1e-6,\noptions={\"maxiter\": 200000, \"maxfev\": None},\n)\nreturn [(x, y) for (x, y) in np.reshape(res.x, (len(Q), 2))]\n</code></pre> </p>"},{"location":"digital_analog_qc/analog-qubo/#define-and-solve-qubo","title":"Define and solve QUBO","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom qadence import add_interaction, chain\nfrom qadence import QuantumModel, QuantumCircuit, AnalogRZ, AnalogRX, Register\nseed = 0\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n</code></pre> <p>The QUBO is defined by weighted connections <code>Q</code> and a cost function.</p> <pre><code>def cost_colouring(bitstring, Q):\nz = np.array(list(bitstring), dtype=int)\ncost = z.T @ Q @ z\nreturn cost\ndef cost_fn(counter, Q):\ncost = sum(counter[key] * cost_colouring(key, Q) for key in counter)\nreturn cost / sum(counter.values())  # Divide by total samples\nQ = np.array(\n[\n[-10.0, 19.7365809, 19.7365809, 5.42015853, 5.42015853],\n[19.7365809, -10.0, 20.67626392, 0.17675796, 0.85604541],\n[19.7365809, 20.67626392, -10.0, 0.85604541, 0.17675796],\n[5.42015853, 0.17675796, 0.85604541, -10.0, 0.32306662],\n[5.42015853, 0.85604541, 0.17675796, 0.32306662, -10.0],\n]\n)\n</code></pre> <p>Build a register from graph extracted from the QUBO exactly as you would do with Pulser. <pre><code>reg = Register.from_coordinates(qubo_register_coords(Q))\n</code></pre> </p> <p>The analog circuit is composed of two global rotations per layer.  The first rotation corresponds to the mixing Hamiltonian and the second one to the embedding Hamiltonian.  Subsequently we add the Ising interaction term to emulate the analog circuit.  This uses a principal quantum number n=70 for the Rydberg level under the hood. <pre><code>from qadence.transpile.emulate import ising_interaction\nLAYERS = 2\nblock = chain(*[AnalogRX(f\"t{i}\") * AnalogRZ(f\"s{i}\") for i in range(LAYERS)])\nemulated = add_interaction(\nreg, block, interaction=lambda r, ps: ising_interaction(r, ps, rydberg_level=70)\n)\nprint(emulated)\n</code></pre> <pre><code>ChainBlock(0,1,2,3,4)\n\u251c\u2500\u2500 ChainBlock(0,1,2,3,4)\n\u2502   \u251c\u2500\u2500 HamEvo(0,1,2,3,4) [params: ['51_4100727736005*t0']]\n\u2502   \u2514\u2500\u2500 HamEvo(0,1,2,3,4) [params: ['39_0388262113427*s0']]\n\u2514\u2500\u2500 ChainBlock(0,1,2,3,4)\n\u251c\u2500\u2500 HamEvo(0,1,2,3,4) [params: ['51_4100727736005*t1']]\n\u2514\u2500\u2500 HamEvo(0,1,2,3,4) [params: ['39_0388262113427*s1']]\n</code></pre> </p> <p>Sample the model to get the initial solution. <pre><code>model = QuantumModel(QuantumCircuit(reg, emulated), backend=\"pyqtorch\", diff_mode='gpsr')\ninitial_counts = model.sample({}, n_shots=1000)[0]\n</code></pre> </p> <p>The loss function is defined by averaging over the evaluated bitstrings. <pre><code>def loss(param, *args):\nQ = args[0]\nparam = torch.tensor(param)\nmodel.reset_vparams(param)\nC = model.sample({}, n_shots=1000)[0]\nreturn cost_fn(C, Q)\n</code></pre>  Here we use a gradient-free optimization loop for reaching the optimal solution. <pre><code>#\nfor i in range(20):\ntry:\nres = minimize(\nloss,\nargs=Q,\nx0=np.random.uniform(1, 10, size=2 * LAYERS),\nmethod=\"COBYLA\",\ntol=1e-8,\noptions={\"maxiter\": 20},\n)\nexcept Exception:\npass\n# sample the optimal solution\nmodel.reset_vparams(res.x)\noptimal_count_dict = model.sample({}, n_shots=1000)[0]\nprint(optimal_count_dict)\n</code></pre> <pre><code>Counter({'00111': 299, '00011': 187, '01010': 94, '00010': 77, '00101': 62, '01011': 52, '00001': 49, '10010': 44, '00100': 42, '00110': 32, '01001': 15, '01000': 12, '10011': 10, '01111': 7, '10001': 6, '01110': 5, '00000': 3, '01100': 3, '01101': 1})\n</code></pre> </p> <pre><code>fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n# known solutions to the QUBO\nsolution_bitstrings=[\"01011\", \"00111\"]\nn_to_show = 20\nxs, ys = zip(*sorted(\ninitial_counts.items(),\nkey=lambda item: item[1],\nreverse=True\n))\ncolors = [\"r\" if x in solution_bitstrings else \"g\" for x in xs]\naxs[0].set_xlabel(\"bitstrings\")\naxs[0].set_ylabel(\"counts\")\naxs[0].bar(xs[:n_to_show], ys[:n_to_show], width=0.5, color=colors)\naxs[0].tick_params(axis=\"x\", labelrotation=90)\naxs[0].set_title(\"Initial solution\")\nxs, ys = zip(*sorted(optimal_count_dict.items(),\nkey=lambda item: item[1],\nreverse=True\n))\ncolors = [\"r\" if x in solution_bitstrings else \"g\" for x in xs]\naxs[1].set_xlabel(\"bitstrings\")\naxs[1].set_ylabel(\"counts\")\naxs[1].bar(xs[:n_to_show], ys[:n_to_show], width=0.5, color=colors)\naxs[1].tick_params(axis=\"x\", labelrotation=90)\naxs[1].set_title(\"Optimal solution\")\nplt.tight_layout()\n</code></pre> 2023-10-10T21:36:25.151955 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"digital_analog_qc/daqc-basics/","title":"Digital-Analog Quantum Computation","text":"<p>Digital-analog quantum computation (DAQC) is a universal quantum computing paradigm<sup>1</sup>, based on two primary computations:</p> <ul> <li>Fast single-qubit operations (digital).</li> <li>Multi-partite entangling operations acting on all qubits (analog).</li> </ul> <p>The DAQC paradigm is typically implemented on quantum computing hardware based on neutral-atoms where both these computations are realizable.</p>"},{"location":"digital_analog_qc/daqc-basics/#digital-analog-emulation","title":"Digital-Analog Emulation","text":"<p>Qadence simplifies the execution of DAQC programs on either emulated or real neutral-atom devices by providing a simplified interface for customizing interactions and interfacing with pulse-level programming in <code>Pulser</code><sup>3</sup>.</p>"},{"location":"digital_analog_qc/daqc-basics/#digital-analog-transformation","title":"Digital-Analog Transformation","text":"<p>Furthermore, the essence of digital-analog computation is the ability to represent any analog operation, i.e. any arbitrary Hamiltonian, using an auxiliary device-amenable Hamiltonian, such as the ubiquitous Ising model<sup>2</sup>. This is at the core of the DAQC implementation in Qadence.</p>"},{"location":"digital_analog_qc/daqc-basics/#references","title":"References","text":"<ol> <li> <p>Dodd et al., Universal quantum computation and simulation using any entangling Hamiltonian and local unitaries, PRA 65, 040301 (2002). \u21a9</p> </li> <li> <p>Pulser: An open-source package for the design of pulse sequences in programmable neutral-atom arrays \u21a9</p> </li> <li> <p>Parra-Rodriguez et al., Digital-Analog Quantum Computation, PRA 101, 022305 (2020). \u21a9</p> </li> </ol>"},{"location":"digital_analog_qc/daqc-cnot/","title":"DAQC Transform","text":"<p>Digital-analog quantum computing focuses on using simple digital gates combined with more complex and device-dependent analog interactions to represent quantum programs. Such techniques have been shown to be universal for quantum computation <sup>1</sup>. However, while this approach may have advantages when adapting quantum programs to real devices, known quantum algorithms are very often expressed in a fully digital paradigm. As such, it is also important to have concrete ways to transform from one paradigm to another.</p> <p>In this tutorial we will exemplify this transformation starting with the representation of a simple digital CNOT using the universality of the Ising Hamiltonian <sup>2</sup>.</p>"},{"location":"digital_analog_qc/daqc-cnot/#cnot-with-cphase","title":"CNOT with CPHASE","text":"<p>Let's look at a single example of how the digital-analog transformation can be used to perform a CNOT on two qubits inside a register of globally interacting qubits.</p> <p>First, note that the CNOT can be decomposed with two Hadamard and a CPHASE gate with \\(\\phi=\\pi\\):</p> <pre><code>import torch\nimport qadence as qd\nfrom qadence.draw import display\nfrom qadence import X, I, Z, H, N, CPHASE, CNOT, HamEvo\nn_qubits = 2\n# CNOT gate\ncnot_gate = CNOT(0, 1)\n# CNOT decomposed\nphi = torch.pi\ncnot_decomp = qd.chain(H(1), CPHASE(0, 1, phi), H(1))\ninit_state = qd.product_state(\"10\")\nprint(qd.sample(n_qubits, block = cnot_gate, state = init_state, n_shots = 100))\nprint(qd.sample(n_qubits, block = cnot_decomp, state = init_state, n_shots = 100))\n</code></pre> <pre><code>[Counter({'11': 100})]\n[Counter({'11': 100})]\n</code></pre> <p>The CPHASE gate is fully diagonal, and can be implemented by exponentiating an Ising-like Hamiltonian, or generator,</p> \\[\\text{CPHASE}(i,j,\\phi)=\\text{exp}\\left(-i\\phi \\mathcal{H}_\\text{CP}(i, j)\\right)\\] \\[\\begin{aligned} \\mathcal{H}_\\text{CP}&amp;=-\\frac{1}{4}(I_i-Z_i)(I_j-Z_j)\\\\ &amp;=-N_iN_j \\end{aligned}\\] <p>where we used the number operator \\(N_i = \\frac{1}{2}(I_i-Z_i)\\), leading to an Ising-like interaction \\(N_iN_j\\) that is common in neutral-atom systems. Let's rebuild the CNOT using this evolution.</p> <pre><code># Hamiltonian for the CPHASE gate\nh_cphase = (-1.0) * qd.kron(N(0), N(1))\n# Exponentiating the Hamiltonian\ncphase_evo = HamEvo(h_cphase, phi)\n# Check that we have the CPHASE gate:\ncphase_matrix = qd.block_to_tensor(CPHASE(0, 1, phi))\ncphase_evo_matrix = qd.block_to_tensor(cphase_evo)\nassert torch.allclose(cphase_matrix, cphase_evo_matrix)\n</code></pre> <p>Now that we have checked the generator of the CPHASE gate, we can use it to apply the CNOT:</p> <pre><code># CNOT with Hamiltonian Evolution\ncnot_evo = qd.chain(\nH(1),\ncphase_evo,\nH(1)\n)\ninit_state = qd.product_state(\"10\")\nprint(qd.sample(n_qubits, block = cnot_gate, state = init_state, n_shots = 100))\nprint(qd.sample(n_qubits, block = cnot_evo, state = init_state, n_shots = 100))\n</code></pre> <pre><code>[Counter({'11': 100})]\n[Counter({'11': 100})]\n</code></pre> <p>Thus, a CNOT gate can be applied by combining a few single-qubit gates together with a 2-qubit Ising interaction between the control and the target qubit. This is important because it now allows us to exemplify the usage of the Ising transform proposed in the DAQC paper <sup>2</sup>. In the paper, the transform is described for \\(ZZ\\) interactions. In <code>qadence</code> it works both with \\(ZZ\\) and \\(NN\\) interactions.</p>"},{"location":"digital_analog_qc/daqc-cnot/#cnot-in-an-interacting-system-of-3-qubits","title":"CNOT in an interacting system of 3 qubits","text":"<p>Consider a simple experimental setup with \\(n=3\\) interacting qubits in a triangular grid. For simplicity let's consider that all qubits interact with each other with an Ising (\\(NN\\)) interaction of constant strength \\(g_\\text{int}\\). The Hamiltonian for the system can be written by summing this interaction over all pairs:</p> \\[\\mathcal{H}_\\text{sys}=\\sum_{i=0}^{n}\\sum_{j=0}^{i-1}g_\\text{int}N_iN_j,\\] <p>which in this case leads to only three interaction terms,</p> \\[\\mathcal{H}_\\text{sys}=g_\\text{int}(N_0N_1+N_1N_2+N_0N_2)\\] <p>This generator can be easily built:</p> <pre><code>n_qubits = 3\ng_int = 1.0\ninteraction_list = []\nfor i in range(n_qubits):\nfor j in range(i):\ninteraction_list.append(g_int * qd.kron(N(i), N(j)))\nh_sys = qd.add(*interaction_list)\nprint(h_sys)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(0)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(2)\n\u2502       \u2514\u2500\u2500 N(0)\n\u2514\u2500\u2500 [mul: 1.00000000000000] \u2514\u2500\u2500 KronBlock(1,2)\n\u251c\u2500\u2500 N(2)\n\u2514\u2500\u2500 N(1)\n</code></pre> <p>Now let's consider that the experimental system is fixed, and we cannot isolate the qubits from each other. All we can do is the following:</p> <ul> <li>Turn on or off the global system Hamiltonian.</li> <li>Perform single-qubit rotations on individual qubits.</li> </ul> <p>How can we perform a CNOT on two specific qubits of our choice?</p> <p>To perform a fully digital CNOT we would need to isolate the control and target qubit from the third one and have those interact to implement the gate directly. While this may be relatively simple for a 3-qubit system, the experimental burden becomes much greater when we start going into the dozens of qubits.</p> <p>However, with the digital-analog paradigm that is not the case! In fact, we can represent the two qubit Ising interaction required for the CNOT by combining the global system Hamiltonian with a specific set of single-qubit rotations. The full details of this transformation are described in the DAQC paper <sup>2</sup>, and it is available in <code>qadence</code> by calling the <code>daqc_transform</code> function.</p> <p>The <code>daqc_transform</code> function will essentially return a program that represents the evolution of an Hamiltonian \\(H_\\text{target}\\) (target Hamiltonian) for a specified time \\(t_f\\) by using only the evolution of an Hamiltonian \\(H_\\text{build}\\) (build Hamiltonian) for specific intervals of time together with specific single-qubit \\(X\\) rotations. Currently, in <code>qadence</code> it is available for resource and target Hamiltonians composed only of \\(ZZ\\) or \\(NN\\) interactions. The generators are parsed by the <code>daqc_transform</code> function, the appropriate type is automatically determined, and the appropriate single-qubit detunings and global phases are applied.</p> <p>Let's exemplify it for our CNOT problem:</p> <pre><code># The target operation\ni = 0  # Control\nj = 1  # Target\nk = 2  # The extra qubit\n# CNOT on control and target, Identity on the extra qubit\ncnot_target = qd.kron(CNOT(i, j), I(k))\n# The two-qubit Ising (NN) interaction for the CPHASE\nh_int = (-1.0) * qd.kron(N(i), N(j))\n# Transforming the two-qubit Ising interaction using only our system Hamiltonian\ntransformed_ising = qd.daqc_transform(\nn_qubits = 3,        # Total number of qubits in the transformation\ngen_target = h_int,  # The target Ising generator\nt_f = torch.pi,      # The target evolution time\ngen_build = h_sys,   # The building block Ising generator to be used\nstrategy = \"sDAQC\",   # Currently only sDAQC is implemented\nignore_global_phases = False  # Global phases from mapping between Z and N\n)\n# display(transformed_ising)\n</code></pre> %3 cluster_444a7cfb77c54a37b7d4e3aed299111e cluster_b127a1c2f97e4a17884e055febd56d4e cluster_733197a7a09442d29c1627276ce72a2b cluster_40889bc98aac4dd6be745b196022a491 cluster_1db65387a354466cbc7e3979d9328747 cluster_4ad24a8ac18a4b08838c4ba5a1e670c5 cluster_da30668bf757458d9a53f5410468d50a 3d6864a970404f3c95064188a898fc65 0 3c8bbde6e77f45e1b295d835ea169488 HamEvo 3d6864a970404f3c95064188a898fc65--3c8bbde6e77f45e1b295d835ea169488 6ed6c702a8a84d47bf249fed7221b04f 1 bae3ba5dc84045228cb14eaeded66d83 HamEvo 3c8bbde6e77f45e1b295d835ea169488--bae3ba5dc84045228cb14eaeded66d83 c4b405ae85964c2dbf3098aa2cb7d6c8 HamEvo bae3ba5dc84045228cb14eaeded66d83--c4b405ae85964c2dbf3098aa2cb7d6c8 f68b9ad63e31497a97b9f0ab536b3c13 X c4b405ae85964c2dbf3098aa2cb7d6c8--f68b9ad63e31497a97b9f0ab536b3c13 a7e486e707e447d48f024b2cd168bab6 HamEvo f68b9ad63e31497a97b9f0ab536b3c13--a7e486e707e447d48f024b2cd168bab6 199349f316f84c4aa7cd9302b1921c4f HamEvo a7e486e707e447d48f024b2cd168bab6--199349f316f84c4aa7cd9302b1921c4f 1e7a8102fa374c7fa513ed2b4fd53e7b X 199349f316f84c4aa7cd9302b1921c4f--1e7a8102fa374c7fa513ed2b4fd53e7b c7e5d369afd94eb8a7d4f535df8ceb3e 1e7a8102fa374c7fa513ed2b4fd53e7b--c7e5d369afd94eb8a7d4f535df8ceb3e c231cf7d56e54afbace91d67d061221e HamEvo c7e5d369afd94eb8a7d4f535df8ceb3e--c231cf7d56e54afbace91d67d061221e c26296c17eb2470e8bcd120f7ce84cc2 HamEvo c231cf7d56e54afbace91d67d061221e--c26296c17eb2470e8bcd120f7ce84cc2 c94b389b22b34824a7c6cdf4b582ef1f c26296c17eb2470e8bcd120f7ce84cc2--c94b389b22b34824a7c6cdf4b582ef1f 06dc3148f27b4d08af5e4278d5667a0a c94b389b22b34824a7c6cdf4b582ef1f--06dc3148f27b4d08af5e4278d5667a0a f96e14fe58f9440fb82ea6ab0363b2f8 d12f7b0ffd204219a1e58033ce54a266 t = -3.142 6ed6c702a8a84d47bf249fed7221b04f--d12f7b0ffd204219a1e58033ce54a266 f354e48a64a943ba8cff7b24d7798fc5 2 7ba1b50b2dd04b25bebd666e5abe30c9 t = 3.142 d12f7b0ffd204219a1e58033ce54a266--7ba1b50b2dd04b25bebd666e5abe30c9 3832c5eeeb8b440db5bb7f9cbed852f3 t = -3.142 7ba1b50b2dd04b25bebd666e5abe30c9--3832c5eeeb8b440db5bb7f9cbed852f3 6dc8ae2a63a04018b222b24a9e7c97b0 3832c5eeeb8b440db5bb7f9cbed852f3--6dc8ae2a63a04018b222b24a9e7c97b0 d9b0984b5b3545c79233c132a6298733 t = 1.571 6dc8ae2a63a04018b222b24a9e7c97b0--d9b0984b5b3545c79233c132a6298733 b835e6cfd6f244a5b463b455bc3f066d t = 1.571 d9b0984b5b3545c79233c132a6298733--b835e6cfd6f244a5b463b455bc3f066d ff8c271ff66e454dbd1c2414132c6206 b835e6cfd6f244a5b463b455bc3f066d--ff8c271ff66e454dbd1c2414132c6206 2914883dc510406ab2dbee7dca47729b X ff8c271ff66e454dbd1c2414132c6206--2914883dc510406ab2dbee7dca47729b 6011592d3eaa418585fea742b2e29d9a t = 1.571 2914883dc510406ab2dbee7dca47729b--6011592d3eaa418585fea742b2e29d9a 4f61da74b4ef4d269830107daa17f66c t = 1.571 6011592d3eaa418585fea742b2e29d9a--4f61da74b4ef4d269830107daa17f66c f0a81a04a8484a18a743bbe250f9096b X 4f61da74b4ef4d269830107daa17f66c--f0a81a04a8484a18a743bbe250f9096b f0a81a04a8484a18a743bbe250f9096b--f96e14fe58f9440fb82ea6ab0363b2f8 0a0946591dad45ed86bef58c21f27c25 2658696b48144e00b823c636c7a1cd56 f354e48a64a943ba8cff7b24d7798fc5--2658696b48144e00b823c636c7a1cd56 1d67b7b6c93c4a1fac4e43292dbbe06c 2658696b48144e00b823c636c7a1cd56--1d67b7b6c93c4a1fac4e43292dbbe06c d84fd8ff322d4acd9ce582cc6e2a192c 1d67b7b6c93c4a1fac4e43292dbbe06c--d84fd8ff322d4acd9ce582cc6e2a192c 2429ab127175464a858cf15fe6790b13 X d84fd8ff322d4acd9ce582cc6e2a192c--2429ab127175464a858cf15fe6790b13 f50e58f53b4344d09efd09d0ee7d091f 2429ab127175464a858cf15fe6790b13--f50e58f53b4344d09efd09d0ee7d091f 8cb7868469fa4a8a9039cf48563b284b f50e58f53b4344d09efd09d0ee7d091f--8cb7868469fa4a8a9039cf48563b284b 548fbb69a0554333abc9cdb2d8d2a8c0 X 8cb7868469fa4a8a9039cf48563b284b--548fbb69a0554333abc9cdb2d8d2a8c0 82fa5c5a5f4145edb0ce36396585d156 X 548fbb69a0554333abc9cdb2d8d2a8c0--82fa5c5a5f4145edb0ce36396585d156 e868d3a7425d4243afb6f3182490dfcc 82fa5c5a5f4145edb0ce36396585d156--e868d3a7425d4243afb6f3182490dfcc 1cd0f4d4fc944c9b9bcd0a032ad2167f e868d3a7425d4243afb6f3182490dfcc--1cd0f4d4fc944c9b9bcd0a032ad2167f b67d3686139f4ae9a2fe1b008944df73 X 1cd0f4d4fc944c9b9bcd0a032ad2167f--b67d3686139f4ae9a2fe1b008944df73 b67d3686139f4ae9a2fe1b008944df73--0a0946591dad45ed86bef58c21f27c25 <p>The circuit above actually only uses two evolutions of the global Hamiltonian. In the displayed circuit also see other instances of <code>HamEvo</code> which account for global-phases and single-qubit detunings related to the mapping between the \\(Z\\) and \\(N\\) operator. Optionally, the application of the global phases can also be ignored, as shown in the input of <code>daqc_transform</code>. This will not create exactly the same state or operator matrix in tensor form, but in practice they will be equivalent.</p> <p>In general, the mapping of a \\(n\\)-qubit Ising Hamiltonian will require at most \\(n(n-1)\\) evolutions. The transformed circuit performs these evolutions for specific times that are computed from the solution of a linear system of equations involving the set of interactions in the target and build Hamiltonians.</p> <p>In this case the mapping is exact, since we used the step-wise DAQC technique (sDAQC). In banged DAQC (bDAQC) the mapping is not exact, but is easier to implement on a physical device with always-on interactions such as neutral-atom systems. Currently, only the sDAQC technique is available in <code>qadence</code>.</p> <p>Just as before, we can check that using the transformed Ising circuit we exactly recover the CPHASE gate:</p> <pre><code># CPHASE on (i, j), Identity on third qubit:\ncphase_matrix = qd.block_to_tensor(qd.kron(CPHASE(i, j, phi), I(k)))\n# CPHASE using the transformed circuit:\ncphase_evo_matrix = qd.block_to_tensor(transformed_ising)\n# Will fail if global phases are ignored:\nassert torch.allclose(cphase_matrix, cphase_evo_matrix)\n</code></pre> <p>And we can now build the CNOT gate:</p> <pre><code>cnot_daqc = qd.chain(\nH(j),\ntransformed_ising,\nH(j)\n)\n# And finally run the CNOT on a specific 3-qubit initial state:\ninit_state = qd.product_state(\"101\")\n# Check we get an equivalent wavefunction (will still pass if global phases are ignored)\nwf_cnot = qd.run(n_qubits, block = cnot_target, state = init_state)\nwf_daqc = qd.run(n_qubits, block = cnot_daqc, state = init_state)\nassert qd.equivalent_state(wf_cnot, wf_daqc)\n# Visualize the CNOT bit-flip:\nprint(qd.sample(n_qubits, block = cnot_target, state = init_state, n_shots = 100))\nprint(qd.sample(n_qubits, block = cnot_daqc, state = init_state, n_shots = 100))\n</code></pre> <pre><code>[Counter({'111': 100})]\n[Counter({'111': 100})]\n</code></pre> <p>And we are done! We have effectively performed a CNOT operation on our desired target qubits by using only the global interaction of the system as the building block Hamiltonian, together with single-qubit rotations. Going through the trouble of decomposing a single digital gate into its Ising Hamiltonian is certainly not very practical, but it serves as a proof of principle for the potential of this technique to represent universal quantum computation. In the next example, we will see it applied to the digital-analog Quantum Fourier Transform.</p>"},{"location":"digital_analog_qc/daqc-cnot/#technical-details-on-the-daqc-transformation","title":"Technical details on the DAQC transformation","text":"<ul> <li>The mapping between target generator and final circuit is performed by solving a linear system of size \\(n(n-1)\\) where \\(n\\) is the number of qubits, so it can be computed efficiently (i.e., with a polynomial cost in the number of qubits).</li> <li>The linear system to be solved is actually not invertible for \\(n=4\\) qubits. This is very specific edge case requiring a workaround, that is currently not yet implemented.</li> <li>As mentioned, the final circuit has at most \\(n(n-1)\\) slices, so there is at most a polynomial overhead in circuit depth.</li> </ul> <p>Finally, and most important to its usage:</p> <ul> <li>The target Hamiltonian should be sufficiently represented in the building block Hamiltonian.</li> </ul> <p>To illustrate this point, consider the following target and build Hamiltonians:</p> <pre><code># Interaction between qubits 0 and 1\ngen_target = 1.0 * (Z(0) @ Z(1))\n# Fixed interaction between qubits 1 and 2, and customizable between 0 and 1\ndef gen_build(g_int):\nreturn g_int * (Z(0) @ Z(1)) + 1.0 * (Z(1) @ Z(2))\n</code></pre> <p>And now we perform the DAQC transform by setting <code>g_int = 1.0</code>, matching the target Hamiltonian:</p> <pre><code>transformed_ising = qd.daqc_transform(\nn_qubits = 3,\ngen_target = gen_target,\nt_f = 1.0,\ngen_build = gen_build(g_int = 1.0),\n)\n# display(transformed_ising)\n</code></pre> %3 cluster_8a03c5acc161412ea9333562ff293dc1 cluster_36fd1b9f590343c4ab43eeab8d46a4fb f441becb067a4b3ba7c55db8780949e7 0 98cc3f7634ae45969a449781eeba8d4d X f441becb067a4b3ba7c55db8780949e7--98cc3f7634ae45969a449781eeba8d4d 986f7a985b354a1e99add2c355070b28 1 4e5a29f6f4e4433bbd009234ee229d04 HamEvo 98cc3f7634ae45969a449781eeba8d4d--4e5a29f6f4e4433bbd009234ee229d04 3f34964211d54ae1b46ce23c1dcab44b X 4e5a29f6f4e4433bbd009234ee229d04--3f34964211d54ae1b46ce23c1dcab44b e128d39e95b44084bab7210f7d204a67 3f34964211d54ae1b46ce23c1dcab44b--e128d39e95b44084bab7210f7d204a67 632dd032d64f4b7ba25ff3bb2ba810b2 HamEvo e128d39e95b44084bab7210f7d204a67--632dd032d64f4b7ba25ff3bb2ba810b2 1afc05a6684648c5b1d5275e6c4bc253 632dd032d64f4b7ba25ff3bb2ba810b2--1afc05a6684648c5b1d5275e6c4bc253 dbaf937ae2324b088c77a3a6e3dc124a 1afc05a6684648c5b1d5275e6c4bc253--dbaf937ae2324b088c77a3a6e3dc124a dac1652dab7542df83c7e5e37774d339 793e8435dbdc4d69bdfb3bdd289fcc46 986f7a985b354a1e99add2c355070b28--793e8435dbdc4d69bdfb3bdd289fcc46 218c841b551e4405a8126cd5e87d4167 2 402dc16ebb2b4791928b58ec76e3d8e3 t = -0.500 793e8435dbdc4d69bdfb3bdd289fcc46--402dc16ebb2b4791928b58ec76e3d8e3 022c209a2e94423c9801b50aee1560e3 402dc16ebb2b4791928b58ec76e3d8e3--022c209a2e94423c9801b50aee1560e3 4eb863ecb0f3443eba130a5c301719de X 022c209a2e94423c9801b50aee1560e3--4eb863ecb0f3443eba130a5c301719de ca74565f81c34078aa956e5cd5892e06 t = -0.500 4eb863ecb0f3443eba130a5c301719de--ca74565f81c34078aa956e5cd5892e06 5856b89ba5964e5aa70d2070e4465965 X ca74565f81c34078aa956e5cd5892e06--5856b89ba5964e5aa70d2070e4465965 5856b89ba5964e5aa70d2070e4465965--dac1652dab7542df83c7e5e37774d339 bb2fc803d14847d4a4fc1db455550e15 67412d4596704002b43227a4eba7530e X 218c841b551e4405a8126cd5e87d4167--67412d4596704002b43227a4eba7530e 401b979418ff45559fe5d91eb587febe 67412d4596704002b43227a4eba7530e--401b979418ff45559fe5d91eb587febe dfd5771601f4422fb808c5945342885b X 401b979418ff45559fe5d91eb587febe--dfd5771601f4422fb808c5945342885b d78f3b5717954904b4bb728dc064f6b5 X dfd5771601f4422fb808c5945342885b--d78f3b5717954904b4bb728dc064f6b5 adae1c5d1cde416aab3d8a87b7808659 d78f3b5717954904b4bb728dc064f6b5--adae1c5d1cde416aab3d8a87b7808659 096663d28d334fdbb00807d52e9f5999 X adae1c5d1cde416aab3d8a87b7808659--096663d28d334fdbb00807d52e9f5999 096663d28d334fdbb00807d52e9f5999--bb2fc803d14847d4a4fc1db455550e15 <p>And we get the transformed circuit. What if our build Hamiltonian has a very weak interaction between qubits 0 and 1?</p> <pre><code>transformed_ising = qd.daqc_transform(\nn_qubits = 3,\ngen_target = gen_target,\nt_f = 1.0,\ngen_build = gen_build(g_int = 0.001),\n)\n# display(transformed_ising)\n</code></pre> %3 cluster_9dffe4902741438c99af414315c80e29 cluster_40709e7d56174ef39bcc30dd499c3b47 f3973a170f084055b05fac20718ed42f 0 8b685d235c1d4f15b3ae38c466429fc3 X f3973a170f084055b05fac20718ed42f--8b685d235c1d4f15b3ae38c466429fc3 949b6c15c9294f918fefb4540089302e 1 8cb6407b416d4d45b8fdb33d81a5d734 HamEvo 8b685d235c1d4f15b3ae38c466429fc3--8cb6407b416d4d45b8fdb33d81a5d734 8710a1fcdb7d423485d85a7d0e4a1a1d X 8cb6407b416d4d45b8fdb33d81a5d734--8710a1fcdb7d423485d85a7d0e4a1a1d d502c4d6af3f4b55834f5bfdb7e93690 8710a1fcdb7d423485d85a7d0e4a1a1d--d502c4d6af3f4b55834f5bfdb7e93690 ab7e1ca9c24049019fa0273a3df1e879 HamEvo d502c4d6af3f4b55834f5bfdb7e93690--ab7e1ca9c24049019fa0273a3df1e879 1b4a578022e44dd1a949c258548517d4 ab7e1ca9c24049019fa0273a3df1e879--1b4a578022e44dd1a949c258548517d4 47eb1f0565124f8b9dd9c6f3033f7e28 1b4a578022e44dd1a949c258548517d4--47eb1f0565124f8b9dd9c6f3033f7e28 36b6bf50da5540009c3c9cd24774bb8f c8fcd9b41e6541a49036ccec99c53c25 949b6c15c9294f918fefb4540089302e--c8fcd9b41e6541a49036ccec99c53c25 0a16ba225a64497cb784ea80b5a8cb2e 2 ea3f26a92c1a4c13875bb02f75994c2d t = -500.000000000000 c8fcd9b41e6541a49036ccec99c53c25--ea3f26a92c1a4c13875bb02f75994c2d 12c2f1e4be3c4c8e9e11b8d05043bcbc ea3f26a92c1a4c13875bb02f75994c2d--12c2f1e4be3c4c8e9e11b8d05043bcbc e4cba8f6a01d4acf910a3077efa3b8d4 X 12c2f1e4be3c4c8e9e11b8d05043bcbc--e4cba8f6a01d4acf910a3077efa3b8d4 0ea33fdb18bb4c48b4217224ca2faa4e t = -500.000000000000 e4cba8f6a01d4acf910a3077efa3b8d4--0ea33fdb18bb4c48b4217224ca2faa4e bbe9b2ca2ea44af68f3cb7dcc14a48d6 X 0ea33fdb18bb4c48b4217224ca2faa4e--bbe9b2ca2ea44af68f3cb7dcc14a48d6 bbe9b2ca2ea44af68f3cb7dcc14a48d6--36b6bf50da5540009c3c9cd24774bb8f a3fd7f47944d495391e9eff3f23bd56d 030bcbcdad1f4c21b9ace3b120877ea9 X 0a16ba225a64497cb784ea80b5a8cb2e--030bcbcdad1f4c21b9ace3b120877ea9 35fa1b29720d400888ff3855cc0630bc 030bcbcdad1f4c21b9ace3b120877ea9--35fa1b29720d400888ff3855cc0630bc 3d6d26f19a174b46bcd26c8fe7bfe34e X 35fa1b29720d400888ff3855cc0630bc--3d6d26f19a174b46bcd26c8fe7bfe34e 3130ff5082c24c59ba088c1f1f82e719 X 3d6d26f19a174b46bcd26c8fe7bfe34e--3130ff5082c24c59ba088c1f1f82e719 753fcda0af644e5482a6e63f886343b4 3130ff5082c24c59ba088c1f1f82e719--753fcda0af644e5482a6e63f886343b4 b747541e7db24b2d80008abef87590ca X 753fcda0af644e5482a6e63f886343b4--b747541e7db24b2d80008abef87590ca b747541e7db24b2d80008abef87590ca--a3fd7f47944d495391e9eff3f23bd56d <p>As we can see, to represent the same interaction between 0 and 1, the slices using the build Hamiltonian need to evolve for much longer, since the target interaction is not sufficiently represented in the building block Hamiltonian.</p> <p>In the limit where that interaction is not present at all, the transform will not work:</p> <pre><code>try:\ntransformed_ising = qd.daqc_transform(\nn_qubits = 3,\ngen_target = gen_target,\nt_f = 1.0,\ngen_build = gen_build(g_int = 0.0),\n)\nexcept ValueError as error:\nprint(\"Error:\", error)\n</code></pre> <pre><code>Error: Incompatible interactions between target and build Hamiltonians.\n</code></pre>"},{"location":"digital_analog_qc/daqc-cnot/#references","title":"References","text":"<ol> <li> <p>Dodd et al., Universal quantum computation and simulation using any entangling Hamiltonian and local unitaries, PRA 65, 040301 (2002). \u21a9</p> </li> <li> <p>Parra-Rodriguez et al., Digital-Analog Quantum Computation, PRA 101, 022305 (2020). \u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"digital_analog_qc/daqc-qft/","title":"Digital-Analog QFT (Advanced)","text":"<p>Following the work in the DAQC paper <sup>1</sup>, the authors also proposed an algorithm using this technique to perform the well-known Quantum Fourier Transform <sup>2</sup>. In this tutorial we will go over how the Ising transform used in the DAQC technique can be used to recreate the results for the DA-QFT.</p>"},{"location":"digital_analog_qc/daqc-qft/#the-standard-digital-qft","title":"The (standard) digital QFT","text":"<p>The standard Quantum Fourier Transform can be easily built in <code>qadence</code> by calling the <code>qft</code> function. It accepts three arguments:</p> <ul> <li><code>reverse_in</code> (default <code>False</code>): reverses the order of the input qubits</li> <li><code>swaps_out</code> (default <code>False</code>): swaps the qubit states at the output</li> <li><code>inverse</code> (default <code>False</code>): performs the inverse QFT</li> </ul> <pre><code>import torch\nimport qadence as qd\nfrom qadence.draw import display\nfrom qadence import X, I, Z, H, CPHASE, CNOT, HamEvo\nn_qubits = 4\nqft_circuit = qd.qft(n_qubits)\n# display(qft_circuit)\n</code></pre> %3 28b19f02a4654d9bb3ff363492669fda 0 89aa4d7e06914f9ba37d03c6a2d8126b H 28b19f02a4654d9bb3ff363492669fda--89aa4d7e06914f9ba37d03c6a2d8126b a5180e58bcca4655b866849b13d48512 1 27d2e41dda034e54bbd75aa0dd0ffa24 PHASE(1.571) 89aa4d7e06914f9ba37d03c6a2d8126b--27d2e41dda034e54bbd75aa0dd0ffa24 4835f59f97264f1485143b78de7df657 PHASE(0.785) 27d2e41dda034e54bbd75aa0dd0ffa24--4835f59f97264f1485143b78de7df657 906f735409c046bba79547a8d9bcd931 27d2e41dda034e54bbd75aa0dd0ffa24--906f735409c046bba79547a8d9bcd931 a04618674c664d1594b1e846b7435857 PHASE(0.393) 4835f59f97264f1485143b78de7df657--a04618674c664d1594b1e846b7435857 b3c07f7643c34690b99dc07978e661e4 4835f59f97264f1485143b78de7df657--b3c07f7643c34690b99dc07978e661e4 0620d1c0382d445b9ed6d4d013b504c0 a04618674c664d1594b1e846b7435857--0620d1c0382d445b9ed6d4d013b504c0 e5b03ba7f0a2427fb1f034d0ac19fe1a a04618674c664d1594b1e846b7435857--e5b03ba7f0a2427fb1f034d0ac19fe1a da8a4626e4ea447180b92b4d74c249c9 0620d1c0382d445b9ed6d4d013b504c0--da8a4626e4ea447180b92b4d74c249c9 4ed79e2d92ea4630b78adb86d3e05bd9 da8a4626e4ea447180b92b4d74c249c9--4ed79e2d92ea4630b78adb86d3e05bd9 87f7f817e85b43bb80d2bde374795241 4ed79e2d92ea4630b78adb86d3e05bd9--87f7f817e85b43bb80d2bde374795241 37da9e2df6834b55bdc493a092417c17 87f7f817e85b43bb80d2bde374795241--37da9e2df6834b55bdc493a092417c17 acbe310caeeb42c4a53dde972d67d6cd 37da9e2df6834b55bdc493a092417c17--acbe310caeeb42c4a53dde972d67d6cd a59f3129123844beb82efeb88f220ad2 acbe310caeeb42c4a53dde972d67d6cd--a59f3129123844beb82efeb88f220ad2 74013d0cc2a348d1bec0bdb7fb7baf43 4437112e506a4fd08f94251bdf9fa8bf a5180e58bcca4655b866849b13d48512--4437112e506a4fd08f94251bdf9fa8bf c21d9a9471b44806850f3476078307cf 2 4437112e506a4fd08f94251bdf9fa8bf--906f735409c046bba79547a8d9bcd931 fcc326f367da4d9190be0d1b78b317da 906f735409c046bba79547a8d9bcd931--fcc326f367da4d9190be0d1b78b317da c3602effe6cc4c43ad6a0612ebe2b02f H fcc326f367da4d9190be0d1b78b317da--c3602effe6cc4c43ad6a0612ebe2b02f e99f6139ae9d40988682e6ac8a67db89 PHASE(1.571) c3602effe6cc4c43ad6a0612ebe2b02f--e99f6139ae9d40988682e6ac8a67db89 5a9f9d9eab67428b88e5a31dd5e9f09c PHASE(0.785) e99f6139ae9d40988682e6ac8a67db89--5a9f9d9eab67428b88e5a31dd5e9f09c ecbacff8adf14990a33bdbc64752e304 e99f6139ae9d40988682e6ac8a67db89--ecbacff8adf14990a33bdbc64752e304 876b7671402644679541ee305c6561b2 5a9f9d9eab67428b88e5a31dd5e9f09c--876b7671402644679541ee305c6561b2 7144443efef24c759e0cee86239c2d67 5a9f9d9eab67428b88e5a31dd5e9f09c--7144443efef24c759e0cee86239c2d67 bcdf9ed0f7f04184855252992dc6fb68 876b7671402644679541ee305c6561b2--bcdf9ed0f7f04184855252992dc6fb68 2d700c97becb497795c8817185b380de bcdf9ed0f7f04184855252992dc6fb68--2d700c97becb497795c8817185b380de 2d700c97becb497795c8817185b380de--74013d0cc2a348d1bec0bdb7fb7baf43 0059615d14554f47ab057afa472b3645 ff190cdb12bb4149b7470ce9eb67a739 c21d9a9471b44806850f3476078307cf--ff190cdb12bb4149b7470ce9eb67a739 45c4b914fc8f4cbea4af85ee2618959d 3 1c243a30245c4025ae80e8be6242f633 ff190cdb12bb4149b7470ce9eb67a739--1c243a30245c4025ae80e8be6242f633 1c243a30245c4025ae80e8be6242f633--b3c07f7643c34690b99dc07978e661e4 0b21a10cfbe0457182f7225cdd6d9cda b3c07f7643c34690b99dc07978e661e4--0b21a10cfbe0457182f7225cdd6d9cda 0b21a10cfbe0457182f7225cdd6d9cda--ecbacff8adf14990a33bdbc64752e304 949841f9a0f94f7d93462e6943b91ee1 ecbacff8adf14990a33bdbc64752e304--949841f9a0f94f7d93462e6943b91ee1 014e1e78a3be4ff68cd1b3ffbbb0c7aa H 949841f9a0f94f7d93462e6943b91ee1--014e1e78a3be4ff68cd1b3ffbbb0c7aa df93fb2e08354d8dad53fbc014312328 PHASE(1.571) 014e1e78a3be4ff68cd1b3ffbbb0c7aa--df93fb2e08354d8dad53fbc014312328 32e358d27ee8453d9a8b6156e9fe3fbf df93fb2e08354d8dad53fbc014312328--32e358d27ee8453d9a8b6156e9fe3fbf ece1441bedbc42dd8386723ac39b7b70 df93fb2e08354d8dad53fbc014312328--ece1441bedbc42dd8386723ac39b7b70 32e358d27ee8453d9a8b6156e9fe3fbf--0059615d14554f47ab057afa472b3645 cbf5302a5d9842d2a122edb1c0a9fadb 442d840f10b248c6a3b3aca566ffd0b0 45c4b914fc8f4cbea4af85ee2618959d--442d840f10b248c6a3b3aca566ffd0b0 9b719e040ab64ed9afcc451d4b77c0e1 442d840f10b248c6a3b3aca566ffd0b0--9b719e040ab64ed9afcc451d4b77c0e1 a56f29f9e4a04f4ba75d8a87d8e4d4ce 9b719e040ab64ed9afcc451d4b77c0e1--a56f29f9e4a04f4ba75d8a87d8e4d4ce a56f29f9e4a04f4ba75d8a87d8e4d4ce--e5b03ba7f0a2427fb1f034d0ac19fe1a c29d2ec2c5764e708e6b9cbe07589a32 e5b03ba7f0a2427fb1f034d0ac19fe1a--c29d2ec2c5764e708e6b9cbe07589a32 1b652dbe638f4cec90c3613bbb8e69bd c29d2ec2c5764e708e6b9cbe07589a32--1b652dbe638f4cec90c3613bbb8e69bd 1b652dbe638f4cec90c3613bbb8e69bd--7144443efef24c759e0cee86239c2d67 2a4d55c008004a35a24f40cdffed32d2 7144443efef24c759e0cee86239c2d67--2a4d55c008004a35a24f40cdffed32d2 2a4d55c008004a35a24f40cdffed32d2--ece1441bedbc42dd8386723ac39b7b70 eb9ac4922c8d4064a16b12590f1a057c H ece1441bedbc42dd8386723ac39b7b70--eb9ac4922c8d4064a16b12590f1a057c eb9ac4922c8d4064a16b12590f1a057c--cbf5302a5d9842d2a122edb1c0a9fadb <p>Most importantly, the circuit has a layered structure. The QFT for \\(n\\) qubits has a total of \\(n\\) layers, and each layer starts with a Hadamard gate on the first qubit and then builds a ladder of <code>CPHASE</code> gates. Let's see how we can easily build a function to replicate this circuit.</p> <pre><code>def qft_layer(n_qubits, layer_ix):\nqubit_range = range(layer_ix + 1, n_qubits)\n# CPHASE ladder\ncphases = []\nfor j in qubit_range:\nangle = torch.pi / (2 ** (j - layer_ix))\ncphases.append(CPHASE(j, layer_ix, angle))\n# Return Hadamard followed by CPHASEs\nreturn qd.chain(H(layer_ix), *cphases)\n</code></pre> <p>With the layer function we can easily write the full QFT:</p> <pre><code>def qft_digital(n_qubits):\nreturn qd.chain(qft_layer(n_qubits, i) for i in range(n_qubits))\nqft_circuit = qft_digital(4)\n# display(qft_circuit)\n</code></pre> %3 3aa9f6870e9a404d97c39e749ec12460 0 4fda19fa5df34be8bb38cf0de67f559f H 3aa9f6870e9a404d97c39e749ec12460--4fda19fa5df34be8bb38cf0de67f559f dcec6721958d4fbe8f8dfb9162e5703d 1 f01895c7c01849a0ad2adf5056ed67c2 PHASE(1.571) 4fda19fa5df34be8bb38cf0de67f559f--f01895c7c01849a0ad2adf5056ed67c2 8c568627e1944ed2897ee80182c10d9f PHASE(0.785) f01895c7c01849a0ad2adf5056ed67c2--8c568627e1944ed2897ee80182c10d9f 34e309db7b0c42bf801398c2620d70fb f01895c7c01849a0ad2adf5056ed67c2--34e309db7b0c42bf801398c2620d70fb c6214d37ab184842964d064b3f4ed845 PHASE(0.393) 8c568627e1944ed2897ee80182c10d9f--c6214d37ab184842964d064b3f4ed845 1c5562f707e04496bf59c5c16175befb 8c568627e1944ed2897ee80182c10d9f--1c5562f707e04496bf59c5c16175befb d865b8e28d4647cdbd53e2627ce3bd71 c6214d37ab184842964d064b3f4ed845--d865b8e28d4647cdbd53e2627ce3bd71 066e3758aa0c41498d70904ec1b6ca29 c6214d37ab184842964d064b3f4ed845--066e3758aa0c41498d70904ec1b6ca29 271cd51d092b42d3af71dc6a8dc33397 d865b8e28d4647cdbd53e2627ce3bd71--271cd51d092b42d3af71dc6a8dc33397 f682770993ea4f6b897943104ec0ed90 271cd51d092b42d3af71dc6a8dc33397--f682770993ea4f6b897943104ec0ed90 98677571c9b24e78887c6c739621526d f682770993ea4f6b897943104ec0ed90--98677571c9b24e78887c6c739621526d 9b70e073ef1c4ac7bab160db5812472f 98677571c9b24e78887c6c739621526d--9b70e073ef1c4ac7bab160db5812472f f15a09cbf34d4e1095922a81fd5eadad 9b70e073ef1c4ac7bab160db5812472f--f15a09cbf34d4e1095922a81fd5eadad a6cd07b86ace49cc8fef2f896f6a4cd8 f15a09cbf34d4e1095922a81fd5eadad--a6cd07b86ace49cc8fef2f896f6a4cd8 5f146c0fb5f44cd3b854ba557b1daf03 a2cd86a47ebb4a99925014d5a87722ce dcec6721958d4fbe8f8dfb9162e5703d--a2cd86a47ebb4a99925014d5a87722ce 3e2b5b162d6f4bdea447853119ca7143 2 a2cd86a47ebb4a99925014d5a87722ce--34e309db7b0c42bf801398c2620d70fb 18216241f4694a37bba2d2c9164ebf0f 34e309db7b0c42bf801398c2620d70fb--18216241f4694a37bba2d2c9164ebf0f 19ce63f1575c4a87bc7b221df4631f58 H 18216241f4694a37bba2d2c9164ebf0f--19ce63f1575c4a87bc7b221df4631f58 05ed1cb6352d4019a7d37c31e4c3a626 PHASE(1.571) 19ce63f1575c4a87bc7b221df4631f58--05ed1cb6352d4019a7d37c31e4c3a626 187209c1fb9043cbab818e4232b8e9e4 PHASE(0.785) 05ed1cb6352d4019a7d37c31e4c3a626--187209c1fb9043cbab818e4232b8e9e4 a0ad516124f04526b938e2aa5d4666e1 05ed1cb6352d4019a7d37c31e4c3a626--a0ad516124f04526b938e2aa5d4666e1 5d809e27b66f4735be12c9eb44609226 187209c1fb9043cbab818e4232b8e9e4--5d809e27b66f4735be12c9eb44609226 b4c6cd9bcf4d462ba1d380bfb6eb6016 187209c1fb9043cbab818e4232b8e9e4--b4c6cd9bcf4d462ba1d380bfb6eb6016 b6d3701c76714705b56d4cb9bfa4c071 5d809e27b66f4735be12c9eb44609226--b6d3701c76714705b56d4cb9bfa4c071 cdcfb034e52f489387b553493743f6a9 b6d3701c76714705b56d4cb9bfa4c071--cdcfb034e52f489387b553493743f6a9 cdcfb034e52f489387b553493743f6a9--5f146c0fb5f44cd3b854ba557b1daf03 c1cce731e13e4891b79b1bea27c7b1b2 97d6351b38874914b7983ba7fea7f046 3e2b5b162d6f4bdea447853119ca7143--97d6351b38874914b7983ba7fea7f046 f75922e784fe4e2e862ab2c25f892334 3 47d8363317b2491895b5e0fd90e7142a 97d6351b38874914b7983ba7fea7f046--47d8363317b2491895b5e0fd90e7142a 47d8363317b2491895b5e0fd90e7142a--1c5562f707e04496bf59c5c16175befb c3eaf04c7a63469dbd72ed8fa8b96fc3 1c5562f707e04496bf59c5c16175befb--c3eaf04c7a63469dbd72ed8fa8b96fc3 c3eaf04c7a63469dbd72ed8fa8b96fc3--a0ad516124f04526b938e2aa5d4666e1 7388c1fdc4604c9b8ee77e9edd99aa39 a0ad516124f04526b938e2aa5d4666e1--7388c1fdc4604c9b8ee77e9edd99aa39 e31d456fa99f4168aee1ceb8d1a274ef H 7388c1fdc4604c9b8ee77e9edd99aa39--e31d456fa99f4168aee1ceb8d1a274ef 9cbedc67ed604dbc9a5d6c238c879f99 PHASE(1.571) e31d456fa99f4168aee1ceb8d1a274ef--9cbedc67ed604dbc9a5d6c238c879f99 6b71bfbe1ae34c4c9d6b689f81771886 9cbedc67ed604dbc9a5d6c238c879f99--6b71bfbe1ae34c4c9d6b689f81771886 c476d2068c00401bac9bdf94ead13c9d 9cbedc67ed604dbc9a5d6c238c879f99--c476d2068c00401bac9bdf94ead13c9d 6b71bfbe1ae34c4c9d6b689f81771886--c1cce731e13e4891b79b1bea27c7b1b2 dd78d161b616403dba349742a98929f0 301c3dbb3472474fa167f51602a4420b f75922e784fe4e2e862ab2c25f892334--301c3dbb3472474fa167f51602a4420b 52276c270a01404bbf075e964069bfd8 301c3dbb3472474fa167f51602a4420b--52276c270a01404bbf075e964069bfd8 676fd44dff3949449def4151212db95e 52276c270a01404bbf075e964069bfd8--676fd44dff3949449def4151212db95e 676fd44dff3949449def4151212db95e--066e3758aa0c41498d70904ec1b6ca29 2b449bbf200d4f6bb0c731760e522989 066e3758aa0c41498d70904ec1b6ca29--2b449bbf200d4f6bb0c731760e522989 7779bc0a457941a8b631e501d3c8d3f2 2b449bbf200d4f6bb0c731760e522989--7779bc0a457941a8b631e501d3c8d3f2 7779bc0a457941a8b631e501d3c8d3f2--b4c6cd9bcf4d462ba1d380bfb6eb6016 10001324bdb640a989e81fde7041e754 b4c6cd9bcf4d462ba1d380bfb6eb6016--10001324bdb640a989e81fde7041e754 10001324bdb640a989e81fde7041e754--c476d2068c00401bac9bdf94ead13c9d d20bbf7bc49142cdac873a5358db4419 H c476d2068c00401bac9bdf94ead13c9d--d20bbf7bc49142cdac873a5358db4419 d20bbf7bc49142cdac873a5358db4419--dd78d161b616403dba349742a98929f0"},{"location":"digital_analog_qc/daqc-qft/#decomposing-the-cphase-ladder","title":"Decomposing the CPHASE ladder","text":"<p>As we already saw in the previous DAQC tutorial, the CPHASE gate has a well-known decomposition into an Ising Hamiltonian. For the CNOT example, we used the decomposition into \\(NN\\) interactions. However, here we will use the decomposition into \\(ZZ\\) interactions to be consistent with the description in the original DA-QFT paper <sup>2</sup>. The decomposition is the following:</p> \\[\\text{CPHASE}(i,j,\\phi)=\\text{exp}\\left(-i\\phi H_\\text{CP}(i, j)\\right)\\] \\[\\begin{aligned} H_\\text{CP}&amp;=-\\frac{1}{4}(I_i-Z_i)(I_j-Z_j)\\\\ &amp;=-\\frac{1}{4}(I_iI_j-Z_i-Z_j)-\\frac{1}{4}Z_iZ_j \\end{aligned}\\] <p>where the terms in \\((I_iI_j-Z_i-Z_j)\\) represents single-qubit rotations, while the interaction is given by the Ising term \\(Z_iZ_j\\).</p> <p>Just as we did for the CNOT, to build the DA-QFT we need to write the CPHASE ladder as an Ising Hamiltonian. To do so, we again write the Hamiltonian consisting of the single-qubit rotations from all CPHASEs in the layer, as well as the Hamiltonian for the two-qubit Ising interactions so that we can then use the DAQC transformation. The full mathematical details for this are written in the paper <sup>2</sup>, and below we write the necessary code for it, using the same notation as in the paper, including indices running from 1 to N.</p> <pre><code># The angle of the CPHASE used in the single-qubit rotations:\ndef theta(k):\n\"\"\"Eq. (16) from [^2].\"\"\"\nreturn torch.pi / (2 ** (k + 1))\n# The angle of the CPHASE used in the two-qubit interactions:\ndef alpha(c, k, m):\n\"\"\"Eq. (16) from [^2].\"\"\"\nreturn torch.pi / (2 ** (k - m + 2)) if c == m else 0.0\n</code></pre> <p>The first two functions represent the angles of the various <code>CPHASE</code> gates that will be used to build the qubit Hamiltonians representing each QFT layer. In the <code>alpha</code> function we include an implicit kronecker delta between the indices <code>m</code> and <code>c</code>, following the conventions and equations written in the paper <sup>2</sup>. This is simply because when building the Hamiltonian the paper sums through all possible \\(n(n-1)\\) interacting pairs, but only the pairs that are connected by a <code>CPHASE</code> in each QFT layer should have a non-zero interaction.</p> <pre><code># Building the generator for the single-qubit rotations\ndef build_sqg_gen(n_qubits, m):\n\"\"\"Generator in Eq. (13) from [^2] without the Hadamard.\"\"\"\nk_sqg_range = range(2, n_qubits - m + 2)\nsqg_gen_list = []\nfor k in k_sqg_range:\nsqg_gen = qd.kron(I(j) for j in range(n_qubits)) - Z(k+m-2) - Z(m-1)\nsqg_gen_list.append(theta(k) * sqg_gen)\nreturn sqg_gen_list\n# Building the generator for the two-qubit interactions\ndef build_tqg_gen(n_qubits, m):\n\"\"\"Generator in Eq. (14) from [^2].\"\"\"\nk_tqg_range = range(2, n_qubits + 1)\ntqg_gen_list = []\nfor k in k_tqg_range:\nfor c in range(1, k):\ntqg_gen = qd.kron(Z(c-1), Z(k-1))\ntqg_gen_list.append(alpha(c, k, m) * tqg_gen)\nreturn tqg_gen_list\n</code></pre> <p>There's a lot to process in the above functions, and it might be worth taking some time to go through them with the help of the description in <sup>2</sup>.</p> <p>Let's convince ourselves that they are doing what they are supposed to: perform one layer of the QFT using a decomposition of the CPHASE gates into an Ising Hamiltonian. We start by defining the function that will produce a given QFT layer:</p> <pre><code>def qft_layer_decomposed(n_qubits, layer_ix):\nm  = layer_ix + 1 # Paper index convention\n# Step 1:\n# List of generator terms for the single-qubit rotations\nsqg_gen_list = build_sqg_gen(n_qubits, m)\n# Exponentiate the generator for single-qubit rotations:\nsq_rotations = HamEvo(qd.add(*sqg_gen_list), -1.0)\n# Step 2:\n# List of generator for the two-qubit interactions\nising_gen_list = build_tqg_gen(n_qubits, m)\n# Exponentiating the Ising interactions:\nising_cphase = HamEvo(qd.add(*ising_gen_list), -1.0)\n# Add the explicit Hadamard to start followed by the Hamiltonian evolutions\nif len(sqg_gen_list) &gt; 0:\nreturn qd.chain(H(layer_ix), sq_rotations, ising_cphase)\nelse:\n# If the generator lists are empty returns just the Hadamard of the final layer\nreturn H(layer_ix)\n</code></pre> <p>And now we build a layer of the QFT for both the digital and the decomposed case and check that they match:</p> <pre><code>n_qubits = 3\nlayer_ix = 0\n# Building the layer with the digital QFT:\ndigital_layer_block = qft_layer(n_qubits, layer_ix)\n# Building the layer with the Ising decomposition:\ndecomposed_layer_block = qft_layer_decomposed(n_qubits, layer_ix)\n# Check that we get the same block in matrix form:\nblock_digital_matrix = qd.block_to_tensor(digital_layer_block)\nblock_decomposed_matrix = qd.block_to_tensor(decomposed_layer_block)\nassert torch.allclose(block_digital_matrix, block_decomposed_matrix)\n</code></pre>"},{"location":"digital_analog_qc/daqc-qft/#performing-the-daqc-transformation","title":"Performing the DAQC transformation","text":"<p>We now have all the ingredients to build the Digital-Analog QFT:</p> <ul> <li>In the previous DAQC tutorial we have learned about transforming an arbitrary Ising Hamiltonian into a program executing only a fixed, system-specific one.</li> <li>In this tutorial we have so far learned how to \"extract\" the arbitrary Ising Hamiltonian being used in each QFT layer.</li> </ul> <p>All that is left for us to do is to specify our system Hamiltonian, apply the DAQC transform, and build the Digital-Analog QFT layer function.</p> <p>For simplicity, we will once again consider an all-to-all Ising Hamiltonian with a constant interaction strength, but this step generalizes so any other Hamiltonian (given the limitations already discussed in the previous DAQC tutorial).</p> <pre><code>def h_sys(n_qubits, g_int = 1.0):\ninteraction_list = []\nfor i in range(n_qubits):\nfor j in range(i):\ninteraction_list.append(g_int * qd.kron(Z(i), Z(j)))\nreturn qd.add(*interaction_list)\n</code></pre> <p>Now, all we have to do is re-write the qft layer function but replace Step 2. with the transformed evolution:</p> <pre><code>def qft_layer_DAQC(n_qubits, layer_ix):\nm  = layer_ix + 1 # Paper index convention\n# Step 1:\n# List of generator terms for the single-qubit rotations\nsqg_gen_list = build_sqg_gen(n_qubits, m)\n# Exponentiate the generator for single-qubit rotations:\nsq_rotations = HamEvo(qd.add(*sqg_gen_list), -1.0)\n# Step 2:\n# List of generator for the two-qubit interactions\nising_gen_list = build_tqg_gen(n_qubits, m)\n# Transforming the target generator with DAQC:\ngen_target = qd.add(*ising_gen_list)\ntransformed_ising = qd.daqc_transform(\nn_qubits = n_qubits,          # Total number of qubits in the transformation\ngen_target = gen_target,      # The target Ising generator\nt_f = -1.0,                   # The target evolution time\ngen_build = h_sys(n_qubits),  # The building block Ising generator to be used\n)\n# Add the explicit Hadamard to start followed by the Hamiltonian evolutions\nif len(sqg_gen_list) &gt; 0:\nreturn qd.chain(H(layer_ix), sq_rotations, transformed_ising)\nelse:\n# If the generator lists are empty returns just the Hadamard of the final layer\nreturn H(layer_ix)\n</code></pre> <p>And finally, to convince ourselves that the results are correct, let's build the full DA-QFT and compare it with the digital version:</p> <pre><code>def qft_digital_analog(n_qubits):\nreturn qd.chain(qft_layer_DAQC(n_qubits, i) for i in range(n_qubits))\nn_qubits = 3\ndigital_qft_block = qft_digital(n_qubits)\ndaqc_qft_block = qft_digital_analog(n_qubits)\n# Check that we get the same block in matrix form:\nblock_digital_matrix = qd.block_to_tensor(digital_qft_block)\nblock_daqc_matrix = qd.block_to_tensor(daqc_qft_block)\nassert torch.allclose(block_digital_matrix, block_daqc_matrix)\n</code></pre> <p>And we can now display the program for the DA-QFT:</p> <pre><code># display(daqc_qft_block)\n</code></pre> %3 cluster_88ad48ff669c4886b2ea710acc90bc4a cluster_4572eec9ec284ba0973c31e72a9f922e cluster_94c9deb64b1343cda9d9ef54f6da0686 cluster_ffa3b30d05544a3a9e37a748f679c1b7 cluster_882e712216534f32be15be440fc4f82a cluster_15778dff1c31402c8526020243cdd6a6 cluster_4ee0671fdc6449418c2b61c52afca6a4 6ac766fff1d249b0876fcc614c5fdcfe 0 ca950c317cc24b88a7079b0fc5c973de H 6ac766fff1d249b0876fcc614c5fdcfe--ca950c317cc24b88a7079b0fc5c973de c949b915c4274454b540689c9497c7e2 1 abd0dd4e4b79428b9aefa0e653e974ed HamEvo ca950c317cc24b88a7079b0fc5c973de--abd0dd4e4b79428b9aefa0e653e974ed af0c5259cfd64133a054cf0ef5f4a317 X abd0dd4e4b79428b9aefa0e653e974ed--af0c5259cfd64133a054cf0ef5f4a317 035e61c5865b4f76888ce3c3a9b3b383 HamEvo af0c5259cfd64133a054cf0ef5f4a317--035e61c5865b4f76888ce3c3a9b3b383 ca0ee33762c8453b966f8924ef346c2e X 035e61c5865b4f76888ce3c3a9b3b383--ca0ee33762c8453b966f8924ef346c2e bb2098b28da0478f9bb24ddfbf89e48e X ca0ee33762c8453b966f8924ef346c2e--bb2098b28da0478f9bb24ddfbf89e48e 02dc6d03461b4ecd9c6b753919c121cb HamEvo bb2098b28da0478f9bb24ddfbf89e48e--02dc6d03461b4ecd9c6b753919c121cb 42a052f4003a4a2d9132612f34fa7db1 X 02dc6d03461b4ecd9c6b753919c121cb--42a052f4003a4a2d9132612f34fa7db1 87937e10f7a4424db12d57c8967d9b7e 42a052f4003a4a2d9132612f34fa7db1--87937e10f7a4424db12d57c8967d9b7e c9d59c3092ac45a2b2f2daa9126d47dc HamEvo 87937e10f7a4424db12d57c8967d9b7e--c9d59c3092ac45a2b2f2daa9126d47dc 78933b79c97946acb462d6161719ea9b c9d59c3092ac45a2b2f2daa9126d47dc--78933b79c97946acb462d6161719ea9b ecdc2f2ff3d44fb2aa553a0245ca7b79 78933b79c97946acb462d6161719ea9b--ecdc2f2ff3d44fb2aa553a0245ca7b79 ff53819e31db46a095bc939f540cc407 HamEvo ecdc2f2ff3d44fb2aa553a0245ca7b79--ff53819e31db46a095bc939f540cc407 2d1050d694984c78aa09daecb82c795a X ff53819e31db46a095bc939f540cc407--2d1050d694984c78aa09daecb82c795a 7253fd15f5f349969b195f0a80de2cf4 HamEvo 2d1050d694984c78aa09daecb82c795a--7253fd15f5f349969b195f0a80de2cf4 b1646db977424b6e8da1443fa7b124eb X 7253fd15f5f349969b195f0a80de2cf4--b1646db977424b6e8da1443fa7b124eb c72192f465294b1b8f1bafaf75b1b793 X b1646db977424b6e8da1443fa7b124eb--c72192f465294b1b8f1bafaf75b1b793 6d65344147bc4bdfac01c01ba6dacf1c HamEvo c72192f465294b1b8f1bafaf75b1b793--6d65344147bc4bdfac01c01ba6dacf1c 2e60c6d35d774c1fb71eb9d1451442e6 X 6d65344147bc4bdfac01c01ba6dacf1c--2e60c6d35d774c1fb71eb9d1451442e6 5f7d9d7dc08c4a7aa2cdda3b32f50cfe 2e60c6d35d774c1fb71eb9d1451442e6--5f7d9d7dc08c4a7aa2cdda3b32f50cfe 6a3077fd1169403f80de154eeace21d3 5f7d9d7dc08c4a7aa2cdda3b32f50cfe--6a3077fd1169403f80de154eeace21d3 16ec459bf83f4d1e963318a7234f7f59 79e6d1a4395b4adb9ee14a3a88a8f61a c949b915c4274454b540689c9497c7e2--79e6d1a4395b4adb9ee14a3a88a8f61a a91656fa8e6642fd900c4d0b8f2e148e 2 7fe34ac751e6436882aabeb00a68f476 t = -1.00000000000000 79e6d1a4395b4adb9ee14a3a88a8f61a--7fe34ac751e6436882aabeb00a68f476 a9e391866b724268bb74bc41e9beea80 X 7fe34ac751e6436882aabeb00a68f476--a9e391866b724268bb74bc41e9beea80 774a7eccfd874043b3dc4c53a4727275 t = 0.098 a9e391866b724268bb74bc41e9beea80--774a7eccfd874043b3dc4c53a4727275 c5e2e3551373413e97924cc1c7b92e46 X 774a7eccfd874043b3dc4c53a4727275--c5e2e3551373413e97924cc1c7b92e46 999f6d7b7e8243889e1677cd4886e3ef c5e2e3551373413e97924cc1c7b92e46--999f6d7b7e8243889e1677cd4886e3ef 197860c871af47acbfd4c434d1dd2545 t = 0.196 999f6d7b7e8243889e1677cd4886e3ef--197860c871af47acbfd4c434d1dd2545 cc50bafde9744da792463ff44d6b2575 197860c871af47acbfd4c434d1dd2545--cc50bafde9744da792463ff44d6b2575 79b8ec4ddff045b4be73760ba56ad4a3 X cc50bafde9744da792463ff44d6b2575--79b8ec4ddff045b4be73760ba56ad4a3 247bc30b81a24065b69cf68793d240f4 t = 0.295 79b8ec4ddff045b4be73760ba56ad4a3--247bc30b81a24065b69cf68793d240f4 3075deb17f6b4fecb490ea0009d7fbd4 X 247bc30b81a24065b69cf68793d240f4--3075deb17f6b4fecb490ea0009d7fbd4 3e1775903d7c49aa8ef0529bcaf90382 H 3075deb17f6b4fecb490ea0009d7fbd4--3e1775903d7c49aa8ef0529bcaf90382 e8d2439aa0ad4abcb5a9decc3dd4aa64 t = -1.00000000000000 3e1775903d7c49aa8ef0529bcaf90382--e8d2439aa0ad4abcb5a9decc3dd4aa64 ce1506a89e124bedb7461f9d4edba87f X e8d2439aa0ad4abcb5a9decc3dd4aa64--ce1506a89e124bedb7461f9d4edba87f e2286192a30d4d07a9b5804098b9f6d2 t = 0.196 ce1506a89e124bedb7461f9d4edba87f--e2286192a30d4d07a9b5804098b9f6d2 e541cd2ddd964dcc93bfaf356f4841c3 X e2286192a30d4d07a9b5804098b9f6d2--e541cd2ddd964dcc93bfaf356f4841c3 7b71519489b342ca925a3d477d6e983e e541cd2ddd964dcc93bfaf356f4841c3--7b71519489b342ca925a3d477d6e983e ddc3ada16a1e416a9ce254ad51e4ea55 t = 0.196 7b71519489b342ca925a3d477d6e983e--ddc3ada16a1e416a9ce254ad51e4ea55 ee117f6f2c4a47e79ce1f4b7fa09eb96 ddc3ada16a1e416a9ce254ad51e4ea55--ee117f6f2c4a47e79ce1f4b7fa09eb96 8fde0bc3f2c74910bf9f40c406485df3 ee117f6f2c4a47e79ce1f4b7fa09eb96--8fde0bc3f2c74910bf9f40c406485df3 8fde0bc3f2c74910bf9f40c406485df3--16ec459bf83f4d1e963318a7234f7f59 a000aa85310b4d2298bd3c6aea05c22b bc22d3b06e3e45ee81dcee2b6b09f763 a91656fa8e6642fd900c4d0b8f2e148e--bc22d3b06e3e45ee81dcee2b6b09f763 da5791d0ddba49c28c1155f744bb2acd bc22d3b06e3e45ee81dcee2b6b09f763--da5791d0ddba49c28c1155f744bb2acd 65f02225aab145d991daa1765082664d da5791d0ddba49c28c1155f744bb2acd--65f02225aab145d991daa1765082664d e7f395e756024970b7eac9e507fdfb19 65f02225aab145d991daa1765082664d--e7f395e756024970b7eac9e507fdfb19 d0ac085de45949bb820ed75d3412f1af e7f395e756024970b7eac9e507fdfb19--d0ac085de45949bb820ed75d3412f1af d6070e28306e49ddb1324503da837c7d X d0ac085de45949bb820ed75d3412f1af--d6070e28306e49ddb1324503da837c7d 8ea4d09a98894a36aab87937f631e185 d6070e28306e49ddb1324503da837c7d--8ea4d09a98894a36aab87937f631e185 df8ad2d506224edd9f442129bb615cca X 8ea4d09a98894a36aab87937f631e185--df8ad2d506224edd9f442129bb615cca 7c4e4c1d43ef4258a9b9501aeff426df X df8ad2d506224edd9f442129bb615cca--7c4e4c1d43ef4258a9b9501aeff426df 8f996966bebd42c9afff4228289316f0 7c4e4c1d43ef4258a9b9501aeff426df--8f996966bebd42c9afff4228289316f0 a948404985d44a0a802e6d03f6b96ab7 X 8f996966bebd42c9afff4228289316f0--a948404985d44a0a802e6d03f6b96ab7 2a6db7d1559741d797699e299aa18b1d a948404985d44a0a802e6d03f6b96ab7--2a6db7d1559741d797699e299aa18b1d 2406538a74d5457388254831dc2b469a 2a6db7d1559741d797699e299aa18b1d--2406538a74d5457388254831dc2b469a a8b8176337294b7f9effe354a03412cf 2406538a74d5457388254831dc2b469a--a8b8176337294b7f9effe354a03412cf cacbe8864f7640ccaf1e7678dda32d27 a8b8176337294b7f9effe354a03412cf--cacbe8864f7640ccaf1e7678dda32d27 af2c6c9dd3b54431a5e4eaf47126b271 cacbe8864f7640ccaf1e7678dda32d27--af2c6c9dd3b54431a5e4eaf47126b271 5b56b09076544ef6ae3f9e2b177108b4 X af2c6c9dd3b54431a5e4eaf47126b271--5b56b09076544ef6ae3f9e2b177108b4 9865bfe12fa044e0b1d00ae2625bfd99 5b56b09076544ef6ae3f9e2b177108b4--9865bfe12fa044e0b1d00ae2625bfd99 0fd056f5cc704dc2bc500ff25cf404c3 X 9865bfe12fa044e0b1d00ae2625bfd99--0fd056f5cc704dc2bc500ff25cf404c3 b4a12b8124324f17bba718018efd6106 H 0fd056f5cc704dc2bc500ff25cf404c3--b4a12b8124324f17bba718018efd6106 b4a12b8124324f17bba718018efd6106--a000aa85310b4d2298bd3c6aea05c22b"},{"location":"digital_analog_qc/daqc-qft/#the-da-qft-in-qadence","title":"The DA-QFT in <code>qadence</code>:","text":"<p>The digital-analog QFT is available directly by using the <code>strategy</code> argument in the QFT:</p> <pre><code>n_qubits = 3\nqft_circuit = qd.qft(n_qubits, strategy = qd.Strategy.SDAQC)\n# display(qft_circuit)\n</code></pre> %3 cluster_8b49710b0d2c43548128cf1b67d7c281 cluster_9fcfba59ab424719a330ac406ecf0177 cluster_785379db17424179a36b5d30a97e6891 cluster_903b715fb49d4855ba6cb43421a16019 cluster_445a6999617344c294993c9fb82488b3 cluster_2724d66a8f00486f85a8a9ff6bc0686a cluster_e1f70dd11f564cfc9847dc102946ed87 cluster_d02805f284414f1bb74cea5d0b83db73 cluster_1b955ad41d994be1bd8e5a770dd9afc8 cluster_d9998620bb2946b09cbeb83aca725462 cluster_b65878d1836d4d189566e956a489898d cluster_e6048803165b4c5a9894369fe839c76d cluster_5186a800b092438ab4c40f9a986d8c70 cluster_0ffef0f703a449b8a8caf4383f61ef1e 5c5a6878714f472eb18a9988d5ba79ca 0 20f5cefe24c549419407b4accab74c8c H 5c5a6878714f472eb18a9988d5ba79ca--20f5cefe24c549419407b4accab74c8c 70e1eed30ead4292892c263371e93ec8 1 b45b1a4a386b4eba928010e76018568a HamEvo 20f5cefe24c549419407b4accab74c8c--b45b1a4a386b4eba928010e76018568a af4d208bb57e4e67876b15f3faddcf8e HamEvo b45b1a4a386b4eba928010e76018568a--af4d208bb57e4e67876b15f3faddcf8e 29821b6cd0754e0dbfdd1f930d49e472 X af4d208bb57e4e67876b15f3faddcf8e--29821b6cd0754e0dbfdd1f930d49e472 9c21aaac81444f69893718ac678ddd54 HamEvo 29821b6cd0754e0dbfdd1f930d49e472--9c21aaac81444f69893718ac678ddd54 62aedeaf1c2b4bb0a1e5307aaf25dfb4 HamEvo 9c21aaac81444f69893718ac678ddd54--62aedeaf1c2b4bb0a1e5307aaf25dfb4 743835ee4e2f4da6881a3f2666f9d00b X 62aedeaf1c2b4bb0a1e5307aaf25dfb4--743835ee4e2f4da6881a3f2666f9d00b 858983c05ddb4067840537937607e73f X 743835ee4e2f4da6881a3f2666f9d00b--858983c05ddb4067840537937607e73f 04573f6adde440eda316b0c651f1a15f HamEvo 858983c05ddb4067840537937607e73f--04573f6adde440eda316b0c651f1a15f 9c26d9b5569d432aafb2836c6296e2ca HamEvo 04573f6adde440eda316b0c651f1a15f--9c26d9b5569d432aafb2836c6296e2ca b263c1fbdd674399b207950ba18c0616 X 9c26d9b5569d432aafb2836c6296e2ca--b263c1fbdd674399b207950ba18c0616 0db067a7700947638b1a0d24832d0f3d b263c1fbdd674399b207950ba18c0616--0db067a7700947638b1a0d24832d0f3d c5dd0f54642344b88e74bd3fac30f1d1 HamEvo 0db067a7700947638b1a0d24832d0f3d--c5dd0f54642344b88e74bd3fac30f1d1 778d0d7e9fbb477484e8cf2cc057d375 HamEvo c5dd0f54642344b88e74bd3fac30f1d1--778d0d7e9fbb477484e8cf2cc057d375 c06267bc85704d2e8c3b52ceb801bd33 778d0d7e9fbb477484e8cf2cc057d375--c06267bc85704d2e8c3b52ceb801bd33 68af10ce5e374cf59be228f888f1f43e c06267bc85704d2e8c3b52ceb801bd33--68af10ce5e374cf59be228f888f1f43e c47e829ec90a43dba8ed1a8cb3c63f1d HamEvo 68af10ce5e374cf59be228f888f1f43e--c47e829ec90a43dba8ed1a8cb3c63f1d b9894620405e424bb45e2faf5770aa8c HamEvo c47e829ec90a43dba8ed1a8cb3c63f1d--b9894620405e424bb45e2faf5770aa8c 4b106f9eccdb4aa89156b7f3b133af40 X b9894620405e424bb45e2faf5770aa8c--4b106f9eccdb4aa89156b7f3b133af40 17b785e1fd304726b0a78c6ff11d7282 HamEvo 4b106f9eccdb4aa89156b7f3b133af40--17b785e1fd304726b0a78c6ff11d7282 6def16d9fcdf47cfb2052193b19b7600 HamEvo 17b785e1fd304726b0a78c6ff11d7282--6def16d9fcdf47cfb2052193b19b7600 b453c011029241488d10313eaa8a4492 X 6def16d9fcdf47cfb2052193b19b7600--b453c011029241488d10313eaa8a4492 d07e5094a4fb4ae99b0088d51b035f8d X b453c011029241488d10313eaa8a4492--d07e5094a4fb4ae99b0088d51b035f8d a236253531424cfa9bd6aff3fd1087f4 HamEvo d07e5094a4fb4ae99b0088d51b035f8d--a236253531424cfa9bd6aff3fd1087f4 184522afc13c466eaea34bbaf553d19a HamEvo a236253531424cfa9bd6aff3fd1087f4--184522afc13c466eaea34bbaf553d19a ddcfeb6613274f26a8919cb0c27de762 X 184522afc13c466eaea34bbaf553d19a--ddcfeb6613274f26a8919cb0c27de762 c75153e3010249d7819456523874b98b ddcfeb6613274f26a8919cb0c27de762--c75153e3010249d7819456523874b98b 155a58535e4541b4a0ad3896ad73b607 c75153e3010249d7819456523874b98b--155a58535e4541b4a0ad3896ad73b607 b5e174de78df41459fb852fc0856ea56 009fe434e739499d99a6e0561dfb6d97 70e1eed30ead4292892c263371e93ec8--009fe434e739499d99a6e0561dfb6d97 60730e609c324c8d876adcad43b358a0 2 8dce0caeee8944878f5750f17e186ed2 t = -1.00000000000000 009fe434e739499d99a6e0561dfb6d97--8dce0caeee8944878f5750f17e186ed2 a0f363978e3e4e96ad613302ba8756db t = 2.356 8dce0caeee8944878f5750f17e186ed2--a0f363978e3e4e96ad613302ba8756db c628e33f85ce4aedb98098bd4c676010 X a0f363978e3e4e96ad613302ba8756db--c628e33f85ce4aedb98098bd4c676010 21b5acc100874458a27762fd6662daee t = 0.393 c628e33f85ce4aedb98098bd4c676010--21b5acc100874458a27762fd6662daee 958c6869e85d4063bfda93b3b46bee0e t = 0.393 21b5acc100874458a27762fd6662daee--958c6869e85d4063bfda93b3b46bee0e 8d4850aa16b84e6681431e251f7bd1d1 X 958c6869e85d4063bfda93b3b46bee0e--8d4850aa16b84e6681431e251f7bd1d1 fd1fe0eb83ea4c20889da66816335e32 8d4850aa16b84e6681431e251f7bd1d1--fd1fe0eb83ea4c20889da66816335e32 2d9114125f274f829e05603a52e3a1ef t = 0.785 fd1fe0eb83ea4c20889da66816335e32--2d9114125f274f829e05603a52e3a1ef 7fc82f4914294065b2c6c3742f6adc05 t = 0.785 2d9114125f274f829e05603a52e3a1ef--7fc82f4914294065b2c6c3742f6adc05 ab30d5604344475dbadcf381b80f7c8e 7fc82f4914294065b2c6c3742f6adc05--ab30d5604344475dbadcf381b80f7c8e 1b8f3e08c6284cf0bf1b3a8dac7efbb1 X ab30d5604344475dbadcf381b80f7c8e--1b8f3e08c6284cf0bf1b3a8dac7efbb1 a46e5a5e97ae4a199ab9abae1131eb2e t = 1.178 1b8f3e08c6284cf0bf1b3a8dac7efbb1--a46e5a5e97ae4a199ab9abae1131eb2e 3259b970968042be94ff7589e44e8d8a t = 1.178 a46e5a5e97ae4a199ab9abae1131eb2e--3259b970968042be94ff7589e44e8d8a 71d8a68419444a09958b36d939dd6a76 X 3259b970968042be94ff7589e44e8d8a--71d8a68419444a09958b36d939dd6a76 90ea0206fae9409e92ffbea5240460c9 H 71d8a68419444a09958b36d939dd6a76--90ea0206fae9409e92ffbea5240460c9 c5ee28a4860a488b8520ce671af2bd2a t = -1.00000000000000 90ea0206fae9409e92ffbea5240460c9--c5ee28a4860a488b8520ce671af2bd2a 8285d98ac5124d74b8110e856e93a503 t = 1.571 c5ee28a4860a488b8520ce671af2bd2a--8285d98ac5124d74b8110e856e93a503 8fc290858afd40c3b409641b4647f2f8 X 8285d98ac5124d74b8110e856e93a503--8fc290858afd40c3b409641b4647f2f8 6c3ec2c9e6194c6ba66cf9470f962d98 t = 0.785 8fc290858afd40c3b409641b4647f2f8--6c3ec2c9e6194c6ba66cf9470f962d98 42e634069d214c19a8ab5286da0ddb95 t = 0.785 6c3ec2c9e6194c6ba66cf9470f962d98--42e634069d214c19a8ab5286da0ddb95 a1b5d3e99e9a4bc9ad154d6de11305d6 X 42e634069d214c19a8ab5286da0ddb95--a1b5d3e99e9a4bc9ad154d6de11305d6 43e085d05a0d4695ae78bc4e6f6a471c a1b5d3e99e9a4bc9ad154d6de11305d6--43e085d05a0d4695ae78bc4e6f6a471c 09ad4d75958d4b0e8d2f7baefe1c949a t = 0.785 43e085d05a0d4695ae78bc4e6f6a471c--09ad4d75958d4b0e8d2f7baefe1c949a a6e516e0a938458fb4e2d38a1b0a0c17 t = 0.785 09ad4d75958d4b0e8d2f7baefe1c949a--a6e516e0a938458fb4e2d38a1b0a0c17 7aa083525e9648d1a107bc10f943c204 a6e516e0a938458fb4e2d38a1b0a0c17--7aa083525e9648d1a107bc10f943c204 b1766cc2932748e186c8b9af5c0d1816 7aa083525e9648d1a107bc10f943c204--b1766cc2932748e186c8b9af5c0d1816 b1766cc2932748e186c8b9af5c0d1816--b5e174de78df41459fb852fc0856ea56 01a6144344d84f7192d3b1483d1818ff 39aa841e719e4858babe31c6a28c5bd9 60730e609c324c8d876adcad43b358a0--39aa841e719e4858babe31c6a28c5bd9 2431547bb86d4e45b05fd07fa057f945 39aa841e719e4858babe31c6a28c5bd9--2431547bb86d4e45b05fd07fa057f945 13e9c11bd2b346218a7bb0c275942f3f 2431547bb86d4e45b05fd07fa057f945--13e9c11bd2b346218a7bb0c275942f3f 2c7abbfb6d7d402b85a4d84738fe2df5 13e9c11bd2b346218a7bb0c275942f3f--2c7abbfb6d7d402b85a4d84738fe2df5 b3d02705e26e4881b975eaee13395488 2c7abbfb6d7d402b85a4d84738fe2df5--b3d02705e26e4881b975eaee13395488 9be9167948d84ac8b8ba95c33a6b582e b3d02705e26e4881b975eaee13395488--9be9167948d84ac8b8ba95c33a6b582e b4479cc5cd2e4db7a0a65a93d49a59f0 9be9167948d84ac8b8ba95c33a6b582e--b4479cc5cd2e4db7a0a65a93d49a59f0 960f791425d64346aa1f819561f7b2ab X b4479cc5cd2e4db7a0a65a93d49a59f0--960f791425d64346aa1f819561f7b2ab 17244727ecc54a0b95bf69ebc58cdbb5 960f791425d64346aa1f819561f7b2ab--17244727ecc54a0b95bf69ebc58cdbb5 d795a7246a5944efa9a637e435c8f33f 17244727ecc54a0b95bf69ebc58cdbb5--d795a7246a5944efa9a637e435c8f33f bf048219a38d48ff8fd47169b3ae5169 X d795a7246a5944efa9a637e435c8f33f--bf048219a38d48ff8fd47169b3ae5169 df1b2917bc944578b11b464dba70d178 X bf048219a38d48ff8fd47169b3ae5169--df1b2917bc944578b11b464dba70d178 4b74693bbeec470fbe0cf8611e04845f df1b2917bc944578b11b464dba70d178--4b74693bbeec470fbe0cf8611e04845f ce2f531e6dd5405eae9f8c1e973afa99 4b74693bbeec470fbe0cf8611e04845f--ce2f531e6dd5405eae9f8c1e973afa99 3cc71fe21abb4cf58acdcf8197520fcf X ce2f531e6dd5405eae9f8c1e973afa99--3cc71fe21abb4cf58acdcf8197520fcf c0b1d53beae347a58687e168c7caa2ad 3cc71fe21abb4cf58acdcf8197520fcf--c0b1d53beae347a58687e168c7caa2ad 45a68bbf00f74dd08f0ebcb23d6ba4fa c0b1d53beae347a58687e168c7caa2ad--45a68bbf00f74dd08f0ebcb23d6ba4fa 6d3124bde43e49b1bc5a32f8cc48ce43 45a68bbf00f74dd08f0ebcb23d6ba4fa--6d3124bde43e49b1bc5a32f8cc48ce43 0134fa2eb63644ccb86da95d83a003e0 6d3124bde43e49b1bc5a32f8cc48ce43--0134fa2eb63644ccb86da95d83a003e0 c6cbe47980b143deb694c8e0032532fa 0134fa2eb63644ccb86da95d83a003e0--c6cbe47980b143deb694c8e0032532fa 4ae14b0c679748f898d755de6aeda191 c6cbe47980b143deb694c8e0032532fa--4ae14b0c679748f898d755de6aeda191 116f7436f8f24ca7985e42a2009d4afd 4ae14b0c679748f898d755de6aeda191--116f7436f8f24ca7985e42a2009d4afd 2dbdb76ee961428d8a710a2411b3921e X 116f7436f8f24ca7985e42a2009d4afd--2dbdb76ee961428d8a710a2411b3921e f8a79dc445424df8a9f3212b667976d8 2dbdb76ee961428d8a710a2411b3921e--f8a79dc445424df8a9f3212b667976d8 434430be05bb4be285ddc1f10c2ece78 f8a79dc445424df8a9f3212b667976d8--434430be05bb4be285ddc1f10c2ece78 5ef1214d8bb842678928d24487605f57 X 434430be05bb4be285ddc1f10c2ece78--5ef1214d8bb842678928d24487605f57 8a4190da1c334c948ad73fb9724a5574 H 5ef1214d8bb842678928d24487605f57--8a4190da1c334c948ad73fb9724a5574 8a4190da1c334c948ad73fb9724a5574--01a6144344d84f7192d3b1483d1818ff <p>Just like with the <code>daqc_transform</code>, we can pass a different build Hamiltonian to it for the analog blocks, including one composed of \\(NN\\) interactions:</p> <pre><code>from qadence import hamiltonian_factory, Interaction\nn_qubits = 3\ngen_build = hamiltonian_factory(n_qubits, interaction = Interaction.NN)\nqft_circuit = qd.qft(n_qubits, strategy = qd.Strategy.SDAQC, gen_build = gen_build)\n# display(qft_circuit)\n</code></pre> %3 cluster_3ea27f6079ec4aa4b9574e826fba0cee cluster_8b6d38435e704bd1b69693ba6e7d99e9 cluster_b4ec6f3385aa4c129371f19dd66b427e cluster_787359dd3a07452fa01276e38011ac47 cluster_72ca46c7c46346e0b0335c00544368fe cluster_fec6a799f0504128998fb13f28ca3929 cluster_40fa0c04b59541e69da718bcb002e513 cluster_e10541e8235f49f6a25f783339c8a28c cluster_35a2816e2b2e43ab805fe3d780c93f6b cluster_48d092fa456f4536a145232d839dcf21 cluster_3ac7908ca9b443679752e6cf5b8f1078 cluster_d1687cf89e13496c9cc2601dc61b4b33 cluster_fd46bfaad199443e860f0317fac0014a cluster_454f19ae724d43bca155681c7d969b6e e3a7f78eeab04af9ab8cb78ff8b769be 0 44995e1ef76d40e4acd060356b53699a H e3a7f78eeab04af9ab8cb78ff8b769be--44995e1ef76d40e4acd060356b53699a 4faf06d09c4445c5855a7fcbd7009c9b 1 74dfc1b0575d4e439d8b496cc73c5707 HamEvo 44995e1ef76d40e4acd060356b53699a--74dfc1b0575d4e439d8b496cc73c5707 2812da5cf02a45caa1b3d47bdea2b1fa HamEvo 74dfc1b0575d4e439d8b496cc73c5707--2812da5cf02a45caa1b3d47bdea2b1fa 7a6b0d0a2196400c9cd62fbd3e79dbcc X 2812da5cf02a45caa1b3d47bdea2b1fa--7a6b0d0a2196400c9cd62fbd3e79dbcc f701b16fd9a24c64aaa97337f4e2528b HamEvo 7a6b0d0a2196400c9cd62fbd3e79dbcc--f701b16fd9a24c64aaa97337f4e2528b 90cb3506f44848999534230cee68d3e2 HamEvo f701b16fd9a24c64aaa97337f4e2528b--90cb3506f44848999534230cee68d3e2 ce0f23edb2fb4ece87f4ba49e52b171b X 90cb3506f44848999534230cee68d3e2--ce0f23edb2fb4ece87f4ba49e52b171b 145b29ae368f41e69eef68fcdb33e45b X ce0f23edb2fb4ece87f4ba49e52b171b--145b29ae368f41e69eef68fcdb33e45b aaf6ba8b504247d786155924cb11002f HamEvo 145b29ae368f41e69eef68fcdb33e45b--aaf6ba8b504247d786155924cb11002f f72ebee9157a498c9b61c30ae9179e3a HamEvo aaf6ba8b504247d786155924cb11002f--f72ebee9157a498c9b61c30ae9179e3a 368e1404efa648619d3e13689ad87c9f X f72ebee9157a498c9b61c30ae9179e3a--368e1404efa648619d3e13689ad87c9f a0b003ee2ab14095ab51cc8fb0f2b9b7 368e1404efa648619d3e13689ad87c9f--a0b003ee2ab14095ab51cc8fb0f2b9b7 a59f6eb205874fdab90db8ca8bae9854 HamEvo a0b003ee2ab14095ab51cc8fb0f2b9b7--a59f6eb205874fdab90db8ca8bae9854 c45e45d240ef4f2380a24c1733041754 HamEvo a59f6eb205874fdab90db8ca8bae9854--c45e45d240ef4f2380a24c1733041754 97b143bff4634722ae929520afb9a83b c45e45d240ef4f2380a24c1733041754--97b143bff4634722ae929520afb9a83b ced7502f2e54400481d813eaae8895ab 97b143bff4634722ae929520afb9a83b--ced7502f2e54400481d813eaae8895ab 40a271ef202d4afd8af10dc1f28c67ac HamEvo ced7502f2e54400481d813eaae8895ab--40a271ef202d4afd8af10dc1f28c67ac 8c4e94cc627e4e5a8a6ee1dab97c02ec HamEvo 40a271ef202d4afd8af10dc1f28c67ac--8c4e94cc627e4e5a8a6ee1dab97c02ec 0167cc7f9e0e44cfb3cc34f9b209c000 X 8c4e94cc627e4e5a8a6ee1dab97c02ec--0167cc7f9e0e44cfb3cc34f9b209c000 a058cdabc6bd4151a663d12dd4d38d58 HamEvo 0167cc7f9e0e44cfb3cc34f9b209c000--a058cdabc6bd4151a663d12dd4d38d58 189b997707504bcab6f4402240563dcc HamEvo a058cdabc6bd4151a663d12dd4d38d58--189b997707504bcab6f4402240563dcc b2d29de89b73442ba1bc8501bce0511e X 189b997707504bcab6f4402240563dcc--b2d29de89b73442ba1bc8501bce0511e 60001b773796453b85a15102f84baf71 X b2d29de89b73442ba1bc8501bce0511e--60001b773796453b85a15102f84baf71 6615570b8ab446aeb42d44de18d9903b HamEvo 60001b773796453b85a15102f84baf71--6615570b8ab446aeb42d44de18d9903b 5b206365b1dd43f7a71854c7bfa66e28 HamEvo 6615570b8ab446aeb42d44de18d9903b--5b206365b1dd43f7a71854c7bfa66e28 4c5a58483e9045f7a92069a774624063 X 5b206365b1dd43f7a71854c7bfa66e28--4c5a58483e9045f7a92069a774624063 bc98f3bd0e38468eaae135d89c942eae 4c5a58483e9045f7a92069a774624063--bc98f3bd0e38468eaae135d89c942eae d60dc5ae161345e99e5ff20034054c25 bc98f3bd0e38468eaae135d89c942eae--d60dc5ae161345e99e5ff20034054c25 77e3b99070c241439b0bfab679f0cb2c 15b82b59e67a47fc8e74af933a705e23 4faf06d09c4445c5855a7fcbd7009c9b--15b82b59e67a47fc8e74af933a705e23 df04bc8594d2405ab6f0b257360adf7f 2 4e94c1af3fa1471cb4e8c13f2033b8a2 t = -1.00000000000000 15b82b59e67a47fc8e74af933a705e23--4e94c1af3fa1471cb4e8c13f2033b8a2 0af5a923fea2413b8f92f27ac5804691 t = 2.356 4e94c1af3fa1471cb4e8c13f2033b8a2--0af5a923fea2413b8f92f27ac5804691 88ce1e88fca044ca9aac2c51d14de444 X 0af5a923fea2413b8f92f27ac5804691--88ce1e88fca044ca9aac2c51d14de444 6047c7d207e946f9ad11e90da8536a73 t = 0.393 88ce1e88fca044ca9aac2c51d14de444--6047c7d207e946f9ad11e90da8536a73 4728441920274650a847b7f60619eb85 t = 0.393 6047c7d207e946f9ad11e90da8536a73--4728441920274650a847b7f60619eb85 f522673ce16040d0b68ee6dd4a52e7e7 X 4728441920274650a847b7f60619eb85--f522673ce16040d0b68ee6dd4a52e7e7 6a660b4f0e1f48328a400665c0075b01 f522673ce16040d0b68ee6dd4a52e7e7--6a660b4f0e1f48328a400665c0075b01 544f506e109247a0a7c74b06f4dd69a7 t = 0.785 6a660b4f0e1f48328a400665c0075b01--544f506e109247a0a7c74b06f4dd69a7 d584889cc681401a839967ba2f1f0a40 t = 0.785 544f506e109247a0a7c74b06f4dd69a7--d584889cc681401a839967ba2f1f0a40 ef74eb4c846942a0ac8292cf87d3d018 d584889cc681401a839967ba2f1f0a40--ef74eb4c846942a0ac8292cf87d3d018 59bc5f67546541d0898fe308d48aac20 X ef74eb4c846942a0ac8292cf87d3d018--59bc5f67546541d0898fe308d48aac20 74e4aff54916493b80ac6accf4b96d4b t = 1.178 59bc5f67546541d0898fe308d48aac20--74e4aff54916493b80ac6accf4b96d4b 5062a69b08f34235a8fc793776173cba t = 1.178 74e4aff54916493b80ac6accf4b96d4b--5062a69b08f34235a8fc793776173cba 5a313f9079ca4cb3aa73e98787800fa5 X 5062a69b08f34235a8fc793776173cba--5a313f9079ca4cb3aa73e98787800fa5 1499991a851841dbbe27c7dabad3d2ae H 5a313f9079ca4cb3aa73e98787800fa5--1499991a851841dbbe27c7dabad3d2ae d2e5aec1281d495b896f87b9653a4ac1 t = -1.00000000000000 1499991a851841dbbe27c7dabad3d2ae--d2e5aec1281d495b896f87b9653a4ac1 ea8618e20e07400b9ed7cef56496e22e t = 1.571 d2e5aec1281d495b896f87b9653a4ac1--ea8618e20e07400b9ed7cef56496e22e 23de4372435a4480a2f9fdb04c0fd539 X ea8618e20e07400b9ed7cef56496e22e--23de4372435a4480a2f9fdb04c0fd539 ba4a970185044e99a2fea795749e5710 t = 0.785 23de4372435a4480a2f9fdb04c0fd539--ba4a970185044e99a2fea795749e5710 a1ea960e3239432694ebfe7996a602d1 t = 0.785 ba4a970185044e99a2fea795749e5710--a1ea960e3239432694ebfe7996a602d1 db72bdd0e40b4699bc0c7bf192885c47 X a1ea960e3239432694ebfe7996a602d1--db72bdd0e40b4699bc0c7bf192885c47 4718c44f82a648f4a22ec197394de558 db72bdd0e40b4699bc0c7bf192885c47--4718c44f82a648f4a22ec197394de558 1a773475dd7d4c3491918d764d3a8082 t = 0.785 4718c44f82a648f4a22ec197394de558--1a773475dd7d4c3491918d764d3a8082 9735cf3ac5e448048e3e851ac8ae6598 t = 0.785 1a773475dd7d4c3491918d764d3a8082--9735cf3ac5e448048e3e851ac8ae6598 cf79025b243e4ee8b3c6b2b99999f437 9735cf3ac5e448048e3e851ac8ae6598--cf79025b243e4ee8b3c6b2b99999f437 541b9c1175cf4ac7b55abdcba124a29e cf79025b243e4ee8b3c6b2b99999f437--541b9c1175cf4ac7b55abdcba124a29e 541b9c1175cf4ac7b55abdcba124a29e--77e3b99070c241439b0bfab679f0cb2c a2f6bbd25af84a99bf87160c143d36ab 112c656b8a0341298fb41696c455b3d5 df04bc8594d2405ab6f0b257360adf7f--112c656b8a0341298fb41696c455b3d5 578586e344fd4e92b0c75b440375127a 112c656b8a0341298fb41696c455b3d5--578586e344fd4e92b0c75b440375127a 9a0b21e8d1944934a9dfcd9323a5793b 578586e344fd4e92b0c75b440375127a--9a0b21e8d1944934a9dfcd9323a5793b 7b803100a82a43aab3c464af0bee8ef8 9a0b21e8d1944934a9dfcd9323a5793b--7b803100a82a43aab3c464af0bee8ef8 1acfd98950bf4195a2a255d5f91b97f6 7b803100a82a43aab3c464af0bee8ef8--1acfd98950bf4195a2a255d5f91b97f6 fd59ef65c67b4f2d9f3e945b839b6ea5 1acfd98950bf4195a2a255d5f91b97f6--fd59ef65c67b4f2d9f3e945b839b6ea5 6f6c80233b914c299c28cd498288ae68 fd59ef65c67b4f2d9f3e945b839b6ea5--6f6c80233b914c299c28cd498288ae68 c63d902f59074b0e9005cac620fbdc1c X 6f6c80233b914c299c28cd498288ae68--c63d902f59074b0e9005cac620fbdc1c 28599b367c2e4d5fb2d46e09ecf079d8 c63d902f59074b0e9005cac620fbdc1c--28599b367c2e4d5fb2d46e09ecf079d8 79eaf4abf94943ebaec70c52eb548460 28599b367c2e4d5fb2d46e09ecf079d8--79eaf4abf94943ebaec70c52eb548460 c308a3ad8a744742a0eb82ff8782a365 X 79eaf4abf94943ebaec70c52eb548460--c308a3ad8a744742a0eb82ff8782a365 3be648e01bbc472f8ffa64adefdd21ce X c308a3ad8a744742a0eb82ff8782a365--3be648e01bbc472f8ffa64adefdd21ce fc69173fce9943e29cbc09fb71e92b61 3be648e01bbc472f8ffa64adefdd21ce--fc69173fce9943e29cbc09fb71e92b61 df792a90c268409fa7d22300316b6d55 fc69173fce9943e29cbc09fb71e92b61--df792a90c268409fa7d22300316b6d55 858d18cb28d744e7b2a8fcff63d73520 X df792a90c268409fa7d22300316b6d55--858d18cb28d744e7b2a8fcff63d73520 bc807502cf1e4e73a14057cb90324416 858d18cb28d744e7b2a8fcff63d73520--bc807502cf1e4e73a14057cb90324416 d217c898fbf74f15878ff0f5efffc96f bc807502cf1e4e73a14057cb90324416--d217c898fbf74f15878ff0f5efffc96f aa05fafd46a5483bb5721671becfa004 d217c898fbf74f15878ff0f5efffc96f--aa05fafd46a5483bb5721671becfa004 9bdb42f4e8e4469986e23b88c4edc350 aa05fafd46a5483bb5721671becfa004--9bdb42f4e8e4469986e23b88c4edc350 abdf7ab19b5949039edb908e3b15f65a 9bdb42f4e8e4469986e23b88c4edc350--abdf7ab19b5949039edb908e3b15f65a fd9e5c0c9164444db293aa8f8baee2e1 abdf7ab19b5949039edb908e3b15f65a--fd9e5c0c9164444db293aa8f8baee2e1 ad2d53fcb515437e822a4e046c9947cb fd9e5c0c9164444db293aa8f8baee2e1--ad2d53fcb515437e822a4e046c9947cb 677ba75c429f431a815ff38943d3687f X ad2d53fcb515437e822a4e046c9947cb--677ba75c429f431a815ff38943d3687f a70487eae03249d89fc6045922ef0ed4 677ba75c429f431a815ff38943d3687f--a70487eae03249d89fc6045922ef0ed4 e14f5b501cb744419df82d26788a4f4c a70487eae03249d89fc6045922ef0ed4--e14f5b501cb744419df82d26788a4f4c 61eac1e3c2004f528a40d49af060de20 X e14f5b501cb744419df82d26788a4f4c--61eac1e3c2004f528a40d49af060de20 862d506686504823959003696c603fc6 H 61eac1e3c2004f528a40d49af060de20--862d506686504823959003696c603fc6 862d506686504823959003696c603fc6--a2f6bbd25af84a99bf87160c143d36ab"},{"location":"digital_analog_qc/daqc-qft/#references","title":"References","text":"<ol> <li> <p>Parra-Rodriguez et al., Digital-Analog Quantum Computation. PRA 101, 022305 (2020). \u21a9</p> </li> <li> <p>Martin, Ana, et al. Digital-analog quantum algorithm for the quantum Fourier transform. Phys. Rev. Research 2.1, 013012 (2020). \u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"digital_analog_qc/pulser-basic/","title":"Pulse-level Programming with Pulser","text":"<p>Warning</p> <p>This tutorial needs to be fixed.</p> <p>Qadence offers a direct interface with Pulser<sup>1</sup>, an open-source pulse-level interface written in Python and specifically designed for programming neutral atom quantum computers.</p> <p>Using directly Pulser requires deep knowledge on pulse-level programming and on how neutral atom devices work. Qadence abstracts out this complexity by using the familiar block-based interface for building pulse sequences in Pulser while leaving the possibility to directly manipulate them if required.</p> <p>Note</p> <p>The Pulser backend is still experimental and the interface might change in the future.</p> <p>Let's see it in action.</p>"},{"location":"digital_analog_qc/pulser-basic/#default-qubit-interaction","title":"Default qubit interaction","text":"<p>When simulating pulse sequences written using Pulser, the underlying Hamiltonian it constructs is equivalent to a digital-analog quantum computing program with the following interaction Hamiltonian (see digital-analog emulation for more details):</p> \\[ \\mathcal{H}_{int} = \\sum_{i&lt;j} \\frac{C_6}{|R_i - R_j|^6} \\hat{n}_i \\hat{n}_j \\] <p>where \\(C_6\\) is an interaction coefficient which depends on the principal quantum number of the neutral atom system, \\(R_i\\) are the atomic position in Cartesian coordinates and \\(\\hat{n} = \\frac{1-\\sigma^z_i}{2}\\) is the number operator.</p> <p>Notice that this interaction is always-on for any computation performed with the Pulser backend and cannot be switched off.</p>"},{"location":"digital_analog_qc/pulser-basic/#pulse-sequences-with-qadence","title":"Pulse sequences with Qadence","text":"<p>Currently, the backend supports the following operations:</p> gate description trainable parameter <code>RX</code>, <code>RY</code> Single qubit rotations. Notice that the interaction is on and this affects the resulting gate fidelity. rotation angle <code>AnalogRX</code>, <code>AnalogRY</code>, <code>AnalogRZ</code> Span a single qubit rotation among the entire register. rotation angle <code>entangle</code> Fully entangle the register. interaction time <code>wait</code> An idle block to wait for the system to evolve for a specific time according to the interaction. free evolution time"},{"location":"digital_analog_qc/pulser-basic/#two-qubits-register-bell-state","title":"Two qubits register: Bell state","text":"<p>Using the <code>chain</code> block makes it easy to create a gate sequence. Here is an example of how to create a Bell state. The <code>entangle</code> operation uses <code>CZ</code> interactions (according to the interaction Hamiltonian introduced in the first paragraph of this section) to entangle states on the <code>X</code> basis. We move the qubits back to the <code>Z</code> basis for the readout using a <code>Y</code> rotation.</p> <pre><code>from qadence import chain, entangle, RY\nbell_state = chain(\nentangle(\"t\", qubit_support=(0,1)),\nRY(0, \"y\"),\n)\n</code></pre> <p>To convert the chain block into a pulse sequence, we define a <code>Register</code> with two qubits and combine it to create a circuit as usual. Then we construct a <code>QuantumModel</code> with a Pulser backend to convert it into a proper parametrized pulse sequence. Supplying the parameter values allows to sample from the pulse sequence result.</p> <pre><code>import torch\nimport matplotlib.pyplot as plt\nfrom qadence import Register, QuantumCircuit, QuantumModel\nregister = Register(2)\ncircuit = QuantumCircuit(register, bell_state)\nmodel = QuantumModel(circuit, backend=\"pulser\", diff_mode=\"gpsr\")\nparams = {\n\"t\": torch.tensor([383]),  # ns\n\"y\": torch.tensor([3*torch.pi/2]),\n}\n# return the final state vector\nfinal_vector = model.run(params)\nprint(final_vector)\n# sample from the result state vector and plot the distribution\nsample = model.sample(params, n_shots=50)[0]\nprint(sample)\nfig, ax = plt.subplots()\nax.bar(sample.keys(), sample.values())\n</code></pre>   tensor([[-0.7080-0.0207j,  0.0395+0.3061j,  0.0039-0.0540j,  0.6220-0.1151j]]) Counter({'00': 27, '11': 18, '01': 5})  2023-10-10T21:36:26.197767 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ <p>One can visualise the pulse sequence with different parameters using the <code>assign_paramters</code> method.</p> <pre><code>model.assign_parameters(params).draw(show=False)\n</code></pre> 2023-10-10T21:36:26.312585 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"digital_analog_qc/pulser-basic/#change-device-specifications","title":"Change device specifications","text":"<p>At variance with other backends, the Pulser one provides the concept of <code>Device</code>, borrowed from the <code>pulser</code> library.</p> <p>A <code>Device</code> instance encapsulate all the properties defining a real neutral atoms processor, including but not limited to the maximum laser amplitude for the pulses, the maximum distance between two qubits and the maximum duration of the pulse.</p> <p>Warning</p> <p>Fix link below.</p> <p>Qadence offers a simplified interface with only two devices which can be found here</p> <ul> <li><code>IDEALIZED</code> (default): ideal device which should be used only for testing purposes. It does not have any limitation in what can be run with it.</li> <li><code>REALISTIC</code>: device specification very similar to a real neutral atom quantum processor.</li> </ul> <p>Note</p> <p>If you want to perform simulations closer to the specifications of real neutral atom machines, always choose the <code>REALISTIC</code> device.</p> <p>One can use the <code>Configuration</code> of the Pulser backend to select the appropriate device:</p> <pre><code>from qadence.backends.pulser.devices import Device\nregister = Register(2)\ncircuit = QuantumCircuit(register, bell_state)\n# choose a realistic device\nmodel = QuantumModel(\ncircuit,\nbackend=\"pulser\",\ndiff_mode=\"gpsr\",\nconfiguration={\"device_type\": Device.REALISTIC}\n)\n# FIXME: Specified device is not supported.\n# # alternatively directly one of the devices available in Pulser\n# # can also be supplied in the same way\n# from pulser.devices import AnalogDevice\n# model = QuantumModel(\n#     circuit,\n#     backend=\"pulser\",\n#     diff_mode=\"gpsr\",\n#     configuration={\"device_type\": AnalogDevice}\n# )\n</code></pre>"},{"location":"digital_analog_qc/pulser-basic/#create-your-own-gate","title":"Create your own gate","text":"<p>A big advantage of using the block-based interface if <code>qadence</code> is that it makes it easy to create complex operations from simple ones as a block composition. Take the entanglement operation as an example.</p> <p>The operation consists of moving all the qubits to the <code>X</code> basis having the atoms' interaction perform a controlled-Z operation during the free evolution. And we can easily recreate this pattern using the <code>wait</code> (corresponding to free evolution) and <code>AnalogRY</code> blocks with appropriate parameters.</p> <pre><code>from qadence.operations import I, X, Y, Z, kron\nzz = kron(I(0), Z(1), I(2), Z(3))\nxy = kron(I(0), X(1), I(2), Y(3))\nyx = kron(I(0), Y(1), I(2), X(3))\nobs = [zz, xy + yx]\n</code></pre> <p>Now we define the <code>QuantumModel</code> and pass the observable list to it together with the constructed circuit.</p> <pre><code># FIXME: protocol not defined\n# from qadence import RX, AnalogRot\n# register = Register(2)\n# circuit = QuantumCircuit(register, protocol)\n# model = QuantumModel(circuit, backend=\"pulser\", diff_mode='gpsr')\n# params = {\n#     \"t\": torch.tensor([383]),  # ns\n#     \"y\": torch.tensor([torch.pi / 2]),\n# }\n# sample = model.sample(params, n_shots=50)[0]\n# fig, ax = plt.subplots()\n# plt.bar(sample.keys(), sample.values())\n</code></pre> <p>One can also easily access and manipulate the underlying pulse sequence.</p> <pre><code># model.assign_parameters(params).draw(draw_phase_area=True, show=False)\n</code></pre>"},{"location":"digital_analog_qc/pulser-basic/#large-qubits-registers","title":"Large qubits registers","text":"<p>The constructor <code>Register(n_qubits)</code> generates a linear register that works fine with two or three qubits. But for the blocks we have so far, large registers work better with a square loop layout like the following.</p> <pre><code># register = Register.square(qubits_side=4)\n# register.draw(show=False)\n</code></pre> <p>In those cases, global pulses are preferred to generate entanglement to avoid changing the addressing pattern on the fly.</p> <pre><code># from qadence import AnalogRY\n# protocol = chain(\n#     entangle(\"t\"),\n#     AnalogRY(torch.pi / 2),\n# )\n# register = Register.square(qubits_side=2)\n# circuit = QuantumCircuit(register, protocol)\n# model = QuantumModel(circuit, backend=\"pulser\", diff_mode=\"gpsr\")\n# # add modulation to the pulse sequence by modifying the\n# # backend configuration\n# model.backend.backend.config.with_modulation = True\n# params = {\n#     \"x\": torch.tensor([3*torch.pi/2]),  # ns\n# }\n# sample = model.sample(params, n_shots=500)[0]\n# fig, ax = plt.subplots()\n# ax.bar(sample.keys(), sample.values())\n# plt.xticks(rotation='vertical')\n</code></pre> <p>Again, let's plot the corresponding pulse sequence.</p> <pre><code># model.assign_parameters(params).draw(draw_phase_area=True, show=False)\n</code></pre> <p>Note</p> <p>The gates shown here don't work with arbitrary registers since they rely on the registered geometry to work properly.</p>"},{"location":"digital_analog_qc/pulser-basic/#digital-analog-qnn-circuit","title":"Digital-analog QNN circuit","text":"<p>Finally, let's put all together by constructing a digital-analog version of a quantum neural network circuit with feature map and variational ansatz.</p> <pre><code># from qadence import kron, fourier_feature_map\n# from qadence.operations import RX, RY, AnalogRX\n# hea_one_layer = chain(\n#     kron(RY(0, \"th00\"), RY(1, \"th01\")),\n#     kron(RX(0, \"th10\"), RX(1, \"th11\")),\n#     kron(RY(0, \"th20\"), RY(1, \"th21\")),\n#     entangle(\"t\", qubit_support=(0,1)),\n# )\n# protocol = chain(\n#     fourier_feature_map(1, param=\"x\"),\n#     hea_one_layer,\n#     AnalogRX(torch.pi/4)\n# )\n# register = Register(2)\n# circuit = QuantumCircuit(register, protocol)\n# model = QuantumModel(circuit, backend=\"pulser\", diff_mode=\"gpsr\")\n# params = {\n#     \"x\": torch.tensor([0.8]), # rad\n#     \"t\": torch.tensor([900]), # ns\n#     \"th00\":  torch.rand(1), # rad\n#     \"th01\":  torch.rand(1), # rad\n#     \"th10\":  torch.rand(1), # rad\n#     \"th11\":  torch.rand(1), # rad\n#     \"th20\":  torch.rand(1), # rad\n#     \"th21\":  torch.rand(1), # rad\n# }\n# model.assign_parameters(params).draw(draw_phase_area=True, show=True)\n</code></pre>"},{"location":"digital_analog_qc/pulser-basic/#references","title":"References","text":"<ol> <li> <p>Pulser: An open-source package for the design of pulse sequences in programmable neutral-atom arrays \u21a9</p> </li> </ol>"},{"location":"qadence/blocks/","title":"Block system","text":"<p><code>qadence</code> offers a block-based system to construct quantum circuits in a flexible manner.</p>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock","title":"<code>AbstractBlock</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Base class for both primitive and composite blocks</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>A human-readable name attached to the block type. Notice, this is the same for all the class instances so it cannot be used for identifying different blocks</p> <p> TYPE: <code>str</code> </p> <code>qubit_support</code> <p>The qubit support of the block expressed as a tuple of integers</p> <p> TYPE: <code>tuple[int, ...]</code> </p> <code>tag</code> <p>A tag identifying a particular instance of the block which can be used for identification and pretty printing</p> <p> TYPE: <code>str | None</code> </p> <code>eigenvalues</code> <p>The eigenvalues of the matrix representing the block. This is used mainly for primitive blocks and it's needed for generalized parameter shift rule computations. Currently unused.</p> <p> TYPE: <code>list[float] | None</code> </p>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock.is_identity","title":"<code>is_identity: bool</code>  <code>property</code>","text":"<p>Identity predicate for blocks.</p>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock.n_qubits","title":"<code>n_qubits()</code>","text":"<p>The number of qubits in the whole system. A block acting on qubit N would has at least n_qubits &gt;= N + 1.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef n_qubits(self) -&gt; int:\n\"\"\"The number of qubits in the whole system.\n    A block acting on qubit N would has at least n_qubits &gt;= N + 1.\"\"\"\npass\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock.n_supports","title":"<code>n_supports()</code>","text":"<p>The number of qubits the block is acting on.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef n_supports(self) -&gt; int:\n\"\"\"The number of qubits the block is acting on.\"\"\"\npass\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock.qubit_support","title":"<code>qubit_support()</code>","text":"<p>The indices of the qubit(s) the block is acting on. Qadence uses the ordering [0..,N-1] for qubits.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef qubit_support(self) -&gt; Tuple[int, ...]:\n\"\"\"The indices of the qubit(s) the block is acting on.\n    Qadence uses the ordering [0..,N-1] for qubits.\"\"\"\npass\n</code></pre>"},{"location":"qadence/blocks/#primitive-blocks","title":"Primitive blocks","text":""},{"location":"qadence/blocks/#qadence.blocks.primitive.ControlBlock","title":"<code>ControlBlock(control, target_block)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The abstract ControlBlock</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, control: tuple[int, ...], target_block: PrimitiveBlock) -&gt; None:\nself.blocks = (target_block,)\n# using tuple expansion because some control operations could\n# have multiple targets, e.g. CSWAP\nsuper().__init__((*control, *target_block.qubit_support))  # target_block.qubit_support[0]))\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.ParametricBlock","title":"<code>ParametricBlock(qubit_support)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>Parameterized primitive blocks</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, qubit_support: tuple[int, ...]):\nself._qubit_support = qubit_support\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.ParametricBlock.num_parameters","title":"<code>num_parameters()</code>  <code>abstractmethod</code>","text":"<p>The number of parameters required by the block</p> <p>This is a class property since the number of parameters is defined automatically before instantiating the operation. Also, this could correspond to a larger number of actual user-facing parameters since any parameter expression is allowed</p> <p>Examples: - RX operation has 1 parameter - U operation has 3 parameters - HamEvo has 2 parameters (generator and time evolution)</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>@abstractmethod\ndef num_parameters(cls) -&gt; int:\n\"\"\"The number of parameters required by the block\n    This is a class property since the number of parameters is defined\n    automatically before instantiating the operation. Also, this could\n    correspond to a larger number of actual user-facing parameters\n    since any parameter expression is allowed\n    Examples:\n    - RX operation has 1 parameter\n    - U operation has 3 parameters\n    - HamEvo has 2 parameters (generator and time evolution)\n    \"\"\"\npass\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.ParametricControlBlock","title":"<code>ParametricControlBlock(control, target_block)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The abstract parametrized ControlBlock</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, control: tuple[int, ...], target_block: ParametricBlock) -&gt; None:\nself.blocks = (target_block,)\nself.parameters = target_block.parameters\nsuper().__init__((*control, target_block.qubit_support[0]))\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.PrimitiveBlock","title":"<code>PrimitiveBlock(qubit_support)</code>","text":"<p>             Bases: <code>AbstractBlock</code></p> <p>Primitive blocks represent elementary unitary operations such as single/multi-qubit gates or Hamiltonian evolution. See <code>qadence.operations</code> for a full list of primitive blocks.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, qubit_support: tuple[int, ...]):\nself._qubit_support = qubit_support\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.PrimitiveBlock.digital_decomposition","title":"<code>digital_decomposition()</code>","text":"<p>Decomposition into purely digital gates</p> <p>This method returns a decomposition of the Block in a combination of purely digital single-qubit and two-qubit 'gates', by manual/custom knowledge of how this can be done efficiently. :return:</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def digital_decomposition(self) -&gt; AbstractBlock:\n\"\"\"Decomposition into purely digital gates\n    This method returns a decomposition of the Block in a\n    combination of purely digital single-qubit and two-qubit\n    'gates', by manual/custom knowledge of how this can be done efficiently.\n    :return:\n    \"\"\"\nreturn self\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.ScaleBlock","title":"<code>ScaleBlock(block, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>Scale blocks are created when multiplying a block by a number or parameter.</p> <p>Example: <pre><code>from qadence import X\nprint(X(0) * 2)\n</code></pre> <pre><code>[mul: 2] \u2514\u2500\u2500 X(0)\n</code></pre> </p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, block: AbstractBlock, parameter: Any):\nself.block = block\n# TODO: more meaningful name like `scale`?\nself.parameters = (\nparameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n)\nsuper().__init__(block.qubit_support)\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.TimeEvolutionBlock","title":"<code>TimeEvolutionBlock(qubit_support)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>Simple time evolution block with time-independent Hamiltonian</p> <p>This class is just a convenience class which is used to label blocks which contains simple time evolution with time-independent Hamiltonian operators</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, qubit_support: tuple[int, ...]):\nself._qubit_support = qubit_support\n</code></pre>"},{"location":"qadence/blocks/#analog-blocks","title":"Analog blocks","text":"<p>To learn how to use analog blocks and how to mix digital &amp; analog blocks, check out the digital-analog section of the documentation.</p> <p>Examples on how to use digital-analog blocks can be found in the *examples folder of the qadence repo:</p> <ul> <li>Fit a simple sinus: <code>examples/digital-analog/fit-sin.py</code></li> <li>Solve a QUBO: <code>examples/digital-analog/qubo.py</code></li> </ul>"},{"location":"qadence/blocks/#qadence.blocks.analog.AnalogChain","title":"<code>AnalogChain(blocks)</code>  <code>dataclass</code>","text":"<p>             Bases: <code>AnalogComposite</code></p> <p>A chain of analog blocks. Needed because analog blocks require stricter validation than the general <code>ChainBlock</code>.</p> <p><code>AnalogChain</code>s can only be constructed from <code>AnalogKron</code> blocks or globally supported, primitive, analog blocks (like <code>WaitBlock</code>s and <code>ConstantAnalogRotation</code>s).</p> <p>Automatically constructed by the <code>chain</code> function if only analog blocks are given.</p> <p>Example: <pre><code>from qadence import X, chain, wait\nb = chain(wait(200), wait(200))\nprint(type(b))  # this is an `AnalogChain`\nb = chain(X(0), wait(200))\nprint(type(b))  # this is a general `ChainBlock`\n</code></pre> <pre><code>&lt;class 'qadence.blocks.analog.AnalogChain'&gt;\n&lt;class 'qadence.blocks.composite.ChainBlock'&gt;\n</code></pre> </p> Source code in <code>qadence/blocks/analog.py</code> <pre><code>def __init__(self, blocks: Tuple[AnalogBlock, ...]):\n\"\"\"A chain of analog blocks. Needed because analog blocks require\n    stricter validation than the general `ChainBlock`.\n    `AnalogChain`s can only be constructed from `AnalogKron` blocks or\n    _**globally supported**_, primitive, analog blocks (like `WaitBlock`s and\n    `ConstantAnalogRotation`s).\n    Automatically constructed by the [`chain`][qadence.blocks.utils.chain]\n    function if only analog blocks are given.\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, chain, wait\n    b = chain(wait(200), wait(200))\n    print(type(b))  # this is an `AnalogChain`\n    b = chain(X(0), wait(200))\n    print(type(b))  # this is a general `ChainBlock`\n    ```\n    \"\"\"\nfor b in blocks:\nif not (isinstance(b, AnalogKron) or b.qubit_support.is_global):\nraise ValueError(\"Only KronBlocks or global blocks can be chain'ed.\")\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.analog.AnalogKron","title":"<code>AnalogKron(blocks, interaction=Interaction.NN)</code>  <code>dataclass</code>","text":"<p>             Bases: <code>AnalogComposite</code></p> <p>Stack analog blocks vertically (i.e. in time). Needed because analog require stricter validation than the general <code>KronBlock</code>.</p> <p><code>AnalogKron</code>s can only be constructed from non-global, analog blocks with the same duration.</p> Source code in <code>qadence/blocks/analog.py</code> <pre><code>def __init__(self, blocks: Tuple[AnalogBlock, ...], interaction: Interaction = Interaction.NN):\n\"\"\"Stack analog blocks vertically (i.e. in time). Needed because analog require\n    stricter validation than the general `KronBlock`.\n    `AnalogKron`s can only be constructed from _**non-global**_, analog blocks\n    with the _**same duration**_.\n    \"\"\"\nif len(blocks) == 0:\nraise NotImplementedError(\"Empty KronBlocks not supported\")\nself.blocks = blocks\nself.interaction = interaction\nqubit_support = QubitSupport()\nduration = blocks[0].duration\nfor b in blocks:\nif not isinstance(b, AnalogBlock):\nraise ValueError(\"Can only kron `AnalgoBlock`s with other `AnalgoBlock`s.\")\nif b.qubit_support == QubitSupport(\"global\"):\nraise ValueError(\"Blocks with global support cannot be kron'ed.\")\nif not qubit_support.is_disjoint(b.qubit_support):\nraise ValueError(\"Make sure blocks act on distinct qubits!\")\nif not np.isclose(evaluate(duration), evaluate(b.duration)):\nraise ValueError(\"Kron'ed blocks have to have same duration.\")\nqubit_support += b.qubit_support\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.analog.ConstantAnalogRotation","title":"<code>ConstantAnalogRotation</code>  <code>dataclass</code>","text":"<p>             Bases: <code>AnalogBlock</code></p> <p>Implements a constant analog rotation with interaction dictated by the chosen Hamiltonian</p> <pre><code>H = \u2211\u1d62(h\u03a9/2 sin(\u03c6)*X\u1d62 - cos(\u03c6)*Y\u1d62 - h\u03b4n\u1d62) + H\u1d62\u2099\u209c.\n</code></pre> <p>To construct this block you can use of the following convenience wrappers: - The general rotation operation <code>AnalogRot</code> - Shorthands for rotatins around an axis:   <code>AnalogRX</code>,   <code>AnalogRY</code>,   <code>AnalogRZ</code></p> <p>Can be used with <code>add_interaction</code>. WARNING: do not use <code>ConstantAnalogRotation</code> with <code>alpha</code> as differentiable parameter - use the convenience wrappers mentioned above.</p>"},{"location":"qadence/blocks/#qadence.blocks.analog.WaitBlock","title":"<code>WaitBlock</code>  <code>dataclass</code>","text":"<p>             Bases: <code>AnalogBlock</code></p> <p>Waits. In real interacting quantum devices, it means letting the system evolve freely according to the time-dependent Schrodinger equation. With emulators, this block is translated to an appropriate interaction Hamiltonian, for example, an Ising interation</p> <pre><code>H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2086/r\u1d62\u2c7c\u2076 n\u1d62n\u2c7c\n</code></pre> <p>or an XY-interaction</p> <pre><code>H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2083/r\u2c7c\u2c7c\u00b3 (X\u1d62X\u2c7c + Z\u1d62Z\u2c7c)\n</code></pre> <p>with <code>n\u1d62 = (1-Z\u1d62)/2</code>.</p> <p>To construct this block, use the <code>wait</code> function.</p> <p>Can be used with <code>add_interaction</code>.</p>"},{"location":"qadence/blocks/#composite-blocks","title":"Composite blocks","text":""},{"location":"qadence/blocks/#qadence.blocks.utils.chain","title":"<code>chain(*args)</code>","text":"<p>Chain blocks sequentially. On digital backends this can be interpreted loosely as a matrix mutliplication of blocks. In the analog case it chains blocks in time.</p> PARAMETER  DESCRIPTION <code>*args</code> <p>Blocks to chain. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator, List[AbstractBlock]]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>ChainBlock</p> <p>Example: <pre><code>from qadence import X, Y, chain\nb = chain(X(0), Y(0))\n# or use a generator\nb = chain(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>ChainBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def chain(*args: Union[AbstractBlock, Generator, List[AbstractBlock]]) -&gt; ChainBlock:\n\"\"\"Chain blocks sequentially. On digital backends this can be interpreted\n    loosely as a matrix mutliplication of blocks. In the analog case it chains\n    blocks in time.\n    Arguments:\n        *args: Blocks to chain. Can also be a generator.\n    Returns:\n        ChainBlock\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, chain\n    b = chain(X(0), Y(0))\n    # or use a generator\n    b = chain(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n# ugly hack to use `AnalogChain` if we are dealing only with analog blocks\nif len(args) and all(\nisinstance(a, AnalogBlock) or isinstance(a, AnalogComposite) for a in args\n):\nreturn analog_chain(*args)  # type: ignore[return-value,arg-type]\nreturn _construct(ChainBlock, args)\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.utils.kron","title":"<code>kron(*args)</code>","text":"<p>Stack blocks vertically. On digital backends this can be intepreted loosely as a kronecker product of blocks. In the analog case it executes blocks parallel in time.</p> PARAMETER  DESCRIPTION <code>*args</code> <p>Blocks to kron. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>KronBlock</p> <p>Example: <pre><code>from qadence import X, Y, kron\nb = kron(X(0), Y(1))\n# or use a generator\nb = kron(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def kron(*args: Union[AbstractBlock, Generator]) -&gt; KronBlock:\n\"\"\"Stack blocks vertically. On digital backends this can be intepreted\n    loosely as a kronecker product of blocks. In the analog case it executes\n    blocks parallel in time.\n    Arguments:\n        *args: Blocks to kron. Can also be a generator.\n    Returns:\n        KronBlock\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, kron\n    b = kron(X(0), Y(1))\n    # or use a generator\n    b = kron(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n# ugly hack to use `AnalogKron` if we are dealing only with analog blocks\nif len(args) and all(\nisinstance(a, AnalogBlock) or isinstance(a, AnalogComposite) for a in args\n):\nreturn analog_kron(*args)  # type: ignore[return-value,arg-type]\nreturn _construct(KronBlock, args)\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.utils.add","title":"<code>add(*args)</code>","text":"<p>Sums blocks.</p> PARAMETER  DESCRIPTION <code>*args</code> <p>Blocks to add. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>AddBlock</code> <p>AddBlock</p> <p>Example: <pre><code>from qadence import X, Y, add\nb = add(X(0), Y(0))\n# or use a generator\nb = add(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def add(*args: Union[AbstractBlock, Generator]) -&gt; AddBlock:\n\"\"\"Sums blocks.\n    Arguments:\n        *args: Blocks to add. Can also be a generator.\n    Returns:\n        AddBlock\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, add\n    b = add(X(0), Y(0))\n    # or use a generator\n    b = add(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\nreturn _construct(AddBlock, args)\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.composite.AddBlock","title":"<code>AddBlock(blocks)</code>","text":"<p>             Bases: <code>CompositeBlock</code></p> <p>Adds blocks. Constructed via <code>add</code>.</p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.composite.ChainBlock","title":"<code>ChainBlock(blocks)</code>","text":"<p>             Bases: <code>CompositeBlock</code></p> <p>Chains blocks sequentially. Constructed via <code>chain</code></p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.composite.CompositeBlock","title":"<code>CompositeBlock</code>","text":"<p>             Bases: <code>AbstractBlock</code></p> <p>Block which composes multiple blocks into one larger block (which can again be composed). Composite blocks are constructed via <code>chain</code>, <code>kron</code>, and <code>add</code>.</p>"},{"location":"qadence/blocks/#qadence.blocks.composite.KronBlock","title":"<code>KronBlock(blocks)</code>","text":"<p>             Bases: <code>CompositeBlock</code></p> <p>Stacks blocks horizontally. Constructed via <code>kron</code>.</p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\nif len(blocks) == 0:\nraise NotImplementedError(\"Empty KronBlocks not supported\")\nqubit_support = QubitSupport()\nfor b in blocks:\nassert (\nQubitSupportType.GLOBAL,\n) != b.qubit_support, \"Blocks with global support cannot be kron'ed.\"\nassert qubit_support.is_disjoint(\nb.qubit_support\n), \"Make sure blocks act on distinct qubits!\"\nqubit_support += b.qubit_support\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#converting-blocks-to-matrices","title":"Converting blocks to matrices","text":""},{"location":"qadence/blocks/#qadence.blocks.block_to_tensor.block_to_tensor","title":"<code>block_to_tensor(block, values={}, qubit_support=None, use_full_support=True, tensor_type=TensorType.DENSE, endianness=Endianness.BIG)</code>","text":"<p>Convert a block into a torch tensor.</p> PARAMETER  DESCRIPTION <code>block</code> <p>The block to convert.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>values</code> <p>A optional dict with values for parameters.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>qubit_support</code> <p>The qubit_support of the block.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>use_full_support</code> <p>True infers the total number of qubits.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>tensor_type</code> <p>the target tensor type.</p> <p> TYPE: <code>TensorType</code> DEFAULT: <code>DENSE</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence import hea, hamiltonian_factory, Z, block_to_tensor\nblock = hea(2,2)\nprint(block_to_tensor(block))\n# In case you have a diagonal observable, you can use\nobs = hamiltonian_factory(2, detuning = Z)\nprint(block_to_tensor(obs, tensor_type=\"SparseDiagonal\"))\n</code></pre> <pre><code>tensor([[[ 0.2007+0.0805j, -0.5658-0.5491j, -0.2342+0.0500j, -0.4570+0.2556j],\n[ 0.3659-0.2959j,  0.1552+0.2681j, -0.7016-0.4269j, -0.0898+0.0058j],\n[-0.3565-0.6061j, -0.4251-0.0858j,  0.0676-0.2161j,  0.0196-0.5156j],\n[-0.4868-0.0187j,  0.0594-0.3011j, -0.1193-0.4503j,  0.3894+0.5476j]]],\ngrad_fn=&lt;UnsafeViewBackward0&gt;)\ntensor(indices=tensor([[0, 3],\n[0, 3]]),\nvalues=tensor([ 2.+0.j, -2.+0.j]),\nsize=(4, 4), nnz=2, layout=torch.sparse_coo)\n</code></pre> </p> Source code in <code>qadence/blocks/block_to_tensor.py</code> <pre><code>def block_to_tensor(\nblock: AbstractBlock,\nvalues: dict[str, TNumber | torch.Tensor] = {},\nqubit_support: tuple | None = None,\nuse_full_support: bool = True,\ntensor_type: TensorType = TensorType.DENSE,\nendianness: Endianness = Endianness.BIG,\n) -&gt; torch.Tensor:\n\"\"\"\n    Convert a block into a torch tensor.\n    Arguments:\n        block (AbstractBlock): The block to convert.\n        values (dict): A optional dict with values for parameters.\n        qubit_support (tuple): The qubit_support of the block.\n        use_full_support (bool): True infers the total number of qubits.\n        tensor_type (TensorType): the target tensor type.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import hea, hamiltonian_factory, Z, block_to_tensor\n    block = hea(2,2)\n    print(block_to_tensor(block))\n    # In case you have a diagonal observable, you can use\n    obs = hamiltonian_factory(2, detuning = Z)\n    print(block_to_tensor(obs, tensor_type=\"SparseDiagonal\"))\n    ```\n    \"\"\"\n# FIXME: default use_full_support to False. In general, it would\n# be more efficient to do that, and make sure that computations such\n# as observables only do the matmul of the size of the qubit support.\nif tensor_type == TensorType.DENSE:\nfrom qadence.blocks import embedding\n(ps, embed) = embedding(block)\nreturn _block_to_tensor_embedded(\nblock, embed(ps, values), qubit_support, use_full_support, endianness=endianness\n)\nelif tensor_type == TensorType.SPARSEDIAGONAL:\nt = block_to_diagonal(block, endianness=endianness)\nindices, values, size = torch.nonzero(t), t[t != 0], len(t)\nindices = torch.stack((indices.flatten(), indices.flatten()))\nreturn torch.sparse_coo_tensor(indices, values, (size, size))\n</code></pre>"},{"location":"qadence/constructors/","title":"Constructors for common quantum circuits","text":""},{"location":"qadence/constructors/#qadence.constructors.feature_maps.chebyshev_feature_map","title":"<code>chebyshev_feature_map(n_qubits, support=None, param='phi', op=RX)</code>","text":"<p>Construct a Chebyshev feature map</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits across which the FM is created</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>The qubit support</p> <p> TYPE: <code>Iterable[int]</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>The base name for the feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'phi'</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def chebyshev_feature_map(\nn_qubits: int, support: tuple[int, ...] = None, param: str = \"phi\", op: Type[Rotation] = RX\n) -&gt; AbstractBlock:\n\"\"\"Construct a Chebyshev feature map\n    Args:\n        n_qubits: number of qubits across which the FM is created\n        support (Iterable[int]): The qubit support\n        param: The base name for the feature `Parameter`\n    \"\"\"\nfm = feature_map(n_qubits, support=support, param=param, op=op, fm_type=\"chebyshev\")\nreturn tag(fm, tag=\"ChebyshevFM\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.feature_maps.exp_fourier_feature_map","title":"<code>exp_fourier_feature_map(n_qubits, support=None, param='x', feature_range=None)</code>","text":"<p>Exponential fourier feature map.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the feature</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>qubit support</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>name of feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'x'</code> </p> <code>feature_range</code> <p>min and max value of the feature, as floats in a Tuple</p> <p> TYPE: <code>tuple[float, float]</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def exp_fourier_feature_map(\nn_qubits: int,\nsupport: tuple[int, ...] = None,\nparam: str = \"x\",\nfeature_range: tuple[float, float] = None,\n) -&gt; AbstractBlock:\n\"\"\"\n    Exponential fourier feature map.\n    Args:\n        n_qubits: number of qubits in the feature\n        support: qubit support\n        param: name of feature `Parameter`\n        feature_range: min and max value of the feature, as floats in a Tuple\n    \"\"\"\nif feature_range is None:\nfeature_range = (0.0, 2.0**n_qubits)\nif support is None:\nsupport = tuple(range(n_qubits))\nxmax = max(feature_range)\nxmin = min(feature_range)\nx = Parameter(param, trainable=False)\n# The feature map works on the range of 0 to 2**n\nx_rescaled = 2 * np.pi * (x - xmin) / (xmax - xmin)\nhlayer = kron(H(qubit) for qubit in support)\nrlayer = kron(RZ(support[i], x_rescaled * (2**i)) for i in range(n_qubits))\nreturn tag(chain(hlayer, rlayer), f\"ExpFourierFM({param})\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.feature_maps.feature_map","title":"<code>feature_map(n_qubits, support=None, param='phi', op=RX, fm_type='fourier')</code>","text":"<p>Construct a feature map of a given type.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>Number of qubits the feature map covers. Results in <code>support=range(n_qubits)</code>.</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>Overrides <code>n_qubits</code>. Puts one rotation gate on every qubit in <code>support</code>.</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>Parameter of the feature map.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'phi'</code> </p> <code>op</code> <p>Rotation operation of the feature map.</p> <p> TYPE: <code>Type[Rotation]</code> DEFAULT: <code>RX</code> </p> <code>fm_type</code> <p>Determines the additional expression the final feature parameter (the addtional term in front of <code>param</code>). <code>\"fourier\": param</code> (nothing is done to <code>param</code>) <code>\"chebyshev\": 2*acos(param)</code>, <code>\"tower\": (i+1)*2*acos(param)</code> (where <code>i</code> is the qubit index).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'fourier'</code> </p> <p>Example: <pre><code>from qadence import feature_map\nfm = feature_map(3, fm_type=\"fourier\")\nprint(f\"{fm = }\")\nfm = feature_map(3, fm_type=\"chebyshev\")\nprint(f\"{fm = }\")\nfm = feature_map(3, fm_type=\"tower\")\nprint(f\"{fm = }\")\n</code></pre> <pre><code>fm = KronBlock(0,1,2) [tag: FM]\n\u251c\u2500\u2500 RX(0) [params: ['phi']]\n\u251c\u2500\u2500 RX(1) [params: ['phi']]\n\u2514\u2500\u2500 RX(2) [params: ['phi']]\nfm = KronBlock(0,1,2) [tag: FM]\n\u251c\u2500\u2500 RX(0) [params: ['2*acos(phi)']]\n\u251c\u2500\u2500 RX(1) [params: ['2*acos(phi)']]\n\u2514\u2500\u2500 RX(2) [params: ['2*acos(phi)']]\nfm = KronBlock(0,1,2) [tag: FM]\n\u251c\u2500\u2500 RX(0) [params: ['2*acos(phi)']]\n\u251c\u2500\u2500 RX(1) [params: ['4*acos(phi)']]\n\u2514\u2500\u2500 RX(2) [params: ['6*acos(phi)']]\n</code></pre> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def feature_map(\nn_qubits: int,\nsupport: tuple[int, ...] = None,\nparam: str = \"phi\",\nop: Type[Rotation] = RX,\nfm_type: str = \"fourier\",\n) -&gt; KronBlock:\n\"\"\"Construct a feature map of a given type.\n    Arguments:\n        n_qubits: Number of qubits the feature map covers. Results in `support=range(n_qubits)`.\n        support: Overrides `n_qubits`. Puts one rotation gate on every qubit in `support`.\n        param: Parameter of the feature map.\n        op: Rotation operation of the feature map.\n        fm_type: Determines the additional expression the final feature parameter (the addtional\n            term in front of `param`). `\"fourier\": param` (nothing is done to `param`)\n            `\"chebyshev\": 2*acos(param)`, `\"tower\": (i+1)*2*acos(param)` (where `i` is the qubit\n            index).\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import feature_map\n    fm = feature_map(3, fm_type=\"fourier\")\n    print(f\"{fm = }\")\n    fm = feature_map(3, fm_type=\"chebyshev\")\n    print(f\"{fm = }\")\n    fm = feature_map(3, fm_type=\"tower\")\n    print(f\"{fm = }\")\n    ```\n    \"\"\"\nfparam = FeatureParameter(param)\nif support is None:\nsupport = tuple(range(n_qubits))\nassert len(support) &lt;= n_qubits, \"Wrong qubit support supplied\"\nif fm_type == \"fourier\":\nfm = kron(*[op(qubit, fparam) for qubit in support])\nelif fm_type == \"chebyshev\":\nfm = kron(*[op(qubit, 2 * sympy.acos(fparam)) for qubit in support])\nelif fm_type == \"tower\":\nfm = kron(*[op(qubit, (i + 1) * 2 * sympy.acos(fparam)) for i, qubit in enumerate(support)])\nelse:\nraise NotImplementedError(f\"Feature map {fm_type} not implemented\")\nfm.tag = \"FM\"\nreturn fm\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.feature_maps.fourier_feature_map","title":"<code>fourier_feature_map(n_qubits, support=None, param='phi', op=RX)</code>","text":"<p>Construct a Fourier feature map</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits across which the FM is created</p> <p> TYPE: <code>int</code> </p> <code>param</code> <p>The base name for the feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'phi'</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def fourier_feature_map(\nn_qubits: int, support: tuple[int, ...] = None, param: str = \"phi\", op: Type[Rotation] = RX\n) -&gt; AbstractBlock:\n\"\"\"Construct a Fourier feature map\n    Args:\n        n_qubits: number of qubits across which the FM is created\n        param: The base name for the feature `Parameter`\n    \"\"\"\nfm = feature_map(n_qubits, support=support, param=param, op=op, fm_type=\"fourier\")\nreturn tag(fm, tag=\"FourierFM\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.feature_maps.tower_feature_map","title":"<code>tower_feature_map(n_qubits, support=None, param='phi', op=RX)</code>","text":"<p>Construct a Chebyshev tower feature map</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits across which the FM is created</p> <p> TYPE: <code>int</code> </p> <code>param</code> <p>The base name for the feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'phi'</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def tower_feature_map(\nn_qubits: int, support: tuple[int, ...] = None, param: str = \"phi\", op: Type[Rotation] = RX\n) -&gt; AbstractBlock:\n\"\"\"Construct a Chebyshev tower feature map\n    Args:\n        n_qubits: number of qubits across which the FM is created\n        param: The base name for the feature `Parameter`\n    \"\"\"\nfm = feature_map(n_qubits, support=support, param=param, op=op, fm_type=\"tower\")\nreturn tag(fm, tag=\"TowerFM\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.ansatze.build_qnn","title":"<code>build_qnn(n_qubits, n_features, depth=None, ansatz=None, fm_pauli=RY, spectrum='simple', basis='fourier', fm_strategy='parallel')</code>","text":"<p>Helper function to build a qadence QNN quantum circuit</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>n_features</code> <p>The number of input dimensions.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>The depth of the ansatz.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>ansatz</code> <p>An optional argument to pass a custom qadence ansatz.</p> <p> TYPE: <code>Optional[AbstractBlock]</code> DEFAULT: <code>None</code> </p> <code>fm_pauli</code> <p>The type of Pauli gate for the feature map. Must be one of 'RX', 'RY', or 'RZ'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>RY</code> </p> <code>spectrum</code> <p>The desired spectrum of the feature map generator. The options simple, tower and exponential produce a spectrum with linear, quadratic and exponential eigenvalues with respect to the number of qubits.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'simple'</code> </p> <code>basis</code> <p>The encoding function. The options fourier and chebyshev correspond to \u03a6(x)=x and arcos(x) respectively.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'fourier'</code> </p> <code>fm_strategy</code> <p>The feature map encoding strategy. If \"parallel\", the features are encoded in one block of rotation gates, with each feature given an equal number of qubits. If \"serial\", the features are encoded sequentially, with a HEA block between.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'parallel'</code> </p> RETURNS DESCRIPTION <code>list[AbstractBlock]</code> <p>A list of Abstract blocks to be used for constructing a quantum circuit</p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def build_qnn(\nn_qubits: int,\nn_features: int,\ndepth: int = None,\nansatz: Optional[AbstractBlock] = None,\nfm_pauli: Type[RY] = RY,\nspectrum: str = \"simple\",\nbasis: str = \"fourier\",\nfm_strategy: str = \"parallel\",\n) -&gt; list[AbstractBlock]:\n\"\"\"Helper function to build a qadence QNN quantum circuit\n    Args:\n        n_qubits (int): The number of qubits.\n        n_features (int): The number of input dimensions.\n        depth (int): The depth of the ansatz.\n        ansatz (Optional[AbstractBlock]):  An optional argument to pass a custom qadence ansatz.\n        fm_pauli (str): The type of Pauli gate for the feature map. Must be one of 'RX',\n            'RY', or 'RZ'.\n        spectrum (str): The desired spectrum of the feature map generator. The options simple,\n            tower and exponential produce a spectrum with linear, quadratic and exponential\n            eigenvalues with respect to the number of qubits.\n        basis (str): The encoding function. The options fourier and chebyshev correspond to \u03a6(x)=x\n            and arcos(x) respectively.\n        fm_strategy (str): The feature map encoding strategy. If \"parallel\", the features\n            are encoded in one block of rotation gates, with each feature given\n            an equal number of qubits. If \"serial\", the features are encoded\n            sequentially, with a HEA block between.\n    Returns:\n        A list of Abstract blocks to be used for constructing a quantum circuit\n    \"\"\"\ndepth = n_qubits if depth is None else depth\nidx_fms = build_idx_fms(basis, fm_pauli, fm_strategy, n_features, n_qubits, spectrum)\nif fm_strategy == \"parallel\":\n_fm = kron(*idx_fms)\nfm = tag(_fm, tag=\"FM\")\nelif fm_strategy == \"serial\":\nfm_components: list[AbstractBlock] = []\nfor j, fm_idx in enumerate(idx_fms[:-1]):\nfm_idx = tag(fm_idx, tag=f\"FM{j}\")  # type: ignore[assignment]\nfm_component = (fm_idx, hea(n_qubits, 1, f\"theta_{j}\"))\nfm_components.extend(fm_component)\nfm_components.append(tag(idx_fms[-1], tag=f\"FM{len(idx_fms) - 1}\"))\nfm = chain(*fm_components)  # type: ignore[assignment]\nansatz = hea(n_qubits, depth=depth) if ansatz is None else ansatz\nreturn [fm, ansatz]\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.ansatze.hea","title":"<code>hea(n_qubits, depth=1, param_prefix='theta', support=None, strategy=Strategy.DIGITAL, **strategy_args)</code>","text":"<p>Factory function for the Hardware Efficient Ansatz (HEA).</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indexes where the HEA is applied</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>strategy</code> <p>Strategy.Digital or Strategy.DigitalAnalog</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>**strategy_args</code> <p>see below</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> PARAMETER DESCRIPTION <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer. Valid for Digital and DigitalAnalog HEA.</p> <p> TYPE: <code>list</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. periodic=False is not supported in emu-c. Valid for only for Digital HEA.</p> <p> TYPE: <code>bool</code> </p> <code>entangler</code> <ul> <li>Digital: 2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational parameters on the rotation angles.</li> <li>DigitaAnalog | Analog: Hamiltonian generator for the analog entangling layer. Defaults to global ZZ Hamiltonian. Time parameter is considered variational.</li> </ul> <p> TYPE: <code>AbstractBlock</code> </p> <p>Examples: <pre><code>from qadence import RZ, RX\nfrom qadence import hea\n# create the circuit\nn_qubits, depth = 2, 4\nansatz = hea(\nn_qubits=n_qubits,\ndepth=depth,\nstrategy=\"sDAQC\",\noperations=[RZ,RX,RZ]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def hea(\nn_qubits: int,\ndepth: int = 1,\nparam_prefix: str = \"theta\",\nsupport: tuple[int, ...] = None,\nstrategy: Strategy = Strategy.DIGITAL,\n**strategy_args: Any,\n) -&gt; AbstractBlock:\n\"\"\"\n    Factory function for the Hardware Efficient Ansatz (HEA).\n    Args:\n        n_qubits: number of qubits in the block\n        depth: number of layers of the HEA\n        param_prefix: the base name of the variational parameters\n        support: qubit indexes where the HEA is applied\n        strategy: Strategy.Digital or Strategy.DigitalAnalog\n        **strategy_args: see below\n    Keyword Arguments:\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer. Valid for\n            Digital and DigitalAnalog HEA.\n        periodic (bool): if the qubits should be linked periodically.\n            periodic=False is not supported in emu-c. Valid for only\n            for Digital HEA.\n        entangler (AbstractBlock):\n            - Digital: 2-qubit entangling operation. Supports CNOT, CZ,\n            CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational\n            parameters on the rotation angles.\n            - DigitaAnalog | Analog: Hamiltonian generator for the\n            analog entangling layer. Defaults to global ZZ Hamiltonian.\n            Time parameter is considered variational.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import RZ, RX\n    from qadence import hea\n    # create the circuit\n    n_qubits, depth = 2, 4\n    ansatz = hea(\n        n_qubits=n_qubits,\n        depth=depth,\n        strategy=\"sDAQC\",\n        operations=[RZ,RX,RZ]\n    )\n    ```\n    \"\"\"\nif support is None:\nsupport = tuple(range(n_qubits))\nhea_func_dict = {\nStrategy.DIGITAL: hea_digital,\nStrategy.SDAQC: hea_sDAQC,\nStrategy.BDAQC: hea_bDAQC,\nStrategy.ANALOG: hea_analog,\n}\ntry:\nhea_func = hea_func_dict[strategy]\nexcept KeyError:\nraise KeyError(f\"Strategy {strategy} not recognized.\")\nhea_block: AbstractBlock = hea_func(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=param_prefix,\nsupport=support,\n**strategy_args,\n)  # type: ignore\nreturn hea_block\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.ansatze.hea_digital","title":"<code>hea_digital(n_qubits, depth=1, param_prefix='theta', periodic=False, operations=[RX, RY, RX], support=None, entangler=CNOT)</code>","text":"<p>Construct the Digital Hardware Efficient Ansatz (HEA).</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. periodic=False is not supported in emu-c.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY, RX]</code> </p> <code>support</code> <p>qubit indexes where the HEA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>entangler</code> <p>2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations will have variational parameters on the rotation angles.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>CNOT</code> </p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def hea_digital(\nn_qubits: int,\ndepth: int = 1,\nparam_prefix: str = \"theta\",\nperiodic: bool = False,\noperations: list[type[AbstractBlock]] = [RX, RY, RX],\nsupport: tuple[int, ...] = None,\nentangler: Type[DigitalEntanglers] = CNOT,\n) -&gt; AbstractBlock:\n\"\"\"\n    Construct the Digital Hardware Efficient Ansatz (HEA).\n    Args:\n        n_qubits (int): number of qubits in the block.\n        depth (int): number of layers of the HEA.\n        param_prefix (str): the base name of the variational parameters\n        periodic (bool): if the qubits should be linked periodically.\n            periodic=False is not supported in emu-c.\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        support (tuple): qubit indexes where the HEA is applied.\n        entangler (AbstractBlock): 2-qubit entangling operation.\n            Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations\n            will have variational parameters on the rotation angles.\n    \"\"\"\ntry:\nif entangler not in [CNOT, CZ, CRX, CRY, CRZ, CPHASE]:\nraise ValueError(\n\"Please provide a valid two-qubit entangler operation for digital HEA.\"\n)\nexcept TypeError:\nraise ValueError(\"Please provide a valid two-qubit entangler operation for digital HEA.\")\nrot_list = _rotations_digital(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=param_prefix,\nsupport=support,\noperations=operations,\n)\nent_list = _entanglers_digital(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=param_prefix,\nsupport=support,\nperiodic=periodic,\nentangler=entangler,\n)\nlayers = []\nfor d in range(depth):\nlayers.append(rot_list[d])\nlayers.append(ent_list[d])\nreturn tag(chain(*layers), \"HEA\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.ansatze.hea_sDAQC","title":"<code>hea_sDAQC(n_qubits, depth=1, param_prefix='theta', operations=[RX, RY, RX], support=None, entangler=None)</code>","text":"<p>Construct the Hardware Efficient Ansatz (HEA) with analog entangling layers using step-wise digital-analog computation.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY, RX]</code> </p> <code>support</code> <p>qubit indexes where the HEA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>entangler</code> <p>Hamiltonian generator for the analog entangling layer. Defaults to global ZZ Hamiltonian. Time parameter is considered variational.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def hea_sDAQC(\nn_qubits: int,\ndepth: int = 1,\nparam_prefix: str = \"theta\",\noperations: list[type[AbstractBlock]] = [RX, RY, RX],\nsupport: tuple[int, ...] = None,\nentangler: AbstractBlock | None = None,\n) -&gt; AbstractBlock:\n\"\"\"\n    Construct the Hardware Efficient Ansatz (HEA) with analog entangling layers\n    using step-wise digital-analog computation.\n    Args:\n        n_qubits (int): number of qubits in the block.\n        depth (int): number of layers of the HEA.\n        param_prefix (str): the base name of the variational parameters\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        support (tuple): qubit indexes where the HEA is applied.\n        entangler (AbstractBlock): Hamiltonian generator for the\n            analog entangling layer. Defaults to global ZZ Hamiltonian.\n            Time parameter is considered variational.\n    \"\"\"\n# TODO: Add qubit support\nif entangler is None:\nentangler = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\ntry:\nif not block_is_qubit_hamiltonian(entangler):\nraise ValueError(\n\"Please provide a valid Pauli Hamiltonian generator for digital-analog HEA.\"\n)\nexcept NotImplementedError:\nraise ValueError(\n\"Please provide a valid Pauli Hamiltonian generator for digital-analog HEA.\"\n)\nrot_list = _rotations_digital(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=param_prefix,\nsupport=support,\noperations=operations,\n)\nent_list = _entanglers_analog(\ndepth=depth,\nparam_prefix=param_prefix,\nentangler=entangler,\n)\nlayers = []\nfor d in range(depth):\nlayers.append(rot_list[d])\nlayers.append(ent_list[d])\nreturn tag(chain(*layers), \"HEA-sDA\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.hamiltonian_factory","title":"<code>hamiltonian_factory(register, interaction=None, detuning=None, interaction_strength=None, detuning_strength=None, random_strength=False, force_update=False)</code>","text":"<p>General Hamiltonian creation function. Can be used to create Hamiltonians with 2-qubit interactions and single-qubit detunings, both with arbitrary strength or parameterized.</p> PARAMETER  DESCRIPTION <code>register</code> <p>register of qubits with a specific graph topology, or number of qubits. When passing a number of qubits a register with all-to-all connectivity is created.</p> <p> TYPE: <code>Register | int</code> </p> <code>interaction</code> <p>Interaction.ZZ, Interaction.NN, Interaction.XY, or Interacton.XYZ.</p> <p> TYPE: <code>Interaction | None</code> DEFAULT: <code>None</code> </p> <code>detuning</code> <p>single-qubit operator N, X, Y, or Z.</p> <p> TYPE: <code>TDetuning | None</code> DEFAULT: <code>None</code> </p> <code>interaction_strength</code> <p>list of values to be used as the interaction strength for each pair of qubits. Should be ordered following the order of <code>Register(n_qubits).edges</code>. Alternatively, some string \"x\" can be passed, which will create a parameterized interactions for each pair of qubits, each labelled as <code>\"x_ij\"</code>.</p> <p> TYPE: <code>TArray | str | None</code> DEFAULT: <code>None</code> </p> <code>detuning_strength</code> <p>list of values to be used as the detuning strength for each qubit. Alternatively, some string \"x\" can be passed, which will create a parameterized detuning for each qubit, each labelled as <code>\"x_i\"</code>.</p> <p> TYPE: <code>TArray | str | None</code> DEFAULT: <code>None</code> </p> <code>random_strength</code> <p>set random interaction and detuning strengths between -1 and 1.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>force_update</code> <p>force override register detuning and interaction strengths.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Examples:</p> <pre><code>from qadence import hamiltonian_factory, Interaction, Register, Z\nn_qubits = 3\n# Constant total magnetization observable:\nobservable = hamiltonian_factory(n_qubits, detuning = Z)\n# Parameterized total magnetization observable:\nobservable = hamiltonian_factory(n_qubits, detuning = Z, detuning_strength = \"z\")\n# Random all-to-all XY Hamiltonian generator:\ngenerator = hamiltonian_factory(\nn_qubits,\ninteraction = Interaction.XY,\nrandom_strength = True,\n)\n# Parameterized NN Hamiltonian generator with a square grid interaction topology:\nregister = Register.square(qubits_side = n_qubits)\ngenerator = hamiltonian_factory(\nregister,\ninteraction = Interaction.NN,\ninteraction_strength = \"theta\"\n)\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def hamiltonian_factory(\nregister: Register | int,\ninteraction: Interaction | None = None,\ndetuning: TDetuning | None = None,\ninteraction_strength: TArray | str | None = None,\ndetuning_strength: TArray | str | None = None,\nrandom_strength: bool = False,\nforce_update: bool = False,\n) -&gt; AbstractBlock:\n\"\"\"\n    General Hamiltonian creation function. Can be used to create Hamiltonians with 2-qubit\n    interactions and single-qubit detunings, both with arbitrary strength or parameterized.\n    Arguments:\n        register: register of qubits with a specific graph topology, or number of qubits.\n            When passing a number of qubits a register with all-to-all connectivity\n            is created.\n        interaction: Interaction.ZZ, Interaction.NN, Interaction.XY, or Interacton.XYZ.\n        detuning: single-qubit operator N, X, Y, or Z.\n        interaction_strength: list of values to be used as the interaction strength for each\n            pair of qubits. Should be ordered following the order of `Register(n_qubits).edges`.\n            Alternatively, some string \"x\" can be passed, which will create a parameterized\n            interactions for each pair of qubits, each labelled as `\"x_ij\"`.\n        detuning_strength: list of values to be used as the detuning strength for each qubit.\n            Alternatively, some string \"x\" can be passed, which will create a parameterized\n            detuning for each qubit, each labelled as `\"x_i\"`.\n        random_strength: set random interaction and detuning strengths between -1 and 1.\n        force_update: force override register detuning and interaction strengths.\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import hamiltonian_factory, Interaction, Register, Z\n        n_qubits = 3\n        # Constant total magnetization observable:\n        observable = hamiltonian_factory(n_qubits, detuning = Z)\n        # Parameterized total magnetization observable:\n        observable = hamiltonian_factory(n_qubits, detuning = Z, detuning_strength = \"z\")\n        # Random all-to-all XY Hamiltonian generator:\n        generator = hamiltonian_factory(\n            n_qubits,\n            interaction = Interaction.XY,\n            random_strength = True,\n            )\n        # Parameterized NN Hamiltonian generator with a square grid interaction topology:\n        register = Register.square(qubits_side = n_qubits)\n        generator = hamiltonian_factory(\n            register,\n            interaction = Interaction.NN,\n            interaction_strength = \"theta\"\n            )\n        ```\n    \"\"\"\nif interaction is None and detuning is None:\nraise ValueError(\"Please provide an interaction and/or detuning for the Hamiltonian.\")\n# If number of qubits is given, creates all-to-all register\nregister = Register(register) if isinstance(register, int) else register\n# Get interaction function\ntry:\nint_fn = INTERACTION_DICT[interaction]  # type: ignore [index]\nexcept (KeyError, ValueError) as error:\nif interaction is None:\npass\nelse:\nraise KeyError(f\"Interaction {interaction} not supported.\")\n# Check single-qubit detuning\nif (detuning is not None) and (detuning not in DETUNINGS):\nraise TypeError(f\"Detuning of type {type(detuning)} not supported.\")\n# Pre-process detuning and interaction strengths and update register\nhas_detuning_strength, detuning_strength = _preprocess_strengths(\nregister, detuning_strength, \"nodes\", force_update, random_strength\n)\nhas_interaction_strength, interaction_strength = _preprocess_strengths(\nregister, interaction_strength, \"edges\", force_update, random_strength\n)\nif (not has_detuning_strength) or force_update:\nregister = _update_detuning_strength(register, detuning_strength)\nif (not has_interaction_strength) or force_update:\nregister = _update_interaction_strength(register, interaction_strength)\n# Create single-qubit detunings:\nsingle_qubit_terms: List[AbstractBlock] = []\nif detuning is not None:\nfor node in register.nodes:\nblock_sq = detuning(node)  # type: ignore [operator]\nstrength_sq = register.nodes[node][\"strength\"]\nsingle_qubit_terms.append(strength_sq * block_sq)\n# Create two-qubit interactions:\ntwo_qubit_terms: List[AbstractBlock] = []\nif interaction is not None:\nfor edge in register.edges:\nblock_tq = int_fn(*edge)  # type: ignore [operator]\nstrength_tq = register.edges[edge][\"strength\"]\ntwo_qubit_terms.append(strength_tq * block_tq)\nreturn add(*single_qubit_terms, *two_qubit_terms)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.interaction_nn","title":"<code>interaction_nn(i, j)</code>","text":"<p>Ising NN interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_nn(i: int, j: int) -&gt; AbstractBlock:\n\"\"\"Ising NN interaction.\"\"\"\nreturn N(i) @ N(j)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.interaction_xy","title":"<code>interaction_xy(i, j)</code>","text":"<p>XY interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_xy(i: int, j: int) -&gt; AbstractBlock:\n\"\"\"XY interaction.\"\"\"\nreturn X(i) @ X(j) + Y(i) @ Y(j)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.interaction_xyz","title":"<code>interaction_xyz(i, j)</code>","text":"<p>Heisenberg XYZ interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_xyz(i: int, j: int) -&gt; AbstractBlock:\n\"\"\"Heisenberg XYZ interaction.\"\"\"\nreturn X(i) @ X(j) + Y(i) @ Y(j) + Z(i) @ Z(j)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.interaction_zz","title":"<code>interaction_zz(i, j)</code>","text":"<p>Ising ZZ interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_zz(i: int, j: int) -&gt; AbstractBlock:\n\"\"\"Ising ZZ interaction.\"\"\"\nreturn Z(i) @ Z(j)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.qft.qft","title":"<code>qft(n_qubits, support=None, inverse=False, reverse_in=False, swaps_out=False, strategy=Strategy.DIGITAL, gen_build=None)</code>","text":"<p>The Quantum Fourier Transform</p> <p>Depending on the application, user should be careful with qubit ordering in the input and output. This can be controlled with reverse_in and swaps_out arguments.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the QFT</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>qubit support to use</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>inverse</code> <p>True performs the inverse QFT</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>reverse_in</code> <p>Reverses the input qubits to account for endianness</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>swaps_out</code> <p>Performs swaps on the output qubits to match the \"textbook\" QFT.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>strategy</code> <p>Strategy.Digital or Strategy.sDAQC</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>gen_build</code> <p>building block Ising Hamiltonian for the DAQC transform. Defaults to constant all-to-all Ising.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>from qadence import qft\nn_qubits = 3\nqft_circuit = qft(n_qubits, strategy = \"sDAQC\")\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/qft.py</code> <pre><code>def qft(\nn_qubits: int,\nsupport: tuple[int, ...] = None,\ninverse: bool = False,\nreverse_in: bool = False,\nswaps_out: bool = False,\nstrategy: Strategy = Strategy.DIGITAL,\ngen_build: AbstractBlock | None = None,\n) -&gt; AbstractBlock:\n\"\"\"\n    The Quantum Fourier Transform\n    Depending on the application, user should be careful with qubit ordering\n    in the input and output. This can be controlled with reverse_in and swaps_out\n    arguments.\n    Args:\n        n_qubits: number of qubits in the QFT\n        support: qubit support to use\n        inverse: True performs the inverse QFT\n        reverse_in: Reverses the input qubits to account for endianness\n        swaps_out: Performs swaps on the output qubits to match the \"textbook\" QFT.\n        strategy: Strategy.Digital or Strategy.sDAQC\n        gen_build: building block Ising Hamiltonian for the DAQC transform.\n            Defaults to constant all-to-all Ising.\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import qft\n        n_qubits = 3\n        qft_circuit = qft(n_qubits, strategy = \"sDAQC\")\n        ```\n    \"\"\"\nif support is None:\nsupport = tuple(range(n_qubits))\nassert len(support) &lt;= n_qubits, \"Wrong qubit support supplied\"\nif reverse_in:\nsupport = support[::-1]\nqft_layer_dict = {\nStrategy.DIGITAL: _qft_layer_digital,\nStrategy.SDAQC: _qft_layer_sDAQC,\nStrategy.BDAQC: _qft_layer_bDAQC,\nStrategy.ANALOG: _qft_layer_analog,\n}\ntry:\nlayer_func = qft_layer_dict[strategy]\nexcept KeyError:\nraise KeyError(f\"Strategy {strategy} not recognized.\")\nqft_layers = reversed(range(n_qubits)) if inverse else range(n_qubits)\nqft_circ = chain(\nlayer_func(\nn_qubits=n_qubits, support=support, layer=layer, inverse=inverse, gen_build=gen_build\n)  # type: ignore\nfor layer in qft_layers\n)\nif swaps_out:\nswap_ops = [SWAP(support[i], support[n_qubits - i - 1]) for i in range(n_qubits // 2)]\nqft_circ = chain(*swap_ops, qft_circ) if inverse else chain(qft_circ, *swap_ops)\nreturn tag(qft_circ, tag=\"iQFT\") if inverse else tag(qft_circ, tag=\"QFT\")\n</code></pre>"},{"location":"qadence/constructors/#the-daqc-transform","title":"The DAQC Transform","text":""},{"location":"qadence/constructors/#qadence.constructors.daqc.daqc.daqc_transform","title":"<code>daqc_transform(n_qubits, gen_target, t_f, gen_build=None, zero_tol=1e-08, strategy=Strategy.SDAQC, ignore_global_phases=False)</code>","text":"<p>Implements the DAQC transform for representing an arbitrary 2-body Hamiltonian with another fixed 2-body Hamiltonian.</p> <p>Reference for universality of 2-body Hamiltonians:</p> <p>-- https://arxiv.org/abs/quant-ph/0106064</p> <p>Based on the transformation for Ising (ZZ) interactions, as described in the paper</p> <p>-- https://arxiv.org/abs/1812.03637</p> <p>The transform translates a target weighted generator of the type:</p> <pre><code>`gen_target = add(g_jk * kron(op(j), op(k)) for j &lt; k)`\n</code></pre> <p>To a circuit using analog evolutions with a fixed building block generator:</p> <pre><code>`gen_build = add(f_jk * kron(op(j), op(k)) for j &lt; k)`\n</code></pre> <p>where <code>op = Z</code> or <code>op = N</code>.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>total number of qubits to use.</p> <p> TYPE: <code>int</code> </p> <code>gen_target</code> <p>target generator built with the structure above. The type of the generator will be automatically evaluated when parsing.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>t_f</code> <p>total time for the gen_target evolution.</p> <p> TYPE: <code>float</code> </p> <code>gen_build</code> <p>fixed generator to act as a building block. Defaults to constant NN: add(1.0 * kron(N(j), N(k)) for j &lt; k). The type of the generator will be automatically evaluated when parsing.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <code>zero_tol</code> <p>default \"zero\" for a missing interaction. Included for numerical reasons, see notes below.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-08</code> </p> <code>strategy</code> <p>sDAQC or bDAQC, following definitions in the reference paper.</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>SDAQC</code> </p> <code>ignore_global_phases</code> <p>if <code>True</code> the transform does not correct the global phases coming from the mapping between ZZ and NN interactions.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Notes:</p> <pre><code>The paper follows an index convention of running from 1 to N. A few functions\nhere also use that convention to be consistent with the paper. However, for qadence\nrelated things the indices are converted to [0, N-1].\n\nThe case for `n_qubits = 4` is an edge case where the sign matrix is not invertible.\nThere is a workaround for this described in the paper, but it is currently not implemented.\n\nThe current implementation may result in evolution times that are both positive or\nnegative. In practice, both can be represented by simply changing the signs of the\ninteractions. However, for a real implementation where the interactions should remain\nfixed, the paper discusses a workaround that is not currently implemented.\n\nThe transformation works by representing each interaction in the target hamiltonian by\na set of evolutions using the build hamiltonian. As a consequence, some care must be\ntaken when choosing the build hamiltonian. Some cases:\n\n- The target hamiltonian can have any interaction, as long as it is sufficiently\nrepresented in the build hamiltonian. E.g., if the interaction `g_01 * kron(Z(0), Z(1))`\nis in the target hamiltonian, the corresponding interaction `f_01 * kron(Z(0), Z(1))`\nneeds to be in the build hamiltonian. This is checked when the generators are parsed.\n\n- The build hamiltonian can have any interaction, irrespectively of it being needed\nfor the target hamiltonian. This is especially useful for designing local operations\nthrough the repeated evolution of a \"global\" hamiltonian.\n\n- The parameter `zero_tol` controls what it means for an interaction to be \"missing\".\nAny interaction strength smaller than `zero_tol` in the build hamiltonian will not be\nconsidered, and thus that interaction is missing.\n\n- The various ratios `g_jk / f_jk` will influence the time parameter for the various\nevolution slices, meaning that if there is a big discrepancy in the interaction strength\nfor a given qubit pair (j, k), the output circuit may require the usage of hamiltonian\nevolutions with very large times.\n\n- A warning will be issued for evolution times larger than `1/sqrt(zero_tol)`. Evolution\ntimes smaller than `zero_tol` will not be represented.\n</code></pre> <p>Examples:</p> <pre><code>from qadence import Z, N, daqc_transform\nn_qubits = 3\ngen_build = 0.5 * (N(0)@N(1)) + 0.7 * (N(1)@N(2)) + 0.2 * (N(0)@N(2))\ngen_target = 0.1 * (Z(1)@Z(2))\nt_f = 2.0\ntransformed_circuit = daqc_transform(\nn_qubits = n_qubits,\ngen_target = gen_target,\nt_f = t_f,\ngen_build = gen_build,\n)\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/daqc/daqc.py</code> <pre><code>def daqc_transform(\nn_qubits: int,\ngen_target: AbstractBlock,\nt_f: float,\ngen_build: AbstractBlock | None = None,\nzero_tol: float = 1e-08,\nstrategy: Strategy = Strategy.SDAQC,\nignore_global_phases: bool = False,\n) -&gt; AbstractBlock:\n\"\"\"\n    Implements the DAQC transform for representing an arbitrary 2-body Hamiltonian\n    with another fixed 2-body Hamiltonian.\n    Reference for universality of 2-body Hamiltonians:\n    -- https://arxiv.org/abs/quant-ph/0106064\n    Based on the transformation for Ising (ZZ) interactions, as described in the paper\n    -- https://arxiv.org/abs/1812.03637\n    The transform translates a target weighted generator of the type:\n        `gen_target = add(g_jk * kron(op(j), op(k)) for j &lt; k)`\n    To a circuit using analog evolutions with a fixed building block generator:\n        `gen_build = add(f_jk * kron(op(j), op(k)) for j &lt; k)`\n    where `op = Z` or `op = N`.\n    Args:\n        n_qubits: total number of qubits to use.\n        gen_target: target generator built with the structure above. The type\n            of the generator will be automatically evaluated when parsing.\n        t_f (float): total time for the gen_target evolution.\n        gen_build: fixed generator to act as a building block. Defaults to\n            constant NN: add(1.0 * kron(N(j), N(k)) for j &lt; k). The type\n            of the generator will be automatically evaluated when parsing.\n        zero_tol: default \"zero\" for a missing interaction. Included for\n            numerical reasons, see notes below.\n        strategy: sDAQC or bDAQC, following definitions in the reference paper.\n        ignore_global_phases: if `True` the transform does not correct the global\n            phases coming from the mapping between ZZ and NN interactions.\n    Notes:\n        The paper follows an index convention of running from 1 to N. A few functions\n        here also use that convention to be consistent with the paper. However, for qadence\n        related things the indices are converted to [0, N-1].\n        The case for `n_qubits = 4` is an edge case where the sign matrix is not invertible.\n        There is a workaround for this described in the paper, but it is currently not implemented.\n        The current implementation may result in evolution times that are both positive or\n        negative. In practice, both can be represented by simply changing the signs of the\n        interactions. However, for a real implementation where the interactions should remain\n        fixed, the paper discusses a workaround that is not currently implemented.\n        The transformation works by representing each interaction in the target hamiltonian by\n        a set of evolutions using the build hamiltonian. As a consequence, some care must be\n        taken when choosing the build hamiltonian. Some cases:\n        - The target hamiltonian can have any interaction, as long as it is sufficiently\n        represented in the build hamiltonian. E.g., if the interaction `g_01 * kron(Z(0), Z(1))`\n        is in the target hamiltonian, the corresponding interaction `f_01 * kron(Z(0), Z(1))`\n        needs to be in the build hamiltonian. This is checked when the generators are parsed.\n        - The build hamiltonian can have any interaction, irrespectively of it being needed\n        for the target hamiltonian. This is especially useful for designing local operations\n        through the repeated evolution of a \"global\" hamiltonian.\n        - The parameter `zero_tol` controls what it means for an interaction to be \"missing\".\n        Any interaction strength smaller than `zero_tol` in the build hamiltonian will not be\n        considered, and thus that interaction is missing.\n        - The various ratios `g_jk / f_jk` will influence the time parameter for the various\n        evolution slices, meaning that if there is a big discrepancy in the interaction strength\n        for a given qubit pair (j, k), the output circuit may require the usage of hamiltonian\n        evolutions with very large times.\n        - A warning will be issued for evolution times larger than `1/sqrt(zero_tol)`. Evolution\n        times smaller than `zero_tol` will not be represented.\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import Z, N, daqc_transform\n        n_qubits = 3\n        gen_build = 0.5 * (N(0)@N(1)) + 0.7 * (N(1)@N(2)) + 0.2 * (N(0)@N(2))\n        gen_target = 0.1 * (Z(1)@Z(2))\n        t_f = 2.0\n        transformed_circuit = daqc_transform(\n            n_qubits = n_qubits,\n            gen_target = gen_target,\n            t_f = t_f,\n            gen_build = gen_build,\n        )\n        ```\n    \"\"\"\n##################\n# Input controls #\n##################\nif strategy != Strategy.SDAQC:\nraise NotImplementedError(\"Currently only the sDAQC transform is implemented.\")\nif n_qubits == 4:\nraise NotImplementedError(\"DAQC transform 4-qubit edge case not implemented.\")\nif gen_build is None:\ngen_build = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\ntry:\nif (not block_is_qubit_hamiltonian(gen_target)) or (\nnot block_is_qubit_hamiltonian(gen_build)\n):\nraise ValueError(\n\"Generator block is not a qubit Hamiltonian. Only ZZ or NN interactions allowed.\"\n)\nexcept NotImplementedError:\n# Happens when block_is_qubit_hamiltonian is called on something that is not a block.\nraise TypeError(\n\"Generator block is not a qubit Hamiltonian. Only ZZ or NN interactions allowed.\"\n)\n#####################\n# Generator parsing #\n#####################\ng_jk_target, mat_jk_target, target_type = _parse_generator(n_qubits, gen_target, 0.0)\ng_jk_build, mat_jk_build, build_type = _parse_generator(n_qubits, gen_build, zero_tol)\n# Get the global phase hamiltonian and single-qubit detuning hamiltonian\nif build_type == GenDAQC.NN:\nh_phase_build, h_sq_build = _nn_phase_and_detunings(n_qubits, mat_jk_build)\nif target_type == GenDAQC.NN:\nh_phase_target, h_sq_target = _nn_phase_and_detunings(n_qubits, mat_jk_target)\n# Time re-scalings\nif build_type == GenDAQC.ZZ and target_type == GenDAQC.NN:\nt_star = t_f / 4.0\nelif build_type == GenDAQC.NN and target_type == GenDAQC.ZZ:\nt_star = 4.0 * t_f\nelse:\nt_star = t_f\n# Check if target Hamiltonian can be mapped with the build Hamiltonian\nassert _check_compatibility(g_jk_target, g_jk_build, zero_tol)\n##################\n# DAQC Transform #\n##################\n# Section III A of https://arxiv.org/abs/1812.03637:\n# Matrix M for the linear system, exemplified in Table I:\nmatrix_M = _build_matrix_M(n_qubits)\n# Linear system mapping interaction ratios -&gt; evolution times.\nt_slices = torch.linalg.solve(matrix_M, g_jk_target / g_jk_build) * t_star\n# ZZ-DAQC with ZZ or NN build Hamiltonian\ndaqc_slices = []\nfor m in range(2, n_qubits + 1):\nfor n in range(1, m):\nalpha = _ix_map(n_qubits, n, m)\nt = t_slices[alpha - 1]\nif abs(t) &gt; zero_tol:\nif abs(t) &gt; (1 / (zero_tol**0.5)):\nlogger.warning(\n\"\"\"\nTransformed circuit with very long evolution time.\nMake sure your target interactions are sufficiently\nrepresented in the build Hamiltonian.\"\"\"\n)\nx_gates = kron(X(n - 1), X(m - 1))\nanalog_evo = HamEvo(gen_build, t)\n# TODO: Fix repeated X-gates\nif build_type == GenDAQC.NN:\n# Local detuning at each DAQC layer for NN build Hamiltonian\nsq_detuning_build = HamEvo(h_sq_build, t)\ndaqc_slices.append(chain(x_gates, sq_detuning_build, analog_evo, x_gates))\nelif build_type == GenDAQC.ZZ:\ndaqc_slices.append(chain(x_gates, analog_evo, x_gates))\ndaqc_circuit = chain(*daqc_slices)\n########################\n# Phases and Detunings #\n########################\nif target_type == GenDAQC.NN:\n# Local detuning given a NN target Hamiltonian\nsq_detuning_target = HamEvo(h_sq_target, t_f).dagger()\ndaqc_circuit = chain(sq_detuning_target, daqc_circuit)\nif not ignore_global_phases:\nif build_type == GenDAQC.NN:\n# Constant global phase given a NN build Hamiltonian\nglobal_phase_build = HamEvo(h_phase_build, t_slices.sum())\ndaqc_circuit = chain(global_phase_build, daqc_circuit)\nif target_type == GenDAQC.NN:\n# Constant global phase and given a NN target Hamiltonian\nglobal_phase_target = HamEvo(h_phase_target, t_f).dagger()\ndaqc_circuit = chain(global_phase_target, daqc_circuit)\nreturn daqc_circuit\n</code></pre>"},{"location":"qadence/constructors/#some-utility-functions","title":"Some utility functions","text":""},{"location":"qadence/constructors/#qadence.constructors.utils.build_idx_fms","title":"<code>build_idx_fms(basis, fm_pauli, fm_strategy, n_features, n_qubits, spectrum)</code>","text":"<p>Builds the index feature maps based on the given parameters.</p> PARAMETER  DESCRIPTION <code>basis</code> <p>Type of basis chosen for the feature map.</p> <p> TYPE: <code>str</code> </p> <code>fm_pauli</code> <p>The chosen Pauli rotation type.</p> <p> TYPE: <code>PrimitiveBlock type</code> </p> <code>fm_strategy</code> <p>The feature map strategy to be used. Possible values are 'parallel' or 'serial'.</p> <p> TYPE: <code>str</code> </p> <code>n_features</code> <p>The number of features.</p> <p> TYPE: <code>int</code> </p> <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>spectrum</code> <p>The chosen spectrum.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>list[KronBlock]</code> <p>List[KronBlock]: The list of index feature maps.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def build_idx_fms(\nbasis: str,\nfm_pauli: Type[RY],\nfm_strategy: str,\nn_features: int,\nn_qubits: int,\nspectrum: str,\n) -&gt; list[KronBlock]:\n\"\"\"Builds the index feature maps based on the given parameters.\n    Args:\n        basis (str): Type of basis chosen for the feature map.\n        fm_pauli (PrimitiveBlock type): The chosen Pauli rotation type.\n        fm_strategy (str): The feature map strategy to be used. Possible values are\n            'parallel' or 'serial'.\n        n_features (int): The number of features.\n        n_qubits (int): The number of qubits.\n        spectrum (str): The chosen spectrum.\n    Returns:\n        List[KronBlock]: The list of index feature maps.\n    \"\"\"\nidx_fms = []\nfor i in range(n_features):\ntarget_qubits = get_fm_qubits(fm_strategy, i, n_qubits, n_features)\nparam = FeatureParameter(f\"x{i}\")\nblock = kron(\n*[\nfm_pauli(qubit, generator_prefactor(spectrum, j) * basis_func(basis, param))\nfor j, qubit in enumerate(target_qubits)\n]\n)\nidx_fm = block\nidx_fms.append(idx_fm)\nreturn idx_fms\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.utils.generator_prefactor","title":"<code>generator_prefactor(spectrum, qubit_index)</code>","text":"<p>Converts a spectrum string (e.g., tower or exponential) to the correct generator prefactor.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def generator_prefactor(spectrum: str, qubit_index: int) -&gt; float | int:\n\"\"\"\n    Converts a spectrum string (e.g., tower or exponential) to the correct generator prefactor.\n    \"\"\"\nspectrum = spectrum.lower()\nconversion_dict: dict[str, float | int] = {\n\"simple\": 1,\n\"tower\": qubit_index + 1,\n\"exponential\": 2 * np.pi / (2 ** (qubit_index + 1)),\n}\nreturn conversion_dict[spectrum]\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.utils.get_fm_qubits","title":"<code>get_fm_qubits(fm_strategy, i, n_qubits, n_features)</code>","text":"<p>Returns the list of target qubits for the given feature map strategy and feature index</p> PARAMETER  DESCRIPTION <code>fm_strategy</code> <p>The feature map strategy to be used. Possible values are 'parallel' or 'serial'.</p> <p> TYPE: <code>str</code> </p> <code>i</code> <p>The feature index.</p> <p> TYPE: <code>int</code> </p> <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>n_features</code> <p>The number of features.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Iterable</code> <p>List[int]: The list of target qubits.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the feature map strategy is not implemented.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def get_fm_qubits(fm_strategy: str, i: int, n_qubits: int, n_features: int) -&gt; Iterable:\n\"\"\"Returns the list of target qubits for the given feature map strategy and feature index\n    Args:\n        fm_strategy (str): The feature map strategy to be used. Possible values\n            are 'parallel' or 'serial'.\n        i (int): The feature index.\n        n_qubits (int): The number of qubits.\n        n_features (int): The number of features.\n    Returns:\n        List[int]: The list of target qubits.\n    Raises:\n        ValueError: If the feature map strategy is not implemented.\n    \"\"\"\nif fm_strategy == \"parallel\":\nn_qubits_per_feature = int(n_qubits / n_features)\ntarget_qubits = range(i * n_qubits_per_feature, (i + 1) * n_qubits_per_feature)\nelif fm_strategy == \"serial\":\ntarget_qubits = range(0, n_qubits)\nelse:\nraise ValueError(f\"Feature map strategy {fm_strategy} not implemented.\")\nreturn target_qubits\n</code></pre>"},{"location":"qadence/execution/","title":"Execution","text":""},{"location":"qadence/execution/#qadence.execution.expectation","title":"<code>expectation(x, observable, values={}, state=None, backend=BackendName.PYQTORCH, diff_mode=None, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.expectation</code> method.  This is a <code>functools.singledispatch</code>ed function so it can be called with a number of different arguments (see in the examples).</p> PARAMETER  DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>observable</code> <p>Observable(s) w.r.t. which the expectation is computed.</p> <p> TYPE: <code>Union[list[AbstractBlock], AbstractBlock]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>Which differentiation mode to use.</p> <p> TYPE: <code>Union[DiffMode, str, None]</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A wavefunction</p> <pre><code>from qadence import RX, Z, Register, QuantumCircuit, expectation\nreg = Register(1)\nblock = RX(0, 0.5)\nobservable = Z(0)\ncirc = QuantumCircuit(reg, block)\n# You can compute the expectation for a\n# QuantumCircuit with a given observable.\nexpectation(circ, observable)\n# You can also use only a block.\n# In this case the register is constructed automatically to\n# Register.line(block.n_qubits)\nexpectation(block, observable)\n# Or a register and block\nexpectation(reg, block, observable)\n</code></pre> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef expectation(\nx: Union[QuantumCircuit, AbstractBlock, Register, int],\nobservable: Union[list[AbstractBlock], AbstractBlock],\nvalues: dict = {},\nstate: Tensor = None,\nbackend: BackendName = BackendName.PYQTORCH,\ndiff_mode: Union[DiffMode, str, None] = None,\nendianness: Endianness = Endianness.BIG,\nconfiguration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; Tensor:\n\"\"\"Convenience wrapper for the `QuantumModel.expectation` method.  This is a\n    `functools.singledispatch`ed function so it can be called with a number of different arguments\n    (see in the examples).\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        observable: Observable(s) w.r.t. which the expectation is computed.\n        values: User-facing parameter dict.\n        state: Initial state.\n        backend: Name of the backend to run on.\n        diff_mode: Which differentiation mode to use.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n    Returns:\n        A wavefunction\n    ```python exec=\"on\" source=\"material-block\"\n    from qadence import RX, Z, Register, QuantumCircuit, expectation\n    reg = Register(1)\n    block = RX(0, 0.5)\n    observable = Z(0)\n    circ = QuantumCircuit(reg, block)\n    # You can compute the expectation for a\n    # QuantumCircuit with a given observable.\n    expectation(circ, observable)\n    # You can also use only a block.\n    # In this case the register is constructed automatically to\n    # Register.line(block.n_qubits)\n    expectation(block, observable)\n    # Or a register and block\n    expectation(reg, block, observable)\n    ```\"\"\"\nraise ValueError(f\"Cannot execute {type(x)}\")\n</code></pre>"},{"location":"qadence/execution/#qadence.execution.run","title":"<code>run(x, *args, values={}, state=None, backend=BackendName.PYQTORCH, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.run</code> method.  This is a <code>functools.singledispatch</code>ed function so it can be called with a number of different arguments. See the examples of the <code>expectation</code> function. This function works exactly the same.</p> PARAMETER  DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A wavefunction</p> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef run(\nx: Union[QuantumCircuit, AbstractBlock, Register, int],\n*args: Any,\nvalues: dict = {},\nstate: Tensor = None,\nbackend: BackendName = BackendName.PYQTORCH,\nendianness: Endianness = Endianness.BIG,\nconfiguration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; Tensor:\n\"\"\"Convenience wrapper for the `QuantumModel.run` method.  This is a\n    `functools.singledispatch`ed function so it can be called with a number of different arguments.\n    See the examples of the [`expectation`][qadence.execution.expectation] function. This function\n    works exactly the same.\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        values: User-facing parameter dict.\n        state: Initial state.\n        backend: Name of the backend to run on.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n    Returns:\n        A wavefunction\n    \"\"\"\nraise ValueError(f\"Cannot run {type(x)}\")\n</code></pre>"},{"location":"qadence/execution/#qadence.execution.sample","title":"<code>sample(x, *args, values={}, state=None, n_shots=100, backend=BackendName.PYQTORCH, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.sample</code> method.  This is a <code>functools.singledispatch</code>ed function so it can be called with a number of different arguments. See the examples of the <code>expectation</code> function. This function works exactly the same.</p> PARAMETER  DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Union[Tensor, None]</code> DEFAULT: <code>None</code> </p> <code>n_shots</code> <p>Number of shots per element in the batch.</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[Counter]</code> <p>A list of Counter instances with the sample results</p> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef sample(\nx: Union[QuantumCircuit, AbstractBlock, Register, int],\n*args: Any,\nvalues: dict = {},\nstate: Union[Tensor, None] = None,\nn_shots: int = 100,\nbackend: BackendName = BackendName.PYQTORCH,\nendianness: Endianness = Endianness.BIG,\nconfiguration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; list[Counter]:\n\"\"\"Convenience wrapper for the `QuantumModel.sample` method.  This is a\n    `functools.singledispatch`ed function so it can be called with a number of different arguments.\n    See the examples of the [`expectation`][qadence.execution.expectation] function. This function\n    works exactly the same.\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        values: User-facing parameter dict.\n        state: Initial state.\n        n_shots: Number of shots per element in the batch.\n        backend: Name of the backend to run on.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n    Returns:\n        A list of Counter instances with the sample results\n    \"\"\"\nraise ValueError(f\"Cannot sample from {type(x)}\")\n</code></pre>"},{"location":"qadence/ml_tools/","title":"Machine Learning Tools","text":""},{"location":"qadence/ml_tools/#ml-tools","title":"ML Tools","text":"<p>This module implements gradient-free and gradient-based training loops for torch Modules and QuantumModel.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig","title":"<code>TrainConfig</code>  <code>dataclass</code>","text":"<p>Default config for the train function. The default value of each field can be customize with the constructor:</p> <pre><code>from qadence.ml_tools import TrainConfig\nc = TrainConfig(folder=\"/tmp/train\")\n</code></pre> <pre><code>TrainConfig(max_iter=10000, print_every=1000, write_every=50, checkpoint_every=5000, folder=PosixPath('/tmp/train'), create_subfolder_per_run=False, checkpoint_best_only=False, validation_criterion=&lt;function TrainConfig.__post_init__.&lt;locals&gt;.&lt;lambda&gt; at 0x7f34300e5e10&gt;, trainstop_criterion=&lt;function TrainConfig.__post_init__.&lt;locals&gt;.&lt;lambda&gt; at 0x7f34300e5990&gt;, batch_size=1)\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.batch_size","title":"<code>batch_size: int = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The batch_size to use when passing a list/tuple of torch.Tensors.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.checkpoint_best_only","title":"<code>checkpoint_best_only: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Write model/optimizer checkpoint only if a metric has improved</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.checkpoint_every","title":"<code>checkpoint_every: int = 5000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Write model/optimizer checkpoint</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.create_subfolder_per_run","title":"<code>create_subfolder_per_run: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Checkpoint/tensorboard logs stored in subfolder with name <code>&lt;timestamp&gt;_&lt;PID&gt;</code>. Prevents continuing from previous checkpoint, useful for fast prototyping.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.folder","title":"<code>folder: Optional[Path] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Checkpoint/tensorboard logs folder</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.max_iter","title":"<code>max_iter: int = 10000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of training iterations.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.print_every","title":"<code>print_every: int = 1000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Print loss/metrics.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.trainstop_criterion","title":"<code>trainstop_criterion: Optional[Callable] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A boolean function which evaluates a given training stopping metric is satisfied</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.validation_criterion","title":"<code>validation_criterion: Optional[Callable] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A boolean function which evaluates a given validation metric is satisfied</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.write_every","title":"<code>write_every: int = 50</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Write tensorboard logs</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.parameters.get_parameters","title":"<code>get_parameters(model)</code>","text":"<p>Retrieve all trainable model parameters in a single vector</p> PARAMETER  DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a 1-dimensional tensor with the parameters</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def get_parameters(model: Module) -&gt; Tensor:\n\"\"\"Retrieve all trainable model parameters in a single vector\n    Args:\n        model (Module): the input PyTorch model\n    Returns:\n        Tensor: a 1-dimensional tensor with the parameters\n    \"\"\"\nps = [p.reshape(-1) for p in model.parameters() if p.requires_grad]\nreturn torch.concat(ps)\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.parameters.num_parameters","title":"<code>num_parameters(model)</code>","text":"<p>Return the total number of parameters of the given model</p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def num_parameters(model: Module) -&gt; int:\n\"\"\"Return the total number of parameters of the given model\"\"\"\nreturn len(get_parameters(model))\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.parameters.set_parameters","title":"<code>set_parameters(model, theta)</code>","text":"<p>Set all trainable parameters of a model from a single vector</p> <p>Notice that this function assumes prior knowledge of right number of parameters in the model</p> PARAMETER  DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> <code>theta</code> <p>the parameters to assign</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def set_parameters(model: Module, theta: Tensor) -&gt; None:\n\"\"\"Set all trainable parameters of a model from a single vector\n    Notice that this function assumes prior knowledge of right number\n    of parameters in the model\n    Args:\n        model (Module): the input PyTorch model\n        theta (Tensor): the parameters to assign\n    \"\"\"\nwith torch.no_grad():\nidx = 0\nfor ps in model.parameters():\nif ps.requires_grad:\nn = torch.numel(ps)\nif ps.ndim == 0:\nps[()] = theta[idx : idx + n]\nelse:\nps[:] = theta[idx : idx + n].reshape(ps.size())\nidx += n\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.optimize_step.data_to_model","title":"<code>data_to_model(xs, device='cpu')</code>","text":"<p>Default behavior for single-dispatched function</p> <p>Just return the given data independently on the type</p> PARAMETER  DESCRIPTION <code>xs</code> <p>the input data</p> <p> TYPE: <code>Any</code> </p> <code>device</code> <p>The torch device. Not used in this implementation.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>the <code>xs</code> argument untouched</p> <p> TYPE: <code>Any</code> </p> Source code in <code>qadence/ml_tools/optimize_step.py</code> <pre><code>@singledispatch\ndef data_to_model(xs: Any, device: str = \"cpu\") -&gt; Any:\n\"\"\"Default behavior for single-dispatched function\n    Just return the given data independently on the type\n    Args:\n        xs (Any): the input data\n        device (str, optional): The torch device. Not used in this implementation.\n    Returns:\n        Any: the `xs` argument untouched\n    \"\"\"\nreturn xs\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.optimize_step.optimize_step","title":"<code>optimize_step(model, optimizer, loss_fn, xs, device='cpu')</code>","text":"<p>Default Torch optimize step with closure</p> <p>This is the default optimization step which should work for most of the standard use cases of optimization of Torch models</p> PARAMETER  DESCRIPTION <code>model</code> <p>The input model</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>The chosen Torch optimizer</p> <p> TYPE: <code>Optimizer</code> </p> <code>loss_fn</code> <p>A custom loss function</p> <p> TYPE: <code>Callable</code> </p> <code>xs</code> <p>the input data. If None it means that the given model does not require any input data</p> <p> TYPE: <code>dict | list | Tensor | None</code> </p> <code>device</code> <p>The device were computations are executed. Defaults to \"cpu\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> RETURNS DESCRIPTION <code>tuple</code> <p>tuple containing the model, the optimizer, a dictionary with the collected metrics and the compute value loss</p> <p> TYPE: <code>tuple[Tensor | float, dict | None]</code> </p> Source code in <code>qadence/ml_tools/optimize_step.py</code> <pre><code>def optimize_step(\nmodel: Module,\noptimizer: Optimizer,\nloss_fn: Callable,\nxs: dict | list | torch.Tensor | None,\ndevice: str = \"cpu\",\n) -&gt; tuple[torch.Tensor | float, dict | None]:\n\"\"\"Default Torch optimize step with closure\n    This is the default optimization step which should work for most\n    of the standard use cases of optimization of Torch models\n    Args:\n        model (Module): The input model\n        optimizer (Optimizer): The chosen Torch optimizer\n        loss_fn (Callable): A custom loss function\n        xs (dict | list | torch.Tensor | None): the input data. If None it means\n            that the given model does not require any input data\n        device (str, optional): The device were computations are executed.\n            Defaults to \"cpu\".\n    Returns:\n        tuple: tuple containing the model, the optimizer, a dictionary with\n            the collected metrics and the compute value loss\n    \"\"\"\nloss, metrics = None, {}\ndef closure() -&gt; Any:\n# NOTE: We need the nonlocal as we can't return a metric dict and\n# because e.g. LBFGS calls this closure multiple times but for some\n# reason the returned loss is always the first one...\nnonlocal metrics, loss\noptimizer.zero_grad()\nloss, metrics = loss_fn(model, xs)\nloss.backward(retain_graph=True)\nreturn loss.item()\noptimizer.step(closure)\n# return the loss/metrics that are being mutated inside the closure...\nreturn loss, metrics\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.train_grad.train","title":"<code>train(model, dataloader, optimizer, config, loss_fn, device='cpu', optimize_step=optimize_step, write_tensorboard=write_tensorboard)</code>","text":"<p>Runs the training loop with gradient-based optimizer</p> <p>Assumes that <code>loss_fn</code> returns a tuple of (loss, metrics: dict), where <code>metrics</code> is a dict of scalars. Loss and metrics are written to tensorboard. Checkpoints are written every <code>config.checkpoint_every</code> steps (and after the last training step).  If a checkpoint is found at <code>config.folder</code> we resume training from there.  The tensorboard logs can be viewed via <code>tensorboard --logdir /path/to/folder</code>.</p> PARAMETER  DESCRIPTION <code>model</code> <p>The model to train.</p> <p> TYPE: <code>Module</code> </p> <code>dataloader</code> <p>dataloader of different types. If None, no data is required by the model</p> <p> TYPE: <code>DictDataLoader | DataLoader | list[Tensor] | tuple[Tensor, Tensor] | None</code> </p> <code>optimizer</code> <p>The optimizer to use.</p> <p> TYPE: <code>Optimizer</code> </p> <code>config</code> <p><code>TrainConfig</code> with additional training options.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>loss_fn</code> <p>Loss function returning (loss: float, metrics: dict[str, float])</p> <p> TYPE: <code>Callable</code> </p> <code>device</code> <p>String defining device to train on, pass 'cuda' for GPU.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> <code>optimize_step</code> <p>Customizable optimization callback which is called at every iteration.= The function must have the signature <code>optimize_step(model, optimizer, loss_fn, xs, device=\"cpu\")</code> (see the example below). Apart from the default we already supply three other optimization functions <code>optimize_step_evo</code>, <code>optimize_step_grad_norm</code>, and <code>optimize_step_inv_dirichlet</code>. Learn more about how to use this in the Advancded features tutorial of the documentation.</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>optimize_step</code> </p> <code>write_tensorboard</code> <p>Customizable tensorboard logging callback which is called every <code>config.write_every</code> iterations. The function must have the signature <code>write_tensorboard(writer, loss, metrics, iteration)</code> (see the example below).</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>write_tensorboard</code> </p> <p>Example: <pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence.models import QNN\nfrom qadence.ml_tools import train_with_grad, TrainConfig\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning = Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\n## lets prepare the train routine\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\nnext(cnt)\nx, y = data[0], data[1]\nout = model(x)\nloss = criterion(out, y)\nreturn loss, {}\ntmp_path = Path(\"/tmp\")\nn_epochs = 5\nconfig = TrainConfig(\nfolder=tmp_path,\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\nbatch_size = 25\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\ntrain_with_grad(model, (x, y), optimizer, config, loss_fn=loss_fn)\n</code></pre> </p> Source code in <code>qadence/ml_tools/train_grad.py</code> <pre><code>def train(\nmodel: Module,\ndataloader: DictDataLoader | DataLoader | list[Tensor] | tuple[Tensor, Tensor] | None,\noptimizer: Optimizer,\nconfig: TrainConfig,\nloss_fn: Callable,\ndevice: str = \"cpu\",\noptimize_step: Callable = optimize_step,\nwrite_tensorboard: Callable = write_tensorboard,\n) -&gt; tuple[Module, Optimizer]:\n\"\"\"Runs the training loop with gradient-based optimizer\n    Assumes that `loss_fn` returns a tuple of (loss,\n    metrics: dict), where `metrics` is a dict of scalars. Loss and metrics are\n    written to tensorboard. Checkpoints are written every\n    `config.checkpoint_every` steps (and after the last training step).  If a\n    checkpoint is found at `config.folder` we resume training from there.  The\n    tensorboard logs can be viewed via `tensorboard --logdir /path/to/folder`.\n    Args:\n        model: The model to train.\n        dataloader: dataloader of different types. If None, no data is required by\n            the model\n        optimizer: The optimizer to use.\n        config: `TrainConfig` with additional training options.\n        loss_fn: Loss function returning (loss: float, metrics: dict[str, float])\n        device: String defining device to train on, pass 'cuda' for GPU.\n        optimize_step: Customizable optimization callback which is called at every iteration.=\n            The function must have the signature `optimize_step(model,\n            optimizer, loss_fn, xs, device=\"cpu\")` (see the example below).\n            Apart from the default we already supply three other optimization\n            functions `optimize_step_evo`, `optimize_step_grad_norm`, and\n            `optimize_step_inv_dirichlet`. Learn more about how to use this in\n            the [Advancded features](../../tutorials/advanced) tutorial of the\n            documentation.\n        write_tensorboard: Customizable tensorboard logging callback which is\n            called every `config.write_every` iterations. The function must have\n            the signature `write_tensorboard(writer, loss, metrics, iteration)`\n            (see the example below).\n    Example:\n    ```python exec=\"on\" source=\"material-block\"\n    from pathlib import Path\n    import torch\n    from itertools import count\n    from qadence.constructors import hamiltonian_factory, hea, feature_map\n    from qadence import chain, Parameter, QuantumCircuit, Z\n    from qadence.models import QNN\n    from qadence.ml_tools import train_with_grad, TrainConfig\n    n_qubits = 2\n    fm = feature_map(n_qubits)\n    ansatz = hea(n_qubits=n_qubits, depth=3)\n    observable = hamiltonian_factory(n_qubits, detuning = Z)\n    circuit = QuantumCircuit(n_qubits, fm, ansatz)\n    model = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\n    batch_size = 1\n    input_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\n    pred = model(input_values)\n    ## lets prepare the train routine\n    cnt = count()\n    criterion = torch.nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n    def loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n        next(cnt)\n        x, y = data[0], data[1]\n        out = model(x)\n        loss = criterion(out, y)\n        return loss, {}\n    tmp_path = Path(\"/tmp\")\n    n_epochs = 5\n    config = TrainConfig(\n        folder=tmp_path,\n        max_iter=n_epochs,\n        checkpoint_every=100,\n        write_every=100,\n        batch_size=batch_size,\n    )\n    batch_size = 25\n    x = torch.linspace(0, 1, batch_size).reshape(-1, 1)\n    y = torch.sin(x)\n    train_with_grad(model, (x, y), optimizer, config, loss_fn=loss_fn)\n    ```\n    \"\"\"\nassert loss_fn is not None, \"Provide a valid loss function\"\n# Move model to device before optimizer is loaded\nmodel = model.to(device)\n# load available checkpoint\ninit_iter = 0\nif config.folder:\nmodel, optimizer, init_iter = load_checkpoint(config.folder, model, optimizer)\nlogger.debug(f\"Loaded model and optimizer from {config.folder}\")\n# initialize tensorboard\nwriter = SummaryWriter(config.folder, purge_step=init_iter)\n## Training\nprogress = Progress(\nTextColumn(\"[progress.description]{task.description}\"),\nBarColumn(),\nTaskProgressColumn(),\nTimeRemainingColumn(elapsed_when_finished=True),\n)\nif isinstance(dataloader, (list, tuple)):\nfrom qadence.ml_tools.data import to_dataloader\nassert len(dataloader) == 2, \"Please provide exactly two torch tensors.\"\nx, y = dataloader\ndataloader = to_dataloader(x=x, y=y, batch_size=config.batch_size)\nwith progress:\ndl_iter = iter(dataloader) if isinstance(dataloader, DictDataLoader) else None\n# outer epoch loop\nfor iteration in progress.track(range(init_iter, init_iter + config.max_iter)):\ntry:\n# in case there is not data needed by the model\n# this is the case, for example, of quantum models\n# which do not have classical input data (e.g. chemistry)\nif dataloader is None:\nloss, metrics = optimize_step(\nmodel, optimizer, loss_fn, dataloader, device=device\n)\n# single epoch with DictDataloader using a single iteration method\n# DictDataloader returns a single sample of the data\n# with a given batch size decided when the dataloader is defined\nelif isinstance(dataloader, DictDataLoader):\n# resample all the time from the dataloader\n# by creating a fresh iterator if the dataloader\n# does not support automatically iterating datasets\nif not dataloader.has_automatic_iter:\ndl_iter = iter(dataloader)\ndata = next(dl_iter)  # type: ignore[arg-type]\nloss, metrics = optimize_step(model, optimizer, loss_fn, data, device=device)\nelif isinstance(dataloader, DataLoader):\n# single-epoch with standard DataLoader\n# otherwise a standard PyTorch DataLoader behavior\n# is assumed with optional mini-batches\nrunning_loss = 0.0\nfor i, data in enumerate(dataloader):\n# TODO: make sure to average metrics as well\nloss, metrics = optimize_step(\nmodel, optimizer, loss_fn, data, device=device\n)\nrunning_loss += loss.item()\nloss = running_loss / (i + 1)\nelse:\nraise NotImplementedError(\"Unsupported dataloader type!\")\nif iteration % config.print_every == 0:\nprint_metrics(loss, metrics, iteration)\nif iteration % config.write_every == 0:\nwrite_tensorboard(writer, loss, metrics, iteration)\nif config.folder:\nif iteration % config.checkpoint_every == 0:\nwrite_checkpoint(config.folder, model, optimizer, iteration)\nexcept KeyboardInterrupt:\nprint(\"Terminating training gracefully after the current iteration.\")\nbreak\n# Final writing and checkpointing\nif config.folder:\nwrite_checkpoint(config.folder, model, optimizer, iteration)\nwrite_tensorboard(writer, loss, metrics, iteration)\nwriter.close()\nreturn model, optimizer\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.train_no_grad.train","title":"<code>train(model, dataloader, optimizer, config, loss_fn)</code>","text":"<p>Runs the training loop with a gradient-free optimizer</p> <p>Assumes that <code>loss_fn</code> returns a tuple of (loss, metrics: dict), where <code>metrics</code> is a dict of scalars. Loss and metrics are written to tensorboard. Checkpoints are written every <code>config.checkpoint_every</code> steps (and after the last training step).  If a checkpoint is found at <code>config.folder</code> we resume training from there.  The tensorboard logs can be viewed via <code>tensorboard --logdir /path/to/folder</code>.</p> PARAMETER  DESCRIPTION <code>model</code> <p>The model to train</p> <p> TYPE: <code>Module</code> </p> <code>dataloader</code> <p>Dataloader constructed via <code>dictdataloader</code></p> <p> TYPE: <code>DictDataLoader | DataLoader | None</code> </p> <code>optimizer</code> <p>The optimizer to use taken from the Nevergrad library. If this is not the case the function will raise an AssertionError</p> <p> TYPE: <code>Optimizer</code> </p> <code>loss_fn</code> <p>Loss function returning (loss: float, metrics: dict[str, float])</p> <p> TYPE: <code>Callable</code> </p> Source code in <code>qadence/ml_tools/train_no_grad.py</code> <pre><code>def train(\nmodel: Module,\ndataloader: DictDataLoader | DataLoader | None,\noptimizer: NGOptimizer,\nconfig: TrainConfig,\nloss_fn: Callable,\n) -&gt; tuple[Module, NGOptimizer]:\n\"\"\"Runs the training loop with a gradient-free optimizer\n    Assumes that `loss_fn` returns a tuple of (loss, metrics: dict), where\n    `metrics` is a dict of scalars. Loss and metrics are written to\n    tensorboard. Checkpoints are written every `config.checkpoint_every` steps\n    (and after the last training step).  If a checkpoint is found at `config.folder`\n    we resume training from there.  The tensorboard logs can be viewed via\n    `tensorboard --logdir /path/to/folder`.\n    Args:\n        model: The model to train\n        dataloader: Dataloader constructed via `dictdataloader`\n        optimizer: The optimizer to use taken from the Nevergrad library. If this is not\n            the case the function will raise an AssertionError\n        loss_fn: Loss function returning (loss: float, metrics: dict[str, float])\n    \"\"\"\ninit_iter = 0\nif config.folder:\nmodel, optimizer, init_iter = load_checkpoint(config.folder, model, optimizer)\nlogger.debug(f\"Loaded model and optimizer from {config.folder}\")\ndef _update_parameters(\ndata: Tensor | None, ng_params: ng.p.Array\n) -&gt; tuple[float, dict, ng.p.Array]:\nloss, metrics = loss_fn(model, data)  # type: ignore[misc]\noptimizer.tell(ng_params, float(loss))\nng_params = optimizer.ask()  # type: ignore [assignment]\nparams = promote_to_tensor(ng_params.value, requires_grad=False)\nset_parameters(model, params)\nreturn loss, metrics, ng_params\nassert loss_fn is not None, \"Provide a valid loss function\"\n# TODO: support also Scipy optimizers\nassert isinstance(optimizer, NGOptimizer), \"Use only optimizers from the Nevergrad library\"\n# initialize tensorboard\nwriter = SummaryWriter(config.folder, purge_step=init_iter)\n# set optimizer configuration and initial parameters\noptimizer.budget = config.max_iter\noptimizer.enable_pickling()\n# TODO: Make it GPU compatible if possible\nparams = get_parameters(model).detach().numpy()\nng_params = ng.p.Array(init=params)\n# serial training\n# TODO: Add a parallelization using the num_workers argument in Nevergrad\nprogress = Progress(\nTextColumn(\"[progress.description]{task.description}\"),\nBarColumn(),\nTaskProgressColumn(),\nTimeRemainingColumn(elapsed_when_finished=True),\n)\nwith progress:\ndl_iter = iter(dataloader) if isinstance(dataloader, DictDataLoader) else None\nfor iteration in progress.track(range(init_iter, init_iter + config.max_iter)):\nif dataloader is None:\nloss, metrics, ng_params = _update_parameters(None, ng_params)\nelif isinstance(dataloader, DictDataLoader):\n# resample all the time from the dataloader\n# by creating a fresh iterator if the dataloader\n# does not support automatically iterating datasets\nif not dataloader.has_automatic_iter:\ndl_iter = iter(dataloader)\ndata = next(dl_iter)  # type: ignore[arg-type]\nloss, metrics, ng_params = _update_parameters(data, ng_params)\nelif isinstance(dataloader, DataLoader):\n# single-epoch with standard DataLoader\n# otherwise a standard PyTorch DataLoader behavior\n# is assumed with optional mini-batches\nrunning_loss = 0.0\nfor i, data in enumerate(dataloader):\nloss, metrics, ng_params = _update_parameters(data, ng_params)\nrunning_loss += loss\nloss = running_loss / (i + 1)\nelse:\nraise NotImplementedError(\"Unsupported dataloader type!\")\nif iteration % config.print_every == 0:\nprint_metrics(loss, metrics, iteration)\nif iteration % config.write_every == 0:\nwrite_tensorboard(writer, loss, metrics, iteration)\nif config.folder:\nif iteration % config.checkpoint_every == 0:\nwrite_checkpoint(config.folder, model, optimizer, iteration)\nif iteration &gt;= init_iter + config.max_iter:\nbreak\n## Final writing and stuff\nif config.folder:\nwrite_checkpoint(config.folder, model, optimizer, iteration)\nwrite_tensorboard(writer, loss, metrics, iteration)\nwriter.close()\nreturn model, optimizer\n</code></pre>"},{"location":"qadence/operations/","title":"Operations","text":"<p>Operations are common <code>PrimitiveBlocks</code>, these are often called gates elsewhere.</p>"},{"location":"qadence/operations/#constant-blocks","title":"Constant blocks","text":"<p>CY gate not implemented</p>"},{"location":"qadence/operations/#qadence.operations.X","title":"<code>X(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The X gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.Y","title":"<code>Y(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Y gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.Z","title":"<code>Z(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Z gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.I","title":"<code>I(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The identity gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.H","title":"<code>H(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Hadamard or H gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = (1 / np.sqrt(2)) * (X(target) + Z(target) - np.sqrt(2) * I(target))\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.S","title":"<code>S(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The S / Phase gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.SDagger","title":"<code>SDagger(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Hermitian adjoint/conjugate transpose of the S / Phase gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.SWAP","title":"<code>SWAP(control, target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The SWAP gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, control: int, target: int) -&gt; None:\na11 = 0.5 * (Z(control) - I(control))\na22 = -0.5 * (Z(target) + I(target))\na12 = 0.5 * (chain(X(control), Z(control)) + X(control))\na21 = 0.5 * (chain(Z(target), X(target)) + X(target))\nself.generator = (\nkron(-1.0 * a22, a11) + kron(-1.0 * a11, a22) + kron(a12, a21) + kron(a21, a12)\n)\nsuper().__init__((control, target))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.T","title":"<code>T(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The T gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.TDagger","title":"<code>TDagger(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Hermitian adjoint/conjugate transpose of the T gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CNOT","title":"<code>CNOT(control, target)</code>","text":"<p>             Bases: <code>ControlBlock</code></p> <p>The CNot, or CX, gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, control: int, target: int) -&gt; None:\nself.generator = kron((I(control) - Z(control)) * 0.5, X(target) - I(target))\nsuper().__init__((control,), X(target))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CZ","title":"<code>CZ(control, target)</code>","text":"<p>             Bases: <code>MCZ</code></p> <p>The CZ gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, control: int, target: int) -&gt; None:\nsuper().__init__((control,), target)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CPHASE","title":"<code>CPHASE(control, target, parameter)</code>","text":"<p>             Bases: <code>MCPHASE</code></p> <p>The CPHASE gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ncontrol: int,\ntarget: int,\nparameter: Parameter | TNumber | sympy.Expr | str,\n):\nsuper().__init__((control,), target, parameter)\n</code></pre>"},{"location":"qadence/operations/#parametrized-blocks","title":"Parametrized blocks","text":""},{"location":"qadence/operations/#qadence.operations.RX","title":"<code>RX(target, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The Rx gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TParameter | ParamMap):\n# TODO: should we give them more meaningful names? like 'angle'?\nself.parameters = (\nparameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n)\nself.generator = X(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.RY","title":"<code>RY(target, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The Ry gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TParameter | ParamMap):\nself.parameters = (\nparameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n)\nself.generator = Y(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.RZ","title":"<code>RZ(target, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The Rz gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TParameter | ParamMap):\nself.parameters = (\nparameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n)\nself.generator = Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CRX","title":"<code>CRX(control, target, parameter)</code>","text":"<p>             Bases: <code>MCRX</code></p> <p>The CRX gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ncontrol: int,\ntarget: int,\nparameter: Parameter | TNumber | sympy.Expr | str,\n):\nsuper().__init__((control,), target, parameter)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CRY","title":"<code>CRY(control, target, parameter)</code>","text":"<p>             Bases: <code>MCRY</code></p> <p>The CRY gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ncontrol: int,\ntarget: int,\nparameter: Parameter | TNumber | sympy.Expr | str,\n):\nsuper().__init__((control,), target, parameter)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CRZ","title":"<code>CRZ(control, target, parameter)</code>","text":"<p>             Bases: <code>MCRZ</code></p> <p>The CRZ gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ncontrol: int,\ntarget: int,\nparameter: Parameter | TNumber | sympy.Expr | str,\n):\nsuper().__init__((control,), target, parameter)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.PHASE","title":"<code>PHASE(target, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The Parametric Phase / S gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TNumber | sympy.Expr | str):\nself.parameters = ParamMap(parameter=parameter)\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#hamiltonian-evolution","title":"Hamiltonian Evolution","text":"<p>AnalogSWAP should be turned into a proper analog block</p>"},{"location":"qadence/operations/#qadence.operations.HamEvo","title":"<code>HamEvo(generator, parameter, qubit_support=None)</code>","text":"<p>             Bases: <code>TimeEvolutionBlock</code></p> A block implementing the Hamiltonian evolution operation H where <p>H = exp(-iG, t)</p> <p>where G represents a square generator and t represents the time parameter which can be parametrized.</p> PARAMETER  DESCRIPTION <code>generator</code> <p>Either a AbstractBlock, torch.Tensor or numpy.ndarray.</p> <p> TYPE: <code>Union[TGenerator, AbstractBlock]</code> </p> <code>parameter</code> <p>A scalar or vector of numeric or torch.Tensor type.</p> <p> TYPE: <code>TParameter</code> </p> <code>qubit_support</code> <p>The qubits on which the evolution will be performed on.</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>from qadence import RX, HamEvo, run\nimport torch\nhevo = HamEvo(generator=RX(0, torch.pi), parameter=torch.rand(2))\nprint(run(hevo))\n# Now lets use a torch.Tensor as a generator, Now we have to pass the support\ngen = torch.rand(2,2, dtype=torch.complex128)\nhevo = HamEvo(generator=gen, parameter=torch.rand(2), qubit_support=(0,))\nprint(run(hevo))\n</code></pre> <pre><code>tensor([[ 1.1399-3.6499e-17j, -0.5471+1.7518e-17j],\n[ 1.3490-6.7151e-17j, -0.9055+4.5072e-17j]])\ntensor([[1.0977-0.3999j, 0.3273-0.0901j],\n[1.0129-1.3459j, 0.7903-0.5616j]])\n</code></pre> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ngenerator: Union[TGenerator, AbstractBlock],\nparameter: TParameter,\nqubit_support: tuple[int, ...] = None,\n):\ngen_exprs = {}\nif qubit_support is None and not isinstance(generator, AbstractBlock):\nraise ValueError(\"You have to supply a qubit support for non-block generators.\")\nsuper().__init__(qubit_support if qubit_support else generator.qubit_support)\nif isinstance(generator, AbstractBlock):\nqubit_support = generator.qubit_support\nif generator.is_parametric:\ngen_exprs = {str(e): e for e in expressions(generator)}\nelif isinstance(generator, torch.Tensor):\nmsg = \"Please provide a square generator.\"\nif len(generator.shape) == 2:\nassert generator.shape[0] == generator.shape[1], msg\nelif len(generator.shape) == 3:\nassert generator.shape[1] == generator.shape[2], msg\nassert generator.shape[0] == 1, \"Qadence doesnt support batched generators.\"\nelse:\nraise TypeError(\n\"Only 2D or 3D generators are supported.\\\n                            In case of a 3D generator, the batch dim\\\n                            is expected to be at dim 0.\"\n)\ngen_exprs = {str(generator.__hash__()): generator}\nelif isinstance(generator, (sympy.Basic, sympy.Array)):\ngen_exprs = {str(generator): generator}\nelse:\nraise TypeError(\nf\"Generator of type {type(generator)} not supported.\\\n                        If you're using a numpy.ndarray, please cast it to a torch tensor.\"\n)\nps = {\"parameter\": Parameter(parameter), **gen_exprs}\nself.parameters = ParamMap(**ps)\nself.generator = generator\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.HamEvo.digital_decomposition","title":"<code>digital_decomposition(approximation=LTSOrder.ST4)</code>","text":"<p>Decompose the Hamiltonian evolution into digital gates</p> PARAMETER  DESCRIPTION <code>approximation</code> <p>Choose the type of decomposition. Defaults to \"st4\". Available types are: * 'basic' = apply first-order Trotter formula and decompose each term of     the exponential into digital gates. It is exact only if applied to an     operator whose terms are mutually commuting. * 'st2' = Trotter-Suzuki 2nd order formula for approximating non-commuting     Hamiltonians. * 'st4' = Trotter-Suzuki 4th order formula for approximating non-commuting     Hamiltonians.</p> <p> TYPE: <code>str</code> DEFAULT: <code>ST4</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>a block with the digital decomposition</p> <p> TYPE: <code>AbstractBlock</code> </p> Source code in <code>qadence/operations.py</code> <pre><code>def digital_decomposition(self, approximation: LTSOrder = LTSOrder.ST4) -&gt; AbstractBlock:\n\"\"\"Decompose the Hamiltonian evolution into digital gates\n    Args:\n        approximation (str, optional): Choose the type of decomposition. Defaults to \"st4\".\n            Available types are:\n            * 'basic' = apply first-order Trotter formula and decompose each term of\n                the exponential into digital gates. It is exact only if applied to an\n                operator whose terms are mutually commuting.\n            * 'st2' = Trotter-Suzuki 2nd order formula for approximating non-commuting\n                Hamiltonians.\n            * 'st4' = Trotter-Suzuki 4th order formula for approximating non-commuting\n                Hamiltonians.\n    Returns:\n        AbstractBlock: a block with the digital decomposition\n    \"\"\"\n# psi(t) = exp(-i * H * t * psi0)\n# psi(t) = exp(-i * lambda * t * psi0)\n# H = sum(Paulin) + sum(Pauli1*Pauli2)\nlogger.info(\"Quantum simulation of the time-independent Schr\u00f6dinger equation.\")\nblocks = []\n# how to change the type/dict to enum effectively\n# when there is a term including non-commuting matrices use st2 or st4\n# 1) should check that the given generator respects the constraints\n# single-qubit gates\nassert isinstance(\nself.generator, AbstractBlock\n), \"Only a generator represented as a block can be decomposed\"\nif block_is_qubit_hamiltonian(self.generator):\ntry:\nblock_is_commuting_hamiltonian(self.generator)\napproximation = LTSOrder.BASIC  # use the simpler approach if the H is commuting\nexcept TypeError:\nlogger.warning(\n\"\"\"Non-commuting terms in the Pauli operator.\n                The Suzuki-Trotter approximation is applied.\"\"\"\n)\nblocks.extend(\nlie_trotter_suzuki(\nblock=self.generator,\nparameter=self.parameters.parameter,\norder=LTSOrder[approximation],\n)\n)\n# 2) return an AbstractBlock instance with the set of gates\n# resulting from the decomposition\nreturn chain(*blocks)\nelse:\nraise NotImplementedError(\n\"The current digital decomposition can be applied only to Pauli Hamiltonians.\"\n)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.AnalogSWAP","title":"<code>AnalogSWAP(control, target, parameter=3 * np.pi / 4)</code>","text":"<p>             Bases: <code>HamEvo</code></p> <p>Single time-independent Hamiltonian evolution over a Rydberg Ising hamiltonian yielding a SWAP (up to global phase).</p> <p>Derived from Bapat et al. where it is applied to XX-type Hamiltonian</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, control: int, target: int, parameter: TParameter = 3 * np.pi / 4):\nrydberg_ising_hamiltonian_generator = (\n4.0 * kron((I(control) - Z(control)) / 2.0, (I(target) - Z(target)) / 2.0)\n+ (2.0 / 3.0) * np.sqrt(2.0) * X(control)\n+ (2.0 / 3.0) * np.sqrt(2.0) * X(target)\n+ (1.0 + np.sqrt(5.0) / 3) * Z(control)\n+ (1.0 + np.sqrt(5.0) / 3) * Z(target)\n)\nsuper().__init__(rydberg_ising_hamiltonian_generator, parameter, (control, target))\n</code></pre>"},{"location":"qadence/operations/#analog-blocks","title":"Analog blocks","text":""},{"location":"qadence/operations/#qadence.operations.AnalogRX","title":"<code>AnalogRX(angle, qubit_support='global')</code>","text":"<p>Analog X rotation. Shorthand for <code>AnalogRot</code>:</p> <pre><code>\u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\nAnalogRot(duration=t, omega=\u03a9)\n</code></pre> PARAMETER  DESCRIPTION <code>angle</code> <p>Rotation angle [rad]</p> <p> TYPE: <code>float | str | Parameter</code> </p> <code>qubit_support</code> <p>Defines the (local/global) qubit support</p> <p> TYPE: <code>str | QubitSupport | Tuple</code> DEFAULT: <code>'global'</code> </p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations.py</code> <pre><code>def AnalogRX(\nangle: float | str | Parameter,\nqubit_support: str | QubitSupport | Tuple = \"global\",\n) -&gt; ConstantAnalogRotation:\n\"\"\"Analog X rotation. Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n    ```python\n    \u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\n    AnalogRot(duration=t, omega=\u03a9)\n    ```\n    Arguments:\n        angle: Rotation angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\nreturn _analog_rot(angle, qubit_support, phase=0)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.AnalogRY","title":"<code>AnalogRY(angle, qubit_support='global')</code>","text":"<p>Analog Y rotation. Shorthand for <code>AnalogRot</code>:</p> <p><pre><code>\u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\nAnalogRot(duration=t, omega=\u03a9, phase=-\u03c0/2)\n</code></pre> Arguments:     angle: Rotation angle [rad]     qubit_support: Defines the (local/global) qubit support</p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations.py</code> <pre><code>def AnalogRY(\nangle: float | str | Parameter,\nqubit_support: str | QubitSupport | Tuple = \"global\",\n) -&gt; ConstantAnalogRotation:\n\"\"\"Analog Y rotation. Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n    ```python\n    \u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\n    AnalogRot(duration=t, omega=\u03a9, phase=-\u03c0/2)\n    ```\n    Arguments:\n        angle: Rotation angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\nreturn _analog_rot(angle, qubit_support, phase=-np.pi / 2)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.AnalogRZ","title":"<code>AnalogRZ(angle, qubit_support='global')</code>","text":"<p>Analog Z rotation. Shorthand for <code>AnalogRot</code>: <pre><code>\u03c6=2.4; \u03b4=\u03c0; t = \u03c6/\u03b4 * 100)\nAnalogRot(duration=t, delta=\u03b4, phase=\u03c0/2)\n</code></pre></p> Source code in <code>qadence/operations.py</code> <pre><code>def AnalogRZ(\nangle: float | str | Parameter,\nqubit_support: str | QubitSupport | Tuple = \"global\",\n) -&gt; ConstantAnalogRotation:\n\"\"\"Analog Z rotation. Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n    ```\n    \u03c6=2.4; \u03b4=\u03c0; t = \u03c6/\u03b4 * 100)\n    AnalogRot(duration=t, delta=\u03b4, phase=\u03c0/2)\n    ```\n    \"\"\"\nq = _cast(QubitSupport, qubit_support)\nalpha = _cast(Parameter, angle)\ndelta = np.pi\nduration = alpha / delta * 1000\nps = ParamMap(alpha=alpha, duration=duration, omega=0, delta=delta, phase=np.pi / 2)\nreturn ConstantAnalogRotation(qubit_support=q, parameters=ps)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.AnalogRot","title":"<code>AnalogRot(duration=1000.0, omega=0, delta=0, phase=0, qubit_support='global')</code>","text":"<p>General analog rotation operation.</p> PARAMETER  DESCRIPTION <code>duration</code> <p>Duration of the rotation [ns].</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>1000.0</code> </p> <code>omega</code> <p>Rotation frequency [rad/\u03bcs]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>delta</code> <p>Rotation frequency [rad/\u03bcs]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>phase</code> <p>Phase angle [rad]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>qubit_support</code> <p>Defines the (local/global) qubit support</p> <p> TYPE: <code>str | QubitSupport | Tuple</code> DEFAULT: <code>'global'</code> </p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations.py</code> <pre><code>def AnalogRot(\nduration: float | str | Parameter = 1000.0,\nomega: float | str | Parameter = 0,\ndelta: float | str | Parameter = 0,\nphase: float | str | Parameter = 0,\nqubit_support: str | QubitSupport | Tuple = \"global\",\n) -&gt; ConstantAnalogRotation:\n\"\"\"General analog rotation operation.\n    Arguments:\n        duration: Duration of the rotation [ns].\n        omega: Rotation frequency [rad/\u03bcs]\n        delta: Rotation frequency [rad/\u03bcs]\n        phase: Phase angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\nq = _cast(QubitSupport, qubit_support)\nif isinstance(duration, str):\nduration = Parameter(duration)\nalpha = duration * sympy.sqrt(omega**2 + delta**2) / 1000  # type: ignore [operator]\nps = ParamMap(alpha=alpha, duration=duration, omega=omega, delta=delta, phase=phase)\nreturn ConstantAnalogRotation(parameters=ps, qubit_support=q)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.wait","title":"<code>wait(duration, qubit_support='global')</code>","text":"<p>Constructs a <code>WaitBlock</code>.</p> PARAMETER  DESCRIPTION <code>duration</code> <p>Time to wait in nanoseconds.</p> <p> TYPE: <code>TNumber | Basic</code> </p> <code>qubit_support</code> <p>Qubits the <code>WaitBlock</code> is applied to. Can be either <code>\"global\"</code> to apply the wait block to all qubits or a tuple of integers.</p> <p> TYPE: <code>str | QubitSupport | tuple</code> DEFAULT: <code>'global'</code> </p> RETURNS DESCRIPTION <code>WaitBlock</code> <p>a <code>WaitBlock</code></p> Source code in <code>qadence/operations.py</code> <pre><code>def wait(\nduration: TNumber | sympy.Basic,\nqubit_support: str | QubitSupport | tuple = \"global\",\n) -&gt; WaitBlock:\n\"\"\"Constructs a [`WaitBlock`][qadence.blocks.analog.WaitBlock].\n    Arguments:\n        duration: Time to wait in nanoseconds.\n        qubit_support: Qubits the `WaitBlock` is applied to. Can be either\n            `\"global\"` to apply the wait block to all qubits or a tuple of integers.\n    Returns:\n        a `WaitBlock`\n    \"\"\"\nq = _cast(QubitSupport, qubit_support)\nps = ParamMap(duration=duration)\nreturn WaitBlock(parameters=ps, qubit_support=q)\n</code></pre>"},{"location":"qadence/parameters/","title":"Parameters","text":""},{"location":"qadence/parameters/#parameters","title":"Parameters","text":""},{"location":"qadence/parameters/#qadence.parameters.ParamMap","title":"<code>ParamMap(**kwargs)</code>","text":"<p>Connects UUIDs of parameters to their expressions and names. This class is not user-facing and only needed for more complex block definitions. It provides convenient access to expressions/UUIDs/names needed in different backends.</p> PARAMETER  DESCRIPTION <code>kwargs</code> <p>Parameters.</p> <p> TYPE: <code>str | TNumber | Tensor | Basic | Parameter</code> DEFAULT: <code>{}</code> </p> <p>Example: <pre><code>import sympy\nfrom qadence.parameters import ParamMap\n(x,y) = sympy.symbols(\"x y\")\nps = ParamMap(omega=2.0, duration=x+y)\nprint(f\"{ps.names() = }\")\nprint(f\"{ps.expressions() = }\")\nprint(f\"{ps.uuids() = }\")\n</code></pre> <pre><code>ps.names() = dict_keys(['omega', 'duration'])\nps.expressions() = dict_values([2.00000000000000, x + y])\nps.uuids() = dict_keys(['fbe20a27-921f-489b-b697-00459c096c6d', '964a94c7-501f-4b53-824c-0e3f1c474e50'])\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def __init__(self, **kwargs: str | TNumber | Tensor | Basic | Parameter):\nself._name_dict: dict[str, tuple[str, Basic]] = {}\nself._uuid_dict: dict[str, str] = {}\nfor name, v in kwargs.items():\nparam = v if isinstance(v, sympy.Basic) else Parameter(v)\nuuid = str(uuid4())\nself._name_dict[name] = (uuid, param)\nself._uuid_dict[uuid] = param\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.Parameter","title":"<code>Parameter</code>","text":"<p>             Bases: <code>Symbol</code></p> <p>A wrapper on top of <code>sympy.Symbol</code> to include two additional keywords: <code>trainable</code> and <code>value</code>. This class is to define both feature parameter and variational parameters.</p>"},{"location":"qadence/parameters/#qadence.parameters.Parameter.trainable","title":"<code>trainable: bool</code>  <code>instance-attribute</code>","text":"<p>Trainable parameters are variational parameters. Non-trainable parameters are feature parameters.</p>"},{"location":"qadence/parameters/#qadence.parameters.Parameter.value","title":"<code>value: TNumber</code>  <code>instance-attribute</code>","text":"<p>(Initial) value of the parameter.</p>"},{"location":"qadence/parameters/#qadence.parameters.Parameter.__new__","title":"<code>__new__(name, **assumptions)</code>","text":"PARAMETER  DESCRIPTION <code>name</code> <p>When given a string only, the class constructs a trainable Parameter with a a randomly initialized value.</p> <p> TYPE: <code>str | TNumber | Tensor | Basic | Parameter</code> </p> <code>**assumptions</code> <p>are passed on to the parent class <code>sympy.Symbol</code>. Two new assumption kwargs are supported by this constructor: <code>trainable: bool</code>, and <code>value: TNumber</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> <p>Example: <pre><code>from qadence import Parameter, VariationalParameter\ntheta = Parameter(\"theta\")\nprint(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\nassert not theta.is_number\n# you can specify both trainable/value in the constructor\ntheta = Parameter(\"theta\", trainable=True, value=2.0)\nprint(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n# VariationalParameter/FeatureParameter are constructing\n# trainable/untrainable Parameters\ntheta = VariationalParameter(\"theta\", value=2.0)\nassert theta == Parameter(\"theta\", trainable=True, value=2.0)\n# When provided with a numeric type, Parameter constructs a sympy numeric type\":\nconstant_zero = Parameter(0)\nassert constant_zero.is_number\n# When passed a Parameter or a sympy expression, it just returns it.\nexpr = Parameter(\"x\") * Parameter(\"y\")\nprint(f\"{expr=} : {expr.free_symbols}\")\n</code></pre> <pre><code>theta: trainable=True value=0.10140800929297022\ntheta: trainable=True value=2.0\nexpr=x*y : {y, x}\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def __new__(\ncls, name: str | TNumber | Tensor | Basic | Parameter, **assumptions: Any\n) -&gt; Parameter | Basic | Expr | Array:\n\"\"\"\n    Arguments:\n        name: When given a string only, the class\n            constructs a trainable Parameter with a a randomly initialized value.\n        **assumptions: are passed on to the parent class `sympy.Symbol`. Two new assumption\n            kwargs are supported by this constructor: `trainable: bool`, and `value: TNumber`.\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import Parameter, VariationalParameter\n    theta = Parameter(\"theta\")\n    print(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n    assert not theta.is_number\n    # you can specify both trainable/value in the constructor\n    theta = Parameter(\"theta\", trainable=True, value=2.0)\n    print(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n    # VariationalParameter/FeatureParameter are constructing\n    # trainable/untrainable Parameters\n    theta = VariationalParameter(\"theta\", value=2.0)\n    assert theta == Parameter(\"theta\", trainable=True, value=2.0)\n    # When provided with a numeric type, Parameter constructs a sympy numeric type\":\n    constant_zero = Parameter(0)\n    assert constant_zero.is_number\n    # When passed a Parameter or a sympy expression, it just returns it.\n    expr = Parameter(\"x\") * Parameter(\"y\")\n    print(f\"{expr=} : {expr.free_symbols}\")\n    ```\n    \"\"\"\np: Parameter\nif isinstance(name, get_args(TNumber)):\nreturn sympify(name)\nelif isinstance(name, Tensor):\nif name.numel() == 1:\nreturn sympify(name)\nelse:\nreturn Array(name.detach().numpy())\nelif isinstance(name, Parameter):\np = super().__new__(cls, name.name, **assumptions)\np.name = name.name\np.trainable = name.trainable\np.value = name.value\nreturn p\nelif isinstance(name, (Basic, Expr)):\nif name.is_number:\nreturn sympify(evaluate(name))\nreturn name\nelif isinstance(name, str):\np = super().__new__(cls, name, **assumptions)\np.trainable = assumptions.get(\"trainable\", True)\np.value = assumptions.get(\"value\", None)\nif p.value is None:\np.value = torch.rand(1).item()\nreturn p\nelse:\nraise TypeError(f\"Parameter does not support type {type(name)}\")\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.FeatureParameter","title":"<code>FeatureParameter(name, **kwargs)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=False)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def FeatureParameter(name: str, **kwargs: Any) -&gt; Parameter:\n\"\"\"Shorthand for `Parameter(..., trainable=False)`.\"\"\"\nreturn Parameter(name, trainable=False, **kwargs)\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.VariationalParameter","title":"<code>VariationalParameter(name, **kwargs)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=True)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def VariationalParameter(name: str, **kwargs: Any) -&gt; Parameter:\n\"\"\"Shorthand for `Parameter(..., trainable=True)`.\"\"\"\nreturn Parameter(name, trainable=True, **kwargs)\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.evaluate","title":"<code>evaluate(expr, values={}, as_torch=False)</code>","text":"PARAMETER  DESCRIPTION <code>expr</code> <p>An expression consisting of Parameters.</p> <p> TYPE: <code>Expr</code> </p> <code>values</code> <p>values dict which contains values for the Parameters, if empty, Parameter.value will be used.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>as_torch</code> <p>Whether to retrieve a torch-differentiable expression result.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Example: <pre><code>from qadence.parameters import Parameter, evaluate\nexpr = Parameter(\"x\") * Parameter(\"y\")\n# Unless specified, Parameter initialized random values\n# Lets evaluate this expression and see what the result is\nres = evaluate(expr)\nprint(res)\n# We can also evaluate the expr using a custom dict\nd = {\"x\": 1, \"y\":2}\nres = evaluate(expr, d)\nprint(res)\n# Lastly, if we want a differentiable result, lets put the as_torch flag\nres = evaluate(expr, d, as_torch=True)\nprint(res)\n</code></pre> <pre><code>0.2139500222033144\n2.0\ntensor([2])\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def evaluate(expr: Expr, values: dict = {}, as_torch: bool = False) -&gt; TNumber | Tensor:\n\"\"\"\n    Arguments:\n        expr: An expression consisting of Parameters.\n        values: values dict which contains values for the Parameters,\n            if empty, Parameter.value will be used.\n        as_torch: Whether to retrieve a torch-differentiable expression result.\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.parameters import Parameter, evaluate\n    expr = Parameter(\"x\") * Parameter(\"y\")\n    # Unless specified, Parameter initialized random values\n    # Lets evaluate this expression and see what the result is\n    res = evaluate(expr)\n    print(res)\n    # We can also evaluate the expr using a custom dict\n    d = {\"x\": 1, \"y\":2}\n    res = evaluate(expr, d)\n    print(res)\n    # Lastly, if we want a differentiable result, lets put the as_torch flag\n    res = evaluate(expr, d, as_torch=True)\n    print(res)\n    ```\n    \"\"\"\nres: Basic\nres_value: TNumber | Tensor\nquery: dict[Parameter, TNumber | Tensor] = {}\nif isinstance(expr, Array):\nreturn torch.Tensor(expr.tolist())\nelse:\nif not expr.is_number:\nfor s in expr.free_symbols:\nif s.name in values.keys():\nquery[s] = values[s.name]\nelif hasattr(s, \"value\"):\nquery[s] = s.value\nelse:\nraise ValueError(f\"No value provided for symbol {s.name}\")\nif as_torch:\nres_value = torchify(expr)(**{s.name: torch.tensor(v) for s, v in query.items()})\nelse:\nres = expr.subs(query)\nres_value = sympy_to_numeric(res)\nreturn res_value\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.extract_original_param_entry","title":"<code>extract_original_param_entry(param)</code>","text":"<p>Given an Expression, what was the original \"param\" given by the user? It is either going to be a numeric value, or a sympy Expression (in case a string was given, it was converted via Parameter(\"string\").</p> Source code in <code>qadence/parameters.py</code> <pre><code>def extract_original_param_entry(\nparam: Expr,\n) -&gt; TNumber | Tensor | Expr:\n\"\"\"\n    Given an Expression, what was the original \"param\" given by the user? It is either\n    going to be a numeric value, or a sympy Expression (in case a string was given,\n    it was converted via Parameter(\"string\").\n    \"\"\"\nreturn param if not param.is_number else evaluate(param)\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.torchify","title":"<code>torchify(expr)</code>","text":"PARAMETER  DESCRIPTION <code>expr</code> <p>An expression consisting of Parameters.</p> <p> TYPE: <code>Expr</code> </p> RETURNS DESCRIPTION <code>SymPyModule</code> <p>A torchified, differentiable Expression.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def torchify(expr: Expr) -&gt; SymPyModule:\n\"\"\"\n    Arguments:\n        expr: An expression consisting of Parameters.\n    Returns:\n        A torchified, differentiable Expression.\n    \"\"\"\nextra_funcs = {sympy.core.numbers.ImaginaryUnit: 1.0j}\nreturn SymPyModule(expressions=[expr], extra_funcs=extra_funcs)\n</code></pre>"},{"location":"qadence/parameters/#parameter-embedding","title":"Parameter embedding","text":""},{"location":"qadence/parameters/#qadence.blocks.embedding.embedding","title":"<code>embedding(block, to_gate_params=False)</code>","text":"<p>Construct embedding function which maps user-facing parameters to either expression-level parameters or gate-level parameters. The construced embedding function has the signature:</p> <pre><code> embedding_fn(params: StrTensorDict, inputs: StrTensorDict) -&gt; StrTensorDict:\n</code></pre> <p>which means that it maps the variational parameter dict <code>params</code> and the feature parameter dict <code>inputs</code> to one new parameter dict <code>embedded_dict</code> which holds all parameters that are needed to execute a circuit on a given backend. There are two different modes for this mapping:</p> <ul> <li>Expression-level parameters: For AD-based optimization. For every unique expression we end   up with one entry in the embedded dict:   <code>len(embedded_dict) == len(unique_parameter_expressions)</code>.</li> <li>Gate-level parameters: For PSR-based optimization or real devices. One parameter for each   gate parameter, regardless if they are based on the same expression. <code>len(embedded_dict) ==   len(parametric_gates)</code>. This is needed because PSR requires to shift the angles of every   gate where the same parameter appears.</li> </ul> PARAMETER  DESCRIPTION <code>block</code> <p>parametrized block into which we want to embed parameters.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>to_gate_params</code> <p>A boolean flag whether to generate gate-level parameters or expression-level parameters.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>tuple[StrTensorDict, Callable[[StrTensorDict, StrTensorDict], StrTensorDict]]</code> <p>A tuple with variational parameter dict and the embedding function.</p> Source code in <code>qadence/blocks/embedding.py</code> <pre><code>def embedding(\nblock: AbstractBlock, to_gate_params: bool = False\n) -&gt; tuple[StrTensorDict, Callable[[StrTensorDict, StrTensorDict], StrTensorDict],]:\n\"\"\"Construct embedding function which maps user-facing parameters to either *expression-level*\n    parameters or *gate-level* parameters. The construced embedding function has the signature:\n         embedding_fn(params: StrTensorDict, inputs: StrTensorDict) -&gt; StrTensorDict:\n    which means that it maps the *variational* parameter dict `params` and the *feature* parameter\n    dict `inputs` to one new parameter dict `embedded_dict` which holds all parameters that are\n    needed to execute a circuit on a given backend. There are two different *modes* for this\n    mapping:\n    - *Expression-level* parameters: For AD-based optimization. For every unique expression we end\n      up with one entry in the embedded dict:\n      `len(embedded_dict) == len(unique_parameter_expressions)`.\n    - *Gate-level* parameters: For PSR-based optimization or real devices. One parameter for each\n      gate parameter, regardless if they are based on the same expression. `len(embedded_dict) ==\n      len(parametric_gates)`. This is needed because PSR requires to shift the angles of **every**\n      gate where the same parameter appears.\n    Arguments:\n        block: parametrized block into which we want to embed parameters.\n        to_gate_params: A boolean flag whether to generate gate-level parameters or\n            expression-level parameters.\n    Returns:\n        A tuple with variational parameter dict and the embedding function.\n    \"\"\"\nunique_expressions = unique(expressions(block))\nunique_symbols = [p for p in unique(parameters(block)) if not isinstance(p, sympy.Array)]\nunique_const_matrices = [e for e in unique_expressions if isinstance(e, sympy.Array)]\nunique_expressions = [e for e in unique_expressions if not isinstance(e, sympy.Array)]\n# NOTE\n# there are 3 kinds of parameters in qadence\n# - non-trainable which are considered as inputs for classical data\n# - trainable which are the variational parameters to be optimized\n# - fixed: which are non-trainable parameters with fixed value (e.g. pi/2)\n#\n# both non-trainable and trainable parameters can have the same element applied\n# to different operations in the quantum circuit, e.g. assigning the same parameter\n# to multiple gates.\nnon_numeric_symbols = [p for p in unique_symbols if not p.is_number]\ntrainable_symbols = [p for p in non_numeric_symbols if p.trainable]\nconstant_expressions = [expr for expr in unique_expressions if expr.is_number]\n# we dont need to care about constant symbols if they are contained in an symbolic expression\n# we only care about gate params which are ONLY a constant\nembeddings: dict[sympy.Expr, sympytorch.SymPyModule] = {\nexpr: torchify(expr) for expr in unique_expressions if not expr.is_number\n}\nuuid_to_expr = uuid_to_expression(block)\ndef embedding_fn(params: StrTensorDict, inputs: StrTensorDict) -&gt; StrTensorDict:\nembedded_params: dict[sympy.Expr, Tensor] = {}\nfor expr, fn in embeddings.items():\nangle: Tensor\nvalues = {}\nfor symbol in expr.free_symbols:\nif symbol.name in inputs:\nvalue = inputs[symbol.name]\nelif symbol.name in params:\nvalue = params[symbol.name]\nelse:\nmsg_trainable = \"Trainable\" if symbol.trainable else \"Non-trainable\"\nraise KeyError(\nf\"{msg_trainable} parameter '{symbol.name}' not found in the \"\nf\"inputs list: {list(inputs.keys())} nor the \"\nf\"params list: {list(params.keys())}.\"\n)\nvalues[symbol.name] = value\nangle = fn(**values)\n# do not reshape parameters which are multi-dimensional\n# tensors, such as for example generator matrices\nif not len(angle.squeeze().shape) &gt; 1:\nangle = angle.reshape(-1)\nembedded_params[expr] = angle\nfor e in constant_expressions + unique_const_matrices:\nembedded_params[e] = params[stringify(e)]\nif to_gate_params:\ngate_lvl_params: StrTensorDict = {}\nfor uuid, e in uuid_to_expr.items():\ngate_lvl_params[uuid] = embedded_params[e]\nreturn gate_lvl_params\nelse:\nreturn {stringify(k): v for k, v in embedded_params.items()}\nparams: StrTensorDict\nparams = {p.name: torch.tensor([p.value], requires_grad=True) for p in trainable_symbols}\nparams.update(\n{\nstringify(expr): torch.tensor([evaluate(expr)], requires_grad=False)\nfor expr in constant_expressions\n}\n)\nparams.update(\n{\nstringify(expr): torch.tensor(\nnp.array(expr.tolist(), dtype=np.cdouble), requires_grad=False\n)\nfor expr in unique_const_matrices\n}\n)\nreturn params, embedding_fn\n</code></pre>"},{"location":"qadence/quantumcircuit/","title":"QuantumCircuit","text":""},{"location":"qadence/quantumcircuit/#quantumcircuit","title":"QuantumCircuit","text":"<p>The abstract <code>QuantumCircuit</code> is the key object in Qadence, as it is what can be executed.</p>"},{"location":"qadence/quantumcircuit/#qadence.circuit.QuantumCircuit","title":"<code>QuantumCircuit(support, *blocks)</code>  <code>dataclass</code>","text":"<p>A QuantumCircuit instance is completely abstract and it needs to be passed to a quantum backend in order to be executed.</p> PARAMETER  DESCRIPTION <code>support</code> <p><code>Register</code> or number of qubits. If an integer is provided, a register is constructed with <code>Register.all_to_all(x)</code></p> <p> TYPE: <code>int | Register</code> </p> <code>*blocks</code> <p>(Possibly multiple) blocks to construct the circuit from.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>()</code> </p> Source code in <code>qadence/circuit.py</code> <pre><code>def __init__(self, support: int | Register, *blocks: AbstractBlock):\n\"\"\"\n    Arguments:\n        support: `Register` or number of qubits. If an integer is provided, a register is\n            constructed with `Register.all_to_all(x)`\n        *blocks: (Possibly multiple) blocks to construct the circuit from.\n    \"\"\"\nself.block = chain(*blocks) if len(blocks) != 1 else blocks[0]\nself.register = Register(support) if isinstance(support, int) else support\nglobal_block = isinstance(self.block, AnalogBlock) and self.block.qubit_support.is_global\nif not global_block and len(self.block) and self.block.n_qubits &gt; self.register.n_qubits:\nraise ValueError(\nf\"Register with {self.register.n_qubits} qubits is too small for the \"\nf\"given block with {self.block.n_qubits} qubits\"\n)\n</code></pre>"},{"location":"qadence/quantumcircuit/#qadence.circuit.QuantumCircuit.unique_parameters","title":"<code>unique_parameters: list[Parameter]</code>  <code>property</code>","text":"<p>Return the unique parameters in the circuit</p> <p>These parameters are the actual user-facing parameters which can be assigned by the user. Multiple gates can contain the same unique parameter</p> RETURNS DESCRIPTION <code>list[Parameter]</code> <p>list[Parameter]: List of unique parameters in the circuit</p>"},{"location":"qadence/quantumcircuit/#qadence.circuit.QuantumCircuit.get_blocks_by_tag","title":"<code>get_blocks_by_tag(tag)</code>","text":"<p>Extract one or more blocks using the human-readable tag</p> <p>This function recurservily explores all composite blocks to find all the occurrences of a certain tag in the blocks</p> PARAMETER  DESCRIPTION <code>tag</code> <p>the tag to look for</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>list[AbstractBlock]</code> <p>list[AbstractBlock]: The block(s) corresponding to the given tag</p> Source code in <code>qadence/circuit.py</code> <pre><code>def get_blocks_by_tag(self, tag: str) -&gt; list[AbstractBlock]:\n\"\"\"Extract one or more blocks using the human-readable tag\n    This function recurservily explores all composite blocks to find\n    all the occurrences of a certain tag in the blocks\n    Args:\n        tag (str): the tag to look for\n    Returns:\n        list[AbstractBlock]: The block(s) corresponding to the given tag\n    \"\"\"\ndef _get_block(block: AbstractBlock) -&gt; list[AbstractBlock]:\nblocks = []\nif block.tag == tag:\nblocks += [block]\nif isinstance(block, CompositeBlock):\nblocks += flatten(*[_get_block(b) for b in block.blocks])\nreturn blocks\nreturn _get_block(self.block)\n</code></pre>"},{"location":"qadence/quantumcircuit/#qadence.circuit.QuantumCircuit.parameters","title":"<code>parameters()</code>","text":"<p>Extract all parameters for primitive blocks in the circuit</p> <p>Notice that this function returns all the unique Parameters used in the quantum circuit. These can correspond to constants too.</p> RETURNS DESCRIPTION <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>List[tuple[Parameter]]: A list of tuples containing the Parameter</p> <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>instance of each of the primitive blocks in the circuit or, if the <code>flatten</code></p> <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>flag is set to True, a flattened list of all circuit parameters</p> Source code in <code>qadence/circuit.py</code> <pre><code>def parameters(self) -&gt; list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]:\n\"\"\"Extract all parameters for primitive blocks in the circuit\n    Notice that this function returns all the unique Parameters used\n    in the quantum circuit. These can correspond to constants too.\n    Returns:\n        List[tuple[Parameter]]: A list of tuples containing the Parameter\n        instance of each of the primitive blocks in the circuit or, if the `flatten`\n        flag is set to True, a flattened list of all circuit parameters\n    \"\"\"\nreturn parameters(self.block)\n</code></pre>"},{"location":"qadence/register/","title":"Register","text":""},{"location":"qadence/register/#quantum-registers","title":"Quantum Registers","text":""},{"location":"qadence/register/#qadence.register.Register","title":"<code>Register(support)</code>","text":"<p>A 2D register of qubits which includes their coordinates (needed for e.g. analog computing). The coordinates are ignored in backends that don't need them. The easiest way to construct a register is via its classmethods like <code>Register.triangular_lattice</code>.</p> PARAMETER  DESCRIPTION <code>support</code> <p>A graph or number of qubits. Nodes can include a <code>\"pos\"</code> attribute such that e.g.: <code>graph.nodes = {0: {\"pos\": (2,3)}, 1: {\"pos\": (0,0)}, ...}</code> which will be used in backends that need qubit coordinates. See the classmethods for simple construction of some predefined lattices if you don't want to build a graph manually. If you pass an integer the resulting register is the same as <code>Register.all_to_all(n_qubits)</code>.</p> <p> TYPE: <code>Graph | int</code> </p> <p>Examples: <pre><code>from qadence import Register\nreg = Register.honeycomb_lattice(2,3)\nreg.draw()\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/register.py</code> <pre><code>def __init__(self, support: nx.Graph | int):\n\"\"\"A 2D register of qubits which includes their coordinates (needed for e.g. analog\n    computing). The coordinates are ignored in backends that don't need them. The easiest\n    way to construct a register is via its classmethods like `Register.triangular_lattice`.\n    Arguments:\n        support: A graph or number of qubits. Nodes can include a `\"pos\"` attribute\n            such that e.g.: `graph.nodes = {0: {\"pos\": (2,3)}, 1: {\"pos\": (0,0)}, ...}` which\n            will be used in backends that need qubit coordinates.\n            See the classmethods for simple construction of some predefined lattices if you\n            don't want to build a graph manually.\n            If you pass an integer the resulting register is the same as\n            `Register.all_to_all(n_qubits)`.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import Register\n    reg = Register.honeycomb_lattice(2,3)\n    reg.draw()\n    ```\n    \"\"\"\nself.graph = support if isinstance(support, nx.Graph) else alltoall_graph(support)\n</code></pre>"},{"location":"qadence/register/#qadence.register.line_graph","title":"<code>line_graph(n_qubits, spacing=1.0)</code>","text":"<p>Create graph representing linear lattice.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of nodes in the graph</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Graph</code> <p>graph instance</p> Source code in <code>qadence/register.py</code> <pre><code>def line_graph(n_qubits: int, spacing: float = 1.0) -&gt; nx.Graph:\n\"\"\"Create graph representing linear lattice.\n    Args:\n        n_qubits (int): number of nodes in the graph\n    Returns:\n        graph instance\n    \"\"\"\ngraph = nx.Graph()\nfor i in range(n_qubits):\ngraph.add_node(i, pos=(i * spacing, 0.0))\nfor i, j in zip(range(n_qubits - 1), range(1, n_qubits)):\ngraph.add_edge(i, j)\nreturn graph\n</code></pre>"},{"location":"qadence/serialization/","title":"Serialization","text":""},{"location":"qadence/serialization/#serialization","title":"Serialization","text":""},{"location":"qadence/serialization/#qadence.serialization.deserialize","title":"<code>deserialize(d, as_torch=False)</code>","text":"<p>Supported Types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | Module Deserializes a dict to one of the supported types.</p> PARAMETER  DESCRIPTION <code>d</code> <p>A dict containing a serialized object.</p> <p> TYPE: <code>dict</code> </p> <p>Returns:     AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register, Module.</p> <p>Examples: <pre><code>import torch\nfrom qadence import serialize, deserialize, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nblock_dict = serialize(myblock)\nprint(block_dict)\n## Lets use myblock in a QuantumCircuit and serialize it.\nqc = QuantumCircuit(n_qubits, myblock)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n## Finally, let's wrap it in a QuantumModel\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Lets check if the loaded QuantumModel returns the same expectation\nassert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n</code></pre> <pre><code>{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': 'HEA', 'blocks': [{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('4e21586a-c5ea-4433-a95c-cd4e5073869c', {'name': 'theta_0', 'expression': \"Parameter('theta_0')\", 'symbols': {'theta_0': {'name': 'theta_0', 'trainable': 'True', 'value': '0.5684311223821024'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('bfde1467-821f-415e-8c6e-3c8c3c2c3e33', {'name': 'theta_1', 'expression': \"Parameter('theta_1')\", 'symbols': {'theta_1': {'name': 'theta_1', 'trainable': 'True', 'value': '0.3999646827175872'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RY', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('74c910db-b901-4012-8d0b-5656616e00d7', {'name': 'theta_2', 'expression': \"Parameter('theta_2')\", 'symbols': {'theta_2': {'name': 'theta_2', 'trainable': 'True', 'value': '0.7371985429677512'}}})}}}, {'type': 'RY', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('ff3f7e42-af4b-4d1f-9d3c-19967168372a', {'name': 'theta_3', 'expression': \"Parameter('theta_3')\", 'symbols': {'theta_3': {'name': 'theta_3', 'trainable': 'True', 'value': '0.7247187743783847'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('cc189501-9b58-481b-b04c-9401ef003297', {'name': 'theta_4', 'expression': \"Parameter('theta_4')\", 'symbols': {'theta_4': {'name': 'theta_4', 'trainable': 'True', 'value': '0.8265140180940678'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('87eefb9a-c133-4057-abb1-a17993a269bf', {'name': 'theta_5', 'expression': \"Parameter('theta_5')\", 'symbols': {'theta_5': {'name': 'theta_5', 'trainable': 'True', 'value': '0.29601786363991645'}}})}}}]}]}, {'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'CNOT', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'X', 'qubit_support': (1,), 'tag': None}]}]}]}]}\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def deserialize(d: dict, as_torch: bool = False) -&gt; SUPPORTED_TYPES:\n\"\"\"\n    Supported Types:\n    AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | Module\n    Deserializes a dict to one of the supported types.\n    Arguments:\n        d (dict): A dict containing a serialized object.\n    Returns:\n        AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register, Module.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence import serialize, deserialize, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    block_dict = serialize(myblock)\n    print(block_dict)\n    ## Lets use myblock in a QuantumCircuit and serialize it.\n    qc = QuantumCircuit(n_qubits, myblock)\n    qc_dict = serialize(qc)\n    qc_deserialized = deserialize(qc_dict)\n    assert qc == qc_deserialized\n    ## Finally, let's wrap it in a QuantumModel\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    qm_dict = serialize(qm)\n    qm_deserialized = deserialize(qm_dict)\n    # Lets check if the loaded QuantumModel returns the same expectation\n    assert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n    ```\n    \"\"\"\nobj: Any\nif d.get(\"expression\"):\nexpr = eval(d[\"expression\"])\nif hasattr(expr, \"free_symbols\"):\nfor symb in expr.free_symbols:\nsymb.value = float(d[\"symbols\"][symb.name][\"value\"])\nobj = expr\nelif d.get(\"QuantumModel\"):\nobj = QuantumModel._from_dict(d, as_torch)\nelif d.get(\"QNN\"):\nobj = QNN._from_dict(d, as_torch)\nelif d.get(\"TransformedModule\"):\nobj = TransformedModule._from_dict(d, as_torch)\nelif d.get(\"block\") and d.get(\"register\"):\nobj = QuantumCircuit._from_dict(d)\nelif d.get(\"graph\"):\nobj = Register._from_dict(d)\nelif d.get(\"type\"):\nif d[\"type\"] in ALL_BLOCK_NAMES:\nblock: AbstractBlock = (\ngetattr(operations, d[\"type\"])._from_dict(d)\nif hasattr(operations, d[\"type\"])\nelse getattr(qadenceblocks, d[\"type\"])._from_dict(d)\n)\nif d[\"tag\"] is not None:\nblock = tag(block, d[\"tag\"])\nobj = block\nelse:\nimport warnings\nmsg = warnings.warn(\n\"In order to load a custom torch.nn.Module, make sure its imported in the namespace.\"\n)\ntry:\nmodule_name = list(d.keys())[0]\nobj = getattr(globals(), module_name)\nobj.load_state_dict(d[module_name])\nexcept Exception as e:\nlogger.error(\nTypeError(\nf\"{msg}. Unable to deserialize object due to {e}.\\\n                    Supported objects are: {SUPPORTED_OBJECTS}\"\n)\n)\nreturn obj\n</code></pre>"},{"location":"qadence/serialization/#qadence.serialization.load","title":"<code>load(file_path, map_location='cpu')</code>","text":"<p>Same as serialize/deserialize but for storing/loading files. Supported types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register Loads a .json or .pt file to one of the supported types.</p> PARAMETER  DESCRIPTION <code>file_path</code> <p>The name of the file.</p> <p> TYPE: <code>str</code> </p> <code>map_location</code> <p>In case of a .pt file, on which device to load the object (cpu,cuda).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> <p>Returns:     A object of type AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register.</p> <p>Examples: <pre><code>import torch\nfrom pathlib import Path\nimport os\nfrom qadence import save, load, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nqc = QuantumCircuit(n_qubits, myblock)\n# Lets store the circuit in a json file\nsave(qc, '.', 'circ')\nloaded_qc = load(Path('circ.json'))\nqc == loaded_qc\nos.remove('circ.json')\n## Let's wrap it in a QuantumModel and store that\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nsave(qm, folder= '.',file_name= 'quantum_model')\nqm_loaded = load('quantum_model.json')\nos.remove('quantum_model.json')\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def load(file_path: str | Path, map_location: str = \"cpu\") -&gt; SUPPORTED_TYPES:\n\"\"\"\n    Same as serialize/deserialize but for storing/loading files.\n    Supported types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register\n    Loads a .json or .pt file to one of the supported types.\n    Arguments:\n        file_path (str): The name of the file.\n        map_location (str): In case of a .pt file, on which device to load the object (cpu,cuda).\n    Returns:\n        A object of type AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from pathlib import Path\n    import os\n    from qadence import save, load, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    qc = QuantumCircuit(n_qubits, myblock)\n    # Lets store the circuit in a json file\n    save(qc, '.', 'circ')\n    loaded_qc = load(Path('circ.json'))\n    qc == loaded_qc\n    os.remove('circ.json')\n    ## Let's wrap it in a QuantumModel and store that\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    save(qm, folder= '.',file_name= 'quantum_model')\n    qm_loaded = load('quantum_model.json')\n    os.remove('quantum_model.json')\n    ```\n    \"\"\"\nd = {}\nif isinstance(file_path, str):\nfile_path = Path(file_path)\nif not os.path.exists(file_path):\nlogger.error(f\"File {file_path} not found.\")\nraise FileNotFoundError\nFORMAT = file_extension(file_path)\n_, _, load_fn, _ = FORMAT_DICT[FORMAT]  # type: ignore[index]\ntry:\nd = load_fn(file_path, map_location)\nlogger.debug(f\"Successfully loaded {d} from {file_path}.\")\nexcept Exception as e:\nlogger.error(f\"Unable to load Object from {file_path} due to {e}\")\nreturn deserialize(d)\n</code></pre>"},{"location":"qadence/serialization/#qadence.serialization.save","title":"<code>save(obj, folder, file_name='', format=SerializationFormat.JSON)</code>","text":"<p>Same as serialize/deserialize but for storing/loading files. Supported types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | torch.nn.Module Saves a qadence object to a json/.pt.</p> PARAMETER  DESCRIPTION <code>obj</code> <pre><code>Either AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register.\n</code></pre> <p> TYPE: <code>AbstractBlock | QuantumCircuit | QuantumModel | Register</code> </p> <code>file_name</code> <p>The name of the file.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>format</code> <p>The type of file to save.</p> <p> TYPE: <code>str</code> DEFAULT: <code>JSON</code> </p> <p>Returns:     None.</p> <p>Examples: <pre><code>import torch\nfrom pathlib import Path\nimport os\nfrom qadence import save, load, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nqc = QuantumCircuit(n_qubits, myblock)\n# Lets store the circuit in a json file\nsave(qc, '.', 'circ')\nloaded_qc = load(Path('circ.json'))\nqc == loaded_qc\nos.remove('circ.json')\n## Let's wrap it in a QuantumModel and store that\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nsave(qm, folder= '.',file_name= 'quantum_model')\nqm_loaded = load('quantum_model.json')\nos.remove('quantum_model.json')\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def save(\nobj: SUPPORTED_TYPES,\nfolder: str | Path,\nfile_name: str = \"\",\nformat: SerializationFormat = SerializationFormat.JSON,\n) -&gt; None:\n\"\"\"\n    Same as serialize/deserialize but for storing/loading files.\n    Supported types:\n    AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | torch.nn.Module\n    Saves a qadence object to a json/.pt.\n    Arguments:\n        obj (AbstractBlock | QuantumCircuit | QuantumModel | Register):\n                Either AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register.\n        file_name (str): The name of the file.\n        format (str): The type of file to save.\n    Returns:\n        None.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from pathlib import Path\n    import os\n    from qadence import save, load, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    qc = QuantumCircuit(n_qubits, myblock)\n    # Lets store the circuit in a json file\n    save(qc, '.', 'circ')\n    loaded_qc = load(Path('circ.json'))\n    qc == loaded_qc\n    os.remove('circ.json')\n    ## Let's wrap it in a QuantumModel and store that\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    save(qm, folder= '.',file_name= 'quantum_model')\n    qm_loaded = load('quantum_model.json')\n    os.remove('quantum_model.json')\n    ```\n    \"\"\"\nif not isinstance(obj, get_args(SUPPORTED_TYPES)):\nlogger.error(f\"Serialization of object type {type(obj)} not supported.\")\nfolder = Path(folder)\nif not folder.is_dir():\nlogger.error(NotADirectoryError)\nif file_name == \"\":\nfile_name = type(obj).__name__\ntry:\nsuffix, save_fn, _, save_params = FORMAT_DICT[format]\nd = serialize(obj, save_params)\nfile_path = folder / Path(file_name + suffix)\nsave_fn(d, file_path)\nlogger.debug(f\"Successfully saved {obj} from to {folder}.\")\nexcept Exception as e:\nlogger.error(f\"Unable to write {type(obj)} to disk due to {e}\")\n</code></pre>"},{"location":"qadence/serialization/#qadence.serialization.serialize","title":"<code>serialize(obj, save_params=False)</code>","text":"<p>Supported Types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | Module Serializes a qadence object to a dictionary.</p> PARAMETER  DESCRIPTION <code>obj</code> <p> TYPE: <code>AbstractBlock | QuantumCircuit | QuantumModel | Register | Module</code> </p> <p>Returns:     A dict.</p> <p>Examples: <pre><code>import torch\nfrom qadence import serialize, deserialize, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nblock_dict = serialize(myblock)\nprint(block_dict)\n## Lets use myblock in a QuantumCircuit and serialize it.\nqc = QuantumCircuit(n_qubits, myblock)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n## Finally, let's wrap it in a QuantumModel\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Lets check if the loaded QuantumModel returns the same expectation\nassert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n</code></pre> <pre><code>{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': 'HEA', 'blocks': [{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('bb02298a-0db6-4a39-924b-2e1597fe417d', {'name': 'theta_0', 'expression': \"Parameter('theta_0')\", 'symbols': {'theta_0': {'name': 'theta_0', 'trainable': 'True', 'value': '0.7463305876414196'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('90c756d1-1b2a-4973-94db-27201c9b48ff', {'name': 'theta_1', 'expression': \"Parameter('theta_1')\", 'symbols': {'theta_1': {'name': 'theta_1', 'trainable': 'True', 'value': '0.03877776513563347'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RY', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('1803bb24-e478-47ad-b150-ef7a736c6534', {'name': 'theta_2', 'expression': \"Parameter('theta_2')\", 'symbols': {'theta_2': {'name': 'theta_2', 'trainable': 'True', 'value': '0.6066138129044197'}}})}}}, {'type': 'RY', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('ac1a9b78-cba5-4d63-b1fb-397fdd0a8fc0', {'name': 'theta_3', 'expression': \"Parameter('theta_3')\", 'symbols': {'theta_3': {'name': 'theta_3', 'trainable': 'True', 'value': '0.10912842676989187'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('abce4976-786b-4fc4-94de-d0187002d259', {'name': 'theta_4', 'expression': \"Parameter('theta_4')\", 'symbols': {'theta_4': {'name': 'theta_4', 'trainable': 'True', 'value': '0.29822982454792'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('49666887-a42f-4b81-9257-06445d91e4bf', {'name': 'theta_5', 'expression': \"Parameter('theta_5')\", 'symbols': {'theta_5': {'name': 'theta_5', 'trainable': 'True', 'value': '0.4192989963624322'}}})}}}]}]}, {'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'CNOT', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'X', 'qubit_support': (1,), 'tag': None}]}]}]}]}\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def serialize(obj: SUPPORTED_TYPES, save_params: bool = False) -&gt; dict:\n\"\"\"\n    Supported Types:\n    AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | Module\n    Serializes a qadence object to a dictionary.\n    Arguments:\n        obj (AbstractBlock | QuantumCircuit | QuantumModel | Register | Module):\n    Returns:\n        A dict.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence import serialize, deserialize, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    block_dict = serialize(myblock)\n    print(block_dict)\n    ## Lets use myblock in a QuantumCircuit and serialize it.\n    qc = QuantumCircuit(n_qubits, myblock)\n    qc_dict = serialize(qc)\n    qc_deserialized = deserialize(qc_dict)\n    assert qc == qc_deserialized\n    ## Finally, let's wrap it in a QuantumModel\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    qm_dict = serialize(qm)\n    qm_deserialized = deserialize(qm_dict)\n    # Lets check if the loaded QuantumModel returns the same expectation\n    assert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n    ```\n    \"\"\"\nif not isinstance(obj, get_args(SUPPORTED_TYPES)):\nlogger.error(TypeError(f\"Serialization of object type {type(obj)} not supported.\"))\nd: dict = {}\ntry:\nif isinstance(obj, Expr):\nsymb_dict = {}\nexpr_dict = {\"name\": str(obj), \"expression\": srepr(obj)}\nsymbs: set[Parameter | Basic] = obj.free_symbols\nif symbs:\nsymb_dict = {\"symbols\": {str(s): s._to_dict() for s in symbs}}\nd = {**expr_dict, **symb_dict}\nelif isinstance(obj, (QuantumModel, QNN, TransformedModule)):\nd = obj._to_dict(save_params)\nelif isinstance(obj, torch.nn.Module):\nd = {type(obj).__name__: obj.state_dict()}\nelse:\nd = obj._to_dict()\nexcept Exception as e:\nlogger.error(f\"Serialization of object {obj} failed due to {e}\")\nreturn d\n</code></pre>"},{"location":"qadence/states/","title":"State Preparation","text":""},{"location":"qadence/states/#state-preparation-routines","title":"State Preparation Routines","text":""},{"location":"qadence/states/#qadence.states.ghz_block","title":"<code>ghz_block(n_qubits)</code>","text":"<p>Generates the abstract ghz state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>A ChainBlock representing the GHZ state.</p> <p>Examples: <pre><code>from qadence.states import ghz_block\nblock = ghz_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 ChainBlock(0,1)\n\u2514\u2500\u2500 CNOT(0,1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def ghz_block(n_qubits: int) -&gt; ChainBlock:\n\"\"\"\n    Generates the abstract ghz state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A ChainBlock representing the GHZ state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import ghz_block\n    block = ghz_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\ncnots = chain(CNOT(i - 1, i) for i in range(1, n_qubits))\nreturn chain(H(0), cnots)\n</code></pre>"},{"location":"qadence/states/#qadence.states.ghz_state","title":"<code>ghz_state(n_qubits, batch_size=1)</code>","text":"<p>Creates a GHZ state.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>How many bitstrings to use.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import ghz_state\nprint(ghz_state(n_qubits=2, batch_size=2))\n</code></pre> <pre><code>tensor([[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j],\n[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def ghz_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Creates a GHZ state.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): How many bitstrings to use.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import ghz_state\n    print(ghz_state(n_qubits=2, batch_size=2))\n    ```\n    \"\"\"\nnorm = 1 / torch.sqrt(torch.tensor(2))\nreturn norm * (zero_state(n_qubits, batch_size) + one_state(n_qubits, batch_size))\n</code></pre>"},{"location":"qadence/states/#qadence.states.is_normalized","title":"<code>is_normalized(wf, atol=NORMALIZATION_ATOL)</code>","text":"<p>Checks if a wave function is normalized.</p> PARAMETER  DESCRIPTION <code>wf</code> <p>The wave function as a torch tensor.</p> <p> TYPE: <code>Tensor</code> </p> <code>atol</code> <p>The tolerance.</p> <p> TYPE: <code>float) </code> DEFAULT: <code>NORMALIZATION_ATOL</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>A bool.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, is_normalized\nprint(is_normalized(uniform_state(2)))\n</code></pre> <pre><code>True\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def is_normalized(wf: Tensor, atol: float = NORMALIZATION_ATOL) -&gt; bool:\n\"\"\"\n    Checks if a wave function is normalized.\n    Arguments:\n        wf (torch.Tensor): The wave function as a torch tensor.\n        atol (float) : The tolerance.\n    Returns:\n        A bool.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, is_normalized\n    print(is_normalized(uniform_state(2)))\n    ```\n    \"\"\"\nif wf.dim() == 1:\nwf = wf.unsqueeze(0)\nsum_probs: Tensor = (wf.abs() ** 2).sum(dim=1)\nones = torch.ones_like(sum_probs)\nreturn torch.allclose(sum_probs, ones, rtol=0.0, atol=atol)  # type: ignore[no-any-return]\n</code></pre>"},{"location":"qadence/states/#qadence.states.normalize","title":"<code>normalize(wf)</code>","text":"<p>Normalizes a wavefunction or batch of wave functions.</p> PARAMETER  DESCRIPTION <code>wf</code> <p>Normalized wavefunctions.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, normalize\nprint(normalize(uniform_state(2, 2)))\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j],\n[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def normalize(wf: Tensor) -&gt; Tensor:\n\"\"\"\n    Normalizes a wavefunction or batch of wave functions.\n    Arguments:\n        wf (torch.Tensor): Normalized wavefunctions.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, normalize\n    print(normalize(uniform_state(2, 2)))\n    ```\n    \"\"\"\nif wf.dim() == 1:\nreturn wf / torch.sqrt((wf.abs() ** 2).sum())\nelse:\nreturn wf / torch.sqrt((wf.abs() ** 2).sum(1)).unsqueeze(1)\n</code></pre>"},{"location":"qadence/states/#qadence.states.one_block","title":"<code>one_block(n_qubits)</code>","text":"<p>Generates the abstract one state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the one state.</p> <p>Examples: <pre><code>from qadence.states import one_block\nblock = one_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def one_block(n_qubits: int) -&gt; KronBlock:\n\"\"\"\n    Generates the abstract one state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A KronBlock representing the one state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import one_block\n    block = one_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\nreturn _from_op(X, n_qubits=n_qubits)\n</code></pre>"},{"location":"qadence/states/#qadence.states.one_state","title":"<code>one_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the one state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import one_state\nstate = one_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def one_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Generates the one state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): The batch size.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import one_state\n    state = one_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\nbitstring = \"1\" * n_qubits\nreturn _state_from_bitstring(bitstring, batch_size)\n</code></pre>"},{"location":"qadence/states/#qadence.states.pmf","title":"<code>pmf(wf)</code>","text":"<p>Converts a wave function into a torch Distribution.</p> PARAMETER  DESCRIPTION <code>wf</code> <p>The wave function as a torch tensor.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Distribution</code> <p>A torch.distributions.Distribution.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, pmf\nprint(pmf(uniform_state(2)).probs)\n</code></pre> <pre><code>tensor([[0.2500, 0.2500, 0.2500, 0.2500]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def pmf(wf: Tensor) -&gt; Distribution:\n\"\"\"\n    Converts a wave function into a torch Distribution.\n    Arguments:\n        wf (torch.Tensor): The wave function as a torch tensor.\n    Returns:\n        A torch.distributions.Distribution.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, pmf\n    print(pmf(uniform_state(2)).probs)\n    ```\n    \"\"\"\nreturn Categorical(torch.abs(torch.pow(wf, 2)))\n</code></pre>"},{"location":"qadence/states/#qadence.states.product_block","title":"<code>product_block(bitstring)</code>","text":"<p>Creates an abstract product state from a bitstring.</p> PARAMETER  DESCRIPTION <code>bitstring</code> <p>A bitstring.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the product state.</p> <p>Examples: <pre><code>from qadence.states import product_block\nprint(product_block(\"1100\"))\n</code></pre> <pre><code>KronBlock(0,1,2,3)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u251c\u2500\u2500 I(2)\n\u2514\u2500\u2500 I(3)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def product_block(bitstring: str) -&gt; KronBlock:\n\"\"\"\n    Creates an abstract product state from a bitstring.\n    Arguments:\n        bitstring (str): A bitstring.\n    Returns:\n        A KronBlock representing the product state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import product_block\n    print(product_block(\"1100\"))\n    ```\n    \"\"\"\nreturn _block_from_bitstring(bitstring)\n</code></pre>"},{"location":"qadence/states/#qadence.states.product_state","title":"<code>product_state(bitstring, batch_size=1, endianness=Endianness.BIG)</code>","text":"<p>Creates a product state from a bitstring.</p> PARAMETER  DESCRIPTION <code>bitstring</code> <p>A bitstring.</p> <p> TYPE: <code>str</code> </p> <code>batch_size</code> <p>Batch size.</p> <p> TYPE: <code>int) </code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import product_state\nprint(product_state(\"1100\"))\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>@singledispatch\ndef product_state(\nbitstring: str, batch_size: int = 1, endianness: Endianness = Endianness.BIG\n) -&gt; Tensor:\n\"\"\"\n    Creates a product state from a bitstring.\n    Arguments:\n        bitstring (str): A bitstring.\n        batch_size (int) : Batch size.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import product_state\n    print(product_state(\"1100\"))\n    ```\n    \"\"\"\nreturn _state_from_bitstring(bitstring, batch_size, endianness=endianness)\n</code></pre>"},{"location":"qadence/states/#qadence.states.rand_bitstring","title":"<code>rand_bitstring(N)</code>","text":"<p>Creates a random bistring.</p> PARAMETER  DESCRIPTION <code>N</code> <p>The length of the bitstring.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>str</code> <p>A string.</p> <p>Examples: <pre><code>from qadence.states import rand_bitstring\nprint(rand_bitstring(N=8))\n</code></pre> <pre><code>11110111\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_bitstring(N: int) -&gt; str:\n\"\"\"\n    Creates a random bistring.\n    Arguments:\n        N (int): The length of the bitstring.\n    Returns:\n        A string.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_bitstring\n    print(rand_bitstring(N=8))\n    ```\n    \"\"\"\nreturn \"\".join(str(random.randint(0, 1)) for _ in range(N))\n</code></pre>"},{"location":"qadence/states/#qadence.states.rand_product_block","title":"<code>rand_product_block(n_qubits)</code>","text":"<p>Creates a block representing a random abstract product state.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the product state.</p> <p>Examples: <pre><code>from qadence.states import rand_product_block\nprint(rand_product_block(n_qubits=2))\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 I(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_product_block(n_qubits: int) -&gt; KronBlock:\n\"\"\"\n    Creates a block representing a random abstract product state.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A KronBlock representing the product state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_product_block\n    print(rand_product_block(n_qubits=2))\n    ```\n    \"\"\"\nreturn product_block(rand_bitstring(n_qubits))\n</code></pre>"},{"location":"qadence/states/#qadence.states.rand_product_state","title":"<code>rand_product_state(n_qubits, batch_size=1)</code>","text":"<p>Creates a random product state.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>How many bitstrings to use.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import rand_product_state\nprint(rand_product_state(n_qubits=2, batch_size=2))\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_product_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Creates a random product state.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): How many bitstrings to use.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_product_state\n    print(rand_product_state(n_qubits=2, batch_size=2))\n    ```\n    \"\"\"\nwf_batch = torch.zeros(batch_size, 2**n_qubits, dtype=DTYPE)\nrand_pos = torch.randint(0, 2**n_qubits, (batch_size,))\nwf_batch[torch.arange(batch_size), rand_pos] = torch.tensor(1.0 + 0j, dtype=DTYPE)\nreturn wf_batch\n</code></pre>"},{"location":"qadence/states/#qadence.states.random_state","title":"<code>random_state(n_qubits, batch_size=1, backend=BackendName.PYQTORCH, type=StateGeneratorType.HAAR_MEASURE_FAST)</code>","text":"<p>Generates a random state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>backend</code> <p>The backend to use.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PYQTORCH</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>type</code> <p>StateGeneratorType.</p> <p> DEFAULT: <code>HAAR_MEASURE_FAST</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import random_state, StateGeneratorType\nfrom qadence.states import random_state, is_normalized, pmf\nfrom qadence.backend import BackendName\nfrom torch.distributions import Distribution\n### We have the following options:\nprint([g.value for g in StateGeneratorType])\nn_qubits = 2\n# The default is StateGeneratorType.HAAR_MEASURE_FAST\nstate = random_state(n_qubits=n_qubits)\nprint(state)\n### Lets initialize a state using random rotations, i.e., StateGeneratorType.RANDOM_ROTATIONS.\nrandom = random_state(n_qubits=n_qubits, type=StateGeneratorType.RANDOM_ROTATIONS)\nprint(random)\n</code></pre> <pre><code>['RandomRotations', 'HaarMeasureFast', 'HaarMeasureSlow']\ntensor([[ 0.1372+0.2371j, -0.4552+0.2257j, -0.3039-0.5416j, -0.1540+0.5073j]])\ntensor([[0.5824-0.5747j, 0.0000+0.0000j, 0.4092-0.4038j, 0.0000+0.0000j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def random_state(\nn_qubits: int,\nbatch_size: int = 1,\nbackend: str = BackendName.PYQTORCH,\ntype: StateGeneratorType = StateGeneratorType.HAAR_MEASURE_FAST,\n) -&gt; Tensor:\n\"\"\"\n    Generates a random state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        backend (str): The backend to use.\n        batch_size (int): The batch size.\n        type : StateGeneratorType.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import random_state, StateGeneratorType\n    from qadence.states import random_state, is_normalized, pmf\n    from qadence.backend import BackendName\n    from torch.distributions import Distribution\n    ### We have the following options:\n    print([g.value for g in StateGeneratorType])\n    n_qubits = 2\n    # The default is StateGeneratorType.HAAR_MEASURE_FAST\n    state = random_state(n_qubits=n_qubits)\n    print(state)\n    ### Lets initialize a state using random rotations, i.e., StateGeneratorType.RANDOM_ROTATIONS.\n    random = random_state(n_qubits=n_qubits, type=StateGeneratorType.RANDOM_ROTATIONS)\n    print(random)\n    ```\n    \"\"\"\nif type == StateGeneratorType.HAAR_MEASURE_FAST:\nstate = concat(tuple(_rand_haar_fast(n_qubits) for _ in range(batch_size)), dim=0)\nelif type == StateGeneratorType.HAAR_MEASURE_SLOW:\nstate = concat(tuple(_rand_haar_slow(n_qubits) for _ in range(batch_size)), dim=0)\nelif type == StateGeneratorType.RANDOM_ROTATIONS:\nstate = _run_state(_abstract_random_state(n_qubits, batch_size), backend)  # type: ignore\nassert all(list(map(is_normalized, state)))\nreturn state\n</code></pre>"},{"location":"qadence/states/#qadence.states.uniform_block","title":"<code>uniform_block(n_qubits)</code>","text":"<p>Generates the abstract uniform state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the uniform state.</p> <p>Examples: <pre><code>from qadence.states import uniform_block\nblock = uniform_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 H(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def uniform_block(n_qubits: int) -&gt; KronBlock:\n\"\"\"\n    Generates the abstract uniform state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A KronBlock representing the uniform state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_block\n    block = uniform_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\nreturn _from_op(H, n_qubits=n_qubits)\n</code></pre>"},{"location":"qadence/states/#qadence.states.uniform_state","title":"<code>uniform_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the uniform state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import uniform_state\nstate = uniform_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def uniform_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Generates the uniform state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): The batch size.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state\n    state = uniform_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\nnorm = 1 / torch.sqrt(torch.tensor(2**n_qubits))\nreturn norm * torch.ones(batch_size, 2**n_qubits, dtype=DTYPE)\n</code></pre>"},{"location":"qadence/states/#qadence.states.zero_block","title":"<code>zero_block(n_qubits)</code>","text":"<p>Generates the abstract zero state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the zero state.</p> <p>Examples: <pre><code>from qadence.states import zero_block\nblock = zero_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 I(0)\n\u2514\u2500\u2500 I(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def zero_block(n_qubits: int) -&gt; KronBlock:\n\"\"\"\n    Generates the abstract zero state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A KronBlock representing the zero state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import zero_block\n    block = zero_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\nreturn _from_op(I, n_qubits=n_qubits)\n</code></pre>"},{"location":"qadence/states/#qadence.states.zero_state","title":"<code>zero_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the zero state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits for which the zero state is to be generated.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size for the zero state.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import zero_state\nstate = zero_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def zero_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Generates the zero state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits for which the zero state is to be generated.\n        batch_size (int): The batch size for the zero state.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import zero_state\n    state = zero_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\nbitstring = \"0\" * n_qubits\nreturn _state_from_bitstring(bitstring, batch_size)\n</code></pre>"},{"location":"qadence/transpile/","title":"Transpilation","text":"<p>Contains functions that operate on blocks and circuits to <code>transpile</code> them to new blocks/circuits.</p>"},{"location":"qadence/transpile/#qadence.transpile.transpile.transpile","title":"<code>transpile(*fs)</code>","text":"<p><code>AbstractBlock</code> or <code>QuantumCircuit</code> transpilation. Compose functions that accept a circuit/block and returns a circuit/block.</p> PARAMETER  DESCRIPTION <code>*fs</code> <p>composable functions that either map blocks to blocks (<code>Callable[[AbstractBlock], AbstractBlock]</code>) or circuits to circuits (<code>Callable[[QuantumCircuit], QuantumCircuit]</code>).</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>Composed function.</p> <p>Examples:</p> <p>Flatten a block of nested chains and krons: <pre><code>from qadence import *\nfrom qadence.transpile import transpile, flatten, scale_primitive_blocks_only\nb = chain(2 * chain(chain(X(0), Y(0))), kron(kron(X(0), X(1))))\nprint(b)\n# both flatten and scale_primitive_blocks_only are functions that accept and\n# return a block\nt = transpile(flatten, scale_primitive_blocks_only)(b)\nprint(t)\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 [mul: 2] \u2502   \u2514\u2500\u2500 ChainBlock(0)\n\u2502       \u2514\u2500\u2500 ChainBlock(0)\n\u2502           \u251c\u2500\u2500 X(0)\n\u2502           \u2514\u2500\u2500 Y(0)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\nChainBlock(0,1)\n\u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2514\u2500\u2500 X(0)\n\u251c\u2500\u2500 Y(0)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> <p>We also proved a decorator to easily turn a function <code>Callable[[AbstractBlock], AbstractBlock]</code> into a <code>Callable[[QuantumCircuit], QuantumCircuit]</code> to be used in circuit transpilation. <pre><code>from qadence import *\nfrom qadence.transpile import transpile, blockfn_to_circfn, flatten\n# We want to pass this circuit to `transpile` instead of a block,\n# so we need functions that map from a circuit to a circuit.\ncirc = QuantumCircuit(2, chain(chain(X(0), chain(X(1)))))\n@blockfn_to_circfn\ndef fn(block):\n# un-decorated function accepts a block and returns a block\nreturn block * block\ntransp = transpile(\n# the decorated function accepts a circuit and returns a circuit\nfn,\n# already existing functions can also be decorated\nblockfn_to_circfn(flatten)\n)\nprint(transp(circ))\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 X(0)\n\u2502   \u2514\u2500\u2500 X(1)\n\u2514\u2500\u2500 ChainBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/transpile/transpile.py</code> <pre><code>def transpile(*fs: Callable) -&gt; Callable:\n\"\"\"`AbstractBlock` or `QuantumCircuit` transpilation. Compose functions that\n    accept a circuit/block and returns a circuit/block.\n    Arguments:\n        *fs: composable functions that either map blocks to blocks\n            (`Callable[[AbstractBlock], AbstractBlock]`)\n            or circuits to circuits (`Callable[[QuantumCircuit], QuantumCircuit]`).\n    Returns:\n        Composed function.\n    Examples:\n    Flatten a block of nested chains and krons:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import *\n    from qadence.transpile import transpile, flatten, scale_primitive_blocks_only\n    b = chain(2 * chain(chain(X(0), Y(0))), kron(kron(X(0), X(1))))\n    print(b)\n    print() # markdown-exec: hide\n    # both flatten and scale_primitive_blocks_only are functions that accept and\n    # return a block\n    t = transpile(flatten, scale_primitive_blocks_only)(b)\n    print(t)\n    ```\n    We also proved a decorator to easily turn a function `Callable[[AbstractBlock], AbstractBlock]`\n    into a `Callable[[QuantumCircuit], QuantumCircuit]` to be used in circuit transpilation.\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import *\n    from qadence.transpile import transpile, blockfn_to_circfn, flatten\n    # We want to pass this circuit to `transpile` instead of a block,\n    # so we need functions that map from a circuit to a circuit.\n    circ = QuantumCircuit(2, chain(chain(X(0), chain(X(1)))))\n    @blockfn_to_circfn\n    def fn(block):\n        # un-decorated function accepts a block and returns a block\n        return block * block\n    transp = transpile(\n        # the decorated function accepts a circuit and returns a circuit\n        fn,\n        # already existing functions can also be decorated\n        blockfn_to_circfn(flatten)\n    )\n    print(transp(circ))\n    ```\n    \"\"\"\nreturn lambda x: reduce(lambda acc, f: f(acc), reversed(fs), x)\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.chain_single_qubit_ops","title":"<code>chain_single_qubit_ops(block)</code>","text":"<p>Transpile a chain of krons into a kron of chains of single qubit operations.</p> <p>Examples: <pre><code>from qadence import hea\nfrom qadence.transpile.block import chain_single_qubit_ops\n# Consider a single HEA layer\nblock = hea(2,1)\nprint(block)\n# After applying chain_single_qubit_ops, we get:\nprint(chain_single_qubit_ops(block))\n</code></pre> <pre><code>ChainBlock(0,1) [tag: HEA]\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502   \u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_2']]\n\u2502   \u2502   \u2514\u2500\u2500 RY(1) [params: ['theta_3']]\n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 RX(0) [params: ['theta_4']]\n\u2502       \u2514\u2500\u2500 RX(1) [params: ['theta_5']]\n\u2514\u2500\u2500 ChainBlock(0,1)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u2514\u2500\u2500 CNOT(0,1)\nChainBlock(0,1)\n\u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u251c\u2500\u2500 ChainBlock(0)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_2']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(0) [params: ['theta_4']]\n\u2502   \u2514\u2500\u2500 ChainBlock(1)\n\u2502       \u251c\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502       \u251c\u2500\u2500 RY(1) [params: ['theta_3']]\n\u2502       \u2514\u2500\u2500 RX(1) [params: ['theta_5']]\n\u2514\u2500\u2500 ChainBlock(0,1)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u2514\u2500\u2500 CNOT(0,1)\n</code></pre></p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def chain_single_qubit_ops(block: AbstractBlock) -&gt; AbstractBlock:\n\"\"\"Transpile a chain of krons into a kron of chains of single qubit operations.\n    Examples:\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import hea\n    from qadence.transpile.block import chain_single_qubit_ops\n    # Consider a single HEA layer\n    block = hea(2,1)\n    print(block)\n    # After applying chain_single_qubit_ops, we get:\n    print(chain_single_qubit_ops(block))\n    ```\n    \"\"\"\nif is_chain_of_primitivekrons(block):\nkronblocks = block.blocks  # type: ignore[attr-defined]\nn_blocks = len(kronblocks)\nchains = []\nfor qb_idx in range(block.n_qubits):\nprim_gates = []\nfor kron_idx in range(n_blocks):\nprim_gates.append(kronblocks[kron_idx][qb_idx])  # type: ignore[index]\nchains.append(chain(*prim_gates))\ntry:\nreturn kron(*chains)\nexcept Exception as e:\nlogger.debug(\nf\"Unable to transpile {block} using chain_single_qubit_ops\\\n                         due to {e}. Returning original circuit.\"\n)\nreturn block\nelif isinstance(block, CompositeBlock):\nreturn _construct(type(block), tuple(chain_single_qubit_ops(b) for b in block.blocks))\nelse:\nreturn block\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.flatten","title":"<code>flatten(block, types=[ChainBlock, KronBlock, AddBlock])</code>","text":"<p>Flattens the given types of <code>CompositeBlock</code>s if possible.</p> <p>Example: <pre><code>from qadence import chain, kron, X\nfrom qadence.transpile import flatten\nfrom qadence.blocks import ChainBlock, KronBlock, AddBlock\nx = chain(chain(chain(X(0))), kron(kron(X(0))))\n# flatten only `ChainBlock`s\nassert flatten(x, [ChainBlock]) == chain(X(0), kron(kron(X(0))))\n# flatten `ChainBlock`s and `KronBlock`s\nassert flatten(x, [ChainBlock, KronBlock]) == chain(X(0), kron(X(0)))\n# flatten `AddBlock`s (does nothing in this case)\nassert flatten(x, [AddBlock]) == x\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def flatten(block: AbstractBlock, types: list = [ChainBlock, KronBlock, AddBlock]) -&gt; AbstractBlock:\n\"\"\"Flattens the given types of `CompositeBlock`s if possible.\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import chain, kron, X\n    from qadence.transpile import flatten\n    from qadence.blocks import ChainBlock, KronBlock, AddBlock\n    x = chain(chain(chain(X(0))), kron(kron(X(0))))\n    # flatten only `ChainBlock`s\n    assert flatten(x, [ChainBlock]) == chain(X(0), kron(kron(X(0))))\n    # flatten `ChainBlock`s and `KronBlock`s\n    assert flatten(x, [ChainBlock, KronBlock]) == chain(X(0), kron(X(0)))\n    # flatten `AddBlock`s (does nothing in this case)\n    assert flatten(x, [AddBlock]) == x\n    ```\n    \"\"\"\nif isinstance(block, CompositeBlock):\ndef fn(b: AbstractBlock, T: Type) -&gt; AbstractBlock:\nreturn _construct(type(block), tuple(_flat_blocks(b, T)))\nreturn reduce(fn, types, block)  # type: ignore[arg-type]\nelif isinstance(block, ScaleBlock):\nblk = deepcopy(block)\nblk.block = flatten(block.block, types=types)\nreturn blk\nelse:\nreturn block\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.scale_primitive_blocks_only","title":"<code>scale_primitive_blocks_only(block, scale=None)</code>","text":"<p>When given a scaled CompositeBlock consisting of several PrimitiveBlocks, move the scale all the way down into the leaves of the block tree.</p> PARAMETER  DESCRIPTION <code>block</code> <p>The block to be transpiled.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>scale</code> <p>An optional scale parameter. Only to be used for recursive calls internally.</p> <p> TYPE: <code>Basic</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>A block of the same type where the scales have been moved into the subblocks.</p> <p> TYPE: <code>AbstractBlock</code> </p> <p>Examples:</p> <p>There are two different cases: <code>ChainBlock</code>s/<code>KronBlock</code>s: Only the first subblock needs to be scaled because chains/krons represent multiplications. <pre><code>from qadence import chain, X, RX\nfrom qadence.transpile import scale_primitive_blocks_only\nb = 2 * chain(X(0), RX(0, \"theta\"))\nprint(b)\n# After applying scale_primitive_blocks_only\nprint(scale_primitive_blocks_only(b))\n</code></pre> <pre><code>[mul: 2] \u2514\u2500\u2500 ChainBlock(0)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 RX(0) [params: ['theta']]\nChainBlock(0)\n\u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 RX(0) [params: ['theta']]\n</code></pre></p> <p><code>AddBlock</code>s: Consider 2 * add(X(0), RX(0, \"theta\")).  The scale needs to be added to all subblocks.  We get add(2 * X(0), 2 * RX(0, \"theta\")). <pre><code>from qadence import add, X, RX\nfrom qadence.transpile import scale_primitive_blocks_only\nb = 2 * add(X(0), RX(0, \"theta\"))\nprint(b)\n# After applying scale_primitive_blocks_only\nprint(scale_primitive_blocks_only(b))\n</code></pre> <pre><code>[mul: 2] \u2514\u2500\u2500 AddBlock(0)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 RX(0) [params: ['theta']]\nAddBlock(0)\n\u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 [mul: 2.00000000000000] \u2514\u2500\u2500 RX(0) [params: ['theta']]\n</code></pre></p> Source code in <code>qadence/transpile/block.py</code> <pre><code>@singledispatch\ndef scale_primitive_blocks_only(block: AbstractBlock, scale: sympy.Basic = None) -&gt; AbstractBlock:\n\"\"\"When given a scaled CompositeBlock consisting of several PrimitiveBlocks,\n    move the scale all the way down into the leaves of the block tree.\n    Arguments:\n        block: The block to be transpiled.\n        scale: An optional scale parameter. Only to be used for recursive calls internally.\n    Returns:\n        AbstractBlock: A block of the same type where the scales have been moved into the subblocks.\n    Examples:\n    There are two different cases:\n    `ChainBlock`s/`KronBlock`s: Only the first subblock needs to be scaled because chains/krons\n    represent multiplications.\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import chain, X, RX\n    from qadence.transpile import scale_primitive_blocks_only\n    b = 2 * chain(X(0), RX(0, \"theta\"))\n    print(b)\n    # After applying scale_primitive_blocks_only\n    print(scale_primitive_blocks_only(b))\n    ```\n    `AddBlock`s: Consider 2 * add(X(0), RX(0, \"theta\")).  The scale needs to be added to all\n    subblocks.  We get add(2 * X(0), 2 * RX(0, \"theta\")).\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import add, X, RX\n    from qadence.transpile import scale_primitive_blocks_only\n    b = 2 * add(X(0), RX(0, \"theta\"))\n    print(b)\n    # After applying scale_primitive_blocks_only\n    print(scale_primitive_blocks_only(b))\n    ```\n    \"\"\"\nraise NotImplementedError(f\"scale_primitive_blocks_only is not implemented for {type(block)}\")\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.set_trainable","title":"<code>set_trainable(blocks, value=True, inplace=True)</code>","text":"<p>Set the trainability of all parameters in a block to a given value</p> PARAMETER  DESCRIPTION <code>blocks</code> <p>Block or list of blocks for which to set the trainable attribute</p> <p> TYPE: <code>AbstractBlock | list[AbstractBlock]</code> </p> <code>value</code> <p>The value of the trainable attribute to assign to the input blocks</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>inplace</code> <p>Whether to modify the block(s) in place or not. Currently, only</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>if the <code>inplace</code> argument is set to False, the function will raise  this exception</p> RETURNS DESCRIPTION <code>AbstractBlock | list[AbstractBlock]</code> <p>AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable attribute set to the given value</p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def set_trainable(\nblocks: AbstractBlock | list[AbstractBlock], value: bool = True, inplace: bool = True\n) -&gt; AbstractBlock | list[AbstractBlock]:\n\"\"\"Set the trainability of all parameters in a block to a given value\n    Args:\n        blocks (AbstractBlock | list[AbstractBlock]): Block or list of blocks for which\n            to set the trainable attribute\n        value (bool, optional): The value of the trainable attribute to assign to the input blocks\n        inplace (bool, optional): Whether to modify the block(s) in place or not. Currently, only\n    Raises:\n        NotImplementedError: if the `inplace` argument is set to False, the function will\n            raise  this exception\n    Returns:\n        AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable\n            attribute set to the given value\n    \"\"\"\nif isinstance(blocks, AbstractBlock):\nblocks = [blocks]\nif inplace:\nfor block in blocks:\nparams: list[sympy.Basic] = parameters(block)\nfor p in params:\nif not p.is_number:\np.trainable = value\nelse:\nraise NotImplementedError(\"Not inplace set_trainable is not yet available\")\nreturn blocks if len(blocks) &gt; 1 else blocks[0]\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.validate","title":"<code>validate(block)</code>","text":"<p>Moves a block from global to local qubit numbers by adding PutBlocks and reassigning qubit locations approriately.</p>"},{"location":"qadence/transpile/#qadence.transpile.block.validate--example","title":"Example","text":"<pre><code>from qadence.blocks import chain\nfrom qadence.operations import X\nfrom qadence.transpile import validate\nx = chain(chain(X(0)), chain(X(1)))\nprint(x)\nprint(validate(x))\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 ChainBlock(0)\n\u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 ChainBlock(1)\n\u2514\u2500\u2500 X(1)\nChainBlock(0,1)\n\u251c\u2500\u2500 put on (0)\n\u2502   \u2514\u2500\u2500 ChainBlock(0)\n\u2502       \u2514\u2500\u2500 put on (0)\n\u2502           \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 put on (1)\n\u2514\u2500\u2500 ChainBlock(0)\n\u2514\u2500\u2500 put on (0)\n\u2514\u2500\u2500 X(0)\n</code></pre> Source code in <code>qadence/transpile/block.py</code> <pre><code>def validate(block: AbstractBlock) -&gt; AbstractBlock:\n\"\"\"Moves a block from global to local qubit numbers by adding PutBlocks and reassigning\n    qubit locations approriately.\n    # Example\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence.blocks import chain\n    from qadence.operations import X\n    from qadence.transpile import validate\n    x = chain(chain(X(0)), chain(X(1)))\n    print(x)\n    print(validate(x))\n    ```\n    \"\"\"\nvblock: AbstractBlock\nfrom qadence.transpile import reassign\nif isinstance(block, ControlBlock):\nvblock = deepcopy(block)\nb: AbstractBlock\n(b,) = block.blocks\nb = reassign(b, {i: i - min(b.qubit_support) for i in b.qubit_support})\nb = validate(b)\nvblock.blocks = (b,)  # type: ignore[assignment]\nelif isinstance(block, CompositeBlock):\nblocks = []\nfor b in block.blocks:\nmi, ma = min(b.qubit_support), max(b.qubit_support)\nnb = reassign(b, {i: i - min(b.qubit_support) for i in b.qubit_support})\nnb = validate(nb)\nnb = PutBlock(nb, tuple(range(mi, ma + 1)))\nblocks.append(nb)\ntry:\nvblock = _construct(type(block), tuple(blocks))\nexcept AssertionError as e:\nif str(e) == \"Make sure blocks act on distinct qubits!\":\nvblock = chain(*blocks)\nelse:\nraise e\nelif isinstance(block, PrimitiveBlock):\nvblock = deepcopy(block)\nelse:\nraise NotImplementedError\nvblock.tag = block.tag\nreturn vblock\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.emulate.add_interaction","title":"<code>add_interaction(x, *args, interaction=Interaction.NN, spacing=1.0)</code>","text":"<p>Turns blocks or circuits into (a chain of) <code>HamEvo</code> blocks including a chosen interaction term.</p> <p>This is a <code>@singledipatch</code>ed function which can be called in three ways:</p> <ul> <li>With a <code>QuantumCircuit</code> which contains all necessary information: <code>add_interaction(circuit)</code></li> <li>With a <code>Register</code> and an <code>AbstractBlock</code>: <code>add_interaction(reg, block)</code></li> <li>With an <code>AbstractBlock</code> only: <code>add_interaction(block)</code></li> </ul> <p>See the section about analog blocks for detailed information about how which types of blocks are translated.</p> PARAMETER  DESCRIPTION <code>x</code> <p>Circuit or block to be emulated. See the examples on which argument combinations are accepted.</p> <p> TYPE: <code>Register | QuantumCircuit | AbstractBlock</code> </p> <code>interaction</code> <p>Type of interaction that is added. Can also be a function that accepts a register and a list of edges that define which qubits interact (see the examples).</p> <p> TYPE: <code>Interaction | Callable</code> DEFAULT: <code>NN</code> </p> <code>spacing</code> <p>All qubit coordinates are multiplied by <code>spacing</code>.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <p>Examples: <pre><code>from qadence import QuantumCircuit, AnalogRX, add_interaction\nc = QuantumCircuit(2, AnalogRX(2.0))\ne = add_interaction(c)\n</code></pre> <pre><code>[mul: 0.0] \u2514\u2500\u2500 AddBlock(0,1)\n\u251c\u2500\u2500 AddBlock(0,1)\n\u2502   \u2514\u2500\u2500 AddBlock(0,1)\n\u2502       \u251c\u2500\u2500 [mul: 1.571] \u2502       \u2502   \u2514\u2500\u2500 AddBlock(0,1)\n\u2502       \u2502       \u251c\u2500\u2500 AddBlock(0)\n\u2502       \u2502       \u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502       \u2502       \u2502   \u2502   \u2514\u2500\u2500 X(0)\n\u2502       \u2502       \u2502   \u2514\u2500\u2500 [mul: 0.0] \u2502       \u2502       \u2502       \u2514\u2500\u2500 Y(0)\n\u2502       \u2502       \u2514\u2500\u2500 AddBlock(1)\n\u2502       \u2502           \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502       \u2502           \u2502   \u2514\u2500\u2500 X(1)\n\u2502       \u2502           \u2514\u2500\u2500 [mul: 0.0] \u2502       \u2502               \u2514\u2500\u2500 Y(1)\n\u2502       \u2514\u2500\u2500 [mul: 0.0] \u2502           \u2514\u2500\u2500 AddBlock(0,1)\n\u2502               \u251c\u2500\u2500 N(0)\n\u2502               \u2514\u2500\u2500 N(1)\n\u2514\u2500\u2500 AddBlock(0,1)\n\u2514\u2500\u2500 [mul: 865723.020] \u2514\u2500\u2500 KronBlock(0,1)\n\u251c\u2500\u2500 N(0)\n\u2514\u2500\u2500 N(1)\n</code></pre>  You can also use <code>add_interaction</code> directly on a block, but you have to provide either the <code>Register</code> or define a non-global qubit support. <pre><code>from qadence import AnalogRX, Register, add_interaction\nb = AnalogRX(2.0)\nr = Register(1)\ne = add_interaction(r, b)\n# or provide only the block with local qubit support\n# in this case the register is created via `Register(b.n_qubits)`\ne = add_interaction(AnalogRX(2.0, qubit_support=(0,)))\nprint(e.generator)\n</code></pre> <pre><code>[mul: 0.450] \u2514\u2500\u2500 AddBlock(0)\n\u2514\u2500\u2500 AddBlock(0)\n\u251c\u2500\u2500 [mul: 1.571] \u2502   \u2514\u2500\u2500 AddBlock(0)\n\u2502       \u2514\u2500\u2500 AddBlock(0)\n\u2502           \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502           \u2502   \u2514\u2500\u2500 X(0)\n\u2502           \u2514\u2500\u2500 [mul: 0.0] \u2502               \u2514\u2500\u2500 Y(0)\n\u2514\u2500\u2500 [mul: 0.0] \u2514\u2500\u2500 AddBlock(0)\n\u2514\u2500\u2500 N(0)\n[mul: 0.450] \u2514\u2500\u2500 AddBlock(0)\n\u2514\u2500\u2500 AddBlock(0)\n\u251c\u2500\u2500 [mul: 1.571] \u2502   \u2514\u2500\u2500 AddBlock(0)\n\u2502       \u2514\u2500\u2500 AddBlock(0)\n\u2502           \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502           \u2502   \u2514\u2500\u2500 X(0)\n\u2502           \u2514\u2500\u2500 [mul: 0.0] \u2502               \u2514\u2500\u2500 Y(0)\n\u2514\u2500\u2500 [mul: 0.0] \u2514\u2500\u2500 AddBlock(0)\n\u2514\u2500\u2500 N(0)\n</code></pre>  You can specify a custom <code>interaction</code> function which has to accept a <code>Register</code> and a list of <code>edges: list[tuple[int, int]]</code>: <pre><code>from qadence import AnalogRX, Register, add_interaction\nfrom qadence.transpile.emulate import ising_interaction\ndef int_fn(r: Register, pairs: list[tuple[int, int]]) -&gt; AbstractBlock:\n# do either something completely custom\n# ...\n# or e.g. change the default kwargs to `ising_interaction`\nreturn ising_interaction(r, pairs, rydberg_level=70)\nb = AnalogRX(2.0)\nr = Register(1)\ne = add_interaction(r, b, interaction=int_fn)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/transpile/emulate.py</code> <pre><code>@singledispatch\ndef add_interaction(\nx: Register | QuantumCircuit | AbstractBlock,\n*args: Any,\ninteraction: Interaction | Callable = Interaction.NN,\nspacing: float = 1.0,\n) -&gt; QuantumCircuit | AbstractBlock:\n\"\"\"Turns blocks or circuits into (a chain of) `HamEvo` blocks including a\n    chosen interaction term.\n    This is a `@singledipatch`ed function which can be called in three ways:\n    * With a `QuantumCircuit` which contains all necessary information: `add_interaction(circuit)`\n    * With a `Register` and an `AbstractBlock`: `add_interaction(reg, block)`\n    * With an `AbstractBlock` only: `add_interaction(block)`\n    See the section about [analog blocks](/digital_analog_qc/analog-basics.md) for\n    detailed information about how which types of blocks are translated.\n    Arguments:\n        x: Circuit or block to be emulated. See the examples on which argument\n            combinations are accepted.\n        interaction: Type of interaction that is added. Can also be a function that accepts a\n            register and a list of edges that define which qubits interact (see the examples).\n        spacing: All qubit coordinates are multiplied by `spacing`.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import QuantumCircuit, AnalogRX, add_interaction\n    c = QuantumCircuit(2, AnalogRX(2.0))\n    e = add_interaction(c)\n    print(str(e.block.generator)) # markdown-exec: hide\n    ```\n    You can also use `add_interaction` directly on a block, but you have to provide either\n    the `Register` or define a non-global qubit support.\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import AnalogRX, Register, add_interaction\n    b = AnalogRX(2.0)\n    r = Register(1)\n    e = add_interaction(r, b)\n    print(e.generator) # markdown-exec: hide\n    # or provide only the block with local qubit support\n    # in this case the register is created via `Register(b.n_qubits)`\n    e = add_interaction(AnalogRX(2.0, qubit_support=(0,)))\n    print(e.generator)\n    ```\n    You can specify a custom `interaction` function which has to accept a `Register` and a list\n    of `edges: list[tuple[int, int]]`:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import AnalogRX, Register, add_interaction\n    from qadence.transpile.emulate import ising_interaction\n    def int_fn(r: Register, pairs: list[tuple[int, int]]) -&gt; AbstractBlock:\n        # do either something completely custom\n        # ...\n        # or e.g. change the default kwargs to `ising_interaction`\n        return ising_interaction(r, pairs, rydberg_level=70)\n    b = AnalogRX(2.0)\n    r = Register(1)\n    e = add_interaction(r, b, interaction=int_fn)\n    ```\n    \"\"\"\nraise ValueError(f\"`add_interaction` is not implemented for {type(x)}\")\n</code></pre>"},{"location":"qadence/types/","title":"Types","text":""},{"location":"qadence/types/#qadence-types","title":"Qadence Types","text":""},{"location":"qadence/types/#qadence.types.TArray","title":"<code>TArray = Union[Iterable, torch.Tensor, np.ndarray]</code>  <code>module-attribute</code>","text":"<p>Union of common array types.</p>"},{"location":"qadence/types/#qadence.types.TGenerator","title":"<code>TGenerator = Union[torch.Tensor, sympy.Array, sympy.Basic]</code>  <code>module-attribute</code>","text":"<p>Union of torch tensors and numpy arrays.</p>"},{"location":"qadence/types/#qadence.types.TNumber","title":"<code>TNumber = Union[int, float, complex]</code>  <code>module-attribute</code>","text":"<p>Union of python number types.</p>"},{"location":"qadence/types/#qadence.types.TParameter","title":"<code>TParameter = Union[TNumber, torch.Tensor, sympy.Basic, str]</code>  <code>module-attribute</code>","text":"<p>Union of numbers, tensors, and parameter types.</p>"},{"location":"qadence/types/#qadence.types.AlgoHEvo","title":"<code>AlgoHEvo</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Hamiltonian Evolution algorithms that can be used by the backend.</p>"},{"location":"qadence/types/#qadence.types.AlgoHEvo.EIG","title":"<code>EIG = 'EIG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using Hamiltonian diagonalization.</p>"},{"location":"qadence/types/#qadence.types.AlgoHEvo.EXP","title":"<code>EXP = 'EXP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using torch.matrix_exp on the generator matrix.</p>"},{"location":"qadence/types/#qadence.types.AlgoHEvo.RK4","title":"<code>RK4 = 'RK4'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>4th order Runge-Kutta approximation.</p>"},{"location":"qadence/types/#qadence.types.Endianness","title":"<code>Endianness</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>The endianness convention to use.</p>"},{"location":"qadence/types/#qadence.types.Endianness.BIG","title":"<code>BIG = 'Big'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use Big endianness.</p>"},{"location":"qadence/types/#qadence.types.Endianness.LITTLE","title":"<code>LITTLE = 'Little'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use little endianness.</p>"},{"location":"qadence/types/#qadence.types.FigFormat","title":"<code>FigFormat</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Available output formats for exporting visualized circuits to a file.</p>"},{"location":"qadence/types/#qadence.types.FigFormat.PDF","title":"<code>PDF = 'PDF'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>PDF format.</p>"},{"location":"qadence/types/#qadence.types.FigFormat.PNG","title":"<code>PNG = 'PNG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>PNG format.</p>"},{"location":"qadence/types/#qadence.types.FigFormat.SVG","title":"<code>SVG = 'SVG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>SVG format.</p>"},{"location":"qadence/types/#qadence.types.GenDAQC","title":"<code>GenDAQC</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>The type of interaction for the DAQC transform.</p>"},{"location":"qadence/types/#qadence.types.GenDAQC.NN","title":"<code>NN = 'NN'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NN</p>"},{"location":"qadence/types/#qadence.types.GenDAQC.ZZ","title":"<code>ZZ = 'ZZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZZ</p>"},{"location":"qadence/types/#qadence.types.Interaction","title":"<code>Interaction</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Interaction types used in - <code>add_interaction</code>. - <code>hamiltonian_factory</code>.</p>"},{"location":"qadence/types/#qadence.types.Interaction.NN","title":"<code>NN = 'NN'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NN-Ising Interaction, N=(I-Z)/2</p>"},{"location":"qadence/types/#qadence.types.Interaction.XY","title":"<code>XY = 'XY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>XY Interaction</p>"},{"location":"qadence/types/#qadence.types.Interaction.XYZ","title":"<code>XYZ = 'XYZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>XYZ Interaction</p>"},{"location":"qadence/types/#qadence.types.Interaction.ZZ","title":"<code>ZZ = 'ZZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZZ-Ising Interaction</p>"},{"location":"qadence/types/#qadence.types.LTSOrder","title":"<code>LTSOrder</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Lie-Trotter-Suzuki approximation order.</p>"},{"location":"qadence/types/#qadence.types.LTSOrder.BASIC","title":"<code>BASIC = 'BASIC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Basic.</p>"},{"location":"qadence/types/#qadence.types.LTSOrder.ST2","title":"<code>ST2 = 'ST2'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ST2.</p>"},{"location":"qadence/types/#qadence.types.LTSOrder.ST4","title":"<code>ST4 = 'ST4'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ST4.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology","title":"<code>LatticeTopology</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Lattice topologies to choose from for the register.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.ALL_TO_ALL","title":"<code>ALL_TO_ALL = 'all_to_all'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>All to all- connected lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.ARBITRARY","title":"<code>ARBITRARY = 'arbitrary'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Arbitrarily-shaped lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.CIRCLE","title":"<code>CIRCLE = 'circle'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Circular lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.HONEYCOMB_LATTICE","title":"<code>HONEYCOMB_LATTICE = 'honeycomb_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Honeycomb-shaped lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.LINE","title":"<code>LINE = 'line'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Line-format lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.RECTANGULAR_LATTICE","title":"<code>RECTANGULAR_LATTICE = 'rectangular_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Rectangular-shaped lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.SQUARE","title":"<code>SQUARE = 'square'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Square lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.TRIANGULAR_LATTICE","title":"<code>TRIANGULAR_LATTICE = 'triangular_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Triangular-shaped shape.</p>"},{"location":"qadence/types/#qadence.types.OpName","title":"<code>OpName</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>A list of all available of digital-analog operations.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGENTANG","title":"<code>ANALOGENTANG = 'AnalogEntanglement'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog entanglement operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGRX","title":"<code>ANALOGRX = 'AnalogRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RX operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGRY","title":"<code>ANALOGRY = 'AnalogRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RY operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGRZ","title":"<code>ANALOGRZ = 'AnalogRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RZ operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGSWAP","title":"<code>ANALOGSWAP = 'AnalogSWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog SWAP operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.CNOT","title":"<code>CNOT = 'CNOT'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The CNOT gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CPHASE","title":"<code>CPHASE = 'CPHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The controlled PHASE gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CRX","title":"<code>CRX = 'CRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control RX gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CRY","title":"<code>CRY = 'CRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Controlled RY gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CRZ","title":"<code>CRZ = 'CRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control RZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CSWAP","title":"<code>CSWAP = 'CSWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control SWAP gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CZ","title":"<code>CZ = 'CZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The CZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.ENTANG","title":"<code>ENTANG = 'entangle'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The entanglement operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.H","title":"<code>H = 'H'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Hadamard gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.HAMEVO","title":"<code>HAMEVO = 'HamEvo'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Hamiltonian Evolution operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.I","title":"<code>I = 'I'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Identity gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCPHASE","title":"<code>MCPHASE = 'MCPHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol PHASE gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCRX","title":"<code>MCRX = 'MCRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RX gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCRY","title":"<code>MCRY = 'MCRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RY gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCRZ","title":"<code>MCRZ = 'MCRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCZ","title":"<code>MCZ = 'MCZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol CZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.N","title":"<code>N = 'N'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The N = (1/2)(I-Z) operator</p>"},{"location":"qadence/types/#qadence.types.OpName.PHASE","title":"<code>PHASE = 'PHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The PHASE gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.RX","title":"<code>RX = 'RX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RX gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.RY","title":"<code>RY = 'RY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RY gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.RZ","title":"<code>RZ = 'RZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.S","title":"<code>S = 'S'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The S gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.SDAGGER","title":"<code>SDAGGER = 'SDagger'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The S dagger gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.SWAP","title":"<code>SWAP = 'SWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The SWAP gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.T","title":"<code>T = 'T'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The T gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.TDAGGER","title":"<code>TDAGGER = 'TDagger'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The T dagger gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.TOFFOLI","title":"<code>TOFFOLI = 'Toffoli'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Toffoli gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.U","title":"<code>U = 'U'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The U gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.WAIT","title":"<code>WAIT = 'wait'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The wait operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.X","title":"<code>X = 'X'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The X gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.Y","title":"<code>Y = 'Y'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Y gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.Z","title":"<code>Z = 'Z'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Z gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.ZERO","title":"<code>ZERO = 'Zero'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The zero gate.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod","title":"<code>OverlapMethod</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Overlap Methods to choose from.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.COMPUTE_UNCOMPUTE","title":"<code>COMPUTE_UNCOMPUTE = 'compute_uncompute'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Compute-uncompute.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.EXACT","title":"<code>EXACT = 'exact'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Exact.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.HADAMARD_TEST","title":"<code>HADAMARD_TEST = 'hadamard_test'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Hadamard-test.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.JENSEN_SHANNON","title":"<code>JENSEN_SHANNON = 'jensen_shannon'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Jensen-shannon.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.SWAP_TEST","title":"<code>SWAP_TEST = 'swap_test'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Swap-test.</p>"},{"location":"qadence/types/#qadence.types.ParameterType","title":"<code>ParameterType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Parameter types available in qadence.</p>"},{"location":"qadence/types/#qadence.types.ParameterType.FEATURE","title":"<code>FEATURE = 'Feature'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>FeatureParameters act as input and are not trainable.</p>"},{"location":"qadence/types/#qadence.types.ParameterType.FIXED","title":"<code>FIXED = 'Fixed'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Fixed/ constant parameters are neither trainable nor act as input.</p>"},{"location":"qadence/types/#qadence.types.ParameterType.VARIATIONAL","title":"<code>VARIATIONAL = 'Variational'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>VariationalParameters are trainable.</p>"},{"location":"qadence/types/#qadence.types.QubitSupportType","title":"<code>QubitSupportType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Qubit support types.</p>"},{"location":"qadence/types/#qadence.types.QubitSupportType.GLOBAL","title":"<code>GLOBAL = 'global'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use global qubit support.</p>"},{"location":"qadence/types/#qadence.types.ResultType","title":"<code>ResultType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Available data types for generating certain results.</p>"},{"location":"qadence/types/#qadence.types.ResultType.NUMPY","title":"<code>NUMPY = 'Numpy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Numpy Array Type.</p>"},{"location":"qadence/types/#qadence.types.ResultType.STRING","title":"<code>STRING = 'String'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String Type.</p>"},{"location":"qadence/types/#qadence.types.ResultType.TORCH","title":"<code>TORCH = 'Torch'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Torch Tensor Type.</p>"},{"location":"qadence/types/#qadence.types.SerializationFormat","title":"<code>SerializationFormat</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Available serialization formats for circuits.</p>"},{"location":"qadence/types/#qadence.types.SerializationFormat.JSON","title":"<code>JSON = 'JSON'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Json format.</p>"},{"location":"qadence/types/#qadence.types.SerializationFormat.PT","title":"<code>PT = 'PT'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The PT format used by Torch.</p>"},{"location":"qadence/types/#qadence.types.StateGeneratorType","title":"<code>StateGeneratorType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Methods to generate random states.</p>"},{"location":"qadence/types/#qadence.types.StateGeneratorType.HAAR_MEASURE_FAST","title":"<code>HAAR_MEASURE_FAST = 'HaarMeasureFast'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>HaarMeasure.</p>"},{"location":"qadence/types/#qadence.types.StateGeneratorType.HAAR_MEASURE_SLOW","title":"<code>HAAR_MEASURE_SLOW = 'HaarMeasureSlow'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>HaarMeasure non-optimized version.</p>"},{"location":"qadence/types/#qadence.types.StateGeneratorType.RANDOM_ROTATIONS","title":"<code>RANDOM_ROTATIONS = 'RandomRotations'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Random Rotations.</p>"},{"location":"qadence/types/#qadence.types.StrEnum","title":"<code>StrEnum</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"qadence/types/#qadence.types.StrEnum.__str__","title":"<code>__str__()</code>","text":"<p>Used when dumping enum fields in a schema.</p> Source code in <code>qadence/types.py</code> <pre><code>def __str__(self) -&gt; str:\n\"\"\"Used when dumping enum fields in a schema.\"\"\"\nret: str = self.value\nreturn ret\n</code></pre>"},{"location":"qadence/types/#qadence.types.Strategy","title":"<code>Strategy</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Computing paradigm.</p>"},{"location":"qadence/types/#qadence.types.Strategy.ANALOG","title":"<code>ANALOG = 'Analog'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the analog paradigm.</p>"},{"location":"qadence/types/#qadence.types.Strategy.BDAQC","title":"<code>BDAQC = 'bDAQC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the banged digital-analog QC paradigm.</p>"},{"location":"qadence/types/#qadence.types.Strategy.DIGITAL","title":"<code>DIGITAL = 'Digital'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the digital paradigm.</p>"},{"location":"qadence/types/#qadence.types.Strategy.SDAQC","title":"<code>SDAQC = 'sDAQC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the step-wise digital-analog QC paradigm.</p>"},{"location":"qadence/types/#qadence.types.TensorType","title":"<code>TensorType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Tensor Types for converting blocks to tensors.</p>"},{"location":"qadence/types/#qadence.types.TensorType.DENSE","title":"<code>DENSE = 'Dense'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a block to a dense tensor.</p>"},{"location":"qadence/types/#qadence.types.TensorType.SPARSE","title":"<code>SPARSE = 'Sparse'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a observable block to a sparse tensor.</p>"},{"location":"qadence/types/#qadence.types.TensorType.SPARSEDIAGONAL","title":"<code>SPARSEDIAGONAL = 'SparseDiagonal'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a diagonal observable block to a sparse diagonal if possible.</p>"},{"location":"qml/","title":"Variational Quantum Algorithms","text":"<p>Variational algorithms on noisy devices and quantum machine learning (QML) [^1] in particular are the target applications for Qadence. For this purpose, the library offers both flexible symbolic expressions for the quantum circuit parameters via <code>sympy</code> (see here for more details) and native automatic differentiation via integration with PyTorch deep learning framework.</p> <p>Qadence symbolic parameter interface allows to create arbitrary feature maps to encode classical data into quantum circuits with an arbitrary non-linear function embedding for the input values:</p> <pre><code>import qadence as qd\nfrom qadence.operations import *\nimport torch\nfrom sympy import acos\nn_qubits = 4\nfp = qd.FeatureParameter(\"phi\")\nfeature_map = qd.kron(RX(i, 2 * acos(fp)) for i in range(n_qubits))\n# the key in the dictionary must correspond to\n# the name of the assigned to the feature parameter\ninputs = {\"phi\": torch.rand(3)}\nsamples = qd.sample(feature_map, values=inputs)\nprint(samples)\n</code></pre>   [Counter({'0000': 16, '1000': 9, '0001': 8, '0101': 8, '1100': 8, '0011': 7, '1001': 6, '1110': 6, '0010': 5, '0100': 5, '0111': 5, '1011': 5, '1101': 4, '0110': 3, '1010': 3, '1111': 2}), Counter({'1111': 96, '1101': 2, '0111': 1, '1110': 1}), Counter({'1111': 34, '0111': 11, '1011': 11, '1110': 9, '0110': 6, '1101': 6, '0011': 4, '0101': 4, '1100': 4, '0001': 3, '0010': 2, '1001': 2, '1010': 2, '0000': 1, '1000': 1})]    <p>The <code>constructors.feature_map</code> module provides convenience functions to build commonly used feature maps where the input parameter is encoded in the single-qubit gates rotation angle.</p> <p>Furthermore, Qadence is natively integrated with PyTorch automatic differentiation engine thus Qadence quantum models can be used seamlessly in a PyTorch workflow.</p> <p>Let's create a quantum neural network model using the feature map just defined, a digital-analog variational ansaztz and a simple observable \\(X(0) \\otimes X(1)\\). We use the convenience <code>QNN</code> quantum model abstraction.</p> <pre><code>ansatz = qd.hea(n_qubits, strategy=\"sDAQC\")\ncircuit = qd.QuantumCircuit(n_qubits, feature_map, ansatz)\nobservable = qd.kron(X(0), X(1))\nmodel = qd.QNN(circuit, observable)\n# NOTE: the `QNN` is a torch.nn.Module\nassert isinstance(model, torch.nn.Module)\n</code></pre> <pre><code>\n</code></pre> <p>Differentiation works the same way as any other PyTorch module:</p> <pre><code>values = {\"phi\": torch.rand(10, requires_grad=True)}\n# the forward pass of the quantum model returns the expectation\n# value of the input observable\nout = model(values)\nprint(f\"Quantum model output: {out}\")\n# you can compute the gradient with respect to inputs using\n# PyTorch autograd differentiation engine\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: {dout}\")\n# you can also call directly a backward pass to compute derivatives with respect\n# to the variational parameters and use it for implementing variational\n# optimization\nout.sum().backward()\n</code></pre>   Quantum model output: tensor([[ 0.2032],         [ 0.2917],         [ 0.1796],         [-0.0787],         [-0.0011],         [-0.0282],         [-0.1629],         [ 0.3357],         [ 0.1045],         [ 0.2066]], grad_fn=) First-order derivative w.r.t. the feature parameter: tensor([ -1.1605,  -0.9653,  -1.1902,  -0.9553,  -1.1569,  -1.1053,  -0.0851,         -54.6866,   2.6188,  -1.1556], grad_fn=)    <p>To run QML on real devices, Qadence offers generalized parameter shift rules (GPSR) <sup>1</sup> for arbitrary quantum operations which can be selected when constructing the <code>QNN</code> model:</p> <pre><code>model = qd.QNN(circuit, observable, diff_mode=\"gpsr\")\nout = model(values)\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: {dout}\")\n</code></pre>   First-order derivative w.r.t. the feature parameter: tensor([ -1.1605,  -0.9653,  -1.1902,  -0.9553,  -1.1569,  -1.1053,  -0.0851,         -54.6866,   2.6188,  -1.1556], grad_fn=)    <p>See here for more details on how the parameter shift rules implementation works in Qadence.</p>"},{"location":"qml/#references","title":"References","text":"<p>[^1] Schuld, Petruccione, Machine learning on Quantum Computers, Springer Nature (2021)</p> <ol> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9</p> </li> </ol>"},{"location":"qml/qaoa/","title":"QAOA for Solving MaxCut","text":"<p>In this tutorial, we show how to solve the maximum cut (MaxCut) combinatorial optimization problem on a graph using the Quantum Approximate Optimization Algorithm (QAOA<sup>1</sup>), introduced in 2014. This showcases the flexibility of Qadence for implementing variational algorithms without classical input data.</p> <p>Given an arbitrary graph, the MaxCut problem consists in finding a cut partitioning the nodes into two sets, such that the number edges that are the cut is maximized. This is a very common combinatorial problem, the interested reader can refer to this introduction. Let's first generate a random graph using the <code>networkx</code> library.</p> <pre><code>import numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\n# ensure reproducibility\nseed = 10\nnp.random.seed(seed)\nn_nodes = 8\ngraph = nx.gnp_random_graph(n_nodes, 0.5)\nnx.draw(graph)\n</code></pre> 2023-10-10T21:36:30.216306 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ <p>The goal of the MaxCut algorithm is to maximize the following cost function:</p> \\[ \\mathcal{C}(p) = \\sum_{\\alpha}^m \\mathcal{C}_{\\alpha}(p) \\] <p>where \\(p\\) is the given partition of the graph, \\(\\alpha\\) is an index over the edges and \\(\\mathcal{C}_{\\alpha}(p)\\) is written such that if the nodes connected by the \\(\\alpha\\) edge are in the same set, it returns \\(0\\), otherwise it returns \\(1\\).</p>"},{"location":"qml/qaoa/#the-qaoa-quantum-circuit","title":"The QAOA quantum circuit","text":"<p>Let's see how to solve this problem using a parametrized quantum circuit. The QAOA algorithm requires a circuit with two main components:</p> <ul> <li>the cost component is a circuit generated by a diagonal Hamiltonian which   encodes the cost function described above into a quantum circuit.</li> <li>the mixing component is a simple set of single qubit rotations with adjustable   angles which are tuned during the classical optimization loop</li> </ul> <p>First, construct the generators associated with the edges of the given graph. These will be used both in the definition of the loss function of our problem and in constructing the quantum circuit.</p> <pre><code>from qadence import kron, Z\nzz_ops = [kron(Z(edge[0]), Z(edge[1])) for edge in graph.edges()]\n</code></pre> <p>Let's now define the QAOA quantum circuits with the cost and mixing components. <pre><code>from qadence import Zero, I, HamEvo, tag, chain, QuantumCircuit, RX\nn_qubits = graph.number_of_nodes()\nn_layers = 2\ncost_ham = Zero()\nfor op in zz_ops:\ncost_ham += 0.5 * op\ncost_ham = 0.5 * kron(I(i) for i in range(n_qubits)) - cost_ham\nlayers = []\nfor layer in range(n_layers):\n# cost layer with digital decomposition\ncost_layer = HamEvo(cost_ham, f\"g{layer}\").digital_decomposition()\ncost_layer = tag(cost_layer, \"cost\")\n# mixing layer with single qubit rotations\nmixing_layer = kron(RX(i, f\"b{layer}{i}\") for i in range(n_qubits))\nmixing_layer = tag(mixing_layer, \"mixing\")\n# putting all together in a single ChainBlock\nlayers.append(chain(cost_layer, mixing_layer))\nfinal_b = chain(*layers)\ncircuit = QuantumCircuit(n_qubits, final_b)\n</code></pre> %3 cluster_9ed938f48037410da0c2d65c7ff39f8a mixing cluster_98ba86f25e954ead8e285e83037b9278 cost cluster_7882b2d014a04dd7bc70e2b2dd5841f0 mixing cluster_a267fcab6d624ffd8387575d9aa34f64 cost f0f8e39dc9dc44e7a89de14a78e1f89d 0 d8c5cdd147e945eab7178a9dc878804e f0f8e39dc9dc44e7a89de14a78e1f89d--d8c5cdd147e945eab7178a9dc878804e 01b41043b32b47a88a3852dda94857f1 1 5d81c21a3d3a41fba19aaf58a1d3ca64 d8c5cdd147e945eab7178a9dc878804e--5d81c21a3d3a41fba19aaf58a1d3ca64 0ea22949784845b2924905832d9b62a5 5d81c21a3d3a41fba19aaf58a1d3ca64--0ea22949784845b2924905832d9b62a5 870f56d1fece4a99a6fe16eadf4ef08b 0ea22949784845b2924905832d9b62a5--870f56d1fece4a99a6fe16eadf4ef08b a9e0a878f4ac4e718b6534bea0bbd735 870f56d1fece4a99a6fe16eadf4ef08b--a9e0a878f4ac4e718b6534bea0bbd735 946ba279d8394f5d9a77cd125ceddeff a9e0a878f4ac4e718b6534bea0bbd735--946ba279d8394f5d9a77cd125ceddeff 2017e4fe5ab248b58bbecda41624338b 946ba279d8394f5d9a77cd125ceddeff--2017e4fe5ab248b58bbecda41624338b 1444c57f323c459fb256c3134b81ad47 2017e4fe5ab248b58bbecda41624338b--1444c57f323c459fb256c3134b81ad47 ac49252757054a079184f3c6f1df7088 1444c57f323c459fb256c3134b81ad47--ac49252757054a079184f3c6f1df7088 38713859d338400fb905b1d1c9d253d1 ac49252757054a079184f3c6f1df7088--38713859d338400fb905b1d1c9d253d1 37d2dc997fb744029c0bc9d14d1912e8 38713859d338400fb905b1d1c9d253d1--37d2dc997fb744029c0bc9d14d1912e8 40206ba357c44707b4f3d82720214fe5 37d2dc997fb744029c0bc9d14d1912e8--40206ba357c44707b4f3d82720214fe5 63300b2d2ea64bf0bff6936132150c33 40206ba357c44707b4f3d82720214fe5--63300b2d2ea64bf0bff6936132150c33 3b880b88f51c49a0a3833120b32b2c8e 63300b2d2ea64bf0bff6936132150c33--3b880b88f51c49a0a3833120b32b2c8e 50ce772ad8b141abad9f61da50d4cc4b 3b880b88f51c49a0a3833120b32b2c8e--50ce772ad8b141abad9f61da50d4cc4b ee1c0acb90d4444789a3e524bc79aeb6 50ce772ad8b141abad9f61da50d4cc4b--ee1c0acb90d4444789a3e524bc79aeb6 0a25399c934a407bb63bc8437889a723 ee1c0acb90d4444789a3e524bc79aeb6--0a25399c934a407bb63bc8437889a723 c8d09b9c50564b4998a8a1d744227f04 0a25399c934a407bb63bc8437889a723--c8d09b9c50564b4998a8a1d744227f04 5cf00c392de64108b12faab7cf5634b9 c8d09b9c50564b4998a8a1d744227f04--5cf00c392de64108b12faab7cf5634b9 3f9cf5d30d844dd79e29dbe9ab94b826 5cf00c392de64108b12faab7cf5634b9--3f9cf5d30d844dd79e29dbe9ab94b826 74807c70b1b34931b14cc8eab72c1305 3f9cf5d30d844dd79e29dbe9ab94b826--74807c70b1b34931b14cc8eab72c1305 8169d99fe2db477aa08161de55b2ba3b 74807c70b1b34931b14cc8eab72c1305--8169d99fe2db477aa08161de55b2ba3b da8f4caf90454976824a2e9b21a3a137 8169d99fe2db477aa08161de55b2ba3b--da8f4caf90454976824a2e9b21a3a137 bea3e38ee093497cb8534a85cf1ac4ee da8f4caf90454976824a2e9b21a3a137--bea3e38ee093497cb8534a85cf1ac4ee f00d4f4bfde14cf2b10df02ee9a4bdd3 bea3e38ee093497cb8534a85cf1ac4ee--f00d4f4bfde14cf2b10df02ee9a4bdd3 0cbb1712b1144a8ead0af2ca19dbb54a f00d4f4bfde14cf2b10df02ee9a4bdd3--0cbb1712b1144a8ead0af2ca19dbb54a 2a2aaee0eb914aa7b32ddabea9737899 0cbb1712b1144a8ead0af2ca19dbb54a--2a2aaee0eb914aa7b32ddabea9737899 a14db6daea8542cea1e6d2951e7ef98c 2a2aaee0eb914aa7b32ddabea9737899--a14db6daea8542cea1e6d2951e7ef98c 95611a936ae14af7bb862b64a94dbea9 a14db6daea8542cea1e6d2951e7ef98c--95611a936ae14af7bb862b64a94dbea9 4115b39a94a6401cbf6b9b3f16c5c465 95611a936ae14af7bb862b64a94dbea9--4115b39a94a6401cbf6b9b3f16c5c465 f4c4d200c3fe446cb42d1a9376a571b7 4115b39a94a6401cbf6b9b3f16c5c465--f4c4d200c3fe446cb42d1a9376a571b7 8fdfd3c83e04404eb529f756546e2db1 f4c4d200c3fe446cb42d1a9376a571b7--8fdfd3c83e04404eb529f756546e2db1 741f53fc53b84c558180328b14c2be04 8fdfd3c83e04404eb529f756546e2db1--741f53fc53b84c558180328b14c2be04 05f4799f9fed436192091e6734c22da7 741f53fc53b84c558180328b14c2be04--05f4799f9fed436192091e6734c22da7 c6b78f64fc434920a6199e499c288062 05f4799f9fed436192091e6734c22da7--c6b78f64fc434920a6199e499c288062 9a2328cd5f184ca3b8cb305c4bae24a8 c6b78f64fc434920a6199e499c288062--9a2328cd5f184ca3b8cb305c4bae24a8 199edc9a4aa24559829d234778b2b1cb 9a2328cd5f184ca3b8cb305c4bae24a8--199edc9a4aa24559829d234778b2b1cb 74b8a90b35dd4406901f312d67400176 199edc9a4aa24559829d234778b2b1cb--74b8a90b35dd4406901f312d67400176 dbaf8dcd26884ef58fc340998f0bc8de 74b8a90b35dd4406901f312d67400176--dbaf8dcd26884ef58fc340998f0bc8de 88b32196ea7d46de9f77c85b45ef4764 dbaf8dcd26884ef58fc340998f0bc8de--88b32196ea7d46de9f77c85b45ef4764 f6f6db97f27248adbb81a67498dabdf7 88b32196ea7d46de9f77c85b45ef4764--f6f6db97f27248adbb81a67498dabdf7 7dc60365ef944586829c7bca6dca9a95 f6f6db97f27248adbb81a67498dabdf7--7dc60365ef944586829c7bca6dca9a95 7753292c5816409884b4dab64605f566 7dc60365ef944586829c7bca6dca9a95--7753292c5816409884b4dab64605f566 bc16ee8035cf49db81ca77343730946d 7753292c5816409884b4dab64605f566--bc16ee8035cf49db81ca77343730946d 3334ab380a7b486fbd9b887da34389e6 bc16ee8035cf49db81ca77343730946d--3334ab380a7b486fbd9b887da34389e6 3e7c531785bc443a992f4ae661514803 3334ab380a7b486fbd9b887da34389e6--3e7c531785bc443a992f4ae661514803 f236a79c13284e4099e9a6d376f44bab 3e7c531785bc443a992f4ae661514803--f236a79c13284e4099e9a6d376f44bab b93d434ef0304da8a159d1d531e50dad f236a79c13284e4099e9a6d376f44bab--b93d434ef0304da8a159d1d531e50dad 584bcde4cc1949caafbbecf664151e9d b93d434ef0304da8a159d1d531e50dad--584bcde4cc1949caafbbecf664151e9d 0b8dafd9edff45a7af415e80f5142013 584bcde4cc1949caafbbecf664151e9d--0b8dafd9edff45a7af415e80f5142013 e684e8fdce924ce09ab8cc083a445344 0b8dafd9edff45a7af415e80f5142013--e684e8fdce924ce09ab8cc083a445344 b144518661504e158ac83db7f34fc625 e684e8fdce924ce09ab8cc083a445344--b144518661504e158ac83db7f34fc625 1c59c76c95d144deb858c221bda5bca7 b144518661504e158ac83db7f34fc625--1c59c76c95d144deb858c221bda5bca7 ef35747d446c44a3bcd5ed00dfe1ea1e 1c59c76c95d144deb858c221bda5bca7--ef35747d446c44a3bcd5ed00dfe1ea1e 044b4f84fb0a4e7d9dd9f11147acb133 ef35747d446c44a3bcd5ed00dfe1ea1e--044b4f84fb0a4e7d9dd9f11147acb133 4bed5f0c7acc44f2a9b31cbdd970669c 044b4f84fb0a4e7d9dd9f11147acb133--4bed5f0c7acc44f2a9b31cbdd970669c 92eb9f19ac2543b6bc025177b73fdd06 4bed5f0c7acc44f2a9b31cbdd970669c--92eb9f19ac2543b6bc025177b73fdd06 732f618d18ad42b6b5ed3f71eed1f92a 92eb9f19ac2543b6bc025177b73fdd06--732f618d18ad42b6b5ed3f71eed1f92a 923b128860484a5c8d057489a3ebb765 732f618d18ad42b6b5ed3f71eed1f92a--923b128860484a5c8d057489a3ebb765 6108569f18e948db98038b3253bfab73 923b128860484a5c8d057489a3ebb765--6108569f18e948db98038b3253bfab73 9562f642a6734acb8b29aaa9d35a1b44 6108569f18e948db98038b3253bfab73--9562f642a6734acb8b29aaa9d35a1b44 7ed1b58fc93749169bf20640af1a0fb1 9562f642a6734acb8b29aaa9d35a1b44--7ed1b58fc93749169bf20640af1a0fb1 709c81279011450eaec758b072ed5761 7ed1b58fc93749169bf20640af1a0fb1--709c81279011450eaec758b072ed5761 c42643d6715e48ba883baa6f14b3390c 709c81279011450eaec758b072ed5761--c42643d6715e48ba883baa6f14b3390c 60a6e94bc4004a4d8bba1095bc0638a6 c42643d6715e48ba883baa6f14b3390c--60a6e94bc4004a4d8bba1095bc0638a6 12900bb7a32743d4bae01f1677453ca8 60a6e94bc4004a4d8bba1095bc0638a6--12900bb7a32743d4bae01f1677453ca8 bf97cd5fda5846afaa28e10c567e4069 12900bb7a32743d4bae01f1677453ca8--bf97cd5fda5846afaa28e10c567e4069 081d2569117a4fc2bbce0e2da78e4be0 bf97cd5fda5846afaa28e10c567e4069--081d2569117a4fc2bbce0e2da78e4be0 300242237695485e8eaa4cc93f1ac69a 081d2569117a4fc2bbce0e2da78e4be0--300242237695485e8eaa4cc93f1ac69a 89cd9f530514419ebb2118846026cf4c 300242237695485e8eaa4cc93f1ac69a--89cd9f530514419ebb2118846026cf4c 4232418556d44b858ff5c5c7af23fc7a 89cd9f530514419ebb2118846026cf4c--4232418556d44b858ff5c5c7af23fc7a 8f4c01739cda4eef9e1ec9738e8cb922 4232418556d44b858ff5c5c7af23fc7a--8f4c01739cda4eef9e1ec9738e8cb922 154d3b36b76e459c876380df916f3ed5 8f4c01739cda4eef9e1ec9738e8cb922--154d3b36b76e459c876380df916f3ed5 fb0dc7f924e54282b414f5c5b20dfe2f 154d3b36b76e459c876380df916f3ed5--fb0dc7f924e54282b414f5c5b20dfe2f 31d20991131948a1be43fdbfc6ab5601 fb0dc7f924e54282b414f5c5b20dfe2f--31d20991131948a1be43fdbfc6ab5601 550191acfb6a44a8ba87c784cb1ac5c4 31d20991131948a1be43fdbfc6ab5601--550191acfb6a44a8ba87c784cb1ac5c4 6cec528e22a4415daefc7dfabf01b900 550191acfb6a44a8ba87c784cb1ac5c4--6cec528e22a4415daefc7dfabf01b900 79ec9e73568c4238bf18c5a4a9af8553 6cec528e22a4415daefc7dfabf01b900--79ec9e73568c4238bf18c5a4a9af8553 969523df721544d9a28e610ebe5bbdad 79ec9e73568c4238bf18c5a4a9af8553--969523df721544d9a28e610ebe5bbdad 9c8a9fe967cd493182f5f3a99730e3f7 969523df721544d9a28e610ebe5bbdad--9c8a9fe967cd493182f5f3a99730e3f7 a8db806d00694425a1489ec7ee9630f0 9c8a9fe967cd493182f5f3a99730e3f7--a8db806d00694425a1489ec7ee9630f0 3ee8f32b70584165abf77152649375bd a8db806d00694425a1489ec7ee9630f0--3ee8f32b70584165abf77152649375bd ee02f204cd3549e9b2e7d0a9bdb8d201 3ee8f32b70584165abf77152649375bd--ee02f204cd3549e9b2e7d0a9bdb8d201 1aeb3f8c7e7f4ac09833d5460694514a ee02f204cd3549e9b2e7d0a9bdb8d201--1aeb3f8c7e7f4ac09833d5460694514a cc323a031a054d3099d21cfe93c09b05 1aeb3f8c7e7f4ac09833d5460694514a--cc323a031a054d3099d21cfe93c09b05 c4598b4d133748a18f160580a8c148f6 cc323a031a054d3099d21cfe93c09b05--c4598b4d133748a18f160580a8c148f6 b56d9428e7af48d1bda9f9b73889d367 c4598b4d133748a18f160580a8c148f6--b56d9428e7af48d1bda9f9b73889d367 c85e67ee6d344b538a645c22d4c5a7da b56d9428e7af48d1bda9f9b73889d367--c85e67ee6d344b538a645c22d4c5a7da 0dff41acb0774e609655f23ca96ff37d c85e67ee6d344b538a645c22d4c5a7da--0dff41acb0774e609655f23ca96ff37d bbf21c4e4c034d03aec30463b0ae8e7c 0dff41acb0774e609655f23ca96ff37d--bbf21c4e4c034d03aec30463b0ae8e7c 2c60cda725ab4ea29fba6a939458f2c2 bbf21c4e4c034d03aec30463b0ae8e7c--2c60cda725ab4ea29fba6a939458f2c2 75223464f957454884016af9df34c81a 2c60cda725ab4ea29fba6a939458f2c2--75223464f957454884016af9df34c81a d8ad318b8f1345ac99e3cf2164d03e23 75223464f957454884016af9df34c81a--d8ad318b8f1345ac99e3cf2164d03e23 958a2628b1c44e75b652f9f9de00aadd d8ad318b8f1345ac99e3cf2164d03e23--958a2628b1c44e75b652f9f9de00aadd 7910236849f44e00a05ceb52465b77df 958a2628b1c44e75b652f9f9de00aadd--7910236849f44e00a05ceb52465b77df 3e7d7c09b7d94d36894f986e6949b272 7910236849f44e00a05ceb52465b77df--3e7d7c09b7d94d36894f986e6949b272 a096ba4865c44416b923299dae258b60 3e7d7c09b7d94d36894f986e6949b272--a096ba4865c44416b923299dae258b60 d791267670c445e2b10fbfc4d9c2b13d a096ba4865c44416b923299dae258b60--d791267670c445e2b10fbfc4d9c2b13d e0d717f4287a43f7a5b1269665160c06 d791267670c445e2b10fbfc4d9c2b13d--e0d717f4287a43f7a5b1269665160c06 df2d7cea8c5345ce83c9686a7ef523b0 e0d717f4287a43f7a5b1269665160c06--df2d7cea8c5345ce83c9686a7ef523b0 6628fa23240444b183482b3993e77ba8 df2d7cea8c5345ce83c9686a7ef523b0--6628fa23240444b183482b3993e77ba8 6f756c1101f04461afde49cdbbeb9170 6628fa23240444b183482b3993e77ba8--6f756c1101f04461afde49cdbbeb9170 b74b3bd265d84b27863d56dd161c39ee 6f756c1101f04461afde49cdbbeb9170--b74b3bd265d84b27863d56dd161c39ee 807c0d3b13104b5098f0bc593733f1b8 b74b3bd265d84b27863d56dd161c39ee--807c0d3b13104b5098f0bc593733f1b8 fe10555f9a6f447ab26d7538ed7ca0ad 807c0d3b13104b5098f0bc593733f1b8--fe10555f9a6f447ab26d7538ed7ca0ad 5532bf8980254020a4a7944425d7a46e fe10555f9a6f447ab26d7538ed7ca0ad--5532bf8980254020a4a7944425d7a46e 992a5e6921cd4e028eca16ac6df9fb9b 5532bf8980254020a4a7944425d7a46e--992a5e6921cd4e028eca16ac6df9fb9b 7b0dc8f6a37c4d58b556f89f31bfe663 992a5e6921cd4e028eca16ac6df9fb9b--7b0dc8f6a37c4d58b556f89f31bfe663 64487052f4774de9ba0138cb7090ddf4 7b0dc8f6a37c4d58b556f89f31bfe663--64487052f4774de9ba0138cb7090ddf4 53731d5d31df4612a98fa6f5cabb02cc 64487052f4774de9ba0138cb7090ddf4--53731d5d31df4612a98fa6f5cabb02cc 0f25c3745e6046e09ee26f50573b5a63 53731d5d31df4612a98fa6f5cabb02cc--0f25c3745e6046e09ee26f50573b5a63 1b9f294959c2420884a03561d49c7f5f 0f25c3745e6046e09ee26f50573b5a63--1b9f294959c2420884a03561d49c7f5f 8c6bf3abcadb4a01bfb13254ce20aa8c 1b9f294959c2420884a03561d49c7f5f--8c6bf3abcadb4a01bfb13254ce20aa8c 03e6752d698f4ae7b76da49c5591ed69 8c6bf3abcadb4a01bfb13254ce20aa8c--03e6752d698f4ae7b76da49c5591ed69 3cbaa1d2bf3c479698df2e1497b89513 03e6752d698f4ae7b76da49c5591ed69--3cbaa1d2bf3c479698df2e1497b89513 cdbc11281da74afabf2a74722ba7418f 3cbaa1d2bf3c479698df2e1497b89513--cdbc11281da74afabf2a74722ba7418f 5f13b3cd7a9144d5ab3ca337688b0923 cdbc11281da74afabf2a74722ba7418f--5f13b3cd7a9144d5ab3ca337688b0923 2be35efdf99a448c95f17407bae795f3 5f13b3cd7a9144d5ab3ca337688b0923--2be35efdf99a448c95f17407bae795f3 12ead89a4c554e6291adc23e6c97572f 2be35efdf99a448c95f17407bae795f3--12ead89a4c554e6291adc23e6c97572f 9d4248ce94c74338aceb32c38fe85299 12ead89a4c554e6291adc23e6c97572f--9d4248ce94c74338aceb32c38fe85299 f0e7d2b1df5d41fabe34b2787afee304 9d4248ce94c74338aceb32c38fe85299--f0e7d2b1df5d41fabe34b2787afee304 047c1c0e8c034b5ba99e62c78b2f6cca f0e7d2b1df5d41fabe34b2787afee304--047c1c0e8c034b5ba99e62c78b2f6cca 51782c000970416a887dbee48fd440e6 047c1c0e8c034b5ba99e62c78b2f6cca--51782c000970416a887dbee48fd440e6 0621e0a5ed91447bb20ca5588fe51085 51782c000970416a887dbee48fd440e6--0621e0a5ed91447bb20ca5588fe51085 131e9a4b99984ff988788750403e21fa 0621e0a5ed91447bb20ca5588fe51085--131e9a4b99984ff988788750403e21fa 9c9da99c7f18477d903fcdb47c4c4c53 131e9a4b99984ff988788750403e21fa--9c9da99c7f18477d903fcdb47c4c4c53 051b82bcb5ba4c34aa955cfb5edf304c 9c9da99c7f18477d903fcdb47c4c4c53--051b82bcb5ba4c34aa955cfb5edf304c 2bce4033ece046a986e8bb6387796cce 051b82bcb5ba4c34aa955cfb5edf304c--2bce4033ece046a986e8bb6387796cce 74e979b9b18046d0b0054d62693ad1af 2bce4033ece046a986e8bb6387796cce--74e979b9b18046d0b0054d62693ad1af 235a086bee85402da52c4599a3dcbfc9 74e979b9b18046d0b0054d62693ad1af--235a086bee85402da52c4599a3dcbfc9 aae215ec614d4f0dbe163843fb81d024 235a086bee85402da52c4599a3dcbfc9--aae215ec614d4f0dbe163843fb81d024 a5ac0d6221e640aba251ed6bc9ccad6c aae215ec614d4f0dbe163843fb81d024--a5ac0d6221e640aba251ed6bc9ccad6c 9a9c76a8671b4782b11f400a306e9d67 a5ac0d6221e640aba251ed6bc9ccad6c--9a9c76a8671b4782b11f400a306e9d67 05553c0286644d9794955cf179e914c2 9a9c76a8671b4782b11f400a306e9d67--05553c0286644d9794955cf179e914c2 711e5ee57b8a4d90a3f9c8fe008ed18c 05553c0286644d9794955cf179e914c2--711e5ee57b8a4d90a3f9c8fe008ed18c a308f2a89d2b47b1975fca7b9606527e 711e5ee57b8a4d90a3f9c8fe008ed18c--a308f2a89d2b47b1975fca7b9606527e 03960f7e13ca4f45be62fa940b93d9cf a308f2a89d2b47b1975fca7b9606527e--03960f7e13ca4f45be62fa940b93d9cf 12c350df87a2466da26f9a08d49f7876 03960f7e13ca4f45be62fa940b93d9cf--12c350df87a2466da26f9a08d49f7876 7f5f93953c9e40e3b40bbd67174f4c8c 12c350df87a2466da26f9a08d49f7876--7f5f93953c9e40e3b40bbd67174f4c8c 8be9a0fa857e4ef381d85bbb69ebcb6e 7f5f93953c9e40e3b40bbd67174f4c8c--8be9a0fa857e4ef381d85bbb69ebcb6e 810bcfb72efb4e3a9a6388be371449af 8be9a0fa857e4ef381d85bbb69ebcb6e--810bcfb72efb4e3a9a6388be371449af 1ae7962131f244028638eb093b98fe3b 810bcfb72efb4e3a9a6388be371449af--1ae7962131f244028638eb093b98fe3b 8a4d2e06f8504045b1bf162df68cc649 1ae7962131f244028638eb093b98fe3b--8a4d2e06f8504045b1bf162df68cc649 181c989ac4474223a1b25bc2c4702eff 8a4d2e06f8504045b1bf162df68cc649--181c989ac4474223a1b25bc2c4702eff 9c9eec1928744df3a12ce1c5e0d211c1 181c989ac4474223a1b25bc2c4702eff--9c9eec1928744df3a12ce1c5e0d211c1 1e5af6ec379149d9b927be4ae4d96f0f 9c9eec1928744df3a12ce1c5e0d211c1--1e5af6ec379149d9b927be4ae4d96f0f e849d834f38d42acb35084dfb5064973 1e5af6ec379149d9b927be4ae4d96f0f--e849d834f38d42acb35084dfb5064973 09b14c86a8d94e589aa01369a841e565 e849d834f38d42acb35084dfb5064973--09b14c86a8d94e589aa01369a841e565 ef2b55dc58fe4457b50f36678970c6cb 09b14c86a8d94e589aa01369a841e565--ef2b55dc58fe4457b50f36678970c6cb d1df9e2ed4984bcd8f92b7f809dbc81c ef2b55dc58fe4457b50f36678970c6cb--d1df9e2ed4984bcd8f92b7f809dbc81c 0ac200ff1c914b68a4cda763d650222a d1df9e2ed4984bcd8f92b7f809dbc81c--0ac200ff1c914b68a4cda763d650222a 4001105eb5be493fa41c1dce330258a6 RX(b00) 0ac200ff1c914b68a4cda763d650222a--4001105eb5be493fa41c1dce330258a6 1780e152376a47749d05ab4341294ea3 4001105eb5be493fa41c1dce330258a6--1780e152376a47749d05ab4341294ea3 abeb6677fef64277aa391615926705e9 1780e152376a47749d05ab4341294ea3--abeb6677fef64277aa391615926705e9 1545072013554096a8eaa7cb2258e4b6 abeb6677fef64277aa391615926705e9--1545072013554096a8eaa7cb2258e4b6 6f768c4fb14e4ccd962ed69d0592a134 1545072013554096a8eaa7cb2258e4b6--6f768c4fb14e4ccd962ed69d0592a134 55126c64f4e544df85d4632f3b58b6bd 6f768c4fb14e4ccd962ed69d0592a134--55126c64f4e544df85d4632f3b58b6bd cfa5fcbf88584c69a1e7de59a43cc688 55126c64f4e544df85d4632f3b58b6bd--cfa5fcbf88584c69a1e7de59a43cc688 86000258d8b748c0a2e503ab8ed32448 cfa5fcbf88584c69a1e7de59a43cc688--86000258d8b748c0a2e503ab8ed32448 85ed30101f4c407abf4a8a1f65af0fa2 86000258d8b748c0a2e503ab8ed32448--85ed30101f4c407abf4a8a1f65af0fa2 0b31ed7ec293456c935c52b2bf628e3b 85ed30101f4c407abf4a8a1f65af0fa2--0b31ed7ec293456c935c52b2bf628e3b 2ceff20aa90441cbb17d314a88abaa1d 0b31ed7ec293456c935c52b2bf628e3b--2ceff20aa90441cbb17d314a88abaa1d 3f39ebc3ad3848ca9cac99514e552200 2ceff20aa90441cbb17d314a88abaa1d--3f39ebc3ad3848ca9cac99514e552200 91f2edcebdaa4c809907c5eb2767697a 3f39ebc3ad3848ca9cac99514e552200--91f2edcebdaa4c809907c5eb2767697a 4d093d65cd1b43e8a5ad0782a256a28f 91f2edcebdaa4c809907c5eb2767697a--4d093d65cd1b43e8a5ad0782a256a28f d9f92d25559e4fceb6563f14b42a590f 4d093d65cd1b43e8a5ad0782a256a28f--d9f92d25559e4fceb6563f14b42a590f 5f5750ba8de44f7795b689019c422723 d9f92d25559e4fceb6563f14b42a590f--5f5750ba8de44f7795b689019c422723 5554aeeb17704033a40fc3b3428bf525 5f5750ba8de44f7795b689019c422723--5554aeeb17704033a40fc3b3428bf525 46fc2ab2d9c5472baec7444bf9d3a383 5554aeeb17704033a40fc3b3428bf525--46fc2ab2d9c5472baec7444bf9d3a383 ab4b62d9c4f94a418680f0aa543bc76f 46fc2ab2d9c5472baec7444bf9d3a383--ab4b62d9c4f94a418680f0aa543bc76f c871dab8873e46699aac1b44f0e72a7a ab4b62d9c4f94a418680f0aa543bc76f--c871dab8873e46699aac1b44f0e72a7a e7e5645e96d34d6dafbc64161ef386a7 c871dab8873e46699aac1b44f0e72a7a--e7e5645e96d34d6dafbc64161ef386a7 2c5df13adf9d4cff9fcecd119c740b9e e7e5645e96d34d6dafbc64161ef386a7--2c5df13adf9d4cff9fcecd119c740b9e 283fe82c84a1478ca7916251b94a9206 2c5df13adf9d4cff9fcecd119c740b9e--283fe82c84a1478ca7916251b94a9206 47a578a0c31c46ee9545f601413e638c 283fe82c84a1478ca7916251b94a9206--47a578a0c31c46ee9545f601413e638c f14a7a67e09048a69c0ba3d4768d5f87 47a578a0c31c46ee9545f601413e638c--f14a7a67e09048a69c0ba3d4768d5f87 cea6ed6663214043af73001dd92cf7bf f14a7a67e09048a69c0ba3d4768d5f87--cea6ed6663214043af73001dd92cf7bf 8872da833aec48c29084411b68b8b542 cea6ed6663214043af73001dd92cf7bf--8872da833aec48c29084411b68b8b542 66a6a58b59504b42a726224bc731ded8 8872da833aec48c29084411b68b8b542--66a6a58b59504b42a726224bc731ded8 a7dfe415b3ab4fdf8b9050636a62a90e 66a6a58b59504b42a726224bc731ded8--a7dfe415b3ab4fdf8b9050636a62a90e d86d2e243db84558907a8f5024bb56c6 a7dfe415b3ab4fdf8b9050636a62a90e--d86d2e243db84558907a8f5024bb56c6 de514e5fa4144ce19e0a189b854c2bb1 d86d2e243db84558907a8f5024bb56c6--de514e5fa4144ce19e0a189b854c2bb1 b8cb5ecf05de490fbd9125e88930e801 de514e5fa4144ce19e0a189b854c2bb1--b8cb5ecf05de490fbd9125e88930e801 f9859bc06536499a98ccb7bb7a9bc1a5 b8cb5ecf05de490fbd9125e88930e801--f9859bc06536499a98ccb7bb7a9bc1a5 89587bb65e6d4147b1f0adfc69b7d911 f9859bc06536499a98ccb7bb7a9bc1a5--89587bb65e6d4147b1f0adfc69b7d911 1ccb6cd135594c41ae235ce3cf820242 89587bb65e6d4147b1f0adfc69b7d911--1ccb6cd135594c41ae235ce3cf820242 bbc0ab10a8084b94abca9df8d9487625 1ccb6cd135594c41ae235ce3cf820242--bbc0ab10a8084b94abca9df8d9487625 03f5a9706d4f472eb385cb57fa712331 bbc0ab10a8084b94abca9df8d9487625--03f5a9706d4f472eb385cb57fa712331 c4210b4a2bef42fb9bfc234a2f5cf78f 03f5a9706d4f472eb385cb57fa712331--c4210b4a2bef42fb9bfc234a2f5cf78f 410eff45908b4a6bb806e060039dab0c c4210b4a2bef42fb9bfc234a2f5cf78f--410eff45908b4a6bb806e060039dab0c d52a4bc94d52425ab4b8ac24349def66 410eff45908b4a6bb806e060039dab0c--d52a4bc94d52425ab4b8ac24349def66 67841a41877045af876a1c1f28aaa001 d52a4bc94d52425ab4b8ac24349def66--67841a41877045af876a1c1f28aaa001 e44320fd45764ca5b18f5824a28ab6b7 67841a41877045af876a1c1f28aaa001--e44320fd45764ca5b18f5824a28ab6b7 cc27e2b071754ba2ad4bc254b40c662a e44320fd45764ca5b18f5824a28ab6b7--cc27e2b071754ba2ad4bc254b40c662a 34b2e708fab748c79989a2e56bc0ada3 cc27e2b071754ba2ad4bc254b40c662a--34b2e708fab748c79989a2e56bc0ada3 6a6755fe558c492e950fb36d974888f1 34b2e708fab748c79989a2e56bc0ada3--6a6755fe558c492e950fb36d974888f1 baa6b75839414c9b91d3259fcdce4a21 6a6755fe558c492e950fb36d974888f1--baa6b75839414c9b91d3259fcdce4a21 7a676f8c561f4158b3c52a02092490ef baa6b75839414c9b91d3259fcdce4a21--7a676f8c561f4158b3c52a02092490ef 9ca59d08c1b344adb7dce9e505dd985a 7a676f8c561f4158b3c52a02092490ef--9ca59d08c1b344adb7dce9e505dd985a 1fb109d8677f45e69bf9e4d7af85f14b 9ca59d08c1b344adb7dce9e505dd985a--1fb109d8677f45e69bf9e4d7af85f14b 23f36e699cfb4458a274dc74aa609008 1fb109d8677f45e69bf9e4d7af85f14b--23f36e699cfb4458a274dc74aa609008 4ea753cd352c496b9f9bb17841c28d06 23f36e699cfb4458a274dc74aa609008--4ea753cd352c496b9f9bb17841c28d06 378d0460b30748c981b70fb0a15c902e 4ea753cd352c496b9f9bb17841c28d06--378d0460b30748c981b70fb0a15c902e 183d886a121e4216b0bb2490039d8eae 378d0460b30748c981b70fb0a15c902e--183d886a121e4216b0bb2490039d8eae 8d7d655c505b418088f8e0541a474e21 183d886a121e4216b0bb2490039d8eae--8d7d655c505b418088f8e0541a474e21 82d28c4d983d47c4b74ad0c1bc1eea53 8d7d655c505b418088f8e0541a474e21--82d28c4d983d47c4b74ad0c1bc1eea53 fc9d782a23a14f6dbb159e0e9223503f 82d28c4d983d47c4b74ad0c1bc1eea53--fc9d782a23a14f6dbb159e0e9223503f 66f4a79c34f4451ea95c2337c92892df fc9d782a23a14f6dbb159e0e9223503f--66f4a79c34f4451ea95c2337c92892df 05ca5bef5975465b8ac771584da2b61b 66f4a79c34f4451ea95c2337c92892df--05ca5bef5975465b8ac771584da2b61b 14abd17ae00840c5aa744a8e0b9170ef 05ca5bef5975465b8ac771584da2b61b--14abd17ae00840c5aa744a8e0b9170ef 276bbbcae2b8497b9461c4dc1685718d 14abd17ae00840c5aa744a8e0b9170ef--276bbbcae2b8497b9461c4dc1685718d 4d275028c0a64bc18b65ac87f496550e 276bbbcae2b8497b9461c4dc1685718d--4d275028c0a64bc18b65ac87f496550e 44d6088e5da64fd9802c553bdc1388c5 4d275028c0a64bc18b65ac87f496550e--44d6088e5da64fd9802c553bdc1388c5 f17876e0a9cf4a7793d2954a85f59aba 44d6088e5da64fd9802c553bdc1388c5--f17876e0a9cf4a7793d2954a85f59aba db3a9b5843ea43fba1cb4d418925aedb f17876e0a9cf4a7793d2954a85f59aba--db3a9b5843ea43fba1cb4d418925aedb e3ca2b6d31b24147802cb26343cc97b0 db3a9b5843ea43fba1cb4d418925aedb--e3ca2b6d31b24147802cb26343cc97b0 b37a0fcb4cbc4732b007525ecf242aa3 e3ca2b6d31b24147802cb26343cc97b0--b37a0fcb4cbc4732b007525ecf242aa3 0a155b62b85d4e74bca064f43b6e5b6f b37a0fcb4cbc4732b007525ecf242aa3--0a155b62b85d4e74bca064f43b6e5b6f 954fc48b06f44ade96d1f576b2586e23 0a155b62b85d4e74bca064f43b6e5b6f--954fc48b06f44ade96d1f576b2586e23 07d104f608c44694b629dfe96db14f8b 954fc48b06f44ade96d1f576b2586e23--07d104f608c44694b629dfe96db14f8b ea90eeaa8e6e40358cb82d500ba1c0ef 07d104f608c44694b629dfe96db14f8b--ea90eeaa8e6e40358cb82d500ba1c0ef 6b49e10f78f3438ca77a606f32591bf0 ea90eeaa8e6e40358cb82d500ba1c0ef--6b49e10f78f3438ca77a606f32591bf0 6c7e4f29ca2f4c1cac0eb238ea8008d3 6b49e10f78f3438ca77a606f32591bf0--6c7e4f29ca2f4c1cac0eb238ea8008d3 23771f90e28241068918da7fd0332ba3 6c7e4f29ca2f4c1cac0eb238ea8008d3--23771f90e28241068918da7fd0332ba3 518423e9ec824051a79a0838b3c0c5b4 23771f90e28241068918da7fd0332ba3--518423e9ec824051a79a0838b3c0c5b4 aa7e2ab3b2bd45bca2a16607c8689d7e 518423e9ec824051a79a0838b3c0c5b4--aa7e2ab3b2bd45bca2a16607c8689d7e ee0634b011114e91b3e3454a25cd0b8b aa7e2ab3b2bd45bca2a16607c8689d7e--ee0634b011114e91b3e3454a25cd0b8b 73e7dcf50058430fa47af2a2f78049f0 ee0634b011114e91b3e3454a25cd0b8b--73e7dcf50058430fa47af2a2f78049f0 66d75c31fe234464a10323f03f327ddb 73e7dcf50058430fa47af2a2f78049f0--66d75c31fe234464a10323f03f327ddb c8b11c740ab24a3eb2e71f71417185d7 66d75c31fe234464a10323f03f327ddb--c8b11c740ab24a3eb2e71f71417185d7 fd0abfc0fdc6417bbee2b054ee07a011 c8b11c740ab24a3eb2e71f71417185d7--fd0abfc0fdc6417bbee2b054ee07a011 eceb26dbc4124e0986daed8836e3aad3 fd0abfc0fdc6417bbee2b054ee07a011--eceb26dbc4124e0986daed8836e3aad3 7f10c9b6a6ea498fb3496f8f8ebb4c7f eceb26dbc4124e0986daed8836e3aad3--7f10c9b6a6ea498fb3496f8f8ebb4c7f f306444b636849ab94b8f784fb8bd5e6 7f10c9b6a6ea498fb3496f8f8ebb4c7f--f306444b636849ab94b8f784fb8bd5e6 9e634ba3cfef44608adc981406289f45 f306444b636849ab94b8f784fb8bd5e6--9e634ba3cfef44608adc981406289f45 05d64a1a117e489087adf8c5471be110 9e634ba3cfef44608adc981406289f45--05d64a1a117e489087adf8c5471be110 ab84b54c0dfb48b3be92cdee997e4dd7 05d64a1a117e489087adf8c5471be110--ab84b54c0dfb48b3be92cdee997e4dd7 19508b5e06274e389832f0d3756e0bbb ab84b54c0dfb48b3be92cdee997e4dd7--19508b5e06274e389832f0d3756e0bbb 0fd137be71fb423ea12e8748131fcdd2 19508b5e06274e389832f0d3756e0bbb--0fd137be71fb423ea12e8748131fcdd2 0e2c6ec9f99040f9935971366d1d0cfa 0fd137be71fb423ea12e8748131fcdd2--0e2c6ec9f99040f9935971366d1d0cfa 8626c4074bf64ca4afa25fe9d24a1125 0e2c6ec9f99040f9935971366d1d0cfa--8626c4074bf64ca4afa25fe9d24a1125 74424f47f9ad4b5ab5f24631de4ef5d4 8626c4074bf64ca4afa25fe9d24a1125--74424f47f9ad4b5ab5f24631de4ef5d4 dfaa9ffdb5fe49b3acb7d46e959ac2ac 74424f47f9ad4b5ab5f24631de4ef5d4--dfaa9ffdb5fe49b3acb7d46e959ac2ac 00233e2ae57e49e98af3f31fd7343703 dfaa9ffdb5fe49b3acb7d46e959ac2ac--00233e2ae57e49e98af3f31fd7343703 f3267a7bcaf84e72892df9721954ffab 00233e2ae57e49e98af3f31fd7343703--f3267a7bcaf84e72892df9721954ffab df1fb46c76e44df8a8230e34674d0738 f3267a7bcaf84e72892df9721954ffab--df1fb46c76e44df8a8230e34674d0738 a83e95d7c1324f7798c1083c810f0df9 df1fb46c76e44df8a8230e34674d0738--a83e95d7c1324f7798c1083c810f0df9 fcfd9f738f9049d6bb4c5d6de044c51d a83e95d7c1324f7798c1083c810f0df9--fcfd9f738f9049d6bb4c5d6de044c51d e610671cb37e46a0ac831e8dd7097bd3 fcfd9f738f9049d6bb4c5d6de044c51d--e610671cb37e46a0ac831e8dd7097bd3 139d4529f6114b579ba548e8688384e2 e610671cb37e46a0ac831e8dd7097bd3--139d4529f6114b579ba548e8688384e2 c2c6251dae3b4931b92468f4b547c283 139d4529f6114b579ba548e8688384e2--c2c6251dae3b4931b92468f4b547c283 d17b9d4186c34d60ab9c4ce1398d408d c2c6251dae3b4931b92468f4b547c283--d17b9d4186c34d60ab9c4ce1398d408d bff1777f03834a1394defef199805010 d17b9d4186c34d60ab9c4ce1398d408d--bff1777f03834a1394defef199805010 3f148bc004124add809ca08d96a3f51f bff1777f03834a1394defef199805010--3f148bc004124add809ca08d96a3f51f 6462b034d6644cfcb6b5cc387ad7644c 3f148bc004124add809ca08d96a3f51f--6462b034d6644cfcb6b5cc387ad7644c b8aba8485b4149a4b56c60da6144cd81 6462b034d6644cfcb6b5cc387ad7644c--b8aba8485b4149a4b56c60da6144cd81 b8a6bf55765b43b0baf96c9587b90661 b8aba8485b4149a4b56c60da6144cd81--b8a6bf55765b43b0baf96c9587b90661 7d8e74fcdbd74bc3975817c020133ed1 b8a6bf55765b43b0baf96c9587b90661--7d8e74fcdbd74bc3975817c020133ed1 7ffb703797db4d018e9208722fb4ea16 7d8e74fcdbd74bc3975817c020133ed1--7ffb703797db4d018e9208722fb4ea16 ead5fefcae6c42548d9708ab5aa0f557 7ffb703797db4d018e9208722fb4ea16--ead5fefcae6c42548d9708ab5aa0f557 888e76fdd77d4046bfdb382e12637b98 ead5fefcae6c42548d9708ab5aa0f557--888e76fdd77d4046bfdb382e12637b98 ad7dae32e6634bf6844bd61fc1bf40d2 888e76fdd77d4046bfdb382e12637b98--ad7dae32e6634bf6844bd61fc1bf40d2 fef607773ba54561860a0ffc8b724bce ad7dae32e6634bf6844bd61fc1bf40d2--fef607773ba54561860a0ffc8b724bce d878b62d1ef04065bef5f5a492ef2648 fef607773ba54561860a0ffc8b724bce--d878b62d1ef04065bef5f5a492ef2648 4442c5777da44fabb01d5c647bbd39da d878b62d1ef04065bef5f5a492ef2648--4442c5777da44fabb01d5c647bbd39da de1d90a43c904590883de332b0b9d0e3 4442c5777da44fabb01d5c647bbd39da--de1d90a43c904590883de332b0b9d0e3 6b21a85356b04a3ca218829a961a5b8e de1d90a43c904590883de332b0b9d0e3--6b21a85356b04a3ca218829a961a5b8e 73227777bff14266a85681e159c054a6 6b21a85356b04a3ca218829a961a5b8e--73227777bff14266a85681e159c054a6 b1497891435a4aa693fbe6457da9194d 73227777bff14266a85681e159c054a6--b1497891435a4aa693fbe6457da9194d 1ce59622eae44ff79a61296ab7b83251 b1497891435a4aa693fbe6457da9194d--1ce59622eae44ff79a61296ab7b83251 ac1363d5755442d58537620ddfae912d 1ce59622eae44ff79a61296ab7b83251--ac1363d5755442d58537620ddfae912d 98fa7ebe16ea4c3b93cc7f3befa37fa1 ac1363d5755442d58537620ddfae912d--98fa7ebe16ea4c3b93cc7f3befa37fa1 179c2115587d4ec08574e278c92171db 98fa7ebe16ea4c3b93cc7f3befa37fa1--179c2115587d4ec08574e278c92171db 4d8e1c75ce694dd3a439a2a43297ff62 179c2115587d4ec08574e278c92171db--4d8e1c75ce694dd3a439a2a43297ff62 d8aec1974a7d439b977ad200489a0b0e 4d8e1c75ce694dd3a439a2a43297ff62--d8aec1974a7d439b977ad200489a0b0e b1a259a672ae41cbb3005f3b041dd35f d8aec1974a7d439b977ad200489a0b0e--b1a259a672ae41cbb3005f3b041dd35f 30c07a8d315347da8c119711054f6a5c b1a259a672ae41cbb3005f3b041dd35f--30c07a8d315347da8c119711054f6a5c 721f0030276543928d8f4ce21cab884b 30c07a8d315347da8c119711054f6a5c--721f0030276543928d8f4ce21cab884b 1a36cf39fe22451aa694103f1acc5a80 721f0030276543928d8f4ce21cab884b--1a36cf39fe22451aa694103f1acc5a80 dec7fed369a54647ba30d8c04986e2e5 1a36cf39fe22451aa694103f1acc5a80--dec7fed369a54647ba30d8c04986e2e5 468c1c7573b84d0581065880fa81c70f dec7fed369a54647ba30d8c04986e2e5--468c1c7573b84d0581065880fa81c70f b88f8e2013564a6faa8c331c1808f690 468c1c7573b84d0581065880fa81c70f--b88f8e2013564a6faa8c331c1808f690 97fd5fea58104832b156a10688169a1e b88f8e2013564a6faa8c331c1808f690--97fd5fea58104832b156a10688169a1e 36b8e3da16774e608a4cf29e1c023d0f 97fd5fea58104832b156a10688169a1e--36b8e3da16774e608a4cf29e1c023d0f 728bad9609ba4836a1aef4c5b8227f8e 36b8e3da16774e608a4cf29e1c023d0f--728bad9609ba4836a1aef4c5b8227f8e cbdda8e8bce3486fae1c68c036d27a73 728bad9609ba4836a1aef4c5b8227f8e--cbdda8e8bce3486fae1c68c036d27a73 fe3adc0d1a92461481b200cbcfbb6152 cbdda8e8bce3486fae1c68c036d27a73--fe3adc0d1a92461481b200cbcfbb6152 ff59d16fa3534e738864a67fa40b68ed fe3adc0d1a92461481b200cbcfbb6152--ff59d16fa3534e738864a67fa40b68ed 5ac6828b04574cb4ad992d5997e1927a ff59d16fa3534e738864a67fa40b68ed--5ac6828b04574cb4ad992d5997e1927a 8d5bff314ffa400fb2a20a848db11b30 5ac6828b04574cb4ad992d5997e1927a--8d5bff314ffa400fb2a20a848db11b30 c3cf1544267d48f2a0d71fd733c5ade5 8d5bff314ffa400fb2a20a848db11b30--c3cf1544267d48f2a0d71fd733c5ade5 16c4ee8c8c234398b3459730f8e9abc8 c3cf1544267d48f2a0d71fd733c5ade5--16c4ee8c8c234398b3459730f8e9abc8 446e70c5a2be4d82bb6e7010b5e23f1b 16c4ee8c8c234398b3459730f8e9abc8--446e70c5a2be4d82bb6e7010b5e23f1b e8763c6bdd22428988f2e83a2498340c 446e70c5a2be4d82bb6e7010b5e23f1b--e8763c6bdd22428988f2e83a2498340c 6951303f81f742b19187630ed2777a1d e8763c6bdd22428988f2e83a2498340c--6951303f81f742b19187630ed2777a1d dd55976c69f44acca51ab41f55218df8 6951303f81f742b19187630ed2777a1d--dd55976c69f44acca51ab41f55218df8 362de489054c415c98e0975c505c203b dd55976c69f44acca51ab41f55218df8--362de489054c415c98e0975c505c203b 3882dca7720d420aa47c7a18d94dd5e0 362de489054c415c98e0975c505c203b--3882dca7720d420aa47c7a18d94dd5e0 f505c4ec03d24bf38a1c4084597dd139 3882dca7720d420aa47c7a18d94dd5e0--f505c4ec03d24bf38a1c4084597dd139 88a6a8eddd424b59b23e892ad81b6fdd f505c4ec03d24bf38a1c4084597dd139--88a6a8eddd424b59b23e892ad81b6fdd 387da31c368a4aa797e3423525bd70bd 88a6a8eddd424b59b23e892ad81b6fdd--387da31c368a4aa797e3423525bd70bd b1c163f0f3c040669ef6b6e644383ae3 387da31c368a4aa797e3423525bd70bd--b1c163f0f3c040669ef6b6e644383ae3 240c60f7dd0a4af3ae63f4f388d8e09a b1c163f0f3c040669ef6b6e644383ae3--240c60f7dd0a4af3ae63f4f388d8e09a c7fa9bf620bc4f0788be0b50105dbbd4 RX(b10) 240c60f7dd0a4af3ae63f4f388d8e09a--c7fa9bf620bc4f0788be0b50105dbbd4 52e59dfc4e434d35bef004def5776b20 c7fa9bf620bc4f0788be0b50105dbbd4--52e59dfc4e434d35bef004def5776b20 cdf9363aa150460ab409d1a83d6973ba 4acd4314b0914b0f95c6b5222d64064a X 01b41043b32b47a88a3852dda94857f1--4acd4314b0914b0f95c6b5222d64064a 1f767aec097644f4a2ab2c9053c6cae1 2 4acd4314b0914b0f95c6b5222d64064a--d8c5cdd147e945eab7178a9dc878804e 23c6c880a7c14ed2aa9cf76977e05868 4acd4314b0914b0f95c6b5222d64064a--23c6c880a7c14ed2aa9cf76977e05868 173048eb59bc462086d7e2b85f132c39 23c6c880a7c14ed2aa9cf76977e05868--173048eb59bc462086d7e2b85f132c39 cc270617957c4748aca4e650a6985e87 173048eb59bc462086d7e2b85f132c39--cc270617957c4748aca4e650a6985e87 85833c32936145f98dbc8dec0ee2dbda cc270617957c4748aca4e650a6985e87--85833c32936145f98dbc8dec0ee2dbda 783feaf50c6f44a4b32336bf757923bb 85833c32936145f98dbc8dec0ee2dbda--783feaf50c6f44a4b32336bf757923bb ce95c14d659743b5b26e58f548cd5db0 783feaf50c6f44a4b32336bf757923bb--ce95c14d659743b5b26e58f548cd5db0 9a05926f95f34149b20e286b8e3571dd ce95c14d659743b5b26e58f548cd5db0--9a05926f95f34149b20e286b8e3571dd 248246c4df334e46a524661142078042 9a05926f95f34149b20e286b8e3571dd--248246c4df334e46a524661142078042 640cf9213c2347cf9c0e4f761751d148 248246c4df334e46a524661142078042--640cf9213c2347cf9c0e4f761751d148 ba7a07805d6943efae579bbe241a492e 640cf9213c2347cf9c0e4f761751d148--ba7a07805d6943efae579bbe241a492e e4424905c3514c7c9bf42568b245eb78 ba7a07805d6943efae579bbe241a492e--e4424905c3514c7c9bf42568b245eb78 e111af40e820466da0e261afa9792a91 e4424905c3514c7c9bf42568b245eb78--e111af40e820466da0e261afa9792a91 92fd309f69174e369fc7657a381850b1 e111af40e820466da0e261afa9792a91--92fd309f69174e369fc7657a381850b1 e1ea5faff1f74d19b973bf81eb7cd3c7 X 92fd309f69174e369fc7657a381850b1--e1ea5faff1f74d19b973bf81eb7cd3c7 e1ea5faff1f74d19b973bf81eb7cd3c7--50ce772ad8b141abad9f61da50d4cc4b 18c08847e4274bc6975bd533f779c3c4 X e1ea5faff1f74d19b973bf81eb7cd3c7--18c08847e4274bc6975bd533f779c3c4 18c08847e4274bc6975bd533f779c3c4--ee1c0acb90d4444789a3e524bc79aeb6 af08afb6f6cb4d9f8c554c431438dff8 RZ(-1.0*g0) 18c08847e4274bc6975bd533f779c3c4--af08afb6f6cb4d9f8c554c431438dff8 5e1f546efb354c6085e84ed3e7bcef0b X af08afb6f6cb4d9f8c554c431438dff8--5e1f546efb354c6085e84ed3e7bcef0b 5e1f546efb354c6085e84ed3e7bcef0b--c8d09b9c50564b4998a8a1d744227f04 6e7ae0fc3fd24e799593aa73645381d0 X 5e1f546efb354c6085e84ed3e7bcef0b--6e7ae0fc3fd24e799593aa73645381d0 6e7ae0fc3fd24e799593aa73645381d0--5cf00c392de64108b12faab7cf5634b9 a9bcec58851147aeaf3f6ecd5d4c2a13 6e7ae0fc3fd24e799593aa73645381d0--a9bcec58851147aeaf3f6ecd5d4c2a13 667a6e7cde4a40a88d588487c9209c11 a9bcec58851147aeaf3f6ecd5d4c2a13--667a6e7cde4a40a88d588487c9209c11 8f032ba43aad406b9222a3dd3bce4e30 667a6e7cde4a40a88d588487c9209c11--8f032ba43aad406b9222a3dd3bce4e30 54b050c8a9a44693a18a04400ebaacc6 X 8f032ba43aad406b9222a3dd3bce4e30--54b050c8a9a44693a18a04400ebaacc6 54b050c8a9a44693a18a04400ebaacc6--da8f4caf90454976824a2e9b21a3a137 0342d2066cba48fdae808fae72343f63 X 54b050c8a9a44693a18a04400ebaacc6--0342d2066cba48fdae808fae72343f63 0342d2066cba48fdae808fae72343f63--bea3e38ee093497cb8534a85cf1ac4ee b18309dd42cd481e9f98a82ccb873f30 0342d2066cba48fdae808fae72343f63--b18309dd42cd481e9f98a82ccb873f30 ec9f7762eede4f198334b8598f457935 b18309dd42cd481e9f98a82ccb873f30--ec9f7762eede4f198334b8598f457935 04bbfff4628348ef9dbed0018b476122 ec9f7762eede4f198334b8598f457935--04bbfff4628348ef9dbed0018b476122 6c15a0cea2a84befbee5e10069ccf96a 04bbfff4628348ef9dbed0018b476122--6c15a0cea2a84befbee5e10069ccf96a 4d262e13b8d34332914d58676e486d3f 6c15a0cea2a84befbee5e10069ccf96a--4d262e13b8d34332914d58676e486d3f 35dec7ea8c664baca470b8a711297297 4d262e13b8d34332914d58676e486d3f--35dec7ea8c664baca470b8a711297297 99e41f83fa564addbf4abbb02d054968 35dec7ea8c664baca470b8a711297297--99e41f83fa564addbf4abbb02d054968 6ef38da91c864bc3a562483f1f68b090 X 99e41f83fa564addbf4abbb02d054968--6ef38da91c864bc3a562483f1f68b090 6ef38da91c864bc3a562483f1f68b090--8fdfd3c83e04404eb529f756546e2db1 63727677e62f4ecb951d27b3e387d15f X 6ef38da91c864bc3a562483f1f68b090--63727677e62f4ecb951d27b3e387d15f 63727677e62f4ecb951d27b3e387d15f--741f53fc53b84c558180328b14c2be04 8e3496888bf047d899b5af5c554702d2 63727677e62f4ecb951d27b3e387d15f--8e3496888bf047d899b5af5c554702d2 1641e54115ed4aa6bd115fc028c52190 8e3496888bf047d899b5af5c554702d2--1641e54115ed4aa6bd115fc028c52190 879620c9f779435db3df1836090a83e1 1641e54115ed4aa6bd115fc028c52190--879620c9f779435db3df1836090a83e1 a6bfacdeec514303904331a6dfd22683 879620c9f779435db3df1836090a83e1--a6bfacdeec514303904331a6dfd22683 6a33eaf8ecc6432dbdf4c9b5d241ee7b a6bfacdeec514303904331a6dfd22683--6a33eaf8ecc6432dbdf4c9b5d241ee7b e8e6293aa32e426fa313aadbe29f7b0a 6a33eaf8ecc6432dbdf4c9b5d241ee7b--e8e6293aa32e426fa313aadbe29f7b0a 6b861cd510fa442b8aa45210d5cab7f5 e8e6293aa32e426fa313aadbe29f7b0a--6b861cd510fa442b8aa45210d5cab7f5 b45d72be37e5457ca868aa295e42d41b 6b861cd510fa442b8aa45210d5cab7f5--b45d72be37e5457ca868aa295e42d41b 9a8f0ead85be438eaa18a595b5694827 b45d72be37e5457ca868aa295e42d41b--9a8f0ead85be438eaa18a595b5694827 7a70b71f5cb74ab394b821897ba1d818 X 9a8f0ead85be438eaa18a595b5694827--7a70b71f5cb74ab394b821897ba1d818 7a70b71f5cb74ab394b821897ba1d818--7753292c5816409884b4dab64605f566 2af7ab5e41a141a8b31e7c8403796a89 X 7a70b71f5cb74ab394b821897ba1d818--2af7ab5e41a141a8b31e7c8403796a89 2af7ab5e41a141a8b31e7c8403796a89--bc16ee8035cf49db81ca77343730946d 55750ca9f8e048c5a7ab3e47d84ea02b 2af7ab5e41a141a8b31e7c8403796a89--55750ca9f8e048c5a7ab3e47d84ea02b 202e7c85ed774ad78e9902a4d6a2bede 55750ca9f8e048c5a7ab3e47d84ea02b--202e7c85ed774ad78e9902a4d6a2bede b98155b9d1b04a63936f58986474ca18 202e7c85ed774ad78e9902a4d6a2bede--b98155b9d1b04a63936f58986474ca18 34ec10c5fcb347aa8c4960fe4c68590a b98155b9d1b04a63936f58986474ca18--34ec10c5fcb347aa8c4960fe4c68590a 0abf3076d01d4845acf9252e77307635 34ec10c5fcb347aa8c4960fe4c68590a--0abf3076d01d4845acf9252e77307635 a0c2204cef33428588920ddc6655f877 0abf3076d01d4845acf9252e77307635--a0c2204cef33428588920ddc6655f877 aa58173498c743c383562f23f26f63b5 a0c2204cef33428588920ddc6655f877--aa58173498c743c383562f23f26f63b5 005fafe6bee74333ab40545d21a4419e aa58173498c743c383562f23f26f63b5--005fafe6bee74333ab40545d21a4419e 9e578b44b7584ebaa694fdf59ba76abc 005fafe6bee74333ab40545d21a4419e--9e578b44b7584ebaa694fdf59ba76abc 8106ecddb85540de90165489c29c2af2 9e578b44b7584ebaa694fdf59ba76abc--8106ecddb85540de90165489c29c2af2 add522e2b77646c6b272801fe2cffc8d 8106ecddb85540de90165489c29c2af2--add522e2b77646c6b272801fe2cffc8d 76218c69931049c69dd35ed88d9e3943 add522e2b77646c6b272801fe2cffc8d--76218c69931049c69dd35ed88d9e3943 084052cca1964a118a5ed882fa010076 76218c69931049c69dd35ed88d9e3943--084052cca1964a118a5ed882fa010076 a1a1a758a68c478aa5744981d62aacd1 X 084052cca1964a118a5ed882fa010076--a1a1a758a68c478aa5744981d62aacd1 a1a1a758a68c478aa5744981d62aacd1--732f618d18ad42b6b5ed3f71eed1f92a d37ebbda89dd4c8eadc57632655edb77 a1a1a758a68c478aa5744981d62aacd1--d37ebbda89dd4c8eadc57632655edb77 57c0b45dd62a4d2bb623b577fb63c7ba d37ebbda89dd4c8eadc57632655edb77--57c0b45dd62a4d2bb623b577fb63c7ba d605fbd1ba824e9bbb77ef12c8ba7993 57c0b45dd62a4d2bb623b577fb63c7ba--d605fbd1ba824e9bbb77ef12c8ba7993 9f0cb6b2f5b740db93410f5b20709860 d605fbd1ba824e9bbb77ef12c8ba7993--9f0cb6b2f5b740db93410f5b20709860 9b8c3c573f934c3b84531b2579c1fb61 9f0cb6b2f5b740db93410f5b20709860--9b8c3c573f934c3b84531b2579c1fb61 a6f48edc804c4388ba312a8be491afc0 9b8c3c573f934c3b84531b2579c1fb61--a6f48edc804c4388ba312a8be491afc0 737328ff507448b3b9a45d61e276658e a6f48edc804c4388ba312a8be491afc0--737328ff507448b3b9a45d61e276658e 5b3792ecc262429c8e37b8d2e4844a08 737328ff507448b3b9a45d61e276658e--5b3792ecc262429c8e37b8d2e4844a08 e455acee63e44db18ce1fb63f5bb763c 5b3792ecc262429c8e37b8d2e4844a08--e455acee63e44db18ce1fb63f5bb763c 77ecb5db18304be7bccd29fca4a45a2c e455acee63e44db18ce1fb63f5bb763c--77ecb5db18304be7bccd29fca4a45a2c 1cd61a5af1074949a8d53776cdf5e3fb 77ecb5db18304be7bccd29fca4a45a2c--1cd61a5af1074949a8d53776cdf5e3fb a7dd836852f14f06a253633c4026c9ba 1cd61a5af1074949a8d53776cdf5e3fb--a7dd836852f14f06a253633c4026c9ba e4c932e8b78d4c1bb86758ebcb62c5d9 a7dd836852f14f06a253633c4026c9ba--e4c932e8b78d4c1bb86758ebcb62c5d9 47536b65a1944c4ca0d4ee29bee1abe4 e4c932e8b78d4c1bb86758ebcb62c5d9--47536b65a1944c4ca0d4ee29bee1abe4 92c1a66d1cd343e6a4006fb015256422 47536b65a1944c4ca0d4ee29bee1abe4--92c1a66d1cd343e6a4006fb015256422 b088f7169b9843dd87163a3d37d5b63f 92c1a66d1cd343e6a4006fb015256422--b088f7169b9843dd87163a3d37d5b63f c1cd63becd8f4fd18bad8c567944c67d b088f7169b9843dd87163a3d37d5b63f--c1cd63becd8f4fd18bad8c567944c67d 25d0738058764fc5adfc9769a0555c3f c1cd63becd8f4fd18bad8c567944c67d--25d0738058764fc5adfc9769a0555c3f a3fd0c89a4b24bd59d8a085ca6ccad39 25d0738058764fc5adfc9769a0555c3f--a3fd0c89a4b24bd59d8a085ca6ccad39 264afce2506f477ca4b6cf04b41f4ae3 a3fd0c89a4b24bd59d8a085ca6ccad39--264afce2506f477ca4b6cf04b41f4ae3 daa80fedeb894aac996e29d6e4e4ffdb 264afce2506f477ca4b6cf04b41f4ae3--daa80fedeb894aac996e29d6e4e4ffdb f7a94df51593458aab43835b4060bcc1 daa80fedeb894aac996e29d6e4e4ffdb--f7a94df51593458aab43835b4060bcc1 baa0ac91c54f4285b135a96b095d21a5 f7a94df51593458aab43835b4060bcc1--baa0ac91c54f4285b135a96b095d21a5 e586e9831d244fafb7b04222c3a5ac4d baa0ac91c54f4285b135a96b095d21a5--e586e9831d244fafb7b04222c3a5ac4d 0782722ff5bf4801bd2b6a0ab9d105c8 e586e9831d244fafb7b04222c3a5ac4d--0782722ff5bf4801bd2b6a0ab9d105c8 a5b7e6b434d34739afdc5cf3202d8cf4 0782722ff5bf4801bd2b6a0ab9d105c8--a5b7e6b434d34739afdc5cf3202d8cf4 c288d2b491a04f12a35a7a62d2e2f5ed a5b7e6b434d34739afdc5cf3202d8cf4--c288d2b491a04f12a35a7a62d2e2f5ed 9f294ba9774f4564a3d5671c6eaa740f c288d2b491a04f12a35a7a62d2e2f5ed--9f294ba9774f4564a3d5671c6eaa740f 7efce93bf566459db8eaf881756c47a2 9f294ba9774f4564a3d5671c6eaa740f--7efce93bf566459db8eaf881756c47a2 57a60d69aa824ab58a750ced4559f147 7efce93bf566459db8eaf881756c47a2--57a60d69aa824ab58a750ced4559f147 a52ebbcb07d0474885f3798d425c9070 57a60d69aa824ab58a750ced4559f147--a52ebbcb07d0474885f3798d425c9070 8f748555fd0045808cf58e860a990152 a52ebbcb07d0474885f3798d425c9070--8f748555fd0045808cf58e860a990152 cfdd2d9ce65c400c931855de8a8a4b0e 8f748555fd0045808cf58e860a990152--cfdd2d9ce65c400c931855de8a8a4b0e 55b21b45701c48eabaeb365ba6ac2bc8 cfdd2d9ce65c400c931855de8a8a4b0e--55b21b45701c48eabaeb365ba6ac2bc8 b54a1d6427884466882fda50a2213651 55b21b45701c48eabaeb365ba6ac2bc8--b54a1d6427884466882fda50a2213651 21edde29dceb417f89f14d44b9bc8249 b54a1d6427884466882fda50a2213651--21edde29dceb417f89f14d44b9bc8249 5c66ac00b87c41d0b534f02d63864532 21edde29dceb417f89f14d44b9bc8249--5c66ac00b87c41d0b534f02d63864532 c56d8867db7047a68d2664c7533e8d5a 5c66ac00b87c41d0b534f02d63864532--c56d8867db7047a68d2664c7533e8d5a 6b9fe631ba794ce98cd238484dd430d6 c56d8867db7047a68d2664c7533e8d5a--6b9fe631ba794ce98cd238484dd430d6 e12f1640bca94f0d97fa2744f1215e62 6b9fe631ba794ce98cd238484dd430d6--e12f1640bca94f0d97fa2744f1215e62 78434d55fb12459391ceaa03fd09299c e12f1640bca94f0d97fa2744f1215e62--78434d55fb12459391ceaa03fd09299c c7886ee22dbd47b9b76a7a808e450b56 78434d55fb12459391ceaa03fd09299c--c7886ee22dbd47b9b76a7a808e450b56 27bc650d28744d09a45f7bb514fd4fbb c7886ee22dbd47b9b76a7a808e450b56--27bc650d28744d09a45f7bb514fd4fbb f0e6895cff9347df9641a8d3b2df2f3f 27bc650d28744d09a45f7bb514fd4fbb--f0e6895cff9347df9641a8d3b2df2f3f bd1e4d2fce4c45d09decbe57a631e4ac f0e6895cff9347df9641a8d3b2df2f3f--bd1e4d2fce4c45d09decbe57a631e4ac 06e6abfe1935462ba7d88f85443de805 bd1e4d2fce4c45d09decbe57a631e4ac--06e6abfe1935462ba7d88f85443de805 58e42331e2d248bd97cc9ee1f61c3df2 06e6abfe1935462ba7d88f85443de805--58e42331e2d248bd97cc9ee1f61c3df2 5df41b0260af4dc28f46226eb60ddcf9 58e42331e2d248bd97cc9ee1f61c3df2--5df41b0260af4dc28f46226eb60ddcf9 a62cad6be69f453bade5be2d4c55184b 5df41b0260af4dc28f46226eb60ddcf9--a62cad6be69f453bade5be2d4c55184b 900755e459c044fabf2456ffe6819ab3 a62cad6be69f453bade5be2d4c55184b--900755e459c044fabf2456ffe6819ab3 a2a16761e1f545c781255d1f2b75513c 900755e459c044fabf2456ffe6819ab3--a2a16761e1f545c781255d1f2b75513c 444cfcaa70aa4ae5a609a43da200af5d a2a16761e1f545c781255d1f2b75513c--444cfcaa70aa4ae5a609a43da200af5d ede69d990f544d39a7d09e536d9cb063 444cfcaa70aa4ae5a609a43da200af5d--ede69d990f544d39a7d09e536d9cb063 4f52d00761484f709a26ffecd970f2e9 ede69d990f544d39a7d09e536d9cb063--4f52d00761484f709a26ffecd970f2e9 1d01e66e9d654284b72af042ff135845 4f52d00761484f709a26ffecd970f2e9--1d01e66e9d654284b72af042ff135845 81358817b32241b09e6cbc05da3c5be7 1d01e66e9d654284b72af042ff135845--81358817b32241b09e6cbc05da3c5be7 b6410d67a1724fd2b7935e3c6340ba46 81358817b32241b09e6cbc05da3c5be7--b6410d67a1724fd2b7935e3c6340ba46 ce032d490571457781e2e82e8562c7e2 b6410d67a1724fd2b7935e3c6340ba46--ce032d490571457781e2e82e8562c7e2 6e9de5c43e07478983d007e62286a335 ce032d490571457781e2e82e8562c7e2--6e9de5c43e07478983d007e62286a335 933bb80922cd4c40aaad4bec6a836f99 6e9de5c43e07478983d007e62286a335--933bb80922cd4c40aaad4bec6a836f99 32b7048084a04fd085decb28b24b74ee 933bb80922cd4c40aaad4bec6a836f99--32b7048084a04fd085decb28b24b74ee 192251190ef1491d8c44f3c34871e256 32b7048084a04fd085decb28b24b74ee--192251190ef1491d8c44f3c34871e256 2ff83d896c2a4031917f14b0e71dd6eb 192251190ef1491d8c44f3c34871e256--2ff83d896c2a4031917f14b0e71dd6eb 6d57b094efc345acb451bdd3978774d4 2ff83d896c2a4031917f14b0e71dd6eb--6d57b094efc345acb451bdd3978774d4 7fb18268f8f14855aa15a11a901088d4 6d57b094efc345acb451bdd3978774d4--7fb18268f8f14855aa15a11a901088d4 0b5292a5b8534526b6163919cb88ece3 7fb18268f8f14855aa15a11a901088d4--0b5292a5b8534526b6163919cb88ece3 9a44e1bd644f4e9ab37d783690d92eaa 0b5292a5b8534526b6163919cb88ece3--9a44e1bd644f4e9ab37d783690d92eaa b13345a3435b4098aec86931b05fbe28 9a44e1bd644f4e9ab37d783690d92eaa--b13345a3435b4098aec86931b05fbe28 c3ecc0deba2e4b208a054634d1fc038d b13345a3435b4098aec86931b05fbe28--c3ecc0deba2e4b208a054634d1fc038d 7b391b14794c43c29bc5e7b7c033d4c0 c3ecc0deba2e4b208a054634d1fc038d--7b391b14794c43c29bc5e7b7c033d4c0 5cc2f6700cb04f3696c42d728da39cff 7b391b14794c43c29bc5e7b7c033d4c0--5cc2f6700cb04f3696c42d728da39cff a8c4fb5c4d3d4ea19b23812682aaee32 5cc2f6700cb04f3696c42d728da39cff--a8c4fb5c4d3d4ea19b23812682aaee32 295e73773d194f4b80e1eeb651fc0274 a8c4fb5c4d3d4ea19b23812682aaee32--295e73773d194f4b80e1eeb651fc0274 42ebfb1d789a47c0a17ff002e251e624 295e73773d194f4b80e1eeb651fc0274--42ebfb1d789a47c0a17ff002e251e624 af490d41b8784b109711383b06a89f09 42ebfb1d789a47c0a17ff002e251e624--af490d41b8784b109711383b06a89f09 a67a729d6d39447b837d27bcc19cfb6a af490d41b8784b109711383b06a89f09--a67a729d6d39447b837d27bcc19cfb6a e27ca10962884aaea96651f42bf10681 a67a729d6d39447b837d27bcc19cfb6a--e27ca10962884aaea96651f42bf10681 8a153695c73d4db888ed5a41bf78722e e27ca10962884aaea96651f42bf10681--8a153695c73d4db888ed5a41bf78722e a2413152cb4542549006e3512c6b89f9 8a153695c73d4db888ed5a41bf78722e--a2413152cb4542549006e3512c6b89f9 e9abe3baa090424d9be3155da17f2c36 a2413152cb4542549006e3512c6b89f9--e9abe3baa090424d9be3155da17f2c36 f7a12f6cc9d64333b50b974a46f915d9 e9abe3baa090424d9be3155da17f2c36--f7a12f6cc9d64333b50b974a46f915d9 dffd519f4c064b5baad4fa9d5fbc462a f7a12f6cc9d64333b50b974a46f915d9--dffd519f4c064b5baad4fa9d5fbc462a 46a92b528a874ab0a41ad115b3503e92 dffd519f4c064b5baad4fa9d5fbc462a--46a92b528a874ab0a41ad115b3503e92 c8712588941f442ca21642011206d2bc 46a92b528a874ab0a41ad115b3503e92--c8712588941f442ca21642011206d2bc dfc6169da9ae40e8931dc1b42235feab c8712588941f442ca21642011206d2bc--dfc6169da9ae40e8931dc1b42235feab 3cd27932beeb4638ba5beae0b5fac02c dfc6169da9ae40e8931dc1b42235feab--3cd27932beeb4638ba5beae0b5fac02c 8951ee8fd634426fad520ccad176f960 3cd27932beeb4638ba5beae0b5fac02c--8951ee8fd634426fad520ccad176f960 e38d5a46f4b1432e897a81bab94d1d55 8951ee8fd634426fad520ccad176f960--e38d5a46f4b1432e897a81bab94d1d55 157410c6e3ec4c4d9fa9422b4253ea83 e38d5a46f4b1432e897a81bab94d1d55--157410c6e3ec4c4d9fa9422b4253ea83 a93c9e204b4842f6826ae1947a6e4b4f 157410c6e3ec4c4d9fa9422b4253ea83--a93c9e204b4842f6826ae1947a6e4b4f df9b6c7a80f04a58abcc5232d3d7280e a93c9e204b4842f6826ae1947a6e4b4f--df9b6c7a80f04a58abcc5232d3d7280e 79fa820305ab439085ae318f714893f3 df9b6c7a80f04a58abcc5232d3d7280e--79fa820305ab439085ae318f714893f3 cd78d3658e7b4238baa402c605b2ccd5 79fa820305ab439085ae318f714893f3--cd78d3658e7b4238baa402c605b2ccd5 3e4b1f0532864122838d874ea18c2421 RX(b01) cd78d3658e7b4238baa402c605b2ccd5--3e4b1f0532864122838d874ea18c2421 72c0c4ba1e0b416e93637b7d2d58eb27 X 3e4b1f0532864122838d874ea18c2421--72c0c4ba1e0b416e93637b7d2d58eb27 72c0c4ba1e0b416e93637b7d2d58eb27--1780e152376a47749d05ab4341294ea3 66170b005f7c4852a7f19e5ba494263d 72c0c4ba1e0b416e93637b7d2d58eb27--66170b005f7c4852a7f19e5ba494263d ba7939b9d0264aff994127bec93c9969 66170b005f7c4852a7f19e5ba494263d--ba7939b9d0264aff994127bec93c9969 cc81d1e96cb44766af2f4a741715a974 ba7939b9d0264aff994127bec93c9969--cc81d1e96cb44766af2f4a741715a974 87121c0b401949fe90f00a8718efe01e cc81d1e96cb44766af2f4a741715a974--87121c0b401949fe90f00a8718efe01e ecabca8d301e4ef18814cf139b3da3a5 87121c0b401949fe90f00a8718efe01e--ecabca8d301e4ef18814cf139b3da3a5 0228b0a4cafa4312b52ed781fd299ea7 ecabca8d301e4ef18814cf139b3da3a5--0228b0a4cafa4312b52ed781fd299ea7 581bcf2f2dc84d4f93012ea1892c5ee1 0228b0a4cafa4312b52ed781fd299ea7--581bcf2f2dc84d4f93012ea1892c5ee1 ec53eb5be44a44f69c7b9e7754419566 581bcf2f2dc84d4f93012ea1892c5ee1--ec53eb5be44a44f69c7b9e7754419566 c971302bd1684b43b513284d22a8d75a ec53eb5be44a44f69c7b9e7754419566--c971302bd1684b43b513284d22a8d75a 6c928d06ecff4a0d8a8cdffbd5c9807c c971302bd1684b43b513284d22a8d75a--6c928d06ecff4a0d8a8cdffbd5c9807c dcc5bde0d556452485654e297dcb921d 6c928d06ecff4a0d8a8cdffbd5c9807c--dcc5bde0d556452485654e297dcb921d 757faefa2f0346d58f4a407fbbc24f58 dcc5bde0d556452485654e297dcb921d--757faefa2f0346d58f4a407fbbc24f58 89a9e993fe574f0392e23696833b95e5 757faefa2f0346d58f4a407fbbc24f58--89a9e993fe574f0392e23696833b95e5 ec640b432f34489da80ee7c6be754f2c X 89a9e993fe574f0392e23696833b95e5--ec640b432f34489da80ee7c6be754f2c ec640b432f34489da80ee7c6be754f2c--5f5750ba8de44f7795b689019c422723 3bb1a1c0b80e4e95847add2c916c6b52 X ec640b432f34489da80ee7c6be754f2c--3bb1a1c0b80e4e95847add2c916c6b52 3bb1a1c0b80e4e95847add2c916c6b52--5554aeeb17704033a40fc3b3428bf525 99373a5716b24c78b2521f1e75e58854 RZ(-1.0*g1) 3bb1a1c0b80e4e95847add2c916c6b52--99373a5716b24c78b2521f1e75e58854 d9eb744ccd54441ca38823e47aa97ea2 X 99373a5716b24c78b2521f1e75e58854--d9eb744ccd54441ca38823e47aa97ea2 d9eb744ccd54441ca38823e47aa97ea2--ab4b62d9c4f94a418680f0aa543bc76f df4d233e8ccc466b84c1c3bcc0fb0dfc X d9eb744ccd54441ca38823e47aa97ea2--df4d233e8ccc466b84c1c3bcc0fb0dfc df4d233e8ccc466b84c1c3bcc0fb0dfc--c871dab8873e46699aac1b44f0e72a7a 14c4399824874bc59844c370bd8fb455 df4d233e8ccc466b84c1c3bcc0fb0dfc--14c4399824874bc59844c370bd8fb455 c828ec6823e540e4885f8d23052b7f71 14c4399824874bc59844c370bd8fb455--c828ec6823e540e4885f8d23052b7f71 912a8b7742c64044ac91b8e09a800dce c828ec6823e540e4885f8d23052b7f71--912a8b7742c64044ac91b8e09a800dce 76619d6d035f479686bc76ed0c6b6e09 X 912a8b7742c64044ac91b8e09a800dce--76619d6d035f479686bc76ed0c6b6e09 76619d6d035f479686bc76ed0c6b6e09--47a578a0c31c46ee9545f601413e638c 35a62ad01b704794bf41d749706d60b2 X 76619d6d035f479686bc76ed0c6b6e09--35a62ad01b704794bf41d749706d60b2 35a62ad01b704794bf41d749706d60b2--f14a7a67e09048a69c0ba3d4768d5f87 a5ad83976e9c4129bfc535421e1d75e3 35a62ad01b704794bf41d749706d60b2--a5ad83976e9c4129bfc535421e1d75e3 97c5dd3212af4d54affb867112e8c4e5 a5ad83976e9c4129bfc535421e1d75e3--97c5dd3212af4d54affb867112e8c4e5 11f1ab1efaf74c07ac9d177919824279 97c5dd3212af4d54affb867112e8c4e5--11f1ab1efaf74c07ac9d177919824279 f8c53c4e5a42485bb9a729c800ddd0c1 11f1ab1efaf74c07ac9d177919824279--f8c53c4e5a42485bb9a729c800ddd0c1 460554f3f2894a459d99e5c69f57ac47 f8c53c4e5a42485bb9a729c800ddd0c1--460554f3f2894a459d99e5c69f57ac47 50371b9ac4dd4cfbab6114ecf2469fab 460554f3f2894a459d99e5c69f57ac47--50371b9ac4dd4cfbab6114ecf2469fab 25346345a85c47ebb125ababa509681e 50371b9ac4dd4cfbab6114ecf2469fab--25346345a85c47ebb125ababa509681e 995ab9566bd8401a9e3c5a32b7d6130d X 25346345a85c47ebb125ababa509681e--995ab9566bd8401a9e3c5a32b7d6130d 995ab9566bd8401a9e3c5a32b7d6130d--f9859bc06536499a98ccb7bb7a9bc1a5 d1b8bfcad3c84e35ac34c8c02d88be87 X 995ab9566bd8401a9e3c5a32b7d6130d--d1b8bfcad3c84e35ac34c8c02d88be87 d1b8bfcad3c84e35ac34c8c02d88be87--89587bb65e6d4147b1f0adfc69b7d911 284fc584442643b282fc8a16d0b27b61 d1b8bfcad3c84e35ac34c8c02d88be87--284fc584442643b282fc8a16d0b27b61 f8113894fb6a407c9742db59b6a6dee7 284fc584442643b282fc8a16d0b27b61--f8113894fb6a407c9742db59b6a6dee7 0b1951038ae940ed8f2376b7619542af f8113894fb6a407c9742db59b6a6dee7--0b1951038ae940ed8f2376b7619542af 63e0abe0f40e488b8a0df8fbb107d328 0b1951038ae940ed8f2376b7619542af--63e0abe0f40e488b8a0df8fbb107d328 2e6a84bf1f00463096264173610e0f57 63e0abe0f40e488b8a0df8fbb107d328--2e6a84bf1f00463096264173610e0f57 aaa418ef76ab477bbad82033a6cc6066 2e6a84bf1f00463096264173610e0f57--aaa418ef76ab477bbad82033a6cc6066 0db80d560c304c92b0cba9a3e9941573 aaa418ef76ab477bbad82033a6cc6066--0db80d560c304c92b0cba9a3e9941573 e08a3c48cd244872b02776954df0a4f5 0db80d560c304c92b0cba9a3e9941573--e08a3c48cd244872b02776954df0a4f5 efb247bca60547009b27ad89ede81d41 e08a3c48cd244872b02776954df0a4f5--efb247bca60547009b27ad89ede81d41 8dfedca7e35c4ed8a359f25ba04f767a X efb247bca60547009b27ad89ede81d41--8dfedca7e35c4ed8a359f25ba04f767a 8dfedca7e35c4ed8a359f25ba04f767a--34b2e708fab748c79989a2e56bc0ada3 afb778ab52be4d45a7a85f9d0e953c0a X 8dfedca7e35c4ed8a359f25ba04f767a--afb778ab52be4d45a7a85f9d0e953c0a afb778ab52be4d45a7a85f9d0e953c0a--6a6755fe558c492e950fb36d974888f1 8560e165ef484aad8ccd08c1a8f64f5b afb778ab52be4d45a7a85f9d0e953c0a--8560e165ef484aad8ccd08c1a8f64f5b b3dc14e11e0641c39ec88c3ba279ad69 8560e165ef484aad8ccd08c1a8f64f5b--b3dc14e11e0641c39ec88c3ba279ad69 24f64389a6c6422983f6d54701dac43d b3dc14e11e0641c39ec88c3ba279ad69--24f64389a6c6422983f6d54701dac43d 5311822fcd72443eb8b93f00802fee6a 24f64389a6c6422983f6d54701dac43d--5311822fcd72443eb8b93f00802fee6a 4463c21fd48542f0bc8e252919598291 5311822fcd72443eb8b93f00802fee6a--4463c21fd48542f0bc8e252919598291 a2574960f3c44c9ab8cc265c01ec46cc 4463c21fd48542f0bc8e252919598291--a2574960f3c44c9ab8cc265c01ec46cc 8f4dd8c2d6374d95a6ad9b2edaf86374 a2574960f3c44c9ab8cc265c01ec46cc--8f4dd8c2d6374d95a6ad9b2edaf86374 34f9574054a3447db70a6540c659bf6e 8f4dd8c2d6374d95a6ad9b2edaf86374--34f9574054a3447db70a6540c659bf6e 1a19d0dbd19f4f21acb3e2612fcd8915 34f9574054a3447db70a6540c659bf6e--1a19d0dbd19f4f21acb3e2612fcd8915 9be20e1b379e4fa29b6527ae9f3a7990 1a19d0dbd19f4f21acb3e2612fcd8915--9be20e1b379e4fa29b6527ae9f3a7990 0905720fea694b8597e04e420052b173 9be20e1b379e4fa29b6527ae9f3a7990--0905720fea694b8597e04e420052b173 39225f51e02f465ab1d76b7e88734026 0905720fea694b8597e04e420052b173--39225f51e02f465ab1d76b7e88734026 5c115affd4d04c1eae095644733b550a 39225f51e02f465ab1d76b7e88734026--5c115affd4d04c1eae095644733b550a 64bf2aa2d0a24b848872c9fd4aaa4d8d X 5c115affd4d04c1eae095644733b550a--64bf2aa2d0a24b848872c9fd4aaa4d8d 64bf2aa2d0a24b848872c9fd4aaa4d8d--14abd17ae00840c5aa744a8e0b9170ef 4e0c135804d340acbacbf1de6cf398ca 64bf2aa2d0a24b848872c9fd4aaa4d8d--4e0c135804d340acbacbf1de6cf398ca 5dff7c71bbb449e8aa44d2d1b4011b6f 4e0c135804d340acbacbf1de6cf398ca--5dff7c71bbb449e8aa44d2d1b4011b6f c21497abc9d642509953d23b57b0c56e 5dff7c71bbb449e8aa44d2d1b4011b6f--c21497abc9d642509953d23b57b0c56e 279756e8c4454b889a621cf6563fdbee c21497abc9d642509953d23b57b0c56e--279756e8c4454b889a621cf6563fdbee 70d2f464c0dd4c588fba210edf497ebc 279756e8c4454b889a621cf6563fdbee--70d2f464c0dd4c588fba210edf497ebc 90d59f75e17d45b79bceb77b0335989a 70d2f464c0dd4c588fba210edf497ebc--90d59f75e17d45b79bceb77b0335989a 8c7b9a60119d48daae46d3831af9bb88 90d59f75e17d45b79bceb77b0335989a--8c7b9a60119d48daae46d3831af9bb88 931e8b51e07b4ab1b902fee4d16401ed 8c7b9a60119d48daae46d3831af9bb88--931e8b51e07b4ab1b902fee4d16401ed f05581881b9b4aa99d9946dc4727efae 931e8b51e07b4ab1b902fee4d16401ed--f05581881b9b4aa99d9946dc4727efae 6680548dbb56474787cdc826dade3fb1 f05581881b9b4aa99d9946dc4727efae--6680548dbb56474787cdc826dade3fb1 c0caf0454afd410b8e3a3ff80e765f54 6680548dbb56474787cdc826dade3fb1--c0caf0454afd410b8e3a3ff80e765f54 739dff504bac4228b4bd0c982a1f61de c0caf0454afd410b8e3a3ff80e765f54--739dff504bac4228b4bd0c982a1f61de edd001211af34c559c9f6f3c175e7c13 739dff504bac4228b4bd0c982a1f61de--edd001211af34c559c9f6f3c175e7c13 2cf457047f1a4fe790c91d3766a0555d edd001211af34c559c9f6f3c175e7c13--2cf457047f1a4fe790c91d3766a0555d 1477e05ec11e40549d78998233b56867 2cf457047f1a4fe790c91d3766a0555d--1477e05ec11e40549d78998233b56867 6ccc3ca5d8ba4c97b219179cc3d9e295 1477e05ec11e40549d78998233b56867--6ccc3ca5d8ba4c97b219179cc3d9e295 3d6886d35ece49018acf5758055bf399 6ccc3ca5d8ba4c97b219179cc3d9e295--3d6886d35ece49018acf5758055bf399 738527fc85e447a7aabb92d20641e28a 3d6886d35ece49018acf5758055bf399--738527fc85e447a7aabb92d20641e28a 34852912fc964719bf606dce8ffccd32 738527fc85e447a7aabb92d20641e28a--34852912fc964719bf606dce8ffccd32 6e5d4165bff1470ab0a80957a494d052 34852912fc964719bf606dce8ffccd32--6e5d4165bff1470ab0a80957a494d052 3ffff9f8818f4e5a82acc66d7ebbf373 6e5d4165bff1470ab0a80957a494d052--3ffff9f8818f4e5a82acc66d7ebbf373 a1cbab82930f4b11b6645b44df18d554 3ffff9f8818f4e5a82acc66d7ebbf373--a1cbab82930f4b11b6645b44df18d554 5648df9fee024b06849187124f83f6e5 a1cbab82930f4b11b6645b44df18d554--5648df9fee024b06849187124f83f6e5 3c8b62c664f44f00b108586a84fc5f39 5648df9fee024b06849187124f83f6e5--3c8b62c664f44f00b108586a84fc5f39 973bc934142946be816c73c2d047edae 3c8b62c664f44f00b108586a84fc5f39--973bc934142946be816c73c2d047edae b5e81829507141248ed78fb01e5d1da9 973bc934142946be816c73c2d047edae--b5e81829507141248ed78fb01e5d1da9 d4bda9c310cf40719c050935fa782fb6 b5e81829507141248ed78fb01e5d1da9--d4bda9c310cf40719c050935fa782fb6 f6db139686e943e3a1b4661188673991 d4bda9c310cf40719c050935fa782fb6--f6db139686e943e3a1b4661188673991 eae63ace45f744d39fa8049ce553dca2 f6db139686e943e3a1b4661188673991--eae63ace45f744d39fa8049ce553dca2 f7f6fb14f08f4850b46a9d9f0fbfb148 eae63ace45f744d39fa8049ce553dca2--f7f6fb14f08f4850b46a9d9f0fbfb148 ae96fd4035ac4eb9b41370e59306e7c7 f7f6fb14f08f4850b46a9d9f0fbfb148--ae96fd4035ac4eb9b41370e59306e7c7 7e80c77d875a4bc3bc422933ab4083ef ae96fd4035ac4eb9b41370e59306e7c7--7e80c77d875a4bc3bc422933ab4083ef 1a3da6eecbd0403181ae11c0736ecac0 7e80c77d875a4bc3bc422933ab4083ef--1a3da6eecbd0403181ae11c0736ecac0 8026619f54524836b947c2373c9441cd 1a3da6eecbd0403181ae11c0736ecac0--8026619f54524836b947c2373c9441cd 359577ff2cbc404d96505dd53fc74368 8026619f54524836b947c2373c9441cd--359577ff2cbc404d96505dd53fc74368 3691122db9ab4af295003724340ca0ed 359577ff2cbc404d96505dd53fc74368--3691122db9ab4af295003724340ca0ed 6ecfb499736140538b51812853b4b031 3691122db9ab4af295003724340ca0ed--6ecfb499736140538b51812853b4b031 82d21b70706642ea8aa4afdbee60de03 6ecfb499736140538b51812853b4b031--82d21b70706642ea8aa4afdbee60de03 7a96678da7c84cb0af5a455d7f42e23a 82d21b70706642ea8aa4afdbee60de03--7a96678da7c84cb0af5a455d7f42e23a 905f6cb0dc0d45a18b3ba828a96d732d 7a96678da7c84cb0af5a455d7f42e23a--905f6cb0dc0d45a18b3ba828a96d732d 83144710d9d046e283ce035de9847a4a 905f6cb0dc0d45a18b3ba828a96d732d--83144710d9d046e283ce035de9847a4a 980df35668cd496490a59448e80b26d9 83144710d9d046e283ce035de9847a4a--980df35668cd496490a59448e80b26d9 41fdcfa4932844328162043c0db9e646 980df35668cd496490a59448e80b26d9--41fdcfa4932844328162043c0db9e646 0385000270b04995b473e02dfde3f459 41fdcfa4932844328162043c0db9e646--0385000270b04995b473e02dfde3f459 667a87a042a1405ba2bf96c4ed31c2d1 0385000270b04995b473e02dfde3f459--667a87a042a1405ba2bf96c4ed31c2d1 a40f8ba205e14c75971761997679979e 667a87a042a1405ba2bf96c4ed31c2d1--a40f8ba205e14c75971761997679979e 8007aa2bf19f4a7fbe08fe1ccf73f50b a40f8ba205e14c75971761997679979e--8007aa2bf19f4a7fbe08fe1ccf73f50b 3857456689e644aba777ee3d52605894 8007aa2bf19f4a7fbe08fe1ccf73f50b--3857456689e644aba777ee3d52605894 fb232ea80b794963bf927d11c81f1cb0 3857456689e644aba777ee3d52605894--fb232ea80b794963bf927d11c81f1cb0 762341978fb94ba490f033532d399ea9 fb232ea80b794963bf927d11c81f1cb0--762341978fb94ba490f033532d399ea9 27cc5f853010441698fe6ec6f8a53c97 762341978fb94ba490f033532d399ea9--27cc5f853010441698fe6ec6f8a53c97 befcf96169fc485587d6dc4a37baafaf 27cc5f853010441698fe6ec6f8a53c97--befcf96169fc485587d6dc4a37baafaf 13a6a515786e487fb521e416167ec7af befcf96169fc485587d6dc4a37baafaf--13a6a515786e487fb521e416167ec7af 2427cbfbd34e4b99a64e0b8dfcca53db 13a6a515786e487fb521e416167ec7af--2427cbfbd34e4b99a64e0b8dfcca53db 7e022f26ba7749279d770fc5f8026eec 2427cbfbd34e4b99a64e0b8dfcca53db--7e022f26ba7749279d770fc5f8026eec b3221a45bb3541198313bf91fc7611bd 7e022f26ba7749279d770fc5f8026eec--b3221a45bb3541198313bf91fc7611bd 8542092efab04dd18aba3d56e6d9a946 b3221a45bb3541198313bf91fc7611bd--8542092efab04dd18aba3d56e6d9a946 8a75d64aa9f44dd784e29428fccfaa9f 8542092efab04dd18aba3d56e6d9a946--8a75d64aa9f44dd784e29428fccfaa9f 27e40ecaa9944d039336f7b820fd13e3 8a75d64aa9f44dd784e29428fccfaa9f--27e40ecaa9944d039336f7b820fd13e3 b9d0429b674c4e0487db7f395d73834c 27e40ecaa9944d039336f7b820fd13e3--b9d0429b674c4e0487db7f395d73834c 18bcfe8f67a94d1095697caab66b0065 b9d0429b674c4e0487db7f395d73834c--18bcfe8f67a94d1095697caab66b0065 71195fedadac4d06a05955963447f6fc 18bcfe8f67a94d1095697caab66b0065--71195fedadac4d06a05955963447f6fc 1334bad4544740569f46dccc10bf64de 71195fedadac4d06a05955963447f6fc--1334bad4544740569f46dccc10bf64de 6b66dca83fcf45d9b50688b0c482c223 1334bad4544740569f46dccc10bf64de--6b66dca83fcf45d9b50688b0c482c223 f84ffbedcde24479a6f3cb0a9ffcad8d 6b66dca83fcf45d9b50688b0c482c223--f84ffbedcde24479a6f3cb0a9ffcad8d 1ce5c7983f62482096a1338971556b9b f84ffbedcde24479a6f3cb0a9ffcad8d--1ce5c7983f62482096a1338971556b9b d7d5ab2ecaf747d3ae1b3529bb4abf16 1ce5c7983f62482096a1338971556b9b--d7d5ab2ecaf747d3ae1b3529bb4abf16 6ff8251aeb284fc8ba6c74917264f9de d7d5ab2ecaf747d3ae1b3529bb4abf16--6ff8251aeb284fc8ba6c74917264f9de 7ef347d96f304825a97ab7a6a3f4cfe8 6ff8251aeb284fc8ba6c74917264f9de--7ef347d96f304825a97ab7a6a3f4cfe8 ca62f14195b542eeadecedacfd1f6ada 7ef347d96f304825a97ab7a6a3f4cfe8--ca62f14195b542eeadecedacfd1f6ada 44910d99bb8e4b639e01e926afb806dc ca62f14195b542eeadecedacfd1f6ada--44910d99bb8e4b639e01e926afb806dc dd7d3657b6174a9c8264fdc4b0a1e910 44910d99bb8e4b639e01e926afb806dc--dd7d3657b6174a9c8264fdc4b0a1e910 ec74673fbaa3470ea2b296a5b4323c2f dd7d3657b6174a9c8264fdc4b0a1e910--ec74673fbaa3470ea2b296a5b4323c2f b0e5216335f34101aa2b00ca3deadfda ec74673fbaa3470ea2b296a5b4323c2f--b0e5216335f34101aa2b00ca3deadfda 3c1e8aa9e50a4e508a2070b2e6cb32fd b0e5216335f34101aa2b00ca3deadfda--3c1e8aa9e50a4e508a2070b2e6cb32fd e393196f80994150b9e2607eab9797ee 3c1e8aa9e50a4e508a2070b2e6cb32fd--e393196f80994150b9e2607eab9797ee 3f57b22683954ed3aaa6d72589c59aad e393196f80994150b9e2607eab9797ee--3f57b22683954ed3aaa6d72589c59aad a32156f0e66942999937e0cb7d8d717a 3f57b22683954ed3aaa6d72589c59aad--a32156f0e66942999937e0cb7d8d717a 6a3a436bb3874ff2b1431ac64dc69edd a32156f0e66942999937e0cb7d8d717a--6a3a436bb3874ff2b1431ac64dc69edd 307920d3aff74976978ab2069563e991 6a3a436bb3874ff2b1431ac64dc69edd--307920d3aff74976978ab2069563e991 a1706cac603642f18110fe072c73823a 307920d3aff74976978ab2069563e991--a1706cac603642f18110fe072c73823a 3c6fe7f1a77f428e8c8b51c6046ef4e3 a1706cac603642f18110fe072c73823a--3c6fe7f1a77f428e8c8b51c6046ef4e3 8f0b97a571d847088ff6a1e2e249ecc1 3c6fe7f1a77f428e8c8b51c6046ef4e3--8f0b97a571d847088ff6a1e2e249ecc1 6ed37848e1324e128be5eff1774aaabc 8f0b97a571d847088ff6a1e2e249ecc1--6ed37848e1324e128be5eff1774aaabc 2286252013ca4a3b93f441765177e285 6ed37848e1324e128be5eff1774aaabc--2286252013ca4a3b93f441765177e285 59f3a3dc2e5a4ee9a7223190baec3a35 2286252013ca4a3b93f441765177e285--59f3a3dc2e5a4ee9a7223190baec3a35 6ad635d9dc03455cac26460ad6a38c6d 59f3a3dc2e5a4ee9a7223190baec3a35--6ad635d9dc03455cac26460ad6a38c6d 92af114403784b59986387ac2c3652a0 6ad635d9dc03455cac26460ad6a38c6d--92af114403784b59986387ac2c3652a0 d7c39540514e4e5ca89a026011252f98 92af114403784b59986387ac2c3652a0--d7c39540514e4e5ca89a026011252f98 7560e3426b774bd395f007c0868bae00 d7c39540514e4e5ca89a026011252f98--7560e3426b774bd395f007c0868bae00 28e500d7c62d48e1bdc145ec244dccd3 7560e3426b774bd395f007c0868bae00--28e500d7c62d48e1bdc145ec244dccd3 786b63f352d54579a29dadc48bcf49d8 28e500d7c62d48e1bdc145ec244dccd3--786b63f352d54579a29dadc48bcf49d8 87612d2dbd4840ee88dc7a798b09577e 786b63f352d54579a29dadc48bcf49d8--87612d2dbd4840ee88dc7a798b09577e b2604d041b2e450fae15e49d953a2f7f RX(b11) 87612d2dbd4840ee88dc7a798b09577e--b2604d041b2e450fae15e49d953a2f7f b2604d041b2e450fae15e49d953a2f7f--cdf9363aa150460ab409d1a83d6973ba afd8edd532c845fca5ead6cba0e14f7a 2b83739eb55e4c86a929c66c635f598d 1f767aec097644f4a2ab2c9053c6cae1--2b83739eb55e4c86a929c66c635f598d 3a51073a4d52419bae027bea46df9dfd 3 2c8fe70c4aef4f9191604d3baf00683c X 2b83739eb55e4c86a929c66c635f598d--2c8fe70c4aef4f9191604d3baf00683c 2c8fe70c4aef4f9191604d3baf00683c--23c6c880a7c14ed2aa9cf76977e05868 c8198e1b3574455b94c367518a91ddef 2c8fe70c4aef4f9191604d3baf00683c--c8198e1b3574455b94c367518a91ddef 3682ead38f2441f38ac78995ba40d0e1 c8198e1b3574455b94c367518a91ddef--3682ead38f2441f38ac78995ba40d0e1 f8ada3460c5446a7bf99219f4b9afd16 3682ead38f2441f38ac78995ba40d0e1--f8ada3460c5446a7bf99219f4b9afd16 f4e21449c58d48fc81e17338590a250e f8ada3460c5446a7bf99219f4b9afd16--f4e21449c58d48fc81e17338590a250e ac967b969c0e4f5fa66398bacdfd9f7b f4e21449c58d48fc81e17338590a250e--ac967b969c0e4f5fa66398bacdfd9f7b 4033b754b4e54cc1bfb3d174004b380d ac967b969c0e4f5fa66398bacdfd9f7b--4033b754b4e54cc1bfb3d174004b380d 92f8d08827464ee58cf25c9d4f2dd6e7 4033b754b4e54cc1bfb3d174004b380d--92f8d08827464ee58cf25c9d4f2dd6e7 f34a32a7361445b4844d1ea0d4401c83 92f8d08827464ee58cf25c9d4f2dd6e7--f34a32a7361445b4844d1ea0d4401c83 b2c5478dc2bd4c0e9059d39f062cfcd4 f34a32a7361445b4844d1ea0d4401c83--b2c5478dc2bd4c0e9059d39f062cfcd4 c3695b6df3794e55b19a7148645597e2 b2c5478dc2bd4c0e9059d39f062cfcd4--c3695b6df3794e55b19a7148645597e2 22dc471c4d7b495795679d5213ef8540 c3695b6df3794e55b19a7148645597e2--22dc471c4d7b495795679d5213ef8540 4dd975eddb2840b890eaa075f2f6c440 X 22dc471c4d7b495795679d5213ef8540--4dd975eddb2840b890eaa075f2f6c440 4dd975eddb2840b890eaa075f2f6c440--92fd309f69174e369fc7657a381850b1 cb81d5a1a22b42b1b221f4a165a7aa80 4dd975eddb2840b890eaa075f2f6c440--cb81d5a1a22b42b1b221f4a165a7aa80 2a340d222a8e4fbd91f8f97e16fa6b0c cb81d5a1a22b42b1b221f4a165a7aa80--2a340d222a8e4fbd91f8f97e16fa6b0c 76c8e393ccc24487af2fb790585dc90d 2a340d222a8e4fbd91f8f97e16fa6b0c--76c8e393ccc24487af2fb790585dc90d 2064b3ca1c964a7b9ea1f749f8630378 76c8e393ccc24487af2fb790585dc90d--2064b3ca1c964a7b9ea1f749f8630378 878dcbe7672a4518b47e233c5a2aa9b1 2064b3ca1c964a7b9ea1f749f8630378--878dcbe7672a4518b47e233c5a2aa9b1 415be54498324aa1964bfbbff8d127b3 X 878dcbe7672a4518b47e233c5a2aa9b1--415be54498324aa1964bfbbff8d127b3 415be54498324aa1964bfbbff8d127b3--a9bcec58851147aeaf3f6ecd5d4c2a13 160c372b4d2f482093af2a7f82f8dac7 RZ(-1.0*g0) 415be54498324aa1964bfbbff8d127b3--160c372b4d2f482093af2a7f82f8dac7 2f9ae6a5644b4af6a9973130a8db4058 X 160c372b4d2f482093af2a7f82f8dac7--2f9ae6a5644b4af6a9973130a8db4058 2f9ae6a5644b4af6a9973130a8db4058--8f032ba43aad406b9222a3dd3bce4e30 bba9b88e3b784c8abaceea6e251b4e63 2f9ae6a5644b4af6a9973130a8db4058--bba9b88e3b784c8abaceea6e251b4e63 dcd7328150dc43419b33c2353a42469b bba9b88e3b784c8abaceea6e251b4e63--dcd7328150dc43419b33c2353a42469b 2006c7f8a6064b8191c49ee8f9f5f924 X dcd7328150dc43419b33c2353a42469b--2006c7f8a6064b8191c49ee8f9f5f924 2006c7f8a6064b8191c49ee8f9f5f924--b18309dd42cd481e9f98a82ccb873f30 488a10c6d4a3480f9202a29add025cda 2006c7f8a6064b8191c49ee8f9f5f924--488a10c6d4a3480f9202a29add025cda d689219ad3ea4416b8e64bc6982a159c 488a10c6d4a3480f9202a29add025cda--d689219ad3ea4416b8e64bc6982a159c 93e513bbb5374948a5abbf4ec600cb5f d689219ad3ea4416b8e64bc6982a159c--93e513bbb5374948a5abbf4ec600cb5f b301ed67f61448768766b21dd3185e6b 93e513bbb5374948a5abbf4ec600cb5f--b301ed67f61448768766b21dd3185e6b 2178b3a3cfc84d1a9437a44b93e20846 b301ed67f61448768766b21dd3185e6b--2178b3a3cfc84d1a9437a44b93e20846 a0128ff56ca94179b939870568642021 X 2178b3a3cfc84d1a9437a44b93e20846--a0128ff56ca94179b939870568642021 a0128ff56ca94179b939870568642021--99e41f83fa564addbf4abbb02d054968 336353f51d3745c0bad2b7b2146d70c5 a0128ff56ca94179b939870568642021--336353f51d3745c0bad2b7b2146d70c5 5374db5f6bf4492dba3632409f86c9b5 336353f51d3745c0bad2b7b2146d70c5--5374db5f6bf4492dba3632409f86c9b5 b0e2630ac0d24da4a1438c1e04cdbee1 X 5374db5f6bf4492dba3632409f86c9b5--b0e2630ac0d24da4a1438c1e04cdbee1 b0e2630ac0d24da4a1438c1e04cdbee1--8e3496888bf047d899b5af5c554702d2 5bb8f031bc7f4a99826fec9bdb255bcb b0e2630ac0d24da4a1438c1e04cdbee1--5bb8f031bc7f4a99826fec9bdb255bcb e52cd6786f4a4b258bcea25d46bf2293 5bb8f031bc7f4a99826fec9bdb255bcb--e52cd6786f4a4b258bcea25d46bf2293 152be3dc30e045309db37279cd0f0685 e52cd6786f4a4b258bcea25d46bf2293--152be3dc30e045309db37279cd0f0685 8abaab9c33aa4b5583943f202f22c38a 152be3dc30e045309db37279cd0f0685--8abaab9c33aa4b5583943f202f22c38a 5c2df3aff7ac4d1da5a3e5bdd69f125c 8abaab9c33aa4b5583943f202f22c38a--5c2df3aff7ac4d1da5a3e5bdd69f125c a157cc704daf4f559ab82eb5e6384478 5c2df3aff7ac4d1da5a3e5bdd69f125c--a157cc704daf4f559ab82eb5e6384478 ab138edd61f54dd8bc1ea9149dac4834 a157cc704daf4f559ab82eb5e6384478--ab138edd61f54dd8bc1ea9149dac4834 088ce234f91b49de8a4e7472d2b4199e X ab138edd61f54dd8bc1ea9149dac4834--088ce234f91b49de8a4e7472d2b4199e 088ce234f91b49de8a4e7472d2b4199e--9a8f0ead85be438eaa18a595b5694827 6070069ceb814a24bd69fd6f8a799dde 088ce234f91b49de8a4e7472d2b4199e--6070069ceb814a24bd69fd6f8a799dde a683edc97db8438b967690696cc87b9c 6070069ceb814a24bd69fd6f8a799dde--a683edc97db8438b967690696cc87b9c 81c5c8f46cb0495d8a2d04c36284b15a X a683edc97db8438b967690696cc87b9c--81c5c8f46cb0495d8a2d04c36284b15a 81c5c8f46cb0495d8a2d04c36284b15a--55750ca9f8e048c5a7ab3e47d84ea02b 59602f6b5ce64ce7ba49351e5fcada7c 81c5c8f46cb0495d8a2d04c36284b15a--59602f6b5ce64ce7ba49351e5fcada7c 3f00fa21f0744e25a45fc88218e6483e 59602f6b5ce64ce7ba49351e5fcada7c--3f00fa21f0744e25a45fc88218e6483e ea9aa4acca534be4a0b75b9edaa70b91 3f00fa21f0744e25a45fc88218e6483e--ea9aa4acca534be4a0b75b9edaa70b91 7112b6975b40424c81a255b424a80eb9 ea9aa4acca534be4a0b75b9edaa70b91--7112b6975b40424c81a255b424a80eb9 0b6c734a6bdd41f6afdb6806c0b80c65 7112b6975b40424c81a255b424a80eb9--0b6c734a6bdd41f6afdb6806c0b80c65 c24363213a504f5f8655ed7cf67b0af6 0b6c734a6bdd41f6afdb6806c0b80c65--c24363213a504f5f8655ed7cf67b0af6 4ac15e255b1642f3b61c56bb961e2c23 c24363213a504f5f8655ed7cf67b0af6--4ac15e255b1642f3b61c56bb961e2c23 ddcc9fe27b394ad58bfbc67ecc51af1f 4ac15e255b1642f3b61c56bb961e2c23--ddcc9fe27b394ad58bfbc67ecc51af1f 12520f251dc949ceb2140772c03232cc ddcc9fe27b394ad58bfbc67ecc51af1f--12520f251dc949ceb2140772c03232cc 26b4f1cdbccc4608856b142992534633 12520f251dc949ceb2140772c03232cc--26b4f1cdbccc4608856b142992534633 83afdde66f2b4a0cb28735578c15c13a 26b4f1cdbccc4608856b142992534633--83afdde66f2b4a0cb28735578c15c13a 7fc19133c5a64d60bf7f9ce6589e313c X 83afdde66f2b4a0cb28735578c15c13a--7fc19133c5a64d60bf7f9ce6589e313c 7fc19133c5a64d60bf7f9ce6589e313c--084052cca1964a118a5ed882fa010076 63a2555998b14e5cb5191071e76280f7 7fc19133c5a64d60bf7f9ce6589e313c--63a2555998b14e5cb5191071e76280f7 eb1412d35909497f9ebf877c0b93d24a X 63a2555998b14e5cb5191071e76280f7--eb1412d35909497f9ebf877c0b93d24a eb1412d35909497f9ebf877c0b93d24a--d37ebbda89dd4c8eadc57632655edb77 ca237cdfb7e94940b3807df8e5d57e48 RZ(-1.0*g0) eb1412d35909497f9ebf877c0b93d24a--ca237cdfb7e94940b3807df8e5d57e48 a3b1802baf104943a7ca1f5a9ad105d3 X ca237cdfb7e94940b3807df8e5d57e48--a3b1802baf104943a7ca1f5a9ad105d3 a3b1802baf104943a7ca1f5a9ad105d3--d605fbd1ba824e9bbb77ef12c8ba7993 441caa03b69f4566bc981fc7d2e43104 X a3b1802baf104943a7ca1f5a9ad105d3--441caa03b69f4566bc981fc7d2e43104 441caa03b69f4566bc981fc7d2e43104--9f0cb6b2f5b740db93410f5b20709860 9e624ba7411448de9dd7e078d0bdf876 441caa03b69f4566bc981fc7d2e43104--9e624ba7411448de9dd7e078d0bdf876 b126a5d6f8aa4008a585ae01aea06dbc 9e624ba7411448de9dd7e078d0bdf876--b126a5d6f8aa4008a585ae01aea06dbc 7e1e2553edb44ca887b737b6ebdaef95 b126a5d6f8aa4008a585ae01aea06dbc--7e1e2553edb44ca887b737b6ebdaef95 235c425550304e64bbca1f5a5a934cc2 X 7e1e2553edb44ca887b737b6ebdaef95--235c425550304e64bbca1f5a5a934cc2 235c425550304e64bbca1f5a5a934cc2--5b3792ecc262429c8e37b8d2e4844a08 0d4050dd12cc43ffb18f30d6262485f0 X 235c425550304e64bbca1f5a5a934cc2--0d4050dd12cc43ffb18f30d6262485f0 0d4050dd12cc43ffb18f30d6262485f0--e455acee63e44db18ce1fb63f5bb763c b0b86308a242474998a3de1362dbbba2 0d4050dd12cc43ffb18f30d6262485f0--b0b86308a242474998a3de1362dbbba2 933f78681ec2490d88d5a8253c8c77a2 b0b86308a242474998a3de1362dbbba2--933f78681ec2490d88d5a8253c8c77a2 71a77853f09d44aabbc75d4454c511c8 933f78681ec2490d88d5a8253c8c77a2--71a77853f09d44aabbc75d4454c511c8 3bcfa1c4b044400d95de6662881d66e1 71a77853f09d44aabbc75d4454c511c8--3bcfa1c4b044400d95de6662881d66e1 8e475cd41e294b74a6fdff2f681ebe50 3bcfa1c4b044400d95de6662881d66e1--8e475cd41e294b74a6fdff2f681ebe50 12bb5b67d97e4884b53ea183cf679f8e X 8e475cd41e294b74a6fdff2f681ebe50--12bb5b67d97e4884b53ea183cf679f8e 12bb5b67d97e4884b53ea183cf679f8e--92c1a66d1cd343e6a4006fb015256422 e8a67ab2a33147749746f2a05b29c421 X 12bb5b67d97e4884b53ea183cf679f8e--e8a67ab2a33147749746f2a05b29c421 e8a67ab2a33147749746f2a05b29c421--b088f7169b9843dd87163a3d37d5b63f ff4443101a11444db49321a461c37974 e8a67ab2a33147749746f2a05b29c421--ff4443101a11444db49321a461c37974 9fda01c9386c4378b3104871faa3b1f2 ff4443101a11444db49321a461c37974--9fda01c9386c4378b3104871faa3b1f2 9cdd773d9105495d809717473abafc36 9fda01c9386c4378b3104871faa3b1f2--9cdd773d9105495d809717473abafc36 631821f28d6e4503a715021fac3048f0 9cdd773d9105495d809717473abafc36--631821f28d6e4503a715021fac3048f0 ead9fb2b43074336abd8ef58850d3056 631821f28d6e4503a715021fac3048f0--ead9fb2b43074336abd8ef58850d3056 d75e491d47f84e7aa89f9c883cd397fc ead9fb2b43074336abd8ef58850d3056--d75e491d47f84e7aa89f9c883cd397fc 314cc255c73446c6b590e23b8304294d d75e491d47f84e7aa89f9c883cd397fc--314cc255c73446c6b590e23b8304294d ad2a05425e29446f9cd9fbbf383c257e X 314cc255c73446c6b590e23b8304294d--ad2a05425e29446f9cd9fbbf383c257e ad2a05425e29446f9cd9fbbf383c257e--e586e9831d244fafb7b04222c3a5ac4d b1919d828e64498eb33b91e577b05825 X ad2a05425e29446f9cd9fbbf383c257e--b1919d828e64498eb33b91e577b05825 b1919d828e64498eb33b91e577b05825--0782722ff5bf4801bd2b6a0ab9d105c8 db54e1ed99f44e2a90a69c0873c988d4 b1919d828e64498eb33b91e577b05825--db54e1ed99f44e2a90a69c0873c988d4 5d82d8a550a54bdfb0a5d27eac3dc13a db54e1ed99f44e2a90a69c0873c988d4--5d82d8a550a54bdfb0a5d27eac3dc13a f6f498a42e2246429072044c7fcafd8a 5d82d8a550a54bdfb0a5d27eac3dc13a--f6f498a42e2246429072044c7fcafd8a 6eecbc849df743e8af3b10ff258c82ef f6f498a42e2246429072044c7fcafd8a--6eecbc849df743e8af3b10ff258c82ef 3afc45ef009d4e68a233f468446c581d 6eecbc849df743e8af3b10ff258c82ef--3afc45ef009d4e68a233f468446c581d 3572486951ee4ff6b8fd04689dd4db2e 3afc45ef009d4e68a233f468446c581d--3572486951ee4ff6b8fd04689dd4db2e 9ab20e3f009a4ef796fdb07cfbe21a8d 3572486951ee4ff6b8fd04689dd4db2e--9ab20e3f009a4ef796fdb07cfbe21a8d 9a021e36efb440659e30a868271ca858 9ab20e3f009a4ef796fdb07cfbe21a8d--9a021e36efb440659e30a868271ca858 ede041d1f8a74c94bbfe0d77ed676045 9a021e36efb440659e30a868271ca858--ede041d1f8a74c94bbfe0d77ed676045 6e42dd61d96a405c85f20aa4ee129d36 X ede041d1f8a74c94bbfe0d77ed676045--6e42dd61d96a405c85f20aa4ee129d36 6e42dd61d96a405c85f20aa4ee129d36--b54a1d6427884466882fda50a2213651 22005c08a2a2456593ae40dac44a53b6 X 6e42dd61d96a405c85f20aa4ee129d36--22005c08a2a2456593ae40dac44a53b6 22005c08a2a2456593ae40dac44a53b6--21edde29dceb417f89f14d44b9bc8249 904a668b40144abab4d9e236106f9336 22005c08a2a2456593ae40dac44a53b6--904a668b40144abab4d9e236106f9336 52c8f08e83484e7c9667a1d630004f1a 904a668b40144abab4d9e236106f9336--52c8f08e83484e7c9667a1d630004f1a 623253adcc1c45b9bdeb7fd3b7bdbc6e 52c8f08e83484e7c9667a1d630004f1a--623253adcc1c45b9bdeb7fd3b7bdbc6e ed568943509c4d8fbcf372155f7e4f86 623253adcc1c45b9bdeb7fd3b7bdbc6e--ed568943509c4d8fbcf372155f7e4f86 4edf6aa21588425bbf5a12a2f5acaf57 ed568943509c4d8fbcf372155f7e4f86--4edf6aa21588425bbf5a12a2f5acaf57 a7cab9b9a78c4df08972ac2213717037 4edf6aa21588425bbf5a12a2f5acaf57--a7cab9b9a78c4df08972ac2213717037 3f56b27f99b448c6a11282ddb4284463 a7cab9b9a78c4df08972ac2213717037--3f56b27f99b448c6a11282ddb4284463 43784a32fe074ec98cf92280d26b8630 3f56b27f99b448c6a11282ddb4284463--43784a32fe074ec98cf92280d26b8630 b343b2c55b484831ad94622c679dc61d 43784a32fe074ec98cf92280d26b8630--b343b2c55b484831ad94622c679dc61d f8c736525112494da8edf2684f16c18e b343b2c55b484831ad94622c679dc61d--f8c736525112494da8edf2684f16c18e 6949e0f3a7254e3bb5f3179e534ef1a9 f8c736525112494da8edf2684f16c18e--6949e0f3a7254e3bb5f3179e534ef1a9 2a19e3c4baf5425ca2b81b4088415e16 X 6949e0f3a7254e3bb5f3179e534ef1a9--2a19e3c4baf5425ca2b81b4088415e16 2a19e3c4baf5425ca2b81b4088415e16--5df41b0260af4dc28f46226eb60ddcf9 f3950f24e7c74416b4193811737b887b 2a19e3c4baf5425ca2b81b4088415e16--f3950f24e7c74416b4193811737b887b 0ae509d76da84baabc3346ce737aed50 f3950f24e7c74416b4193811737b887b--0ae509d76da84baabc3346ce737aed50 0bf35a9eb13b43029bdf6022e4aaa5e6 0ae509d76da84baabc3346ce737aed50--0bf35a9eb13b43029bdf6022e4aaa5e6 5f35199a655145249d213b2d5b6290ea 0bf35a9eb13b43029bdf6022e4aaa5e6--5f35199a655145249d213b2d5b6290ea d908b1bc852a4542a9eb041d428bc009 5f35199a655145249d213b2d5b6290ea--d908b1bc852a4542a9eb041d428bc009 bb69aa8cbc1148af972b2c79b387230d d908b1bc852a4542a9eb041d428bc009--bb69aa8cbc1148af972b2c79b387230d 2ba10f47089d4003bb3393c7966b76f1 bb69aa8cbc1148af972b2c79b387230d--2ba10f47089d4003bb3393c7966b76f1 621cb2665e6d4b1bb1ecab0ed75b595e 2ba10f47089d4003bb3393c7966b76f1--621cb2665e6d4b1bb1ecab0ed75b595e 4a12992b7dd747bd90157a08a21fe3de 621cb2665e6d4b1bb1ecab0ed75b595e--4a12992b7dd747bd90157a08a21fe3de 6952c599f4bf46de859b42356e0e141f 4a12992b7dd747bd90157a08a21fe3de--6952c599f4bf46de859b42356e0e141f 49a506dabbf44b8db7e9e24f6c28dc9a 6952c599f4bf46de859b42356e0e141f--49a506dabbf44b8db7e9e24f6c28dc9a 6a2b12616ff4402f8bffc1395384c9a0 49a506dabbf44b8db7e9e24f6c28dc9a--6a2b12616ff4402f8bffc1395384c9a0 07fc3c2d77b3488abcbd8dfd7c36b3f1 6a2b12616ff4402f8bffc1395384c9a0--07fc3c2d77b3488abcbd8dfd7c36b3f1 967d359f319e41d690c0a43b7b4357c0 07fc3c2d77b3488abcbd8dfd7c36b3f1--967d359f319e41d690c0a43b7b4357c0 9e766814e8b44a34b801397284db9501 967d359f319e41d690c0a43b7b4357c0--9e766814e8b44a34b801397284db9501 bcfea49f437042d294c7e07c03578eb8 9e766814e8b44a34b801397284db9501--bcfea49f437042d294c7e07c03578eb8 eecef38182294c71aa2ebf398b92a763 bcfea49f437042d294c7e07c03578eb8--eecef38182294c71aa2ebf398b92a763 5b9e3a2325f94e78ab289c0a0e7dc275 eecef38182294c71aa2ebf398b92a763--5b9e3a2325f94e78ab289c0a0e7dc275 8617cba67cba40068192c8a226312a05 5b9e3a2325f94e78ab289c0a0e7dc275--8617cba67cba40068192c8a226312a05 ca911360ca3e4dfab6ca9c255be9e7e1 8617cba67cba40068192c8a226312a05--ca911360ca3e4dfab6ca9c255be9e7e1 4f48f90305324b578731a4ee24aee1c4 ca911360ca3e4dfab6ca9c255be9e7e1--4f48f90305324b578731a4ee24aee1c4 01b7f19e848f4440b1db80067cc87f84 4f48f90305324b578731a4ee24aee1c4--01b7f19e848f4440b1db80067cc87f84 a130b36bbf6c415882395ecd0c099d16 01b7f19e848f4440b1db80067cc87f84--a130b36bbf6c415882395ecd0c099d16 0dadeeab40f843d5b46bb11b3b692dc7 a130b36bbf6c415882395ecd0c099d16--0dadeeab40f843d5b46bb11b3b692dc7 a3be6c9de1664e83b77edeb8f4ac190e 0dadeeab40f843d5b46bb11b3b692dc7--a3be6c9de1664e83b77edeb8f4ac190e 7fb018f48df844ed958f7a75ad14192e a3be6c9de1664e83b77edeb8f4ac190e--7fb018f48df844ed958f7a75ad14192e 7d655802a898489989e6cb907c841838 7fb018f48df844ed958f7a75ad14192e--7d655802a898489989e6cb907c841838 878fde8af916466586f605cb81e5c3f2 7d655802a898489989e6cb907c841838--878fde8af916466586f605cb81e5c3f2 992aa07074164049953c97bb37881ea0 878fde8af916466586f605cb81e5c3f2--992aa07074164049953c97bb37881ea0 5ccc4c78b3464d59b7c16362bad3c21b 992aa07074164049953c97bb37881ea0--5ccc4c78b3464d59b7c16362bad3c21b ba9aa9d74ec144bb8e8c9292c9f988ee 5ccc4c78b3464d59b7c16362bad3c21b--ba9aa9d74ec144bb8e8c9292c9f988ee 4f492b2fe0b742be977dac46653b5feb ba9aa9d74ec144bb8e8c9292c9f988ee--4f492b2fe0b742be977dac46653b5feb 382c7f7cb5e54ca6a80f5d216eee2a84 4f492b2fe0b742be977dac46653b5feb--382c7f7cb5e54ca6a80f5d216eee2a84 8bf4698690df4fa0946d3126b9872412 382c7f7cb5e54ca6a80f5d216eee2a84--8bf4698690df4fa0946d3126b9872412 374fe31787574caea27356ffb87e53b6 8bf4698690df4fa0946d3126b9872412--374fe31787574caea27356ffb87e53b6 631a17ff7c6648e2a4274bbefd6ca03c 374fe31787574caea27356ffb87e53b6--631a17ff7c6648e2a4274bbefd6ca03c 5b9bb39aee2d4d9ba8cd128d3a86cf99 631a17ff7c6648e2a4274bbefd6ca03c--5b9bb39aee2d4d9ba8cd128d3a86cf99 e9ffc2053f424d449757d76da85d25be 5b9bb39aee2d4d9ba8cd128d3a86cf99--e9ffc2053f424d449757d76da85d25be 05cafd7316d04fabb805b4c15028daeb e9ffc2053f424d449757d76da85d25be--05cafd7316d04fabb805b4c15028daeb 7e3154b4b05140ebb420a2935cf077f0 05cafd7316d04fabb805b4c15028daeb--7e3154b4b05140ebb420a2935cf077f0 38af41eb373b42249c445d803c4ca046 7e3154b4b05140ebb420a2935cf077f0--38af41eb373b42249c445d803c4ca046 2c2d862113004b5eb3311a32fd22441b 38af41eb373b42249c445d803c4ca046--2c2d862113004b5eb3311a32fd22441b 2d059cc7fb34499bacb739d3d5ed09f0 2c2d862113004b5eb3311a32fd22441b--2d059cc7fb34499bacb739d3d5ed09f0 839f078ae45a42f298b214756df96e10 2d059cc7fb34499bacb739d3d5ed09f0--839f078ae45a42f298b214756df96e10 4d88f25da04f4ff395e9bfefd2cccc1f 839f078ae45a42f298b214756df96e10--4d88f25da04f4ff395e9bfefd2cccc1f 46dc906252254950acb98a9fab40c5d4 RX(b02) 4d88f25da04f4ff395e9bfefd2cccc1f--46dc906252254950acb98a9fab40c5d4 ee64aa3c178b474d930646d8adab5107 46dc906252254950acb98a9fab40c5d4--ee64aa3c178b474d930646d8adab5107 8c09ae0cdbcb4b6bb73f67829201f0a3 X ee64aa3c178b474d930646d8adab5107--8c09ae0cdbcb4b6bb73f67829201f0a3 8c09ae0cdbcb4b6bb73f67829201f0a3--66170b005f7c4852a7f19e5ba494263d 549434e60dfd479696d771407b3412ca 8c09ae0cdbcb4b6bb73f67829201f0a3--549434e60dfd479696d771407b3412ca fe31ecda0d4b49d2a9b1850cbfbe9618 549434e60dfd479696d771407b3412ca--fe31ecda0d4b49d2a9b1850cbfbe9618 63b77658bcaa4d1199f610758962d52b fe31ecda0d4b49d2a9b1850cbfbe9618--63b77658bcaa4d1199f610758962d52b 73b8bfd767fd481390b7d64b3bb79518 63b77658bcaa4d1199f610758962d52b--73b8bfd767fd481390b7d64b3bb79518 1e86ed21aa0a439698b983a6c874a6dc 73b8bfd767fd481390b7d64b3bb79518--1e86ed21aa0a439698b983a6c874a6dc 603c7c3784ee46f2ad2c925bfde9ae4f 1e86ed21aa0a439698b983a6c874a6dc--603c7c3784ee46f2ad2c925bfde9ae4f 9771b217521a449aac2cf68ab4ab11ef 603c7c3784ee46f2ad2c925bfde9ae4f--9771b217521a449aac2cf68ab4ab11ef 97b49c529fe443689e34035e5553eafa 9771b217521a449aac2cf68ab4ab11ef--97b49c529fe443689e34035e5553eafa 77b9b2290acf4ec0a8346dc6adbdf97e 97b49c529fe443689e34035e5553eafa--77b9b2290acf4ec0a8346dc6adbdf97e 9c8f781c388849ab95f6d29f8b2e6671 77b9b2290acf4ec0a8346dc6adbdf97e--9c8f781c388849ab95f6d29f8b2e6671 d451f5e5ef3c4fe7a6cc88a382a30477 9c8f781c388849ab95f6d29f8b2e6671--d451f5e5ef3c4fe7a6cc88a382a30477 38fe946bcf9d4514bec6d86cf521db0c X d451f5e5ef3c4fe7a6cc88a382a30477--38fe946bcf9d4514bec6d86cf521db0c 38fe946bcf9d4514bec6d86cf521db0c--89a9e993fe574f0392e23696833b95e5 079ac4c510ff413890212f2f68e773c5 38fe946bcf9d4514bec6d86cf521db0c--079ac4c510ff413890212f2f68e773c5 2c4fda17e1b54eed99f639e4f39e44bd 079ac4c510ff413890212f2f68e773c5--2c4fda17e1b54eed99f639e4f39e44bd a13f4c8aa3bd40e6a2827f9657d23e63 2c4fda17e1b54eed99f639e4f39e44bd--a13f4c8aa3bd40e6a2827f9657d23e63 e6878dda955f4cde8b1a0bf2f9d96107 a13f4c8aa3bd40e6a2827f9657d23e63--e6878dda955f4cde8b1a0bf2f9d96107 585277c11cf240c795f369e7dea70419 e6878dda955f4cde8b1a0bf2f9d96107--585277c11cf240c795f369e7dea70419 64d437b44940407fb4b6c4be10afd7f6 X 585277c11cf240c795f369e7dea70419--64d437b44940407fb4b6c4be10afd7f6 64d437b44940407fb4b6c4be10afd7f6--14c4399824874bc59844c370bd8fb455 c2967a8817a24ac68ee7b5e47284a749 RZ(-1.0*g1) 64d437b44940407fb4b6c4be10afd7f6--c2967a8817a24ac68ee7b5e47284a749 a1fd7ec2643b47f8909491f0ce0c0086 X c2967a8817a24ac68ee7b5e47284a749--a1fd7ec2643b47f8909491f0ce0c0086 a1fd7ec2643b47f8909491f0ce0c0086--912a8b7742c64044ac91b8e09a800dce 93056127baf54bc08024c22af6e67e9e a1fd7ec2643b47f8909491f0ce0c0086--93056127baf54bc08024c22af6e67e9e 039ad79014264eae84212588f8f2112e 93056127baf54bc08024c22af6e67e9e--039ad79014264eae84212588f8f2112e 6437470cdd5b4825aeca5a76b6f61909 X 039ad79014264eae84212588f8f2112e--6437470cdd5b4825aeca5a76b6f61909 6437470cdd5b4825aeca5a76b6f61909--a5ad83976e9c4129bfc535421e1d75e3 fd9d558f1ff04829868caf09c05e9e13 6437470cdd5b4825aeca5a76b6f61909--fd9d558f1ff04829868caf09c05e9e13 a58f7e4cbc444023bf6f12b3691f3876 fd9d558f1ff04829868caf09c05e9e13--a58f7e4cbc444023bf6f12b3691f3876 cf04e5de03094014bfd84f1925631ab4 a58f7e4cbc444023bf6f12b3691f3876--cf04e5de03094014bfd84f1925631ab4 90c9bdb57a314bb3b2a84af0e3464942 cf04e5de03094014bfd84f1925631ab4--90c9bdb57a314bb3b2a84af0e3464942 6b38244d867c4651b472961fa27976fd 90c9bdb57a314bb3b2a84af0e3464942--6b38244d867c4651b472961fa27976fd 6765ae560da14ad68d9a051625c04608 X 6b38244d867c4651b472961fa27976fd--6765ae560da14ad68d9a051625c04608 6765ae560da14ad68d9a051625c04608--25346345a85c47ebb125ababa509681e 2de0cd72bd62475f83dde7ec1b3ce8de 6765ae560da14ad68d9a051625c04608--2de0cd72bd62475f83dde7ec1b3ce8de 1da591f68ded430f91843d0744b062a5 2de0cd72bd62475f83dde7ec1b3ce8de--1da591f68ded430f91843d0744b062a5 ad5353846dec4ab292c7880842c49017 X 1da591f68ded430f91843d0744b062a5--ad5353846dec4ab292c7880842c49017 ad5353846dec4ab292c7880842c49017--284fc584442643b282fc8a16d0b27b61 e257aaf8ee7145af9277bfff443a6950 ad5353846dec4ab292c7880842c49017--e257aaf8ee7145af9277bfff443a6950 ceb7efdab002440fbf0425e2232476ef e257aaf8ee7145af9277bfff443a6950--ceb7efdab002440fbf0425e2232476ef d4b615fcf8e54dc59f46452c74b8af24 ceb7efdab002440fbf0425e2232476ef--d4b615fcf8e54dc59f46452c74b8af24 fd1056f41fed4b1bbb54ec949972a823 d4b615fcf8e54dc59f46452c74b8af24--fd1056f41fed4b1bbb54ec949972a823 6988e65063cd4373adf3c8f867793483 fd1056f41fed4b1bbb54ec949972a823--6988e65063cd4373adf3c8f867793483 2484de513a134c62bb3e26dfc2c1afa3 6988e65063cd4373adf3c8f867793483--2484de513a134c62bb3e26dfc2c1afa3 9344a6fe6cf140509eb8bfb397485c4b 2484de513a134c62bb3e26dfc2c1afa3--9344a6fe6cf140509eb8bfb397485c4b 1476f136d71149d68df0690acf1b1611 X 9344a6fe6cf140509eb8bfb397485c4b--1476f136d71149d68df0690acf1b1611 1476f136d71149d68df0690acf1b1611--efb247bca60547009b27ad89ede81d41 8591d1e77f264727aa61d52459a696c2 1476f136d71149d68df0690acf1b1611--8591d1e77f264727aa61d52459a696c2 443d14116d3944a89d31d4d6b8c04568 8591d1e77f264727aa61d52459a696c2--443d14116d3944a89d31d4d6b8c04568 8b1956472ee942cba9828e32f668adf0 X 443d14116d3944a89d31d4d6b8c04568--8b1956472ee942cba9828e32f668adf0 8b1956472ee942cba9828e32f668adf0--8560e165ef484aad8ccd08c1a8f64f5b 43f9147245d2454eb0629f5c2e6b4ba6 8b1956472ee942cba9828e32f668adf0--43f9147245d2454eb0629f5c2e6b4ba6 3e7a1e3a9c3f499d996ea1a901718745 43f9147245d2454eb0629f5c2e6b4ba6--3e7a1e3a9c3f499d996ea1a901718745 a3d4afaff0194ffe9cc8565cbb6c2a36 3e7a1e3a9c3f499d996ea1a901718745--a3d4afaff0194ffe9cc8565cbb6c2a36 dbcde5296cb844a28c0b357c1d095aa3 a3d4afaff0194ffe9cc8565cbb6c2a36--dbcde5296cb844a28c0b357c1d095aa3 2aaed5434db94a5ba27975903e466511 dbcde5296cb844a28c0b357c1d095aa3--2aaed5434db94a5ba27975903e466511 73ace7096c174138b8cac23dadd9d290 2aaed5434db94a5ba27975903e466511--73ace7096c174138b8cac23dadd9d290 cb62b678408a41e687fe25e153b6a3aa 73ace7096c174138b8cac23dadd9d290--cb62b678408a41e687fe25e153b6a3aa e43e40d93bbb46f9b6bd3e2f26148798 cb62b678408a41e687fe25e153b6a3aa--e43e40d93bbb46f9b6bd3e2f26148798 3775469df9dc40e4af0ac3ad90077e94 e43e40d93bbb46f9b6bd3e2f26148798--3775469df9dc40e4af0ac3ad90077e94 215ecf05c2b140868453864742e59427 3775469df9dc40e4af0ac3ad90077e94--215ecf05c2b140868453864742e59427 d8ef7eb2a5e54161a8b97a0709a7b29f 215ecf05c2b140868453864742e59427--d8ef7eb2a5e54161a8b97a0709a7b29f 9f86f4c6a7b741d3880c5aa5f16a2622 X d8ef7eb2a5e54161a8b97a0709a7b29f--9f86f4c6a7b741d3880c5aa5f16a2622 9f86f4c6a7b741d3880c5aa5f16a2622--5c115affd4d04c1eae095644733b550a d9373f3d0106473e892df28daeb90ec0 9f86f4c6a7b741d3880c5aa5f16a2622--d9373f3d0106473e892df28daeb90ec0 ab5a001d3bb646e6823b80c23c7f58d3 X d9373f3d0106473e892df28daeb90ec0--ab5a001d3bb646e6823b80c23c7f58d3 ab5a001d3bb646e6823b80c23c7f58d3--4e0c135804d340acbacbf1de6cf398ca a2048dce09b54a51ba6b0a65ebafad01 RZ(-1.0*g1) ab5a001d3bb646e6823b80c23c7f58d3--a2048dce09b54a51ba6b0a65ebafad01 ad9deb99f1344a2895ea001b1e01838d X a2048dce09b54a51ba6b0a65ebafad01--ad9deb99f1344a2895ea001b1e01838d ad9deb99f1344a2895ea001b1e01838d--c21497abc9d642509953d23b57b0c56e 944c4de82c9f42e0b75879931c977e7e X ad9deb99f1344a2895ea001b1e01838d--944c4de82c9f42e0b75879931c977e7e 944c4de82c9f42e0b75879931c977e7e--279756e8c4454b889a621cf6563fdbee a6d78e2fa6704c81aec27afae2dfd974 944c4de82c9f42e0b75879931c977e7e--a6d78e2fa6704c81aec27afae2dfd974 e5d7af2fd51d49f2ba530177c0ae0afb a6d78e2fa6704c81aec27afae2dfd974--e5d7af2fd51d49f2ba530177c0ae0afb 03bf88e7b6d44d72a90b9c44017f586f e5d7af2fd51d49f2ba530177c0ae0afb--03bf88e7b6d44d72a90b9c44017f586f 9530bf123e194856b4a3aaba26e1c6ce X 03bf88e7b6d44d72a90b9c44017f586f--9530bf123e194856b4a3aaba26e1c6ce 9530bf123e194856b4a3aaba26e1c6ce--931e8b51e07b4ab1b902fee4d16401ed 0ef59507db0f48f0abdb7d4483b68b7a X 9530bf123e194856b4a3aaba26e1c6ce--0ef59507db0f48f0abdb7d4483b68b7a 0ef59507db0f48f0abdb7d4483b68b7a--f05581881b9b4aa99d9946dc4727efae d1c4d0c97e544dbdbb26bf0776fc55d7 0ef59507db0f48f0abdb7d4483b68b7a--d1c4d0c97e544dbdbb26bf0776fc55d7 25d5410cae4844d6b9ac2a955bbe164f d1c4d0c97e544dbdbb26bf0776fc55d7--25d5410cae4844d6b9ac2a955bbe164f 9f41b10cfce144bfa8ad31a09fd16822 25d5410cae4844d6b9ac2a955bbe164f--9f41b10cfce144bfa8ad31a09fd16822 ebf7549b37b04950a6e8f15c6e43894d 9f41b10cfce144bfa8ad31a09fd16822--ebf7549b37b04950a6e8f15c6e43894d 27bb81b25a294b63b0d7aa27aa8433b7 ebf7549b37b04950a6e8f15c6e43894d--27bb81b25a294b63b0d7aa27aa8433b7 41622ad1452d48d48f70ee8dd0efb96b X 27bb81b25a294b63b0d7aa27aa8433b7--41622ad1452d48d48f70ee8dd0efb96b 41622ad1452d48d48f70ee8dd0efb96b--1477e05ec11e40549d78998233b56867 1ab0b62076604b2aabea7271329de213 X 41622ad1452d48d48f70ee8dd0efb96b--1ab0b62076604b2aabea7271329de213 1ab0b62076604b2aabea7271329de213--6ccc3ca5d8ba4c97b219179cc3d9e295 d43216cbc3a94c2eb4aa4e4a6e54cb23 1ab0b62076604b2aabea7271329de213--d43216cbc3a94c2eb4aa4e4a6e54cb23 ba81465f3a774784a74fd03ae502e6ee d43216cbc3a94c2eb4aa4e4a6e54cb23--ba81465f3a774784a74fd03ae502e6ee 6ce17d2548704af1bb9b8765dc68c784 ba81465f3a774784a74fd03ae502e6ee--6ce17d2548704af1bb9b8765dc68c784 06598c9a1e094fbbafdd46d1f79c1dc7 6ce17d2548704af1bb9b8765dc68c784--06598c9a1e094fbbafdd46d1f79c1dc7 f001b7dfe5fe441693d41dffa4993aee 06598c9a1e094fbbafdd46d1f79c1dc7--f001b7dfe5fe441693d41dffa4993aee 07522b04d8804901a8ecfff10f222df9 f001b7dfe5fe441693d41dffa4993aee--07522b04d8804901a8ecfff10f222df9 513bbb0b692a4bed80737ab4ecebd0c2 07522b04d8804901a8ecfff10f222df9--513bbb0b692a4bed80737ab4ecebd0c2 dd3f214ba9af40678dc90049cf5a763f X 513bbb0b692a4bed80737ab4ecebd0c2--dd3f214ba9af40678dc90049cf5a763f dd3f214ba9af40678dc90049cf5a763f--3c8b62c664f44f00b108586a84fc5f39 00952471eb124a3eba22057e1f7f7ff6 X dd3f214ba9af40678dc90049cf5a763f--00952471eb124a3eba22057e1f7f7ff6 00952471eb124a3eba22057e1f7f7ff6--973bc934142946be816c73c2d047edae 456f8a3710ec4193a6b2f19d81e28b60 00952471eb124a3eba22057e1f7f7ff6--456f8a3710ec4193a6b2f19d81e28b60 6e0c8259b1024ffb8ca5cf17931d1907 456f8a3710ec4193a6b2f19d81e28b60--6e0c8259b1024ffb8ca5cf17931d1907 719cdb3b3804483abd25bdd81a2d9878 6e0c8259b1024ffb8ca5cf17931d1907--719cdb3b3804483abd25bdd81a2d9878 03c742ac0b584312b67d1def123f804e 719cdb3b3804483abd25bdd81a2d9878--03c742ac0b584312b67d1def123f804e dc08892aebdc46e99ba446e4c7b0e836 03c742ac0b584312b67d1def123f804e--dc08892aebdc46e99ba446e4c7b0e836 3163160cb2d84fb58442fa65e955555f dc08892aebdc46e99ba446e4c7b0e836--3163160cb2d84fb58442fa65e955555f 65acccc59d934bfe993ffcb5bf992ed8 3163160cb2d84fb58442fa65e955555f--65acccc59d934bfe993ffcb5bf992ed8 926f51ae37b64baf8d1b2877b4159c25 65acccc59d934bfe993ffcb5bf992ed8--926f51ae37b64baf8d1b2877b4159c25 b0943ba1a1904e46b87f10d6e416eb83 926f51ae37b64baf8d1b2877b4159c25--b0943ba1a1904e46b87f10d6e416eb83 9890b43794824304ae50ab08e19792d1 X b0943ba1a1904e46b87f10d6e416eb83--9890b43794824304ae50ab08e19792d1 9890b43794824304ae50ab08e19792d1--359577ff2cbc404d96505dd53fc74368 870c59d3fe714bfc8e105b4d1a0a01c5 X 9890b43794824304ae50ab08e19792d1--870c59d3fe714bfc8e105b4d1a0a01c5 870c59d3fe714bfc8e105b4d1a0a01c5--3691122db9ab4af295003724340ca0ed 6a49fe969a644931865bddd4d945272d 870c59d3fe714bfc8e105b4d1a0a01c5--6a49fe969a644931865bddd4d945272d aa30aebac5804f0fb294a10afc4fb366 6a49fe969a644931865bddd4d945272d--aa30aebac5804f0fb294a10afc4fb366 3d6ea37f76f44221a1609c1ab0106e22 aa30aebac5804f0fb294a10afc4fb366--3d6ea37f76f44221a1609c1ab0106e22 29493380b4a14ad5861357c5fdf97652 3d6ea37f76f44221a1609c1ab0106e22--29493380b4a14ad5861357c5fdf97652 dbc3807ff4964ee194feaaef709a5e39 29493380b4a14ad5861357c5fdf97652--dbc3807ff4964ee194feaaef709a5e39 45d4f6101cf343d787f0e610bccd8996 dbc3807ff4964ee194feaaef709a5e39--45d4f6101cf343d787f0e610bccd8996 7edd487460b04affba7f9a759f054f86 45d4f6101cf343d787f0e610bccd8996--7edd487460b04affba7f9a759f054f86 c775f73cd31c4a56afc46e66ab6a8986 7edd487460b04affba7f9a759f054f86--c775f73cd31c4a56afc46e66ab6a8986 ff29c2b519d84952b30065483340dfb0 c775f73cd31c4a56afc46e66ab6a8986--ff29c2b519d84952b30065483340dfb0 53538adbdfcf41dfa30c0c1ec98bc55b ff29c2b519d84952b30065483340dfb0--53538adbdfcf41dfa30c0c1ec98bc55b 881a82b3dd8b44db90cdb3177d7b1bd8 53538adbdfcf41dfa30c0c1ec98bc55b--881a82b3dd8b44db90cdb3177d7b1bd8 98f86a213e5848eb82b8a849985e4b27 X 881a82b3dd8b44db90cdb3177d7b1bd8--98f86a213e5848eb82b8a849985e4b27 98f86a213e5848eb82b8a849985e4b27--3857456689e644aba777ee3d52605894 3588cc6f7fab4f2cacd3540da5ff821e 98f86a213e5848eb82b8a849985e4b27--3588cc6f7fab4f2cacd3540da5ff821e ef1863d311e5465c8164ee1b33c5dce0 3588cc6f7fab4f2cacd3540da5ff821e--ef1863d311e5465c8164ee1b33c5dce0 5ad07e1569e440e5a8324c4255134fe2 ef1863d311e5465c8164ee1b33c5dce0--5ad07e1569e440e5a8324c4255134fe2 e30f9022c2424725a893964744fa3aa0 5ad07e1569e440e5a8324c4255134fe2--e30f9022c2424725a893964744fa3aa0 bf83ee4866564f098944c811c917e56a e30f9022c2424725a893964744fa3aa0--bf83ee4866564f098944c811c917e56a 004b804d61f24e1dbf211d700c720f19 bf83ee4866564f098944c811c917e56a--004b804d61f24e1dbf211d700c720f19 2d5ae05fe83d4953b2a438c6ed049c47 004b804d61f24e1dbf211d700c720f19--2d5ae05fe83d4953b2a438c6ed049c47 c2154d6566ef44dda1cb849686a8f4e6 2d5ae05fe83d4953b2a438c6ed049c47--c2154d6566ef44dda1cb849686a8f4e6 b9dfb3d44de645e39a1408af01ea603f c2154d6566ef44dda1cb849686a8f4e6--b9dfb3d44de645e39a1408af01ea603f 955d1228eb224bbd8cb562be10792f9a b9dfb3d44de645e39a1408af01ea603f--955d1228eb224bbd8cb562be10792f9a bd4a9d46c7894fa893b0ce7f7510d236 955d1228eb224bbd8cb562be10792f9a--bd4a9d46c7894fa893b0ce7f7510d236 46a8168878544824a0198247eaa9bfde bd4a9d46c7894fa893b0ce7f7510d236--46a8168878544824a0198247eaa9bfde f5497fde9c264536bfc5c09670cc07ee 46a8168878544824a0198247eaa9bfde--f5497fde9c264536bfc5c09670cc07ee cbad29410d8943518cee295a05131d23 f5497fde9c264536bfc5c09670cc07ee--cbad29410d8943518cee295a05131d23 809c5d8c3d7649ff87531676cd30f091 cbad29410d8943518cee295a05131d23--809c5d8c3d7649ff87531676cd30f091 95a8d8b6cecb4b41abc48df982d0443a 809c5d8c3d7649ff87531676cd30f091--95a8d8b6cecb4b41abc48df982d0443a b3b1418f3e41495287ca57a89074ce34 95a8d8b6cecb4b41abc48df982d0443a--b3b1418f3e41495287ca57a89074ce34 787e12e743404c0a92dc84dc420de69c b3b1418f3e41495287ca57a89074ce34--787e12e743404c0a92dc84dc420de69c fc0c685bec6f4942b8fcd4b11cdb57cf 787e12e743404c0a92dc84dc420de69c--fc0c685bec6f4942b8fcd4b11cdb57cf cd81404a379245909b967fcbe5e7b410 fc0c685bec6f4942b8fcd4b11cdb57cf--cd81404a379245909b967fcbe5e7b410 258df0f0bcc347708be7c8b4117f2265 cd81404a379245909b967fcbe5e7b410--258df0f0bcc347708be7c8b4117f2265 8478327e214448ea960a03348efc9fff 258df0f0bcc347708be7c8b4117f2265--8478327e214448ea960a03348efc9fff 4d491f3465fc428e9e717696dba9d7fd 8478327e214448ea960a03348efc9fff--4d491f3465fc428e9e717696dba9d7fd b786b58e5bba4dbcb1fb33e8ed2e3502 4d491f3465fc428e9e717696dba9d7fd--b786b58e5bba4dbcb1fb33e8ed2e3502 72254abc2bdc43bc96c30b5dc69480d3 b786b58e5bba4dbcb1fb33e8ed2e3502--72254abc2bdc43bc96c30b5dc69480d3 49c5020998c6443697f173ac71e5d335 72254abc2bdc43bc96c30b5dc69480d3--49c5020998c6443697f173ac71e5d335 6ca3e9348f3447658b62931753b8768f 49c5020998c6443697f173ac71e5d335--6ca3e9348f3447658b62931753b8768f 3af68d9690a1487c8aad7a4faf0dd61c 6ca3e9348f3447658b62931753b8768f--3af68d9690a1487c8aad7a4faf0dd61c 966b7512ea2a48f4b95c3911bf56c44b 3af68d9690a1487c8aad7a4faf0dd61c--966b7512ea2a48f4b95c3911bf56c44b 92b4b8b3d67d4fef8ae8d5797623eff4 966b7512ea2a48f4b95c3911bf56c44b--92b4b8b3d67d4fef8ae8d5797623eff4 f5ecd0807fcf4988b99fe8ef331fd3b0 92b4b8b3d67d4fef8ae8d5797623eff4--f5ecd0807fcf4988b99fe8ef331fd3b0 72b9ff3565b04763b79995422b1e3d26 f5ecd0807fcf4988b99fe8ef331fd3b0--72b9ff3565b04763b79995422b1e3d26 858f17b623d5453493ddfdef9872a3c0 72b9ff3565b04763b79995422b1e3d26--858f17b623d5453493ddfdef9872a3c0 26e0620a16dc4c4e8849dd238598a304 858f17b623d5453493ddfdef9872a3c0--26e0620a16dc4c4e8849dd238598a304 6f8172b66f08410e89960d8091343e6c 26e0620a16dc4c4e8849dd238598a304--6f8172b66f08410e89960d8091343e6c ceb574ce60bc47bc8abcad5a899df60a 6f8172b66f08410e89960d8091343e6c--ceb574ce60bc47bc8abcad5a899df60a 8dfdc290f85b40fd8ffd17b97fb1c499 ceb574ce60bc47bc8abcad5a899df60a--8dfdc290f85b40fd8ffd17b97fb1c499 b18042166c744495958453c6cc6b377f 8dfdc290f85b40fd8ffd17b97fb1c499--b18042166c744495958453c6cc6b377f 174e6eeac76646f6a84c5d6c7ab4117d b18042166c744495958453c6cc6b377f--174e6eeac76646f6a84c5d6c7ab4117d e38d72325bfc4c63bf5fb878b28596cf 174e6eeac76646f6a84c5d6c7ab4117d--e38d72325bfc4c63bf5fb878b28596cf 4d8bbc782e4f4c19859968c7538130af e38d72325bfc4c63bf5fb878b28596cf--4d8bbc782e4f4c19859968c7538130af b464163349ae4f449bd240296581a9b1 4d8bbc782e4f4c19859968c7538130af--b464163349ae4f449bd240296581a9b1 65a21045eb7a430ebcde5dbe1fd38436 b464163349ae4f449bd240296581a9b1--65a21045eb7a430ebcde5dbe1fd38436 8cfc093c27a74419942dc1d8ec74b967 65a21045eb7a430ebcde5dbe1fd38436--8cfc093c27a74419942dc1d8ec74b967 4a0c45a2b3e7446aad7a9b28a8733185 8cfc093c27a74419942dc1d8ec74b967--4a0c45a2b3e7446aad7a9b28a8733185 b58a3ff18c7c41feb6164883c8210174 RX(b12) 4a0c45a2b3e7446aad7a9b28a8733185--b58a3ff18c7c41feb6164883c8210174 b58a3ff18c7c41feb6164883c8210174--afd8edd532c845fca5ead6cba0e14f7a 3609cc39156945bfa175c9d4cb11ad29 d2ef9c6eead849ffa1574125e6d68a69 3a51073a4d52419bae027bea46df9dfd--d2ef9c6eead849ffa1574125e6d68a69 ae91aab8b32443fa89c6f38e87915f27 4 579c94b059e64734ac2b3d692ad7ad25 d2ef9c6eead849ffa1574125e6d68a69--579c94b059e64734ac2b3d692ad7ad25 a744fc9681df4e649bba5d5a9a23f0fa X 579c94b059e64734ac2b3d692ad7ad25--a744fc9681df4e649bba5d5a9a23f0fa a744fc9681df4e649bba5d5a9a23f0fa--c8198e1b3574455b94c367518a91ddef deffb83f40224cc4800af39a2e07447b a744fc9681df4e649bba5d5a9a23f0fa--deffb83f40224cc4800af39a2e07447b fe10648ab4ed46079e46e12ea1554fba deffb83f40224cc4800af39a2e07447b--fe10648ab4ed46079e46e12ea1554fba 13338765cc824e96ba6eb72248a688bc fe10648ab4ed46079e46e12ea1554fba--13338765cc824e96ba6eb72248a688bc 640a3c94267b4dfeab3cf333d9559f20 13338765cc824e96ba6eb72248a688bc--640a3c94267b4dfeab3cf333d9559f20 15bb59b368ba402591538159ca918e7a 640a3c94267b4dfeab3cf333d9559f20--15bb59b368ba402591538159ca918e7a 5fc7b17dd13e4415b2a5a5bc1b99ce6a 15bb59b368ba402591538159ca918e7a--5fc7b17dd13e4415b2a5a5bc1b99ce6a f10624a4b3bf44f6b19094f93a1e490b 5fc7b17dd13e4415b2a5a5bc1b99ce6a--f10624a4b3bf44f6b19094f93a1e490b d9e2bd264b264dcc9e8923117cd48a03 f10624a4b3bf44f6b19094f93a1e490b--d9e2bd264b264dcc9e8923117cd48a03 2c9b69c179204cf1af918147ab888d47 d9e2bd264b264dcc9e8923117cd48a03--2c9b69c179204cf1af918147ab888d47 058167f7b8434983ac01c8676dedad85 X 2c9b69c179204cf1af918147ab888d47--058167f7b8434983ac01c8676dedad85 058167f7b8434983ac01c8676dedad85--22dc471c4d7b495795679d5213ef8540 9313fb8705d54ec5b3ef71c1bf4fc604 058167f7b8434983ac01c8676dedad85--9313fb8705d54ec5b3ef71c1bf4fc604 970cc7f22d7a42be99c16d9fd8ab82f6 9313fb8705d54ec5b3ef71c1bf4fc604--970cc7f22d7a42be99c16d9fd8ab82f6 22f665b95f614ac98aa78f768410bc87 970cc7f22d7a42be99c16d9fd8ab82f6--22f665b95f614ac98aa78f768410bc87 27572c32f584460b90b03145673ad527 22f665b95f614ac98aa78f768410bc87--27572c32f584460b90b03145673ad527 e3b894735ce04acca3ab5daea281c419 27572c32f584460b90b03145673ad527--e3b894735ce04acca3ab5daea281c419 4a8b888059e64bbdb077de3156d75617 e3b894735ce04acca3ab5daea281c419--4a8b888059e64bbdb077de3156d75617 e990e6608af94f188fe34ea6ebfc0e4a 4a8b888059e64bbdb077de3156d75617--e990e6608af94f188fe34ea6ebfc0e4a e1de39e0d3b74654ba99fc697a203410 e990e6608af94f188fe34ea6ebfc0e4a--e1de39e0d3b74654ba99fc697a203410 21cf7a1cf0b94eb78f93eb1b800d96e0 e1de39e0d3b74654ba99fc697a203410--21cf7a1cf0b94eb78f93eb1b800d96e0 cdbb9cb9e53c4b699ac212f8b188f573 21cf7a1cf0b94eb78f93eb1b800d96e0--cdbb9cb9e53c4b699ac212f8b188f573 e45dbd56ca36481eb8cce513db6cd599 cdbb9cb9e53c4b699ac212f8b188f573--e45dbd56ca36481eb8cce513db6cd599 589245342dd4442cb096cf611038ca9b e45dbd56ca36481eb8cce513db6cd599--589245342dd4442cb096cf611038ca9b 2d4fb777f3904336b054daea3247ae7a X 589245342dd4442cb096cf611038ca9b--2d4fb777f3904336b054daea3247ae7a 2d4fb777f3904336b054daea3247ae7a--488a10c6d4a3480f9202a29add025cda aa89c392c57f4a0fa8e81d5747e0d0ca 2d4fb777f3904336b054daea3247ae7a--aa89c392c57f4a0fa8e81d5747e0d0ca e8fe2cf2a2f8471494a7de13719dbb33 aa89c392c57f4a0fa8e81d5747e0d0ca--e8fe2cf2a2f8471494a7de13719dbb33 568060669d8b468a85daec0e746c57c9 e8fe2cf2a2f8471494a7de13719dbb33--568060669d8b468a85daec0e746c57c9 6f9cae2a3d02436bbdf104dce645769f X 568060669d8b468a85daec0e746c57c9--6f9cae2a3d02436bbdf104dce645769f 6f9cae2a3d02436bbdf104dce645769f--2178b3a3cfc84d1a9437a44b93e20846 b6104776ca4246528fc2e071fb25f84c 6f9cae2a3d02436bbdf104dce645769f--b6104776ca4246528fc2e071fb25f84c 7c9048720a974943b8e075361525bb2c b6104776ca4246528fc2e071fb25f84c--7c9048720a974943b8e075361525bb2c 325d0d01575a4382b10e896be56f4d6e 7c9048720a974943b8e075361525bb2c--325d0d01575a4382b10e896be56f4d6e 5896504042154772a8ebb20435a4698a 325d0d01575a4382b10e896be56f4d6e--5896504042154772a8ebb20435a4698a 7e1a812d0be34f3c82639408338269eb X 5896504042154772a8ebb20435a4698a--7e1a812d0be34f3c82639408338269eb 7e1a812d0be34f3c82639408338269eb--5bb8f031bc7f4a99826fec9bdb255bcb c6cb39fca9ba4966a11b08f92b52a047 7e1a812d0be34f3c82639408338269eb--c6cb39fca9ba4966a11b08f92b52a047 02c3d25d428147c29ed3090072358cd6 c6cb39fca9ba4966a11b08f92b52a047--02c3d25d428147c29ed3090072358cd6 4405c9e54d104ecd9eded3d7c68f97e5 02c3d25d428147c29ed3090072358cd6--4405c9e54d104ecd9eded3d7c68f97e5 64c4d6bfca0343c889d13d0cbdbe98ae 4405c9e54d104ecd9eded3d7c68f97e5--64c4d6bfca0343c889d13d0cbdbe98ae 01ac1032cbf24968823ec23532a65032 64c4d6bfca0343c889d13d0cbdbe98ae--01ac1032cbf24968823ec23532a65032 3e4cf6bb46164f958b1c78eb50cc6af5 X 01ac1032cbf24968823ec23532a65032--3e4cf6bb46164f958b1c78eb50cc6af5 3e4cf6bb46164f958b1c78eb50cc6af5--ab138edd61f54dd8bc1ea9149dac4834 ff71fe9813a74488880477382fe5cb79 3e4cf6bb46164f958b1c78eb50cc6af5--ff71fe9813a74488880477382fe5cb79 9144d853c6e64070ae8c465c3649ff01 ff71fe9813a74488880477382fe5cb79--9144d853c6e64070ae8c465c3649ff01 e2b1f972850245bf92b217249f4ed09a 9144d853c6e64070ae8c465c3649ff01--e2b1f972850245bf92b217249f4ed09a 11c5f85692194420848de3c20903a889 e2b1f972850245bf92b217249f4ed09a--11c5f85692194420848de3c20903a889 184e8dd7ac8740ec871b6afd2fb4d790 X 11c5f85692194420848de3c20903a889--184e8dd7ac8740ec871b6afd2fb4d790 184e8dd7ac8740ec871b6afd2fb4d790--59602f6b5ce64ce7ba49351e5fcada7c c81f98f238fb442ba95cd8c39375dfa6 184e8dd7ac8740ec871b6afd2fb4d790--c81f98f238fb442ba95cd8c39375dfa6 8ca34310573241238160f708c9ac28c6 c81f98f238fb442ba95cd8c39375dfa6--8ca34310573241238160f708c9ac28c6 d2f4561d89864e3b9080430960bab77b 8ca34310573241238160f708c9ac28c6--d2f4561d89864e3b9080430960bab77b 58d8f77e156f4cdabc2acafb102b56ec d2f4561d89864e3b9080430960bab77b--58d8f77e156f4cdabc2acafb102b56ec 5dfa5c95379b4043bbbc70d97a010b89 58d8f77e156f4cdabc2acafb102b56ec--5dfa5c95379b4043bbbc70d97a010b89 25e36da085ad4975af61f2b11f25c146 5dfa5c95379b4043bbbc70d97a010b89--25e36da085ad4975af61f2b11f25c146 fd47a6afb64f4f59925cb165c92456a7 25e36da085ad4975af61f2b11f25c146--fd47a6afb64f4f59925cb165c92456a7 ff77f03f01f9441aaae96f6ebeff3aa0 fd47a6afb64f4f59925cb165c92456a7--ff77f03f01f9441aaae96f6ebeff3aa0 878a5d95c1e24171899d8b4322d61ce5 ff77f03f01f9441aaae96f6ebeff3aa0--878a5d95c1e24171899d8b4322d61ce5 70e2bfb7644748f28d0d2a38107d6ef8 X 878a5d95c1e24171899d8b4322d61ce5--70e2bfb7644748f28d0d2a38107d6ef8 70e2bfb7644748f28d0d2a38107d6ef8--83afdde66f2b4a0cb28735578c15c13a f1671be829304c98bec3de2f00bf0758 70e2bfb7644748f28d0d2a38107d6ef8--f1671be829304c98bec3de2f00bf0758 39656c606ebf4d5197431a8dab1fd8e1 f1671be829304c98bec3de2f00bf0758--39656c606ebf4d5197431a8dab1fd8e1 98f72ccd50724ada8bf13656f107af09 39656c606ebf4d5197431a8dab1fd8e1--98f72ccd50724ada8bf13656f107af09 73253ae2497d454a840ab732e080ff2c 98f72ccd50724ada8bf13656f107af09--73253ae2497d454a840ab732e080ff2c 8985d39791934a798c8dc80199d8672f 73253ae2497d454a840ab732e080ff2c--8985d39791934a798c8dc80199d8672f 744be45dc6424eca870b14b81ef1ed3c 8985d39791934a798c8dc80199d8672f--744be45dc6424eca870b14b81ef1ed3c 9f78bbca34174be786f667c67d0fb221 X 744be45dc6424eca870b14b81ef1ed3c--9f78bbca34174be786f667c67d0fb221 9f78bbca34174be786f667c67d0fb221--9e624ba7411448de9dd7e078d0bdf876 5c88c96244b84b119a1ce3afb91ed9a1 RZ(-1.0*g0) 9f78bbca34174be786f667c67d0fb221--5c88c96244b84b119a1ce3afb91ed9a1 7c3e7cb490494f0cbfef10088921a180 X 5c88c96244b84b119a1ce3afb91ed9a1--7c3e7cb490494f0cbfef10088921a180 7c3e7cb490494f0cbfef10088921a180--7e1e2553edb44ca887b737b6ebdaef95 761e39e7434047d691f3c738582fc23a 7c3e7cb490494f0cbfef10088921a180--761e39e7434047d691f3c738582fc23a f24240af43194809848342a84384dd57 761e39e7434047d691f3c738582fc23a--f24240af43194809848342a84384dd57 b5f5f4e29936438483bfad83c29cddbf X f24240af43194809848342a84384dd57--b5f5f4e29936438483bfad83c29cddbf b5f5f4e29936438483bfad83c29cddbf--b0b86308a242474998a3de1362dbbba2 ba927308ae4643a49bbf70973f5d410b b5f5f4e29936438483bfad83c29cddbf--ba927308ae4643a49bbf70973f5d410b ef37f744f9f448148f9b85e6bcd7a57b ba927308ae4643a49bbf70973f5d410b--ef37f744f9f448148f9b85e6bcd7a57b 8743da010e264023bc4206af1c75a3bf ef37f744f9f448148f9b85e6bcd7a57b--8743da010e264023bc4206af1c75a3bf 2e00837d6b784065a4927314d75bec1b X 8743da010e264023bc4206af1c75a3bf--2e00837d6b784065a4927314d75bec1b 2e00837d6b784065a4927314d75bec1b--8e475cd41e294b74a6fdff2f681ebe50 84d8bf7141fc49ae906fe1a0a7f8ff43 2e00837d6b784065a4927314d75bec1b--84d8bf7141fc49ae906fe1a0a7f8ff43 e6b62afc9e6649218e24762f4d03f345 84d8bf7141fc49ae906fe1a0a7f8ff43--e6b62afc9e6649218e24762f4d03f345 64f92f9472c74d2d9a89821ca02f1aa8 X e6b62afc9e6649218e24762f4d03f345--64f92f9472c74d2d9a89821ca02f1aa8 64f92f9472c74d2d9a89821ca02f1aa8--ff4443101a11444db49321a461c37974 256b727809a944ceafffdf17bc21b1a6 64f92f9472c74d2d9a89821ca02f1aa8--256b727809a944ceafffdf17bc21b1a6 1934c4da3f454b8888b3da1667a8193c 256b727809a944ceafffdf17bc21b1a6--1934c4da3f454b8888b3da1667a8193c edf4510f0ed44bb7bfa027eabedaa7e7 1934c4da3f454b8888b3da1667a8193c--edf4510f0ed44bb7bfa027eabedaa7e7 cff4043dc45b4185a5ca42a24051060e edf4510f0ed44bb7bfa027eabedaa7e7--cff4043dc45b4185a5ca42a24051060e 8bc6017a4d164e738c7e9ba09ca27491 cff4043dc45b4185a5ca42a24051060e--8bc6017a4d164e738c7e9ba09ca27491 787fa29e1f7440a2817b40cee38e43b5 X 8bc6017a4d164e738c7e9ba09ca27491--787fa29e1f7440a2817b40cee38e43b5 787fa29e1f7440a2817b40cee38e43b5--314cc255c73446c6b590e23b8304294d 0d4c23c72bf441be9935078b5190ab16 787fa29e1f7440a2817b40cee38e43b5--0d4c23c72bf441be9935078b5190ab16 67ddbac592d8422b9b3601535aac2329 0d4c23c72bf441be9935078b5190ab16--67ddbac592d8422b9b3601535aac2329 650a1c888d3c4dabb0bfdeb2e1653127 X 67ddbac592d8422b9b3601535aac2329--650a1c888d3c4dabb0bfdeb2e1653127 650a1c888d3c4dabb0bfdeb2e1653127--db54e1ed99f44e2a90a69c0873c988d4 3672d3133df04bebb3eec5343668b271 650a1c888d3c4dabb0bfdeb2e1653127--3672d3133df04bebb3eec5343668b271 a49686e2f2544d4e835e9dac31857e71 3672d3133df04bebb3eec5343668b271--a49686e2f2544d4e835e9dac31857e71 74664d32315040738d495640a05a8b1b a49686e2f2544d4e835e9dac31857e71--74664d32315040738d495640a05a8b1b 650905e7f3ff4ae0b9fba74235daadf5 74664d32315040738d495640a05a8b1b--650905e7f3ff4ae0b9fba74235daadf5 b370bcb2f981420da5c81c0232c71ba8 650905e7f3ff4ae0b9fba74235daadf5--b370bcb2f981420da5c81c0232c71ba8 3919501472a148a992ec1b2880184d93 b370bcb2f981420da5c81c0232c71ba8--3919501472a148a992ec1b2880184d93 02bcefadf2a3496eb638ec650b8a842d 3919501472a148a992ec1b2880184d93--02bcefadf2a3496eb638ec650b8a842d b06bff46cc5a4ffa8dd920509f0a4e38 X 02bcefadf2a3496eb638ec650b8a842d--b06bff46cc5a4ffa8dd920509f0a4e38 b06bff46cc5a4ffa8dd920509f0a4e38--ede041d1f8a74c94bbfe0d77ed676045 49f08715f4964f54af2c09a1d72380cb b06bff46cc5a4ffa8dd920509f0a4e38--49f08715f4964f54af2c09a1d72380cb a7fa23f9459149cc8c85937a865f1ef2 49f08715f4964f54af2c09a1d72380cb--a7fa23f9459149cc8c85937a865f1ef2 6b6ec333d9604963b4d3ac9a6d6ebddd X a7fa23f9459149cc8c85937a865f1ef2--6b6ec333d9604963b4d3ac9a6d6ebddd 6b6ec333d9604963b4d3ac9a6d6ebddd--904a668b40144abab4d9e236106f9336 44ae52e362c248d88b238153098e0f77 6b6ec333d9604963b4d3ac9a6d6ebddd--44ae52e362c248d88b238153098e0f77 e6989081d763448db1fad2ed0b7c90a3 44ae52e362c248d88b238153098e0f77--e6989081d763448db1fad2ed0b7c90a3 66a68270136846a1a56d91734cc515b1 e6989081d763448db1fad2ed0b7c90a3--66a68270136846a1a56d91734cc515b1 f58a7c3e732749bf866481da80b8d0b9 66a68270136846a1a56d91734cc515b1--f58a7c3e732749bf866481da80b8d0b9 b61fb840170c4d61a9fed012e5521435 f58a7c3e732749bf866481da80b8d0b9--b61fb840170c4d61a9fed012e5521435 4379665fd2364d80b6b7084a0709695f b61fb840170c4d61a9fed012e5521435--4379665fd2364d80b6b7084a0709695f 7ca592291f3b4ffaab943774846458fd 4379665fd2364d80b6b7084a0709695f--7ca592291f3b4ffaab943774846458fd 177c1a6b6500453784dbc3f6b5a1e75d 7ca592291f3b4ffaab943774846458fd--177c1a6b6500453784dbc3f6b5a1e75d e82006a725414b8c892a2e99171e6458 177c1a6b6500453784dbc3f6b5a1e75d--e82006a725414b8c892a2e99171e6458 9d2fe674d6e74d919c8206f14feae13c X e82006a725414b8c892a2e99171e6458--9d2fe674d6e74d919c8206f14feae13c 9d2fe674d6e74d919c8206f14feae13c--6949e0f3a7254e3bb5f3179e534ef1a9 ff751ebb707a48c3a86727941fda9129 9d2fe674d6e74d919c8206f14feae13c--ff751ebb707a48c3a86727941fda9129 3596f180a8f44956bf575ddd59e23b5e X ff751ebb707a48c3a86727941fda9129--3596f180a8f44956bf575ddd59e23b5e 3596f180a8f44956bf575ddd59e23b5e--f3950f24e7c74416b4193811737b887b b8be6c528df14e868cccd3d25d9c0534 RZ(-1.0*g0) 3596f180a8f44956bf575ddd59e23b5e--b8be6c528df14e868cccd3d25d9c0534 14fd8d8bae4643ff8386632c7b435d08 X b8be6c528df14e868cccd3d25d9c0534--14fd8d8bae4643ff8386632c7b435d08 14fd8d8bae4643ff8386632c7b435d08--0bf35a9eb13b43029bdf6022e4aaa5e6 20db136bf4a84bc1b003e850d3f09498 X 14fd8d8bae4643ff8386632c7b435d08--20db136bf4a84bc1b003e850d3f09498 20db136bf4a84bc1b003e850d3f09498--5f35199a655145249d213b2d5b6290ea d080c751ad984088988ce9dcdae3b33b 20db136bf4a84bc1b003e850d3f09498--d080c751ad984088988ce9dcdae3b33b 550f2e7b3484464fa548cb0a31138e32 d080c751ad984088988ce9dcdae3b33b--550f2e7b3484464fa548cb0a31138e32 b91acb49c88345a0833fa71cae601dbb 550f2e7b3484464fa548cb0a31138e32--b91acb49c88345a0833fa71cae601dbb 10e5125a6e46424e84513faa50046c9d b91acb49c88345a0833fa71cae601dbb--10e5125a6e46424e84513faa50046c9d 5b57485b310744a38678d679d8d27bd7 10e5125a6e46424e84513faa50046c9d--5b57485b310744a38678d679d8d27bd7 1834af12ceb44e6ca1a294cf90751f6b X 5b57485b310744a38678d679d8d27bd7--1834af12ceb44e6ca1a294cf90751f6b 1834af12ceb44e6ca1a294cf90751f6b--6952c599f4bf46de859b42356e0e141f 62ff5a07cb6f4a20a4977d8579ef40ce X 1834af12ceb44e6ca1a294cf90751f6b--62ff5a07cb6f4a20a4977d8579ef40ce 62ff5a07cb6f4a20a4977d8579ef40ce--49a506dabbf44b8db7e9e24f6c28dc9a 621a10c1c154482da26f3d8a1ae0d712 62ff5a07cb6f4a20a4977d8579ef40ce--621a10c1c154482da26f3d8a1ae0d712 9aeeadd36a914e799168e22c6d977b65 621a10c1c154482da26f3d8a1ae0d712--9aeeadd36a914e799168e22c6d977b65 62a159c5f0774b17b65231d056bef956 9aeeadd36a914e799168e22c6d977b65--62a159c5f0774b17b65231d056bef956 98ec4df32f8b443c85cfdd11c75b7ea0 62a159c5f0774b17b65231d056bef956--98ec4df32f8b443c85cfdd11c75b7ea0 c563376134a54f15ac7f2a68e0f6a97b 98ec4df32f8b443c85cfdd11c75b7ea0--c563376134a54f15ac7f2a68e0f6a97b d9d5f2045f084ace8b886c02d69d9e5a c563376134a54f15ac7f2a68e0f6a97b--d9d5f2045f084ace8b886c02d69d9e5a 25f1a0b40df941bf8872d2baca99cf5b d9d5f2045f084ace8b886c02d69d9e5a--25f1a0b40df941bf8872d2baca99cf5b 4c8c4812f57d40ffb49f458cb903a4ba X 25f1a0b40df941bf8872d2baca99cf5b--4c8c4812f57d40ffb49f458cb903a4ba 4c8c4812f57d40ffb49f458cb903a4ba--8617cba67cba40068192c8a226312a05 dcaeb552d83a44e6b1190bf4a6701202 4c8c4812f57d40ffb49f458cb903a4ba--dcaeb552d83a44e6b1190bf4a6701202 5b14f6bab5df45d3a346a59da2f8c1a7 dcaeb552d83a44e6b1190bf4a6701202--5b14f6bab5df45d3a346a59da2f8c1a7 1b227db5de2e40fe9716ea3c0be95576 5b14f6bab5df45d3a346a59da2f8c1a7--1b227db5de2e40fe9716ea3c0be95576 6a3b8e69577448eba6b8368a4f39c1a1 1b227db5de2e40fe9716ea3c0be95576--6a3b8e69577448eba6b8368a4f39c1a1 079a623af1a8459b91f50f2544630160 6a3b8e69577448eba6b8368a4f39c1a1--079a623af1a8459b91f50f2544630160 eccef29b3fe848b0b24584ec845b412d 079a623af1a8459b91f50f2544630160--eccef29b3fe848b0b24584ec845b412d 080331dc2f824c7f9d5d98158894b7ef eccef29b3fe848b0b24584ec845b412d--080331dc2f824c7f9d5d98158894b7ef e91340a135394483a65bad8c1c441df4 080331dc2f824c7f9d5d98158894b7ef--e91340a135394483a65bad8c1c441df4 af4b22fe15624ab28b8faa22127fd352 e91340a135394483a65bad8c1c441df4--af4b22fe15624ab28b8faa22127fd352 05a3a16223754f03825a41da52f7b03c af4b22fe15624ab28b8faa22127fd352--05a3a16223754f03825a41da52f7b03c cbcc4ecd25824c1ab000f2703d3b51e4 05a3a16223754f03825a41da52f7b03c--cbcc4ecd25824c1ab000f2703d3b51e4 171fcd42c2fb468f926b9b3c552bf1f7 cbcc4ecd25824c1ab000f2703d3b51e4--171fcd42c2fb468f926b9b3c552bf1f7 0530a04b0fb74cbf930c7cd2a0e5fa72 171fcd42c2fb468f926b9b3c552bf1f7--0530a04b0fb74cbf930c7cd2a0e5fa72 f0b8683f25e24a0ebb31592b443c223a 0530a04b0fb74cbf930c7cd2a0e5fa72--f0b8683f25e24a0ebb31592b443c223a 3eb3b6a63765422cbe579cf4f5f59509 f0b8683f25e24a0ebb31592b443c223a--3eb3b6a63765422cbe579cf4f5f59509 3e4e8e15745a43909954d58d58db5f53 3eb3b6a63765422cbe579cf4f5f59509--3e4e8e15745a43909954d58d58db5f53 e7ba6fd0b15c4b339b62bb6dc0a399d5 3e4e8e15745a43909954d58d58db5f53--e7ba6fd0b15c4b339b62bb6dc0a399d5 a290a7f1841b4c61ab88c041f28aaeb3 e7ba6fd0b15c4b339b62bb6dc0a399d5--a290a7f1841b4c61ab88c041f28aaeb3 3c9d937c3ca548c5ae71bbcb47b07367 a290a7f1841b4c61ab88c041f28aaeb3--3c9d937c3ca548c5ae71bbcb47b07367 17c1fce88d364be093f0a8a1107a418c 3c9d937c3ca548c5ae71bbcb47b07367--17c1fce88d364be093f0a8a1107a418c 8a2e94beb29e4149be88c9fa77be7247 17c1fce88d364be093f0a8a1107a418c--8a2e94beb29e4149be88c9fa77be7247 84d54f7bc91d4c22af17e1af35559219 8a2e94beb29e4149be88c9fa77be7247--84d54f7bc91d4c22af17e1af35559219 154291515f064b47b95dfef910572281 84d54f7bc91d4c22af17e1af35559219--154291515f064b47b95dfef910572281 fdb6711efddd4e0c97514faae4cc2fb3 154291515f064b47b95dfef910572281--fdb6711efddd4e0c97514faae4cc2fb3 36c8e82367004ab1a8d003671ebb7c16 fdb6711efddd4e0c97514faae4cc2fb3--36c8e82367004ab1a8d003671ebb7c16 2596a3ac84e64f18b5ff5d9923c4374d 36c8e82367004ab1a8d003671ebb7c16--2596a3ac84e64f18b5ff5d9923c4374d 1ed2384abc7a43968b7bbc659e12132a RX(b03) 2596a3ac84e64f18b5ff5d9923c4374d--1ed2384abc7a43968b7bbc659e12132a 0858eda4bd20483aaa1ba8ba4265a960 1ed2384abc7a43968b7bbc659e12132a--0858eda4bd20483aaa1ba8ba4265a960 f1bfe4b1910b46d9881f43eb038d3667 0858eda4bd20483aaa1ba8ba4265a960--f1bfe4b1910b46d9881f43eb038d3667 be04f76b009644ed88557cc59a6ed3e2 X f1bfe4b1910b46d9881f43eb038d3667--be04f76b009644ed88557cc59a6ed3e2 be04f76b009644ed88557cc59a6ed3e2--549434e60dfd479696d771407b3412ca 139167e1ace44c4e98f12718224c16cd be04f76b009644ed88557cc59a6ed3e2--139167e1ace44c4e98f12718224c16cd 8964459ed0c84615ab54b731ff2f013f 139167e1ace44c4e98f12718224c16cd--8964459ed0c84615ab54b731ff2f013f 6b0dff9a351046e4b4daa34ec63f710e 8964459ed0c84615ab54b731ff2f013f--6b0dff9a351046e4b4daa34ec63f710e 02cf51f0f2de4443860991c272a39d4a 6b0dff9a351046e4b4daa34ec63f710e--02cf51f0f2de4443860991c272a39d4a f86f04493bb14193a975f5465b33b7ea 02cf51f0f2de4443860991c272a39d4a--f86f04493bb14193a975f5465b33b7ea 3d97b994fdc94bdf88c9db54756ce04e f86f04493bb14193a975f5465b33b7ea--3d97b994fdc94bdf88c9db54756ce04e 6afdf199648a4f35b7f7cd3fad3a308a 3d97b994fdc94bdf88c9db54756ce04e--6afdf199648a4f35b7f7cd3fad3a308a 26ace86afbf44f34b69e4f66cf2fa2a8 6afdf199648a4f35b7f7cd3fad3a308a--26ace86afbf44f34b69e4f66cf2fa2a8 13adba3f88674503b2f692a49f201ba5 26ace86afbf44f34b69e4f66cf2fa2a8--13adba3f88674503b2f692a49f201ba5 1b97378d38f64968a98210e6bdd12e3a X 13adba3f88674503b2f692a49f201ba5--1b97378d38f64968a98210e6bdd12e3a 1b97378d38f64968a98210e6bdd12e3a--d451f5e5ef3c4fe7a6cc88a382a30477 1487b7941e4246d3a4e96533ba338ecc 1b97378d38f64968a98210e6bdd12e3a--1487b7941e4246d3a4e96533ba338ecc 487bea458e684b32b1a288365a07bac0 1487b7941e4246d3a4e96533ba338ecc--487bea458e684b32b1a288365a07bac0 95a23edf85b74853921ac7b1621792a3 487bea458e684b32b1a288365a07bac0--95a23edf85b74853921ac7b1621792a3 500d7709d76542659a222632e1ab36c5 95a23edf85b74853921ac7b1621792a3--500d7709d76542659a222632e1ab36c5 0e5b2a5306774bed8f673322d3256d69 500d7709d76542659a222632e1ab36c5--0e5b2a5306774bed8f673322d3256d69 49cddcc1d33946f8be3ea497aed4a360 0e5b2a5306774bed8f673322d3256d69--49cddcc1d33946f8be3ea497aed4a360 17af3b85540344698b78524060c55d62 49cddcc1d33946f8be3ea497aed4a360--17af3b85540344698b78524060c55d62 2f6945a9206e4608ab076e73458ca93f 17af3b85540344698b78524060c55d62--2f6945a9206e4608ab076e73458ca93f 277060a1f34744aaa750484aff99ca1f 2f6945a9206e4608ab076e73458ca93f--277060a1f34744aaa750484aff99ca1f fb8e9afb6fbb43fba02365cb7136eac1 277060a1f34744aaa750484aff99ca1f--fb8e9afb6fbb43fba02365cb7136eac1 1f3b4ce2539149e5a0dc8e38a5919c0c fb8e9afb6fbb43fba02365cb7136eac1--1f3b4ce2539149e5a0dc8e38a5919c0c 13b32beed28648a7a66a628c29087dc4 1f3b4ce2539149e5a0dc8e38a5919c0c--13b32beed28648a7a66a628c29087dc4 e37e9d2320af4c20975b834dab2c4a8d X 13b32beed28648a7a66a628c29087dc4--e37e9d2320af4c20975b834dab2c4a8d e37e9d2320af4c20975b834dab2c4a8d--fd9d558f1ff04829868caf09c05e9e13 6ea36ff4a0354f86924084b4a6328950 e37e9d2320af4c20975b834dab2c4a8d--6ea36ff4a0354f86924084b4a6328950 69396526e36042a2be8fa77149f7cdc2 6ea36ff4a0354f86924084b4a6328950--69396526e36042a2be8fa77149f7cdc2 eb6f23c6956d49318368f83938a35a5c 69396526e36042a2be8fa77149f7cdc2--eb6f23c6956d49318368f83938a35a5c 73feb49e3a2e4025bce1f76ae1cb9466 X eb6f23c6956d49318368f83938a35a5c--73feb49e3a2e4025bce1f76ae1cb9466 73feb49e3a2e4025bce1f76ae1cb9466--6b38244d867c4651b472961fa27976fd 52d8e93228fd43468bce0180c927df79 73feb49e3a2e4025bce1f76ae1cb9466--52d8e93228fd43468bce0180c927df79 0e9ee32fd4d44fdebed4ee8f458bb905 52d8e93228fd43468bce0180c927df79--0e9ee32fd4d44fdebed4ee8f458bb905 a4c296eec4af4858bf0b5e29e4945a69 0e9ee32fd4d44fdebed4ee8f458bb905--a4c296eec4af4858bf0b5e29e4945a69 9cd499526bcd40f891fcae2656d2c5ba a4c296eec4af4858bf0b5e29e4945a69--9cd499526bcd40f891fcae2656d2c5ba ee5c522d39c647f2842fbe688c683541 X 9cd499526bcd40f891fcae2656d2c5ba--ee5c522d39c647f2842fbe688c683541 ee5c522d39c647f2842fbe688c683541--e257aaf8ee7145af9277bfff443a6950 a0efb19e64c04e43b308741fa8f65460 ee5c522d39c647f2842fbe688c683541--a0efb19e64c04e43b308741fa8f65460 8f77744521244a23b544d0d99500ddc1 a0efb19e64c04e43b308741fa8f65460--8f77744521244a23b544d0d99500ddc1 4e01e4594c494237bb71e40010f6897c 8f77744521244a23b544d0d99500ddc1--4e01e4594c494237bb71e40010f6897c 71c0969c32b94ea2a988fb43ce7c0f9a 4e01e4594c494237bb71e40010f6897c--71c0969c32b94ea2a988fb43ce7c0f9a 99287bc69abb413b923c30ede1f47ca9 71c0969c32b94ea2a988fb43ce7c0f9a--99287bc69abb413b923c30ede1f47ca9 0d9eddb3431b4de18f394512fe042441 X 99287bc69abb413b923c30ede1f47ca9--0d9eddb3431b4de18f394512fe042441 0d9eddb3431b4de18f394512fe042441--9344a6fe6cf140509eb8bfb397485c4b 9e1bb0378d9341b4ad2ef6dc5b5a4999 0d9eddb3431b4de18f394512fe042441--9e1bb0378d9341b4ad2ef6dc5b5a4999 2255ab038bf74731876e613c460398cd 9e1bb0378d9341b4ad2ef6dc5b5a4999--2255ab038bf74731876e613c460398cd f97ef1bffee8460991aec18716a76d12 2255ab038bf74731876e613c460398cd--f97ef1bffee8460991aec18716a76d12 88578d1eb1994ddda85762dc547e667d f97ef1bffee8460991aec18716a76d12--88578d1eb1994ddda85762dc547e667d 21aff3b1d07942408394662a9145f9f9 X 88578d1eb1994ddda85762dc547e667d--21aff3b1d07942408394662a9145f9f9 21aff3b1d07942408394662a9145f9f9--43f9147245d2454eb0629f5c2e6b4ba6 79ad687b2c874bad9b471abe9ebcf842 21aff3b1d07942408394662a9145f9f9--79ad687b2c874bad9b471abe9ebcf842 5695954b0eb94932bf664616d2ca9ef7 79ad687b2c874bad9b471abe9ebcf842--5695954b0eb94932bf664616d2ca9ef7 d9c3be50e7d14ce09a08a39db03fe7f0 5695954b0eb94932bf664616d2ca9ef7--d9c3be50e7d14ce09a08a39db03fe7f0 c8866599fa414542ba56b2af9f3aa1cf d9c3be50e7d14ce09a08a39db03fe7f0--c8866599fa414542ba56b2af9f3aa1cf d29d8eefb3c947b39f56f1def72d4a2c c8866599fa414542ba56b2af9f3aa1cf--d29d8eefb3c947b39f56f1def72d4a2c 0a4393ed12b84d45930f6b9be0e7c88b d29d8eefb3c947b39f56f1def72d4a2c--0a4393ed12b84d45930f6b9be0e7c88b 94c12aa6d6b149b5a5f38330de614e84 0a4393ed12b84d45930f6b9be0e7c88b--94c12aa6d6b149b5a5f38330de614e84 8f5e9b9ec76c4a3ab21b5c7c25f7079d 94c12aa6d6b149b5a5f38330de614e84--8f5e9b9ec76c4a3ab21b5c7c25f7079d 56fa2b2ec7f6438c8d3aa3a03a5afbad 8f5e9b9ec76c4a3ab21b5c7c25f7079d--56fa2b2ec7f6438c8d3aa3a03a5afbad 1499c32e6fd747ea9c569221c6bf888d X 56fa2b2ec7f6438c8d3aa3a03a5afbad--1499c32e6fd747ea9c569221c6bf888d 1499c32e6fd747ea9c569221c6bf888d--d8ef7eb2a5e54161a8b97a0709a7b29f 6c417283aece4500a137cd2d6324ee67 1499c32e6fd747ea9c569221c6bf888d--6c417283aece4500a137cd2d6324ee67 64a0b1f2926c4c718d8c526567632bda 6c417283aece4500a137cd2d6324ee67--64a0b1f2926c4c718d8c526567632bda 46876deba6b9426dbf7fbeef37fd0966 64a0b1f2926c4c718d8c526567632bda--46876deba6b9426dbf7fbeef37fd0966 cb708fc6116e4de994394d60f611fb7d 46876deba6b9426dbf7fbeef37fd0966--cb708fc6116e4de994394d60f611fb7d a3e6d5ac58904b089c3169297c694ae9 cb708fc6116e4de994394d60f611fb7d--a3e6d5ac58904b089c3169297c694ae9 ecb7c2907e29438b9a51480b2a9724b1 a3e6d5ac58904b089c3169297c694ae9--ecb7c2907e29438b9a51480b2a9724b1 54ee4ffe962547a38274305614e9185d X ecb7c2907e29438b9a51480b2a9724b1--54ee4ffe962547a38274305614e9185d 54ee4ffe962547a38274305614e9185d--a6d78e2fa6704c81aec27afae2dfd974 5ff0c20d0af04e62a9a0c6f1b4f84412 RZ(-1.0*g1) 54ee4ffe962547a38274305614e9185d--5ff0c20d0af04e62a9a0c6f1b4f84412 9a88d1b17be046f7a6053c2d38a6bbc2 X 5ff0c20d0af04e62a9a0c6f1b4f84412--9a88d1b17be046f7a6053c2d38a6bbc2 9a88d1b17be046f7a6053c2d38a6bbc2--03bf88e7b6d44d72a90b9c44017f586f d2cac99356d14cb3ab41ed80645d31c7 9a88d1b17be046f7a6053c2d38a6bbc2--d2cac99356d14cb3ab41ed80645d31c7 3b1af2588ab2446c9c1ad83a32217467 d2cac99356d14cb3ab41ed80645d31c7--3b1af2588ab2446c9c1ad83a32217467 107486cea6eb479c8b7a9b9b3b03486d X 3b1af2588ab2446c9c1ad83a32217467--107486cea6eb479c8b7a9b9b3b03486d 107486cea6eb479c8b7a9b9b3b03486d--d1c4d0c97e544dbdbb26bf0776fc55d7 6e2c1cfdfdd84075bd88c55a036c4ecb 107486cea6eb479c8b7a9b9b3b03486d--6e2c1cfdfdd84075bd88c55a036c4ecb ba9f5b87882e4335876657d8a49d106a 6e2c1cfdfdd84075bd88c55a036c4ecb--ba9f5b87882e4335876657d8a49d106a 378f2d6fad9a4f8597b339e699a1070a ba9f5b87882e4335876657d8a49d106a--378f2d6fad9a4f8597b339e699a1070a 4a999dec47974fc38bf1afc49021765a X 378f2d6fad9a4f8597b339e699a1070a--4a999dec47974fc38bf1afc49021765a 4a999dec47974fc38bf1afc49021765a--27bb81b25a294b63b0d7aa27aa8433b7 7aad4cdcda1b4d31ad947538e7e3544e 4a999dec47974fc38bf1afc49021765a--7aad4cdcda1b4d31ad947538e7e3544e bb47f1c62da1482fab47e27a42aa29cc 7aad4cdcda1b4d31ad947538e7e3544e--bb47f1c62da1482fab47e27a42aa29cc e1392ffbf92e4dafb92557cd5daadfb4 X bb47f1c62da1482fab47e27a42aa29cc--e1392ffbf92e4dafb92557cd5daadfb4 e1392ffbf92e4dafb92557cd5daadfb4--d43216cbc3a94c2eb4aa4e4a6e54cb23 c4d5a0fbea8b4b728e12df6349030e9b e1392ffbf92e4dafb92557cd5daadfb4--c4d5a0fbea8b4b728e12df6349030e9b 27a9fe169c774ad7a29b3e626f09e800 c4d5a0fbea8b4b728e12df6349030e9b--27a9fe169c774ad7a29b3e626f09e800 96114ccb0ced4c989896d5e9d76c54ad 27a9fe169c774ad7a29b3e626f09e800--96114ccb0ced4c989896d5e9d76c54ad ab219e5911324d9cba8c8e6bfad95125 96114ccb0ced4c989896d5e9d76c54ad--ab219e5911324d9cba8c8e6bfad95125 3c67ed08489842c9b9a36a74cfa400a2 ab219e5911324d9cba8c8e6bfad95125--3c67ed08489842c9b9a36a74cfa400a2 cc51b272fe9646549bbeb41e193ec5a1 X 3c67ed08489842c9b9a36a74cfa400a2--cc51b272fe9646549bbeb41e193ec5a1 cc51b272fe9646549bbeb41e193ec5a1--513bbb0b692a4bed80737ab4ecebd0c2 cd9e376f4f974e3caa8213b929c49fa6 cc51b272fe9646549bbeb41e193ec5a1--cd9e376f4f974e3caa8213b929c49fa6 e9096275ffed42bbb88988125b80f247 cd9e376f4f974e3caa8213b929c49fa6--e9096275ffed42bbb88988125b80f247 826f9d11efee4a1da9178d96cdfd99e4 X e9096275ffed42bbb88988125b80f247--826f9d11efee4a1da9178d96cdfd99e4 826f9d11efee4a1da9178d96cdfd99e4--456f8a3710ec4193a6b2f19d81e28b60 92cbaa9536194a829d4b7f8b31de77c6 826f9d11efee4a1da9178d96cdfd99e4--92cbaa9536194a829d4b7f8b31de77c6 bbac99e02743436382e6b8a08c1a8d97 92cbaa9536194a829d4b7f8b31de77c6--bbac99e02743436382e6b8a08c1a8d97 04c860795e6d430492520a39c029f05e bbac99e02743436382e6b8a08c1a8d97--04c860795e6d430492520a39c029f05e 35268233a1b64290aadacbda926c17b2 04c860795e6d430492520a39c029f05e--35268233a1b64290aadacbda926c17b2 cabb3043a87a4b8ea04b46a7d4a187dd 35268233a1b64290aadacbda926c17b2--cabb3043a87a4b8ea04b46a7d4a187dd 645c1e59c88442b38b024e01c4f0e434 cabb3043a87a4b8ea04b46a7d4a187dd--645c1e59c88442b38b024e01c4f0e434 27ab804b7c734a58a90ffd8ebcabf5dd 645c1e59c88442b38b024e01c4f0e434--27ab804b7c734a58a90ffd8ebcabf5dd ef214fbfe3e0426fa54687467da399d9 X 27ab804b7c734a58a90ffd8ebcabf5dd--ef214fbfe3e0426fa54687467da399d9 ef214fbfe3e0426fa54687467da399d9--b0943ba1a1904e46b87f10d6e416eb83 a9cb2f9dc2eb4b2baf9a83948962a441 ef214fbfe3e0426fa54687467da399d9--a9cb2f9dc2eb4b2baf9a83948962a441 33309c5f9fe44ce5999a59d821795635 a9cb2f9dc2eb4b2baf9a83948962a441--33309c5f9fe44ce5999a59d821795635 e5880d914958450e8af73309575166ca X 33309c5f9fe44ce5999a59d821795635--e5880d914958450e8af73309575166ca e5880d914958450e8af73309575166ca--6a49fe969a644931865bddd4d945272d 848ee760b0164cfbaa5fb0081cd03c81 e5880d914958450e8af73309575166ca--848ee760b0164cfbaa5fb0081cd03c81 39aadfd403174662bc061518f1cbd679 848ee760b0164cfbaa5fb0081cd03c81--39aadfd403174662bc061518f1cbd679 0732a099b95440738e57d2dcfa167e4f 39aadfd403174662bc061518f1cbd679--0732a099b95440738e57d2dcfa167e4f e55fca56c1114b309a059c69cf759723 0732a099b95440738e57d2dcfa167e4f--e55fca56c1114b309a059c69cf759723 6a2f3cbc228147d6a08ae287c48e05ed e55fca56c1114b309a059c69cf759723--6a2f3cbc228147d6a08ae287c48e05ed 4de4b870f1364ce893b30c9819c8d5ee 6a2f3cbc228147d6a08ae287c48e05ed--4de4b870f1364ce893b30c9819c8d5ee 6e981e6e9a6c4696947e58118dcaf2da 4de4b870f1364ce893b30c9819c8d5ee--6e981e6e9a6c4696947e58118dcaf2da 4ef2539d1ebc4ee6a3bcb45ac608be72 6e981e6e9a6c4696947e58118dcaf2da--4ef2539d1ebc4ee6a3bcb45ac608be72 00815708543c4663878c11d8dd84fdd7 4ef2539d1ebc4ee6a3bcb45ac608be72--00815708543c4663878c11d8dd84fdd7 9adaf9a95a19435891f609d27258bdb7 X 00815708543c4663878c11d8dd84fdd7--9adaf9a95a19435891f609d27258bdb7 9adaf9a95a19435891f609d27258bdb7--881a82b3dd8b44db90cdb3177d7b1bd8 6ba0bdaddc164ee49915fe0534c30062 9adaf9a95a19435891f609d27258bdb7--6ba0bdaddc164ee49915fe0534c30062 49942baab36a4f0f8cbb51b6ffbd2f69 X 6ba0bdaddc164ee49915fe0534c30062--49942baab36a4f0f8cbb51b6ffbd2f69 49942baab36a4f0f8cbb51b6ffbd2f69--3588cc6f7fab4f2cacd3540da5ff821e 4ad46f20789d44cda68267ad5d9e9651 RZ(-1.0*g1) 49942baab36a4f0f8cbb51b6ffbd2f69--4ad46f20789d44cda68267ad5d9e9651 94c810799827403baa046c339cb291f0 X 4ad46f20789d44cda68267ad5d9e9651--94c810799827403baa046c339cb291f0 94c810799827403baa046c339cb291f0--5ad07e1569e440e5a8324c4255134fe2 bc648c9223274e2ba2f1bd2400d099d7 X 94c810799827403baa046c339cb291f0--bc648c9223274e2ba2f1bd2400d099d7 bc648c9223274e2ba2f1bd2400d099d7--e30f9022c2424725a893964744fa3aa0 e2ff9654c1444d77852680205a4e3066 bc648c9223274e2ba2f1bd2400d099d7--e2ff9654c1444d77852680205a4e3066 fb16d0d61af64600913be5450eaa47e8 e2ff9654c1444d77852680205a4e3066--fb16d0d61af64600913be5450eaa47e8 fb7a9509d55d41c9832edc12b096f5c3 fb16d0d61af64600913be5450eaa47e8--fb7a9509d55d41c9832edc12b096f5c3 55818c951c3d41f6ba105c65c660da7e fb7a9509d55d41c9832edc12b096f5c3--55818c951c3d41f6ba105c65c660da7e 4cb1abb591d9433f8faf166a338f952d 55818c951c3d41f6ba105c65c660da7e--4cb1abb591d9433f8faf166a338f952d 3a61bb3621f94846b15f3ca1d0780fa6 X 4cb1abb591d9433f8faf166a338f952d--3a61bb3621f94846b15f3ca1d0780fa6 3a61bb3621f94846b15f3ca1d0780fa6--955d1228eb224bbd8cb562be10792f9a 730906fdb3b34f7fae2bccc4e35ab383 X 3a61bb3621f94846b15f3ca1d0780fa6--730906fdb3b34f7fae2bccc4e35ab383 730906fdb3b34f7fae2bccc4e35ab383--bd4a9d46c7894fa893b0ce7f7510d236 30354739ac9a4ce2a0c1260dd1a64320 730906fdb3b34f7fae2bccc4e35ab383--30354739ac9a4ce2a0c1260dd1a64320 92899c7e23e84a04ab871579ea128d8c 30354739ac9a4ce2a0c1260dd1a64320--92899c7e23e84a04ab871579ea128d8c 5b76c14868b64085a1f16976ea27fb6a 92899c7e23e84a04ab871579ea128d8c--5b76c14868b64085a1f16976ea27fb6a 9abc52f9bfa04ef88ebf9055261e4c20 5b76c14868b64085a1f16976ea27fb6a--9abc52f9bfa04ef88ebf9055261e4c20 57f88b3e1f6348beb128206b19b803b0 9abc52f9bfa04ef88ebf9055261e4c20--57f88b3e1f6348beb128206b19b803b0 16a52560bfe3432fa8848f795986164e 57f88b3e1f6348beb128206b19b803b0--16a52560bfe3432fa8848f795986164e 3c6942bfd7184bf8bc262788ddf7ceaa 16a52560bfe3432fa8848f795986164e--3c6942bfd7184bf8bc262788ddf7ceaa 776ca0e51717424b88081c7e0c370521 X 3c6942bfd7184bf8bc262788ddf7ceaa--776ca0e51717424b88081c7e0c370521 776ca0e51717424b88081c7e0c370521--fc0c685bec6f4942b8fcd4b11cdb57cf c73714485fd04f9ab082e5373cb6cc26 776ca0e51717424b88081c7e0c370521--c73714485fd04f9ab082e5373cb6cc26 908fa0e242f24e1e9bf4651ac7246767 c73714485fd04f9ab082e5373cb6cc26--908fa0e242f24e1e9bf4651ac7246767 022abc1ec0fe42a39f0fba989a033b57 908fa0e242f24e1e9bf4651ac7246767--022abc1ec0fe42a39f0fba989a033b57 616e4fc7cbb2447383c828f06d1a9040 022abc1ec0fe42a39f0fba989a033b57--616e4fc7cbb2447383c828f06d1a9040 15b290fddacd4a9e8adb34462a2cea55 616e4fc7cbb2447383c828f06d1a9040--15b290fddacd4a9e8adb34462a2cea55 dfa0deb92d5745088c3bf2bb448e6c25 15b290fddacd4a9e8adb34462a2cea55--dfa0deb92d5745088c3bf2bb448e6c25 b4274bd071164e869395e0d3030fe73f dfa0deb92d5745088c3bf2bb448e6c25--b4274bd071164e869395e0d3030fe73f 18eeaf35b7c44332ba6fca8186fba311 b4274bd071164e869395e0d3030fe73f--18eeaf35b7c44332ba6fca8186fba311 f20345409376488cb6c94afe8fe9bb23 18eeaf35b7c44332ba6fca8186fba311--f20345409376488cb6c94afe8fe9bb23 144d2622632a4470b6362ca84da5b63b f20345409376488cb6c94afe8fe9bb23--144d2622632a4470b6362ca84da5b63b fe610a90d7a045fea5c49aba9b94398c 144d2622632a4470b6362ca84da5b63b--fe610a90d7a045fea5c49aba9b94398c 93ff588cd7db4670916fe4022ff86849 fe610a90d7a045fea5c49aba9b94398c--93ff588cd7db4670916fe4022ff86849 481017e5fd0e46c38f0685978af3b6ee 93ff588cd7db4670916fe4022ff86849--481017e5fd0e46c38f0685978af3b6ee be2d80e0fd9d4f28afc4b5c33ee31a77 481017e5fd0e46c38f0685978af3b6ee--be2d80e0fd9d4f28afc4b5c33ee31a77 ac86f838c7c34a75b5077ab4077801d2 be2d80e0fd9d4f28afc4b5c33ee31a77--ac86f838c7c34a75b5077ab4077801d2 fe75991c8ca144369dd9f6245ecb80fc ac86f838c7c34a75b5077ab4077801d2--fe75991c8ca144369dd9f6245ecb80fc a82ba360f51543e3947a7e10b7a7052d fe75991c8ca144369dd9f6245ecb80fc--a82ba360f51543e3947a7e10b7a7052d 1285bb4ce813449aac69c2d16021cf11 a82ba360f51543e3947a7e10b7a7052d--1285bb4ce813449aac69c2d16021cf11 40994e76c94b4ad9bdc228bd9cf4c1a6 1285bb4ce813449aac69c2d16021cf11--40994e76c94b4ad9bdc228bd9cf4c1a6 8284360d5a534184ba4de0757c32042c 40994e76c94b4ad9bdc228bd9cf4c1a6--8284360d5a534184ba4de0757c32042c ecaa8d864d6b45c9b4bca21d6038b1a5 8284360d5a534184ba4de0757c32042c--ecaa8d864d6b45c9b4bca21d6038b1a5 cc4a58dddff5481093391990981732e0 ecaa8d864d6b45c9b4bca21d6038b1a5--cc4a58dddff5481093391990981732e0 7fca43f278574c929d7625c1818248a9 cc4a58dddff5481093391990981732e0--7fca43f278574c929d7625c1818248a9 a77a1e1ad674410abc71275a6d6696e3 7fca43f278574c929d7625c1818248a9--a77a1e1ad674410abc71275a6d6696e3 62f5b401f1f0442aba5eb75a40e4d4e0 a77a1e1ad674410abc71275a6d6696e3--62f5b401f1f0442aba5eb75a40e4d4e0 928f90a3fef848aba62e9af91e2a4891 62f5b401f1f0442aba5eb75a40e4d4e0--928f90a3fef848aba62e9af91e2a4891 72a2bceeceba41dbb161a41ca96fe46a RX(b13) 928f90a3fef848aba62e9af91e2a4891--72a2bceeceba41dbb161a41ca96fe46a 72a2bceeceba41dbb161a41ca96fe46a--3609cc39156945bfa175c9d4cb11ad29 eddb157f59f14bc891cb8b9bcb3d4096 d0ed07e55e4c4e4987985c96deedbaa2 ae91aab8b32443fa89c6f38e87915f27--d0ed07e55e4c4e4987985c96deedbaa2 4b9f770d314c4162a06fcb0fd70d5f41 5 69cecee91ab04e62aefe2a8a5ad0679e d0ed07e55e4c4e4987985c96deedbaa2--69cecee91ab04e62aefe2a8a5ad0679e ecbb772acea44172a63ff806cb15d444 69cecee91ab04e62aefe2a8a5ad0679e--ecbb772acea44172a63ff806cb15d444 3600dc6db10643f1b671080a29a81da7 X ecbb772acea44172a63ff806cb15d444--3600dc6db10643f1b671080a29a81da7 3600dc6db10643f1b671080a29a81da7--deffb83f40224cc4800af39a2e07447b 182cdc08d7504e02aba1554e4a9f0fac 3600dc6db10643f1b671080a29a81da7--182cdc08d7504e02aba1554e4a9f0fac ca883cb7a01f4a9e8f141ac5ffc62064 182cdc08d7504e02aba1554e4a9f0fac--ca883cb7a01f4a9e8f141ac5ffc62064 8ac3bc9a589a4c1199826a2c689bfeeb ca883cb7a01f4a9e8f141ac5ffc62064--8ac3bc9a589a4c1199826a2c689bfeeb 6766a4f2c37c48a7bf14c50590062339 8ac3bc9a589a4c1199826a2c689bfeeb--6766a4f2c37c48a7bf14c50590062339 c18ffd8b7b6847a49051dbb9ad3ee0d0 6766a4f2c37c48a7bf14c50590062339--c18ffd8b7b6847a49051dbb9ad3ee0d0 3b9e8dc3e08443cd8709e05e8900d5a7 c18ffd8b7b6847a49051dbb9ad3ee0d0--3b9e8dc3e08443cd8709e05e8900d5a7 41081188a09d457aae12e69919ee999d 3b9e8dc3e08443cd8709e05e8900d5a7--41081188a09d457aae12e69919ee999d 532533264f874197bdb6282bae69b736 X 41081188a09d457aae12e69919ee999d--532533264f874197bdb6282bae69b736 532533264f874197bdb6282bae69b736--2c9b69c179204cf1af918147ab888d47 3c782ba272c04abcb3d8a5b77a9498f7 532533264f874197bdb6282bae69b736--3c782ba272c04abcb3d8a5b77a9498f7 ce006e59189747ebb6f28c076a812563 3c782ba272c04abcb3d8a5b77a9498f7--ce006e59189747ebb6f28c076a812563 bf2440f7285b4828970240f2a480ba47 ce006e59189747ebb6f28c076a812563--bf2440f7285b4828970240f2a480ba47 632865f9e6dc4fbea3265362eca8139a bf2440f7285b4828970240f2a480ba47--632865f9e6dc4fbea3265362eca8139a bb9f2d2f13f94f47a2cd10ca0ebf8c36 632865f9e6dc4fbea3265362eca8139a--bb9f2d2f13f94f47a2cd10ca0ebf8c36 01e329bba2ee4747b47d0e6196dd19df bb9f2d2f13f94f47a2cd10ca0ebf8c36--01e329bba2ee4747b47d0e6196dd19df 4d0bda0f06d14753bd64d6a2ab94930e 01e329bba2ee4747b47d0e6196dd19df--4d0bda0f06d14753bd64d6a2ab94930e d536b99ec64a4e6c93b7292db63eeb82 4d0bda0f06d14753bd64d6a2ab94930e--d536b99ec64a4e6c93b7292db63eeb82 ccbd6d1f849d42cbbf056e9d46804e9c d536b99ec64a4e6c93b7292db63eeb82--ccbd6d1f849d42cbbf056e9d46804e9c 4444e6546a2e4be99eb00a1f98cdcd6c ccbd6d1f849d42cbbf056e9d46804e9c--4444e6546a2e4be99eb00a1f98cdcd6c a88ce634b52e47b2ac32bd82c24dde56 4444e6546a2e4be99eb00a1f98cdcd6c--a88ce634b52e47b2ac32bd82c24dde56 8979d4cc468d4821bb5b3022c5a5e359 a88ce634b52e47b2ac32bd82c24dde56--8979d4cc468d4821bb5b3022c5a5e359 fbf789b442254cecaaabdad6993cb2de 8979d4cc468d4821bb5b3022c5a5e359--fbf789b442254cecaaabdad6993cb2de 85c07280a5e74636ab3724562d5eee70 fbf789b442254cecaaabdad6993cb2de--85c07280a5e74636ab3724562d5eee70 8bccf0a6611c4ab1950ab4ee5be474c6 X 85c07280a5e74636ab3724562d5eee70--8bccf0a6611c4ab1950ab4ee5be474c6 8bccf0a6611c4ab1950ab4ee5be474c6--aa89c392c57f4a0fa8e81d5747e0d0ca 1e311fe508d444edbbd958007698f364 RZ(-1.0*g0) 8bccf0a6611c4ab1950ab4ee5be474c6--1e311fe508d444edbbd958007698f364 9179cb88189c4d63adf7818970dc2753 X 1e311fe508d444edbbd958007698f364--9179cb88189c4d63adf7818970dc2753 9179cb88189c4d63adf7818970dc2753--568060669d8b468a85daec0e746c57c9 79c899653db942c085ee554894959fa9 9179cb88189c4d63adf7818970dc2753--79c899653db942c085ee554894959fa9 9da49c0e3e2045a3944c645e3e9acd58 79c899653db942c085ee554894959fa9--9da49c0e3e2045a3944c645e3e9acd58 21ec867611574e91bd78860c83136a26 9da49c0e3e2045a3944c645e3e9acd58--21ec867611574e91bd78860c83136a26 16d3acdae5874bc1a2ac4272ebefbe4e 21ec867611574e91bd78860c83136a26--16d3acdae5874bc1a2ac4272ebefbe4e a31c79175ee04f64b2d74ae1dacd7de0 16d3acdae5874bc1a2ac4272ebefbe4e--a31c79175ee04f64b2d74ae1dacd7de0 3451576afdce4ddfa728def2c8836807 a31c79175ee04f64b2d74ae1dacd7de0--3451576afdce4ddfa728def2c8836807 8a1383fd7732464cbe7d069bdea81da8 X 3451576afdce4ddfa728def2c8836807--8a1383fd7732464cbe7d069bdea81da8 8a1383fd7732464cbe7d069bdea81da8--c6cb39fca9ba4966a11b08f92b52a047 7c03bc2f5d4b4bb5a2390ebeca317262 8a1383fd7732464cbe7d069bdea81da8--7c03bc2f5d4b4bb5a2390ebeca317262 33f253814a6b4a27ac42da4cd58e6f87 7c03bc2f5d4b4bb5a2390ebeca317262--33f253814a6b4a27ac42da4cd58e6f87 853f60bba80643e6b328640252147983 33f253814a6b4a27ac42da4cd58e6f87--853f60bba80643e6b328640252147983 b8eb24558e01465fbd106213bc3fbe48 X 853f60bba80643e6b328640252147983--b8eb24558e01465fbd106213bc3fbe48 b8eb24558e01465fbd106213bc3fbe48--01ac1032cbf24968823ec23532a65032 2bec2d2698424ad68be71798e06234cc b8eb24558e01465fbd106213bc3fbe48--2bec2d2698424ad68be71798e06234cc 2464c8dbc72b4ed1b97ef26574f5d803 2bec2d2698424ad68be71798e06234cc--2464c8dbc72b4ed1b97ef26574f5d803 9f2b7595a2b44f87b169bea5ac1c7085 2464c8dbc72b4ed1b97ef26574f5d803--9f2b7595a2b44f87b169bea5ac1c7085 8d4d9da94c7c4915be22acd21ed18a22 9f2b7595a2b44f87b169bea5ac1c7085--8d4d9da94c7c4915be22acd21ed18a22 dfeaf22fe8264231979e36dafb2df1ac 8d4d9da94c7c4915be22acd21ed18a22--dfeaf22fe8264231979e36dafb2df1ac 8dce7f6ade334d70ad20943a22f5df32 dfeaf22fe8264231979e36dafb2df1ac--8dce7f6ade334d70ad20943a22f5df32 d48b4539d2e547deabd053d56ef7f856 X 8dce7f6ade334d70ad20943a22f5df32--d48b4539d2e547deabd053d56ef7f856 d48b4539d2e547deabd053d56ef7f856--c81f98f238fb442ba95cd8c39375dfa6 882f1cd869ed49a78e4f566083627d31 d48b4539d2e547deabd053d56ef7f856--882f1cd869ed49a78e4f566083627d31 93375b1122264c6390366d5fc8d182bd 882f1cd869ed49a78e4f566083627d31--93375b1122264c6390366d5fc8d182bd b0fac9c7f2e640ed9a3eff8ced6a6bdd 93375b1122264c6390366d5fc8d182bd--b0fac9c7f2e640ed9a3eff8ced6a6bdd 7fb39c25282b479cb721972d1c360c6a b0fac9c7f2e640ed9a3eff8ced6a6bdd--7fb39c25282b479cb721972d1c360c6a b2de9b56999a48a5b9b35194974bef93 7fb39c25282b479cb721972d1c360c6a--b2de9b56999a48a5b9b35194974bef93 a719f873cd8d433386f1bd4432c4c2c6 b2de9b56999a48a5b9b35194974bef93--a719f873cd8d433386f1bd4432c4c2c6 b1e2db3b27814d8a90e6cf687a1ea697 a719f873cd8d433386f1bd4432c4c2c6--b1e2db3b27814d8a90e6cf687a1ea697 5cf66097b5944c2b9d22b2c5c76b701f X b1e2db3b27814d8a90e6cf687a1ea697--5cf66097b5944c2b9d22b2c5c76b701f 5cf66097b5944c2b9d22b2c5c76b701f--878a5d95c1e24171899d8b4322d61ce5 24c12dbc7ffb4c7e97cb934b0274293e 5cf66097b5944c2b9d22b2c5c76b701f--24c12dbc7ffb4c7e97cb934b0274293e 1c9fa2aa4b104b9c83ae520908cba62b 24c12dbc7ffb4c7e97cb934b0274293e--1c9fa2aa4b104b9c83ae520908cba62b ac0497fc221047b0bf008b675809343d 1c9fa2aa4b104b9c83ae520908cba62b--ac0497fc221047b0bf008b675809343d 042fb0db3b7a4f01a43c20518fb96855 ac0497fc221047b0bf008b675809343d--042fb0db3b7a4f01a43c20518fb96855 277751a2447d4556b6ca9ac86d58dafc 042fb0db3b7a4f01a43c20518fb96855--277751a2447d4556b6ca9ac86d58dafc 6ba11898625f43399dd8bfbc4f9e2eb2 277751a2447d4556b6ca9ac86d58dafc--6ba11898625f43399dd8bfbc4f9e2eb2 9d91d49f519841e59b7c96ba2d268eaa 6ba11898625f43399dd8bfbc4f9e2eb2--9d91d49f519841e59b7c96ba2d268eaa 8dba9afd51a84754a39471dbeb4ae7e4 9d91d49f519841e59b7c96ba2d268eaa--8dba9afd51a84754a39471dbeb4ae7e4 ca6a8dcda4a74ff49f75248666ad15fe 8dba9afd51a84754a39471dbeb4ae7e4--ca6a8dcda4a74ff49f75248666ad15fe ca5283404555428ab3f385d0d43f51f5 ca6a8dcda4a74ff49f75248666ad15fe--ca5283404555428ab3f385d0d43f51f5 8743b796b7e7459381e706aeeed59677 ca5283404555428ab3f385d0d43f51f5--8743b796b7e7459381e706aeeed59677 117da6ff84584e708cf2c643db345af6 8743b796b7e7459381e706aeeed59677--117da6ff84584e708cf2c643db345af6 b3f2d2cd71364e509386b33f1b6d2ec9 117da6ff84584e708cf2c643db345af6--b3f2d2cd71364e509386b33f1b6d2ec9 d35923b0debe486691c1514bea2cddcf X b3f2d2cd71364e509386b33f1b6d2ec9--d35923b0debe486691c1514bea2cddcf d35923b0debe486691c1514bea2cddcf--ba927308ae4643a49bbf70973f5d410b 41207459a8144662b3b0ee3020807f72 RZ(-1.0*g0) d35923b0debe486691c1514bea2cddcf--41207459a8144662b3b0ee3020807f72 e4c0f0da5fa94127b314d41cc3d9cd00 X 41207459a8144662b3b0ee3020807f72--e4c0f0da5fa94127b314d41cc3d9cd00 e4c0f0da5fa94127b314d41cc3d9cd00--8743da010e264023bc4206af1c75a3bf 54f3f876ad0a4b48ae324c2d05a4cdb4 e4c0f0da5fa94127b314d41cc3d9cd00--54f3f876ad0a4b48ae324c2d05a4cdb4 70d13e149eac446b98a5b954b2ac35c5 54f3f876ad0a4b48ae324c2d05a4cdb4--70d13e149eac446b98a5b954b2ac35c5 d1696538ac4b4f73ac616159ccb639d4 70d13e149eac446b98a5b954b2ac35c5--d1696538ac4b4f73ac616159ccb639d4 20a7e3235dd44e748f518ba69de9cfe6 d1696538ac4b4f73ac616159ccb639d4--20a7e3235dd44e748f518ba69de9cfe6 70be9447b88e428a8a965ea0344e0630 X 20a7e3235dd44e748f518ba69de9cfe6--70be9447b88e428a8a965ea0344e0630 70be9447b88e428a8a965ea0344e0630--256b727809a944ceafffdf17bc21b1a6 a984de19c76f4c07892656c69740f694 70be9447b88e428a8a965ea0344e0630--a984de19c76f4c07892656c69740f694 f280b43ea4a14201bb6f422a7e27ef53 a984de19c76f4c07892656c69740f694--f280b43ea4a14201bb6f422a7e27ef53 7776f1c0ae6c4f14a1ff4b579015abf5 f280b43ea4a14201bb6f422a7e27ef53--7776f1c0ae6c4f14a1ff4b579015abf5 2e519829c85445019626b5949ffd5c2b X 7776f1c0ae6c4f14a1ff4b579015abf5--2e519829c85445019626b5949ffd5c2b 2e519829c85445019626b5949ffd5c2b--8bc6017a4d164e738c7e9ba09ca27491 0c0b32f9edc0465e89d2b5063a5dada3 2e519829c85445019626b5949ffd5c2b--0c0b32f9edc0465e89d2b5063a5dada3 ee9586f1df104bf0b696034aacd15b6a 0c0b32f9edc0465e89d2b5063a5dada3--ee9586f1df104bf0b696034aacd15b6a 9917c672be26454b965d7529cdbc0ef3 ee9586f1df104bf0b696034aacd15b6a--9917c672be26454b965d7529cdbc0ef3 6ed882b94171425289ca3e579b100b1c 9917c672be26454b965d7529cdbc0ef3--6ed882b94171425289ca3e579b100b1c 8c4ecaa6d48b47bea675fde189d09e72 X 6ed882b94171425289ca3e579b100b1c--8c4ecaa6d48b47bea675fde189d09e72 8c4ecaa6d48b47bea675fde189d09e72--3672d3133df04bebb3eec5343668b271 ca838981902b4fc093b621f49443225f 8c4ecaa6d48b47bea675fde189d09e72--ca838981902b4fc093b621f49443225f fcc8ce273ec444b49f88c1571cd8b95d ca838981902b4fc093b621f49443225f--fcc8ce273ec444b49f88c1571cd8b95d 268baa8c24a441e58d86cee84e841ac2 fcc8ce273ec444b49f88c1571cd8b95d--268baa8c24a441e58d86cee84e841ac2 4a398250a4e74b87a0f1f546c93a137a 268baa8c24a441e58d86cee84e841ac2--4a398250a4e74b87a0f1f546c93a137a f361961bb8ee4893a9a3e93bde04b8e6 4a398250a4e74b87a0f1f546c93a137a--f361961bb8ee4893a9a3e93bde04b8e6 7007f6d1b3a143f3bf0d81b2e730a48a X f361961bb8ee4893a9a3e93bde04b8e6--7007f6d1b3a143f3bf0d81b2e730a48a 7007f6d1b3a143f3bf0d81b2e730a48a--02bcefadf2a3496eb638ec650b8a842d e870d8de4b1d418181165273487467a9 7007f6d1b3a143f3bf0d81b2e730a48a--e870d8de4b1d418181165273487467a9 0a33ba7caccb49248a306d85937f38b4 e870d8de4b1d418181165273487467a9--0a33ba7caccb49248a306d85937f38b4 a6b685d6fb4a4562b5fb3f497a3c0bc3 0a33ba7caccb49248a306d85937f38b4--a6b685d6fb4a4562b5fb3f497a3c0bc3 84ac65edd7ef4a779afc150b64d0300e a6b685d6fb4a4562b5fb3f497a3c0bc3--84ac65edd7ef4a779afc150b64d0300e b7ea46b130134d3aa5995c84f33335fb X 84ac65edd7ef4a779afc150b64d0300e--b7ea46b130134d3aa5995c84f33335fb b7ea46b130134d3aa5995c84f33335fb--44ae52e362c248d88b238153098e0f77 c416a08f16c241a2a4f8486d4a76b8c0 b7ea46b130134d3aa5995c84f33335fb--c416a08f16c241a2a4f8486d4a76b8c0 21d12cac84e14694a849291269210ab1 c416a08f16c241a2a4f8486d4a76b8c0--21d12cac84e14694a849291269210ab1 4e12194db72f49139b30600da3882b94 21d12cac84e14694a849291269210ab1--4e12194db72f49139b30600da3882b94 be314b180c5e46a68c012581f5b38b5a 4e12194db72f49139b30600da3882b94--be314b180c5e46a68c012581f5b38b5a a90ae823f5e24136bcee2c343fcce45a be314b180c5e46a68c012581f5b38b5a--a90ae823f5e24136bcee2c343fcce45a 51c255c534404e98950a9b7f4f4ecc1b a90ae823f5e24136bcee2c343fcce45a--51c255c534404e98950a9b7f4f4ecc1b 5b160e110a004e919835e65091ef6073 51c255c534404e98950a9b7f4f4ecc1b--5b160e110a004e919835e65091ef6073 32c08489950d4815bce9d18b25897c2a X 5b160e110a004e919835e65091ef6073--32c08489950d4815bce9d18b25897c2a 32c08489950d4815bce9d18b25897c2a--e82006a725414b8c892a2e99171e6458 ff4d5e8181fe43d596545b1d6c6c3765 32c08489950d4815bce9d18b25897c2a--ff4d5e8181fe43d596545b1d6c6c3765 ed35a4683cef4dd2ab55b056fa8a01b5 ff4d5e8181fe43d596545b1d6c6c3765--ed35a4683cef4dd2ab55b056fa8a01b5 cad4e5fdc3354565bda83042cdde9344 ed35a4683cef4dd2ab55b056fa8a01b5--cad4e5fdc3354565bda83042cdde9344 b0b5875cb2874264b3040c8c3a7d5bba cad4e5fdc3354565bda83042cdde9344--b0b5875cb2874264b3040c8c3a7d5bba 6b93325430f54e2880df3b88298be1ea b0b5875cb2874264b3040c8c3a7d5bba--6b93325430f54e2880df3b88298be1ea 4f4220361162417cbbf53fab0da4aa4c 6b93325430f54e2880df3b88298be1ea--4f4220361162417cbbf53fab0da4aa4c 052d4671ac2649f0bb1296e69b9ea418 X 4f4220361162417cbbf53fab0da4aa4c--052d4671ac2649f0bb1296e69b9ea418 052d4671ac2649f0bb1296e69b9ea418--d080c751ad984088988ce9dcdae3b33b 961c096242524824b30245a694af1d72 052d4671ac2649f0bb1296e69b9ea418--961c096242524824b30245a694af1d72 1520cf48d09b4fd1a887b43cd700ddc4 961c096242524824b30245a694af1d72--1520cf48d09b4fd1a887b43cd700ddc4 5d27cf1bd2c14c37b96d155764fa585c 1520cf48d09b4fd1a887b43cd700ddc4--5d27cf1bd2c14c37b96d155764fa585c 7cd5fb65758a405981fb51065012ec4b X 5d27cf1bd2c14c37b96d155764fa585c--7cd5fb65758a405981fb51065012ec4b 7cd5fb65758a405981fb51065012ec4b--5b57485b310744a38678d679d8d27bd7 d0431f7c822546c1a9c288b2bd5c6d4e 7cd5fb65758a405981fb51065012ec4b--d0431f7c822546c1a9c288b2bd5c6d4e 0bb5e2c73b524ec7abd79ef7e1d685bd d0431f7c822546c1a9c288b2bd5c6d4e--0bb5e2c73b524ec7abd79ef7e1d685bd 68a10494c8b948948016335b058b86d1 X 0bb5e2c73b524ec7abd79ef7e1d685bd--68a10494c8b948948016335b058b86d1 68a10494c8b948948016335b058b86d1--621a10c1c154482da26f3d8a1ae0d712 f4800c3eebba4dccbf0205c3631f7b66 68a10494c8b948948016335b058b86d1--f4800c3eebba4dccbf0205c3631f7b66 6d0c5f60a0c042318559f0fdf957c4f4 f4800c3eebba4dccbf0205c3631f7b66--6d0c5f60a0c042318559f0fdf957c4f4 4103cd86de96472d8fe059552248fb90 6d0c5f60a0c042318559f0fdf957c4f4--4103cd86de96472d8fe059552248fb90 baf1edf5873d4abc98430466a5873308 4103cd86de96472d8fe059552248fb90--baf1edf5873d4abc98430466a5873308 8d5dd662500f43ac831f6dd3101c75b8 baf1edf5873d4abc98430466a5873308--8d5dd662500f43ac831f6dd3101c75b8 1c77b4b12ba542ae83ad30c759391c65 X 8d5dd662500f43ac831f6dd3101c75b8--1c77b4b12ba542ae83ad30c759391c65 1c77b4b12ba542ae83ad30c759391c65--25f1a0b40df941bf8872d2baca99cf5b b5ffaf8ee4944371b0082850a8580109 1c77b4b12ba542ae83ad30c759391c65--b5ffaf8ee4944371b0082850a8580109 f6866cfebb594a6ebbbe52734bd90144 X b5ffaf8ee4944371b0082850a8580109--f6866cfebb594a6ebbbe52734bd90144 f6866cfebb594a6ebbbe52734bd90144--dcaeb552d83a44e6b1190bf4a6701202 a57558c6bea64a298d5499b3ae6011a1 RZ(-1.0*g0) f6866cfebb594a6ebbbe52734bd90144--a57558c6bea64a298d5499b3ae6011a1 4832886d7a0f4cf38cc593f939c43e20 X a57558c6bea64a298d5499b3ae6011a1--4832886d7a0f4cf38cc593f939c43e20 4832886d7a0f4cf38cc593f939c43e20--1b227db5de2e40fe9716ea3c0be95576 b148334fcffd451f80f63ad7381a16a3 4832886d7a0f4cf38cc593f939c43e20--b148334fcffd451f80f63ad7381a16a3 07409cb78b6344788c9ef68c2361c186 b148334fcffd451f80f63ad7381a16a3--07409cb78b6344788c9ef68c2361c186 342507f478c6402c97b9daddc9a67432 07409cb78b6344788c9ef68c2361c186--342507f478c6402c97b9daddc9a67432 fb16b4b6cf2f4e8595c83ec00bed6904 342507f478c6402c97b9daddc9a67432--fb16b4b6cf2f4e8595c83ec00bed6904 cfe791bda44447a9b4e58861ff21936b fb16b4b6cf2f4e8595c83ec00bed6904--cfe791bda44447a9b4e58861ff21936b 24c2ba1190544a539aee1a2e718a6a58 cfe791bda44447a9b4e58861ff21936b--24c2ba1190544a539aee1a2e718a6a58 44eb0a71757f4fbaa8daaa4591b9e168 24c2ba1190544a539aee1a2e718a6a58--44eb0a71757f4fbaa8daaa4591b9e168 2108051fa0fd47b9823ae1797e836048 44eb0a71757f4fbaa8daaa4591b9e168--2108051fa0fd47b9823ae1797e836048 94b496893f124d039f2fdaeb6ce05e91 2108051fa0fd47b9823ae1797e836048--94b496893f124d039f2fdaeb6ce05e91 3c0d66b482694155999f1663eb431d7f 94b496893f124d039f2fdaeb6ce05e91--3c0d66b482694155999f1663eb431d7f 778eb058eba14222bf5c37c6990c0722 3c0d66b482694155999f1663eb431d7f--778eb058eba14222bf5c37c6990c0722 592018801abc49a6801c729cfd3ff848 778eb058eba14222bf5c37c6990c0722--592018801abc49a6801c729cfd3ff848 ff8421b7f6f042e0b09b30d91ef39900 592018801abc49a6801c729cfd3ff848--ff8421b7f6f042e0b09b30d91ef39900 720738c642cf49ed8f6b343804bcdb00 ff8421b7f6f042e0b09b30d91ef39900--720738c642cf49ed8f6b343804bcdb00 498a34a8b5db4f89a67e213342c04cc2 720738c642cf49ed8f6b343804bcdb00--498a34a8b5db4f89a67e213342c04cc2 e5ac6a3173d842ef894b86cf4bbd227a 498a34a8b5db4f89a67e213342c04cc2--e5ac6a3173d842ef894b86cf4bbd227a fd4e87c83174496d8ae3326c815dff5f e5ac6a3173d842ef894b86cf4bbd227a--fd4e87c83174496d8ae3326c815dff5f 2163659bd3a945a0bbe4d7e1a8457232 fd4e87c83174496d8ae3326c815dff5f--2163659bd3a945a0bbe4d7e1a8457232 9b8d804f11fa4219b3746b60daa3cb8a 2163659bd3a945a0bbe4d7e1a8457232--9b8d804f11fa4219b3746b60daa3cb8a 441ff6cebef94fbba2fbd68ef44d5504 9b8d804f11fa4219b3746b60daa3cb8a--441ff6cebef94fbba2fbd68ef44d5504 01d3f46175da4fcab717f89d59c3662e 441ff6cebef94fbba2fbd68ef44d5504--01d3f46175da4fcab717f89d59c3662e c43105e4a4b1436c9033ff006e91b5d1 01d3f46175da4fcab717f89d59c3662e--c43105e4a4b1436c9033ff006e91b5d1 7ee14b5ff7d34551b1f0c0ab1edafa48 c43105e4a4b1436c9033ff006e91b5d1--7ee14b5ff7d34551b1f0c0ab1edafa48 cd47423474ed4c458e712208bf324d03 RX(b04) 7ee14b5ff7d34551b1f0c0ab1edafa48--cd47423474ed4c458e712208bf324d03 171ed56ea7bd4248830deb69957efa98 cd47423474ed4c458e712208bf324d03--171ed56ea7bd4248830deb69957efa98 f6df41deeea14f84adc702a00ec21b79 171ed56ea7bd4248830deb69957efa98--f6df41deeea14f84adc702a00ec21b79 5579a12a6e96493f9cf00aa890c744d3 f6df41deeea14f84adc702a00ec21b79--5579a12a6e96493f9cf00aa890c744d3 ac5e7e7df7ed4fe1a1ddb4bfa6299edf X 5579a12a6e96493f9cf00aa890c744d3--ac5e7e7df7ed4fe1a1ddb4bfa6299edf ac5e7e7df7ed4fe1a1ddb4bfa6299edf--139167e1ace44c4e98f12718224c16cd e62c3d6e64dc44f4bc822fccc37b35e1 ac5e7e7df7ed4fe1a1ddb4bfa6299edf--e62c3d6e64dc44f4bc822fccc37b35e1 d0ff4df0a8c044f5887e2b7e1bc8711d e62c3d6e64dc44f4bc822fccc37b35e1--d0ff4df0a8c044f5887e2b7e1bc8711d 7f1f4281e446405c93d9d6cf73a8b1e1 d0ff4df0a8c044f5887e2b7e1bc8711d--7f1f4281e446405c93d9d6cf73a8b1e1 b88f2f86f0cb4a98ae7461fbe224f2b4 7f1f4281e446405c93d9d6cf73a8b1e1--b88f2f86f0cb4a98ae7461fbe224f2b4 0a96f723658345a2b13ec77664eb18e5 b88f2f86f0cb4a98ae7461fbe224f2b4--0a96f723658345a2b13ec77664eb18e5 00d1d3bcc850491ebbcf63b40644fd5e 0a96f723658345a2b13ec77664eb18e5--00d1d3bcc850491ebbcf63b40644fd5e 7876f253476d4399a83a66a4e49cb139 00d1d3bcc850491ebbcf63b40644fd5e--7876f253476d4399a83a66a4e49cb139 2195375fea634bdf9a8a8cda4675ebc5 X 7876f253476d4399a83a66a4e49cb139--2195375fea634bdf9a8a8cda4675ebc5 2195375fea634bdf9a8a8cda4675ebc5--13adba3f88674503b2f692a49f201ba5 5df9ec156ab84fd1bd6f25694f7fa43f 2195375fea634bdf9a8a8cda4675ebc5--5df9ec156ab84fd1bd6f25694f7fa43f 3caae7d170af49b7ad0e612a15004b37 5df9ec156ab84fd1bd6f25694f7fa43f--3caae7d170af49b7ad0e612a15004b37 12d174b4e652478fb378a19902b46d0e 3caae7d170af49b7ad0e612a15004b37--12d174b4e652478fb378a19902b46d0e 50672fe658034499b1cf76c62df74527 12d174b4e652478fb378a19902b46d0e--50672fe658034499b1cf76c62df74527 1ed8d90de2b14d22bd57bbfcb5e271d4 50672fe658034499b1cf76c62df74527--1ed8d90de2b14d22bd57bbfcb5e271d4 c98941d9d3844d5b9a624c336cad4a52 1ed8d90de2b14d22bd57bbfcb5e271d4--c98941d9d3844d5b9a624c336cad4a52 0541b002f4de4fb7abb0db17c6ac2cab c98941d9d3844d5b9a624c336cad4a52--0541b002f4de4fb7abb0db17c6ac2cab f1bdbf68f28b4ff0a6adc20897869116 0541b002f4de4fb7abb0db17c6ac2cab--f1bdbf68f28b4ff0a6adc20897869116 680c2ede04484f1789d4b90b414d5ad7 f1bdbf68f28b4ff0a6adc20897869116--680c2ede04484f1789d4b90b414d5ad7 bc62f97404bb43c78e0ec0a82244708f 680c2ede04484f1789d4b90b414d5ad7--bc62f97404bb43c78e0ec0a82244708f fe3dfdba3a024e1691533ef1c5734f8b bc62f97404bb43c78e0ec0a82244708f--fe3dfdba3a024e1691533ef1c5734f8b 7282393e96e349dfa88fe92218bb2854 fe3dfdba3a024e1691533ef1c5734f8b--7282393e96e349dfa88fe92218bb2854 9b1d10306fa84e85b6d71d07d33de183 7282393e96e349dfa88fe92218bb2854--9b1d10306fa84e85b6d71d07d33de183 a898a58787e6475098948ea8f560818e 9b1d10306fa84e85b6d71d07d33de183--a898a58787e6475098948ea8f560818e f9e5222e89a64c71a97507ff7e10b9e9 X a898a58787e6475098948ea8f560818e--f9e5222e89a64c71a97507ff7e10b9e9 f9e5222e89a64c71a97507ff7e10b9e9--6ea36ff4a0354f86924084b4a6328950 096ca53ee40e4e0faa749b86a0787a94 RZ(-1.0*g1) f9e5222e89a64c71a97507ff7e10b9e9--096ca53ee40e4e0faa749b86a0787a94 ccf00b36c5b54b3880afa7e5e67186d1 X 096ca53ee40e4e0faa749b86a0787a94--ccf00b36c5b54b3880afa7e5e67186d1 ccf00b36c5b54b3880afa7e5e67186d1--eb6f23c6956d49318368f83938a35a5c 1dc0c376f2dc4581a409fc78535f521f ccf00b36c5b54b3880afa7e5e67186d1--1dc0c376f2dc4581a409fc78535f521f 39e4e9f60f574d0cbbdb208b79adec27 1dc0c376f2dc4581a409fc78535f521f--39e4e9f60f574d0cbbdb208b79adec27 b0bb147d8ba544f8b2e0fbb452a821f8 39e4e9f60f574d0cbbdb208b79adec27--b0bb147d8ba544f8b2e0fbb452a821f8 3d9b5aaa7e7948b6a23b12d5240a21ab b0bb147d8ba544f8b2e0fbb452a821f8--3d9b5aaa7e7948b6a23b12d5240a21ab 9c7c4e8c7602411ba551a1f930a71608 3d9b5aaa7e7948b6a23b12d5240a21ab--9c7c4e8c7602411ba551a1f930a71608 8b99af8911d1460e81251abfc74c17c0 9c7c4e8c7602411ba551a1f930a71608--8b99af8911d1460e81251abfc74c17c0 11fc10bcf32e4e32be489d496da1f447 X 8b99af8911d1460e81251abfc74c17c0--11fc10bcf32e4e32be489d496da1f447 11fc10bcf32e4e32be489d496da1f447--a0efb19e64c04e43b308741fa8f65460 ab40d81a32bc46a9b7c110158f9bd866 11fc10bcf32e4e32be489d496da1f447--ab40d81a32bc46a9b7c110158f9bd866 804fe73e9df84f9c9ec7840b965031ac ab40d81a32bc46a9b7c110158f9bd866--804fe73e9df84f9c9ec7840b965031ac 6680bde7a17d4de49db476a7aae12a23 804fe73e9df84f9c9ec7840b965031ac--6680bde7a17d4de49db476a7aae12a23 c11dd44f3f8e4b9d92510e013ff4c463 X 6680bde7a17d4de49db476a7aae12a23--c11dd44f3f8e4b9d92510e013ff4c463 c11dd44f3f8e4b9d92510e013ff4c463--99287bc69abb413b923c30ede1f47ca9 75c58bac9878410a9001edf77f353131 c11dd44f3f8e4b9d92510e013ff4c463--75c58bac9878410a9001edf77f353131 feb8cafe31bd4dd998de1cb45959d9ea 75c58bac9878410a9001edf77f353131--feb8cafe31bd4dd998de1cb45959d9ea 9e1adecd51454922a61c9ae151e27e8a feb8cafe31bd4dd998de1cb45959d9ea--9e1adecd51454922a61c9ae151e27e8a a914202539624d0294ef97938212a6d8 9e1adecd51454922a61c9ae151e27e8a--a914202539624d0294ef97938212a6d8 7a159f8e49f844f797ed42cde6efed1d a914202539624d0294ef97938212a6d8--7a159f8e49f844f797ed42cde6efed1d 618f966eeb094e6b9234cb747d2d7387 7a159f8e49f844f797ed42cde6efed1d--618f966eeb094e6b9234cb747d2d7387 751a1c17a380458f9f4352726259648e X 618f966eeb094e6b9234cb747d2d7387--751a1c17a380458f9f4352726259648e 751a1c17a380458f9f4352726259648e--79ad687b2c874bad9b471abe9ebcf842 da2f0bdb4a414c1d805974e70c26fb6a 751a1c17a380458f9f4352726259648e--da2f0bdb4a414c1d805974e70c26fb6a e3fe1369988b40e784bbcf3e05d1b379 da2f0bdb4a414c1d805974e70c26fb6a--e3fe1369988b40e784bbcf3e05d1b379 4c0e96b5e7a645fbb8b81ec348f5f3fa e3fe1369988b40e784bbcf3e05d1b379--4c0e96b5e7a645fbb8b81ec348f5f3fa f062fa8b59c7410ba6a4079c806ed6e2 4c0e96b5e7a645fbb8b81ec348f5f3fa--f062fa8b59c7410ba6a4079c806ed6e2 6d4a277e05504231850e7b53e58ba69d f062fa8b59c7410ba6a4079c806ed6e2--6d4a277e05504231850e7b53e58ba69d 3c45e49271fe46d7bbc97494e64b64d6 6d4a277e05504231850e7b53e58ba69d--3c45e49271fe46d7bbc97494e64b64d6 f378701e76e44cc5a7612cbe521f8008 3c45e49271fe46d7bbc97494e64b64d6--f378701e76e44cc5a7612cbe521f8008 081573f6cc474126b8412bb11e76c6c2 X f378701e76e44cc5a7612cbe521f8008--081573f6cc474126b8412bb11e76c6c2 081573f6cc474126b8412bb11e76c6c2--56fa2b2ec7f6438c8d3aa3a03a5afbad cd5d60981d5441529106dfb319a7b51c 081573f6cc474126b8412bb11e76c6c2--cd5d60981d5441529106dfb319a7b51c 563a474d18f84e6fb8cbe76f70d2cf6a cd5d60981d5441529106dfb319a7b51c--563a474d18f84e6fb8cbe76f70d2cf6a a5780e78786d46ca8d4122593dea262d 563a474d18f84e6fb8cbe76f70d2cf6a--a5780e78786d46ca8d4122593dea262d 3dc8141a1d6542d2a05a6c597aa9f65f a5780e78786d46ca8d4122593dea262d--3dc8141a1d6542d2a05a6c597aa9f65f 67e8bb5233714369a55673f03f889dd8 3dc8141a1d6542d2a05a6c597aa9f65f--67e8bb5233714369a55673f03f889dd8 aa75ca8c93ad459bb202154ce00d8f23 67e8bb5233714369a55673f03f889dd8--aa75ca8c93ad459bb202154ce00d8f23 5d362796f1574d4593e7425c398bc79c aa75ca8c93ad459bb202154ce00d8f23--5d362796f1574d4593e7425c398bc79c 89f6222f926846e892c412c105175f29 5d362796f1574d4593e7425c398bc79c--89f6222f926846e892c412c105175f29 535103823733406cb6e8c4e4b30fb403 89f6222f926846e892c412c105175f29--535103823733406cb6e8c4e4b30fb403 99e2abab24c548e9b82f0b21f6363c08 535103823733406cb6e8c4e4b30fb403--99e2abab24c548e9b82f0b21f6363c08 b2f2f4b6daa744b0acde30686f8a8a76 99e2abab24c548e9b82f0b21f6363c08--b2f2f4b6daa744b0acde30686f8a8a76 5c94685b038f4ed1aab90849b0cacb88 b2f2f4b6daa744b0acde30686f8a8a76--5c94685b038f4ed1aab90849b0cacb88 310c6edc08e64390a2fb8ea960f3c74c 5c94685b038f4ed1aab90849b0cacb88--310c6edc08e64390a2fb8ea960f3c74c af4f0aedb21f46979a7c528b09bdad84 X 310c6edc08e64390a2fb8ea960f3c74c--af4f0aedb21f46979a7c528b09bdad84 af4f0aedb21f46979a7c528b09bdad84--6e2c1cfdfdd84075bd88c55a036c4ecb 1f9a3d9cfd2b4f7cbfb1182ee79dd6af RZ(-1.0*g1) af4f0aedb21f46979a7c528b09bdad84--1f9a3d9cfd2b4f7cbfb1182ee79dd6af 3b7918bfc42f4ebdab5976fd694805d3 X 1f9a3d9cfd2b4f7cbfb1182ee79dd6af--3b7918bfc42f4ebdab5976fd694805d3 3b7918bfc42f4ebdab5976fd694805d3--378f2d6fad9a4f8597b339e699a1070a b3e2a8e2875c46f2a6a0b2cd15db61c7 3b7918bfc42f4ebdab5976fd694805d3--b3e2a8e2875c46f2a6a0b2cd15db61c7 56613a8a09154fea94cfbc0e28998657 b3e2a8e2875c46f2a6a0b2cd15db61c7--56613a8a09154fea94cfbc0e28998657 2e7ab520a1f2491a9be9387e50c46197 56613a8a09154fea94cfbc0e28998657--2e7ab520a1f2491a9be9387e50c46197 d719e50222ac40a382c6b6fd3b38d027 2e7ab520a1f2491a9be9387e50c46197--d719e50222ac40a382c6b6fd3b38d027 f47e8bf172194c3d98507058da1bcb35 X d719e50222ac40a382c6b6fd3b38d027--f47e8bf172194c3d98507058da1bcb35 f47e8bf172194c3d98507058da1bcb35--c4d5a0fbea8b4b728e12df6349030e9b 5d4e2441616d4f559cbf4c8ee863664e f47e8bf172194c3d98507058da1bcb35--5d4e2441616d4f559cbf4c8ee863664e 4b0cb62c17084d80b48ed535b083a88e 5d4e2441616d4f559cbf4c8ee863664e--4b0cb62c17084d80b48ed535b083a88e 79e984bec1d84c9893f67010a889161a 4b0cb62c17084d80b48ed535b083a88e--79e984bec1d84c9893f67010a889161a b43e6e49e72947ba8f7e4f41826baea9 X 79e984bec1d84c9893f67010a889161a--b43e6e49e72947ba8f7e4f41826baea9 b43e6e49e72947ba8f7e4f41826baea9--3c67ed08489842c9b9a36a74cfa400a2 e71b0b8892144548a91957f32569d90d b43e6e49e72947ba8f7e4f41826baea9--e71b0b8892144548a91957f32569d90d 7f6e244466b64cee8efaaba779599acd e71b0b8892144548a91957f32569d90d--7f6e244466b64cee8efaaba779599acd 8af31957b8b44ab09d508ffd7d1558d5 7f6e244466b64cee8efaaba779599acd--8af31957b8b44ab09d508ffd7d1558d5 383b890c9aa7438ab655deb6e66ad806 8af31957b8b44ab09d508ffd7d1558d5--383b890c9aa7438ab655deb6e66ad806 e0b205e7f58c44e2bb74f50af6fa435d X 383b890c9aa7438ab655deb6e66ad806--e0b205e7f58c44e2bb74f50af6fa435d e0b205e7f58c44e2bb74f50af6fa435d--92cbaa9536194a829d4b7f8b31de77c6 0ac54277411c421c81e6d1a8f7b4921e e0b205e7f58c44e2bb74f50af6fa435d--0ac54277411c421c81e6d1a8f7b4921e 9d9c82cd901044b59401a37f3993b79e 0ac54277411c421c81e6d1a8f7b4921e--9d9c82cd901044b59401a37f3993b79e 134b7bb5bca94f3e8ef1574badb9a0c6 9d9c82cd901044b59401a37f3993b79e--134b7bb5bca94f3e8ef1574badb9a0c6 da3beec29eda42f08161d980aa18ba5b 134b7bb5bca94f3e8ef1574badb9a0c6--da3beec29eda42f08161d980aa18ba5b 753195bc04e843429da21b642bf4f991 da3beec29eda42f08161d980aa18ba5b--753195bc04e843429da21b642bf4f991 ae0e6140c41a48ef93afc6c65e6371b6 X 753195bc04e843429da21b642bf4f991--ae0e6140c41a48ef93afc6c65e6371b6 ae0e6140c41a48ef93afc6c65e6371b6--27ab804b7c734a58a90ffd8ebcabf5dd 3e212481fcdc4e7abe74ea75db0f598b ae0e6140c41a48ef93afc6c65e6371b6--3e212481fcdc4e7abe74ea75db0f598b 14944fe456d840fdb41e3fe579e749de 3e212481fcdc4e7abe74ea75db0f598b--14944fe456d840fdb41e3fe579e749de 6a20c7a1bf6643868d90af4706d598c9 14944fe456d840fdb41e3fe579e749de--6a20c7a1bf6643868d90af4706d598c9 6f7f375fe9704c61b26e071c2d744b2a 6a20c7a1bf6643868d90af4706d598c9--6f7f375fe9704c61b26e071c2d744b2a 854024759123404d84051b789f841878 X 6f7f375fe9704c61b26e071c2d744b2a--854024759123404d84051b789f841878 854024759123404d84051b789f841878--848ee760b0164cfbaa5fb0081cd03c81 789efa4c09d54882be56a98d8d5dc585 854024759123404d84051b789f841878--789efa4c09d54882be56a98d8d5dc585 538434c201f5417bb70d1b1204c19331 789efa4c09d54882be56a98d8d5dc585--538434c201f5417bb70d1b1204c19331 8d6ebb4765f8455d8fc95f3610ce6173 538434c201f5417bb70d1b1204c19331--8d6ebb4765f8455d8fc95f3610ce6173 6aa3cfd190d14a409e94def88adad266 8d6ebb4765f8455d8fc95f3610ce6173--6aa3cfd190d14a409e94def88adad266 f06bc7b808844dfab2196ee4d8c43f6f 6aa3cfd190d14a409e94def88adad266--f06bc7b808844dfab2196ee4d8c43f6f b50f579d99694ce18865f078968c2ca3 f06bc7b808844dfab2196ee4d8c43f6f--b50f579d99694ce18865f078968c2ca3 aab75082ffc44a0194d95c0a9946376c b50f579d99694ce18865f078968c2ca3--aab75082ffc44a0194d95c0a9946376c d7a2ace1589f43f4be5956bdec3476dd X aab75082ffc44a0194d95c0a9946376c--d7a2ace1589f43f4be5956bdec3476dd d7a2ace1589f43f4be5956bdec3476dd--00815708543c4663878c11d8dd84fdd7 b26af32f520f41bcb8c4b0bbd2f76e19 d7a2ace1589f43f4be5956bdec3476dd--b26af32f520f41bcb8c4b0bbd2f76e19 bae36550d51e4c43898e2b1cca3b6369 b26af32f520f41bcb8c4b0bbd2f76e19--bae36550d51e4c43898e2b1cca3b6369 5372046af6b34da9a87fdebf72cbdadf bae36550d51e4c43898e2b1cca3b6369--5372046af6b34da9a87fdebf72cbdadf 0bc6604e76e849f5a711fc60276013b3 5372046af6b34da9a87fdebf72cbdadf--0bc6604e76e849f5a711fc60276013b3 6b3aff435e2547d198c2ca9fb540078d 0bc6604e76e849f5a711fc60276013b3--6b3aff435e2547d198c2ca9fb540078d 81db2868d45f45f68834fe397fed1ecf 6b3aff435e2547d198c2ca9fb540078d--81db2868d45f45f68834fe397fed1ecf 84300223759446cea85e4f4461dc83ce X 81db2868d45f45f68834fe397fed1ecf--84300223759446cea85e4f4461dc83ce 84300223759446cea85e4f4461dc83ce--e2ff9654c1444d77852680205a4e3066 429fc0ec03dd41148c4811c00c1859bb 84300223759446cea85e4f4461dc83ce--429fc0ec03dd41148c4811c00c1859bb 8a5d4fcedcc1421287e9d5e8442d84f5 429fc0ec03dd41148c4811c00c1859bb--8a5d4fcedcc1421287e9d5e8442d84f5 d3073f355dc1434e8fdcb775088a25dc 8a5d4fcedcc1421287e9d5e8442d84f5--d3073f355dc1434e8fdcb775088a25dc fefa7d0964114f9ebc7c631d7f41f815 X d3073f355dc1434e8fdcb775088a25dc--fefa7d0964114f9ebc7c631d7f41f815 fefa7d0964114f9ebc7c631d7f41f815--4cb1abb591d9433f8faf166a338f952d 7d7c34f367374e87a5708c0121199bf7 fefa7d0964114f9ebc7c631d7f41f815--7d7c34f367374e87a5708c0121199bf7 393450656d1848e59d1b08131efa43e2 7d7c34f367374e87a5708c0121199bf7--393450656d1848e59d1b08131efa43e2 86a61bf823b44ea18132a1a6fcd5cba0 X 393450656d1848e59d1b08131efa43e2--86a61bf823b44ea18132a1a6fcd5cba0 86a61bf823b44ea18132a1a6fcd5cba0--30354739ac9a4ce2a0c1260dd1a64320 e951d8984eaf4604948b383df009682b 86a61bf823b44ea18132a1a6fcd5cba0--e951d8984eaf4604948b383df009682b 2477025ecc414858b785117994f95b29 e951d8984eaf4604948b383df009682b--2477025ecc414858b785117994f95b29 482f1dcc8ce64a17890a7ead26828b42 2477025ecc414858b785117994f95b29--482f1dcc8ce64a17890a7ead26828b42 c035d357e8934354a7bf60697173bb65 482f1dcc8ce64a17890a7ead26828b42--c035d357e8934354a7bf60697173bb65 df1f2801b5c1476482a5b8b9f016e4f2 c035d357e8934354a7bf60697173bb65--df1f2801b5c1476482a5b8b9f016e4f2 29e269d2285d46ed81d84103b226f514 X df1f2801b5c1476482a5b8b9f016e4f2--29e269d2285d46ed81d84103b226f514 29e269d2285d46ed81d84103b226f514--3c6942bfd7184bf8bc262788ddf7ceaa d3254657226f47b48271acd1f2637380 29e269d2285d46ed81d84103b226f514--d3254657226f47b48271acd1f2637380 a1eda506666740029e4eeeb913593aac X d3254657226f47b48271acd1f2637380--a1eda506666740029e4eeeb913593aac a1eda506666740029e4eeeb913593aac--c73714485fd04f9ab082e5373cb6cc26 c4fdcf7e436c47a4a49e0175c91fe536 RZ(-1.0*g1) a1eda506666740029e4eeeb913593aac--c4fdcf7e436c47a4a49e0175c91fe536 b314187a1e0f4b288eb22682c5670a50 X c4fdcf7e436c47a4a49e0175c91fe536--b314187a1e0f4b288eb22682c5670a50 b314187a1e0f4b288eb22682c5670a50--022abc1ec0fe42a39f0fba989a033b57 f927de0843be4370bb2dffb05937dd69 b314187a1e0f4b288eb22682c5670a50--f927de0843be4370bb2dffb05937dd69 a61e5219334441e3a1fce26a25c13a10 f927de0843be4370bb2dffb05937dd69--a61e5219334441e3a1fce26a25c13a10 d6b62d1dae8a4e75900da4842caeed0b a61e5219334441e3a1fce26a25c13a10--d6b62d1dae8a4e75900da4842caeed0b 61b661927991456199778e0233638a94 d6b62d1dae8a4e75900da4842caeed0b--61b661927991456199778e0233638a94 ed2181c143a54579b597070d8f91952b 61b661927991456199778e0233638a94--ed2181c143a54579b597070d8f91952b e8704877d9054352abcaff68ade1da20 ed2181c143a54579b597070d8f91952b--e8704877d9054352abcaff68ade1da20 3691e385f7bf42c0b8d67617910cfdc8 e8704877d9054352abcaff68ade1da20--3691e385f7bf42c0b8d67617910cfdc8 a845c35f30414f69802a9d2b6b2f817c 3691e385f7bf42c0b8d67617910cfdc8--a845c35f30414f69802a9d2b6b2f817c 5ebf37fbf10442889406a086f2e033dc a845c35f30414f69802a9d2b6b2f817c--5ebf37fbf10442889406a086f2e033dc 421221209ddd4dc39e61807b52478672 5ebf37fbf10442889406a086f2e033dc--421221209ddd4dc39e61807b52478672 0ef1d641fd4b4926b2d727354d6260b1 421221209ddd4dc39e61807b52478672--0ef1d641fd4b4926b2d727354d6260b1 c9abeec82bfe4b879abb75f4e804d254 0ef1d641fd4b4926b2d727354d6260b1--c9abeec82bfe4b879abb75f4e804d254 648c7bd6982e41cfa5ea02d8e7c30630 c9abeec82bfe4b879abb75f4e804d254--648c7bd6982e41cfa5ea02d8e7c30630 6e05de5398c2411cae41d2dc95fd7be2 648c7bd6982e41cfa5ea02d8e7c30630--6e05de5398c2411cae41d2dc95fd7be2 96219cac427144a48ebc77a31ec9e6d8 6e05de5398c2411cae41d2dc95fd7be2--96219cac427144a48ebc77a31ec9e6d8 8eefd016dbdd449a958808bee5fad0c9 96219cac427144a48ebc77a31ec9e6d8--8eefd016dbdd449a958808bee5fad0c9 189f359bc89644daac296cc91977d115 8eefd016dbdd449a958808bee5fad0c9--189f359bc89644daac296cc91977d115 e02cbb49ff804a75b25b18807424e28a 189f359bc89644daac296cc91977d115--e02cbb49ff804a75b25b18807424e28a 808bc266277942fca50b1dbb9976318e e02cbb49ff804a75b25b18807424e28a--808bc266277942fca50b1dbb9976318e 4d76ec567b7d44b199b33b0522c325a5 808bc266277942fca50b1dbb9976318e--4d76ec567b7d44b199b33b0522c325a5 e5e99e0b282a445aadca644b80821fe7 4d76ec567b7d44b199b33b0522c325a5--e5e99e0b282a445aadca644b80821fe7 bcc695a0f7654aafb1f3e4c3fd260468 e5e99e0b282a445aadca644b80821fe7--bcc695a0f7654aafb1f3e4c3fd260468 a3e5e682a8d54ec58fe6e5ae6ee9cabd bcc695a0f7654aafb1f3e4c3fd260468--a3e5e682a8d54ec58fe6e5ae6ee9cabd ac8723c98b4643e68e933ba26a5e60df RX(b14) a3e5e682a8d54ec58fe6e5ae6ee9cabd--ac8723c98b4643e68e933ba26a5e60df ac8723c98b4643e68e933ba26a5e60df--eddb157f59f14bc891cb8b9bcb3d4096 853f0ebb7b1041fa85cbcf7714a75760 3664b4f918dd4794859212cd39a35a01 4b9f770d314c4162a06fcb0fd70d5f41--3664b4f918dd4794859212cd39a35a01 72181956eda543a79d2121bc01946886 6 032de499d93c494c8f8452c388ecdf43 3664b4f918dd4794859212cd39a35a01--032de499d93c494c8f8452c388ecdf43 fb8bed16d5304a47ba278cc9851aa28c 032de499d93c494c8f8452c388ecdf43--fb8bed16d5304a47ba278cc9851aa28c 5ac99d5253404fa3adaf553e7053262a fb8bed16d5304a47ba278cc9851aa28c--5ac99d5253404fa3adaf553e7053262a 3c7a5326bb084f3e852691a26a39ec6c X 5ac99d5253404fa3adaf553e7053262a--3c7a5326bb084f3e852691a26a39ec6c 3c7a5326bb084f3e852691a26a39ec6c--182cdc08d7504e02aba1554e4a9f0fac 56f6569ad2c74cf1b27fd7e6cb1b7ae6 3c7a5326bb084f3e852691a26a39ec6c--56f6569ad2c74cf1b27fd7e6cb1b7ae6 e12b66f500ab49f3a4eb0f8725dfeb65 56f6569ad2c74cf1b27fd7e6cb1b7ae6--e12b66f500ab49f3a4eb0f8725dfeb65 e12c05b0b0404185bada787cfcceca8f e12b66f500ab49f3a4eb0f8725dfeb65--e12c05b0b0404185bada787cfcceca8f 0498459037cc4989ab8caf085749a694 e12c05b0b0404185bada787cfcceca8f--0498459037cc4989ab8caf085749a694 f824373c63ef424f827e028b133db8fa 0498459037cc4989ab8caf085749a694--f824373c63ef424f827e028b133db8fa 96a7e35bd85542c4b531e10864c46859 X f824373c63ef424f827e028b133db8fa--96a7e35bd85542c4b531e10864c46859 96a7e35bd85542c4b531e10864c46859--41081188a09d457aae12e69919ee999d b7e0237f69264f07a9f80e9bf82d3085 96a7e35bd85542c4b531e10864c46859--b7e0237f69264f07a9f80e9bf82d3085 f41d816c4ff44061a94d9c5d95481f94 b7e0237f69264f07a9f80e9bf82d3085--f41d816c4ff44061a94d9c5d95481f94 82209c0137db43b5b9ec197e4bcad8f3 f41d816c4ff44061a94d9c5d95481f94--82209c0137db43b5b9ec197e4bcad8f3 537f60d17fa44f43ad153ec680b6518d 82209c0137db43b5b9ec197e4bcad8f3--537f60d17fa44f43ad153ec680b6518d c0a783b8bb4e4056bd58569b5bb1179c 537f60d17fa44f43ad153ec680b6518d--c0a783b8bb4e4056bd58569b5bb1179c 12cbce2fafdb41578c97d001053f1f2e c0a783b8bb4e4056bd58569b5bb1179c--12cbce2fafdb41578c97d001053f1f2e 21b59468852b4430b08f06569cade406 12cbce2fafdb41578c97d001053f1f2e--21b59468852b4430b08f06569cade406 47ce8cbf6b894d9f91166544eff41bee 21b59468852b4430b08f06569cade406--47ce8cbf6b894d9f91166544eff41bee 8d0b9f991d9e4fcd9683aa70c27dad65 47ce8cbf6b894d9f91166544eff41bee--8d0b9f991d9e4fcd9683aa70c27dad65 0355e3fbe9d4432484a0fddc5edbdb6b 8d0b9f991d9e4fcd9683aa70c27dad65--0355e3fbe9d4432484a0fddc5edbdb6b 4527a51e2b5a4766b4f9a5927f571a8a 0355e3fbe9d4432484a0fddc5edbdb6b--4527a51e2b5a4766b4f9a5927f571a8a 68a275b174124bb89e8d877e3665d630 4527a51e2b5a4766b4f9a5927f571a8a--68a275b174124bb89e8d877e3665d630 4e4dccdc9bce43608dbd4a4150fdd91c 68a275b174124bb89e8d877e3665d630--4e4dccdc9bce43608dbd4a4150fdd91c f85f376d18c5400982ce46c7c1628642 4e4dccdc9bce43608dbd4a4150fdd91c--f85f376d18c5400982ce46c7c1628642 d4a9fed731814e13ac80e5f3711fc9fe f85f376d18c5400982ce46c7c1628642--d4a9fed731814e13ac80e5f3711fc9fe 2134b56d05cb4f598a519c64247415b9 d4a9fed731814e13ac80e5f3711fc9fe--2134b56d05cb4f598a519c64247415b9 41c0c0a479a348af86040eb9aca17635 2134b56d05cb4f598a519c64247415b9--41c0c0a479a348af86040eb9aca17635 af4e582115324cf3aacc779647da7f19 41c0c0a479a348af86040eb9aca17635--af4e582115324cf3aacc779647da7f19 8375fd9d9a88456491d615bf9250bf46 af4e582115324cf3aacc779647da7f19--8375fd9d9a88456491d615bf9250bf46 7d47c716f57f4d0893ade440b99a1dbf 8375fd9d9a88456491d615bf9250bf46--7d47c716f57f4d0893ade440b99a1dbf 875a0d62a353443e853c58501e46b3f1 7d47c716f57f4d0893ade440b99a1dbf--875a0d62a353443e853c58501e46b3f1 fd2aa8ee04db486da557abd4a6a60340 875a0d62a353443e853c58501e46b3f1--fd2aa8ee04db486da557abd4a6a60340 565107792f124142837f827a62f3ca3b fd2aa8ee04db486da557abd4a6a60340--565107792f124142837f827a62f3ca3b 27f22a7d85aa44c7b680000326ab6b92 565107792f124142837f827a62f3ca3b--27f22a7d85aa44c7b680000326ab6b92 d93f3b43b2854e7e874ecccf78327ce9 27f22a7d85aa44c7b680000326ab6b92--d93f3b43b2854e7e874ecccf78327ce9 2565797489d34e52b3556c168d2d5e44 X d93f3b43b2854e7e874ecccf78327ce9--2565797489d34e52b3556c168d2d5e44 2565797489d34e52b3556c168d2d5e44--7c03bc2f5d4b4bb5a2390ebeca317262 76bf451c01854f3c98fc6c72efdb0f63 RZ(-1.0*g0) 2565797489d34e52b3556c168d2d5e44--76bf451c01854f3c98fc6c72efdb0f63 48526bcf48294739ad6b352a59333f18 X 76bf451c01854f3c98fc6c72efdb0f63--48526bcf48294739ad6b352a59333f18 48526bcf48294739ad6b352a59333f18--853f60bba80643e6b328640252147983 94debffdea1a43cba1090f83ecc8be3d 48526bcf48294739ad6b352a59333f18--94debffdea1a43cba1090f83ecc8be3d ffe9c3069f734e7fb3fc213ac3b85ad4 94debffdea1a43cba1090f83ecc8be3d--ffe9c3069f734e7fb3fc213ac3b85ad4 6d0d703411e54ec2917458d1c2da2ff4 ffe9c3069f734e7fb3fc213ac3b85ad4--6d0d703411e54ec2917458d1c2da2ff4 760d20e452e84970adc31b90437e56bc 6d0d703411e54ec2917458d1c2da2ff4--760d20e452e84970adc31b90437e56bc 26f2b44d9f1b45269a95f6ba120ac59c 760d20e452e84970adc31b90437e56bc--26f2b44d9f1b45269a95f6ba120ac59c d5d547d19f904dc6bb9b030d8694307e 26f2b44d9f1b45269a95f6ba120ac59c--d5d547d19f904dc6bb9b030d8694307e 5eae9718a0c849baabcf376bce14868e d5d547d19f904dc6bb9b030d8694307e--5eae9718a0c849baabcf376bce14868e b09ad786059f438bafa7b0ad5b73b2dc 5eae9718a0c849baabcf376bce14868e--b09ad786059f438bafa7b0ad5b73b2dc 4ca1a13603a44ccca7efd9763f8554ec X b09ad786059f438bafa7b0ad5b73b2dc--4ca1a13603a44ccca7efd9763f8554ec 4ca1a13603a44ccca7efd9763f8554ec--882f1cd869ed49a78e4f566083627d31 8d386e0b9677403a90bd540fdd4fa5ba 4ca1a13603a44ccca7efd9763f8554ec--8d386e0b9677403a90bd540fdd4fa5ba 03b9e25d0bdc428682e4f5330946271c 8d386e0b9677403a90bd540fdd4fa5ba--03b9e25d0bdc428682e4f5330946271c 0ba32527fac949a5b03f444fb076934c 03b9e25d0bdc428682e4f5330946271c--0ba32527fac949a5b03f444fb076934c b93d60f2a4b94fde9d786579c4be9490 0ba32527fac949a5b03f444fb076934c--b93d60f2a4b94fde9d786579c4be9490 a87ee1fd9acc490ab97654994ad7a726 b93d60f2a4b94fde9d786579c4be9490--a87ee1fd9acc490ab97654994ad7a726 6cb4d648f46b4bdfae62ad309131e573 X a87ee1fd9acc490ab97654994ad7a726--6cb4d648f46b4bdfae62ad309131e573 6cb4d648f46b4bdfae62ad309131e573--b1e2db3b27814d8a90e6cf687a1ea697 c701f3dd00ea470fb5b8e466dd4f5c4c 6cb4d648f46b4bdfae62ad309131e573--c701f3dd00ea470fb5b8e466dd4f5c4c 6422fa3cf424498ba74ae7f549ee8671 c701f3dd00ea470fb5b8e466dd4f5c4c--6422fa3cf424498ba74ae7f549ee8671 33cb8d680e6f4fa8b78ce69b2d826ab9 6422fa3cf424498ba74ae7f549ee8671--33cb8d680e6f4fa8b78ce69b2d826ab9 ca884009036645778905aaf463fcc164 33cb8d680e6f4fa8b78ce69b2d826ab9--ca884009036645778905aaf463fcc164 7f07fb7e645947058305217241ce9605 ca884009036645778905aaf463fcc164--7f07fb7e645947058305217241ce9605 e7ed70c1a5c14f0b97c6d6cfdfc1445f 7f07fb7e645947058305217241ce9605--e7ed70c1a5c14f0b97c6d6cfdfc1445f 738ed99e2f344d649680ef08d6ec0d28 e7ed70c1a5c14f0b97c6d6cfdfc1445f--738ed99e2f344d649680ef08d6ec0d28 a029c138cd394906b75719edd01784b8 738ed99e2f344d649680ef08d6ec0d28--a029c138cd394906b75719edd01784b8 3d9d29c520d64c9186e8a1344315ac45 a029c138cd394906b75719edd01784b8--3d9d29c520d64c9186e8a1344315ac45 6267823e506646f19e94d972e0dfefd7 3d9d29c520d64c9186e8a1344315ac45--6267823e506646f19e94d972e0dfefd7 051b6f2178f44201bb5886a8ec8c906b 6267823e506646f19e94d972e0dfefd7--051b6f2178f44201bb5886a8ec8c906b c0a4cd71969643ccbfffa040d1e11b43 051b6f2178f44201bb5886a8ec8c906b--c0a4cd71969643ccbfffa040d1e11b43 3fe356e34392481da739d2d70bc100f2 c0a4cd71969643ccbfffa040d1e11b43--3fe356e34392481da739d2d70bc100f2 10ddad5f5c13475ba86c66d8099e6296 3fe356e34392481da739d2d70bc100f2--10ddad5f5c13475ba86c66d8099e6296 f260b6936ada4978ac0f3540f420e03e 10ddad5f5c13475ba86c66d8099e6296--f260b6936ada4978ac0f3540f420e03e c1f9c74042fc4abeb0edc7440f819b8b f260b6936ada4978ac0f3540f420e03e--c1f9c74042fc4abeb0edc7440f819b8b 14429c8095b146c38b6565b8f1252ad8 c1f9c74042fc4abeb0edc7440f819b8b--14429c8095b146c38b6565b8f1252ad8 3631a326b3664dc89027d8ac8fb6b22e 14429c8095b146c38b6565b8f1252ad8--3631a326b3664dc89027d8ac8fb6b22e 7ec57db9275743f899118edd38bd8c2d 3631a326b3664dc89027d8ac8fb6b22e--7ec57db9275743f899118edd38bd8c2d 812672aa011b48a4aafe569eedb569f2 7ec57db9275743f899118edd38bd8c2d--812672aa011b48a4aafe569eedb569f2 1313e67ae0d841639d2e5195a1fc3049 812672aa011b48a4aafe569eedb569f2--1313e67ae0d841639d2e5195a1fc3049 06055a7cfd414f6db3f218946123e0e9 1313e67ae0d841639d2e5195a1fc3049--06055a7cfd414f6db3f218946123e0e9 9b9f05f422434a439cce7c2bc6c26232 X 06055a7cfd414f6db3f218946123e0e9--9b9f05f422434a439cce7c2bc6c26232 9b9f05f422434a439cce7c2bc6c26232--a984de19c76f4c07892656c69740f694 ca79dbab78a147f3bb9411fd5572c607 RZ(-1.0*g0) 9b9f05f422434a439cce7c2bc6c26232--ca79dbab78a147f3bb9411fd5572c607 4597189e5ded4e0ca3fff9bca272d850 X ca79dbab78a147f3bb9411fd5572c607--4597189e5ded4e0ca3fff9bca272d850 4597189e5ded4e0ca3fff9bca272d850--7776f1c0ae6c4f14a1ff4b579015abf5 ddf46daed1864dbb9857571c33f9bb3e 4597189e5ded4e0ca3fff9bca272d850--ddf46daed1864dbb9857571c33f9bb3e 2495f26d42794551bdcb161f365c081a ddf46daed1864dbb9857571c33f9bb3e--2495f26d42794551bdcb161f365c081a 830b4075c4c5411491e9608cf1df372d 2495f26d42794551bdcb161f365c081a--830b4075c4c5411491e9608cf1df372d 8a47b7d04daf4983a87ec032cda799f8 830b4075c4c5411491e9608cf1df372d--8a47b7d04daf4983a87ec032cda799f8 45fd8b7a60b04a4d9249fb45411234b3 8a47b7d04daf4983a87ec032cda799f8--45fd8b7a60b04a4d9249fb45411234b3 fb7bbaaa8eac4d159a6e4d04a66bd68b 45fd8b7a60b04a4d9249fb45411234b3--fb7bbaaa8eac4d159a6e4d04a66bd68b 19e97943ca7841a1b3896962e81a5b44 X fb7bbaaa8eac4d159a6e4d04a66bd68b--19e97943ca7841a1b3896962e81a5b44 19e97943ca7841a1b3896962e81a5b44--ca838981902b4fc093b621f49443225f 3a8e8439186e4007887a7cb597232eb7 19e97943ca7841a1b3896962e81a5b44--3a8e8439186e4007887a7cb597232eb7 08eaa9b1e7084e37b31613d94affe523 3a8e8439186e4007887a7cb597232eb7--08eaa9b1e7084e37b31613d94affe523 ecb6c306fb2e4270a389852ddae50675 08eaa9b1e7084e37b31613d94affe523--ecb6c306fb2e4270a389852ddae50675 d417294bc87d416ca093afea91568603 X ecb6c306fb2e4270a389852ddae50675--d417294bc87d416ca093afea91568603 d417294bc87d416ca093afea91568603--f361961bb8ee4893a9a3e93bde04b8e6 cc0098b3b097406eb0344e56db03fe48 d417294bc87d416ca093afea91568603--cc0098b3b097406eb0344e56db03fe48 77dfb9670e4d4af29c8b4d75a14b0dbd cc0098b3b097406eb0344e56db03fe48--77dfb9670e4d4af29c8b4d75a14b0dbd a290fced2e59447fa12e94839c0ffc52 77dfb9670e4d4af29c8b4d75a14b0dbd--a290fced2e59447fa12e94839c0ffc52 532454fea8b74aa4b5af384ddc7601d6 a290fced2e59447fa12e94839c0ffc52--532454fea8b74aa4b5af384ddc7601d6 d965365722b14e70b13bf89b696eb920 532454fea8b74aa4b5af384ddc7601d6--d965365722b14e70b13bf89b696eb920 b9fc1e06cdf747b984ff6135a1a5f8fc d965365722b14e70b13bf89b696eb920--b9fc1e06cdf747b984ff6135a1a5f8fc 62c4690460c245bcaece242290319838 X b9fc1e06cdf747b984ff6135a1a5f8fc--62c4690460c245bcaece242290319838 62c4690460c245bcaece242290319838--c416a08f16c241a2a4f8486d4a76b8c0 39406275b90c45fc9dada5b341e48ba2 62c4690460c245bcaece242290319838--39406275b90c45fc9dada5b341e48ba2 405d1163bdbd40688e7da72080ac6449 39406275b90c45fc9dada5b341e48ba2--405d1163bdbd40688e7da72080ac6449 6c144c966a3d459f8d09dcbcbe147e36 405d1163bdbd40688e7da72080ac6449--6c144c966a3d459f8d09dcbcbe147e36 64e664769d714297b1f8c337fa4fd41f 6c144c966a3d459f8d09dcbcbe147e36--64e664769d714297b1f8c337fa4fd41f c7c2a6a01f71437a9da42f18ddda89d4 64e664769d714297b1f8c337fa4fd41f--c7c2a6a01f71437a9da42f18ddda89d4 7ce5f674c74f4da099dd46a70755e9da X c7c2a6a01f71437a9da42f18ddda89d4--7ce5f674c74f4da099dd46a70755e9da 7ce5f674c74f4da099dd46a70755e9da--5b160e110a004e919835e65091ef6073 bbbe4219bfde41a58bcc10914d1e92d9 7ce5f674c74f4da099dd46a70755e9da--bbbe4219bfde41a58bcc10914d1e92d9 04169a842edd46d2a6ec15153a5eaae7 bbbe4219bfde41a58bcc10914d1e92d9--04169a842edd46d2a6ec15153a5eaae7 8374a2d4b5b940b39341fd051fb6dfda 04169a842edd46d2a6ec15153a5eaae7--8374a2d4b5b940b39341fd051fb6dfda 2e01e937e97342f8858c76e2929d5ad7 8374a2d4b5b940b39341fd051fb6dfda--2e01e937e97342f8858c76e2929d5ad7 bf68f6698ce74d39aaf88868804bbdda 2e01e937e97342f8858c76e2929d5ad7--bf68f6698ce74d39aaf88868804bbdda c4c20c2dabc34d678c19b52d12ef7276 bf68f6698ce74d39aaf88868804bbdda--c4c20c2dabc34d678c19b52d12ef7276 c9d0778912c6417884205d8624353309 c4c20c2dabc34d678c19b52d12ef7276--c9d0778912c6417884205d8624353309 4e844c7602aa4af5baf1602e0ee54a77 c9d0778912c6417884205d8624353309--4e844c7602aa4af5baf1602e0ee54a77 164093ceadcd4de8af2acc57cf95bf79 X 4e844c7602aa4af5baf1602e0ee54a77--164093ceadcd4de8af2acc57cf95bf79 164093ceadcd4de8af2acc57cf95bf79--961c096242524824b30245a694af1d72 4d1f3b2307574d5f8271a6c94a2134fa RZ(-1.0*g0) 164093ceadcd4de8af2acc57cf95bf79--4d1f3b2307574d5f8271a6c94a2134fa bda4ff4a0b3246fc9f58be39a5511667 X 4d1f3b2307574d5f8271a6c94a2134fa--bda4ff4a0b3246fc9f58be39a5511667 bda4ff4a0b3246fc9f58be39a5511667--5d27cf1bd2c14c37b96d155764fa585c d099e721c7be4230bf0828ec9c869b6d bda4ff4a0b3246fc9f58be39a5511667--d099e721c7be4230bf0828ec9c869b6d 33b5eabb0b06499e94b84b9cd75f9127 d099e721c7be4230bf0828ec9c869b6d--33b5eabb0b06499e94b84b9cd75f9127 b4eacbc97d04482eb2c35be551ab3c1a 33b5eabb0b06499e94b84b9cd75f9127--b4eacbc97d04482eb2c35be551ab3c1a f5a33b03609e4a258608e690967a4407 b4eacbc97d04482eb2c35be551ab3c1a--f5a33b03609e4a258608e690967a4407 4dfc09cd59414c659eec6ac0f97a0992 X f5a33b03609e4a258608e690967a4407--4dfc09cd59414c659eec6ac0f97a0992 4dfc09cd59414c659eec6ac0f97a0992--f4800c3eebba4dccbf0205c3631f7b66 fdc9923f29f040da83dfa53d73bdae4c 4dfc09cd59414c659eec6ac0f97a0992--fdc9923f29f040da83dfa53d73bdae4c 332e7496186841a2aa2eb620349370ac fdc9923f29f040da83dfa53d73bdae4c--332e7496186841a2aa2eb620349370ac 30f53f348c7c445185f8acae24d09f67 332e7496186841a2aa2eb620349370ac--30f53f348c7c445185f8acae24d09f67 bb2a3dba335847c5a50dcb4e6ea5c114 X 30f53f348c7c445185f8acae24d09f67--bb2a3dba335847c5a50dcb4e6ea5c114 bb2a3dba335847c5a50dcb4e6ea5c114--8d5dd662500f43ac831f6dd3101c75b8 95c9a45682fa421bbc6395af6e3334c3 bb2a3dba335847c5a50dcb4e6ea5c114--95c9a45682fa421bbc6395af6e3334c3 128ce550380a44269a89f4b880fd0621 95c9a45682fa421bbc6395af6e3334c3--128ce550380a44269a89f4b880fd0621 c7121554a7d540c1a255bb48089c8af2 128ce550380a44269a89f4b880fd0621--c7121554a7d540c1a255bb48089c8af2 df1de40ce56740deafe966e29ec2327a c7121554a7d540c1a255bb48089c8af2--df1de40ce56740deafe966e29ec2327a 74eedb45dfb24d6eaebcee8842207672 df1de40ce56740deafe966e29ec2327a--74eedb45dfb24d6eaebcee8842207672 196a0498611a4298bf72f9179ed88cc6 X 74eedb45dfb24d6eaebcee8842207672--196a0498611a4298bf72f9179ed88cc6 196a0498611a4298bf72f9179ed88cc6--b148334fcffd451f80f63ad7381a16a3 b6a31bd10892487aad0350d277af515a 196a0498611a4298bf72f9179ed88cc6--b6a31bd10892487aad0350d277af515a 62f9e17635c041a7a2dce0b104596b68 b6a31bd10892487aad0350d277af515a--62f9e17635c041a7a2dce0b104596b68 1a89635a54dc452ca4453f760efda1b4 62f9e17635c041a7a2dce0b104596b68--1a89635a54dc452ca4453f760efda1b4 384b073f093f488d8a7211a0cb82d5c7 X 1a89635a54dc452ca4453f760efda1b4--384b073f093f488d8a7211a0cb82d5c7 384b073f093f488d8a7211a0cb82d5c7--cfe791bda44447a9b4e58861ff21936b 3a7119c47b2b4e12b442c0efd3d85c18 X 384b073f093f488d8a7211a0cb82d5c7--3a7119c47b2b4e12b442c0efd3d85c18 3a7119c47b2b4e12b442c0efd3d85c18--24c2ba1190544a539aee1a2e718a6a58 12eac605225545f99b279272b373ce6a 3a7119c47b2b4e12b442c0efd3d85c18--12eac605225545f99b279272b373ce6a c4ab183f82a34a0e8146aa506d60cce6 12eac605225545f99b279272b373ce6a--c4ab183f82a34a0e8146aa506d60cce6 1ab6cdfe97804227bda2f01dc1c52fad c4ab183f82a34a0e8146aa506d60cce6--1ab6cdfe97804227bda2f01dc1c52fad ec57356b29b14e098db4aedeb6fd75dd 1ab6cdfe97804227bda2f01dc1c52fad--ec57356b29b14e098db4aedeb6fd75dd 5cc8fca9945244ee926e602c54faa2f0 ec57356b29b14e098db4aedeb6fd75dd--5cc8fca9945244ee926e602c54faa2f0 b20205a0762b42b58cb37f71657656bd X 5cc8fca9945244ee926e602c54faa2f0--b20205a0762b42b58cb37f71657656bd b20205a0762b42b58cb37f71657656bd--592018801abc49a6801c729cfd3ff848 80522de18b194714bfce0892543660f8 b20205a0762b42b58cb37f71657656bd--80522de18b194714bfce0892543660f8 bca5ce8b72fe436f9b61a9ef8362fc51 80522de18b194714bfce0892543660f8--bca5ce8b72fe436f9b61a9ef8362fc51 5f19be98994746f5919cbb296cdcb768 bca5ce8b72fe436f9b61a9ef8362fc51--5f19be98994746f5919cbb296cdcb768 5a3c3113c3e74ef7a46d52121b785ebe 5f19be98994746f5919cbb296cdcb768--5a3c3113c3e74ef7a46d52121b785ebe 3b4dfea0cacc4d43b8debf5256eb55a1 5a3c3113c3e74ef7a46d52121b785ebe--3b4dfea0cacc4d43b8debf5256eb55a1 95c427a70be14e3a8fee2b64177b38b7 3b4dfea0cacc4d43b8debf5256eb55a1--95c427a70be14e3a8fee2b64177b38b7 286a61f7d13d476e88f0cba63dfa4a77 95c427a70be14e3a8fee2b64177b38b7--286a61f7d13d476e88f0cba63dfa4a77 b4ab316ff9d0422c9d17f8590a5ecdc0 286a61f7d13d476e88f0cba63dfa4a77--b4ab316ff9d0422c9d17f8590a5ecdc0 0f075948a9d04b1d9440b5498d7dc14c b4ab316ff9d0422c9d17f8590a5ecdc0--0f075948a9d04b1d9440b5498d7dc14c f6c5f17823b24e07aa1d0af9d9520d9c 0f075948a9d04b1d9440b5498d7dc14c--f6c5f17823b24e07aa1d0af9d9520d9c d1106f0d0f9d409391816e0788b4c656 f6c5f17823b24e07aa1d0af9d9520d9c--d1106f0d0f9d409391816e0788b4c656 d9663aac5a604e9c86d4ac309989d6a2 RX(b05) d1106f0d0f9d409391816e0788b4c656--d9663aac5a604e9c86d4ac309989d6a2 ae0c93a0947f403799c06cea8a27b6e0 d9663aac5a604e9c86d4ac309989d6a2--ae0c93a0947f403799c06cea8a27b6e0 bbbac4042c134b6ca7c8e0a622f72762 ae0c93a0947f403799c06cea8a27b6e0--bbbac4042c134b6ca7c8e0a622f72762 936b6f643f4f449c95e3d5bbe2fad3ba bbbac4042c134b6ca7c8e0a622f72762--936b6f643f4f449c95e3d5bbe2fad3ba 78754d9e617643039b3b8c434388d312 936b6f643f4f449c95e3d5bbe2fad3ba--78754d9e617643039b3b8c434388d312 fe0bf766b4534ffc82a5c7d2ce0b9877 X 78754d9e617643039b3b8c434388d312--fe0bf766b4534ffc82a5c7d2ce0b9877 fe0bf766b4534ffc82a5c7d2ce0b9877--e62c3d6e64dc44f4bc822fccc37b35e1 d9ea344861914ef084294a96106617c3 fe0bf766b4534ffc82a5c7d2ce0b9877--d9ea344861914ef084294a96106617c3 540433fc6380469ca68f776faa4b0f1e d9ea344861914ef084294a96106617c3--540433fc6380469ca68f776faa4b0f1e 9244ced695c8400bbb8c8cb5123d4e25 540433fc6380469ca68f776faa4b0f1e--9244ced695c8400bbb8c8cb5123d4e25 715c399c070a463ea8df4e3a3a169bee 9244ced695c8400bbb8c8cb5123d4e25--715c399c070a463ea8df4e3a3a169bee d7558069b2094b3f967b8714f2114f0b 715c399c070a463ea8df4e3a3a169bee--d7558069b2094b3f967b8714f2114f0b a23d719f2be14441bb1c59fb6ba954a5 X d7558069b2094b3f967b8714f2114f0b--a23d719f2be14441bb1c59fb6ba954a5 a23d719f2be14441bb1c59fb6ba954a5--7876f253476d4399a83a66a4e49cb139 620ed4a4517b4369859803a336225f88 a23d719f2be14441bb1c59fb6ba954a5--620ed4a4517b4369859803a336225f88 742523427d1e4fdbbc7eb0e37c4955f7 620ed4a4517b4369859803a336225f88--742523427d1e4fdbbc7eb0e37c4955f7 63e2264cf25643a39ab7ec4046e66ef0 742523427d1e4fdbbc7eb0e37c4955f7--63e2264cf25643a39ab7ec4046e66ef0 c17661716bb14ac29aff6cc1d897c15a 63e2264cf25643a39ab7ec4046e66ef0--c17661716bb14ac29aff6cc1d897c15a ac642c28b37d484b95119dd7d9c58d05 c17661716bb14ac29aff6cc1d897c15a--ac642c28b37d484b95119dd7d9c58d05 df664a9b83af4510a8dc3381029b63b1 ac642c28b37d484b95119dd7d9c58d05--df664a9b83af4510a8dc3381029b63b1 15202f7e43d84253991d2a56d2633b84 df664a9b83af4510a8dc3381029b63b1--15202f7e43d84253991d2a56d2633b84 af161b57bdba4ba088d6d480f0ef590d 15202f7e43d84253991d2a56d2633b84--af161b57bdba4ba088d6d480f0ef590d abd73de992ab4686978c2a1a9742d259 af161b57bdba4ba088d6d480f0ef590d--abd73de992ab4686978c2a1a9742d259 8928bfd290674ac8949d1718c1a434ed abd73de992ab4686978c2a1a9742d259--8928bfd290674ac8949d1718c1a434ed 75a539a734314f4b9109246b83efe92b 8928bfd290674ac8949d1718c1a434ed--75a539a734314f4b9109246b83efe92b 4685b272380742149dc9d3e1e4344886 75a539a734314f4b9109246b83efe92b--4685b272380742149dc9d3e1e4344886 660b03b35ac149e38451c2a27862a88e 4685b272380742149dc9d3e1e4344886--660b03b35ac149e38451c2a27862a88e fd39c636fd5e4ca898a3a8f44505e7b8 660b03b35ac149e38451c2a27862a88e--fd39c636fd5e4ca898a3a8f44505e7b8 d8803101236848e78595ed243840c364 fd39c636fd5e4ca898a3a8f44505e7b8--d8803101236848e78595ed243840c364 d0883342170245a9ae8014ba291dbb9c d8803101236848e78595ed243840c364--d0883342170245a9ae8014ba291dbb9c 736940551d414fc0b38020d8fe5e2531 d0883342170245a9ae8014ba291dbb9c--736940551d414fc0b38020d8fe5e2531 53c4174c4da24dd38ce3f8c5ab754251 736940551d414fc0b38020d8fe5e2531--53c4174c4da24dd38ce3f8c5ab754251 2f9a1d40233041918abc1615303ce64d 53c4174c4da24dd38ce3f8c5ab754251--2f9a1d40233041918abc1615303ce64d 1c410bc67af24c8c92c07f3167782190 2f9a1d40233041918abc1615303ce64d--1c410bc67af24c8c92c07f3167782190 3e15735bdf854e98b8816a78b61c72eb 1c410bc67af24c8c92c07f3167782190--3e15735bdf854e98b8816a78b61c72eb 7640a13820374c6b82c1551f2c61beee 3e15735bdf854e98b8816a78b61c72eb--7640a13820374c6b82c1551f2c61beee 1352442e19f549acaedfdc39a2db1dfe 7640a13820374c6b82c1551f2c61beee--1352442e19f549acaedfdc39a2db1dfe f314fd66d3b748d680a2ed0273287b3d 1352442e19f549acaedfdc39a2db1dfe--f314fd66d3b748d680a2ed0273287b3d 9d036a6d2d6e4338ab59fb4da22f364c f314fd66d3b748d680a2ed0273287b3d--9d036a6d2d6e4338ab59fb4da22f364c b3acb687cc36491db4ac34155263fef3 X 9d036a6d2d6e4338ab59fb4da22f364c--b3acb687cc36491db4ac34155263fef3 b3acb687cc36491db4ac34155263fef3--ab40d81a32bc46a9b7c110158f9bd866 9214d29cffd44e00b7d7810653d9a385 RZ(-1.0*g1) b3acb687cc36491db4ac34155263fef3--9214d29cffd44e00b7d7810653d9a385 3d7f015679c74f7d88715b9256b683fc X 9214d29cffd44e00b7d7810653d9a385--3d7f015679c74f7d88715b9256b683fc 3d7f015679c74f7d88715b9256b683fc--6680bde7a17d4de49db476a7aae12a23 ff77d500df5c4c46b6115b2e8875becb 3d7f015679c74f7d88715b9256b683fc--ff77d500df5c4c46b6115b2e8875becb 1ea8b266936d4fbc9f582748d79091c1 ff77d500df5c4c46b6115b2e8875becb--1ea8b266936d4fbc9f582748d79091c1 14cd71b211234a9aa5551fc6bef393e9 1ea8b266936d4fbc9f582748d79091c1--14cd71b211234a9aa5551fc6bef393e9 e3eacf6d6e924f20a242a6ece07bda2e 14cd71b211234a9aa5551fc6bef393e9--e3eacf6d6e924f20a242a6ece07bda2e a12fd5c36022434b8272b39b1bc2ab00 e3eacf6d6e924f20a242a6ece07bda2e--a12fd5c36022434b8272b39b1bc2ab00 9b2601c32a2d47428fc6d6974407c6f4 a12fd5c36022434b8272b39b1bc2ab00--9b2601c32a2d47428fc6d6974407c6f4 82723daec81b4ca6b68af4521904f89c 9b2601c32a2d47428fc6d6974407c6f4--82723daec81b4ca6b68af4521904f89c f7a9e8c66b114503855507cd46cad041 82723daec81b4ca6b68af4521904f89c--f7a9e8c66b114503855507cd46cad041 92978e6aab224256983d6632981c0930 X f7a9e8c66b114503855507cd46cad041--92978e6aab224256983d6632981c0930 92978e6aab224256983d6632981c0930--da2f0bdb4a414c1d805974e70c26fb6a eb9b0837241644d99c2cf87e131126e9 92978e6aab224256983d6632981c0930--eb9b0837241644d99c2cf87e131126e9 fcae526385b04f2aa09775625e932d40 eb9b0837241644d99c2cf87e131126e9--fcae526385b04f2aa09775625e932d40 a8c13eaf7ae740eeb2e55e52acaf6665 fcae526385b04f2aa09775625e932d40--a8c13eaf7ae740eeb2e55e52acaf6665 b509778079c2482698d8837cc43c3aca a8c13eaf7ae740eeb2e55e52acaf6665--b509778079c2482698d8837cc43c3aca ac96a4ee925d44bf821d83bd480f9492 b509778079c2482698d8837cc43c3aca--ac96a4ee925d44bf821d83bd480f9492 24c7c318b4e4413fae4ef61439f89ab4 X ac96a4ee925d44bf821d83bd480f9492--24c7c318b4e4413fae4ef61439f89ab4 24c7c318b4e4413fae4ef61439f89ab4--f378701e76e44cc5a7612cbe521f8008 b9631b01481a4a048857a672884070d2 24c7c318b4e4413fae4ef61439f89ab4--b9631b01481a4a048857a672884070d2 37f1772a219e426aba569110fb3cbe52 b9631b01481a4a048857a672884070d2--37f1772a219e426aba569110fb3cbe52 400625041d6e424e82eaba4e19717b38 37f1772a219e426aba569110fb3cbe52--400625041d6e424e82eaba4e19717b38 14ef9a873db54a40a223e9fe72b0d612 400625041d6e424e82eaba4e19717b38--14ef9a873db54a40a223e9fe72b0d612 f5e8f29c5e3f4419bf8ee0298c13bfb7 14ef9a873db54a40a223e9fe72b0d612--f5e8f29c5e3f4419bf8ee0298c13bfb7 03efea40f05145d9b6aa7c3166a5a63a f5e8f29c5e3f4419bf8ee0298c13bfb7--03efea40f05145d9b6aa7c3166a5a63a e6e6524f1e054a0689b20b0d6d1bd906 03efea40f05145d9b6aa7c3166a5a63a--e6e6524f1e054a0689b20b0d6d1bd906 a8cb4df4bfe141c9bb6f543f89838975 e6e6524f1e054a0689b20b0d6d1bd906--a8cb4df4bfe141c9bb6f543f89838975 611b0a3695324613b86894794666fbc2 a8cb4df4bfe141c9bb6f543f89838975--611b0a3695324613b86894794666fbc2 f9c6db3c53184535955850c43c4549ae 611b0a3695324613b86894794666fbc2--f9c6db3c53184535955850c43c4549ae deb57d70e01e41af91668f7aa61b022f f9c6db3c53184535955850c43c4549ae--deb57d70e01e41af91668f7aa61b022f c6dc420592c94bdba44e47a4655f904e deb57d70e01e41af91668f7aa61b022f--c6dc420592c94bdba44e47a4655f904e 82c0dbcbfdad483ab20638ddddc5a4d4 c6dc420592c94bdba44e47a4655f904e--82c0dbcbfdad483ab20638ddddc5a4d4 9016f24141564e879dbbaec038222ad5 82c0dbcbfdad483ab20638ddddc5a4d4--9016f24141564e879dbbaec038222ad5 ff58fc321e3b4edcabe9bde32896ed08 9016f24141564e879dbbaec038222ad5--ff58fc321e3b4edcabe9bde32896ed08 e89f7f864cf3488e95ea826b42bfc9e7 ff58fc321e3b4edcabe9bde32896ed08--e89f7f864cf3488e95ea826b42bfc9e7 8c65881a708a4858aaf441a2ef10b44b e89f7f864cf3488e95ea826b42bfc9e7--8c65881a708a4858aaf441a2ef10b44b 630ab1c442d9470d8d042179fce3c9da 8c65881a708a4858aaf441a2ef10b44b--630ab1c442d9470d8d042179fce3c9da 3766822ccc74435f9262f496f1389c72 630ab1c442d9470d8d042179fce3c9da--3766822ccc74435f9262f496f1389c72 8ba2ec5a62d944c38ea3e70319f74afe 3766822ccc74435f9262f496f1389c72--8ba2ec5a62d944c38ea3e70319f74afe 38e6c037a0464ff299f22531b40be19e 8ba2ec5a62d944c38ea3e70319f74afe--38e6c037a0464ff299f22531b40be19e 67809997fcaa427c9fc5d40dca591f44 38e6c037a0464ff299f22531b40be19e--67809997fcaa427c9fc5d40dca591f44 f5d564ec982248e8a23d1bf676b590df X 67809997fcaa427c9fc5d40dca591f44--f5d564ec982248e8a23d1bf676b590df f5d564ec982248e8a23d1bf676b590df--5d4e2441616d4f559cbf4c8ee863664e 170292347c724ab0aead038e9d4975c0 RZ(-1.0*g1) f5d564ec982248e8a23d1bf676b590df--170292347c724ab0aead038e9d4975c0 fe2ee7fdce3d4f22b93ea15f8aa48aeb X 170292347c724ab0aead038e9d4975c0--fe2ee7fdce3d4f22b93ea15f8aa48aeb fe2ee7fdce3d4f22b93ea15f8aa48aeb--79e984bec1d84c9893f67010a889161a 65b7ea5876b54b9d894991687ae20d7c fe2ee7fdce3d4f22b93ea15f8aa48aeb--65b7ea5876b54b9d894991687ae20d7c 4085b79646774271a1c21581eba1478a 65b7ea5876b54b9d894991687ae20d7c--4085b79646774271a1c21581eba1478a d8c0956f875449a5ba3cbccb06a7f6a2 4085b79646774271a1c21581eba1478a--d8c0956f875449a5ba3cbccb06a7f6a2 3597ec968cf54fa193a66d1b605cb369 d8c0956f875449a5ba3cbccb06a7f6a2--3597ec968cf54fa193a66d1b605cb369 2b5fe298d1934cbaad207e3554b712b0 3597ec968cf54fa193a66d1b605cb369--2b5fe298d1934cbaad207e3554b712b0 3df995baeadd48e39ee3e23430c735c4 2b5fe298d1934cbaad207e3554b712b0--3df995baeadd48e39ee3e23430c735c4 6720feb28b2f454f9251ca9096344b63 X 3df995baeadd48e39ee3e23430c735c4--6720feb28b2f454f9251ca9096344b63 6720feb28b2f454f9251ca9096344b63--0ac54277411c421c81e6d1a8f7b4921e 1d65a05df5594cf681f837e83ad16b90 6720feb28b2f454f9251ca9096344b63--1d65a05df5594cf681f837e83ad16b90 1ec31f4e97c2466391bb47a5e54ec9b9 1d65a05df5594cf681f837e83ad16b90--1ec31f4e97c2466391bb47a5e54ec9b9 8aaa792718934034a9ea0fee6302c8e2 1ec31f4e97c2466391bb47a5e54ec9b9--8aaa792718934034a9ea0fee6302c8e2 fc8b04e6b4174589b77b34d60703e2d0 X 8aaa792718934034a9ea0fee6302c8e2--fc8b04e6b4174589b77b34d60703e2d0 fc8b04e6b4174589b77b34d60703e2d0--753195bc04e843429da21b642bf4f991 5cbab56ac418434a8d70bbc46a5f506d fc8b04e6b4174589b77b34d60703e2d0--5cbab56ac418434a8d70bbc46a5f506d 8541ab9797774fd9ac78f1f983813f09 5cbab56ac418434a8d70bbc46a5f506d--8541ab9797774fd9ac78f1f983813f09 48a5c63f7b1b4e2cbb46ff4406cd80ef 8541ab9797774fd9ac78f1f983813f09--48a5c63f7b1b4e2cbb46ff4406cd80ef 2be9e25e65af49bba676d4fee2795716 48a5c63f7b1b4e2cbb46ff4406cd80ef--2be9e25e65af49bba676d4fee2795716 eea7d5d304a04c6d894b99b4c2bb8fea 2be9e25e65af49bba676d4fee2795716--eea7d5d304a04c6d894b99b4c2bb8fea 49815202e15b498f931730252bc149b9 eea7d5d304a04c6d894b99b4c2bb8fea--49815202e15b498f931730252bc149b9 2abf605e904b4ffd8da69d4c85d7a8fb X 49815202e15b498f931730252bc149b9--2abf605e904b4ffd8da69d4c85d7a8fb 2abf605e904b4ffd8da69d4c85d7a8fb--789efa4c09d54882be56a98d8d5dc585 b615d503511b4eec854308922b26f987 2abf605e904b4ffd8da69d4c85d7a8fb--b615d503511b4eec854308922b26f987 e839f414b89d463cab83b5901379f395 b615d503511b4eec854308922b26f987--e839f414b89d463cab83b5901379f395 3b1f30b3ec3741878070a77e1402e8dc e839f414b89d463cab83b5901379f395--3b1f30b3ec3741878070a77e1402e8dc 8c587df35bc0449d8163d31a9d4298c1 3b1f30b3ec3741878070a77e1402e8dc--8c587df35bc0449d8163d31a9d4298c1 3b7529b3cbd346c7899649a192133c47 8c587df35bc0449d8163d31a9d4298c1--3b7529b3cbd346c7899649a192133c47 b8547096eb824b8296c937aebca53677 X 3b7529b3cbd346c7899649a192133c47--b8547096eb824b8296c937aebca53677 b8547096eb824b8296c937aebca53677--aab75082ffc44a0194d95c0a9946376c 191e839e56cc485a9ce4c6357b5415b5 b8547096eb824b8296c937aebca53677--191e839e56cc485a9ce4c6357b5415b5 077b3d3759a94bb69f57ec1178caa39e 191e839e56cc485a9ce4c6357b5415b5--077b3d3759a94bb69f57ec1178caa39e 4300836d37ee410d8e2e0ef0471c7035 077b3d3759a94bb69f57ec1178caa39e--4300836d37ee410d8e2e0ef0471c7035 1b7eddd442a948f69ba962eaacc79dcb 4300836d37ee410d8e2e0ef0471c7035--1b7eddd442a948f69ba962eaacc79dcb afefcbf6d5d94c889d22f20f29d76562 1b7eddd442a948f69ba962eaacc79dcb--afefcbf6d5d94c889d22f20f29d76562 89c44f4b929245b6a9dab89adf9456b6 afefcbf6d5d94c889d22f20f29d76562--89c44f4b929245b6a9dab89adf9456b6 f097bb03a89044c2be5d86c7260d2da1 89c44f4b929245b6a9dab89adf9456b6--f097bb03a89044c2be5d86c7260d2da1 31b71c26154d4f4ea52ef0c84b5331da f097bb03a89044c2be5d86c7260d2da1--31b71c26154d4f4ea52ef0c84b5331da bc9dc94904764bf9b08c1678069590f0 X 31b71c26154d4f4ea52ef0c84b5331da--bc9dc94904764bf9b08c1678069590f0 bc9dc94904764bf9b08c1678069590f0--429fc0ec03dd41148c4811c00c1859bb b92311e97b454ecfa01166199cdfe7c6 RZ(-1.0*g1) bc9dc94904764bf9b08c1678069590f0--b92311e97b454ecfa01166199cdfe7c6 7876c92299ec48088e4075995885d9fb X b92311e97b454ecfa01166199cdfe7c6--7876c92299ec48088e4075995885d9fb 7876c92299ec48088e4075995885d9fb--d3073f355dc1434e8fdcb775088a25dc e590ec5638114909a8cc33b704731356 7876c92299ec48088e4075995885d9fb--e590ec5638114909a8cc33b704731356 854f8f03b4764276960af49e8a48c8b6 e590ec5638114909a8cc33b704731356--854f8f03b4764276960af49e8a48c8b6 d3bf46bbe9174d64a926f7844d88b257 854f8f03b4764276960af49e8a48c8b6--d3bf46bbe9174d64a926f7844d88b257 c209a4a3c1f0493db3eff22d844f24a4 d3bf46bbe9174d64a926f7844d88b257--c209a4a3c1f0493db3eff22d844f24a4 7e9cdcf7bd8540ecad29336f507a3ae3 X c209a4a3c1f0493db3eff22d844f24a4--7e9cdcf7bd8540ecad29336f507a3ae3 7e9cdcf7bd8540ecad29336f507a3ae3--e951d8984eaf4604948b383df009682b 213cd778a17b4d909df501a8e120d467 7e9cdcf7bd8540ecad29336f507a3ae3--213cd778a17b4d909df501a8e120d467 5f02fcdb226043e0b883208e07157727 213cd778a17b4d909df501a8e120d467--5f02fcdb226043e0b883208e07157727 cf7e253d238b43afa03e813098c659a8 5f02fcdb226043e0b883208e07157727--cf7e253d238b43afa03e813098c659a8 538951553e9b4972a6e37a939d26c687 X cf7e253d238b43afa03e813098c659a8--538951553e9b4972a6e37a939d26c687 538951553e9b4972a6e37a939d26c687--df1f2801b5c1476482a5b8b9f016e4f2 c50a07739bc34fe48ff01794df494f95 538951553e9b4972a6e37a939d26c687--c50a07739bc34fe48ff01794df494f95 c2956d7855114b7ca4b98665ce8f414e c50a07739bc34fe48ff01794df494f95--c2956d7855114b7ca4b98665ce8f414e 0a26dab2f5e34fbfbdd38dce7b7a418e c2956d7855114b7ca4b98665ce8f414e--0a26dab2f5e34fbfbdd38dce7b7a418e 28bfb5709442438fa9d268b5c4e45f03 0a26dab2f5e34fbfbdd38dce7b7a418e--28bfb5709442438fa9d268b5c4e45f03 8d233be09ec04c028090eaa23b93d720 28bfb5709442438fa9d268b5c4e45f03--8d233be09ec04c028090eaa23b93d720 d6d9ccebe0a24084a963ca287cec2461 X 8d233be09ec04c028090eaa23b93d720--d6d9ccebe0a24084a963ca287cec2461 d6d9ccebe0a24084a963ca287cec2461--f927de0843be4370bb2dffb05937dd69 b171ecb4eb0e46978589eadc761b0f8b d6d9ccebe0a24084a963ca287cec2461--b171ecb4eb0e46978589eadc761b0f8b 15cd9cef9326490cac5d29870fb59695 b171ecb4eb0e46978589eadc761b0f8b--15cd9cef9326490cac5d29870fb59695 4ec77ef8fa4b4e88b8e8ae6c59349396 15cd9cef9326490cac5d29870fb59695--4ec77ef8fa4b4e88b8e8ae6c59349396 b3f52b2ea6ca4c9f909a99164b8cd6e7 X 4ec77ef8fa4b4e88b8e8ae6c59349396--b3f52b2ea6ca4c9f909a99164b8cd6e7 b3f52b2ea6ca4c9f909a99164b8cd6e7--ed2181c143a54579b597070d8f91952b 99981e046fe34331a7bdf4ccdde58c69 X b3f52b2ea6ca4c9f909a99164b8cd6e7--99981e046fe34331a7bdf4ccdde58c69 99981e046fe34331a7bdf4ccdde58c69--e8704877d9054352abcaff68ade1da20 6649fcf5104e45c2aee9816646ad7afd 99981e046fe34331a7bdf4ccdde58c69--6649fcf5104e45c2aee9816646ad7afd 4ff6285321694edb9308deebd6cfe41d 6649fcf5104e45c2aee9816646ad7afd--4ff6285321694edb9308deebd6cfe41d f8f4a74c410f41b3ae3e54996360cc6f 4ff6285321694edb9308deebd6cfe41d--f8f4a74c410f41b3ae3e54996360cc6f 777e4559f54c4e3ea959dd38d3ce4e1a f8f4a74c410f41b3ae3e54996360cc6f--777e4559f54c4e3ea959dd38d3ce4e1a 012179d7c8a4458e94d90df6b67e50ac 777e4559f54c4e3ea959dd38d3ce4e1a--012179d7c8a4458e94d90df6b67e50ac f847af817c4e40b981e00e1ec9872c39 X 012179d7c8a4458e94d90df6b67e50ac--f847af817c4e40b981e00e1ec9872c39 f847af817c4e40b981e00e1ec9872c39--c9abeec82bfe4b879abb75f4e804d254 35a24986161343729ab4dda8c379a95c f847af817c4e40b981e00e1ec9872c39--35a24986161343729ab4dda8c379a95c 7d61cf2b73794bfbb78f7900e7c8364c 35a24986161343729ab4dda8c379a95c--7d61cf2b73794bfbb78f7900e7c8364c 0e6b6cd4cf59460496b31a9efa28ab5f 7d61cf2b73794bfbb78f7900e7c8364c--0e6b6cd4cf59460496b31a9efa28ab5f c0e2a562a0d34a3d8210740d97ff73c5 0e6b6cd4cf59460496b31a9efa28ab5f--c0e2a562a0d34a3d8210740d97ff73c5 ff0ae88b7e424c87adecf7774a4bbc1b c0e2a562a0d34a3d8210740d97ff73c5--ff0ae88b7e424c87adecf7774a4bbc1b 316f92c38b164b60872bb1b17b5679a9 ff0ae88b7e424c87adecf7774a4bbc1b--316f92c38b164b60872bb1b17b5679a9 33eae793c60344ecb741e13aa52fbe13 316f92c38b164b60872bb1b17b5679a9--33eae793c60344ecb741e13aa52fbe13 8b2b0f27c67442c8b50d1e7b2b6e6679 33eae793c60344ecb741e13aa52fbe13--8b2b0f27c67442c8b50d1e7b2b6e6679 e721b5607996497784e443f1249f93cb 8b2b0f27c67442c8b50d1e7b2b6e6679--e721b5607996497784e443f1249f93cb 7395da4c3ae14260a068193cab968624 e721b5607996497784e443f1249f93cb--7395da4c3ae14260a068193cab968624 d8b5263918e84674a06f7280dd2d5b3d 7395da4c3ae14260a068193cab968624--d8b5263918e84674a06f7280dd2d5b3d 18fe899754c2436abce88f4876a6fb1e RX(b15) d8b5263918e84674a06f7280dd2d5b3d--18fe899754c2436abce88f4876a6fb1e 18fe899754c2436abce88f4876a6fb1e--853f0ebb7b1041fa85cbcf7714a75760 c07740f9abfa4854bdb375698b271e64 81a33967962444b3b7b9741d42019208 72181956eda543a79d2121bc01946886--81a33967962444b3b7b9741d42019208 8afcfa29983d4b08b4f94a6b11712827 7 074ced654e2a4fd1848c42bd486783d1 81a33967962444b3b7b9741d42019208--074ced654e2a4fd1848c42bd486783d1 1b7e8273d58342e3b7e483af0a5902c2 074ced654e2a4fd1848c42bd486783d1--1b7e8273d58342e3b7e483af0a5902c2 06c566fbf63e42cf85c6b2be7236e661 1b7e8273d58342e3b7e483af0a5902c2--06c566fbf63e42cf85c6b2be7236e661 cb2e1c225008430489e03e15acb70069 06c566fbf63e42cf85c6b2be7236e661--cb2e1c225008430489e03e15acb70069 ff7dd4c691284a9e8384dc1124628e2b X cb2e1c225008430489e03e15acb70069--ff7dd4c691284a9e8384dc1124628e2b ff7dd4c691284a9e8384dc1124628e2b--56f6569ad2c74cf1b27fd7e6cb1b7ae6 68d8f44259584af09ef2229c5fc1b724 ff7dd4c691284a9e8384dc1124628e2b--68d8f44259584af09ef2229c5fc1b724 8e8ae77eddc94b9792d388ba9b48b7ab 68d8f44259584af09ef2229c5fc1b724--8e8ae77eddc94b9792d388ba9b48b7ab 64b1fd5b1f1c45af97d2430a9cdc286a 8e8ae77eddc94b9792d388ba9b48b7ab--64b1fd5b1f1c45af97d2430a9cdc286a 028ef4a64ece41b68855cb875cfd5039 X 64b1fd5b1f1c45af97d2430a9cdc286a--028ef4a64ece41b68855cb875cfd5039 028ef4a64ece41b68855cb875cfd5039--f824373c63ef424f827e028b133db8fa b16e7d4d214a4f5180ab0711fb4443a3 028ef4a64ece41b68855cb875cfd5039--b16e7d4d214a4f5180ab0711fb4443a3 ef623f42a63a44b09b69d8b9bbad9e2e b16e7d4d214a4f5180ab0711fb4443a3--ef623f42a63a44b09b69d8b9bbad9e2e db71663889724178b8a578028a763d88 ef623f42a63a44b09b69d8b9bbad9e2e--db71663889724178b8a578028a763d88 43f31da0a17c42c4be910b14c663ac16 db71663889724178b8a578028a763d88--43f31da0a17c42c4be910b14c663ac16 f883dd78a0b5426891e05b2615d29ede 43f31da0a17c42c4be910b14c663ac16--f883dd78a0b5426891e05b2615d29ede 88a8f527e39c4ef0b3a7d0245e52de6b f883dd78a0b5426891e05b2615d29ede--88a8f527e39c4ef0b3a7d0245e52de6b 876f3345ba4342e8ad707bf3e67b0708 88a8f527e39c4ef0b3a7d0245e52de6b--876f3345ba4342e8ad707bf3e67b0708 5ec0095a674b494eb2dd59411940ff21 876f3345ba4342e8ad707bf3e67b0708--5ec0095a674b494eb2dd59411940ff21 a682572adc034260a2e9fcfca241a882 5ec0095a674b494eb2dd59411940ff21--a682572adc034260a2e9fcfca241a882 50adffba0f5e4dc09cf76f4e78584cc2 a682572adc034260a2e9fcfca241a882--50adffba0f5e4dc09cf76f4e78584cc2 8d5b69e15abd4246a466b033930dbdca 50adffba0f5e4dc09cf76f4e78584cc2--8d5b69e15abd4246a466b033930dbdca 27904936789343b5a32ed9af670948e1 8d5b69e15abd4246a466b033930dbdca--27904936789343b5a32ed9af670948e1 06af4b0a5d0842b4940fe0439c4cba24 27904936789343b5a32ed9af670948e1--06af4b0a5d0842b4940fe0439c4cba24 593f004e409b4571ade42d63d106bf7a 06af4b0a5d0842b4940fe0439c4cba24--593f004e409b4571ade42d63d106bf7a 4c38daae544c4189b10210a612f89b38 593f004e409b4571ade42d63d106bf7a--4c38daae544c4189b10210a612f89b38 95290d847f8a4f7ba3014d330f90d24e 4c38daae544c4189b10210a612f89b38--95290d847f8a4f7ba3014d330f90d24e ff736bad17a84a58889dc60635b89a4f 95290d847f8a4f7ba3014d330f90d24e--ff736bad17a84a58889dc60635b89a4f 77980cd0174746eb953c9a45f262090b ff736bad17a84a58889dc60635b89a4f--77980cd0174746eb953c9a45f262090b 54cdf1279b8e44f2a8071444ea6face9 77980cd0174746eb953c9a45f262090b--54cdf1279b8e44f2a8071444ea6face9 3e1eaea627b9428291ccb0fde5d7db1b 54cdf1279b8e44f2a8071444ea6face9--3e1eaea627b9428291ccb0fde5d7db1b 1a39b6ca64bd4df58b3fc9feed183a85 3e1eaea627b9428291ccb0fde5d7db1b--1a39b6ca64bd4df58b3fc9feed183a85 be26f4ec4e8f4dc98752455eaa5f0f17 1a39b6ca64bd4df58b3fc9feed183a85--be26f4ec4e8f4dc98752455eaa5f0f17 d1beeb65b5cc43fe84cdf3d6a1b6cda3 be26f4ec4e8f4dc98752455eaa5f0f17--d1beeb65b5cc43fe84cdf3d6a1b6cda3 e08fad4616be4e05bfb02b08374dbadb d1beeb65b5cc43fe84cdf3d6a1b6cda3--e08fad4616be4e05bfb02b08374dbadb e1dd66b75bc84f1f9f6c829cfce44a9a e08fad4616be4e05bfb02b08374dbadb--e1dd66b75bc84f1f9f6c829cfce44a9a f5190608245741bf968ca65e694bbfae e1dd66b75bc84f1f9f6c829cfce44a9a--f5190608245741bf968ca65e694bbfae cb8271a0d39e4e919e306a19dd252e2e f5190608245741bf968ca65e694bbfae--cb8271a0d39e4e919e306a19dd252e2e 95a345fd11424747be63b1e62a2a12fd cb8271a0d39e4e919e306a19dd252e2e--95a345fd11424747be63b1e62a2a12fd 0ee14d62e89a4142a05a9146fb6de555 95a345fd11424747be63b1e62a2a12fd--0ee14d62e89a4142a05a9146fb6de555 4789421e2f534e83baa0fbfbf752abc1 0ee14d62e89a4142a05a9146fb6de555--4789421e2f534e83baa0fbfbf752abc1 33b34ec37caf4c3eb595eea6553bf0a9 4789421e2f534e83baa0fbfbf752abc1--33b34ec37caf4c3eb595eea6553bf0a9 ccd6baf35c9a4528bf16ac19f7d94b08 33b34ec37caf4c3eb595eea6553bf0a9--ccd6baf35c9a4528bf16ac19f7d94b08 1591d3a753754279b048e28cbcab2e2f ccd6baf35c9a4528bf16ac19f7d94b08--1591d3a753754279b048e28cbcab2e2f 16b26fbd954c45be8993fdcea54e369c 1591d3a753754279b048e28cbcab2e2f--16b26fbd954c45be8993fdcea54e369c a6270bf2ba314e4390c4e0f519bee062 16b26fbd954c45be8993fdcea54e369c--a6270bf2ba314e4390c4e0f519bee062 667bb27645a643649cb6f7d03c988836 a6270bf2ba314e4390c4e0f519bee062--667bb27645a643649cb6f7d03c988836 396f34b7a1fb4c50a57f2dae69d6b700 667bb27645a643649cb6f7d03c988836--396f34b7a1fb4c50a57f2dae69d6b700 331f15c4fe494ebdb66489f039464243 396f34b7a1fb4c50a57f2dae69d6b700--331f15c4fe494ebdb66489f039464243 ef9e61c4a9cc47e39e85ade9fe679796 X 331f15c4fe494ebdb66489f039464243--ef9e61c4a9cc47e39e85ade9fe679796 ef9e61c4a9cc47e39e85ade9fe679796--8d386e0b9677403a90bd540fdd4fa5ba 9efb5e547d754e0389faab612f398989 ef9e61c4a9cc47e39e85ade9fe679796--9efb5e547d754e0389faab612f398989 8355a7bf4972423c863ada0d5cf610d3 9efb5e547d754e0389faab612f398989--8355a7bf4972423c863ada0d5cf610d3 d98e1669cb0541feb523fd1d64baac70 8355a7bf4972423c863ada0d5cf610d3--d98e1669cb0541feb523fd1d64baac70 696bb5ebc75e4d81932def704da55afb X d98e1669cb0541feb523fd1d64baac70--696bb5ebc75e4d81932def704da55afb 696bb5ebc75e4d81932def704da55afb--a87ee1fd9acc490ab97654994ad7a726 882e694afa864dcb925c30979cc79cc0 696bb5ebc75e4d81932def704da55afb--882e694afa864dcb925c30979cc79cc0 070e970ba0814b61b1348eba49e9dac8 882e694afa864dcb925c30979cc79cc0--070e970ba0814b61b1348eba49e9dac8 ac34cc1d5a3546d3ba81e8101458c501 070e970ba0814b61b1348eba49e9dac8--ac34cc1d5a3546d3ba81e8101458c501 6bf66e45cd8b46e4a478a0eadf258ffc ac34cc1d5a3546d3ba81e8101458c501--6bf66e45cd8b46e4a478a0eadf258ffc 049edcf1fc884f6ebc1125b3cd0a6115 6bf66e45cd8b46e4a478a0eadf258ffc--049edcf1fc884f6ebc1125b3cd0a6115 e5b4e4a5481342718bb4560e73062889 049edcf1fc884f6ebc1125b3cd0a6115--e5b4e4a5481342718bb4560e73062889 4bf517aa507440ab90437c31a613c29d e5b4e4a5481342718bb4560e73062889--4bf517aa507440ab90437c31a613c29d 6f14ab93d4184ffe80b58df0464bb90c 4bf517aa507440ab90437c31a613c29d--6f14ab93d4184ffe80b58df0464bb90c e5dca7d30f81448b8d185794c7065579 6f14ab93d4184ffe80b58df0464bb90c--e5dca7d30f81448b8d185794c7065579 3d173d7784ed461f8bd9c569ab633334 e5dca7d30f81448b8d185794c7065579--3d173d7784ed461f8bd9c569ab633334 96899febc35f4630b3c0468a911563e7 3d173d7784ed461f8bd9c569ab633334--96899febc35f4630b3c0468a911563e7 ba4cfee4ec3d4a66ace5ba87b9cd24e6 96899febc35f4630b3c0468a911563e7--ba4cfee4ec3d4a66ace5ba87b9cd24e6 3414f964b7fc43b8ae6248234d9b930b ba4cfee4ec3d4a66ace5ba87b9cd24e6--3414f964b7fc43b8ae6248234d9b930b 57829b8767df4581a5df1ad26055496a 3414f964b7fc43b8ae6248234d9b930b--57829b8767df4581a5df1ad26055496a 8e169ff04e8d424c8e02c3b0f8fa116a 57829b8767df4581a5df1ad26055496a--8e169ff04e8d424c8e02c3b0f8fa116a d6f8065eae0046b58748eb0b93f949c0 8e169ff04e8d424c8e02c3b0f8fa116a--d6f8065eae0046b58748eb0b93f949c0 8bf64a9b132e41d6bf49531cf45966ae d6f8065eae0046b58748eb0b93f949c0--8bf64a9b132e41d6bf49531cf45966ae e88f1eca946f44b096716dff1a39d30e 8bf64a9b132e41d6bf49531cf45966ae--e88f1eca946f44b096716dff1a39d30e 2f3c1f1b3146487ca4ff3c3d8fda7e77 e88f1eca946f44b096716dff1a39d30e--2f3c1f1b3146487ca4ff3c3d8fda7e77 7909e99f919d4c538d5a838918a16c80 2f3c1f1b3146487ca4ff3c3d8fda7e77--7909e99f919d4c538d5a838918a16c80 a1bbddcc918b4d46ac78ce7356d0abeb 7909e99f919d4c538d5a838918a16c80--a1bbddcc918b4d46ac78ce7356d0abeb d02a3f66c3a54975b77c3e9f921434dd a1bbddcc918b4d46ac78ce7356d0abeb--d02a3f66c3a54975b77c3e9f921434dd d5cab8da68ca48aca11b7ca7faf516fd d02a3f66c3a54975b77c3e9f921434dd--d5cab8da68ca48aca11b7ca7faf516fd 17622147851541dfbafac041f5de3332 d5cab8da68ca48aca11b7ca7faf516fd--17622147851541dfbafac041f5de3332 e2bedac636814d41ada520b308ce8f51 17622147851541dfbafac041f5de3332--e2bedac636814d41ada520b308ce8f51 d35435e778764008a3a920f2f9527178 e2bedac636814d41ada520b308ce8f51--d35435e778764008a3a920f2f9527178 ee378b5db5424da5adb7b64d0bf5df67 d35435e778764008a3a920f2f9527178--ee378b5db5424da5adb7b64d0bf5df67 d83b2ec45feb41f7a4caf2660b31b9fa ee378b5db5424da5adb7b64d0bf5df67--d83b2ec45feb41f7a4caf2660b31b9fa e67f029d605f4422ac169e1fda1043b7 d83b2ec45feb41f7a4caf2660b31b9fa--e67f029d605f4422ac169e1fda1043b7 1fd4a6dda24445328f1f0b5e822d1f3e e67f029d605f4422ac169e1fda1043b7--1fd4a6dda24445328f1f0b5e822d1f3e 48a5400188764819865687e42a9fb8cb 1fd4a6dda24445328f1f0b5e822d1f3e--48a5400188764819865687e42a9fb8cb fe3e6de4b6a84ba78dd313edabc8e5fe 48a5400188764819865687e42a9fb8cb--fe3e6de4b6a84ba78dd313edabc8e5fe c6b686d7e0e64773a9d8d44052efd80d fe3e6de4b6a84ba78dd313edabc8e5fe--c6b686d7e0e64773a9d8d44052efd80d 9ac0204e77124c80843181d6fc1091d8 X c6b686d7e0e64773a9d8d44052efd80d--9ac0204e77124c80843181d6fc1091d8 9ac0204e77124c80843181d6fc1091d8--3a8e8439186e4007887a7cb597232eb7 9bdeeb6eb2c847a88ec2438cecfedcf8 RZ(-1.0*g0) 9ac0204e77124c80843181d6fc1091d8--9bdeeb6eb2c847a88ec2438cecfedcf8 e8555f9c64544e818ebecf4a78165e27 X 9bdeeb6eb2c847a88ec2438cecfedcf8--e8555f9c64544e818ebecf4a78165e27 e8555f9c64544e818ebecf4a78165e27--ecb6c306fb2e4270a389852ddae50675 966a6f86cd7a4dd7a0a6c9e1a1a43698 e8555f9c64544e818ebecf4a78165e27--966a6f86cd7a4dd7a0a6c9e1a1a43698 ad4ff0b9b09c4d22b9a3d9738971a360 966a6f86cd7a4dd7a0a6c9e1a1a43698--ad4ff0b9b09c4d22b9a3d9738971a360 7f0fc15902304a22b68e3a80ccf4307e ad4ff0b9b09c4d22b9a3d9738971a360--7f0fc15902304a22b68e3a80ccf4307e 98c628bc5ba447dda4a22e1a7e10385d 7f0fc15902304a22b68e3a80ccf4307e--98c628bc5ba447dda4a22e1a7e10385d c42785e944cc4f8fb26f9dd703393124 98c628bc5ba447dda4a22e1a7e10385d--c42785e944cc4f8fb26f9dd703393124 5cc31165f06f4caeadb5042c7ffd60ea c42785e944cc4f8fb26f9dd703393124--5cc31165f06f4caeadb5042c7ffd60ea 8f5b72a2aef649509d710cc390cf2546 5cc31165f06f4caeadb5042c7ffd60ea--8f5b72a2aef649509d710cc390cf2546 4759736b2a4a41649ecb005f506256e1 8f5b72a2aef649509d710cc390cf2546--4759736b2a4a41649ecb005f506256e1 6eaf51b8ad3b41f2b619539c2009eecb X 4759736b2a4a41649ecb005f506256e1--6eaf51b8ad3b41f2b619539c2009eecb 6eaf51b8ad3b41f2b619539c2009eecb--39406275b90c45fc9dada5b341e48ba2 4253a5d2a64a4021aed7968673d11ab1 6eaf51b8ad3b41f2b619539c2009eecb--4253a5d2a64a4021aed7968673d11ab1 336b82ad7d28417999bea47d70dd99c0 4253a5d2a64a4021aed7968673d11ab1--336b82ad7d28417999bea47d70dd99c0 0ee385bda5e54dfebc61bd650afc022f 336b82ad7d28417999bea47d70dd99c0--0ee385bda5e54dfebc61bd650afc022f 38ff8566eebf45549b422cbf32ab45d1 X 0ee385bda5e54dfebc61bd650afc022f--38ff8566eebf45549b422cbf32ab45d1 38ff8566eebf45549b422cbf32ab45d1--c7c2a6a01f71437a9da42f18ddda89d4 97fb6a017f4944c3a4d1b01dadb8ff8f 38ff8566eebf45549b422cbf32ab45d1--97fb6a017f4944c3a4d1b01dadb8ff8f f8133a801fa542999d33760561630b69 97fb6a017f4944c3a4d1b01dadb8ff8f--f8133a801fa542999d33760561630b69 9d394e16a82c4d9cb99429fc8a5f59e0 f8133a801fa542999d33760561630b69--9d394e16a82c4d9cb99429fc8a5f59e0 0dd75629494a468c8245e2dcee68bf34 9d394e16a82c4d9cb99429fc8a5f59e0--0dd75629494a468c8245e2dcee68bf34 5c213f74a9c14971b1b24c8f6915219b 0dd75629494a468c8245e2dcee68bf34--5c213f74a9c14971b1b24c8f6915219b 3e6c8542bb2d49d2a9b3d43c79072463 5c213f74a9c14971b1b24c8f6915219b--3e6c8542bb2d49d2a9b3d43c79072463 00bd15c67af840f98b1c615c535e9206 3e6c8542bb2d49d2a9b3d43c79072463--00bd15c67af840f98b1c615c535e9206 d54adcfe94f541e7af10596de96f0ef9 00bd15c67af840f98b1c615c535e9206--d54adcfe94f541e7af10596de96f0ef9 0800d506921b4e97a78c074b852e4dfb d54adcfe94f541e7af10596de96f0ef9--0800d506921b4e97a78c074b852e4dfb f8fd564f78414e8881d71f084e764168 0800d506921b4e97a78c074b852e4dfb--f8fd564f78414e8881d71f084e764168 2857134e08e1405f8b7f47598e00e6d4 f8fd564f78414e8881d71f084e764168--2857134e08e1405f8b7f47598e00e6d4 be2fd7738bd542fcae56951da5d1914b 2857134e08e1405f8b7f47598e00e6d4--be2fd7738bd542fcae56951da5d1914b d3bc4bc3c7ae47e69db9a963bde35a83 be2fd7738bd542fcae56951da5d1914b--d3bc4bc3c7ae47e69db9a963bde35a83 11826fcc3def4524803317ecc2a8c72e d3bc4bc3c7ae47e69db9a963bde35a83--11826fcc3def4524803317ecc2a8c72e bdc7402468824c8eb1b5337628f696be 11826fcc3def4524803317ecc2a8c72e--bdc7402468824c8eb1b5337628f696be 6adc2837f2494fd7a282cf5400d536bd bdc7402468824c8eb1b5337628f696be--6adc2837f2494fd7a282cf5400d536bd 680188859ce9458bbc55422577b29a4a 6adc2837f2494fd7a282cf5400d536bd--680188859ce9458bbc55422577b29a4a 92c298664f8e4452948c5a82a97950f1 X 680188859ce9458bbc55422577b29a4a--92c298664f8e4452948c5a82a97950f1 92c298664f8e4452948c5a82a97950f1--fdc9923f29f040da83dfa53d73bdae4c 5a0a879c871844f39fa5bbd240ddc44e RZ(-1.0*g0) 92c298664f8e4452948c5a82a97950f1--5a0a879c871844f39fa5bbd240ddc44e 0db226d5b50c432c9a69f264df20656c X 5a0a879c871844f39fa5bbd240ddc44e--0db226d5b50c432c9a69f264df20656c 0db226d5b50c432c9a69f264df20656c--30f53f348c7c445185f8acae24d09f67 6ad4380f1bc54a80a3f8316592b48819 0db226d5b50c432c9a69f264df20656c--6ad4380f1bc54a80a3f8316592b48819 25a5592ddd984069ac1ee116f502097d 6ad4380f1bc54a80a3f8316592b48819--25a5592ddd984069ac1ee116f502097d cf8e86db94a64b7aae6980af52b43e91 25a5592ddd984069ac1ee116f502097d--cf8e86db94a64b7aae6980af52b43e91 c1d4bb335ce247f69fb2ff8dee279cdf cf8e86db94a64b7aae6980af52b43e91--c1d4bb335ce247f69fb2ff8dee279cdf 3fb839b9a9774b97a4fe231ceff84a39 c1d4bb335ce247f69fb2ff8dee279cdf--3fb839b9a9774b97a4fe231ceff84a39 8af8a3ae413d4fdab7af6e5aa40f7f75 3fb839b9a9774b97a4fe231ceff84a39--8af8a3ae413d4fdab7af6e5aa40f7f75 5a194e0cafe3405d911eb13c8ce7d033 8af8a3ae413d4fdab7af6e5aa40f7f75--5a194e0cafe3405d911eb13c8ce7d033 643340db90bd43c1ab199d8d6e9b68e5 X 5a194e0cafe3405d911eb13c8ce7d033--643340db90bd43c1ab199d8d6e9b68e5 643340db90bd43c1ab199d8d6e9b68e5--b6a31bd10892487aad0350d277af515a 5f23cbec60be467d9f7469024ef6e867 RZ(-1.0*g0) 643340db90bd43c1ab199d8d6e9b68e5--5f23cbec60be467d9f7469024ef6e867 72703b96240843cb970513886b8604fd X 5f23cbec60be467d9f7469024ef6e867--72703b96240843cb970513886b8604fd 72703b96240843cb970513886b8604fd--1a89635a54dc452ca4453f760efda1b4 e0781e348dcb4d1b89648ab76d0cac1a 72703b96240843cb970513886b8604fd--e0781e348dcb4d1b89648ab76d0cac1a 28d154b2fa864a8eb456e0b092c990e2 e0781e348dcb4d1b89648ab76d0cac1a--28d154b2fa864a8eb456e0b092c990e2 85acb493fde347c4b8994995ff7de0bb X 28d154b2fa864a8eb456e0b092c990e2--85acb493fde347c4b8994995ff7de0bb 85acb493fde347c4b8994995ff7de0bb--12eac605225545f99b279272b373ce6a 290eed4567754d8b95d5e93f9a7cc61c 85acb493fde347c4b8994995ff7de0bb--290eed4567754d8b95d5e93f9a7cc61c 4eca06bfbc6543aab4e779931e834249 290eed4567754d8b95d5e93f9a7cc61c--4eca06bfbc6543aab4e779931e834249 b98e7a324a9d41049b4ab0828cdfd53a 4eca06bfbc6543aab4e779931e834249--b98e7a324a9d41049b4ab0828cdfd53a ca4badb62bf945c388f90ee0fa0cd085 X b98e7a324a9d41049b4ab0828cdfd53a--ca4badb62bf945c388f90ee0fa0cd085 ca4badb62bf945c388f90ee0fa0cd085--5cc8fca9945244ee926e602c54faa2f0 db351f104ee8428d99e209ef33d25160 ca4badb62bf945c388f90ee0fa0cd085--db351f104ee8428d99e209ef33d25160 910d649ccdc34502aa6c9730af02020d X db351f104ee8428d99e209ef33d25160--910d649ccdc34502aa6c9730af02020d 910d649ccdc34502aa6c9730af02020d--80522de18b194714bfce0892543660f8 e68b6195a6524f8a860b384249dcd1f1 RZ(-1.0*g0) 910d649ccdc34502aa6c9730af02020d--e68b6195a6524f8a860b384249dcd1f1 a0111836654041c887c535a860aa3c8a X e68b6195a6524f8a860b384249dcd1f1--a0111836654041c887c535a860aa3c8a a0111836654041c887c535a860aa3c8a--5f19be98994746f5919cbb296cdcb768 757e4aba130b4906989ef39880a85749 X a0111836654041c887c535a860aa3c8a--757e4aba130b4906989ef39880a85749 757e4aba130b4906989ef39880a85749--5a3c3113c3e74ef7a46d52121b785ebe f0a64d8ba3964875943fee34f78308af 757e4aba130b4906989ef39880a85749--f0a64d8ba3964875943fee34f78308af d541fd661f1e46d9972ba17f7900281e f0a64d8ba3964875943fee34f78308af--d541fd661f1e46d9972ba17f7900281e 9d5db366c10f4915825b881afebcaf21 d541fd661f1e46d9972ba17f7900281e--9d5db366c10f4915825b881afebcaf21 c9826d806a734256afac75b622f082cf X 9d5db366c10f4915825b881afebcaf21--c9826d806a734256afac75b622f082cf c9826d806a734256afac75b622f082cf--b4ab316ff9d0422c9d17f8590a5ecdc0 2b2ce258912045f09483e91a2ad87539 c9826d806a734256afac75b622f082cf--2b2ce258912045f09483e91a2ad87539 9fbebc17b83e4786afe77910494cfc81 2b2ce258912045f09483e91a2ad87539--9fbebc17b83e4786afe77910494cfc81 099ca2a62a0046a6afc6f5f3f0530f49 9fbebc17b83e4786afe77910494cfc81--099ca2a62a0046a6afc6f5f3f0530f49 ed13c42a2f3a47508108e260a61077a2 RX(b06) 099ca2a62a0046a6afc6f5f3f0530f49--ed13c42a2f3a47508108e260a61077a2 f4e3be8cd8484ad79db0e0d506d7b752 ed13c42a2f3a47508108e260a61077a2--f4e3be8cd8484ad79db0e0d506d7b752 bb8eccf5887b407193316bc14260cbca f4e3be8cd8484ad79db0e0d506d7b752--bb8eccf5887b407193316bc14260cbca 9bddbbf14f064f638d40fc5f82088353 bb8eccf5887b407193316bc14260cbca--9bddbbf14f064f638d40fc5f82088353 b719e6180389446bb124c0ba0688ed2c 9bddbbf14f064f638d40fc5f82088353--b719e6180389446bb124c0ba0688ed2c 5b6f3d53a838493d991dc9725c435a1f b719e6180389446bb124c0ba0688ed2c--5b6f3d53a838493d991dc9725c435a1f 2ab14c346bee45ec898822ccb08d105d X 5b6f3d53a838493d991dc9725c435a1f--2ab14c346bee45ec898822ccb08d105d 2ab14c346bee45ec898822ccb08d105d--d9ea344861914ef084294a96106617c3 3473bb2d6370477789819ae655295f34 2ab14c346bee45ec898822ccb08d105d--3473bb2d6370477789819ae655295f34 3d01dbc6695e4a5ca4f7824e7600f4fb 3473bb2d6370477789819ae655295f34--3d01dbc6695e4a5ca4f7824e7600f4fb 688023448dd1493da79fc00d22ce7bbc 3d01dbc6695e4a5ca4f7824e7600f4fb--688023448dd1493da79fc00d22ce7bbc 452ed92b61c241d68545eccd3fd54da9 X 688023448dd1493da79fc00d22ce7bbc--452ed92b61c241d68545eccd3fd54da9 452ed92b61c241d68545eccd3fd54da9--d7558069b2094b3f967b8714f2114f0b 127cd54efbbd49c180a625e345ec1801 452ed92b61c241d68545eccd3fd54da9--127cd54efbbd49c180a625e345ec1801 5ffe115db82c4886928a8f10e94a643a 127cd54efbbd49c180a625e345ec1801--5ffe115db82c4886928a8f10e94a643a 045ab794ae4d4371a269c8cc396032a3 5ffe115db82c4886928a8f10e94a643a--045ab794ae4d4371a269c8cc396032a3 2a16c443ac444069b7390404732117f4 045ab794ae4d4371a269c8cc396032a3--2a16c443ac444069b7390404732117f4 ca626d1421c74e29af5c0f6313974a9c 2a16c443ac444069b7390404732117f4--ca626d1421c74e29af5c0f6313974a9c 3813e8ca91884a33b1ae1df2c9c47945 ca626d1421c74e29af5c0f6313974a9c--3813e8ca91884a33b1ae1df2c9c47945 4d12947275104be59e22ae7dbabfc5dd 3813e8ca91884a33b1ae1df2c9c47945--4d12947275104be59e22ae7dbabfc5dd 32f74216c8154fb090485ca2a12ca4ac 4d12947275104be59e22ae7dbabfc5dd--32f74216c8154fb090485ca2a12ca4ac 1f6a08e0197142158e09ce25ddda3c1b 32f74216c8154fb090485ca2a12ca4ac--1f6a08e0197142158e09ce25ddda3c1b 92cebfe0e0444eecad5cf3d6f3ea83fc 1f6a08e0197142158e09ce25ddda3c1b--92cebfe0e0444eecad5cf3d6f3ea83fc 2f701e5114b54e5194eae02d36fdf1fd 92cebfe0e0444eecad5cf3d6f3ea83fc--2f701e5114b54e5194eae02d36fdf1fd 77a08bb5820142f48d837b770687e6a6 2f701e5114b54e5194eae02d36fdf1fd--77a08bb5820142f48d837b770687e6a6 03690f27ece64acdb4c2e5aab95b3575 77a08bb5820142f48d837b770687e6a6--03690f27ece64acdb4c2e5aab95b3575 d734db10163f4dd29bab4ad916f8b377 03690f27ece64acdb4c2e5aab95b3575--d734db10163f4dd29bab4ad916f8b377 21513d503f924bccb772041db5c91d51 d734db10163f4dd29bab4ad916f8b377--21513d503f924bccb772041db5c91d51 408730d0c10249b1bca3f9f9796cf4d0 21513d503f924bccb772041db5c91d51--408730d0c10249b1bca3f9f9796cf4d0 39a3edac49144bc3bef7d95b3472aea5 408730d0c10249b1bca3f9f9796cf4d0--39a3edac49144bc3bef7d95b3472aea5 1acc496c02f9406c9c2fa53bab9dc19a 39a3edac49144bc3bef7d95b3472aea5--1acc496c02f9406c9c2fa53bab9dc19a a8688433b2ec41838c73fb1a91279405 1acc496c02f9406c9c2fa53bab9dc19a--a8688433b2ec41838c73fb1a91279405 cffc9dbdce424d8fabb1ab3665f96bec a8688433b2ec41838c73fb1a91279405--cffc9dbdce424d8fabb1ab3665f96bec b1126e30d42c47bebe43fb9f34cda37a cffc9dbdce424d8fabb1ab3665f96bec--b1126e30d42c47bebe43fb9f34cda37a 4a6d411ab653401ba11365e7f6dac54f b1126e30d42c47bebe43fb9f34cda37a--4a6d411ab653401ba11365e7f6dac54f 9d3fc2e8d895455e94738e35b8be90c6 4a6d411ab653401ba11365e7f6dac54f--9d3fc2e8d895455e94738e35b8be90c6 dc698310a5de41359c40a1e5789f4081 9d3fc2e8d895455e94738e35b8be90c6--dc698310a5de41359c40a1e5789f4081 d4f1dc571a754ae6a34b1f7ca9058e33 dc698310a5de41359c40a1e5789f4081--d4f1dc571a754ae6a34b1f7ca9058e33 cd1eb61ea2ec4ae98f1374f8aa07ba7b d4f1dc571a754ae6a34b1f7ca9058e33--cd1eb61ea2ec4ae98f1374f8aa07ba7b 4a589acb237449e49932ae53fd653076 cd1eb61ea2ec4ae98f1374f8aa07ba7b--4a589acb237449e49932ae53fd653076 4ece241790bc47adae7f9c2e6b5e6a1d 4a589acb237449e49932ae53fd653076--4ece241790bc47adae7f9c2e6b5e6a1d 3959a38a78644fc19ae0aec118750e8d 4ece241790bc47adae7f9c2e6b5e6a1d--3959a38a78644fc19ae0aec118750e8d b0685b56df114818b920815d5396d538 3959a38a78644fc19ae0aec118750e8d--b0685b56df114818b920815d5396d538 ec03a0aaf7a5428ba3f39c62d66914c8 b0685b56df114818b920815d5396d538--ec03a0aaf7a5428ba3f39c62d66914c8 d1a283d3af5949cbad591bc136302c8c ec03a0aaf7a5428ba3f39c62d66914c8--d1a283d3af5949cbad591bc136302c8c f0aa70ed3a424a408296e1a6b7fcb6c1 d1a283d3af5949cbad591bc136302c8c--f0aa70ed3a424a408296e1a6b7fcb6c1 c08e6d6d62e94d96ac238680b64e5052 f0aa70ed3a424a408296e1a6b7fcb6c1--c08e6d6d62e94d96ac238680b64e5052 21097bca549249e686141ff7c1997c89 c08e6d6d62e94d96ac238680b64e5052--21097bca549249e686141ff7c1997c89 4ca1d439f9ad45f69cdf3d5bf025a5a1 21097bca549249e686141ff7c1997c89--4ca1d439f9ad45f69cdf3d5bf025a5a1 9027552d3ec44f0e87f86b2ce3eddf71 4ca1d439f9ad45f69cdf3d5bf025a5a1--9027552d3ec44f0e87f86b2ce3eddf71 6d85f649fd5b458e94216ecb43ccfed7 9027552d3ec44f0e87f86b2ce3eddf71--6d85f649fd5b458e94216ecb43ccfed7 e948e8b0b3c54f098bfa3f6056b8df01 X 6d85f649fd5b458e94216ecb43ccfed7--e948e8b0b3c54f098bfa3f6056b8df01 e948e8b0b3c54f098bfa3f6056b8df01--eb9b0837241644d99c2cf87e131126e9 560d3d0917e64b3dbc38da5f5fc2bf08 e948e8b0b3c54f098bfa3f6056b8df01--560d3d0917e64b3dbc38da5f5fc2bf08 ba11b9b3044c48339c5ec06dba7d332b 560d3d0917e64b3dbc38da5f5fc2bf08--ba11b9b3044c48339c5ec06dba7d332b 2d9a24145f6e4577b0193da5f5122774 ba11b9b3044c48339c5ec06dba7d332b--2d9a24145f6e4577b0193da5f5122774 e7bb13fec4b54be28169f534aadd7500 X 2d9a24145f6e4577b0193da5f5122774--e7bb13fec4b54be28169f534aadd7500 e7bb13fec4b54be28169f534aadd7500--ac96a4ee925d44bf821d83bd480f9492 10c0f7647b3943718949b8ca81e0e90f e7bb13fec4b54be28169f534aadd7500--10c0f7647b3943718949b8ca81e0e90f 03fda4b58be9420f81dc3d40b74c6381 10c0f7647b3943718949b8ca81e0e90f--03fda4b58be9420f81dc3d40b74c6381 d52a6dbbc30a49a49ec304971e076afd 03fda4b58be9420f81dc3d40b74c6381--d52a6dbbc30a49a49ec304971e076afd 14f23bbebd6542a994f386a68680a795 d52a6dbbc30a49a49ec304971e076afd--14f23bbebd6542a994f386a68680a795 a57c486841e342b8b149b789b205b29f 14f23bbebd6542a994f386a68680a795--a57c486841e342b8b149b789b205b29f abc665aa55884d2f9543d07a8d41bf7b a57c486841e342b8b149b789b205b29f--abc665aa55884d2f9543d07a8d41bf7b f65d15fc2d8b4b0d8b7eda9fe232f20c abc665aa55884d2f9543d07a8d41bf7b--f65d15fc2d8b4b0d8b7eda9fe232f20c 519af24a895544e5bf7e756d369e3604 f65d15fc2d8b4b0d8b7eda9fe232f20c--519af24a895544e5bf7e756d369e3604 acc33050c3cf499cb3f4579ec1a692e3 519af24a895544e5bf7e756d369e3604--acc33050c3cf499cb3f4579ec1a692e3 b1fe713354c44282902990fd4f0bc064 acc33050c3cf499cb3f4579ec1a692e3--b1fe713354c44282902990fd4f0bc064 b8e588c922dc4086b2539c8511aac4d5 b1fe713354c44282902990fd4f0bc064--b8e588c922dc4086b2539c8511aac4d5 01e99af3c984494b840b06f9726c05f0 b8e588c922dc4086b2539c8511aac4d5--01e99af3c984494b840b06f9726c05f0 8ff40bec6cd24f909d25b625d568e868 01e99af3c984494b840b06f9726c05f0--8ff40bec6cd24f909d25b625d568e868 0dae052e034447ef8fe2f0fb89b54560 8ff40bec6cd24f909d25b625d568e868--0dae052e034447ef8fe2f0fb89b54560 252199ea363d46dab9ea51a118ea03eb 0dae052e034447ef8fe2f0fb89b54560--252199ea363d46dab9ea51a118ea03eb 8b6242ffe19f4224bd4b8bbbb77724f9 252199ea363d46dab9ea51a118ea03eb--8b6242ffe19f4224bd4b8bbbb77724f9 61b34e210b6b4e5fab40a0eddf1c7a0f 8b6242ffe19f4224bd4b8bbbb77724f9--61b34e210b6b4e5fab40a0eddf1c7a0f 7ed215516ce0413280977b9fd908df7b 61b34e210b6b4e5fab40a0eddf1c7a0f--7ed215516ce0413280977b9fd908df7b 330910a2a18f4dc7beee7867827b7297 7ed215516ce0413280977b9fd908df7b--330910a2a18f4dc7beee7867827b7297 e6165b76447d42ecb4661c6acc6ea2c4 330910a2a18f4dc7beee7867827b7297--e6165b76447d42ecb4661c6acc6ea2c4 0ffb8b49444a4297821439819ecc4f2c e6165b76447d42ecb4661c6acc6ea2c4--0ffb8b49444a4297821439819ecc4f2c e98f683ed47241abb89238453c90138c 0ffb8b49444a4297821439819ecc4f2c--e98f683ed47241abb89238453c90138c aa02e5ab51614af482d8342577f503a3 e98f683ed47241abb89238453c90138c--aa02e5ab51614af482d8342577f503a3 6d87953c83644cdfad54d4d6094d7d23 aa02e5ab51614af482d8342577f503a3--6d87953c83644cdfad54d4d6094d7d23 7931194fbaa64a588d5dd896908796d3 6d87953c83644cdfad54d4d6094d7d23--7931194fbaa64a588d5dd896908796d3 a5dc0f5d5c6847f98589720530c79fb3 7931194fbaa64a588d5dd896908796d3--a5dc0f5d5c6847f98589720530c79fb3 8663ef37a0f5494d9eaad6aaa83d381d a5dc0f5d5c6847f98589720530c79fb3--8663ef37a0f5494d9eaad6aaa83d381d c3c3d1cabc074540a4f7d012b724a71a 8663ef37a0f5494d9eaad6aaa83d381d--c3c3d1cabc074540a4f7d012b724a71a 51941cefb8f2411590cfc6f582305635 c3c3d1cabc074540a4f7d012b724a71a--51941cefb8f2411590cfc6f582305635 cd7597229f284282a21c6f5de9c4c6db 51941cefb8f2411590cfc6f582305635--cd7597229f284282a21c6f5de9c4c6db 8a94dae0dda646039234b41140eb59d5 cd7597229f284282a21c6f5de9c4c6db--8a94dae0dda646039234b41140eb59d5 9830cc9eb53b4a01aee3e6530c71d7c7 8a94dae0dda646039234b41140eb59d5--9830cc9eb53b4a01aee3e6530c71d7c7 587a29f9ce514eb396a52e5e13adca85 9830cc9eb53b4a01aee3e6530c71d7c7--587a29f9ce514eb396a52e5e13adca85 d5cca077333a4a3dbd03713789b2f63c X 587a29f9ce514eb396a52e5e13adca85--d5cca077333a4a3dbd03713789b2f63c d5cca077333a4a3dbd03713789b2f63c--1d65a05df5594cf681f837e83ad16b90 591d67fc9e734a4ead8503aa63c25f37 RZ(-1.0*g1) d5cca077333a4a3dbd03713789b2f63c--591d67fc9e734a4ead8503aa63c25f37 41d12e9929a34a6fbad8f38765681a64 X 591d67fc9e734a4ead8503aa63c25f37--41d12e9929a34a6fbad8f38765681a64 41d12e9929a34a6fbad8f38765681a64--8aaa792718934034a9ea0fee6302c8e2 e5652d1814d445fb866d751e924b2609 41d12e9929a34a6fbad8f38765681a64--e5652d1814d445fb866d751e924b2609 f6ee89ec9b8643d6be1b9e7f48be4fec e5652d1814d445fb866d751e924b2609--f6ee89ec9b8643d6be1b9e7f48be4fec dfc3bf2bf0d4402e919262401606ef1f f6ee89ec9b8643d6be1b9e7f48be4fec--dfc3bf2bf0d4402e919262401606ef1f 2ac475b9e08647b197df06036b7bb9cf dfc3bf2bf0d4402e919262401606ef1f--2ac475b9e08647b197df06036b7bb9cf 5c73871f1f554c069667172ac6458717 2ac475b9e08647b197df06036b7bb9cf--5c73871f1f554c069667172ac6458717 89c8dd53c6b14257a2da1614ecefc57b 5c73871f1f554c069667172ac6458717--89c8dd53c6b14257a2da1614ecefc57b e3888f5f022a488e8473dffb9a98a650 89c8dd53c6b14257a2da1614ecefc57b--e3888f5f022a488e8473dffb9a98a650 349a81e16c514ccfb3da73e5eab5e29c e3888f5f022a488e8473dffb9a98a650--349a81e16c514ccfb3da73e5eab5e29c a03f829305904dc0b9d9fb2e27b6cdeb X 349a81e16c514ccfb3da73e5eab5e29c--a03f829305904dc0b9d9fb2e27b6cdeb a03f829305904dc0b9d9fb2e27b6cdeb--b615d503511b4eec854308922b26f987 01699dcdc01040cca66ae9fe65036608 a03f829305904dc0b9d9fb2e27b6cdeb--01699dcdc01040cca66ae9fe65036608 0ae6d6078e0a4f0080161951409ce110 01699dcdc01040cca66ae9fe65036608--0ae6d6078e0a4f0080161951409ce110 2ba4c1cb7d044dc5a8c491f7101b9cbc 0ae6d6078e0a4f0080161951409ce110--2ba4c1cb7d044dc5a8c491f7101b9cbc fd5e038e5ff34f22853da8facea17ded X 2ba4c1cb7d044dc5a8c491f7101b9cbc--fd5e038e5ff34f22853da8facea17ded fd5e038e5ff34f22853da8facea17ded--3b7529b3cbd346c7899649a192133c47 77820368b4ae4096b5acd91d69aab721 fd5e038e5ff34f22853da8facea17ded--77820368b4ae4096b5acd91d69aab721 85e57bc783ab4c008b86b92627bb8ec0 77820368b4ae4096b5acd91d69aab721--85e57bc783ab4c008b86b92627bb8ec0 aa4a6c81c0d040cd8807ea7eb315d547 85e57bc783ab4c008b86b92627bb8ec0--aa4a6c81c0d040cd8807ea7eb315d547 1964a48a92564f72bad5c58eceb1d994 aa4a6c81c0d040cd8807ea7eb315d547--1964a48a92564f72bad5c58eceb1d994 cc5680284ae846c6a245a8228c09f0f0 1964a48a92564f72bad5c58eceb1d994--cc5680284ae846c6a245a8228c09f0f0 2672f6e0bbfe47cea5762996ae977dbb cc5680284ae846c6a245a8228c09f0f0--2672f6e0bbfe47cea5762996ae977dbb 180bce09154e459781fb83621935f258 2672f6e0bbfe47cea5762996ae977dbb--180bce09154e459781fb83621935f258 2b2a057b85d74491b46128be0bbc3d25 180bce09154e459781fb83621935f258--2b2a057b85d74491b46128be0bbc3d25 fe3a6d580d2941abbb7f22da0b5a53fd 2b2a057b85d74491b46128be0bbc3d25--fe3a6d580d2941abbb7f22da0b5a53fd 11f503e656484ba2af2cf9edbdb39780 fe3a6d580d2941abbb7f22da0b5a53fd--11f503e656484ba2af2cf9edbdb39780 3e3db40fffad4da9a2b083a4bbf368b3 11f503e656484ba2af2cf9edbdb39780--3e3db40fffad4da9a2b083a4bbf368b3 b70997b9006b43b0b0f5e4b13631d234 3e3db40fffad4da9a2b083a4bbf368b3--b70997b9006b43b0b0f5e4b13631d234 eb082bf9bc874c7db10c0644114071ba b70997b9006b43b0b0f5e4b13631d234--eb082bf9bc874c7db10c0644114071ba edb3a3dd3ff8428f9c831a0b998d8473 eb082bf9bc874c7db10c0644114071ba--edb3a3dd3ff8428f9c831a0b998d8473 0478bf5862fd4f69a84cf5d88e16140d edb3a3dd3ff8428f9c831a0b998d8473--0478bf5862fd4f69a84cf5d88e16140d c19b1b09c034444fad09d2010eeb72b4 0478bf5862fd4f69a84cf5d88e16140d--c19b1b09c034444fad09d2010eeb72b4 470b4e15f2ca48ffb9b2c443c3cd82e7 c19b1b09c034444fad09d2010eeb72b4--470b4e15f2ca48ffb9b2c443c3cd82e7 1a4eb7ebf3684c9c96999d973d53e40f X 470b4e15f2ca48ffb9b2c443c3cd82e7--1a4eb7ebf3684c9c96999d973d53e40f 1a4eb7ebf3684c9c96999d973d53e40f--213cd778a17b4d909df501a8e120d467 ab4310487e614d188374e4656c351372 RZ(-1.0*g1) 1a4eb7ebf3684c9c96999d973d53e40f--ab4310487e614d188374e4656c351372 1fc4843330c2481faaae15c202f2da75 X ab4310487e614d188374e4656c351372--1fc4843330c2481faaae15c202f2da75 1fc4843330c2481faaae15c202f2da75--cf7e253d238b43afa03e813098c659a8 96cd80d7543f40e3aeec34a73505565b 1fc4843330c2481faaae15c202f2da75--96cd80d7543f40e3aeec34a73505565b 15643992d7f4454ab10b9fc481c3c1ae 96cd80d7543f40e3aeec34a73505565b--15643992d7f4454ab10b9fc481c3c1ae f3cb4ddee3804565bb27821b05e3840f 15643992d7f4454ab10b9fc481c3c1ae--f3cb4ddee3804565bb27821b05e3840f ef3e1631e0134918bcf641dd88d953a4 f3cb4ddee3804565bb27821b05e3840f--ef3e1631e0134918bcf641dd88d953a4 262bc474b83e431a88e91686c298fda3 ef3e1631e0134918bcf641dd88d953a4--262bc474b83e431a88e91686c298fda3 b5d7bf3591ca44b598943af2ae21bb7f 262bc474b83e431a88e91686c298fda3--b5d7bf3591ca44b598943af2ae21bb7f 40ea84bf11984c0fbec414a852bee8f0 b5d7bf3591ca44b598943af2ae21bb7f--40ea84bf11984c0fbec414a852bee8f0 aa43fb9d338a46b2b6a53ce8b8053eba X 40ea84bf11984c0fbec414a852bee8f0--aa43fb9d338a46b2b6a53ce8b8053eba aa43fb9d338a46b2b6a53ce8b8053eba--b171ecb4eb0e46978589eadc761b0f8b 27e26639551446e8b6839fd608f98a46 RZ(-1.0*g1) aa43fb9d338a46b2b6a53ce8b8053eba--27e26639551446e8b6839fd608f98a46 9585b750a5c04b539414afc61fa284ac X 27e26639551446e8b6839fd608f98a46--9585b750a5c04b539414afc61fa284ac 9585b750a5c04b539414afc61fa284ac--4ec77ef8fa4b4e88b8e8ae6c59349396 9f0ae491db3f4ce7a14edfe1955368cf 9585b750a5c04b539414afc61fa284ac--9f0ae491db3f4ce7a14edfe1955368cf 8d9fd3a123b54016865fd6999b5ab769 9f0ae491db3f4ce7a14edfe1955368cf--8d9fd3a123b54016865fd6999b5ab769 0a4b8a32175b4d81ac7eb7267a0b2334 X 8d9fd3a123b54016865fd6999b5ab769--0a4b8a32175b4d81ac7eb7267a0b2334 0a4b8a32175b4d81ac7eb7267a0b2334--6649fcf5104e45c2aee9816646ad7afd fa6d5426703c405a8d466e88a7039edb 0a4b8a32175b4d81ac7eb7267a0b2334--fa6d5426703c405a8d466e88a7039edb 5786c8a7c3234470a4aca90ee48016c6 fa6d5426703c405a8d466e88a7039edb--5786c8a7c3234470a4aca90ee48016c6 f9e03b829124420a88b69a49de015448 5786c8a7c3234470a4aca90ee48016c6--f9e03b829124420a88b69a49de015448 c5c78263a7f84f6aaf8b44a9a44287f4 X f9e03b829124420a88b69a49de015448--c5c78263a7f84f6aaf8b44a9a44287f4 c5c78263a7f84f6aaf8b44a9a44287f4--012179d7c8a4458e94d90df6b67e50ac a22dd4e4864147c4bdc506ee1642fd4b c5c78263a7f84f6aaf8b44a9a44287f4--a22dd4e4864147c4bdc506ee1642fd4b 8eda0b420cbd4c8ea4ec782a3e8890e9 X a22dd4e4864147c4bdc506ee1642fd4b--8eda0b420cbd4c8ea4ec782a3e8890e9 8eda0b420cbd4c8ea4ec782a3e8890e9--35a24986161343729ab4dda8c379a95c 5b3d7f2debbe4caeae23b975e1db98ad RZ(-1.0*g1) 8eda0b420cbd4c8ea4ec782a3e8890e9--5b3d7f2debbe4caeae23b975e1db98ad 15b8eeeacad3472da7b3de04eb8f0aaa X 5b3d7f2debbe4caeae23b975e1db98ad--15b8eeeacad3472da7b3de04eb8f0aaa 15b8eeeacad3472da7b3de04eb8f0aaa--0e6b6cd4cf59460496b31a9efa28ab5f f4ae9f8d02d94b04b7d7dc4024a79dab X 15b8eeeacad3472da7b3de04eb8f0aaa--f4ae9f8d02d94b04b7d7dc4024a79dab f4ae9f8d02d94b04b7d7dc4024a79dab--c0e2a562a0d34a3d8210740d97ff73c5 693b337e150c41809e74732e8c143786 f4ae9f8d02d94b04b7d7dc4024a79dab--693b337e150c41809e74732e8c143786 563b248e40fb4d07bfff5b5a7525cb2f 693b337e150c41809e74732e8c143786--563b248e40fb4d07bfff5b5a7525cb2f cb9ed90e3dbd4e61a8a6900ebe473a5f 563b248e40fb4d07bfff5b5a7525cb2f--cb9ed90e3dbd4e61a8a6900ebe473a5f 71d7754511a14624b50f0145479982b6 X cb9ed90e3dbd4e61a8a6900ebe473a5f--71d7754511a14624b50f0145479982b6 71d7754511a14624b50f0145479982b6--8b2b0f27c67442c8b50d1e7b2b6e6679 32ab4cd4aa9d49ccb191bb4196b2228c 71d7754511a14624b50f0145479982b6--32ab4cd4aa9d49ccb191bb4196b2228c 459f9bf034d3482888528b8c326c4328 32ab4cd4aa9d49ccb191bb4196b2228c--459f9bf034d3482888528b8c326c4328 e18d82847a9749b2ba60404fb442d7ad 459f9bf034d3482888528b8c326c4328--e18d82847a9749b2ba60404fb442d7ad f0a7f0a5f8414ebebe6e50fa22bd6022 RX(b16) e18d82847a9749b2ba60404fb442d7ad--f0a7f0a5f8414ebebe6e50fa22bd6022 f0a7f0a5f8414ebebe6e50fa22bd6022--c07740f9abfa4854bdb375698b271e64 746223b7fd684c5498b9950b0b029dea d182a077ab8c4015ac50cb486f161694 8afcfa29983d4b08b4f94a6b11712827--d182a077ab8c4015ac50cb486f161694 548f03e33a59469398294b1a21fa4552 d182a077ab8c4015ac50cb486f161694--548f03e33a59469398294b1a21fa4552 09e3a37f49c947f9983d2cf99f7ed2b8 548f03e33a59469398294b1a21fa4552--09e3a37f49c947f9983d2cf99f7ed2b8 15bf5612a20b408aa8ccea1a4af2cf9b 09e3a37f49c947f9983d2cf99f7ed2b8--15bf5612a20b408aa8ccea1a4af2cf9b 62363450a2304e3ea5112f86997704a8 15bf5612a20b408aa8ccea1a4af2cf9b--62363450a2304e3ea5112f86997704a8 731700b84c414f9d949a6bbd8daa1059 62363450a2304e3ea5112f86997704a8--731700b84c414f9d949a6bbd8daa1059 3d0807874ae7443d93e0397670af8891 X 731700b84c414f9d949a6bbd8daa1059--3d0807874ae7443d93e0397670af8891 3d0807874ae7443d93e0397670af8891--68d8f44259584af09ef2229c5fc1b724 07434821f71d4890bf1ce83556a31648 RZ(1.0*g0) 3d0807874ae7443d93e0397670af8891--07434821f71d4890bf1ce83556a31648 62140d1aa17041b0a3f986dda7f7d223 X 07434821f71d4890bf1ce83556a31648--62140d1aa17041b0a3f986dda7f7d223 62140d1aa17041b0a3f986dda7f7d223--64b1fd5b1f1c45af97d2430a9cdc286a 5b5078f91383492fa69d7032144aeb2f 62140d1aa17041b0a3f986dda7f7d223--5b5078f91383492fa69d7032144aeb2f 3629da95379e44488c15ea4d83205194 5b5078f91383492fa69d7032144aeb2f--3629da95379e44488c15ea4d83205194 2a5cbe466a8641a88dd4fd3789177929 3629da95379e44488c15ea4d83205194--2a5cbe466a8641a88dd4fd3789177929 91ff22e8b39b4a67b7be1fd2e2cf8e63 2a5cbe466a8641a88dd4fd3789177929--91ff22e8b39b4a67b7be1fd2e2cf8e63 d29f27a6c00a4e08bd66b109f22cdda7 91ff22e8b39b4a67b7be1fd2e2cf8e63--d29f27a6c00a4e08bd66b109f22cdda7 dd0e90a8c4ae4ce48fcc023c5b42ea68 d29f27a6c00a4e08bd66b109f22cdda7--dd0e90a8c4ae4ce48fcc023c5b42ea68 3ac153f94b974bc1800b70d9c6aca73e dd0e90a8c4ae4ce48fcc023c5b42ea68--3ac153f94b974bc1800b70d9c6aca73e a8d890f74e9d45e898ee8b195cd44e4d 3ac153f94b974bc1800b70d9c6aca73e--a8d890f74e9d45e898ee8b195cd44e4d 23dd76aa7f1c440295cace98f637dbb0 a8d890f74e9d45e898ee8b195cd44e4d--23dd76aa7f1c440295cace98f637dbb0 9a0e03a6e28142e3ba5b5a93826f03e2 23dd76aa7f1c440295cace98f637dbb0--9a0e03a6e28142e3ba5b5a93826f03e2 74cf4e17ba1f41c0afa252afe52f4dd8 9a0e03a6e28142e3ba5b5a93826f03e2--74cf4e17ba1f41c0afa252afe52f4dd8 4dab5e67d3e94ae2b100eb0c6cd09180 74cf4e17ba1f41c0afa252afe52f4dd8--4dab5e67d3e94ae2b100eb0c6cd09180 c253ded3d6894c91b607148e29055127 4dab5e67d3e94ae2b100eb0c6cd09180--c253ded3d6894c91b607148e29055127 96a910598d544d8990e16fa50f6612cc c253ded3d6894c91b607148e29055127--96a910598d544d8990e16fa50f6612cc ef055d9151e54dfaa9a0ab348dd69760 96a910598d544d8990e16fa50f6612cc--ef055d9151e54dfaa9a0ab348dd69760 96ceada9a21a4ab78938a95f357f99a5 ef055d9151e54dfaa9a0ab348dd69760--96ceada9a21a4ab78938a95f357f99a5 8e8f28ea6f434612a9893aaeb0176a9f 96ceada9a21a4ab78938a95f357f99a5--8e8f28ea6f434612a9893aaeb0176a9f 3c1c8de95e4d4438880c682117ac269e 8e8f28ea6f434612a9893aaeb0176a9f--3c1c8de95e4d4438880c682117ac269e c3cbdc078949400c87010411e3102f03 3c1c8de95e4d4438880c682117ac269e--c3cbdc078949400c87010411e3102f03 3bc229eae2144d758630a8a3d575c74d c3cbdc078949400c87010411e3102f03--3bc229eae2144d758630a8a3d575c74d 0d509720e1014a3198f467ef7c6fa0e4 3bc229eae2144d758630a8a3d575c74d--0d509720e1014a3198f467ef7c6fa0e4 683b09362fc54002bf8011046bec41a3 0d509720e1014a3198f467ef7c6fa0e4--683b09362fc54002bf8011046bec41a3 532104955f934911a66e71f2b7a9195c 683b09362fc54002bf8011046bec41a3--532104955f934911a66e71f2b7a9195c d26d6b9ea6ac46a9a41eff5531dc0a52 532104955f934911a66e71f2b7a9195c--d26d6b9ea6ac46a9a41eff5531dc0a52 d94fe391c0a54c218994f606f40e46ce d26d6b9ea6ac46a9a41eff5531dc0a52--d94fe391c0a54c218994f606f40e46ce 948e446b59014b8b92a92cbdf2638b28 d94fe391c0a54c218994f606f40e46ce--948e446b59014b8b92a92cbdf2638b28 bb54959d724748e7a47ed78e5b578e5f 948e446b59014b8b92a92cbdf2638b28--bb54959d724748e7a47ed78e5b578e5f 2b73794107e34ac98b27ea7b3ccccaa3 bb54959d724748e7a47ed78e5b578e5f--2b73794107e34ac98b27ea7b3ccccaa3 20aac4b94e064e24a690504a94e9f94d 2b73794107e34ac98b27ea7b3ccccaa3--20aac4b94e064e24a690504a94e9f94d 830d40ba1d1141b09f66e308baf84d1e 20aac4b94e064e24a690504a94e9f94d--830d40ba1d1141b09f66e308baf84d1e 4fa7a097d84748639e75d6db38659546 830d40ba1d1141b09f66e308baf84d1e--4fa7a097d84748639e75d6db38659546 155d0844843a4a83a2aef7bce2fa3fdb 4fa7a097d84748639e75d6db38659546--155d0844843a4a83a2aef7bce2fa3fdb 3ecf68fdf29f453fa4a8ea8a0c0900e5 155d0844843a4a83a2aef7bce2fa3fdb--3ecf68fdf29f453fa4a8ea8a0c0900e5 b65df195c3eb47778a4f3c7f513b0807 3ecf68fdf29f453fa4a8ea8a0c0900e5--b65df195c3eb47778a4f3c7f513b0807 43193f72421c4e57a2bbb8dbdc875ffc b65df195c3eb47778a4f3c7f513b0807--43193f72421c4e57a2bbb8dbdc875ffc 3c329b9672fd4dd8b114e37cee899c63 43193f72421c4e57a2bbb8dbdc875ffc--3c329b9672fd4dd8b114e37cee899c63 a9e7c26952624f059b0ff2623fdd50fe 3c329b9672fd4dd8b114e37cee899c63--a9e7c26952624f059b0ff2623fdd50fe 60fbb08ecd864b0da358f12c19e29db6 a9e7c26952624f059b0ff2623fdd50fe--60fbb08ecd864b0da358f12c19e29db6 7191045584af45a0992d5b6f95c42be3 60fbb08ecd864b0da358f12c19e29db6--7191045584af45a0992d5b6f95c42be3 889f0de8f2cc428ca57ecd22bc368034 7191045584af45a0992d5b6f95c42be3--889f0de8f2cc428ca57ecd22bc368034 d5c8b5fbab9f49ada22872c74fe9c390 X 889f0de8f2cc428ca57ecd22bc368034--d5c8b5fbab9f49ada22872c74fe9c390 d5c8b5fbab9f49ada22872c74fe9c390--9efb5e547d754e0389faab612f398989 915c08af3404436980d387985f9687f7 RZ(-1.0*g0) d5c8b5fbab9f49ada22872c74fe9c390--915c08af3404436980d387985f9687f7 3ed617d33404447a908f31fa066f1132 X 915c08af3404436980d387985f9687f7--3ed617d33404447a908f31fa066f1132 3ed617d33404447a908f31fa066f1132--d98e1669cb0541feb523fd1d64baac70 a38e1895d6da4be18bf6c75aa01d9e3e 3ed617d33404447a908f31fa066f1132--a38e1895d6da4be18bf6c75aa01d9e3e 332882ba52db4e45b2bc5de013668e6d a38e1895d6da4be18bf6c75aa01d9e3e--332882ba52db4e45b2bc5de013668e6d 4c7ec745b6a2425d8fb0272ad8037cc1 332882ba52db4e45b2bc5de013668e6d--4c7ec745b6a2425d8fb0272ad8037cc1 788c2d88311c49209473cbf5be5ff076 4c7ec745b6a2425d8fb0272ad8037cc1--788c2d88311c49209473cbf5be5ff076 ffe4b8115eb2471e83266aece31e61cc 788c2d88311c49209473cbf5be5ff076--ffe4b8115eb2471e83266aece31e61cc 86b8019897144c42a93ffe1d896456fc ffe4b8115eb2471e83266aece31e61cc--86b8019897144c42a93ffe1d896456fc bc423f3e490141668adf114ec354c130 86b8019897144c42a93ffe1d896456fc--bc423f3e490141668adf114ec354c130 4724b616e7c94c998617f48bc73bda66 bc423f3e490141668adf114ec354c130--4724b616e7c94c998617f48bc73bda66 2fa1fd16714e4f6ead826fd13f13a859 4724b616e7c94c998617f48bc73bda66--2fa1fd16714e4f6ead826fd13f13a859 65709225fda7434f8720997b23a7a54c 2fa1fd16714e4f6ead826fd13f13a859--65709225fda7434f8720997b23a7a54c 99dc509dac744302b8d32872169d7044 65709225fda7434f8720997b23a7a54c--99dc509dac744302b8d32872169d7044 92b37cdd777e472f80640e741e96d29e 99dc509dac744302b8d32872169d7044--92b37cdd777e472f80640e741e96d29e 2707bda7a6cb4efb9a89c6e0a74418d4 92b37cdd777e472f80640e741e96d29e--2707bda7a6cb4efb9a89c6e0a74418d4 7d1018fbc3c8457dbcab902ca8f1dede 2707bda7a6cb4efb9a89c6e0a74418d4--7d1018fbc3c8457dbcab902ca8f1dede a6826260e6944c34bb517863ae575501 7d1018fbc3c8457dbcab902ca8f1dede--a6826260e6944c34bb517863ae575501 1295b78027144c739d0be46e79f508e3 a6826260e6944c34bb517863ae575501--1295b78027144c739d0be46e79f508e3 e6ccbef9a4714297963b3d7027f7da20 1295b78027144c739d0be46e79f508e3--e6ccbef9a4714297963b3d7027f7da20 a8e15d0841d545688662b808401bba5e e6ccbef9a4714297963b3d7027f7da20--a8e15d0841d545688662b808401bba5e 457410dbd60d49af97b969dfc3557fc5 a8e15d0841d545688662b808401bba5e--457410dbd60d49af97b969dfc3557fc5 a76442071dd744aea4c3ff310604e06c 457410dbd60d49af97b969dfc3557fc5--a76442071dd744aea4c3ff310604e06c 7937232453464f73a491aa86f3c70942 a76442071dd744aea4c3ff310604e06c--7937232453464f73a491aa86f3c70942 cb5adcdcf6d04ce4993dcc2e4a39466d 7937232453464f73a491aa86f3c70942--cb5adcdcf6d04ce4993dcc2e4a39466d afe32d6520ca42c69cdf545ca384b557 cb5adcdcf6d04ce4993dcc2e4a39466d--afe32d6520ca42c69cdf545ca384b557 ad6eb6e50aed428fa194c84ff8e588d4 afe32d6520ca42c69cdf545ca384b557--ad6eb6e50aed428fa194c84ff8e588d4 98ffd8cc588e477995dbafd80d78fe7c ad6eb6e50aed428fa194c84ff8e588d4--98ffd8cc588e477995dbafd80d78fe7c cb91356692e74e1bac135a0fb2d9f8df 98ffd8cc588e477995dbafd80d78fe7c--cb91356692e74e1bac135a0fb2d9f8df 3e038ca51d624422a3eaab2e968d239e cb91356692e74e1bac135a0fb2d9f8df--3e038ca51d624422a3eaab2e968d239e 2f6a7ee0a2fb4d34830317310fe2f875 3e038ca51d624422a3eaab2e968d239e--2f6a7ee0a2fb4d34830317310fe2f875 168b830bbeae4892b82517b02124bf99 2f6a7ee0a2fb4d34830317310fe2f875--168b830bbeae4892b82517b02124bf99 b6c10b9d5bc64aca874efcdfe2c0281d 168b830bbeae4892b82517b02124bf99--b6c10b9d5bc64aca874efcdfe2c0281d 44398796c1b44127a364c106e8930565 b6c10b9d5bc64aca874efcdfe2c0281d--44398796c1b44127a364c106e8930565 60c579e24e2845db9592f772ee040fda 44398796c1b44127a364c106e8930565--60c579e24e2845db9592f772ee040fda 6375c0ed382d4a478d949fb97b72f367 60c579e24e2845db9592f772ee040fda--6375c0ed382d4a478d949fb97b72f367 bba2eba2cc52481998ccc40fac324fdb 6375c0ed382d4a478d949fb97b72f367--bba2eba2cc52481998ccc40fac324fdb 49846540d5414e04ab3387ef3dc1c370 bba2eba2cc52481998ccc40fac324fdb--49846540d5414e04ab3387ef3dc1c370 d603fb4935e44092893ffedb3f51fc4f 49846540d5414e04ab3387ef3dc1c370--d603fb4935e44092893ffedb3f51fc4f f470c1682c0e468badb720217c117985 d603fb4935e44092893ffedb3f51fc4f--f470c1682c0e468badb720217c117985 0efb7d99ac81493ab7df5b411a6b5c42 f470c1682c0e468badb720217c117985--0efb7d99ac81493ab7df5b411a6b5c42 c5b9b01bf18244ad8c38e5131f63faa9 0efb7d99ac81493ab7df5b411a6b5c42--c5b9b01bf18244ad8c38e5131f63faa9 b9766077da6f4eae95ea438f61841286 c5b9b01bf18244ad8c38e5131f63faa9--b9766077da6f4eae95ea438f61841286 6a114ccaf3a0446b843feb2d7c535cd0 b9766077da6f4eae95ea438f61841286--6a114ccaf3a0446b843feb2d7c535cd0 128da3501e8840ac96e27dfb7a03c560 6a114ccaf3a0446b843feb2d7c535cd0--128da3501e8840ac96e27dfb7a03c560 299a78d263e746dd8e0c664a97534009 128da3501e8840ac96e27dfb7a03c560--299a78d263e746dd8e0c664a97534009 bbd7a7ae846b4ed1b8d9aa660a5fd44e 299a78d263e746dd8e0c664a97534009--bbd7a7ae846b4ed1b8d9aa660a5fd44e 6e2dbfc02bf94ac388cf3d26c4966c3e bbd7a7ae846b4ed1b8d9aa660a5fd44e--6e2dbfc02bf94ac388cf3d26c4966c3e 9a534df46ca44d118b6872ae53f49eee 6e2dbfc02bf94ac388cf3d26c4966c3e--9a534df46ca44d118b6872ae53f49eee 8a943750f6f74fd08337c09ede89fe7a X 9a534df46ca44d118b6872ae53f49eee--8a943750f6f74fd08337c09ede89fe7a 8a943750f6f74fd08337c09ede89fe7a--4253a5d2a64a4021aed7968673d11ab1 e9ddf60987e74485ab07a587377acdfa RZ(-1.0*g0) 8a943750f6f74fd08337c09ede89fe7a--e9ddf60987e74485ab07a587377acdfa d0dc8dfbc5e5449cab50cc335ba91a05 X e9ddf60987e74485ab07a587377acdfa--d0dc8dfbc5e5449cab50cc335ba91a05 d0dc8dfbc5e5449cab50cc335ba91a05--0ee385bda5e54dfebc61bd650afc022f 5af15d148fe04eeb8378e7b8a6fa8690 d0dc8dfbc5e5449cab50cc335ba91a05--5af15d148fe04eeb8378e7b8a6fa8690 f0a7af75dd3b4d1c8b281713f03e96da 5af15d148fe04eeb8378e7b8a6fa8690--f0a7af75dd3b4d1c8b281713f03e96da dc5b81d7a46c48d9a0283f7bee831a6d f0a7af75dd3b4d1c8b281713f03e96da--dc5b81d7a46c48d9a0283f7bee831a6d c2824a13654b489fa26d465eeb2256c6 dc5b81d7a46c48d9a0283f7bee831a6d--c2824a13654b489fa26d465eeb2256c6 d871faae87174ae988e97cf09825b515 c2824a13654b489fa26d465eeb2256c6--d871faae87174ae988e97cf09825b515 71b0f4fb897c4cfc87a7a8ff44ce95f5 d871faae87174ae988e97cf09825b515--71b0f4fb897c4cfc87a7a8ff44ce95f5 148a1ae844c447b4a12867169cfed15b 71b0f4fb897c4cfc87a7a8ff44ce95f5--148a1ae844c447b4a12867169cfed15b 8206b520e53c41909f037cd78cb79418 148a1ae844c447b4a12867169cfed15b--8206b520e53c41909f037cd78cb79418 e53b35e364cb4faeb916281b1013b68c 8206b520e53c41909f037cd78cb79418--e53b35e364cb4faeb916281b1013b68c e33fcd833477466e8f48a810d9c36c31 e53b35e364cb4faeb916281b1013b68c--e33fcd833477466e8f48a810d9c36c31 364ae3530abe41f59eac4e9141c9f634 e33fcd833477466e8f48a810d9c36c31--364ae3530abe41f59eac4e9141c9f634 1d694c0de8c6433f9bad9086a7ea5077 364ae3530abe41f59eac4e9141c9f634--1d694c0de8c6433f9bad9086a7ea5077 10217aa13edd4d1d962ea721da5d9429 1d694c0de8c6433f9bad9086a7ea5077--10217aa13edd4d1d962ea721da5d9429 e00bac0c0bc84e02995cee7b7361d7b6 10217aa13edd4d1d962ea721da5d9429--e00bac0c0bc84e02995cee7b7361d7b6 156da92ba3074155a0cb4d020a87c651 e00bac0c0bc84e02995cee7b7361d7b6--156da92ba3074155a0cb4d020a87c651 9a9a59bf00204636933d2e6329614133 156da92ba3074155a0cb4d020a87c651--9a9a59bf00204636933d2e6329614133 2a9b897ecc1d4a44b68e7064d6a1de76 9a9a59bf00204636933d2e6329614133--2a9b897ecc1d4a44b68e7064d6a1de76 e5b3ccabcea24a768c8dc05756b4c937 2a9b897ecc1d4a44b68e7064d6a1de76--e5b3ccabcea24a768c8dc05756b4c937 094b17eec8964c3d86d8361ccc48e480 e5b3ccabcea24a768c8dc05756b4c937--094b17eec8964c3d86d8361ccc48e480 6187b3627d9b47a49b24d284bc30223c 094b17eec8964c3d86d8361ccc48e480--6187b3627d9b47a49b24d284bc30223c 0f926c27e2bc4c66a5ca8f588af9c737 6187b3627d9b47a49b24d284bc30223c--0f926c27e2bc4c66a5ca8f588af9c737 e37c247dc5094f01a1728e1681677d20 0f926c27e2bc4c66a5ca8f588af9c737--e37c247dc5094f01a1728e1681677d20 ccc8c5c71e854f4ebd6e4dc4cfcd7fe7 e37c247dc5094f01a1728e1681677d20--ccc8c5c71e854f4ebd6e4dc4cfcd7fe7 27a46c831b174f7da3bc2eb23a048730 ccc8c5c71e854f4ebd6e4dc4cfcd7fe7--27a46c831b174f7da3bc2eb23a048730 8a849b1f108b437daf34132d029a6f3b 27a46c831b174f7da3bc2eb23a048730--8a849b1f108b437daf34132d029a6f3b ba32e917e8c3474bae11f216dc90d217 8a849b1f108b437daf34132d029a6f3b--ba32e917e8c3474bae11f216dc90d217 58cfeddd01ef49edaf859872ac5f9880 ba32e917e8c3474bae11f216dc90d217--58cfeddd01ef49edaf859872ac5f9880 9bd97cb5060a4ea386f3dafad855fefa 58cfeddd01ef49edaf859872ac5f9880--9bd97cb5060a4ea386f3dafad855fefa eb858ad269234fbd881c2be39c8959c3 9bd97cb5060a4ea386f3dafad855fefa--eb858ad269234fbd881c2be39c8959c3 e655ca500d87477eae143e4f3ee4df7a eb858ad269234fbd881c2be39c8959c3--e655ca500d87477eae143e4f3ee4df7a a9ed588d407c41eab18a07cce5afbf79 e655ca500d87477eae143e4f3ee4df7a--a9ed588d407c41eab18a07cce5afbf79 7489617c356c4ca9acbb180d666298c4 a9ed588d407c41eab18a07cce5afbf79--7489617c356c4ca9acbb180d666298c4 c6e505fa85d94ae4a77614f73e24f97b 7489617c356c4ca9acbb180d666298c4--c6e505fa85d94ae4a77614f73e24f97b 7deffdbd7a0448ed950330d301e6f914 c6e505fa85d94ae4a77614f73e24f97b--7deffdbd7a0448ed950330d301e6f914 63f2042970b743ea98173bc989219c51 X 7deffdbd7a0448ed950330d301e6f914--63f2042970b743ea98173bc989219c51 63f2042970b743ea98173bc989219c51--290eed4567754d8b95d5e93f9a7cc61c d8683831c9654139817d0b761305fdea RZ(-1.0*g0) 63f2042970b743ea98173bc989219c51--d8683831c9654139817d0b761305fdea 0018d1c4afa94bc69cf699f7a2b9ff2d X d8683831c9654139817d0b761305fdea--0018d1c4afa94bc69cf699f7a2b9ff2d 0018d1c4afa94bc69cf699f7a2b9ff2d--b98e7a324a9d41049b4ab0828cdfd53a 2419d37b3e924f72a926560fb6d1a6b4 0018d1c4afa94bc69cf699f7a2b9ff2d--2419d37b3e924f72a926560fb6d1a6b4 d8c030f31a8d4555994848594c29fd63 2419d37b3e924f72a926560fb6d1a6b4--d8c030f31a8d4555994848594c29fd63 825cffea42254bdf8df333cdbefd117d d8c030f31a8d4555994848594c29fd63--825cffea42254bdf8df333cdbefd117d 1795ddda0d3b45ffbe1569bb4b41478c 825cffea42254bdf8df333cdbefd117d--1795ddda0d3b45ffbe1569bb4b41478c 60c0b1737ef64896ae687f1922facc5e 1795ddda0d3b45ffbe1569bb4b41478c--60c0b1737ef64896ae687f1922facc5e 1a26c4d08c1e4b3099b5c2a93156d94a 60c0b1737ef64896ae687f1922facc5e--1a26c4d08c1e4b3099b5c2a93156d94a 015851cde18e4c4ba92b4527aa238073 X 1a26c4d08c1e4b3099b5c2a93156d94a--015851cde18e4c4ba92b4527aa238073 015851cde18e4c4ba92b4527aa238073--f0a64d8ba3964875943fee34f78308af 12118e2c4b6447a8a5e92e98ea7f2998 RZ(-1.0*g0) 015851cde18e4c4ba92b4527aa238073--12118e2c4b6447a8a5e92e98ea7f2998 5c40f8afd0544a7aa02c7bf24f56b4f5 X 12118e2c4b6447a8a5e92e98ea7f2998--5c40f8afd0544a7aa02c7bf24f56b4f5 5c40f8afd0544a7aa02c7bf24f56b4f5--9d5db366c10f4915825b881afebcaf21 b8a606ae9ad64b9fb253cf7966ee009d 5c40f8afd0544a7aa02c7bf24f56b4f5--b8a606ae9ad64b9fb253cf7966ee009d cbb8d28d28464049b9c4fdb9472846f1 X b8a606ae9ad64b9fb253cf7966ee009d--cbb8d28d28464049b9c4fdb9472846f1 cbb8d28d28464049b9c4fdb9472846f1--2b2ce258912045f09483e91a2ad87539 735ab9f771c04eb59de47493153c2de7 RZ(-1.0*g0) cbb8d28d28464049b9c4fdb9472846f1--735ab9f771c04eb59de47493153c2de7 c59176d44086486a9537789ed401c723 X 735ab9f771c04eb59de47493153c2de7--c59176d44086486a9537789ed401c723 c59176d44086486a9537789ed401c723--099ca2a62a0046a6afc6f5f3f0530f49 bb488636095c40939aea6f38d447a184 RX(b07) c59176d44086486a9537789ed401c723--bb488636095c40939aea6f38d447a184 03e37336cfac40adaf0171c25de98ab6 bb488636095c40939aea6f38d447a184--03e37336cfac40adaf0171c25de98ab6 5b6eda994f064fa49d539471f8c6a247 03e37336cfac40adaf0171c25de98ab6--5b6eda994f064fa49d539471f8c6a247 6b61a7c36edd49109b4b2f3dc4283fc2 5b6eda994f064fa49d539471f8c6a247--6b61a7c36edd49109b4b2f3dc4283fc2 72bf1195c7a44a19b1d0e96578c14441 6b61a7c36edd49109b4b2f3dc4283fc2--72bf1195c7a44a19b1d0e96578c14441 d22f357020e747ed99ad9120d9e42d34 72bf1195c7a44a19b1d0e96578c14441--d22f357020e747ed99ad9120d9e42d34 355de718c3354322bd0dc0296794a13f d22f357020e747ed99ad9120d9e42d34--355de718c3354322bd0dc0296794a13f bfc917587a534138885d59b7aa048d96 X 355de718c3354322bd0dc0296794a13f--bfc917587a534138885d59b7aa048d96 bfc917587a534138885d59b7aa048d96--3473bb2d6370477789819ae655295f34 376761a6643642339e985edddd0b431e RZ(1.0*g1) bfc917587a534138885d59b7aa048d96--376761a6643642339e985edddd0b431e 4537cfe6c03847c0bc2e18db9e3cb8db X 376761a6643642339e985edddd0b431e--4537cfe6c03847c0bc2e18db9e3cb8db 4537cfe6c03847c0bc2e18db9e3cb8db--688023448dd1493da79fc00d22ce7bbc 5311b9e153804ed4933a3216292e23ef 4537cfe6c03847c0bc2e18db9e3cb8db--5311b9e153804ed4933a3216292e23ef a859c3ea0dfd4fbb905e7072fb345dad 5311b9e153804ed4933a3216292e23ef--a859c3ea0dfd4fbb905e7072fb345dad 3db714ee26ee4b81b0517e5aa8c3e6ca a859c3ea0dfd4fbb905e7072fb345dad--3db714ee26ee4b81b0517e5aa8c3e6ca 00932ca656bb494b98c9ef5772df2037 3db714ee26ee4b81b0517e5aa8c3e6ca--00932ca656bb494b98c9ef5772df2037 7352c80dce944738acf23d293af94168 00932ca656bb494b98c9ef5772df2037--7352c80dce944738acf23d293af94168 72bd5ae2abcb4a89be444810288ac3e4 7352c80dce944738acf23d293af94168--72bd5ae2abcb4a89be444810288ac3e4 04df83a96ae342db9a527657895ca416 72bd5ae2abcb4a89be444810288ac3e4--04df83a96ae342db9a527657895ca416 3cf77194242741b6b504865caf3a8d96 04df83a96ae342db9a527657895ca416--3cf77194242741b6b504865caf3a8d96 d414053c8acd446f97cd0f1f05f8acd7 3cf77194242741b6b504865caf3a8d96--d414053c8acd446f97cd0f1f05f8acd7 e465f0ac934043ec8fbc37dce70578e8 d414053c8acd446f97cd0f1f05f8acd7--e465f0ac934043ec8fbc37dce70578e8 096837300a5042068518aa9b2c317966 e465f0ac934043ec8fbc37dce70578e8--096837300a5042068518aa9b2c317966 af6d7bc48f0e4d168045675e2a867a2e 096837300a5042068518aa9b2c317966--af6d7bc48f0e4d168045675e2a867a2e 6bdf59d85eef44419bf355d346f9c2c7 af6d7bc48f0e4d168045675e2a867a2e--6bdf59d85eef44419bf355d346f9c2c7 5afde11488f04aafab79eecda0e1dde4 6bdf59d85eef44419bf355d346f9c2c7--5afde11488f04aafab79eecda0e1dde4 5ee14bea4c2546a9b4634394b8a25f0f 5afde11488f04aafab79eecda0e1dde4--5ee14bea4c2546a9b4634394b8a25f0f 176da03d577b4a3e89b91255393803ab 5ee14bea4c2546a9b4634394b8a25f0f--176da03d577b4a3e89b91255393803ab 5e3f272f782d44d0b3efccc10bbcaaf3 176da03d577b4a3e89b91255393803ab--5e3f272f782d44d0b3efccc10bbcaaf3 41049eaf5f88496b8fa862d8d06c66c9 5e3f272f782d44d0b3efccc10bbcaaf3--41049eaf5f88496b8fa862d8d06c66c9 bf0cc4e3f7f643dbaba300fd1fb35e63 41049eaf5f88496b8fa862d8d06c66c9--bf0cc4e3f7f643dbaba300fd1fb35e63 a60ace9c53c2434eb02e740238525dca bf0cc4e3f7f643dbaba300fd1fb35e63--a60ace9c53c2434eb02e740238525dca 50dca01ff33047b68206f07ae4c34876 a60ace9c53c2434eb02e740238525dca--50dca01ff33047b68206f07ae4c34876 047a56a1b2934506b0c49a9f27f36f57 50dca01ff33047b68206f07ae4c34876--047a56a1b2934506b0c49a9f27f36f57 5331f9c11a784d13acc6de139a068ebd 047a56a1b2934506b0c49a9f27f36f57--5331f9c11a784d13acc6de139a068ebd c922ce38643942b6b53064d2163d29dd 5331f9c11a784d13acc6de139a068ebd--c922ce38643942b6b53064d2163d29dd 8f533ae50c374bb7ba51bda345ff5f0e c922ce38643942b6b53064d2163d29dd--8f533ae50c374bb7ba51bda345ff5f0e 771ec7bcddee429c93ff7658d459a59e 8f533ae50c374bb7ba51bda345ff5f0e--771ec7bcddee429c93ff7658d459a59e 18a3969cd93849238252b30813477420 771ec7bcddee429c93ff7658d459a59e--18a3969cd93849238252b30813477420 0b9b2b20feeb4339a77bf84257cf4292 18a3969cd93849238252b30813477420--0b9b2b20feeb4339a77bf84257cf4292 350307dbcb4442a086b0107abecb7a58 0b9b2b20feeb4339a77bf84257cf4292--350307dbcb4442a086b0107abecb7a58 cce4b85425734540908679dce6f8b45d 350307dbcb4442a086b0107abecb7a58--cce4b85425734540908679dce6f8b45d 9e2a86a51ef94fc28f78be162ef52aee cce4b85425734540908679dce6f8b45d--9e2a86a51ef94fc28f78be162ef52aee 731bbb5142004727b98a48b594bb4a05 9e2a86a51ef94fc28f78be162ef52aee--731bbb5142004727b98a48b594bb4a05 5bfb21b79a314f18acb565a6e19bea47 731bbb5142004727b98a48b594bb4a05--5bfb21b79a314f18acb565a6e19bea47 cb63f1b534ad46acaa1d7a62110b658f 5bfb21b79a314f18acb565a6e19bea47--cb63f1b534ad46acaa1d7a62110b658f 00b79f7653204617b1b1865b5a188030 cb63f1b534ad46acaa1d7a62110b658f--00b79f7653204617b1b1865b5a188030 13af4ec344c9498cb2f3a221a5a086b0 00b79f7653204617b1b1865b5a188030--13af4ec344c9498cb2f3a221a5a086b0 1b490a4715594b9a866c4f0dc9d5e040 13af4ec344c9498cb2f3a221a5a086b0--1b490a4715594b9a866c4f0dc9d5e040 1491338b7b3046279042d7040091a99e 1b490a4715594b9a866c4f0dc9d5e040--1491338b7b3046279042d7040091a99e 87723788b9e14a54a6a007074655b396 1491338b7b3046279042d7040091a99e--87723788b9e14a54a6a007074655b396 437a7186fb2441f987ee4eef8f7184e4 87723788b9e14a54a6a007074655b396--437a7186fb2441f987ee4eef8f7184e4 0588b302f6d04ecd9ebf40ac80abfab1 X 437a7186fb2441f987ee4eef8f7184e4--0588b302f6d04ecd9ebf40ac80abfab1 0588b302f6d04ecd9ebf40ac80abfab1--560d3d0917e64b3dbc38da5f5fc2bf08 f8ab130db01b427eb1113b38a9a2ca75 RZ(-1.0*g1) 0588b302f6d04ecd9ebf40ac80abfab1--f8ab130db01b427eb1113b38a9a2ca75 9ca63cb09a694b5fb666c7574cc6a182 X f8ab130db01b427eb1113b38a9a2ca75--9ca63cb09a694b5fb666c7574cc6a182 9ca63cb09a694b5fb666c7574cc6a182--2d9a24145f6e4577b0193da5f5122774 2c19e7cefbe44fffa401c854d443c091 9ca63cb09a694b5fb666c7574cc6a182--2c19e7cefbe44fffa401c854d443c091 bd16bfcf524148f6a50ca88498cbf929 2c19e7cefbe44fffa401c854d443c091--bd16bfcf524148f6a50ca88498cbf929 7214fd7a3a5f48909126d215ad712923 bd16bfcf524148f6a50ca88498cbf929--7214fd7a3a5f48909126d215ad712923 6a37bd404f2f4655923543bca0d73c2d 7214fd7a3a5f48909126d215ad712923--6a37bd404f2f4655923543bca0d73c2d ef17612658594acca2f8a38e96c3f7b1 6a37bd404f2f4655923543bca0d73c2d--ef17612658594acca2f8a38e96c3f7b1 19bd84693454440ab0e8fada19f1dfb7 ef17612658594acca2f8a38e96c3f7b1--19bd84693454440ab0e8fada19f1dfb7 f746cf5a342c4bf0b8e6861ddc9e5029 19bd84693454440ab0e8fada19f1dfb7--f746cf5a342c4bf0b8e6861ddc9e5029 d7bb0a928e154a0294e376836c68c1ab f746cf5a342c4bf0b8e6861ddc9e5029--d7bb0a928e154a0294e376836c68c1ab f1da876916b3405bae8adfce8041d384 d7bb0a928e154a0294e376836c68c1ab--f1da876916b3405bae8adfce8041d384 d782dbf4ec014dbc8d5ef0c8c931bcf3 f1da876916b3405bae8adfce8041d384--d782dbf4ec014dbc8d5ef0c8c931bcf3 31b3ede966f540da8f47b7759db5843a d782dbf4ec014dbc8d5ef0c8c931bcf3--31b3ede966f540da8f47b7759db5843a 9868ac1bd6b243559718f72d57747142 31b3ede966f540da8f47b7759db5843a--9868ac1bd6b243559718f72d57747142 70fbf3eb010449a1b64e1f23663b88f5 9868ac1bd6b243559718f72d57747142--70fbf3eb010449a1b64e1f23663b88f5 7130f79fb586479498bb9f92f86d0c22 70fbf3eb010449a1b64e1f23663b88f5--7130f79fb586479498bb9f92f86d0c22 2e9cbcda89c947aea11ac6a3511905c2 7130f79fb586479498bb9f92f86d0c22--2e9cbcda89c947aea11ac6a3511905c2 5b21c7bdd7224fbc9f9eafab3505fa7b 2e9cbcda89c947aea11ac6a3511905c2--5b21c7bdd7224fbc9f9eafab3505fa7b 67338a818794419795c9463b35befe42 5b21c7bdd7224fbc9f9eafab3505fa7b--67338a818794419795c9463b35befe42 94e2ac093d014aee9d5d0dec0c9678d4 67338a818794419795c9463b35befe42--94e2ac093d014aee9d5d0dec0c9678d4 240637e02971434b90728c7d151357f2 94e2ac093d014aee9d5d0dec0c9678d4--240637e02971434b90728c7d151357f2 c142174905f047c586e9d107a4b85b0b 240637e02971434b90728c7d151357f2--c142174905f047c586e9d107a4b85b0b 2d124e3d9e4c44a5adb7e88b01c94a4a c142174905f047c586e9d107a4b85b0b--2d124e3d9e4c44a5adb7e88b01c94a4a bb0e41ffd5764198a8dc39eda5fd572f 2d124e3d9e4c44a5adb7e88b01c94a4a--bb0e41ffd5764198a8dc39eda5fd572f 0df5a35c2e664e4e89e9744e4176a439 bb0e41ffd5764198a8dc39eda5fd572f--0df5a35c2e664e4e89e9744e4176a439 feb67658f7164cc7b9c79b9bd21473d0 0df5a35c2e664e4e89e9744e4176a439--feb67658f7164cc7b9c79b9bd21473d0 743518119ea94775863bd96be2b67716 feb67658f7164cc7b9c79b9bd21473d0--743518119ea94775863bd96be2b67716 d873ed44180143b293d8f89139cf4c4c 743518119ea94775863bd96be2b67716--d873ed44180143b293d8f89139cf4c4c f7ddb6603212447094739252f3e9e4ac d873ed44180143b293d8f89139cf4c4c--f7ddb6603212447094739252f3e9e4ac 29fd4832b72440d4a6f10a4dce0077c0 f7ddb6603212447094739252f3e9e4ac--29fd4832b72440d4a6f10a4dce0077c0 f444dcc3212d4cdeb8d8c5c2b556ebb0 29fd4832b72440d4a6f10a4dce0077c0--f444dcc3212d4cdeb8d8c5c2b556ebb0 9d2729844d2f4b63846c3e944fed5e48 f444dcc3212d4cdeb8d8c5c2b556ebb0--9d2729844d2f4b63846c3e944fed5e48 17ecc44faf39410db07fe89ad30c9cfe 9d2729844d2f4b63846c3e944fed5e48--17ecc44faf39410db07fe89ad30c9cfe 742d523b4d7c4952a7816e6d2ccbd191 17ecc44faf39410db07fe89ad30c9cfe--742d523b4d7c4952a7816e6d2ccbd191 7567fb2e25aa4e899d9cc7b8c8859123 742d523b4d7c4952a7816e6d2ccbd191--7567fb2e25aa4e899d9cc7b8c8859123 27ae0aadc3a24863b43cf41bc5eb8bc6 7567fb2e25aa4e899d9cc7b8c8859123--27ae0aadc3a24863b43cf41bc5eb8bc6 c20a6c6043fd4d98a5b77b81f3f76f6b 27ae0aadc3a24863b43cf41bc5eb8bc6--c20a6c6043fd4d98a5b77b81f3f76f6b d159f0e72b3744d980a91e578210772b c20a6c6043fd4d98a5b77b81f3f76f6b--d159f0e72b3744d980a91e578210772b 4924fcafeb8b4d328a553f3491d04488 d159f0e72b3744d980a91e578210772b--4924fcafeb8b4d328a553f3491d04488 40095044f8a34a72b8b4af1c4a8d842b 4924fcafeb8b4d328a553f3491d04488--40095044f8a34a72b8b4af1c4a8d842b 548f93b704b24a72863dac3d7f1344a5 40095044f8a34a72b8b4af1c4a8d842b--548f93b704b24a72863dac3d7f1344a5 6fed3f8dff774bef9c33e88a38eb2f94 548f93b704b24a72863dac3d7f1344a5--6fed3f8dff774bef9c33e88a38eb2f94 e3e2a5bcc3254d1b99a262e7e3a89b13 6fed3f8dff774bef9c33e88a38eb2f94--e3e2a5bcc3254d1b99a262e7e3a89b13 feceffd4532b4385b83b7a8eef0e485f e3e2a5bcc3254d1b99a262e7e3a89b13--feceffd4532b4385b83b7a8eef0e485f c2f4c54d1a32436c8ed6d7cd61666dfe feceffd4532b4385b83b7a8eef0e485f--c2f4c54d1a32436c8ed6d7cd61666dfe acf8672764954be48338f73a03d4c4a4 c2f4c54d1a32436c8ed6d7cd61666dfe--acf8672764954be48338f73a03d4c4a4 0178a79adbca4ff9b9fd4e85a4e4f2d6 acf8672764954be48338f73a03d4c4a4--0178a79adbca4ff9b9fd4e85a4e4f2d6 4de6f5426d4245cb8feffd2fc4c6d504 0178a79adbca4ff9b9fd4e85a4e4f2d6--4de6f5426d4245cb8feffd2fc4c6d504 bf0c06f97160458da960f233b257f7d4 X 4de6f5426d4245cb8feffd2fc4c6d504--bf0c06f97160458da960f233b257f7d4 bf0c06f97160458da960f233b257f7d4--01699dcdc01040cca66ae9fe65036608 22c8a5ed66ac436c8c8ff8409d2b7d4f RZ(-1.0*g1) bf0c06f97160458da960f233b257f7d4--22c8a5ed66ac436c8c8ff8409d2b7d4f b1cb9aceb8b24e1a97b5b371c827f4f6 X 22c8a5ed66ac436c8c8ff8409d2b7d4f--b1cb9aceb8b24e1a97b5b371c827f4f6 b1cb9aceb8b24e1a97b5b371c827f4f6--2ba4c1cb7d044dc5a8c491f7101b9cbc 49f5b97e601141b6851d4d98916c2b33 b1cb9aceb8b24e1a97b5b371c827f4f6--49f5b97e601141b6851d4d98916c2b33 c8e1ab0049af4a05b9fd58a5fb5f4d61 49f5b97e601141b6851d4d98916c2b33--c8e1ab0049af4a05b9fd58a5fb5f4d61 7d9d481c37a34dab9f7ee1a24d849ef2 c8e1ab0049af4a05b9fd58a5fb5f4d61--7d9d481c37a34dab9f7ee1a24d849ef2 e2905ef05965463faaf5e8386aba35c5 7d9d481c37a34dab9f7ee1a24d849ef2--e2905ef05965463faaf5e8386aba35c5 16dafcc6464f421fa07f964ac3d48cae e2905ef05965463faaf5e8386aba35c5--16dafcc6464f421fa07f964ac3d48cae ab9ff06a36a543e0bc815be2b3600db4 16dafcc6464f421fa07f964ac3d48cae--ab9ff06a36a543e0bc815be2b3600db4 18444546dd9348b69e37e8cdea1a14cf ab9ff06a36a543e0bc815be2b3600db4--18444546dd9348b69e37e8cdea1a14cf 31e869dcac1649709c69a073e67e3ab4 18444546dd9348b69e37e8cdea1a14cf--31e869dcac1649709c69a073e67e3ab4 8ae2a4ab10bb477991897b17ce36e505 31e869dcac1649709c69a073e67e3ab4--8ae2a4ab10bb477991897b17ce36e505 d07da03ccd714634a73974cb53729d50 8ae2a4ab10bb477991897b17ce36e505--d07da03ccd714634a73974cb53729d50 518f9c123c0a4ef495a8f15797370d5b d07da03ccd714634a73974cb53729d50--518f9c123c0a4ef495a8f15797370d5b a672041d8ed94d2daf945e2af431dee7 518f9c123c0a4ef495a8f15797370d5b--a672041d8ed94d2daf945e2af431dee7 2e9cd2d7ec544f388c58b3c7d33f3c83 a672041d8ed94d2daf945e2af431dee7--2e9cd2d7ec544f388c58b3c7d33f3c83 0a250a260ba84c85900e6717bfb5b3b0 2e9cd2d7ec544f388c58b3c7d33f3c83--0a250a260ba84c85900e6717bfb5b3b0 6fc0c9497c3d44c8a6e2b1332683b4ee 0a250a260ba84c85900e6717bfb5b3b0--6fc0c9497c3d44c8a6e2b1332683b4ee 2e3b18ca07e74ab5a246f1df94aff939 6fc0c9497c3d44c8a6e2b1332683b4ee--2e3b18ca07e74ab5a246f1df94aff939 a4a89b954ac54786b8ce849b5658c57e 2e3b18ca07e74ab5a246f1df94aff939--a4a89b954ac54786b8ce849b5658c57e d0fcf4699877449db6596196d8914d91 a4a89b954ac54786b8ce849b5658c57e--d0fcf4699877449db6596196d8914d91 97fbec1a2c81484bb159187e80247894 d0fcf4699877449db6596196d8914d91--97fbec1a2c81484bb159187e80247894 99740247d9f34c86b282c5262168854f 97fbec1a2c81484bb159187e80247894--99740247d9f34c86b282c5262168854f d3221a6893ee47cd8b12e159f9d38f10 99740247d9f34c86b282c5262168854f--d3221a6893ee47cd8b12e159f9d38f10 09e9c6a0b2464d148b826a335f5a91d9 d3221a6893ee47cd8b12e159f9d38f10--09e9c6a0b2464d148b826a335f5a91d9 5e1217d4a51a46b085352b72d156998f 09e9c6a0b2464d148b826a335f5a91d9--5e1217d4a51a46b085352b72d156998f b98b5e218f8b436f848f464d465994b6 5e1217d4a51a46b085352b72d156998f--b98b5e218f8b436f848f464d465994b6 edb182399c934019a9f979c80992e1c6 b98b5e218f8b436f848f464d465994b6--edb182399c934019a9f979c80992e1c6 a963509aabe4411d917d89f3140f792a edb182399c934019a9f979c80992e1c6--a963509aabe4411d917d89f3140f792a 2f9854a2233b42468333a7eadecff812 a963509aabe4411d917d89f3140f792a--2f9854a2233b42468333a7eadecff812 b8584675cecd4e49a51bc56c46236f08 2f9854a2233b42468333a7eadecff812--b8584675cecd4e49a51bc56c46236f08 962242e6c35c4cb78829c27a5a1d9338 b8584675cecd4e49a51bc56c46236f08--962242e6c35c4cb78829c27a5a1d9338 ba0f0003474e45288798600fd3e08796 962242e6c35c4cb78829c27a5a1d9338--ba0f0003474e45288798600fd3e08796 75524124f72c410eb3c5a21fc6a26979 ba0f0003474e45288798600fd3e08796--75524124f72c410eb3c5a21fc6a26979 239a00062fa34ec2b492c4f389fcff92 75524124f72c410eb3c5a21fc6a26979--239a00062fa34ec2b492c4f389fcff92 f1ccbb3dd62e4283adfd0410fbbea709 239a00062fa34ec2b492c4f389fcff92--f1ccbb3dd62e4283adfd0410fbbea709 6df18f67027041918149f04b62bd54fa f1ccbb3dd62e4283adfd0410fbbea709--6df18f67027041918149f04b62bd54fa 693fffeab6a042018368fa117641d4aa X 6df18f67027041918149f04b62bd54fa--693fffeab6a042018368fa117641d4aa 693fffeab6a042018368fa117641d4aa--fa6d5426703c405a8d466e88a7039edb d18df7a014d7424f8abd661e2fe9409b RZ(-1.0*g1) 693fffeab6a042018368fa117641d4aa--d18df7a014d7424f8abd661e2fe9409b 183e6f819b4e45849c98356fe932ca1b X d18df7a014d7424f8abd661e2fe9409b--183e6f819b4e45849c98356fe932ca1b 183e6f819b4e45849c98356fe932ca1b--f9e03b829124420a88b69a49de015448 f4a441259d1449b4b5081f39866566fd 183e6f819b4e45849c98356fe932ca1b--f4a441259d1449b4b5081f39866566fd 99b95d7f652a497f95042ed49aae4f8b f4a441259d1449b4b5081f39866566fd--99b95d7f652a497f95042ed49aae4f8b f3735d4bdb5849b9af16f9ca28b12fd4 99b95d7f652a497f95042ed49aae4f8b--f3735d4bdb5849b9af16f9ca28b12fd4 e3fb14d62c964fafa01c2b93a9eab425 f3735d4bdb5849b9af16f9ca28b12fd4--e3fb14d62c964fafa01c2b93a9eab425 7c2eb6ffe4244e7b8e068d3874c36840 e3fb14d62c964fafa01c2b93a9eab425--7c2eb6ffe4244e7b8e068d3874c36840 5219fc26da9643e098272834a028e377 7c2eb6ffe4244e7b8e068d3874c36840--5219fc26da9643e098272834a028e377 0ff84c3a03eb47cc87de3538ea50f8d1 X 5219fc26da9643e098272834a028e377--0ff84c3a03eb47cc87de3538ea50f8d1 0ff84c3a03eb47cc87de3538ea50f8d1--693b337e150c41809e74732e8c143786 eee9ca7ed21c435799d021252a9df1e7 RZ(-1.0*g1) 0ff84c3a03eb47cc87de3538ea50f8d1--eee9ca7ed21c435799d021252a9df1e7 94a6d5a4a53a47909234a67e179cc9ca X eee9ca7ed21c435799d021252a9df1e7--94a6d5a4a53a47909234a67e179cc9ca 94a6d5a4a53a47909234a67e179cc9ca--cb9ed90e3dbd4e61a8a6900ebe473a5f 839a81e4407b4ca494c83f22285d5e37 94a6d5a4a53a47909234a67e179cc9ca--839a81e4407b4ca494c83f22285d5e37 45e58d3bc01a415cab385c020290eee6 X 839a81e4407b4ca494c83f22285d5e37--45e58d3bc01a415cab385c020290eee6 45e58d3bc01a415cab385c020290eee6--32ab4cd4aa9d49ccb191bb4196b2228c 1af1b505cb464e189b7a1764f5f27448 RZ(-1.0*g1) 45e58d3bc01a415cab385c020290eee6--1af1b505cb464e189b7a1764f5f27448 a5ae92fe59e64c9798020fb698cc5282 X 1af1b505cb464e189b7a1764f5f27448--a5ae92fe59e64c9798020fb698cc5282 a5ae92fe59e64c9798020fb698cc5282--e18d82847a9749b2ba60404fb442d7ad 4a97c1a4b5e643999b709ed8dab9b535 RX(b17) a5ae92fe59e64c9798020fb698cc5282--4a97c1a4b5e643999b709ed8dab9b535 4a97c1a4b5e643999b709ed8dab9b535--746223b7fd684c5498b9950b0b029dea  Here we used the <code>digital_decomposition()</code> method provided by Qadence for obtaining the set of gates corresponding to the Hamiltonian evolution operation in the cost layer.</p>"},{"location":"qml/qaoa/#train-the-qaoa-circuit-to-solve-maxcut","title":"Train the QAOA circuit to solve MaxCut","text":"<p>Now that we have the circuit, we can create the associated Qadence <code>QuantumModel</code> and train it using standard gradient based optimization. Notice that we give the full list of edge generators since the loss function to be minimized reads:</p> \\[ \\mathcal{L} = \\sum_{i,j}^{N_{\\mathcal{E}}} \\frac{1}{2} \\left(1 - \\langle \\psi | \\sigma_i^z \\sigma_j^z | \\psi \\rangle \\right) \\] <p>where \\(\\psi(\\beta, \\gamma)\\) is the wavefunction obtained by propagating the QAQA quantum circuit and the sum runs over the edges of the graph \\(N_{\\mathcal{E}}\\).</p> <pre><code>import torch\nfrom qadence import QuantumModel\nmodel = QuantumModel(circuit, backend=\"pyqtorch\", observable=zz_ops, diff_mode='gpsr')\n_ = torch.manual_seed(seed)\ndef loss_function(_model: QuantumModel):\nexpval_ops = model.expectation().squeeze()\n# this corresponds to the MaxCut cost by definition\n# with negative sign in front to perform maximization\nexpval = 0.0\nfor val in expval_ops:\nexpval += 0.5 * (1 - val)\nreturn -1.0 * expval\n# initialize the parameters to random values\nmodel.reset_vparams(torch.rand(model.num_vparams))\ninitial_loss = loss_function(model)\nprint(f\"Initial loss: {initial_loss}\")\n# train the model\nn_epochs = 100\nlr = 1.0\noptimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\nfor i in range(n_epochs):\noptimizer.zero_grad()\nloss = loss_function(model)\nloss.backward()\noptimizer.step()\nif (i+1) % (n_epochs // 10) == 0:\nprint(f\"MaxCut cost at iteration {i+1}: {-loss.item()}\")\n</code></pre> <pre><code>Initial loss: -5.258304538813915\nMaxCut cost at iteration 10: 12.983455678548816\nMaxCut cost at iteration 20: 13.99917853783122\nMaxCut cost at iteration 30: 13.999996806875096\nMaxCut cost at iteration 40: 13.987928781862001\nMaxCut cost at iteration 50: 13.99219275204449\nMaxCut cost at iteration 60: 13.999984812932626\nMaxCut cost at iteration 70: 13.999999971320824\nMaxCut cost at iteration 80: 13.999999999945844\nMaxCut cost at iteration 90: 13.999999999999897\nMaxCut cost at iteration 100: 14.0\n</code></pre>"},{"location":"qml/qaoa/#results","title":"Results","text":"<p>Given the optimized model, we need now to sample the resulting quantum state to recover the bitstring with the highest probability which corresponds to the maximum cut of the graph. <pre><code>samples = model.sample(n_shots=100)[0]\nmost_frequent = max(samples, key=samples.get)\nprint(f\"Most frequently sampled bitstring corresponding to the maximum cut: {most_frequent}\")\n# let's now draw the cut obtained with the QAOA procedure\ncolors = []\nlabels = {}\nfor node, b in zip(graph.nodes(), most_frequent):\ncolors.append(\"green\") if int(b) == 0 else colors.append(\"red\")\nlabels[node] = \"A\" if int(b) == 0 else \"B\"\nnx.draw_networkx(graph, node_color=colors, with_labels=True, labels=labels)\n</code></pre>   Most frequently sampled bitstring corresponding to the maximum cut: 10010011  2023-10-10T21:44:04.029525 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ </p>"},{"location":"qml/qaoa/#references","title":"References","text":"<ol> <li> <p>Farhi et al. - A Quantum Approximate Optimization Algorithm\u00a0\u21a9</p> </li> </ol>"},{"location":"qml/qcl/","title":"Quantum Circuit Learning","text":"<p>In this tutorial, we show how to apply <code>qadence</code> for solving a basic quantum machine learning application: fitting a simple function with the quantum circuit learning (QCL) algorithm.</p> <p>Quantum circuit learning <sup>1</sup> is a supervised quantum machine learning algorithm that uses parametrized quantum neural networks to learn the behavior of an arbitrary mathematical function starting from some training data extracted from it. We choose the function</p> <p>For this tutorial, we show how to fit the \\(sin(x)\\) function in the domain \\([-1, 1]\\).</p> <p>Let's start with defining training and test data.</p> <pre><code>from typing import Callable\nimport torch\n# make sure all tensors are kept on the same device\n# only available from PyTorch 2.0\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.set_default_device(device)\n# notice that the domain does not include 1 and -1\n# this avoids a singularity in the rotation angles when\n# when encoding the domain points into the quantum circuit\n# with a non-linear transformation (see below)\ndef qcl_training_data(\ndomain: tuple = (-0.99, 0.99), n_points: int = 100\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\nstart, end = domain\nx_rand, _ = torch.sort(torch.DoubleTensor(n_points).uniform_(start, end))\ny_rand = torch.sin(x_rand)\nreturn x_rand, y_rand\ntest_frac = 0.25\nx, y = qcl_training_data()\nn_test = int(len(x) * test_frac)\nx_train, y_train = x[0:n_test-len(x)], y[0:n_test-len(x)]\nx_test, y_test = x[n_test-len(x):], y[n_test-len(x):]\n</code></pre> <pre><code>\n</code></pre>"},{"location":"qml/qcl/#train-the-qcl-model","title":"Train the QCL model","text":"<p>Qadence provides the <code>QNN</code> convenience constructor to build a quantum neural network. The <code>QNN</code> class needs a circuit and a list of observables; both the number of feature parameters and the number of observables in the list must be equal to the number of desired outputs of the quantum neural network.</p> <p>As observable, we use the total qubit magnetization leveraging a convenience constructor provided by <code>qadence</code>:</p> \\[ \\hat{O} = \\sum_i^N \\hat{\\sigma}_i^z \\] <pre><code>import sympy\nimport qadence as qd\nfrom qadence.operations import RX\nn_qubits = 8\n# create a simple feature map with a non-linear parameter transformation\nfeature_param = qd.FeatureParameter(\"phi\")\nfeature_map = qd.kron(RX(i, feature_param) for i in range(n_qubits))\nfeatre_map = qd.tag(feature_map, \"feature_map\")\n# create a digital-analog variational ansatz using Qadence convenience constructors\nansatz = qd.hea(n_qubits, depth=n_qubits, strategy=qd.Strategy.SDAQC)\nansatz = qd.tag(ansatz, \"ansatz\")\n# total magnetization observable\nobservable = qd.hamiltonian_factory(n_qubits, detuning = qd.Z)\ncircuit = qd.QuantumCircuit(n_qubits, feature_map, ansatz)\nmodel = qd.QNN(circuit, [observable])\nexpval = model(values=torch.rand(10))\nprint(expval)\n</code></pre> <pre><code>tensor([[ 0.1640],\n[-0.0787],\n[-0.4532],\n[ 0.0720],\n[-0.1039],\n[ 0.1009],\n[-0.2124],\n[ 0.1358],\n[-0.4851],\n[ 0.1562]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> <p>The QCL algorithm uses the output of the quantum neural network as a tunable function approximator. We can use standard PyTorch code for training the QNN using a mean-square error loss, the Adam optimizer and also train on the GPU if any is available:</p> <pre><code># train the model\nn_epochs = 200\nlr = 0.5\ninput_values = {\"phi\": x_train}\nmse_loss = torch.nn.MSELoss()  # standard PyTorch loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)  # standard PyTorch Adam optimizer\nprint(f\"Initial loss: {mse_loss(model(input_values), y_train)}\")\ny_pred_initial = model({\"phi\": x_test})\nrunning_loss = 0.0\nfor i in range(n_epochs):\noptimizer.zero_grad()\nloss = mse_loss(model(input_values), y_train)\nloss.backward()\noptimizer.step()\nif (i+1) % 20 == 0:\nprint(f\"Epoch {i+1} - Loss: {loss.item()}\")\n</code></pre> <pre><code>Initial loss: 0.04038257974270301\nEpoch 20 - Loss: 0.060943553558947074\nEpoch 40 - Loss: 0.02019946267299006\nEpoch 60 - Loss: 0.03476874387797955\nEpoch 80 - Loss: 0.10615164456464049\nEpoch 100 - Loss: 1.2905890122975225\nEpoch 120 - Loss: 0.21929946455255525\nEpoch 140 - Loss: 0.013236293097701446\nEpoch 160 - Loss: 0.016120784698980737\nEpoch 180 - Loss: 0.023339611950154646\nEpoch 200 - Loss: 0.03365795073769631\n</code></pre> <p>The quantum model is now trained on the training data points. Let's see how well it fits the function on the test set.</p> <pre><code>import matplotlib.pyplot as plt\ny_pred = model({\"phi\": x_test})\n# convert all the results to numpy arrays for plotting\nx_train_np = x_train.cpu().detach().numpy().flatten()\ny_train_np = y_train.cpu().detach().numpy().flatten()\nx_test_np = x_test.cpu().detach().numpy().flatten()\ny_pred_initial_np = y_pred_initial.cpu().detach().numpy().flatten()\ny_pred_np = y_pred.cpu().detach().numpy().flatten()\nfig, _ = plt.subplots()\nplt.scatter(x_train_np, y_train_np, label=\"Training points\", marker=\"o\", color=\"orange\")\nplt.plot(x_test_np, y_pred_initial_np, label=\"Initial prediction\", color=\"green\", alpha=0.5)\nplt.plot(x_test_np, y_pred_np, label=\"Final prediction\")\nplt.legend()\n</code></pre> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?&gt;\n&lt;!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n\"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"&gt;\n&lt;svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"460.8pt\" height=\"345.6pt\" viewBox=\"0 0 460.8 345.6\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\"&gt;\n&lt;metadata&gt;\n&lt;rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"&gt;\n&lt;cc:Work&gt;\n&lt;dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/&gt;\n&lt;dc:date&gt;2023-10-10T21:44:47.358040&lt;/dc:date&gt;\n&lt;dc:format&gt;image/svg+xml&lt;/dc:format&gt;\n&lt;dc:creator&gt;\n&lt;cc:Agent&gt;\n&lt;dc:title&gt;Matplotlib v3.7.3, https://matplotlib.org/&lt;/dc:title&gt;\n&lt;/cc:Agent&gt;\n&lt;/dc:creator&gt;\n&lt;/cc:Work&gt;\n&lt;/rdf:RDF&gt;\n&lt;/metadata&gt;\n&lt;defs&gt;\n&lt;style type=\"text/css\"&gt;*{stroke-linejoin: round; stroke-linecap: butt}&lt;/style&gt;\n&lt;/defs&gt;\n&lt;g id=\"figure_1\"&gt;\n&lt;g id=\"patch_1\"&gt;\n&lt;path d=\"M 0 345.6 \nL 460.8 345.6 \nL 460.8 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/&gt;\n&lt;/g&gt;\n&lt;g id=\"axes_1\"&gt;\n&lt;g id=\"patch_2\"&gt;\n&lt;path d=\"M 57.6 307.584 \nL 414.72 307.584 \nL 414.72 41.472 \nL 57.6 41.472 \nz\n\" style=\"fill: #ffffff\"/&gt;\n&lt;/g&gt;\n&lt;g id=\"PathCollection_1\"&gt;\n&lt;defs&gt;\n&lt;path id=\"m35c160629b\" d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" style=\"stroke: #ffa500\"/&gt;\n&lt;/defs&gt;\n&lt;g clip-path=\"url(#pfe8f3a97c8)\"&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"73.832727\" y=\"295.488\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"76.444293\" y=\"293.46174\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"77.352048\" y=\"292.746775\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"79.814458\" y=\"290.779886\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"82.435471\" y=\"288.642635\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"83.265341\" y=\"287.95663\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"90.615669\" y=\"281.688473\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"93.06401\" y=\"279.525283\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"98.764986\" y=\"274.346284\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"101.018411\" y=\"272.245422\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"105.613865\" y=\"267.868926\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"106.948085\" y=\"266.575484\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"107.069051\" y=\"266.457713\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"109.734667\" y=\"263.841569\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"113.198769\" y=\"260.382642\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"113.216208\" y=\"260.365062\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"122.252911\" y=\"251.036985\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"126.117629\" y=\"246.918586\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"127.336906\" y=\"245.60379\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"134.760075\" y=\"237.444078\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"140.203184\" y=\"231.298293\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"142.205778\" y=\"229.004064\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"144.965472\" y=\"225.814227\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"154.920388\" y=\"214.048717\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"156.004477\" y=\"212.744153\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"matplotlib.axis_1\"&gt;\n&lt;g id=\"xtick_1\"&gt;\n&lt;g id=\"line2d_1\"&gt;\n&lt;defs&gt;\n&lt;path id=\"md481e8b3d1\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/defs&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#md481e8b3d1\" x=\"68.5969\" y=\"307.584\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_1\"&gt;\n&lt;!-- \u22121.00 --&gt;\n&lt;g transform=\"translate(53.274243 322.182437) scale(0.1 -0.1)\"&gt;\n&lt;defs&gt;\n&lt;path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;/defs&gt;\n&lt;use xlink:href=\"#DejaVuSans-2212\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"242.822266\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"xtick_2\"&gt;\n&lt;g id=\"line2d_2\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#md481e8b3d1\" x=\"110.04231\" y=\"307.584\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_2\"&gt;\n&lt;!-- \u22120.75 --&gt;\n&lt;g transform=\"translate(94.719654 322.182437) scale(0.1 -0.1)\"&gt;\n&lt;defs&gt;\n&lt;path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;/defs&gt;\n&lt;use xlink:href=\"#DejaVuSans-2212\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-37\" x=\"179.199219\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-35\" x=\"242.822266\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"xtick_3\"&gt;\n&lt;g id=\"line2d_3\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#md481e8b3d1\" x=\"151.48772\" y=\"307.584\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_3\"&gt;\n&lt;!-- \u22120.50 --&gt;\n&lt;g transform=\"translate(136.165064 322.182437) scale(0.1 -0.1)\"&gt;\n&lt;use xlink:href=\"#DejaVuSans-2212\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"242.822266\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"xtick_4\"&gt;\n&lt;g id=\"line2d_4\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#md481e8b3d1\" x=\"192.93313\" y=\"307.584\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_4\"&gt;\n&lt;!-- \u22120.25 --&gt;\n&lt;g transform=\"translate(177.610474 322.182437) scale(0.1 -0.1)\"&gt;\n&lt;defs&gt;\n&lt;path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;/defs&gt;\n&lt;use xlink:href=\"#DejaVuSans-2212\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-32\" x=\"179.199219\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-35\" x=\"242.822266\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"xtick_5\"&gt;\n&lt;g id=\"line2d_5\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#md481e8b3d1\" x=\"234.37854\" y=\"307.584\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_5\"&gt;\n&lt;!-- 0.00 --&gt;\n&lt;g transform=\"translate(223.245728 322.182437) scale(0.1 -0.1)\"&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"xtick_6\"&gt;\n&lt;g id=\"line2d_6\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#md481e8b3d1\" x=\"275.823951\" y=\"307.584\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_6\"&gt;\n&lt;!-- 0.25 --&gt;\n&lt;g transform=\"translate(264.691138 322.182437) scale(0.1 -0.1)\"&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"xtick_7\"&gt;\n&lt;g id=\"line2d_7\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#md481e8b3d1\" x=\"317.269361\" y=\"307.584\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_7\"&gt;\n&lt;!-- 0.50 --&gt;\n&lt;g transform=\"translate(306.136548 322.182437) scale(0.1 -0.1)\"&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"xtick_8\"&gt;\n&lt;g id=\"line2d_8\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#md481e8b3d1\" x=\"358.714771\" y=\"307.584\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_8\"&gt;\n&lt;!-- 0.75 --&gt;\n&lt;g transform=\"translate(347.581959 322.182437) scale(0.1 -0.1)\"&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"xtick_9\"&gt;\n&lt;g id=\"line2d_9\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#md481e8b3d1\" x=\"400.160181\" y=\"307.584\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_9\"&gt;\n&lt;!-- 1.00 --&gt;\n&lt;g transform=\"translate(389.027369 322.182437) scale(0.1 -0.1)\"&gt;\n&lt;use xlink:href=\"#DejaVuSans-31\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"matplotlib.axis_2\"&gt;\n&lt;g id=\"ytick_1\"&gt;\n&lt;g id=\"line2d_10\"&gt;\n&lt;defs&gt;\n&lt;path id=\"m4c24411f41\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/defs&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#m4c24411f41\" x=\"57.6\" y=\"290.103413\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_10\"&gt;\n&lt;!-- \u22120.8 --&gt;\n&lt;g transform=\"translate(26.317187 293.902632) scale(0.1 -0.1)\"&gt;\n&lt;defs&gt;\n&lt;path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;/defs&gt;\n&lt;use xlink:href=\"#DejaVuSans-2212\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-38\" x=\"179.199219\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"ytick_2\"&gt;\n&lt;g id=\"line2d_11\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#m4c24411f41\" x=\"57.6\" y=\"245.213142\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_11\"&gt;\n&lt;!-- \u22120.6 --&gt;\n&lt;g transform=\"translate(26.317187 249.012361) scale(0.1 -0.1)\"&gt;\n&lt;defs&gt;\n&lt;path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;/defs&gt;\n&lt;use xlink:href=\"#DejaVuSans-2212\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-36\" x=\"179.199219\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"ytick_3\"&gt;\n&lt;g id=\"line2d_12\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#m4c24411f41\" x=\"57.6\" y=\"200.322871\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_12\"&gt;\n&lt;!-- \u22120.4 --&gt;\n&lt;g transform=\"translate(26.317187 204.12209) scale(0.1 -0.1)\"&gt;\n&lt;defs&gt;\n&lt;path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;/defs&gt;\n&lt;use xlink:href=\"#DejaVuSans-2212\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-34\" x=\"179.199219\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"ytick_4\"&gt;\n&lt;g id=\"line2d_13\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#m4c24411f41\" x=\"57.6\" y=\"155.4326\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_13\"&gt;\n&lt;!-- \u22120.2 --&gt;\n&lt;g transform=\"translate(26.317187 159.231819) scale(0.1 -0.1)\"&gt;\n&lt;use xlink:href=\"#DejaVuSans-2212\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-32\" x=\"179.199219\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"ytick_5\"&gt;\n&lt;g id=\"line2d_14\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#m4c24411f41\" x=\"57.6\" y=\"110.542329\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_14\"&gt;\n&lt;!-- 0.0 --&gt;\n&lt;g transform=\"translate(34.696875 114.341548) scale(0.1 -0.1)\"&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"ytick_6\"&gt;\n&lt;g id=\"line2d_15\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#m4c24411f41\" x=\"57.6\" y=\"65.652058\" style=\"stroke: #000000; stroke-width: 0.8\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_15\"&gt;\n&lt;!-- 0.2 --&gt;\n&lt;g transform=\"translate(34.696875 69.451276) scale(0.1 -0.1)\"&gt;\n&lt;use xlink:href=\"#DejaVuSans-30\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"line2d_16\"&gt;\n&lt;path d=\"M 158.047058 209.764067 \nL 158.493768 209.893067 \nL 160.4537 210.523696 \nL 161.436968 210.87927 \nL 163.889049 211.877548 \nL 166.177749 212.9488 \nL 169.417748 214.684091 \nL 172.511588 216.564192 \nL 174.1609 217.64866 \nL 177.310134 219.863348 \nL 182.184882 223.611639 \nL 183.930028 225.031056 \nL 190.358524 230.499142 \nL 194.588991 234.204109 \nL 195.64228 235.127741 \nL 196.774266 236.117926 \nL 203.865259 242.160351 \nL 205.468552 243.462405 \nL 211.993095 248.36824 \nL 212.404886 248.652384 \nL 212.491588 248.711772 \nL 219.081978 252.729806 \nL 221.588951 253.969095 \nL 223.58233 254.826684 \nL 228.349846 256.381673 \nL 232.744962 257.147784 \nL 240.395848 256.829799 \nL 245.634281 255.345848 \nL 247.047044 254.766666 \nL 247.768722 254.441484 \nL 250.259463 253.167472 \nL 255.122316 250.010559 \nL 256.261009 249.145795 \nL 260.935617 245.113576 \nL 263.971829 242.094777 \nL 269.2018 236.206921 \nL 271.190088 233.755509 \nL 272.08308 232.618693 \nL 272.173162 232.502814 \nL 284.193732 215.306067 \nL 290.620786 204.994747 \nL 301.292886 186.881893 \nL 302.642674 184.542419 \nL 303.360979 183.295349 \nL 304.182592 181.867572 \nL 307.359815 176.339514 \nL 308.051757 175.135565 \nL 310.776023 170.401789 \nL 312.400552 167.587309 \nL 313.34046 165.96299 \nL 315.392325 162.429917 \nL 316.993331 159.68773 \nL 319.454874 155.501377 \nL 322.029611 151.167324 \nL 327.131099 142.740338 \nL 328.300456 140.842243 \nL 335.46288 129.522471 \nL 346.819169 112.75327 \nL 350.133359 108.142335 \nL 351.918088 105.711895 \nL 353.11362 104.104201 \nL 356.125463 100.125561 \nL 357.572211 98.250303 \nL 362.190662 92.415629 \nL 366.765246 86.856036 \nL 371.625094 81.177117 \nL 374.986792 77.379439 \nL 381.251319 70.573434 \nL 382.585928 69.167579 \nL 384.162399 67.526477 \nL 385.059066 66.602419 \nL 389.384204 62.239738 \nL 393.287544 58.436305 \nL 397.693843 54.296044 \nL 398.487273 53.568 \n\" clip-path=\"url(#pfe8f3a97c8)\" style=\"fill: none; stroke: #008000; stroke-opacity: 0.5; stroke-width: 1.5; stroke-linecap: square\"/&gt;\n&lt;/g&gt;\n&lt;g id=\"line2d_17\"&gt;\n&lt;path d=\"M 158.047058 238.657706 \nL 158.493768 238.586674 \nL 160.4537 238.270032 \nL 161.436968 238.108055 \nL 163.889049 237.694671 \nL 166.177749 237.296049 \nL 169.417748 236.708899 \nL 172.511588 236.120751 \nL 174.1609 235.795183 \nL 177.310134 235.148038 \nL 182.184882 234.072442 \nL 183.930028 233.663079 \nL 190.358524 232.028863 \nL 194.588991 230.832266 \nL 195.64228 230.517952 \nL 196.774266 230.172541 \nL 203.865259 227.819487 \nL 205.468552 227.240015 \nL 211.993095 224.692189 \nL 212.404886 224.521013 \nL 212.491588 224.484814 \nL 219.081978 221.5732 \nL 221.588951 220.38402 \nL 223.58233 219.407518 \nL 228.349846 216.966604 \nL 232.744962 214.596348 \nL 240.395848 210.250922 \nL 245.634281 207.169493 \nL 247.047044 206.331151 \nL 247.768722 205.902413 \nL 250.259463 204.422605 \nL 255.122316 201.553148 \nL 256.261009 200.88921 \nL 260.935617 198.217439 \nL 263.971829 196.544898 \nL 269.2018 193.825204 \nL 271.190088 192.85685 \nL 272.08308 192.435401 \nL 272.173162 192.393371 \nL 284.193732 187.729798 \nL 290.620786 186.165335 \nL 301.292886 185.314389 \nL 302.642674 185.374649 \nL 303.360979 185.422624 \nL 304.182592 185.491111 \nL 307.359815 185.893423 \nL 308.051757 186.010113 \nL 310.776023 186.570729 \nL 312.400552 186.981672 \nL 313.34046 187.24545 \nL 315.392325 187.887077 \nL 316.993331 188.449798 \nL 319.454874 189.41939 \nL 322.029611 190.565849 \nL 327.131099 193.218471 \nL 328.300456 193.894225 \nL 335.46288 198.529042 \nL 346.819169 207.263606 \nL 350.133359 210.025322 \nL 351.918088 211.535358 \nL 353.11362 212.553128 \nL 356.125463 215.13007 \nL 357.572211 216.369984 \nL 362.190662 220.305429 \nL 366.765246 224.113425 \nL 371.625094 227.981091 \nL 374.986792 230.506909 \nL 381.251319 234.788567 \nL 382.585928 235.617456 \nL 384.162399 236.5547 \nL 385.059066 237.066776 \nL 389.384204 239.309386 \nL 393.287544 240.986448 \nL 397.693843 242.451988 \nL 398.487273 242.665485 \n\" clip-path=\"url(#pfe8f3a97c8)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/&gt;\n&lt;/g&gt;\n&lt;g id=\"patch_3\"&gt;\n&lt;path d=\"M 57.6 307.584 \nL 57.6 41.472 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/&gt;\n&lt;/g&gt;\n&lt;g id=\"patch_4\"&gt;\n&lt;path d=\"M 414.72 307.584 \nL 414.72 41.472 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/&gt;\n&lt;/g&gt;\n&lt;g id=\"patch_5\"&gt;\n&lt;path d=\"M 57.6 307.584 \nL 414.72 307.584 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/&gt;\n&lt;/g&gt;\n&lt;g id=\"patch_6\"&gt;\n&lt;path d=\"M 57.6 41.472 \nL 414.72 41.472 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/&gt;\n&lt;/g&gt;\n&lt;g id=\"legend_1\"&gt;\n&lt;g id=\"patch_7\"&gt;\n&lt;path d=\"M 64.6 93.506375 \nL 177.615625 93.506375 \nQ 179.615625 93.506375 179.615625 91.506375 \nL 179.615625 48.472 \nQ 179.615625 46.472 177.615625 46.472 \nL 64.6 46.472 \nQ 62.6 46.472 62.6 48.472 \nL 62.6 91.506375 \nQ 62.6 93.506375 64.6 93.506375 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/&gt;\n&lt;/g&gt;\n&lt;g id=\"PathCollection_2\"&gt;\n&lt;g&gt;\n&lt;use xlink:href=\"#m35c160629b\" x=\"76.6\" y=\"55.445438\" style=\"fill: #ffa500; stroke: #ffa500\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"text_16\"&gt;\n&lt;!-- Training points --&gt;\n&lt;g transform=\"translate(94.6 58.070438) scale(0.1 -0.1)\"&gt;\n&lt;defs&gt;\n&lt;path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;/defs&gt;\n&lt;use xlink:href=\"#DejaVuSans-54\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-70\" x=\"426.314453\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-6f\" x=\"489.791016\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-69\" x=\"550.972656\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-6e\" x=\"578.755859\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-74\" x=\"642.134766\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-73\" x=\"681.34375\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"line2d_18\"&gt;\n&lt;path d=\"M 66.6 69.248563 \nL 76.6 69.248563 \nL 86.6 69.248563 \n\" style=\"fill: none; stroke: #008000; stroke-opacity: 0.5; stroke-width: 1.5; stroke-linecap: square\"/&gt;\n&lt;/g&gt;\n&lt;g id=\"text_17\"&gt;\n&lt;!-- Initial prediction --&gt;\n&lt;g transform=\"translate(94.6 72.748563) scale(0.1 -0.1)\"&gt;\n&lt;defs&gt;\n&lt;path id=\"DejaVuSans-49\" d=\"M 628 4666 \nL 1259 4666 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;/defs&gt;\n&lt;use xlink:href=\"#DejaVuSans-49\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-6e\" x=\"29.492188\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-69\" x=\"92.871094\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-74\" x=\"120.654297\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-69\" x=\"159.863281\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-61\" x=\"187.646484\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-6c\" x=\"248.925781\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-20\" x=\"276.708984\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-70\" x=\"308.496094\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-72\" x=\"371.972656\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-65\" x=\"410.835938\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-64\" x=\"472.359375\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-69\" x=\"535.835938\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-63\" x=\"563.619141\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-74\" x=\"618.599609\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-69\" x=\"657.808594\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-6f\" x=\"685.591797\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-6e\" x=\"746.773438\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;g id=\"line2d_19\"&gt;\n&lt;path d=\"M 66.6 83.926688 \nL 76.6 83.926688 \nL 86.6 83.926688 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/&gt;\n&lt;/g&gt;\n&lt;g id=\"text_18\"&gt;\n&lt;!-- Final prediction --&gt;\n&lt;g transform=\"translate(94.6 87.426688) scale(0.1 -0.1)\"&gt;\n&lt;defs&gt;\n&lt;path id=\"DejaVuSans-46\" d=\"M 628 4666 \nL 3309 4666 \nL 3309 4134 \nL 1259 4134 \nL 1259 2759 \nL 3109 2759 \nL 3109 2228 \nL 1259 2228 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/&gt;\n&lt;/defs&gt;\n&lt;use xlink:href=\"#DejaVuSans-46\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-69\" x=\"50.269531\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-6e\" x=\"78.052734\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-61\" x=\"141.431641\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-6c\" x=\"202.710938\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-20\" x=\"230.494141\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-70\" x=\"262.28125\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-72\" x=\"325.757812\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-65\" x=\"364.621094\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-64\" x=\"426.144531\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-69\" x=\"489.621094\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-63\" x=\"517.404297\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-74\" x=\"572.384766\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-69\" x=\"611.59375\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-6f\" x=\"639.376953\"/&gt;\n&lt;use xlink:href=\"#DejaVuSans-6e\" x=\"700.558594\"/&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;/g&gt;\n&lt;defs&gt;\n&lt;clipPath id=\"pfe8f3a97c8\"&gt;\n&lt;rect x=\"57.6\" y=\"41.472\" width=\"357.12\" height=\"266.112\"/&gt;\n&lt;/clipPath&gt;\n&lt;/defs&gt;\n&lt;/svg&gt;\n</code></pre>"},{"location":"qml/qcl/#references","title":"References","text":"<ol> <li> <p>Mitarai et al., Quantum Circuit Learning \u21a9</p> </li> </ol>"},{"location":"tutorials/backends/","title":"Backends","text":"<p>Backends allow execution of Qadence abstract quantum circuits. They could be chosen from a variety of simulators, emulators and hardware and can enable circuit differentiability. The primary way to interact and configure a backend is via the high-level API <code>QuantumModel</code>.</p> <p>Not all backends are equivalent</p> <p>Not all backends support the same set of operations, especially while executing analog blocks. Qadence will throw descriptive errors in such cases.</p>"},{"location":"tutorials/backends/#execution-backends","title":"Execution backends","text":"<p>PyQTorch: An efficient, large-scale simulator designed for quantum machine learning, seamlessly integrated with the popular PyTorch deep learning framework for automatic differentiability. It also offers analog computing for time-independent pulses. See <code>PyQTorchBackend</code>.</p> <p>Pulser: A Python library for pulse-level/analog control of neutral atom devices. Execution via QuTiP. See <code>PulserBackend</code>.</p> <p>Braket: A Python SDK for interacting with quantum devices on Amazon Braket. Currently, only the devices with the digital interface of Amazon Braket are supported and execution is performed using the local simulator. Execution on remote simulators and quantum processing units will be available soon. See <code>BraketBackend</code></p> <p>More: Proprietary Qadence extensions provide more high-performance backends based on tensor networks or differentiation engines. For more enquiries, please contact: <code>info@pasqal.com</code>.</p>"},{"location":"tutorials/backends/#differentiation-backend","title":"Differentiation backend","text":"<p>The <code>DifferentiableBackend</code> class enables different differentiation modes for the given backend. This can be chosen from two types:</p> <ul> <li>Automatic differentiation (AD): available for PyTorch based backends (PyQTorch).</li> <li>Parameter Shift Rules (PSR): available for all backends. See this section for more information on differentiability and PSR.</li> </ul> <p>In practice, only a <code>diff_mode</code> should be provided in the <code>QuantumModel</code>. Please note that <code>diff_mode</code> defaults to <code>None</code>:</p> <pre><code>import sympy\nimport torch\nfrom qadence import Parameter, RX, RZ, Z, CNOT, QuantumCircuit, QuantumModel, chain, BackendName, DiffMode\nx = Parameter(\"x\", trainable=False)\ny = Parameter(\"y\", trainable=False)\nfm = chain(\nRX(0, 3 * x),\nRX(0, x),\nRZ(1, sympy.exp(y)),\nRX(0, 3.14),\nRZ(1, \"theta\")\n)\nansatz = CNOT(0, 1)\nblock = chain(fm, ansatz)\ncircuit = QuantumCircuit(2, block)\nobservable = Z(0)\n# DiffMode.GPSR is available for any backend.\n# DiffMode.AD is only available for natively differentiable backends.\nmodel = QuantumModel(circuit, observable, backend=BackendName.PYQTORCH, diff_mode=DiffMode.GPSR)\n# Get some values for the feature parameters.\nvalues = {\"x\": (x := torch.tensor([0.5], requires_grad=True)), \"y\": torch.tensor([0.1])}\n# Compute expectation.\nexp = model.expectation(values)\n# Differentiate the expectation wrt x.\ndexp_dx = torch.autograd.grad(exp, x, torch.ones_like(exp))\n</code></pre> <pre><code>dexp_dx = (tensor([3.6398]),)\n</code></pre>"},{"location":"tutorials/backends/#low-level-backend_factory-interface","title":"Low-level <code>backend_factory</code> interface","text":"<p>Every backend in Qadence inherits from the abstract <code>Backend</code> class: <code>Backend</code> and implement the following methods:</p> <ul> <li><code>run</code>: propagate the initial state according to the quantum circuit and return the final wavefunction object.</li> <li><code>sample</code>: sample from a circuit.</li> <li><code>expectation</code>: computes the expectation of a circuit given an observable.</li> <li><code>convert</code>: convert the abstract <code>QuantumCircuit</code> object to its backend-native representation including a backend specific parameter embedding function.</li> </ul> <p>Backends are purely functional objects which take as input the values for the circuit parameters and return the desired output from a call to a method. In order to use a backend directly, embedded parameters must be supplied as they are returned by the backend specific embedding function.</p> <p>Here is a simple demonstration of the use of the Braket backend to execute a circuit in non-differentiable mode:</p> <pre><code>from qadence import QuantumCircuit, FeatureParameter, RX, RZ, CNOT, hea, chain\n# Construct a feature map.\nx = FeatureParameter(\"x\")\nz = FeatureParameter(\"y\")\nfm = chain(RX(0, 3 * x), RZ(1, z), CNOT(0, 1))\n# Construct a circuit with an hardware-efficient ansatz.\ncircuit = QuantumCircuit(3, fm, hea(3,1))\n</code></pre> <p>The abstract <code>QuantumCircuit</code> can now be converted to its native representation via the Braket backend.</p> <pre><code>from qadence import backend_factory\n# Use only Braket in non-differentiable mode:\nbackend = backend_factory(\"braket\")\n# The `Converted` object\n# (contains a `ConvertedCircuit` with the original and native representation)\nconv = backend.convert(circuit)\n</code></pre> <pre><code>conv.circuit.original = ChainBlock(0,1,2)\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 RX(0) [params: ['3*x']]\n\u2502   \u251c\u2500\u2500 RZ(1) [params: ['y']]\n\u2502   \u2514\u2500\u2500 CNOT(0,1)\n\u2514\u2500\u2500 ChainBlock(0,1,2) [tag: HEA]\n\u251c\u2500\u2500 ChainBlock(0,1,2)\n\u2502   \u251c\u2500\u2500 KronBlock(0,1,2)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u251c\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(2) [params: ['theta_2']]\n\u2502   \u251c\u2500\u2500 KronBlock(0,1,2)\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_3']]\n\u2502   \u2502   \u251c\u2500\u2500 RY(1) [params: ['theta_4']]\n\u2502   \u2502   \u2514\u2500\u2500 RY(2) [params: ['theta_5']]\n\u2502   \u2514\u2500\u2500 KronBlock(0,1,2)\n\u2502       \u251c\u2500\u2500 RX(0) [params: ['theta_6']]\n\u2502       \u251c\u2500\u2500 RX(1) [params: ['theta_7']]\n\u2502       \u2514\u2500\u2500 RX(2) [params: ['theta_8']]\n\u2514\u2500\u2500 ChainBlock(0,1,2)\n\u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2514\u2500\u2500 CNOT(0,1)\n\u2514\u2500\u2500 KronBlock(1,2)\n\u2514\u2500\u2500 CNOT(1,2)\nconv.circuit.native = Circuit('instructions': [Instruction('operator': Rx('angle': 136cb657-93d9-438b-b7f1-2558402b5710, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rz('angle': ee045a37-2ec3-41e4-a230-43e44321f0d6, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(0), Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': d3baae53-1231-4408-a554-ed32acb61aed, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 7a82950b-951a-415d-a0b0-3e0c9a6ff1d9, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': b1d2f72f-c71d-44bd-a5c8-ff53dd60f90a, 'qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Ry('angle': 31a615f7-995e-4ce2-a5dd-6979a05955eb, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Ry('angle': 34241e71-12f3-4292-8d6b-149bd72438da, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Ry('angle': 50b6315d-bf01-44b8-8244-a81b8ea1a541, 'qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': d921318b-3647-4cde-a3e5-baea892e7b75, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': ad57ac19-6336-480a-a6e8-e471867dbd13, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 5ac9847b-5cc8-4b8d-8c44-6b2b8b6e3b0c, 'qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(0), Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(1), Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1)])\n</code></pre> <p>Additionally, <code>Converted</code> contains all fixed and variational parameters, as well as an embedding function which accepts feature parameters to construct a dictionary of circuit native parameters. These are needed as each backend uses a different representation of the circuit parameters:</p> <pre><code>import torch\n# Contains fixed parameters and variational (from the HEA)\nconv.params\ninputs = {\"x\": torch.tensor([1., 1.]), \"y\":torch.tensor([2., 2.])}\n# get all circuit parameters (including feature params)\nembedded = conv.embedding_fn(conv.params, inputs)\n</code></pre> <pre><code>conv.params = {\ntheta_7: tensor([0.4058], requires_grad=True)\ntheta_1: tensor([0.1440], requires_grad=True)\ntheta_6: tensor([0.6267], requires_grad=True)\ntheta_0: tensor([0.3391], requires_grad=True)\ntheta_3: tensor([0.7342], requires_grad=True)\ntheta_5: tensor([0.1844], requires_grad=True)\ntheta_8: tensor([0.5515], requires_grad=True)\ntheta_2: tensor([0.2953], requires_grad=True)\ntheta_4: tensor([0.1222], requires_grad=True)\n}\nembedded = {\n136cb657-93d9-438b-b7f1-2558402b5710: tensor([3., 3.])\nee045a37-2ec3-41e4-a230-43e44321f0d6: tensor([2., 2.])\nd3baae53-1231-4408-a554-ed32acb61aed: tensor([0.3391], grad_fn=&lt;ViewBackward0&gt;)\n7a82950b-951a-415d-a0b0-3e0c9a6ff1d9: tensor([0.1440], grad_fn=&lt;ViewBackward0&gt;)\nb1d2f72f-c71d-44bd-a5c8-ff53dd60f90a: tensor([0.2953], grad_fn=&lt;ViewBackward0&gt;)\n31a615f7-995e-4ce2-a5dd-6979a05955eb: tensor([0.7342], grad_fn=&lt;ViewBackward0&gt;)\n34241e71-12f3-4292-8d6b-149bd72438da: tensor([0.1222], grad_fn=&lt;ViewBackward0&gt;)\n50b6315d-bf01-44b8-8244-a81b8ea1a541: tensor([0.1844], grad_fn=&lt;ViewBackward0&gt;)\nd921318b-3647-4cde-a3e5-baea892e7b75: tensor([0.6267], grad_fn=&lt;ViewBackward0&gt;)\nad57ac19-6336-480a-a6e8-e471867dbd13: tensor([0.4058], grad_fn=&lt;ViewBackward0&gt;)\n5ac9847b-5cc8-4b8d-8c44-6b2b8b6e3b0c: tensor([0.5515], grad_fn=&lt;ViewBackward0&gt;)\n}\n</code></pre> <p>Note that above the parameters keys have changed as they now address the keys on the Braket device. A more readable embedding is provided by the PyQTorch backend:</p> <pre><code>from qadence import BackendName, DiffMode\npyq_backend = backend_factory(backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD)\n# the `Converted` object\n# (contains a `ConvertedCircuit` wiht the original and native representation)\npyq_conv = pyq_backend.convert(circuit)\nembedded = pyq_conv.embedding_fn(pyq_conv.params, inputs)\n</code></pre> <pre><code>embedded = {\ntheta_7: tensor([0.4058], grad_fn=&lt;ViewBackward0&gt;)\ntheta_6: tensor([0.6267], grad_fn=&lt;ViewBackward0&gt;)\ntheta_1: tensor([0.1440], grad_fn=&lt;ViewBackward0&gt;)\ntheta_3: tensor([0.7342], grad_fn=&lt;ViewBackward0&gt;)\ntheta_0: tensor([0.3391], grad_fn=&lt;ViewBackward0&gt;)\ntheta_5: tensor([0.1844], grad_fn=&lt;ViewBackward0&gt;)\ntheta_4: tensor([0.1222], grad_fn=&lt;ViewBackward0&gt;)\ntheta_2: tensor([0.2953], grad_fn=&lt;ViewBackward0&gt;)\ny: tensor([2., 2.])\n3*x: tensor([3., 3.])\ntheta_8: tensor([0.5515], grad_fn=&lt;ViewBackward0&gt;)\n}\n</code></pre> <p>With the embedded parameters, <code>QuantumModel</code> methods are accessible:</p> <pre><code>embedded = conv.embedding_fn(conv.params, inputs)\nsamples = backend.run(conv.circuit, embedded)\nprint(f\"{samples = }\")\n</code></pre> <pre><code>samples = tensor([[ 0.1564-0.0933j, -0.0253-0.0802j,  0.2182+0.0292j,  0.0474+0.4743j,\n-0.5929-0.4224j, -0.2529+0.2214j,  0.0617+0.0585j, -0.0925+0.1591j],\n[ 0.1564-0.0933j, -0.0253-0.0802j,  0.2182+0.0292j,  0.0474+0.4743j,\n-0.5929-0.4224j, -0.2529+0.2214j,  0.0617+0.0585j, -0.0925+0.1591j]])\n</code></pre>"},{"location":"tutorials/backends/#lower-level-the-backend-representation","title":"Lower-level: the <code>Backend</code> representation","text":"<p>If there is a requirement to work with a specific backend, it is possible to access directly the native circuit. For example, Braket noise features can be imported which are not exposed directly by Qadence.</p> <pre><code>from braket.circuits import Noise\n# Get the native Braket circuit with the given parameters\ninputs = {\"x\": torch.rand(1), \"y\":torch.rand(1)}\nembedded = conv.embedding_fn(conv.params, inputs)\nnative = backend.assign_parameters(conv.circuit, embedded)\n# Define a noise channel\nnoise = Noise.Depolarizing(probability=0.1)\n# Add noise to every gate in the circuit\nnative.apply_gate_noise(noise)\n</code></pre> <p>In order to run this noisy circuit, the density matrix simulator is needed in Braket:</p> <p><pre><code>from braket.devices import LocalSimulator\ndevice = LocalSimulator(\"braket_dm\")\nresult = device.run(native, shots=1000).result().measurement_counts\nprint(result)\n</code></pre> <pre><code>Counter({'000': 256, '111': 158, '001': 135, '011': 125, '100': 97, '110': 95, '010': 72, '101': 62})\n</code></pre> <pre><code>print(conv.circuit.native.diagram())\n</code></pre> <pre><code>T  : |                   0                    |                   1                    |                   2                    |                   3                    |                   4                    |5|6|\nq0 : -Rx(136cb657-93d9-438b-b7f1-2558402b5710)-C----------------------------------------Rx(d3baae53-1231-4408-a554-ed32acb61aed)-Ry(31a615f7-995e-4ce2-a5dd-6979a05955eb)-Rx(d921318b-3647-4cde-a3e5-baea892e7b75)-C---\n|                                                                                                                                                                   |   q1 : -Rz(ee045a37-2ec3-41e4-a230-43e44321f0d6)-X----------------------------------------Rx(7a82950b-951a-415d-a0b0-3e0c9a6ff1d9)-Ry(34241e71-12f3-4292-8d6b-149bd72438da)-Rx(ad57ac19-6336-480a-a6e8-e471867dbd13)-X-C-\n| q2 : -Rx(b1d2f72f-c71d-44bd-a5c8-ff53dd60f90a)-Ry(50b6315d-bf01-44b8-8244-a81b8ea1a541)-Rx(5ac9847b-5cc8-4b8d-8c44-6b2b8b6e3b0c)-------------------------------------------------------------------------------------X-\nT  : |                   0                    |                   1                    |                   2                    |                   3                    |                   4                    |5|6|\nUnassigned parameters: [136cb657-93d9-438b-b7f1-2558402b5710, 31a615f7-995e-4ce2-a5dd-6979a05955eb, 34241e71-12f3-4292-8d6b-149bd72438da, 50b6315d-bf01-44b8-8244-a81b8ea1a541, 5ac9847b-5cc8-4b8d-8c44-6b2b8b6e3b0c, 7a82950b-951a-415d-a0b0-3e0c9a6ff1d9, ad57ac19-6336-480a-a6e8-e471867dbd13, b1d2f72f-c71d-44bd-a5c8-ff53dd60f90a, d3baae53-1231-4408-a554-ed32acb61aed, d921318b-3647-4cde-a3e5-baea892e7b75, ee045a37-2ec3-41e4-a230-43e44321f0d6].\n</code></pre> <pre><code>print(native.diagram())\n</code></pre> <pre><code>T  : |        0         |        1         |        2         |        3         |        4         |     5     |     6     |\nq0 : -Rx(0.18)-DEPO(0.1)-C--------DEPO(0.1)-Rx(0.34)-DEPO(0.1)-Ry(0.73)-DEPO(0.1)-Rx(0.63)-DEPO(0.1)-C-DEPO(0.1)-------------\n|                                                                           |                       q1 : -Rz(0.96)-DEPO(0.1)-X--------DEPO(0.1)-Rx(0.14)-DEPO(0.1)-Ry(0.12)-DEPO(0.1)-Rx(0.41)-DEPO(0.1)-X-DEPO(0.1)-C-DEPO(0.1)-\n|           q2 : -Rx(0.30)-DEPO(0.1)-Ry(0.18)-DEPO(0.1)-Rx(0.55)-DEPO(0.1)---------------------------------------------------X-DEPO(0.1)-\nT  : |        0         |        1         |        2         |        3         |        4         |     5     |     6     |\n</code></pre> </p>"},{"location":"tutorials/getting_started/","title":"Getting Started","text":"<p>Quantum programs in Qadence are constructed via a block-system, with an emphasis on composability of primitive blocks to obtain larger, composite blocks. This functional approach is different from other frameworks which follow a more object-oriented way to construct circuits and express programs.</p> How to visualize blocks <p>There are two ways to display blocks in a Python interpreter: either as a tree in ASCII format using <code>print</code>:</p> <p><pre><code>from qadence import X, Y, kron\nkron_block = kron(X(0), Y(1))\nprint(kron_block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 Y(1)\n</code></pre> </p> <p>Or using the visualization package which opens an interactive window:</p> <p><pre><code>from qadence import X, Y, kron\n#from visualization import display\nkron_block = kron(X(0), Y(1))\n#display(kron_block)\n</code></pre> %3 b023312f8b3e4083816878584391f103 0 8c3288307bd741cd802a0cf98f26b12c X b023312f8b3e4083816878584391f103--8c3288307bd741cd802a0cf98f26b12c c6c5bd7dca7044568988687830c98cd0 1 b3a90d1f290c4f54b6413be42edc950c 8c3288307bd741cd802a0cf98f26b12c--b3a90d1f290c4f54b6413be42edc950c c81ebf4df3554ee0ae0fc24224daea8f 4ad8af668efe44749586cd8bc15b8c90 Y c6c5bd7dca7044568988687830c98cd0--4ad8af668efe44749586cd8bc15b8c90 4ad8af668efe44749586cd8bc15b8c90--c81ebf4df3554ee0ae0fc24224daea8f </p>"},{"location":"tutorials/getting_started/#primitive-blocks","title":"Primitive blocks","text":"<p>A <code>PrimitiveBlock</code> represents a digital or an analog time-evolution quantum operation applied to a qubit support. Programs can always be decomposed down into a sequence of <code>PrimitiveBlock</code> elements.</p> <p>Two canonical examples of digital primitive blocks are the parametrized <code>RX</code> and the <code>CNOT</code> gates:</p> <pre><code>from qadence import RX\n# A rotation gate on qubit 0 with a fixed numerical parameter.\nrx_gate = RX(0, 0.5)\n</code></pre> %3 18ad0689c36e40abb696ab83d798dcb7 0 db9549c6536c4fc48c35fe4fc8b0a152 RX(0.5) 18ad0689c36e40abb696ab83d798dcb7--db9549c6536c4fc48c35fe4fc8b0a152 fca6aff035794e439441088a0f21fc15 db9549c6536c4fc48c35fe4fc8b0a152--fca6aff035794e439441088a0f21fc15 <pre><code>from qadence import CNOT\n# A CNOT gate with control on qubit 0 and target on qubit 1.\ncnot_gate = CNOT(0, 1)\n</code></pre> %3 d3124ac02281425996038cb69866e2d3 0 7f59411c9d7f48f3976c8b6959127427 d3124ac02281425996038cb69866e2d3--7f59411c9d7f48f3976c8b6959127427 85cd423b6f0d49c18c1bd59f09aa6879 1 1b3558142d244405b3442e5ce7db53ab 7f59411c9d7f48f3976c8b6959127427--1b3558142d244405b3442e5ce7db53ab cc6111bc090a44c5a46dd5bd42d72dc6 57c0c1a233b5448daa075bffaa938183 X 85cd423b6f0d49c18c1bd59f09aa6879--57c0c1a233b5448daa075bffaa938183 57c0c1a233b5448daa075bffaa938183--7f59411c9d7f48f3976c8b6959127427 57c0c1a233b5448daa075bffaa938183--cc6111bc090a44c5a46dd5bd42d72dc6 <p>A list of all instances of primitive blocks (also referred to as operations) can be found here.</p>"},{"location":"tutorials/getting_started/#composite-blocks","title":"Composite Blocks","text":"<p>Programs can be expressed by composing blocks to result in a larger <code>CompositeBlock</code> using three fundamental operations: chain, kron, and add.</p> <ul> <li>chain applies a set of blocks in sequence on the same or overlapping qubit supports and results in a <code>ChainBlock</code> type. It is akin to applying a matrix product of the sub-blocks with the <code>*</code> operator.</li> </ul> <p><pre><code>from qadence import X, chain\n# Chaining on the same qubit using a call to the function.\nchain_x = chain(X(0), X(0))\n</code></pre> %3 95e10d4fb23b49ad858a026517ec8ee8 0 e8b42000f55a42b9b106495b302028d3 X 95e10d4fb23b49ad858a026517ec8ee8--e8b42000f55a42b9b106495b302028d3 d438121994e846f1a98dc4e9aca4364a X e8b42000f55a42b9b106495b302028d3--d438121994e846f1a98dc4e9aca4364a 1f71ff61e7714361a114034856463b58 d438121994e846f1a98dc4e9aca4364a--1f71ff61e7714361a114034856463b58 <pre><code># Chaining on different qubits using the operator overload.\n# Identical to the kron operation.\nchain_xx = X(0) * X(1)\n</code></pre> %3 862ee90b6eec40a18bacbccd50e2c970 0 e3f887257eca4240a66111b876981eb5 X 862ee90b6eec40a18bacbccd50e2c970--e3f887257eca4240a66111b876981eb5 924d9f0059174e0a828c18d9ed40655e 1 b0c1613418634ea7a43685bea6ac06d8 e3f887257eca4240a66111b876981eb5--b0c1613418634ea7a43685bea6ac06d8 6a5cb316bb134c80b71c51f60fcd08d4 b0c1613418634ea7a43685bea6ac06d8--6a5cb316bb134c80b71c51f60fcd08d4 450b1e7bb6734e93b2ccbdf23ca38218 ed2e6d0ddaf343ad91a6203fb01cc1ab 924d9f0059174e0a828c18d9ed40655e--ed2e6d0ddaf343ad91a6203fb01cc1ab dee155304b2743c88aeeb072b7c6b8ec X ed2e6d0ddaf343ad91a6203fb01cc1ab--dee155304b2743c88aeeb072b7c6b8ec dee155304b2743c88aeeb072b7c6b8ec--450b1e7bb6734e93b2ccbdf23ca38218 </p> <ul> <li>kron applies a set of blocks in parallel (simultaneously) on disjoint qubit support and results in a <code>KronBlock</code> type. This is akin to applying a tensor product of the sub-blocks with the <code>@</code> operator.</li> </ul> <pre><code>from qadence import X, kron\nkron_xx = kron(X(0), X(1))  # Equivalent to X(0) @ X(1)\n</code></pre> %3 0dac9f66c78243e8b81b3ab7f79039d2 0 e712b7da5f3d44ac897bc25248c0d682 X 0dac9f66c78243e8b81b3ab7f79039d2--e712b7da5f3d44ac897bc25248c0d682 7be2764603d34f5a826dd119fe655729 1 4c9177d1084945a396ca42f5ee02ce5e e712b7da5f3d44ac897bc25248c0d682--4c9177d1084945a396ca42f5ee02ce5e d3f4ad8c887d4e1c8f7cb9efec512b4f f81c9d4ab1814317b0b7b03b46e17841 X 7be2764603d34f5a826dd119fe655729--f81c9d4ab1814317b0b7b03b46e17841 f81c9d4ab1814317b0b7b03b46e17841--d3f4ad8c887d4e1c8f7cb9efec512b4f <p>For the digital case, it should be noted that <code>kron</code> and <code>chain</code> are semantically equivalent up to the diagrammatic representation as <code>chain</code> implicitly fills blank wires with identities. However, Qadence also supports analog blocks, for which composing sequentially or in parallel becomes non-equivalent. More about analog blocks can be found in the digital-analog section.</p> <ul> <li>add sums the corresponding matrix of each sub-block and results in a <code>AddBlock</code> type which can be used to construct Pauli operators. Please note that <code>AddBlock</code> can give rise to non-unitary computations that might not be supported by all backends.</li> </ul> Get the matrix of a block <p>It is always possible to retrieve the matrix representation of a block by calling the <code>block.tensor()</code> method. Please note that the returned tensor contains a batch dimension for the purposes of block parametrization.</p> <p><pre><code>\n</code></pre> <pre><code>X(0) * X(0) tensor = tensor([[[1.+0.j, 0.+0.j],\n[0.+0.j, 1.+0.j]]])\nX(0) @ X(1) tensor = tensor([[[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]]])\n</code></pre> </p> <pre><code>from qadence import X, Z\nxz = X(0) + Z(0)\nprint(xz.tensor())\n</code></pre> <pre><code>tensor([[[ 1.+0.j,  1.+0.j],\n[ 1.+0.j, -1.+0.j]]])\n</code></pre> <p>Finally, it is possible to tag blocks with human-readable names:</p> <pre><code>from qadence import X, Y, CNOT, kron, chain, tag\nxy = kron(X(0), Y(1))\ntag(xy, \"subblock\")\ncomposite_block = kron(xy, CNOT(3,4))\nfinal_block = chain(composite_block, composite_block)\n</code></pre> %3 cluster_c317f650d1014e6a80e1578a5b652f43 subblock cluster_b6f5caadba8945479146acd38edb1221 subblock 4124d515da744a39a13041c85ef10ddd 0 74afa942d1ad4f7daf8aebb7ef3d968f X 4124d515da744a39a13041c85ef10ddd--74afa942d1ad4f7daf8aebb7ef3d968f 6955a6c32de14f1ba65053023d7a97b0 1 8d1f4043ac5b49fb8c8c5f47a0cca67a X 74afa942d1ad4f7daf8aebb7ef3d968f--8d1f4043ac5b49fb8c8c5f47a0cca67a 79a7eb3497b54d6d8e6a342a23d95dbd 8d1f4043ac5b49fb8c8c5f47a0cca67a--79a7eb3497b54d6d8e6a342a23d95dbd e01277fe42184e639eae55576861de91 94ef13f2cbc24b85831ce637f362e878 Y 6955a6c32de14f1ba65053023d7a97b0--94ef13f2cbc24b85831ce637f362e878 da4dda0dfcd342d0bce0d81a92e33ea3 2 88d036b28ee248c7aa6661562d432b1d Y 94ef13f2cbc24b85831ce637f362e878--88d036b28ee248c7aa6661562d432b1d 88d036b28ee248c7aa6661562d432b1d--e01277fe42184e639eae55576861de91 c8854eb3bf5d4fb7a85f43fe75bd9cfc c4fb40b468ff4d6a89dfb46041317fae da4dda0dfcd342d0bce0d81a92e33ea3--c4fb40b468ff4d6a89dfb46041317fae 801a341f415841a78c1447825449ced7 3 938a08c6236c4896ad3836a2e1d4dc78 c4fb40b468ff4d6a89dfb46041317fae--938a08c6236c4896ad3836a2e1d4dc78 938a08c6236c4896ad3836a2e1d4dc78--c8854eb3bf5d4fb7a85f43fe75bd9cfc 8595580477434c468e3e3e3fbe53c0e8 580798793de04e86812e5decf4acda94 801a341f415841a78c1447825449ced7--580798793de04e86812e5decf4acda94 91504d7f604f488eada08718ae0e877d 4 65e0aec9318c4e43967dc775d4677bd1 580798793de04e86812e5decf4acda94--65e0aec9318c4e43967dc775d4677bd1 65e0aec9318c4e43967dc775d4677bd1--8595580477434c468e3e3e3fbe53c0e8 7097b0388e8844d48bee3e8e70c28587 b9ffacb127d94d45956a25ec62e2279b X 91504d7f604f488eada08718ae0e877d--b9ffacb127d94d45956a25ec62e2279b b9ffacb127d94d45956a25ec62e2279b--580798793de04e86812e5decf4acda94 a43c70723f1e4ad3b9d3bdfa5b96461a X b9ffacb127d94d45956a25ec62e2279b--a43c70723f1e4ad3b9d3bdfa5b96461a a43c70723f1e4ad3b9d3bdfa5b96461a--65e0aec9318c4e43967dc775d4677bd1 a43c70723f1e4ad3b9d3bdfa5b96461a--7097b0388e8844d48bee3e8e70c28587"},{"location":"tutorials/getting_started/#block-execution","title":"Block execution","text":"<p>To quickly run quantum operations and access wavefunctions, samples or expectation values of observables, one can use the convenience functions <code>run</code>, <code>sample</code> and <code>expectation</code>. The following example shows an execution workflow with the natively available <code>PyQTorch</code> backend:</p> <pre><code>from qadence import chain, add, H, Z, run, sample, expectation\nn_qubits = 2\nblock = chain(H(0), H(1))\n# Compute the wavefunction.\n# Please check the documentation for other available backends.\nwf = run(block)\n# Sample the resulting wavefunction with a given number of shots.\nxs = sample(block, n_shots=1000)\n# Compute an expectation based on an observable of Pauli-Z operators.\nobs = add(Z(i) for i in range(n_qubits))\nex = expectation(block, obs)\n</code></pre> <pre><code>wf = tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\nxs = [Counter({'11': 257, '01': 253, '00': 248, '10': 242})]\nex = tensor([[0.]])\n</code></pre> <p>More fine-grained control and better performance is provided via the high-level <code>QuantumModel</code> abstraction.</p>"},{"location":"tutorials/getting_started/#execution-via-quantumcircuit-and-quantummodel","title":"Execution via <code>QuantumCircuit</code> and <code>QuantumModel</code>","text":"<p>Quantum programs in Qadence are constructed in two steps:</p> <ol> <li>Build a <code>QuantumCircuit</code> which ties together a composite block and a register.</li> <li>Define a <code>QuantumModel</code> which differentiates, compiles and executes the circuit.</li> </ol> <p><code>QuantumCircuit</code> is a central class in Qadence and circuits are abstract objects from the actual hardware/simulator that they are expected to be executed on. They require to specify the <code>Register</code> of resources to execute your program on. Previous examples were already using <code>QuantumCircuit</code> with a <code>Register</code> that fits the qubit support for the given block.</p> <pre><code>from qadence import QuantumCircuit, Register, H, chain\n# NOTE: Run a block which supports two qubits\n# on a register of three qubits.\nregister = Register(3)\ncircuit = QuantumCircuit(register, chain(H(0), H(1)))\n</code></pre> <pre><code>circuit = ChainBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 H(1)\n</code></pre> <p>Registers and qubit supports</p> <p>Registers can also be constructed from qubit coordinates to create arbitrary register topologies. See details in the digital-analog section. Qubit supports are subsets of the circuit register tied to blocks.</p> <p><code>QuantumModel</code> is another central class in Qadence. It specifies a Backend for the differentiation, compilation and execution of the abstract circuit.</p> <pre><code>from qadence import BackendName, DiffMode, QuantumCircuit, QuantumModel, Register, H, chain\nreg = Register(3)\ncirc = QuantumCircuit(reg, chain(H(0), H(1)))\nmodel = QuantumModel(circ, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD)\nxs = model.sample(n_shots=100)\n</code></pre> <pre><code>xs = [Counter({'000': 32, '100': 25, '010': 22, '110': 21})]\n</code></pre> <p>For more details on <code>QuantumModel</code>, see here.</p>"},{"location":"tutorials/hamiltonians/","title":"Constructing arbitrary Hamiltonians","text":"<p>At the heart of digital-analog quantum computing is the description and execution of analog blocks, which represent a set of interacting qubits under some interaction Hamiltonian. For this purpose, Qadence relies on the <code>hamiltonian_factory</code> function to create arbitrary Hamiltonian blocks to be used as generators of <code>HamEvo</code> or as observables to be measured.</p>"},{"location":"tutorials/hamiltonians/#arbitrary-all-to-all-hamiltonians","title":"Arbitrary all-to-all Hamiltonians","text":"<p>Arbitrary all-to-all interaction Hamiltonians can be easily created by passing the number of qubits in the first argument. The type of <code>interaction</code> can be chosen from the available ones in the <code>Interaction</code> enum type.</p> <pre><code>from qadence import hamiltonian_factory\nfrom qadence import N, X, Y, Z\nfrom qadence import Interaction\nn_qubits = 3\nhamilt = hamiltonian_factory(n_qubits, interaction=Interaction.ZZ)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(2)\n\u2514\u2500\u2500 [mul: 1.00000000000000] \u2514\u2500\u2500 KronBlock(1,2)\n\u251c\u2500\u2500 Z(1)\n\u2514\u2500\u2500 Z(2)\n</code></pre> <p>Single-qubit terms can also be added by passing the respective operator directly to the <code>detuning</code> argument. For example, the total magnetization is commonly used as an observable to be measured:</p> <pre><code>total_mag = hamiltonian_factory(n_qubits, detuning = Z)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 Z(0)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 Z(1)\n\u2514\u2500\u2500 [mul: 1.00000000000000] \u2514\u2500\u2500 Z(2)\n</code></pre> <p>For further customization, arbitrary coefficients can be passed as arrays to the <code>interaction_strength</code> and <code>detuning_strength</code> arguments for the two-qubits and single-qubit terms respectively.</p> <pre><code>n_qubits = 3\nhamilt = hamiltonian_factory(\nn_qubits,\ninteraction=Interaction.ZZ,\ndetuning=Z,\ninteraction_strength=[0.5, 0.2, 0.1],\ndetuning_strength=[0.1, 0.5, -0.3]\n)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 0.100] \u2502   \u2514\u2500\u2500 Z(0)\n\u251c\u2500\u2500 [mul: 0.500] \u2502   \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: -0.300] \u2502   \u2514\u2500\u2500 Z(2)\n\u251c\u2500\u2500 [mul: 0.500] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: 0.200] \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(2)\n\u2514\u2500\u2500 [mul: 0.100] \u2514\u2500\u2500 KronBlock(1,2)\n\u251c\u2500\u2500 Z(1)\n\u2514\u2500\u2500 Z(2)\n</code></pre> <p>Ordering interaction strengths matters</p> <p>When passing interaction strengths as an array, the ordering must be indentical to the one obtained from the <code>edge</code> property of a Qadence <code>Register</code>:</p> <p><pre><code>from qadence import Register\nprint(Register(n_qubits).edges)\n</code></pre> <pre><code>[(0, 1), (0, 2), (1, 2)]\n</code></pre> </p> <p>For one more example, let's create a transverse-field Ising model,</p> <pre><code>n_qubits = 4\nn_edges = int(0.5 * n_qubits * (n_qubits - 1))\nz_terms = [1.0] * n_qubits\nzz_terms = [2.0] * n_edges\nzz_ham = hamiltonian_factory(\nn_qubits,\ninteraction=Interaction.ZZ,\ndetuning=Z,\ninteraction_strength=zz_terms,\ndetuning_strength=z_terms\n)\nx_terms = [-1.0] * n_qubits\nx_ham = hamiltonian_factory(n_qubits, detuning = X, detuning_strength = x_terms)\ntransverse_ising = zz_ham + x_ham\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 AddBlock(0,1,2,3)\n\u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 Z(0)\n\u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 Z(1)\n\u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 Z(3)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(1)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(3)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502   \u2502       \u251c\u2500\u2500 Z(1)\n\u2502   \u2502       \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(1,3)\n\u2502   \u2502       \u251c\u2500\u2500 Z(1)\n\u2502   \u2502       \u2514\u2500\u2500 Z(3)\n\u2502   \u2514\u2500\u2500 [mul: 2.00000000000000] \u2502       \u2514\u2500\u2500 KronBlock(2,3)\n\u2502           \u251c\u2500\u2500 Z(2)\n\u2502           \u2514\u2500\u2500 Z(3)\n\u2514\u2500\u2500 AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: -1.00000000000000] \u2502   \u2514\u2500\u2500 X(0)\n\u251c\u2500\u2500 [mul: -1.00000000000000] \u2502   \u2514\u2500\u2500 X(1)\n\u251c\u2500\u2500 [mul: -1.00000000000000] \u2502   \u2514\u2500\u2500 X(2)\n\u2514\u2500\u2500 [mul: -1.00000000000000] \u2514\u2500\u2500 X(3)\n</code></pre> <p>Random interaction coefficients</p> <p>Random interaction coefficients can be chosen between -1 and 1 by simply passing <code>random_strength = True</code> instead of <code>detuning_strength</code> and <code>interaction_strength</code>.</p>"},{"location":"tutorials/hamiltonians/#arbitrary-hamiltonian-topologies","title":"Arbitrary Hamiltonian topologies","text":"<p>Arbitrary interaction topologies can be created using the Qadence <code>Register</code>. Simply pass the register with the desired topology as the first argument to the <code>hamiltonian_factory</code>:</p> <pre><code>from qadence import Register\nreg = Register.square(qubits_side=2)\nsquare_hamilt = hamiltonian_factory(reg, interaction=Interaction.NN)\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(3)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: 1.00000000000000] \u2514\u2500\u2500 KronBlock(2,3)\n\u251c\u2500\u2500 N(2)\n\u2514\u2500\u2500 N(3)\n</code></pre> <p>Custom Hamiltonian coefficients can also be added to the register beforehand using the <code>\"strength\"</code> key.</p> <pre><code>reg = Register.square(qubits_side = 2)\nfor i, edge in enumerate(reg.edges):\nreg.edges[edge][\"strength\"] = (0.5 * i) ** 2\nsquare_hamilt = hamiltonian_factory(reg, interaction=Interaction.NN)\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: 0.0] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: 0.250] \u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(3)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: 2.250] \u2514\u2500\u2500 KronBlock(2,3)\n\u251c\u2500\u2500 N(2)\n\u2514\u2500\u2500 N(3)\n</code></pre> <p>Alternatively, if the register already stores interaction or detuning strengths, it is possible to override them in the Hamiltonian creation by using <code>force_update = True</code>.</p>"},{"location":"tutorials/hamiltonians/#adding-variational-parameters","title":"Adding variational parameters","text":"<p>Finally, fully parameterized Hamiltonians can be created by passing a string to the strength arguments:</p> <pre><code>n_qubits = 3\nnn_ham = hamiltonian_factory(\nn_qubits,\ninteraction=Interaction.NN,\ndetuning=N,\ninteraction_strength=\"c\",\ndetuning_strength=\"d\"\n)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: d_0] \u2502   \u2514\u2500\u2500 N(0)\n\u251c\u2500\u2500 [mul: d_1] \u2502   \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: d_2] \u2502   \u2514\u2500\u2500 N(2)\n\u251c\u2500\u2500 [mul: c_01] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: c_02] \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: c_12] \u2514\u2500\u2500 KronBlock(1,2)\n\u251c\u2500\u2500 N(1)\n\u2514\u2500\u2500 N(2)\n</code></pre>"},{"location":"tutorials/ml_tools/","title":"Ml tools","text":"<p><code>qadence</code> also offers a out-of-the-box training routine called <code>train_with_grad</code> for optimizing fully-differentiable models like <code>QNN</code>s and <code>QuantumModel</code>s containing either trainable and/or non-trainable parameters (i.e., inputs). Feel free to refresh your memory about different parameter types.</p>"},{"location":"tutorials/ml_tools/#ml-tools-basics","title":"ML tools Basics","text":"<p><code>train_with_grad</code> performs training, logging/printing loss metrics and storing intermediate checkpoints of models.</p> <p>As every other training routine commonly used in Machine Learning, it requires <code>model</code>, <code>data</code> and an <code>optimizer</code> as input arguments. However, in addition, it requires a <code>loss_fn</code> and a <code>TrainConfig</code>. A <code>loss_fn</code> is required to be a function which expects both a model and data and returns a tuple of (loss, metrics: dict), where <code>metrics</code> is a dict of scalars which can be customized too.</p> <pre><code>import torch\nfrom itertools import count\ncnt = count()\ncriterion = torch.nn.MSELoss()\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\nnext(cnt)\nx, y = data[0], data[1]\nout = model(x)\nloss = criterion(out, y)\nreturn loss, {}\n</code></pre> <pre><code>\n</code></pre> <p>The <code>TrainConfig</code> [qadence.ml_tools.config] tells <code>train_with_grad</code> what batch_size should be used, how many epochs to train, in which intervals to print/log metrics and how often to store intermediate checkpoints.</p> <pre><code>from qadence.ml_tools import TrainConfig\nbatch_size = 5\nn_epochs = 100\nconfig = TrainConfig(\nfolder=\"some_path/\",\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/ml_tools/#fitting-a-funtion-with-a-qnn-using-ml_tools","title":"Fitting a funtion with a QNN using ml_tools","text":"<p>Let's look at a complete example of how to use <code>train_with_grad</code> now.</p> <pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence.models import QNN\nfrom qadence.ml_tools import train_with_grad, TrainConfig\nimport matplotlib.pyplot as plt\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\nnext(cnt)\nx, y = data[0], data[1]\nout = model(x)\nloss = criterion(out, y)\nreturn loss, {}\ntmp_path = Path(\"/tmp\")\nn_epochs = 5\nconfig = TrainConfig(\nfolder=tmp_path,\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\nbatch_size = 25\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\ntrain_with_grad(model, (x, y), optimizer, config, loss_fn=loss_fn)\nplt.plot(y.numpy())\nplt.plot(model(input_values).detach().numpy())\n</code></pre> <pre><code>\n</code></pre> <p>For users who want to use the low-level API of <code>qadence</code>, here is the example from above written without <code>train_with_grad</code>.</p>"},{"location":"tutorials/ml_tools/#fitting-a-function-low-level-api","title":"Fitting a function - Low-level API","text":"<pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence.models import QNN\nfrom qadence.ml_tools import train_with_grad, TrainConfig\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\nn_epochs=50\ncnt = count()\ntmp_path = Path(\"/tmp\")\nconfig = TrainConfig(\nfolder=tmp_path,\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\nfor i in range(n_epochs):\nout = model(x)\nloss = criterion(out, y)\nloss.backward()\noptimizer.step()\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/overlap/","title":"Wavefunction Overlaps","text":"<p>Qadence offers convenience functions for computing the overlap between the wavefunctions generated by two quantum circuits \\(U\\) and \\(W\\) as:</p> \\[ S = |\\langle \\psi_U | \\psi_W \\rangle|^2 \\quad \\textrm{where} \\quad \\psi_U = U|\\psi_0\\rangle \\] <p>Here is an example on how to compute the overlap between two very simple parametric circuits consisting of a single <code>RX</code> rotation on different qubits. The overlap is expected to be non-zero only when the rotation angle is different from \\(\\pi \\; \\textrm{mod}\\; 2\\pi\\) for both rotations:</p> <pre><code>import torch\nimport numpy as np\nfrom qadence import Overlap, OverlapMethod, QuantumCircuit, H, RX, X, FeatureParameter, hea\n# Create two quantum circuits\n# with a single qubit rotation on two random qubits\nn_qubits = 4\nqubits = np.random.choice(list(range(n_qubits)), n_qubits, replace=True)\nphi = FeatureParameter(\"phi\")\ncircuit_bra = QuantumCircuit(n_qubits, RX(qubits[0], phi))\npsi = FeatureParameter(\"psi\")\ncircuit_ket = QuantumCircuit(n_qubits, RX(qubits[1], psi))\n# Values for the feature parameters\nvalues_bra = {\"phi\": torch.Tensor([torch.pi / 2, torch.pi])}\nvalues_ket = {\"psi\": torch.Tensor([torch.pi / 2, torch.pi])}\n# Calculate overlap by assigning values to the given bra and ket circuits\novrlp = Overlap(circuit_bra, circuit_ket)\novrlp = ovrlp(bra_param_values=values_bra, ket_param_values=values_ket)\n</code></pre> <pre><code>Overlap with exact method:\ntensor([[2.5000e-01, 1.8747e-33],\n[1.8747e-33, 1.4058e-65]])\n</code></pre> <p>The <code>Overlap</code> class above inherits from <code>QuantumModel</code> and is executed through its inherited forward method for the given input parameter values. By default, the overlap is computed exactly by performing the dot product of the wavefunction propagated from bra and ket circuits.</p> <p>However, it is possible to choose a different method from the <code>OverlapMethod</code> enumeration to be passed via the <code>overlap_method</code> argument in the <code>Overlap</code> initializer. Currently, one can choose from:</p> <ul> <li><code>EXACT</code>: exact computation using the wavefunction matrix representation. Does not work with real devices since it assumes access to the complete qubit system wavefunction.</li> <li><code>COMPUTE_UNCOMPUTE</code>: exact or sampling-based computation using bra \\(U\\) and ket \\(W^{\\dagger}\\) unitaries.</li> <li><code>SWAP_TEST</code>: exact or sampling-based computation using the SWAP test method.</li> <li><code>HADAMARD_TEST</code>: exact or sampling-based computation using the Hadamard test method.</li> <li><code>JENSEN_SHANNON</code>: compute the overlap using the Jensen-Shannon divergence of the two probability distributions obtained by sampling the propagated circuits. This will yield a different result than the other methods.</li> </ul> <p>All methods (except for the <code>EXACT</code> method) take an optional <code>n_shots</code> argument which can be used to perform shot-based calculations.</p> <p>Warning</p> <p>If you select a finite number of shots, the overlap is not differentiable. Therefore, it cannot be used as output of a quantum model if gradients are required.</p> <pre><code># Calculate overlap with SWAP test\novrlp = Overlap(circuit_bra, circuit_ket, method=OverlapMethod.SWAP_TEST)\novrlp_ha = ovrlp(values_bra, values_ket)\n# Calculate overlap with SWAP test\n# using a finite number of shots\novrlp = Overlap(circuit_bra, circuit_ket, method=OverlapMethod.SWAP_TEST)\novrlp_ha = ovrlp(values_bra, values_ket, n_shots=10_000)\n</code></pre> <pre><code>Overlap with SWAP test:\ntensor([[2.5000e-01, 4.4409e-16],\n[4.4409e-16, 4.4409e-16]])\nOverlap with SWAP test with finite number of shots:\ntensor([[ 0.2538, -0.0064],\n[ 0.0006,  0.0064]])\n</code></pre>"},{"location":"tutorials/parameters/","title":"Parametric Programs","text":"<p>Qadence base <code>Parameter</code> type is a subtype of <code>sympy.Symbol</code>. There are three kinds of parameter subtypes used:</p> <ul> <li>Fixed Parameter: A constant with a fixed, non-trainable value (e.g. \\(\\dfrac{\\pi}{2}\\)).</li> <li>Variational Parameter: A trainable parameter which can be be optimized.</li> <li>Feature Parameter: A non-trainable parameter which can be used to encode classical data into a quantum state.</li> </ul>"},{"location":"tutorials/parameters/#fixed-parameters","title":"Fixed Parameters","text":"<p>To pass a fixed parameter to a gate (or any parametrizable block), one can simply use either Python numeric types or wrapped in a <code>torch.Tensor</code>.</p> <pre><code>from torch import pi\nfrom qadence import RX, run\n# Let's use a torch type.\nblock = RX(0, pi)\nwf = run(block)\n# Let's pass a simple float.\nblock = RX(0, 1.)\nwf = run(block)\n</code></pre> <pre><code>wf = tensor([[6.1232e-17+0.j, 0.0000e+00-1.j]])\nwf = tensor([[0.8776+0.0000j, 0.0000-0.4794j]])\n</code></pre>"},{"location":"tutorials/parameters/#variational-parameters","title":"Variational Parameters","text":"<p>To parametrize a block by an angle <code>theta</code>, either a Python <code>string</code> or an instance of  <code>VariationalParameter</code> can be passed instead of a numeric type to the gate constructor:</p> <pre><code>from qadence import RX, run, VariationalParameter\nblock = RX(0, \"theta\")\n# This is equivalent to:\nblock = RX(0, VariationalParameter(\"theta\"))\nwf = run(block)\n</code></pre> <pre><code>wf = tensor([[0.9575+0.0000j, 0.0000-0.2883j]])\n</code></pre> <p>In the first case in the above example, <code>theta</code> is automatically inferred as a <code>VariationalParameter</code> (i.e. trainable). It is initialized to a random value for the purposes of execution. In the context of a <code>QuantumModel</code>, there is no need to pass a value for <code>theta</code> to the <code>run</code> method since it is stored within the underlying model parameter dictionary.</p>"},{"location":"tutorials/parameters/#feature-parameters","title":"Feature Parameters","text":"<p><code>FeatureParameter</code> types (i.e. inputs), always need to be provided with a value or a batch of values as a dictionary:</p> <pre><code>from torch import tensor\nfrom qadence import RX, run, FeatureParameter\nblock = RX(0, FeatureParameter(\"phi\"))\nwf = run(block, values={\"phi\": tensor([1., 2.])})\n</code></pre> <pre><code>wf = tensor([[0.8776+0.0000j, 0.0000-0.4794j],\n[0.5403+0.0000j, 0.0000-0.8415j]])\n</code></pre> <p>Now, <code>run</code> returns a batch of states, one for every provided angle which coincides with the value of the particular <code>FeatureParameter</code>.</p>"},{"location":"tutorials/parameters/#multiparameter-expressions","title":"Multiparameter Expressions","text":"<p>However, an angle can itself be an expression <code>Parameter</code> types of any kind. As such, any sympy expression <code>expr: sympy.Basic</code> consisting of a combination of free symbols (i.e. <code>sympy</code> types) and Qadence <code>Parameter</code> can be passed to a block, including trigonometric functions.</p> <pre><code>from torch import tensor\nfrom qadence import RX, Parameter, run, FeatureParameter\nfrom sympy import sin\ntheta, phi = Parameter(\"theta\"), FeatureParameter(\"phi\")\nblock = RX(0, sin(theta+phi))\n# Remember, to run the block, only FeatureParameter values have to be provided:\nvalues = {\"phi\": tensor([1.0, 2.0])}\nwf = run(block, values=values)\n</code></pre> <pre><code>wf = tensor([[0.8818+0.0000j, 0.0000-0.4716j],\n[0.9827+0.0000j, 0.0000-0.1854j]])\n</code></pre>"},{"location":"tutorials/parameters/#parameters-redundancy","title":"Parameters Redundancy","text":"<p>Parameters are uniquely defined by their name and redundancy is allowed in composite blocks to assign the same value to different blocks.</p> <pre><code>import torch\nfrom qadence import RX, RY, run, chain, kron\nblock = chain(\nkron(RX(0, \"phi\"), RY(1, \"theta\")),\nkron(RX(0, \"phi\"), RY(1, \"theta\")),\n)\nwf = run(block)  # Same random initialization for all instances of phi and theta.\n</code></pre> <pre><code>wf = tensor([[0.8666+0.0000j, 0.4489+0.0000j, 0.0000-0.1937j, 0.0000-0.1003j]])\n</code></pre>"},{"location":"tutorials/parameters/#parametrized-circuits","title":"Parametrized Circuits","text":"<p>Now, let's have a look at the construction of a variational ansatz which composes <code>FeatureParameter</code> and <code>VariationalParameter</code> types:</p> <pre><code>import sympy\nfrom qadence import RX, RY, RZ, CNOT, Z, run, chain, kron, FeatureParameter, VariationalParameter\nphi = FeatureParameter(\"phi\")\ntheta = VariationalParameter(\"theta\")\nblock = chain(\nkron(\nRX(0, phi/theta),\nRY(1, theta*2),\nRZ(2, sympy.cos(phi)),\n),\nkron(\nRX(0, phi),\nRY(1, theta),\nRZ(2, phi),\n),\nkron(\nRX(0, phi),\nRY(1, theta),\nRZ(2, phi),\n),\nkron(\nRX(0, phi + theta),\nRY(1, theta**2),\nRZ(2, sympy.cos(phi)),\n),\nchain(CNOT(0,1), CNOT(1,2))\n)\nblock.tag = \"Rotations\"\nobs = 2*kron(*map(Z, range(3)))\nblock = chain(block, obs)\n</code></pre> %3 cluster_90adc0bff21549a2bf3cf9958b0d90d9 [* 2] cluster_1fd3472d28634d14aa9626ff9933e158 Rotations 534b03f7891142cda8f6bc3b4eaa0093 0 8487a87e258a45888ee0cb782075f39b RX(phi/theta) 534b03f7891142cda8f6bc3b4eaa0093--8487a87e258a45888ee0cb782075f39b d2116026cf0e4bbbb5541339a4512b10 1 cbd0a5e0a2204ce6bc56474912751a72 RX(phi) 8487a87e258a45888ee0cb782075f39b--cbd0a5e0a2204ce6bc56474912751a72 671ed674f5244ae093bbabd232508344 RX(phi) cbd0a5e0a2204ce6bc56474912751a72--671ed674f5244ae093bbabd232508344 ef5e8be6f4054c7a96521fbf8fa337bb RX(phi + theta) 671ed674f5244ae093bbabd232508344--ef5e8be6f4054c7a96521fbf8fa337bb a20c60d44ab94771bca251e24aadfa2b ef5e8be6f4054c7a96521fbf8fa337bb--a20c60d44ab94771bca251e24aadfa2b fa84113a57fd47d0b549be55bea9bede a20c60d44ab94771bca251e24aadfa2b--fa84113a57fd47d0b549be55bea9bede e3554223e03c401fba4cad52748851c3 Z fa84113a57fd47d0b549be55bea9bede--e3554223e03c401fba4cad52748851c3 cbb180d8d56b437287d680f47f23de1f e3554223e03c401fba4cad52748851c3--cbb180d8d56b437287d680f47f23de1f 51b82fb0c7c1458a8e9904f7c4eebcb7 739f9e4524704139a1a8243528389921 RY(2*theta) d2116026cf0e4bbbb5541339a4512b10--739f9e4524704139a1a8243528389921 b8e6c63212e04c388b74dd73ab3a2f58 2 a9733346b81c4c679452746c20904320 RY(theta) 739f9e4524704139a1a8243528389921--a9733346b81c4c679452746c20904320 c766d4e87f5f4e9192b315d09722acc0 RY(theta) a9733346b81c4c679452746c20904320--c766d4e87f5f4e9192b315d09722acc0 95f218707b334405a5e70716528698d2 RY(theta**2) c766d4e87f5f4e9192b315d09722acc0--95f218707b334405a5e70716528698d2 81a2b5df70e449739ca1641416ef01a5 X 95f218707b334405a5e70716528698d2--81a2b5df70e449739ca1641416ef01a5 81a2b5df70e449739ca1641416ef01a5--a20c60d44ab94771bca251e24aadfa2b 02d0e1853ae445c3b0e279056b16dbb7 81a2b5df70e449739ca1641416ef01a5--02d0e1853ae445c3b0e279056b16dbb7 52f4cf5597484a5bac66f0213bc7519b Z 02d0e1853ae445c3b0e279056b16dbb7--52f4cf5597484a5bac66f0213bc7519b 52f4cf5597484a5bac66f0213bc7519b--51b82fb0c7c1458a8e9904f7c4eebcb7 fdd60530eed84e3b8f81541c0843ce32 a750b66a50a6439a818f5e256b876e0b RZ(cos(phi)) b8e6c63212e04c388b74dd73ab3a2f58--a750b66a50a6439a818f5e256b876e0b 05373a2138904bd18af72f7fbe695f5a RZ(phi) a750b66a50a6439a818f5e256b876e0b--05373a2138904bd18af72f7fbe695f5a ece954b4eabd46589a7e2e5c8e8006d9 RZ(phi) 05373a2138904bd18af72f7fbe695f5a--ece954b4eabd46589a7e2e5c8e8006d9 5a44224f8c134647b80e731487d0834e RZ(cos(phi)) ece954b4eabd46589a7e2e5c8e8006d9--5a44224f8c134647b80e731487d0834e 8cddda4852f046e3bf2db7157d272263 5a44224f8c134647b80e731487d0834e--8cddda4852f046e3bf2db7157d272263 b7f8699118c4462f8c7d061b709dc8d8 X 8cddda4852f046e3bf2db7157d272263--b7f8699118c4462f8c7d061b709dc8d8 b7f8699118c4462f8c7d061b709dc8d8--02d0e1853ae445c3b0e279056b16dbb7 318a8ffcda494455b2084fec74990394 Z b7f8699118c4462f8c7d061b709dc8d8--318a8ffcda494455b2084fec74990394 318a8ffcda494455b2084fec74990394--fdd60530eed84e3b8f81541c0843ce32 <p>Please note the different colors for the parametrization with different types. The default palette assigns light blue for <code>VariationalParameter</code>, light green for <code>FeatureParameter</code> and shaded red for observables.</p>"},{"location":"tutorials/parameters/#parametrized-quantummodels","title":"Parametrized QuantumModels","text":"<p>As a quick reminder: <code>FeatureParameter</code> are used for data input and data encoding into a quantum state. <code>VariationalParameter</code> are trainable parameters in a variational ansatz. When used within a <code>QuantumModel</code>, an abstract quantum circuit is made differentiable with respect to both variational and feature parameters which are uniquely identified by their name.</p> <pre><code>from qadence import FeatureParameter, Parameter, VariationalParameter\n# Feature parameters are non-trainable parameters.\n# Their primary use is input data encoding.\nfp = FeatureParameter(\"x\")\nassert fp == Parameter(\"x\", trainable=False)\n# Variational parameters are trainable parameters.\n# Their primary use is for optimization.\nvp = VariationalParameter(\"y\")\nassert vp == Parameter(\"y\", trainable=True)\n</code></pre> <p>Let's construct a parametric quantum circuit.</p> <pre><code>from qadence import QuantumCircuit, RX, RY, chain, kron\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\nblock = chain(\nkron(RX(0, theta), RY(1, theta)),\nkron(RX(0, phi), RY(1, phi)),\n)\ncircuit = QuantumCircuit(2, block)\nunique_params = circuit.unique_parameters\n</code></pre> <pre><code>unique_params = [theta, phi]\n</code></pre> <p>In the circuit above, four parameters are defined but only two unique names. Therefore, there will be only one variational parameter to be optimized.</p> <p>The <code>QuantumModel</code> class also provides convenience methods to manipulate parameters.</p> <pre><code>from qadence import QuantumModel, BackendName, DiffMode\nmodel = QuantumModel(circuit, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD)\nnum_vparams = model.num_vparams\nvparams_values = model.vparams\n</code></pre> <pre><code>num_vparams = 1\nvparams_values = OrderedDict([('theta', tensor([0.5877]))])\n</code></pre> <p>Only provide feature parameter values to the quantum model</p> <p>In order to <code>run</code> the variational circuit only feature parameter values have to be provided. Variational parameters are stored in the model itself. If multiple feature parameters are present, values must be provided in batches of same length.</p> <p><pre><code>import torch\nvalues = {\"phi\": torch.rand(3)} # theta does not appear here\nwf = model.run(values)\n</code></pre> <pre><code>wf = tensor([[0.5120+0.0000j, 0.4999+0.0000j, 0.0000-0.4999j, 0.0000-0.4880j],\n[0.5607+0.0000j, 0.4963+0.0000j, 0.0000-0.4963j, 0.0000-0.4393j],\n[0.6286+0.0000j, 0.4832+0.0000j, 0.0000-0.4832j, 0.0000-0.3714j]],\ngrad_fn=&lt;TBackward0&gt;)\n</code></pre> </p>"},{"location":"tutorials/parameters/#standard-constructors","title":"Standard constructors","text":"<p>The unique parameter identification is relevant when using built-in Qadence block constructors in the <code>qadence.constructors</code> module such as feature maps and hardware efficient ansatze (HEA).</p> <p><pre><code>from qadence import QuantumCircuit, hea\nn_qubits = 4\ndepth = 2\nhea1 = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, hea1)\nnum_unique_parameters = circuit.num_unique_parameters\n</code></pre> <pre><code>Unique parameters with a single HEA: 24\n</code></pre> %3 d5167ed6781f4657b712237b1f1458ca 0 d94436daee0b4f7cbe6390310691f67a RX(theta\u2080) d5167ed6781f4657b712237b1f1458ca--d94436daee0b4f7cbe6390310691f67a f78569cac8bf400ea9baabef513ca989 1 72d22cce8dd94a8d806104f6807b9cc6 RY(theta\u2084) d94436daee0b4f7cbe6390310691f67a--72d22cce8dd94a8d806104f6807b9cc6 692e667b0ebf4efbbff91a05b5ec4062 RX(theta\u2088) 72d22cce8dd94a8d806104f6807b9cc6--692e667b0ebf4efbbff91a05b5ec4062 36ae858633c84217b3762b41fdda25f9 692e667b0ebf4efbbff91a05b5ec4062--36ae858633c84217b3762b41fdda25f9 bf311995dc2543489b03f20a95ed7989 36ae858633c84217b3762b41fdda25f9--bf311995dc2543489b03f20a95ed7989 84f440949693450f9c2ce552d9c71802 RX(theta\u2081\u2082) bf311995dc2543489b03f20a95ed7989--84f440949693450f9c2ce552d9c71802 0d461be963ce43d19aacb68c4eef2b4f RY(theta\u2081\u2086) 84f440949693450f9c2ce552d9c71802--0d461be963ce43d19aacb68c4eef2b4f e03777dbf577408a8cf6178ae4986813 RX(theta\u2082\u2080) 0d461be963ce43d19aacb68c4eef2b4f--e03777dbf577408a8cf6178ae4986813 b9174aaa801b4e3abb06467e71aa3b62 e03777dbf577408a8cf6178ae4986813--b9174aaa801b4e3abb06467e71aa3b62 308dd9ec07e54ab7b4fce0f020b50f05 b9174aaa801b4e3abb06467e71aa3b62--308dd9ec07e54ab7b4fce0f020b50f05 0e2bb46c9a374efabed3e0ae56b389e8 308dd9ec07e54ab7b4fce0f020b50f05--0e2bb46c9a374efabed3e0ae56b389e8 5accdd84b66246adade8608f216ad10c 72c64d3a812e4c4390292a112bea8fa2 RX(theta\u2081) f78569cac8bf400ea9baabef513ca989--72c64d3a812e4c4390292a112bea8fa2 88316228578347c8bc2284849515ba5a 2 a486b383464c4dbb86867a26d774137d RY(theta\u2085) 72c64d3a812e4c4390292a112bea8fa2--a486b383464c4dbb86867a26d774137d 1612f29f85214f929f22e9a75f7aef46 RX(theta\u2089) a486b383464c4dbb86867a26d774137d--1612f29f85214f929f22e9a75f7aef46 20c52924fdca48f3a70fdb7161bf0041 X 1612f29f85214f929f22e9a75f7aef46--20c52924fdca48f3a70fdb7161bf0041 20c52924fdca48f3a70fdb7161bf0041--36ae858633c84217b3762b41fdda25f9 2e70fb4a5e5a456e88e21f025cf167f5 20c52924fdca48f3a70fdb7161bf0041--2e70fb4a5e5a456e88e21f025cf167f5 1d08f6ea90f640d9a5c95354acf51e8a RX(theta\u2081\u2083) 2e70fb4a5e5a456e88e21f025cf167f5--1d08f6ea90f640d9a5c95354acf51e8a 1cdfdf17f34b4a1d8dbd4f90ae3002b6 RY(theta\u2081\u2087) 1d08f6ea90f640d9a5c95354acf51e8a--1cdfdf17f34b4a1d8dbd4f90ae3002b6 36214872224c4293bf9c299e6396a8df RX(theta\u2082\u2081) 1cdfdf17f34b4a1d8dbd4f90ae3002b6--36214872224c4293bf9c299e6396a8df 6bcf102010ea4db0a5fd9ec702836113 X 36214872224c4293bf9c299e6396a8df--6bcf102010ea4db0a5fd9ec702836113 6bcf102010ea4db0a5fd9ec702836113--b9174aaa801b4e3abb06467e71aa3b62 aba773bdebd34e9295fd53a02413ca57 6bcf102010ea4db0a5fd9ec702836113--aba773bdebd34e9295fd53a02413ca57 aba773bdebd34e9295fd53a02413ca57--5accdd84b66246adade8608f216ad10c 0de53a4546c543419d21013d33d3f2eb 9498aa83ff554fc2949694449f328abf RX(theta\u2082) 88316228578347c8bc2284849515ba5a--9498aa83ff554fc2949694449f328abf 1a44c3b40ba64b2480a38784aa8164e6 3 564ed21308334885939f72934892fa10 RY(theta\u2086) 9498aa83ff554fc2949694449f328abf--564ed21308334885939f72934892fa10 aec891bd01d24d9fabd3b51d21dc2903 RX(theta\u2081\u2080) 564ed21308334885939f72934892fa10--aec891bd01d24d9fabd3b51d21dc2903 38ab3c828ddf45d58fff34efca36c14b aec891bd01d24d9fabd3b51d21dc2903--38ab3c828ddf45d58fff34efca36c14b 28920e1cb7f24384a4df697b66e7c669 X 38ab3c828ddf45d58fff34efca36c14b--28920e1cb7f24384a4df697b66e7c669 28920e1cb7f24384a4df697b66e7c669--2e70fb4a5e5a456e88e21f025cf167f5 45167288c658447596943efbe37d488e RX(theta\u2081\u2084) 28920e1cb7f24384a4df697b66e7c669--45167288c658447596943efbe37d488e 107d2d2df5f04c3181c531c10c2e6a62 RY(theta\u2081\u2088) 45167288c658447596943efbe37d488e--107d2d2df5f04c3181c531c10c2e6a62 9720901b2bc0409cb0f9668a372ca20e RX(theta\u2082\u2082) 107d2d2df5f04c3181c531c10c2e6a62--9720901b2bc0409cb0f9668a372ca20e 591e6b875dc049ea9e86b310931d9eb5 9720901b2bc0409cb0f9668a372ca20e--591e6b875dc049ea9e86b310931d9eb5 adb40f25b9c74d8ca49a96d8e29abbf3 X 591e6b875dc049ea9e86b310931d9eb5--adb40f25b9c74d8ca49a96d8e29abbf3 adb40f25b9c74d8ca49a96d8e29abbf3--aba773bdebd34e9295fd53a02413ca57 adb40f25b9c74d8ca49a96d8e29abbf3--0de53a4546c543419d21013d33d3f2eb 5442d2420af240ca9ca2a08bbd65123b e907de8905394eb4bd9b0bb5bf819ab6 RX(theta\u2083) 1a44c3b40ba64b2480a38784aa8164e6--e907de8905394eb4bd9b0bb5bf819ab6 b6063291b3054fb8ab5cf490647cdfa4 RY(theta\u2087) e907de8905394eb4bd9b0bb5bf819ab6--b6063291b3054fb8ab5cf490647cdfa4 485e7f5f07674ad4aa21eb163fd7c128 RX(theta\u2081\u2081) b6063291b3054fb8ab5cf490647cdfa4--485e7f5f07674ad4aa21eb163fd7c128 92edbfb993c744138182e47ce5eb1a0b X 485e7f5f07674ad4aa21eb163fd7c128--92edbfb993c744138182e47ce5eb1a0b 92edbfb993c744138182e47ce5eb1a0b--38ab3c828ddf45d58fff34efca36c14b 135c10ee8517457c868b5d9c7f965654 92edbfb993c744138182e47ce5eb1a0b--135c10ee8517457c868b5d9c7f965654 b04c979f4bd6411788ac5f8655138876 RX(theta\u2081\u2085) 135c10ee8517457c868b5d9c7f965654--b04c979f4bd6411788ac5f8655138876 a8e262d3469449ca85f24b9ed71edb61 RY(theta\u2081\u2089) b04c979f4bd6411788ac5f8655138876--a8e262d3469449ca85f24b9ed71edb61 a8b40ec7ce7f4ba1a94daa4207fbcf1a RX(theta\u2082\u2083) a8e262d3469449ca85f24b9ed71edb61--a8b40ec7ce7f4ba1a94daa4207fbcf1a 72f165be21c24f7bada297f8f2c2d70e X a8b40ec7ce7f4ba1a94daa4207fbcf1a--72f165be21c24f7bada297f8f2c2d70e 72f165be21c24f7bada297f8f2c2d70e--591e6b875dc049ea9e86b310931d9eb5 b090a1496ca5464b8b47d08fd9ff5f7d 72f165be21c24f7bada297f8f2c2d70e--b090a1496ca5464b8b47d08fd9ff5f7d b090a1496ca5464b8b47d08fd9ff5f7d--5442d2420af240ca9ca2a08bbd65123b </p> <p>A new circuit can be created by adding another identical HEA. As expected, the number of unique parameters is the same.</p> <p><pre><code>hea2 = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, hea1, hea2)\nnum_unique_params_two_heas = circuit.num_unique_parameters\n</code></pre> <pre><code>Unique parameters with two stacked HEAs: 24\n</code></pre> %3 cluster_b924c21c82eb4131a8d257a08347232c HEA cluster_545d65bc026d49218972c434c0f97232 HEA 76694ae0e41441fc8af5f35105555645 0 8d633546120846c6991c314dc50929a0 RX(theta\u2080) 76694ae0e41441fc8af5f35105555645--8d633546120846c6991c314dc50929a0 b7392b6a3b3a4ae3ab7ced806f19653b 1 9f8ad03c691c488780e1496ac3808109 RY(theta\u2084) 8d633546120846c6991c314dc50929a0--9f8ad03c691c488780e1496ac3808109 e3f5b41c82d54da395b3f05c660498c0 RX(theta\u2088) 9f8ad03c691c488780e1496ac3808109--e3f5b41c82d54da395b3f05c660498c0 1e1ebb8384c047078a1e3ac8cfb4cdde e3f5b41c82d54da395b3f05c660498c0--1e1ebb8384c047078a1e3ac8cfb4cdde 27e1b36fef0643eda9e0a4c91e10303e 1e1ebb8384c047078a1e3ac8cfb4cdde--27e1b36fef0643eda9e0a4c91e10303e 6613972cbd384d77a48a2670a82f3f5e RX(theta\u2081\u2082) 27e1b36fef0643eda9e0a4c91e10303e--6613972cbd384d77a48a2670a82f3f5e 85985fd5cf5940a4aa387723e157ab35 RY(theta\u2081\u2086) 6613972cbd384d77a48a2670a82f3f5e--85985fd5cf5940a4aa387723e157ab35 fec5029c63304f74a245a4983df350ea RX(theta\u2082\u2080) 85985fd5cf5940a4aa387723e157ab35--fec5029c63304f74a245a4983df350ea ba141aabbaad4fddbd443774b289d191 fec5029c63304f74a245a4983df350ea--ba141aabbaad4fddbd443774b289d191 86e298fcdf8849498209838766147a16 ba141aabbaad4fddbd443774b289d191--86e298fcdf8849498209838766147a16 11d3c7fdedf94827a1a9097772ffc7a4 RX(theta\u2080) 86e298fcdf8849498209838766147a16--11d3c7fdedf94827a1a9097772ffc7a4 939f2f30f4154309a8693e43a9e8bb3c RY(theta\u2084) 11d3c7fdedf94827a1a9097772ffc7a4--939f2f30f4154309a8693e43a9e8bb3c 5384be70eec44c0782e69155699c65e9 RX(theta\u2088) 939f2f30f4154309a8693e43a9e8bb3c--5384be70eec44c0782e69155699c65e9 9972d794909e4d8c82cb1b7ec41c3045 5384be70eec44c0782e69155699c65e9--9972d794909e4d8c82cb1b7ec41c3045 3c30311c47854cb1b311a7a81f7964f0 9972d794909e4d8c82cb1b7ec41c3045--3c30311c47854cb1b311a7a81f7964f0 0fcd3c550c6b4cb893063205d7e4207c RX(theta\u2081\u2082) 3c30311c47854cb1b311a7a81f7964f0--0fcd3c550c6b4cb893063205d7e4207c 08ed3c90b9544e4e8d2c2c4d7f26cb1f RY(theta\u2081\u2086) 0fcd3c550c6b4cb893063205d7e4207c--08ed3c90b9544e4e8d2c2c4d7f26cb1f e90d6ca0e7b64d60850365b97118f083 RX(theta\u2082\u2080) 08ed3c90b9544e4e8d2c2c4d7f26cb1f--e90d6ca0e7b64d60850365b97118f083 b8dd6c5a8d3f409e84d874b4335dbc9a e90d6ca0e7b64d60850365b97118f083--b8dd6c5a8d3f409e84d874b4335dbc9a 3d90109f5acb4c8c8f03bcae2e066da4 b8dd6c5a8d3f409e84d874b4335dbc9a--3d90109f5acb4c8c8f03bcae2e066da4 008ce57bc0124932bc0f5d979e2bc48d 3d90109f5acb4c8c8f03bcae2e066da4--008ce57bc0124932bc0f5d979e2bc48d b3266cde736e4674ae8d77e2944c7b51 eeb8f2c5a26b475a9983e003d3418d70 RX(theta\u2081) b7392b6a3b3a4ae3ab7ced806f19653b--eeb8f2c5a26b475a9983e003d3418d70 9b07d92092e04d08bb99fe629c33538b 2 17ab949f3cf44fe3a48250b289f97130 RY(theta\u2085) eeb8f2c5a26b475a9983e003d3418d70--17ab949f3cf44fe3a48250b289f97130 dcc85672d23f40f1a46973ddbd0e436d RX(theta\u2089) 17ab949f3cf44fe3a48250b289f97130--dcc85672d23f40f1a46973ddbd0e436d 939a131f6e7346e6b4f8af57098dc902 X dcc85672d23f40f1a46973ddbd0e436d--939a131f6e7346e6b4f8af57098dc902 939a131f6e7346e6b4f8af57098dc902--1e1ebb8384c047078a1e3ac8cfb4cdde ca6b6d9ce45f48798ef439fd9a4524ff 939a131f6e7346e6b4f8af57098dc902--ca6b6d9ce45f48798ef439fd9a4524ff 9859338385d04d409b16af62aad6398c RX(theta\u2081\u2083) ca6b6d9ce45f48798ef439fd9a4524ff--9859338385d04d409b16af62aad6398c 216fe31bb3be44e688c663b37a3b8add RY(theta\u2081\u2087) 9859338385d04d409b16af62aad6398c--216fe31bb3be44e688c663b37a3b8add eefbe05d15f04e48852171048a1d309a RX(theta\u2082\u2081) 216fe31bb3be44e688c663b37a3b8add--eefbe05d15f04e48852171048a1d309a c9b9fb7804e449ef9c1e32603047813c X eefbe05d15f04e48852171048a1d309a--c9b9fb7804e449ef9c1e32603047813c c9b9fb7804e449ef9c1e32603047813c--ba141aabbaad4fddbd443774b289d191 7d99d31133d1480b8d1f8517825e8477 c9b9fb7804e449ef9c1e32603047813c--7d99d31133d1480b8d1f8517825e8477 b74b522aabaa49ddbb0850d3b8975c01 RX(theta\u2081) 7d99d31133d1480b8d1f8517825e8477--b74b522aabaa49ddbb0850d3b8975c01 ef781d8b6fe54526bac5ae04bbad89c0 RY(theta\u2085) b74b522aabaa49ddbb0850d3b8975c01--ef781d8b6fe54526bac5ae04bbad89c0 45a11cecdc824eaeb34b8ef03873518e RX(theta\u2089) ef781d8b6fe54526bac5ae04bbad89c0--45a11cecdc824eaeb34b8ef03873518e 8e90824967ed4143845ec02614a2d71a X 45a11cecdc824eaeb34b8ef03873518e--8e90824967ed4143845ec02614a2d71a 8e90824967ed4143845ec02614a2d71a--9972d794909e4d8c82cb1b7ec41c3045 3142dee86a484ed5a582d2417f08889e 8e90824967ed4143845ec02614a2d71a--3142dee86a484ed5a582d2417f08889e 61bafe56377145079c4be6dd78a9aeb5 RX(theta\u2081\u2083) 3142dee86a484ed5a582d2417f08889e--61bafe56377145079c4be6dd78a9aeb5 c644ffe695524a84b1d2b35b710678ba RY(theta\u2081\u2087) 61bafe56377145079c4be6dd78a9aeb5--c644ffe695524a84b1d2b35b710678ba b4312ba07f384b53b41eeea153df4847 RX(theta\u2082\u2081) c644ffe695524a84b1d2b35b710678ba--b4312ba07f384b53b41eeea153df4847 4b59923e6295477ab20413ddfcae5d89 X b4312ba07f384b53b41eeea153df4847--4b59923e6295477ab20413ddfcae5d89 4b59923e6295477ab20413ddfcae5d89--b8dd6c5a8d3f409e84d874b4335dbc9a 30ca64651e0c40dea93d6b3cb948645d 4b59923e6295477ab20413ddfcae5d89--30ca64651e0c40dea93d6b3cb948645d 30ca64651e0c40dea93d6b3cb948645d--b3266cde736e4674ae8d77e2944c7b51 980c8406e6144904b6f1b9f1f7100f89 7be5f9504ae846a48c82fe7cdbd6ab8c RX(theta\u2082) 9b07d92092e04d08bb99fe629c33538b--7be5f9504ae846a48c82fe7cdbd6ab8c be79263194f3407899d10e9798371d82 3 92cb6a557e09418bbda40b0ab1c8ffeb RY(theta\u2086) 7be5f9504ae846a48c82fe7cdbd6ab8c--92cb6a557e09418bbda40b0ab1c8ffeb 8570c0179f454a69b0c286233eac4ae5 RX(theta\u2081\u2080) 92cb6a557e09418bbda40b0ab1c8ffeb--8570c0179f454a69b0c286233eac4ae5 3d4a18a0d18a4d4abf6e74914da89baf 8570c0179f454a69b0c286233eac4ae5--3d4a18a0d18a4d4abf6e74914da89baf 0e7972f87fed415aba27f155adbf5b2f X 3d4a18a0d18a4d4abf6e74914da89baf--0e7972f87fed415aba27f155adbf5b2f 0e7972f87fed415aba27f155adbf5b2f--ca6b6d9ce45f48798ef439fd9a4524ff deb1406c84d14490a017dfd45e464713 RX(theta\u2081\u2084) 0e7972f87fed415aba27f155adbf5b2f--deb1406c84d14490a017dfd45e464713 8b651f12c22e4d03b836c38cdcfa2966 RY(theta\u2081\u2088) deb1406c84d14490a017dfd45e464713--8b651f12c22e4d03b836c38cdcfa2966 a939625a2fd74b44ac216760b333dd11 RX(theta\u2082\u2082) 8b651f12c22e4d03b836c38cdcfa2966--a939625a2fd74b44ac216760b333dd11 14c1474635a54bfcaa5db2047b82a826 a939625a2fd74b44ac216760b333dd11--14c1474635a54bfcaa5db2047b82a826 9788a2b2fab74a5fa7f0775f24938948 X 14c1474635a54bfcaa5db2047b82a826--9788a2b2fab74a5fa7f0775f24938948 9788a2b2fab74a5fa7f0775f24938948--7d99d31133d1480b8d1f8517825e8477 2e31172eef33406f8c845dabe1fcd0be RX(theta\u2082) 9788a2b2fab74a5fa7f0775f24938948--2e31172eef33406f8c845dabe1fcd0be bca6115a9a99440aa70371ad5f371da4 RY(theta\u2086) 2e31172eef33406f8c845dabe1fcd0be--bca6115a9a99440aa70371ad5f371da4 09679d5705684d9ba3c7cc5785cf802b RX(theta\u2081\u2080) bca6115a9a99440aa70371ad5f371da4--09679d5705684d9ba3c7cc5785cf802b 1d32c7f3459341c6a93575b303515dea 09679d5705684d9ba3c7cc5785cf802b--1d32c7f3459341c6a93575b303515dea 1ae5f9c286df45a990104905040e7f03 X 1d32c7f3459341c6a93575b303515dea--1ae5f9c286df45a990104905040e7f03 1ae5f9c286df45a990104905040e7f03--3142dee86a484ed5a582d2417f08889e 92b412cdc3d2407aabad68414c0bb5b7 RX(theta\u2081\u2084) 1ae5f9c286df45a990104905040e7f03--92b412cdc3d2407aabad68414c0bb5b7 f8652de0b4d94922aad1f985d3a58585 RY(theta\u2081\u2088) 92b412cdc3d2407aabad68414c0bb5b7--f8652de0b4d94922aad1f985d3a58585 6fa2101fe65046eba0f878ae2444556d RX(theta\u2082\u2082) f8652de0b4d94922aad1f985d3a58585--6fa2101fe65046eba0f878ae2444556d 8d25a06990f24d3e87c34255d3755a5b 6fa2101fe65046eba0f878ae2444556d--8d25a06990f24d3e87c34255d3755a5b 0d0a3a5745bb4f94a87b06ee7c373d43 X 8d25a06990f24d3e87c34255d3755a5b--0d0a3a5745bb4f94a87b06ee7c373d43 0d0a3a5745bb4f94a87b06ee7c373d43--30ca64651e0c40dea93d6b3cb948645d 0d0a3a5745bb4f94a87b06ee7c373d43--980c8406e6144904b6f1b9f1f7100f89 650a511877f845e09a084ba71e84b1b2 08fa5f5707624e799a6456ca57ae5469 RX(theta\u2083) be79263194f3407899d10e9798371d82--08fa5f5707624e799a6456ca57ae5469 de43c1e7cc034b43865c31120be007bc RY(theta\u2087) 08fa5f5707624e799a6456ca57ae5469--de43c1e7cc034b43865c31120be007bc 5cf38f6a44484928becdd157325dbae4 RX(theta\u2081\u2081) de43c1e7cc034b43865c31120be007bc--5cf38f6a44484928becdd157325dbae4 e3aed8126c6b40f497d7294fea15e96f X 5cf38f6a44484928becdd157325dbae4--e3aed8126c6b40f497d7294fea15e96f e3aed8126c6b40f497d7294fea15e96f--3d4a18a0d18a4d4abf6e74914da89baf 78ae3dd6b34a4351aad6123e9902f08d e3aed8126c6b40f497d7294fea15e96f--78ae3dd6b34a4351aad6123e9902f08d 1277a4995b3c486f9527003857d598fe RX(theta\u2081\u2085) 78ae3dd6b34a4351aad6123e9902f08d--1277a4995b3c486f9527003857d598fe 8eb74ed79d4c4213984c9ca8d2237a43 RY(theta\u2081\u2089) 1277a4995b3c486f9527003857d598fe--8eb74ed79d4c4213984c9ca8d2237a43 c4e9bd004383403b83ca95c4d2af66ad RX(theta\u2082\u2083) 8eb74ed79d4c4213984c9ca8d2237a43--c4e9bd004383403b83ca95c4d2af66ad b53918881f154e57bffd96c3376a2f95 X c4e9bd004383403b83ca95c4d2af66ad--b53918881f154e57bffd96c3376a2f95 b53918881f154e57bffd96c3376a2f95--14c1474635a54bfcaa5db2047b82a826 77ca20abbb534438a02ed45475b56327 b53918881f154e57bffd96c3376a2f95--77ca20abbb534438a02ed45475b56327 195f673d8bc64252b67a482176b35161 RX(theta\u2083) 77ca20abbb534438a02ed45475b56327--195f673d8bc64252b67a482176b35161 047b0aa1fb1f447a97982b22accd6037 RY(theta\u2087) 195f673d8bc64252b67a482176b35161--047b0aa1fb1f447a97982b22accd6037 26bada4fc0a6447a8a4ddd5843ebe755 RX(theta\u2081\u2081) 047b0aa1fb1f447a97982b22accd6037--26bada4fc0a6447a8a4ddd5843ebe755 e0485df024b840928784f5a626633bdc X 26bada4fc0a6447a8a4ddd5843ebe755--e0485df024b840928784f5a626633bdc e0485df024b840928784f5a626633bdc--1d32c7f3459341c6a93575b303515dea 656f093e75fb4bd5a048dfcb61dd767b e0485df024b840928784f5a626633bdc--656f093e75fb4bd5a048dfcb61dd767b 9ceb74ab735f44a5b40a674099baf6aa RX(theta\u2081\u2085) 656f093e75fb4bd5a048dfcb61dd767b--9ceb74ab735f44a5b40a674099baf6aa c0c30305470b4fd499241ef62fa34efd RY(theta\u2081\u2089) 9ceb74ab735f44a5b40a674099baf6aa--c0c30305470b4fd499241ef62fa34efd 49bc51ee22c54305a3a740c2ad249758 RX(theta\u2082\u2083) c0c30305470b4fd499241ef62fa34efd--49bc51ee22c54305a3a740c2ad249758 61baeacafab7454f87ffab62e0aeb0d2 X 49bc51ee22c54305a3a740c2ad249758--61baeacafab7454f87ffab62e0aeb0d2 61baeacafab7454f87ffab62e0aeb0d2--8d25a06990f24d3e87c34255d3755a5b 5767c5f9f277407996cc344b24a81a7e 61baeacafab7454f87ffab62e0aeb0d2--5767c5f9f277407996cc344b24a81a7e 5767c5f9f277407996cc344b24a81a7e--650a511877f845e09a084ba71e84b1b2 </p> <p>Avoid non-unique names by prefixing</p> <p>A parameter prefix for each HEA can be passed as follows:</p> <p><pre><code>hea1 = hea(n_qubits=n_qubits, depth=depth, param_prefix=\"p1\")\nhea2 = hea(n_qubits=n_qubits, depth=depth, param_prefix=\"p2\")\ncircuit = QuantumCircuit(n_qubits, hea1, hea2)\nn_params_two_heas = circuit.num_unique_parameters\n</code></pre> <pre><code>Unique parameters with two stacked HEAs: 48\n</code></pre> %3 cluster_f9f55d8d1b4c45b687b01c4e9b9aa155 HEA cluster_47f2a42a0e3c4f7db8ec63ec1bb6bdce HEA 0ec53a4273914a828235db6ae44a30fe 0 041d85740f234842865a1e577d257ae9 RX(p1\u2080) 0ec53a4273914a828235db6ae44a30fe--041d85740f234842865a1e577d257ae9 845ca2c0dc3e42c48416c923d8e181e8 1 33bd735c4b9b4ecf88b401a6594b2971 RY(p1\u2084) 041d85740f234842865a1e577d257ae9--33bd735c4b9b4ecf88b401a6594b2971 6dff6a0f78d34a8b8ca6167ba2482ec6 RX(p1\u2088) 33bd735c4b9b4ecf88b401a6594b2971--6dff6a0f78d34a8b8ca6167ba2482ec6 3cd557c0b68b45b4b51663bdeb2ad51c 6dff6a0f78d34a8b8ca6167ba2482ec6--3cd557c0b68b45b4b51663bdeb2ad51c 5acf2b9392e1463ca74bb57542e4c203 3cd557c0b68b45b4b51663bdeb2ad51c--5acf2b9392e1463ca74bb57542e4c203 ea60d0979bc442fbb99291209e321570 RX(p1\u2081\u2082) 5acf2b9392e1463ca74bb57542e4c203--ea60d0979bc442fbb99291209e321570 d4a01ae63ed947be88574650ee269c62 RY(p1\u2081\u2086) ea60d0979bc442fbb99291209e321570--d4a01ae63ed947be88574650ee269c62 a6129d595a814774ad9d2c31556091a8 RX(p1\u2082\u2080) d4a01ae63ed947be88574650ee269c62--a6129d595a814774ad9d2c31556091a8 664624f0967a4bad911407888597880a a6129d595a814774ad9d2c31556091a8--664624f0967a4bad911407888597880a 131f554e71c64f23953e2fad199aa2fb 664624f0967a4bad911407888597880a--131f554e71c64f23953e2fad199aa2fb 095e414f6df143d1bd47c8211f2a578a RX(p2\u2080) 131f554e71c64f23953e2fad199aa2fb--095e414f6df143d1bd47c8211f2a578a 36b48812b2ba4d89941b717f81665735 RY(p2\u2084) 095e414f6df143d1bd47c8211f2a578a--36b48812b2ba4d89941b717f81665735 0d35f35891de4a4aa2f39eb98474eea0 RX(p2\u2088) 36b48812b2ba4d89941b717f81665735--0d35f35891de4a4aa2f39eb98474eea0 7c7cf0f4524249faaf4859666fc917eb 0d35f35891de4a4aa2f39eb98474eea0--7c7cf0f4524249faaf4859666fc917eb 0d8eecf1c2b644b4b4c21edae69e3217 7c7cf0f4524249faaf4859666fc917eb--0d8eecf1c2b644b4b4c21edae69e3217 f9cc746e44774639becc94f3d8e0fb0c RX(p2\u2081\u2082) 0d8eecf1c2b644b4b4c21edae69e3217--f9cc746e44774639becc94f3d8e0fb0c 63458814eca54ce396eea3ddccc800eb RY(p2\u2081\u2086) f9cc746e44774639becc94f3d8e0fb0c--63458814eca54ce396eea3ddccc800eb 3c2c7bcb0df6471fbb9353380a559e1e RX(p2\u2082\u2080) 63458814eca54ce396eea3ddccc800eb--3c2c7bcb0df6471fbb9353380a559e1e 5543155317344a258654a714fa77b1e4 3c2c7bcb0df6471fbb9353380a559e1e--5543155317344a258654a714fa77b1e4 adcb28dcd1674908ae5df32fa1901a11 5543155317344a258654a714fa77b1e4--adcb28dcd1674908ae5df32fa1901a11 12e6c67995ac4fd0bc85c5c96cb01a8a adcb28dcd1674908ae5df32fa1901a11--12e6c67995ac4fd0bc85c5c96cb01a8a cb5588a336014bf8a828c4baab297b62 301d0d7d2e884b79b5c89ca2aea0d286 RX(p1\u2081) 845ca2c0dc3e42c48416c923d8e181e8--301d0d7d2e884b79b5c89ca2aea0d286 de32d384661743c9a9398b4a957551db 2 b1d0bf2c17fa4118be7238cba05259f2 RY(p1\u2085) 301d0d7d2e884b79b5c89ca2aea0d286--b1d0bf2c17fa4118be7238cba05259f2 683b0bd5540349c88961a842ac1dc64e RX(p1\u2089) b1d0bf2c17fa4118be7238cba05259f2--683b0bd5540349c88961a842ac1dc64e 7c5387845c504067a4633d524c1fb68c X 683b0bd5540349c88961a842ac1dc64e--7c5387845c504067a4633d524c1fb68c 7c5387845c504067a4633d524c1fb68c--3cd557c0b68b45b4b51663bdeb2ad51c a1d4b8577c3a42dca9b33591f50f6b49 7c5387845c504067a4633d524c1fb68c--a1d4b8577c3a42dca9b33591f50f6b49 9a3953048ec04b9184d52cc0e8bbfa05 RX(p1\u2081\u2083) a1d4b8577c3a42dca9b33591f50f6b49--9a3953048ec04b9184d52cc0e8bbfa05 17f64733d5354f1eb9cc3d903b15f002 RY(p1\u2081\u2087) 9a3953048ec04b9184d52cc0e8bbfa05--17f64733d5354f1eb9cc3d903b15f002 2404ab2e1dab4459bfbfac28257866b2 RX(p1\u2082\u2081) 17f64733d5354f1eb9cc3d903b15f002--2404ab2e1dab4459bfbfac28257866b2 3c028e4ac40b4638b551f6f81d8875f4 X 2404ab2e1dab4459bfbfac28257866b2--3c028e4ac40b4638b551f6f81d8875f4 3c028e4ac40b4638b551f6f81d8875f4--664624f0967a4bad911407888597880a 818dd1e9bf4446169511a2d6c5d537b5 3c028e4ac40b4638b551f6f81d8875f4--818dd1e9bf4446169511a2d6c5d537b5 48a5ce41dedd466db66ef2f044100d67 RX(p2\u2081) 818dd1e9bf4446169511a2d6c5d537b5--48a5ce41dedd466db66ef2f044100d67 1423f273779a487f9a2bb156378f2b9e RY(p2\u2085) 48a5ce41dedd466db66ef2f044100d67--1423f273779a487f9a2bb156378f2b9e fefa2c11baaa4045a698521c60302e36 RX(p2\u2089) 1423f273779a487f9a2bb156378f2b9e--fefa2c11baaa4045a698521c60302e36 8d3a63e19dc040edbc2c71467d9f9222 X fefa2c11baaa4045a698521c60302e36--8d3a63e19dc040edbc2c71467d9f9222 8d3a63e19dc040edbc2c71467d9f9222--7c7cf0f4524249faaf4859666fc917eb 4fd7d4bb8c3549c69b5ac40aa42579cf 8d3a63e19dc040edbc2c71467d9f9222--4fd7d4bb8c3549c69b5ac40aa42579cf 073eab547457465bbf2cdbb71ca55835 RX(p2\u2081\u2083) 4fd7d4bb8c3549c69b5ac40aa42579cf--073eab547457465bbf2cdbb71ca55835 9b162a8f2c1247f9b0d47197eca2863c RY(p2\u2081\u2087) 073eab547457465bbf2cdbb71ca55835--9b162a8f2c1247f9b0d47197eca2863c 866068338bd84ac2b208f7c99c01cdef RX(p2\u2082\u2081) 9b162a8f2c1247f9b0d47197eca2863c--866068338bd84ac2b208f7c99c01cdef 61751f448833468e9069938cbd2a1234 X 866068338bd84ac2b208f7c99c01cdef--61751f448833468e9069938cbd2a1234 61751f448833468e9069938cbd2a1234--5543155317344a258654a714fa77b1e4 eb7aca270b3c44e695ae7982599faa1d 61751f448833468e9069938cbd2a1234--eb7aca270b3c44e695ae7982599faa1d eb7aca270b3c44e695ae7982599faa1d--cb5588a336014bf8a828c4baab297b62 1c49ee8ea3f641b888dee22981c9072e 7d56fb2644934d289b6ab4c67232ec43 RX(p1\u2082) de32d384661743c9a9398b4a957551db--7d56fb2644934d289b6ab4c67232ec43 dc29528873cc442088e86d66a6285d84 3 3ecd5435b58d48c0bb3cc1c038a4c8bf RY(p1\u2086) 7d56fb2644934d289b6ab4c67232ec43--3ecd5435b58d48c0bb3cc1c038a4c8bf 7b6688ef86794494a09d3cf64f0442cc RX(p1\u2081\u2080) 3ecd5435b58d48c0bb3cc1c038a4c8bf--7b6688ef86794494a09d3cf64f0442cc 2e265de3b16f4500b3c87cb4cc9133e5 7b6688ef86794494a09d3cf64f0442cc--2e265de3b16f4500b3c87cb4cc9133e5 05f7bdee1f9745b88679570c6efa3f42 X 2e265de3b16f4500b3c87cb4cc9133e5--05f7bdee1f9745b88679570c6efa3f42 05f7bdee1f9745b88679570c6efa3f42--a1d4b8577c3a42dca9b33591f50f6b49 bcce1cda88fa4a19abffa8106430ab98 RX(p1\u2081\u2084) 05f7bdee1f9745b88679570c6efa3f42--bcce1cda88fa4a19abffa8106430ab98 cf00386d66bb49f99d423d033fe51a31 RY(p1\u2081\u2088) bcce1cda88fa4a19abffa8106430ab98--cf00386d66bb49f99d423d033fe51a31 a1f111161a0e413592b08d3daac3aea5 RX(p1\u2082\u2082) cf00386d66bb49f99d423d033fe51a31--a1f111161a0e413592b08d3daac3aea5 10328d2cd3944bc795a3aa43cb43baec a1f111161a0e413592b08d3daac3aea5--10328d2cd3944bc795a3aa43cb43baec 72e2d199a86040c1ba66783178a88f01 X 10328d2cd3944bc795a3aa43cb43baec--72e2d199a86040c1ba66783178a88f01 72e2d199a86040c1ba66783178a88f01--818dd1e9bf4446169511a2d6c5d537b5 b58d0d9c7bcd49bb9619c6771d4869d6 RX(p2\u2082) 72e2d199a86040c1ba66783178a88f01--b58d0d9c7bcd49bb9619c6771d4869d6 960bcc87ccf045fd91d44134775f59dc RY(p2\u2086) b58d0d9c7bcd49bb9619c6771d4869d6--960bcc87ccf045fd91d44134775f59dc 8521d3f99b384a5b85b9b51ab39335e1 RX(p2\u2081\u2080) 960bcc87ccf045fd91d44134775f59dc--8521d3f99b384a5b85b9b51ab39335e1 ce5caf4492f74d78a35f4b948cc6c06c 8521d3f99b384a5b85b9b51ab39335e1--ce5caf4492f74d78a35f4b948cc6c06c 926b66f8ed9646a389e9d6afaa3f359a X ce5caf4492f74d78a35f4b948cc6c06c--926b66f8ed9646a389e9d6afaa3f359a 926b66f8ed9646a389e9d6afaa3f359a--4fd7d4bb8c3549c69b5ac40aa42579cf 2d83338c96ac4b5fad9afde06546282f RX(p2\u2081\u2084) 926b66f8ed9646a389e9d6afaa3f359a--2d83338c96ac4b5fad9afde06546282f 2a997929f83248f091fbfb0af58ee884 RY(p2\u2081\u2088) 2d83338c96ac4b5fad9afde06546282f--2a997929f83248f091fbfb0af58ee884 34ad3f568f3a4513929c1e717c1629d6 RX(p2\u2082\u2082) 2a997929f83248f091fbfb0af58ee884--34ad3f568f3a4513929c1e717c1629d6 111a2b68c61741709ab93f7e959afec6 34ad3f568f3a4513929c1e717c1629d6--111a2b68c61741709ab93f7e959afec6 d422c08844bf4bdc99cf320f5667e359 X 111a2b68c61741709ab93f7e959afec6--d422c08844bf4bdc99cf320f5667e359 d422c08844bf4bdc99cf320f5667e359--eb7aca270b3c44e695ae7982599faa1d d422c08844bf4bdc99cf320f5667e359--1c49ee8ea3f641b888dee22981c9072e c484b45799eb4f0c9b89c04c0eadaa47 ed9aa5c9b58c4744840bc6b7ec02b421 RX(p1\u2083) dc29528873cc442088e86d66a6285d84--ed9aa5c9b58c4744840bc6b7ec02b421 e2c3158893184d08b666d78c575809d2 RY(p1\u2087) ed9aa5c9b58c4744840bc6b7ec02b421--e2c3158893184d08b666d78c575809d2 399e562deb834803808b37c7a8825d85 RX(p1\u2081\u2081) e2c3158893184d08b666d78c575809d2--399e562deb834803808b37c7a8825d85 60a5c3f8e7c14c1d87dbfa8eb2507be1 X 399e562deb834803808b37c7a8825d85--60a5c3f8e7c14c1d87dbfa8eb2507be1 60a5c3f8e7c14c1d87dbfa8eb2507be1--2e265de3b16f4500b3c87cb4cc9133e5 5749b512d1dd44099563f67e6363b5d3 60a5c3f8e7c14c1d87dbfa8eb2507be1--5749b512d1dd44099563f67e6363b5d3 cc14f4007df64ba3b6d7103bdf75c9fd RX(p1\u2081\u2085) 5749b512d1dd44099563f67e6363b5d3--cc14f4007df64ba3b6d7103bdf75c9fd 7ebbb378a05545d3b711095ab33e5a84 RY(p1\u2081\u2089) cc14f4007df64ba3b6d7103bdf75c9fd--7ebbb378a05545d3b711095ab33e5a84 71277c19d18d40c5aa3fa25af92a1832 RX(p1\u2082\u2083) 7ebbb378a05545d3b711095ab33e5a84--71277c19d18d40c5aa3fa25af92a1832 e90a32d699dc42feae1bf3f86f98fdbc X 71277c19d18d40c5aa3fa25af92a1832--e90a32d699dc42feae1bf3f86f98fdbc e90a32d699dc42feae1bf3f86f98fdbc--10328d2cd3944bc795a3aa43cb43baec f532ec89619b4db6944f5fd3e70400a1 e90a32d699dc42feae1bf3f86f98fdbc--f532ec89619b4db6944f5fd3e70400a1 b35db25755e04cc4ab3d3083c978b549 RX(p2\u2083) f532ec89619b4db6944f5fd3e70400a1--b35db25755e04cc4ab3d3083c978b549 82edd62e5bd2481d9b309b21136038b9 RY(p2\u2087) b35db25755e04cc4ab3d3083c978b549--82edd62e5bd2481d9b309b21136038b9 18791387395c4e3f9b2c88c9827884c1 RX(p2\u2081\u2081) 82edd62e5bd2481d9b309b21136038b9--18791387395c4e3f9b2c88c9827884c1 0504c4dbdf6e4279a96571f75078be2a X 18791387395c4e3f9b2c88c9827884c1--0504c4dbdf6e4279a96571f75078be2a 0504c4dbdf6e4279a96571f75078be2a--ce5caf4492f74d78a35f4b948cc6c06c d3a9fe86f96d4e739eb1c8e6877814fe 0504c4dbdf6e4279a96571f75078be2a--d3a9fe86f96d4e739eb1c8e6877814fe 7b9cbd733a4148be9eb5e14e81cd0f70 RX(p2\u2081\u2085) d3a9fe86f96d4e739eb1c8e6877814fe--7b9cbd733a4148be9eb5e14e81cd0f70 d14b19d107e648dd9fddb19fb8fe016d RY(p2\u2081\u2089) 7b9cbd733a4148be9eb5e14e81cd0f70--d14b19d107e648dd9fddb19fb8fe016d 7caa20c3696d4eeda78c3c438283df9c RX(p2\u2082\u2083) d14b19d107e648dd9fddb19fb8fe016d--7caa20c3696d4eeda78c3c438283df9c 079f6a52dae04498a2bc166968bec704 X 7caa20c3696d4eeda78c3c438283df9c--079f6a52dae04498a2bc166968bec704 079f6a52dae04498a2bc166968bec704--111a2b68c61741709ab93f7e959afec6 5fa150467eb24422b3218ff662bdbccd 079f6a52dae04498a2bc166968bec704--5fa150467eb24422b3218ff662bdbccd 5fa150467eb24422b3218ff662bdbccd--c484b45799eb4f0c9b89c04c0eadaa47 </p> <p>The <code>hea</code> function will be further explored in the QML Constructors tutorial.</p>"},{"location":"tutorials/parameters/#parametric-observables","title":"Parametric observables","text":"<p>In Qadence, one can define quantum observables with classical optimizable parameters to improve the convergence of QML calculations. This is particularly useful for differentiable quantum circuits.</p> <pre><code>from qadence import VariationalParameter, Z, add, tag\ns = VariationalParameter(\"s\")\nobservable = add(s * Z(i) for i in range(n_qubits))\n</code></pre> <p>Now, a quantum model can be created with the parametric observable. The observable variational parameters are included among the model ones.</p> <pre><code>from qadence import QuantumModel, QuantumCircuit\ncircuit = QuantumCircuit(n_qubits, hea(n_qubits, depth))\nmodel = QuantumModel(circuit, observable=observable)\n</code></pre> <pre><code>Variational parameters = OrderedDict([('s', tensor([0.3775])), ('theta_0', tensor([0.4898])), ('theta_1', tensor([0.2495])), ('theta_10', tensor([0.7195])), ('theta_11', tensor([0.9956])), ('theta_12', tensor([0.9429])), ('theta_13', tensor([0.2319])), ('theta_14', tensor([0.9940])), ('theta_15', tensor([0.9964])), ('theta_16', tensor([0.6051])), ('theta_17', tensor([0.7252])), ('theta_18', tensor([0.3309])), ('theta_19', tensor([0.5177])), ('theta_2', tensor([0.2404])), ('theta_20', tensor([0.1400])), ('theta_21', tensor([0.8528])), ('theta_22', tensor([0.3188])), ('theta_23', tensor([0.2410])), ('theta_3', tensor([0.8505])), ('theta_4', tensor([0.2859])), ('theta_5', tensor([0.2913])), ('theta_6', tensor([0.4297])), ('theta_7', tensor([0.0077])), ('theta_8', tensor([0.4412])), ('theta_9', tensor([0.8012]))])\n</code></pre> <p>One optimization step (forward and backward pass) can be performed using built-in <code>torch</code> functionalities. Variational parameters can be checked to have been updated accordingly:</p> <pre><code>import torch\nmse_loss = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters())\n# Compute forward &amp; backward pass\noptimizer.zero_grad()\nloss = mse_loss(model.expectation({}), torch.zeros(1))\nloss.backward()\n# Update the parameters and check the parameters.\noptimizer.step()\n</code></pre> <pre><code>Variational parameters = OrderedDict([('s', tensor([0.3765])), ('theta_0', tensor([0.4908])), ('theta_1', tensor([0.2485])), ('theta_10', tensor([0.7205])), ('theta_11', tensor([0.9966])), ('theta_12', tensor([0.9439])), ('theta_13', tensor([0.2329])), ('theta_14', tensor([0.9930])), ('theta_15', tensor([0.9974])), ('theta_16', tensor([0.6061])), ('theta_17', tensor([0.7262])), ('theta_18', tensor([0.3319])), ('theta_19', tensor([0.5167])), ('theta_2', tensor([0.2414])), ('theta_20', tensor([0.1410])), ('theta_21', tensor([0.8538])), ('theta_22', tensor([0.3178])), ('theta_23', tensor([0.2420])), ('theta_3', tensor([0.8515])), ('theta_4', tensor([0.2869])), ('theta_5', tensor([0.2923])), ('theta_6', tensor([0.4307])), ('theta_7', tensor([0.0067])), ('theta_8', tensor([0.4422])), ('theta_9', tensor([0.8002]))])\n</code></pre>"},{"location":"tutorials/parameters/#non-unitary-circuits","title":"Non-unitary circuits","text":"<p>Qadence allows to compose with non-unitary blocks. Here is an example of a non-unitary block as a sum of Pauli operators with complex coefficients.</p> <p>Currently, only the <code>PyQTorch</code> backend fully supports execution with non-unitary circuits.</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, Z, X\nc1 = 2.0\nc2 = 2.0 + 2.0j\nblock = c1 * Z(0) + c2 * X(1) + c1 * c2 * (Z(2) + X(3))\ncircuit = QuantumCircuit(4, block)\nmodel = QuantumModel(circuit)  # BackendName.PYQTORCH and DiffMode.AD by default.\n</code></pre> <pre><code>wf = tensor([[6.+4.j, 4.+4.j, 0.+0.j, 0.+0.j, 2.+2.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre>"},{"location":"tutorials/qml_tools/","title":"Quantum Machine Learning Constructors","text":"<p>Besides the arbitrary Hamiltonian constructors, Qadence also provides a complete set of program constructors useful for digital-analog quantum machine learning programs.</p>"},{"location":"tutorials/qml_tools/#feature-maps","title":"Feature Maps","text":"<p>A few feature maps are directly available for feature loading,</p> <pre><code>from qadence import feature_map\nn_qubits = 3\nfm = feature_map(n_qubits, fm_type=\"fourier\")\nfm = feature_map(n_qubits, fm_type=\"chebyshev\")\nfm = feature_map(n_qubits, fm_type=\"tower\")\n</code></pre> <pre><code>Fourier = KronBlock(0,1,2) [tag: FM]\n\u251c\u2500\u2500 RX(0) [params: ['phi']]\n\u251c\u2500\u2500 RX(1) [params: ['phi']]\n\u2514\u2500\u2500 RX(2) [params: ['phi']]\nChebyshev KronBlock(0,1,2) [tag: FM]\n\u251c\u2500\u2500 RX(0) [params: ['2*acos(phi)']]\n\u251c\u2500\u2500 RX(1) [params: ['2*acos(phi)']]\n\u2514\u2500\u2500 RX(2) [params: ['2*acos(phi)']]\nTower KronBlock(0,1,2) [tag: FM]\n\u251c\u2500\u2500 RX(0) [params: ['2*acos(phi)']]\n\u251c\u2500\u2500 RX(1) [params: ['4*acos(phi)']]\n\u2514\u2500\u2500 RX(2) [params: ['6*acos(phi)']]\n</code></pre>"},{"location":"tutorials/qml_tools/#hardware-efficient-ansatz","title":"Hardware-Efficient Ansatz","text":"<p>Ansatze blocks for quantum machine-learning are typically built following the Hardware-Efficient Ansatz formalism (HEA). Both fully digital and digital-analog HEAs can easily be built with the <code>hea</code> function. By default, the digital version is returned:</p> <pre><code>from qadence import hea\nfrom qadence.draw import display\nn_qubits = 3\ndepth = 2\nansatz = hea(n_qubits, depth)\n</code></pre> %3 11f0663d19b6471c9fb77d5d84fb4471 0 98441540942d4319a93462736c537233 RX(theta\u2080) 11f0663d19b6471c9fb77d5d84fb4471--98441540942d4319a93462736c537233 3c183c56aeb34c98b8217475cb7a73ff 1 f59aec44209b44018d2c92eb031e63c6 RY(theta\u2083) 98441540942d4319a93462736c537233--f59aec44209b44018d2c92eb031e63c6 6abcb1c2d9844dfca62dfba4de1809e4 RX(theta\u2086) f59aec44209b44018d2c92eb031e63c6--6abcb1c2d9844dfca62dfba4de1809e4 3dc65f416c144f328fb9c0a5d8b4d698 6abcb1c2d9844dfca62dfba4de1809e4--3dc65f416c144f328fb9c0a5d8b4d698 3e6f507c28444b1ca4f5202c4a30d607 3dc65f416c144f328fb9c0a5d8b4d698--3e6f507c28444b1ca4f5202c4a30d607 5328dc434bb4469091871e4009bed4d3 RX(theta\u2089) 3e6f507c28444b1ca4f5202c4a30d607--5328dc434bb4469091871e4009bed4d3 32f87769899842bc893be1b2d7848acb RY(theta\u2081\u2082) 5328dc434bb4469091871e4009bed4d3--32f87769899842bc893be1b2d7848acb f417fde3c30841a7842519e2379ac207 RX(theta\u2081\u2085) 32f87769899842bc893be1b2d7848acb--f417fde3c30841a7842519e2379ac207 a0aa51e274b848719cb8174f22f059bc f417fde3c30841a7842519e2379ac207--a0aa51e274b848719cb8174f22f059bc 9e5ba65ea935431c88e8746c10c72890 a0aa51e274b848719cb8174f22f059bc--9e5ba65ea935431c88e8746c10c72890 5dfa9202258f4a839a37ff4004f5a5d8 9e5ba65ea935431c88e8746c10c72890--5dfa9202258f4a839a37ff4004f5a5d8 06fbd84c85554665a62c73a4072f2e1e 50d7b183143b4d8c9a7f8a8e3bc8baea RX(theta\u2081) 3c183c56aeb34c98b8217475cb7a73ff--50d7b183143b4d8c9a7f8a8e3bc8baea 8e45e357116b4fbdb0cc3295c37c429f 2 25b340d31dc64ff09f70fd47675890e5 RY(theta\u2084) 50d7b183143b4d8c9a7f8a8e3bc8baea--25b340d31dc64ff09f70fd47675890e5 3f3438b4e5c446bdb08810820e035c68 RX(theta\u2087) 25b340d31dc64ff09f70fd47675890e5--3f3438b4e5c446bdb08810820e035c68 95e0aaadb01943e5b5aa842fdfe7d3ae X 3f3438b4e5c446bdb08810820e035c68--95e0aaadb01943e5b5aa842fdfe7d3ae 95e0aaadb01943e5b5aa842fdfe7d3ae--3dc65f416c144f328fb9c0a5d8b4d698 71ecfc1355294367bfe2e5f7ad04d154 95e0aaadb01943e5b5aa842fdfe7d3ae--71ecfc1355294367bfe2e5f7ad04d154 159bfbe5d56346f886b27d3f660d4199 RX(theta\u2081\u2080) 71ecfc1355294367bfe2e5f7ad04d154--159bfbe5d56346f886b27d3f660d4199 4124e4f59c3f4f42a1443a9d959db814 RY(theta\u2081\u2083) 159bfbe5d56346f886b27d3f660d4199--4124e4f59c3f4f42a1443a9d959db814 2decf678f3bf47a8a7f76823c78ce9e4 RX(theta\u2081\u2086) 4124e4f59c3f4f42a1443a9d959db814--2decf678f3bf47a8a7f76823c78ce9e4 6922d5d00f3f4955952c76d4329532f5 X 2decf678f3bf47a8a7f76823c78ce9e4--6922d5d00f3f4955952c76d4329532f5 6922d5d00f3f4955952c76d4329532f5--a0aa51e274b848719cb8174f22f059bc 167e5af1572b44e2ac3cd1d8b2b720d8 6922d5d00f3f4955952c76d4329532f5--167e5af1572b44e2ac3cd1d8b2b720d8 167e5af1572b44e2ac3cd1d8b2b720d8--06fbd84c85554665a62c73a4072f2e1e ae918bfb099346e5a13a42871536efc1 707410e69fb446389679c0d677bbba70 RX(theta\u2082) 8e45e357116b4fbdb0cc3295c37c429f--707410e69fb446389679c0d677bbba70 ce5ba182da584ec3be3bf5e60df05b1e RY(theta\u2085) 707410e69fb446389679c0d677bbba70--ce5ba182da584ec3be3bf5e60df05b1e 34293be03d424401918cd71681e4ce5c RX(theta\u2088) ce5ba182da584ec3be3bf5e60df05b1e--34293be03d424401918cd71681e4ce5c 4e898d7b7fee428b8a10c605988c3e15 34293be03d424401918cd71681e4ce5c--4e898d7b7fee428b8a10c605988c3e15 d66200b665af4c84820aca4950633688 X 4e898d7b7fee428b8a10c605988c3e15--d66200b665af4c84820aca4950633688 d66200b665af4c84820aca4950633688--71ecfc1355294367bfe2e5f7ad04d154 acbbe78f6f034d9e91514f67bf323caf RX(theta\u2081\u2081) d66200b665af4c84820aca4950633688--acbbe78f6f034d9e91514f67bf323caf bc64c4c79e3245ebaebd1be34909dd87 RY(theta\u2081\u2084) acbbe78f6f034d9e91514f67bf323caf--bc64c4c79e3245ebaebd1be34909dd87 09f6cce9bcea43dfb191e17f7a7d8067 RX(theta\u2081\u2087) bc64c4c79e3245ebaebd1be34909dd87--09f6cce9bcea43dfb191e17f7a7d8067 0464fb6b3d5849f394d34bb3fcf9c733 09f6cce9bcea43dfb191e17f7a7d8067--0464fb6b3d5849f394d34bb3fcf9c733 12447a5eadc64736a718545612568fb0 X 0464fb6b3d5849f394d34bb3fcf9c733--12447a5eadc64736a718545612568fb0 12447a5eadc64736a718545612568fb0--167e5af1572b44e2ac3cd1d8b2b720d8 12447a5eadc64736a718545612568fb0--ae918bfb099346e5a13a42871536efc1 <p>As seen above, the rotation layers are automatically parameterized, and the prefix <code>\"theta\"</code> can be changed with the <code>param_prefix</code> argument.</p> <p>Furthermore, both the single-qubit rotations and the two-qubit entangler can be customized with the <code>operations</code> and <code>entangler</code> argument. The operations can be passed as a list of single-qubit rotations, while the entangler should be either <code>CNOT</code>, <code>CZ</code>, <code>CRX</code>, <code>CRY</code>, <code>CRZ</code> or <code>CPHASE</code>.</p> <pre><code>from qadence import RX, RY, CPHASE\nansatz = hea(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=\"phi\",\noperations=[RX, RY, RX],\nentangler=CPHASE\n)\n</code></pre> %3 85162bbc45584a56bbe50378b758dfc9 0 d2f5129c2d1e4d2a83f1d166cc94c122 RX(phi\u2080) 85162bbc45584a56bbe50378b758dfc9--d2f5129c2d1e4d2a83f1d166cc94c122 8e3724f8e9d144b8b1759c5585fa2320 1 94d51bbff1694241ad5ba1f6d056a22c RY(phi\u2083) d2f5129c2d1e4d2a83f1d166cc94c122--94d51bbff1694241ad5ba1f6d056a22c 452bcf99eb984065b6f05490d09c3f63 RX(phi\u2086) 94d51bbff1694241ad5ba1f6d056a22c--452bcf99eb984065b6f05490d09c3f63 a659be2eb0fa42c7a5e30403cced4283 452bcf99eb984065b6f05490d09c3f63--a659be2eb0fa42c7a5e30403cced4283 189a88f7cb94468b900ed67dd58ca5f0 a659be2eb0fa42c7a5e30403cced4283--189a88f7cb94468b900ed67dd58ca5f0 0d29ca6da1d54baab5faa949eff11d7e RX(phi\u2089) 189a88f7cb94468b900ed67dd58ca5f0--0d29ca6da1d54baab5faa949eff11d7e 867fa1fe36bf4e8ba89d1ae888810ad6 RY(phi\u2081\u2082) 0d29ca6da1d54baab5faa949eff11d7e--867fa1fe36bf4e8ba89d1ae888810ad6 c92f292ca3f64a6a859d48856c84f73b RX(phi\u2081\u2085) 867fa1fe36bf4e8ba89d1ae888810ad6--c92f292ca3f64a6a859d48856c84f73b e2b735a48c3f43c9aaeebf168ac4c9c4 c92f292ca3f64a6a859d48856c84f73b--e2b735a48c3f43c9aaeebf168ac4c9c4 0ae0df5af4b9453fbd0333e5829f9f55 e2b735a48c3f43c9aaeebf168ac4c9c4--0ae0df5af4b9453fbd0333e5829f9f55 78238345188f4097b73aa90e5da480a3 0ae0df5af4b9453fbd0333e5829f9f55--78238345188f4097b73aa90e5da480a3 f81d45e45da742e98abc21c2d6b3daa1 3197580b870d44cb846e8ff73d6ad73f RX(phi\u2081) 8e3724f8e9d144b8b1759c5585fa2320--3197580b870d44cb846e8ff73d6ad73f 6f460e832e5c4d85a52b5ff04c9c368a 2 bd72b29a49de4683bcd45eb8b4cb192d RY(phi\u2084) 3197580b870d44cb846e8ff73d6ad73f--bd72b29a49de4683bcd45eb8b4cb192d 694402cc6cd94ee08f75674d5af0c6fd RX(phi\u2087) bd72b29a49de4683bcd45eb8b4cb192d--694402cc6cd94ee08f75674d5af0c6fd 3fb3e72c8f614d2ca7461661eb8be639 PHASE(phi_ent\u2080) 694402cc6cd94ee08f75674d5af0c6fd--3fb3e72c8f614d2ca7461661eb8be639 3fb3e72c8f614d2ca7461661eb8be639--a659be2eb0fa42c7a5e30403cced4283 cef166efe55347ed9b578537161deb3b 3fb3e72c8f614d2ca7461661eb8be639--cef166efe55347ed9b578537161deb3b 12da0cd420a54f4e8ade93ef9f3db98a RX(phi\u2081\u2080) cef166efe55347ed9b578537161deb3b--12da0cd420a54f4e8ade93ef9f3db98a 186de9dcb7984aeea518bcc6817e9f2f RY(phi\u2081\u2083) 12da0cd420a54f4e8ade93ef9f3db98a--186de9dcb7984aeea518bcc6817e9f2f 2b406562873b434ca050d3a98fb039e1 RX(phi\u2081\u2086) 186de9dcb7984aeea518bcc6817e9f2f--2b406562873b434ca050d3a98fb039e1 2f3890894de84a54aabc236166749469 PHASE(phi_ent\u2082) 2b406562873b434ca050d3a98fb039e1--2f3890894de84a54aabc236166749469 2f3890894de84a54aabc236166749469--e2b735a48c3f43c9aaeebf168ac4c9c4 7fc64e27a2044e909819f6e77255ccfd 2f3890894de84a54aabc236166749469--7fc64e27a2044e909819f6e77255ccfd 7fc64e27a2044e909819f6e77255ccfd--f81d45e45da742e98abc21c2d6b3daa1 6c85f86fddb6453c88a450d42d817cb9 03685e933968479fb1d07461e09a14f4 RX(phi\u2082) 6f460e832e5c4d85a52b5ff04c9c368a--03685e933968479fb1d07461e09a14f4 40dd0569982446948ab741d8aa47c058 RY(phi\u2085) 03685e933968479fb1d07461e09a14f4--40dd0569982446948ab741d8aa47c058 755fda1715154917ab68f72af96c1fad RX(phi\u2088) 40dd0569982446948ab741d8aa47c058--755fda1715154917ab68f72af96c1fad b8a39805d2fe4b2ca9a3a209298a3081 755fda1715154917ab68f72af96c1fad--b8a39805d2fe4b2ca9a3a209298a3081 c738260b190840d0a2f11fc11779c055 PHASE(phi_ent\u2081) b8a39805d2fe4b2ca9a3a209298a3081--c738260b190840d0a2f11fc11779c055 c738260b190840d0a2f11fc11779c055--cef166efe55347ed9b578537161deb3b 0cf3ff3b7dc04486803172f1ff5a8155 RX(phi\u2081\u2081) c738260b190840d0a2f11fc11779c055--0cf3ff3b7dc04486803172f1ff5a8155 df4fe6aead0c40e89446f2b044cc7e88 RY(phi\u2081\u2084) 0cf3ff3b7dc04486803172f1ff5a8155--df4fe6aead0c40e89446f2b044cc7e88 a65a97869bb642ed91955561c19d9323 RX(phi\u2081\u2087) df4fe6aead0c40e89446f2b044cc7e88--a65a97869bb642ed91955561c19d9323 c82b2115f78042088b92169b1f3258dc a65a97869bb642ed91955561c19d9323--c82b2115f78042088b92169b1f3258dc ce6b70ced9c34774b2f7d0868a93bb6a PHASE(phi_ent\u2083) c82b2115f78042088b92169b1f3258dc--ce6b70ced9c34774b2f7d0868a93bb6a ce6b70ced9c34774b2f7d0868a93bb6a--7fc64e27a2044e909819f6e77255ccfd ce6b70ced9c34774b2f7d0868a93bb6a--6c85f86fddb6453c88a450d42d817cb9 <p>Having a truly hardware-efficient ansatz means that the entangling operation can be chosen according to each device's native interactions. Besides digital operations, in Qadence it is also possible to build digital-analog HEAs with the entanglement produced by the natural evolution of a set of interacting qubits, as is natural in neutral atom devices. As with other digital-analog functions, this can be controlled with the <code>strategy</code> argument which can be chosen from the <code>Strategy</code> enum type. Currently, only <code>Strategy.DIGITAL</code> and <code>Strategy.SDAQC</code> are available. By default, calling <code>strategy = Strategy.SDAQC</code> will use a global entangling Hamiltonian with Ising-like NN interactions and constant interaction strength inside a <code>HamEvo</code> operation,</p> <pre><code>from qadence import Strategy\nansatz = hea(\nn_qubits,\ndepth=depth,\nstrategy=Strategy.SDAQC\n)\n</code></pre> %3 cluster_19edd8da2df0494d951b1198b26070fa cluster_2808bcf21f9f45848bb53bb09c1050fd 8d2dbed2d4c44f56888ab631d87392de 0 bd65751c8ca44b55b74522eee8b65409 RX(theta\u2080) 8d2dbed2d4c44f56888ab631d87392de--bd65751c8ca44b55b74522eee8b65409 4bcae4867caf4af2b14f24d59d552935 1 79fbfc96e0e042cf8479562f5a0df741 RY(theta\u2083) bd65751c8ca44b55b74522eee8b65409--79fbfc96e0e042cf8479562f5a0df741 9f03819d1c7f493eab58a88c919ba8bb RX(theta\u2086) 79fbfc96e0e042cf8479562f5a0df741--9f03819d1c7f493eab58a88c919ba8bb 8f1ae458556641e5b7d1dfe8ad5d5967 HamEvo 9f03819d1c7f493eab58a88c919ba8bb--8f1ae458556641e5b7d1dfe8ad5d5967 07997c067ffb44f194c6b4f2b0ba0714 RX(theta\u2089) 8f1ae458556641e5b7d1dfe8ad5d5967--07997c067ffb44f194c6b4f2b0ba0714 f347f7739a8b4590a88fa9272da9a84a RY(theta\u2081\u2082) 07997c067ffb44f194c6b4f2b0ba0714--f347f7739a8b4590a88fa9272da9a84a bc955ff1cb5241499c666865e29d6d11 RX(theta\u2081\u2085) f347f7739a8b4590a88fa9272da9a84a--bc955ff1cb5241499c666865e29d6d11 831e72e443a34bfaa8d8f9a9715a676b HamEvo bc955ff1cb5241499c666865e29d6d11--831e72e443a34bfaa8d8f9a9715a676b badc14d969f04829846332816e761b67 831e72e443a34bfaa8d8f9a9715a676b--badc14d969f04829846332816e761b67 9bf5a4df9a8c4840bcb04b2940d15320 e246ff143fd64146839bc35698f00d93 RX(theta\u2081) 4bcae4867caf4af2b14f24d59d552935--e246ff143fd64146839bc35698f00d93 cc91a1167d1e49658be970508b13e7eb 2 e94350db19c742ed89fc0f76ecb7bee0 RY(theta\u2084) e246ff143fd64146839bc35698f00d93--e94350db19c742ed89fc0f76ecb7bee0 534c4d4e3fe141f99ca226bb17bdbfdd RX(theta\u2087) e94350db19c742ed89fc0f76ecb7bee0--534c4d4e3fe141f99ca226bb17bdbfdd 48cfc8abde5c4b8ca9af1044aa9a99b6 t = theta_t\u2080 534c4d4e3fe141f99ca226bb17bdbfdd--48cfc8abde5c4b8ca9af1044aa9a99b6 22b85c90ace7483691c6af7e24db5925 RX(theta\u2081\u2080) 48cfc8abde5c4b8ca9af1044aa9a99b6--22b85c90ace7483691c6af7e24db5925 8a4989c5a053474a8b4a017d1c398644 RY(theta\u2081\u2083) 22b85c90ace7483691c6af7e24db5925--8a4989c5a053474a8b4a017d1c398644 027aa78166b849c897625fa95965533a RX(theta\u2081\u2086) 8a4989c5a053474a8b4a017d1c398644--027aa78166b849c897625fa95965533a 877c63505d74465a911e0f05239c80cc t = theta_t\u2081 027aa78166b849c897625fa95965533a--877c63505d74465a911e0f05239c80cc 877c63505d74465a911e0f05239c80cc--9bf5a4df9a8c4840bcb04b2940d15320 ee7ed2807d6348e385ad88b603fa8dce f04c6da8ab0a4bf6bd299794626e4082 RX(theta\u2082) cc91a1167d1e49658be970508b13e7eb--f04c6da8ab0a4bf6bd299794626e4082 9b17b258029a44e492c279aef3577b6f RY(theta\u2085) f04c6da8ab0a4bf6bd299794626e4082--9b17b258029a44e492c279aef3577b6f 311d6031fbad465e9026424d23fb8cbe RX(theta\u2088) 9b17b258029a44e492c279aef3577b6f--311d6031fbad465e9026424d23fb8cbe 12c761b2e5f94a2bb97faa1583de2e05 311d6031fbad465e9026424d23fb8cbe--12c761b2e5f94a2bb97faa1583de2e05 c9ac03cb9339422ca7f3147a2585b591 RX(theta\u2081\u2081) 12c761b2e5f94a2bb97faa1583de2e05--c9ac03cb9339422ca7f3147a2585b591 1d66b33453874873b5349cba24087569 RY(theta\u2081\u2084) c9ac03cb9339422ca7f3147a2585b591--1d66b33453874873b5349cba24087569 2179f44618884138bafddffbe505a234 RX(theta\u2081\u2087) 1d66b33453874873b5349cba24087569--2179f44618884138bafddffbe505a234 d1fa1f7184404a9397cea25128e4f0ef 2179f44618884138bafddffbe505a234--d1fa1f7184404a9397cea25128e4f0ef d1fa1f7184404a9397cea25128e4f0ef--ee7ed2807d6348e385ad88b603fa8dce <p>Note that, by default, only the time-parameter is automatically parameterized when building a digital-analog HEA. However, as described in the Hamiltonians tutorial, arbitrary interaction Hamiltonians can be easily built with the <code>hamiltonian_factory</code> function, with both customized or fully parameterized interactions, and these can be directly passed as the <code>entangler</code> for a customizable digital-analog HEA.</p> <p><pre><code>from qadence import hamiltonian_factory, Interaction, N, Register, hea\n# Build a parameterized neutral-atom Hamiltonian following a honeycomb_lattice:\nregister = Register.honeycomb_lattice(1, 1)\nentangler = hamiltonian_factory(\nregister,\ninteraction=Interaction.NN,\ndetuning=N,\ninteraction_strength=\"e\",\ndetuning_strength=\"n\"\n)\n# Build a fully parameterized Digital-Analog HEA:\nn_qubits = register.n_qubits\ndepth = 2\nansatz = hea(\nn_qubits=register.n_qubits,\ndepth=depth,\noperations=[RX, RY, RX],\nentangler=entangler,\nstrategy=Strategy.SDAQC\n)\n</code></pre> %3 cluster_61425953959b447cb7c3145974dd2fe4 cluster_ad806daa582347719ba44cf1228bd289 d4b973bb6a404d10b01d213037a1af36 0 fb194e6d108a4ad4a90d7ff42ced7cf2 RX(theta\u2080) d4b973bb6a404d10b01d213037a1af36--fb194e6d108a4ad4a90d7ff42ced7cf2 b28a21886c3c4dcdbbe3e0ad169d38db 1 844b75817c664809b470ad1c5218949d RY(theta\u2086) fb194e6d108a4ad4a90d7ff42ced7cf2--844b75817c664809b470ad1c5218949d b2127ce4ce5045098ef0d9b7ba83cf53 RX(theta\u2081\u2082) 844b75817c664809b470ad1c5218949d--b2127ce4ce5045098ef0d9b7ba83cf53 2d58dbfc67264a6e86729c0f92d651ba b2127ce4ce5045098ef0d9b7ba83cf53--2d58dbfc67264a6e86729c0f92d651ba 25e0c0bade54442e9316fac9d97db709 RX(theta\u2081\u2088) 2d58dbfc67264a6e86729c0f92d651ba--25e0c0bade54442e9316fac9d97db709 1f72b72853154a579d6bf8a5b50d140a RY(theta\u2082\u2084) 25e0c0bade54442e9316fac9d97db709--1f72b72853154a579d6bf8a5b50d140a 822cc376f9164244838fc82e0866db34 RX(theta\u2083\u2080) 1f72b72853154a579d6bf8a5b50d140a--822cc376f9164244838fc82e0866db34 8b85e7aaa4404beaba162742e5821871 822cc376f9164244838fc82e0866db34--8b85e7aaa4404beaba162742e5821871 cc90a34317bb412ba2c9162978a296c1 8b85e7aaa4404beaba162742e5821871--cc90a34317bb412ba2c9162978a296c1 271b5517893d447cba34ff4e5e08f60a 420f1cf5a2ce41d089b708fece50eeed RX(theta\u2081) b28a21886c3c4dcdbbe3e0ad169d38db--420f1cf5a2ce41d089b708fece50eeed 992bf3b0cbee4e868904475eb92f567c 2 37f3b135fd0c4f13a3de3ed8bf7de78a RY(theta\u2087) 420f1cf5a2ce41d089b708fece50eeed--37f3b135fd0c4f13a3de3ed8bf7de78a d46a60c2e2814335a02c6ecedaf1ad6e RX(theta\u2081\u2083) 37f3b135fd0c4f13a3de3ed8bf7de78a--d46a60c2e2814335a02c6ecedaf1ad6e 0a695a09dd2146319912d11872ebad9d d46a60c2e2814335a02c6ecedaf1ad6e--0a695a09dd2146319912d11872ebad9d 9354ad22f0c64e369d6d571610e571e1 RX(theta\u2081\u2089) 0a695a09dd2146319912d11872ebad9d--9354ad22f0c64e369d6d571610e571e1 318a1b6fb0ab46fea7c25b00c7c37146 RY(theta\u2082\u2085) 9354ad22f0c64e369d6d571610e571e1--318a1b6fb0ab46fea7c25b00c7c37146 0043538e9c9c485391f80b7e04fd457e RX(theta\u2083\u2081) 318a1b6fb0ab46fea7c25b00c7c37146--0043538e9c9c485391f80b7e04fd457e 48e4ded5652746bbb2f55df70c29e875 0043538e9c9c485391f80b7e04fd457e--48e4ded5652746bbb2f55df70c29e875 48e4ded5652746bbb2f55df70c29e875--271b5517893d447cba34ff4e5e08f60a 5c0fe756360e41189d010a5496379f3b 5c2a6f6df89744c682b29bb663fcf17b RX(theta\u2082) 992bf3b0cbee4e868904475eb92f567c--5c2a6f6df89744c682b29bb663fcf17b e1006349c1b441de9c5ee02716e07568 3 d22460c236e9456ca05eb37da0d6f81e RY(theta\u2088) 5c2a6f6df89744c682b29bb663fcf17b--d22460c236e9456ca05eb37da0d6f81e b219d33d438a4ff88da52b6471613414 RX(theta\u2081\u2084) d22460c236e9456ca05eb37da0d6f81e--b219d33d438a4ff88da52b6471613414 9023343a34564235b30044775ad1e03f HamEvo b219d33d438a4ff88da52b6471613414--9023343a34564235b30044775ad1e03f 979af5292c1646bc98a23cd05194305b RX(theta\u2082\u2080) 9023343a34564235b30044775ad1e03f--979af5292c1646bc98a23cd05194305b 111441a9356443f6a1f1803cf61395da RY(theta\u2082\u2086) 979af5292c1646bc98a23cd05194305b--111441a9356443f6a1f1803cf61395da 0c75b6a7b5704a879a801ebb81e1b09c RX(theta\u2083\u2082) 111441a9356443f6a1f1803cf61395da--0c75b6a7b5704a879a801ebb81e1b09c b33d8cb360aa4093b92acd73b9629493 HamEvo 0c75b6a7b5704a879a801ebb81e1b09c--b33d8cb360aa4093b92acd73b9629493 b33d8cb360aa4093b92acd73b9629493--5c0fe756360e41189d010a5496379f3b 585fbfbacaf14cbbb0a49e560a7b0383 e4b3737b00f64fafa34354285717f4bd RX(theta\u2083) e1006349c1b441de9c5ee02716e07568--e4b3737b00f64fafa34354285717f4bd 9becc7533f02436fb406f5b8aa8e6a7a 4 57761921522f4be19cd5569687b22311 RY(theta\u2089) e4b3737b00f64fafa34354285717f4bd--57761921522f4be19cd5569687b22311 d09480580a484e53b0009da608f6df4c RX(theta\u2081\u2085) 57761921522f4be19cd5569687b22311--d09480580a484e53b0009da608f6df4c 9c4f6dcb0c064b99b74e524769c0e183 t = theta_t\u2080 d09480580a484e53b0009da608f6df4c--9c4f6dcb0c064b99b74e524769c0e183 251485eb4f33421d960c2da10ad1fcd3 RX(theta\u2082\u2081) 9c4f6dcb0c064b99b74e524769c0e183--251485eb4f33421d960c2da10ad1fcd3 9c015523296f4214b00bb156d85f5a47 RY(theta\u2082\u2087) 251485eb4f33421d960c2da10ad1fcd3--9c015523296f4214b00bb156d85f5a47 dddde1a5671549ce9487dbfcf7ccbb7e RX(theta\u2083\u2083) 9c015523296f4214b00bb156d85f5a47--dddde1a5671549ce9487dbfcf7ccbb7e 25c8cae953494f228849fd36e6e4c62d t = theta_t\u2081 dddde1a5671549ce9487dbfcf7ccbb7e--25c8cae953494f228849fd36e6e4c62d 25c8cae953494f228849fd36e6e4c62d--585fbfbacaf14cbbb0a49e560a7b0383 a151ac2342614addaafc726dbb7024f6 61620cced5b34c2185e13b0e9656c4e9 RX(theta\u2084) 9becc7533f02436fb406f5b8aa8e6a7a--61620cced5b34c2185e13b0e9656c4e9 be825d22604d4ccfb9e2bcc0e1923f6e 5 93a05487ab424e52a08cc58275a35881 RY(theta\u2081\u2080) 61620cced5b34c2185e13b0e9656c4e9--93a05487ab424e52a08cc58275a35881 fda6dcac659046e3922887485bf9a3e3 RX(theta\u2081\u2086) 93a05487ab424e52a08cc58275a35881--fda6dcac659046e3922887485bf9a3e3 b17de94f215e480d849c4ec356b3b3d8 fda6dcac659046e3922887485bf9a3e3--b17de94f215e480d849c4ec356b3b3d8 cc7e9f3ebcab4395bc79fc26d83bcbe8 RX(theta\u2082\u2082) b17de94f215e480d849c4ec356b3b3d8--cc7e9f3ebcab4395bc79fc26d83bcbe8 9f1307ea8b43481fad67b83cdb48e90b RY(theta\u2082\u2088) cc7e9f3ebcab4395bc79fc26d83bcbe8--9f1307ea8b43481fad67b83cdb48e90b 2582cf18b06f4ad58b15262f6f103d53 RX(theta\u2083\u2084) 9f1307ea8b43481fad67b83cdb48e90b--2582cf18b06f4ad58b15262f6f103d53 a96877724c9749a294f96345b986b53c 2582cf18b06f4ad58b15262f6f103d53--a96877724c9749a294f96345b986b53c a96877724c9749a294f96345b986b53c--a151ac2342614addaafc726dbb7024f6 0538a5ac3e1c4a6c866691d88b2d312e 1bd0939339a44516936d361680469544 RX(theta\u2085) be825d22604d4ccfb9e2bcc0e1923f6e--1bd0939339a44516936d361680469544 3121bfd5e2f74d45a8326e8d698664a3 RY(theta\u2081\u2081) 1bd0939339a44516936d361680469544--3121bfd5e2f74d45a8326e8d698664a3 8690b391f56e4838a65ec8a9d8ecfc51 RX(theta\u2081\u2087) 3121bfd5e2f74d45a8326e8d698664a3--8690b391f56e4838a65ec8a9d8ecfc51 6b8d45b637cb4a0e842561a8b847635e 8690b391f56e4838a65ec8a9d8ecfc51--6b8d45b637cb4a0e842561a8b847635e 218632e25e7f4dfc9f6eae37614d23c0 RX(theta\u2082\u2083) 6b8d45b637cb4a0e842561a8b847635e--218632e25e7f4dfc9f6eae37614d23c0 fc6bae226607473b9c7b7d0f5eb24ed9 RY(theta\u2082\u2089) 218632e25e7f4dfc9f6eae37614d23c0--fc6bae226607473b9c7b7d0f5eb24ed9 687d5353b0324cd5b260acf7c6ef1d0c RX(theta\u2083\u2085) fc6bae226607473b9c7b7d0f5eb24ed9--687d5353b0324cd5b260acf7c6ef1d0c 30db378315724cfbaf6ed35d7e5e023e 687d5353b0324cd5b260acf7c6ef1d0c--30db378315724cfbaf6ed35d7e5e023e 30db378315724cfbaf6ed35d7e5e023e--0538a5ac3e1c4a6c866691d88b2d312e  Qadence also offers a out-of-the-box training routine called <code>train_with_grad</code> for optimizing fully-differentiable models like <code>QNN</code>s and <code>QuantumModel</code>s containing either trainable and/or non-trainable parameters (i.e., inputs). Feel free to refresh your memory about different parameter types.</p>"},{"location":"tutorials/qml_tools/#machine-learning-tools","title":"Machine Learning Tools","text":"<p><code>train_with_grad</code> performs training, logging/printing loss metrics and storing intermediate checkpoints of models.</p> <p>As every other training routine commonly used in Machine Learning, it requires <code>model</code>, <code>data</code> and an <code>optimizer</code> as input arguments. However, in addition, it requires a <code>loss_fn</code> and a <code>TrainConfig</code>. A <code>loss_fn</code> is required to be a function which expects both a model and data and returns a tuple of (loss, metrics: <code>&lt;dict&gt;</code>), where <code>metrics</code> is a dict of scalars which can be customized too.</p> <pre><code>import torch\nfrom itertools import count\ncnt = count()\ncriterion = torch.nn.MSELoss()\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\nnext(cnt)\nx, y = data[0], data[1]\nout = model(x)\nloss = criterion(out, y)\nreturn loss, {}\n</code></pre> <pre><code>\n</code></pre> <p>The <code>TrainConfig</code> [qadence.ml_tools.config] tells <code>train_with_grad</code> what batch_size should be used, how many epochs to train, in which intervals to print/log metrics and how often to store intermediate checkpoints.</p> <pre><code>from qadence.ml_tools import TrainConfig\nbatch_size = 5\nn_epochs = 100\nconfig = TrainConfig(\nfolder=\"some_path/\",\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/qml_tools/#fitting-a-funtion-with-a-qnn-using-ml_tools","title":"Fitting a funtion with a QNN using <code>ml_tools</code>","text":"<p>Let's look at a complete example of how to use <code>train_with_grad</code> now.</p> <pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence.models import QNN\nfrom qadence.ml_tools import train_with_grad, TrainConfig\nimport matplotlib.pyplot as plt\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\nnext(cnt)\nx, y = data[0], data[1]\nout = model(x)\nloss = criterion(out, y)\nreturn loss, {}\ntmp_path = Path(\"/tmp\")\nn_epochs = 5\nconfig = TrainConfig(\nfolder=tmp_path,\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\nbatch_size = 25\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\ntrain_with_grad(model, (x, y), optimizer, config, loss_fn=loss_fn)\nplt.plot(y.numpy())\nplt.plot(model(input_values).detach().numpy())\n</code></pre> <pre><code>\n</code></pre> <p>For users who want to use the low-level API of <code>qadence</code>, here is the example from above written without <code>train_with_grad</code>.</p>"},{"location":"tutorials/qml_tools/#fitting-a-function-low-level-api","title":"Fitting a function - Low-level API","text":"<pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence.models import QNN\nfrom qadence.ml_tools import train_with_grad, TrainConfig\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\nn_epochs=50\ncnt = count()\ntmp_path = Path(\"/tmp\")\nconfig = TrainConfig(\nfolder=tmp_path,\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\nfor i in range(n_epochs):\nout = model(x)\nloss = criterion(out, y)\nloss.backward()\noptimizer.step()\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/quantummodels/","title":"Quantum Models","text":"<p>A quantum program can be expressed and executed using the <code>QuantumModel</code> type. It serves three primary purposes:</p> <p>Parameter handling: by conveniently handling and embedding the two parameter types that Qadence supports: feature and variational (see more details in this section).</p> <p>Differentiability: by enabling a differentiable backend that supports two differentiable modes: automated differentiation (AD) and parameter shift rule (PSR). The former is used to differentiate non-gate parameters and enabled for PyTorch-based simulators only. The latter is used to differentiate gate parameters and is enabled for all backends.</p> <p>Execution: by defining which backend the program is expected to be executed on. Qadence supports circuit compilation to the native backend representation.</p> <p>Backends</p> <p>Quantum models can execute on a number of different purpose backends: simulators, emulators or real hardware. By default, Qadence executes on the PyQTorch backend which implements a state vector simulator. Other choices include the Pulser backend (pulse sequences on programmable neutral atom arrays).  For more information see backend tutorial.</p> <p>The base <code>QuantumModel</code> exposes the following methods:</p> <ul> <li><code>QuantumModel.run()</code>: To extract the wavefunction after circuit execution. Not supported by all backends.</li> <li><code>QuantumModel.sample()</code>: Sample a bitstring from the resulting quantum state after circuit execution. Supported by all backends.</li> <li><code>QuantumModel.expectation()</code>: Compute the expectation value of an observable.</li> </ul> <p>Every <code>QuantumModel</code> is an instance of a <code>torch.nn.Module</code> that enables differentiability for its <code>expectation</code> method.</p> <p>Upon construction of the model, a compiled version of the abstract <code>QuantumCircuit</code> is created:</p> <pre><code>from qadence import QuantumCircuit, QuantumModel, RX, Z, chain, BackendName, Parameter\n# Construct a parametrized abstract circuit.\n# At this point we cannot run anything yet.\nx = Parameter(\"x\")\nn_qubits = 2\nblock = chain(RX(0, x), RX(1, x))\ncircuit = QuantumCircuit(n_qubits, block)\nobservable = Z(0)\n# Construct a QuantumModel which will compile\n# the abstract circuit to targetted backend.\n# By default, diff_mode=DiffMode.AD.\nmodel = QuantumModel(circuit, observable, backend=BackendName.PYQTORCH)\n# The converted circuit is a private attribute and should not\n# manually be tampered with, but we can at least verify its there\n# by printing it.\nprint(model._circuit.native)\n</code></pre> <pre><code>QuantumCircuit(\n(operations): ModuleList(\n(0): QuantumCircuit(\n(operations): ModuleList(\n(0): ParametricPyQOperation(\n(operation): RX(qubits=(0,), n_qubits=2)\n)\n(1): ParametricPyQOperation(\n(operation): RX(qubits=(1,), n_qubits=2)\n)\n)\n)\n)\n)\n</code></pre> <p>Now, the wavefunction, sample, or expectation value are computable by passing a batch of values :</p> <pre><code>import torch\n# Set a batch of random parameter values.\nvalues = {\"x\": torch.rand(3)}\nwf = model.run(values)\nxs = model.sample(values, n_shots=100)\nex = model.expectation(values)\n</code></pre> <pre><code>wf = tensor([[ 0.9587+0.0000j,  0.0000-0.1990j,  0.0000-0.1990j, -0.0413+0.0000j],\n[ 0.9884+0.0000j,  0.0000-0.1072j,  0.0000-0.1072j, -0.0116+0.0000j],\n[ 0.8170+0.0000j,  0.0000-0.3867j,  0.0000-0.3867j, -0.1830+0.0000j]])\nxs = [Counter({'00': 92, '10': 4, '01': 3, '11': 1}), Counter({'00': 98, '01': 1, '10': 1}), Counter({'00': 64, '01': 19, '10': 15, '11': 2})]\nex = tensor([[0.9174],\n[0.9767],\n[0.6340]], requires_grad=True)\n</code></pre> <p>You can also measure multiple observables by passing a list of blocks.</p> <pre><code># By default, backend=BackendName.PYQTORCH.\nmodel = QuantumModel(circuit, [Z(0), Z(1)])\nex = model.expectation(values)\n</code></pre> <pre><code>ex = tensor([[0.9174, 0.9174],\n[0.9767, 0.9767],\n[0.6340, 0.6340]], requires_grad=True)\n</code></pre>"},{"location":"tutorials/quantummodels/#quantum-neural-network-qnn","title":"Quantum Neural Network (QNN)","text":"<p>The <code>QNN</code> is a subclass of the <code>QuantumModel</code> geared towards quantum machine learning and parameter optimisation. See the ML Tools section or the <code>QNN</code> API reference for more detailed information, and the parametric program tutorial for parameterization.</p>"},{"location":"tutorials/register/","title":"Quantum Registers","text":"<p>In Qadence, quantum programs can be executed by specifying the layout of a register of resources as a lattice. Built-in <code>Register</code> types can be used or constructed for arbitrary topologies. Common register topologies are available and illustrated in the plot below.</p> 2023-10-10T21:44:54.759650 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"tutorials/register/#building-and-drawing-registers","title":"Building and drawing registers","text":"<p>Built-in topologies are directly accessible in the <code>Register</code>:</p> <pre><code>from qadence import Register\nreg = Register.honeycomb_lattice(2, 3)\nreg.draw()\n</code></pre> 2023-10-10T21:44:55.372393 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ <p>Arbitrarily shaped registers can be constructed by providing coordinates.</p> <p>Registers defined from coordinates</p> <p><code>Register</code> constructed via the <code>from_coordinates</code> method do not define edges in the connectivity graph.</p> <pre><code>import numpy as np\nfrom qadence import Register\nreg = Register.from_coordinates(\n[(x, np.sin(x)) for x in np.linspace(0, 2*np.pi, 10)]\n)\nreg.draw()\n</code></pre> 2023-10-10T21:44:55.468980 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ <p>Units for qubit coordinates</p> <p>Qubits coordinates in Qadence are dimensionless but converted to the required unit when executed on a backend. For instance, Pulser uses \\(\\mu \\textrm{m}\\).</p>"},{"location":"tutorials/register/#connectivity-graphs","title":"Connectivity graphs","text":"<p>Register topology is often asssumed in simulations to be an all-to-all qubit connectivity. When running on real devices that enable the digital-analog computing paradigm, qubit interaction must be specified either by specifying distances between qubits, or by defining edges in the register connectivity graph.</p> <p>It is possible to access the abstract graph nodes and edges to work with if needed as in the perfect state transfer example.</p> <pre><code>from qadence import Register\nreg = Register.rectangular_lattice(2,3)\n</code></pre> <pre><code>reg.nodes = NodeView((0, 1, 2, 3, 4, 5))\nreg.edges = EdgeView([(0, 2), (0, 1), (1, 3), (2, 4), (2, 3), (3, 5), (4, 5)])\n</code></pre> <p>It is possible to customize qubit interaction through the <code>add_interaction</code> method. In that case, <code>Register.coords</code> are accessible from the concrete graph:</p> <pre><code>\n</code></pre> <pre><code>reg.coords = {0: (0.0, 0.0), 1: (0.0, 1.0), 2: (1.0, 0.0), 3: (1.0, 1.0), 4: (2.0, 0.0), 5: (2.0, 1.0)}\n</code></pre> <p>More details about their usage in the digital-analog paradigm can be found in the digital-analog basics section.</p>"},{"location":"tutorials/serializ_and_prep/","title":"Serialization","text":"<p>Qadence offers convenience functions for serializing and deserializing any quantum program. This is useful for storing quantum programs and sending them for execution over the network via an API.</p> <p>Note</p> <p>Qadence currently uses a custom JSON serialization as interchange format. Support for QASM format for digital quantum programs is currently under consideration.</p> <ul> <li><code>serialize/deserialize</code>: serialize and deserialize a Qadence object into a dictionary</li> <li><code>save/load</code>: save and load a Qadence object to a file with one of the supported   formats. Currently, these are <code>.json</code> and the PyTorch-compatible <code>.pt</code> format.</li> </ul> <p>Let's start with serialization into a dictionary.</p> <pre><code>import torch\nfrom qadence import QuantumCircuit, QuantumModel, DiffMode\nfrom qadence import chain, hamiltonian_factory, feature_map, hea, Z\nfrom qadence.serialization import serialize, deserialize\nn_qubits = 4\nmy_block = chain(feature_map(n_qubits, param=\"x\"), hea(n_qubits, depth=2))\nobs = hamiltonian_factory(n_qubits, detuning=Z)\n# Use the block defined above to create a quantum circuit\n# serialize/deserialize it\nqc = QuantumCircuit(n_qubits, my_block)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n# Let's wrap it in a QuantumModel\n# and serialize it\nqm = QuantumModel(qc, obs, diff_mode=DiffMode.AD)\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Check if the loaded QuantumModel returns the same expectation\nvalues = {\"x\": torch.rand(10)}\nassert torch.allclose(qm.expectation(values=values), qm_deserialized.expectation(values=values))\n</code></pre> <p>Finally, we can save the quantum circuit and the model with the two supported formats.</p> <pre><code>from qadence.serialization import serialize, deserialize, save, load, SerializationFormat\nqc_fname = \"circuit\"\nsave(qc, folder=\".\", file_name=qc_fname, format=SerializationFormat.PT)\nloaded_qc = load(f\"{qc_fname}.pt\")\nassert qc == loaded_qc\nqm_fname = \"model\"\nsave(qm, folder=\".\", file_name=qm_fname, format=SerializationFormat.JSON)\nmodel = load(f\"{qm_fname}.json\")\nassert isinstance(model, QuantumModel)\n</code></pre>"},{"location":"tutorials/state_conventions/","title":"State Conventions","text":"<p>Here is an overview of the state conventions used in Qadence together with practical examples.</p>"},{"location":"tutorials/state_conventions/#qubit-register-order","title":"Qubit register order","text":"<p>Qubit registers in quantum computing are often indexed in increasing or decreasing order from left to right. In Qadence, the convention is qubit indexation in increasing order. For example, a register of four qubits in bra-ket notation reads:</p> \\[|q_0, q_1, q_2, q_3\\rangle\\] <p>Furthermore, when displaying a quantum circuit, qubits are ordered from top to bottom.</p>"},{"location":"tutorials/state_conventions/#basis-state-order","title":"Basis state order","text":"<p>Basis state ordering refers to how basis states are ordered when considering the conversion from bra-ket notation to the standard linear algebra basis. In Qadence, basis states are ordered in the following manner:</p> \\[ \\begin{align} |00\\rangle = [1, 0, 0, 0]^T\\\\ |01\\rangle = [0, 1, 0, 0]^T\\\\ |10\\rangle = [0, 0, 1, 0]^T\\\\ |11\\rangle = [0, 0, 0, 1]^T \\end{align} \\]"},{"location":"tutorials/state_conventions/#endianness","title":"Endianness","text":"<p>Endianness refers to the storage convention for binary information (in bytes) in a classical memory register. In quantum computing, information is either stored in bits or in qubits. The most commonly used conventions are:</p> <ul> <li>A big-endian system stores the most significant bit of a binary word at the smallest memory address.</li> <li>A little-endian system stores the least significant bit of a binary word at the smallest memory address.</li> </ul> <p>Given the register convention in Qadence, the integer \\(2\\) written in binary big-endian as \\(10\\) can be encoded in a qubit register in both big-endian as \\(|10\\rangle\\) or little-endian as \\(|01\\rangle\\).</p> <p>The convention for Qadence is big-endian.</p>"},{"location":"tutorials/state_conventions/#quantum-states","title":"Quantum states","text":"<p>In practical scenarios, conventions regarding register order, basis state order and endianness are very much intertwined, and identical results can be obtained by fixing or varying any of them. In Qadence, we assume that qubit ordering and basis state ordering is fixed, and allow an <code>endianness</code> argument that can be passed to control the expected result. Here are a few examples:</p> <p>A simple and direct way to exemplify the endianness convention is using convenience functions for state preparation.</p> <p>Bitstring convention as inputs</p> <p>When a bitstring is passed as input to a function for state preparation, it has to be understood in big-endian convention.</p> <pre><code>from qadence import Endianness, product_state\n# The state |10&gt;, the 3rd basis state.\nstate_big = product_state(\"10\", endianness=Endianness.BIG) # or just \"Big\"\n# The state |01&gt;, the 2nd basis state.\nstate_little = product_state(\"10\", endianness=Endianness.LITTLE) # or just \"Little\"\n</code></pre> <pre><code>State in big endian = tensor([[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]])\nState in little endian = tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> <p>Here, a bitword expressed as a Python string to encode the integer 2 in big-endian is used to create the respective basis state in both conventions. However, note that the same results can be obtained by fixing the endianness convention as big-endian (thus creating the state \\(|10\\rangle\\) in both cases), and changing the basis state ordering. A similar argument holds for fixing both endianness and basis state ordering and simply changing the qubit index order.</p> <p>Another example where endianness directly comes into play is when measuring a register. A big- or little-endian measurement will choose the first or the last qubit, respectively, as the most significant bit. Let's see this in an example:</p> <pre><code>from qadence import I, H, sample\n# Create superposition state: |00&gt; + |01&gt; (normalized)\nblock = I(0) @ H(1)  # Identity on qubit 0, Hadamard on qubit 1\n# Generate bitword samples following both conventions\n# Samples \"00\" and \"01\"\nresult_big = sample(block, endianness=Endianness.BIG)\n# Samples \"00\" and \"10\"\nresult_little = sample(block, endianness=Endianness.LITTLE)\n</code></pre> <pre><code>Sample in big endian = [Counter({'00': 53, '01': 47})]\nSample in little endian = [Counter({'00': 55, '10': 45})]\n</code></pre> <p>In Qadence, endianness can be flipped for many relevant objects:</p> <pre><code>from qadence import invert_endianness\n# Equivalent to sampling in little-endian.\nflip_big_sample = invert_endianness(result_big)\n# Equivalent to a state created in little-endian.\nflip_big_state = invert_endianness(state_big)\n</code></pre> <pre><code>Flipped sample = [Counter({'00': 53, '10': 47})]\nFlipped state = tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre>"},{"location":"tutorials/state_conventions/#quantum-operations","title":"Quantum operations","text":"<p>When looking at the matricial form of quantum operations, the usage of the term endianness becomes slightly abusive. To exemplify, we may consider the <code>CNOT</code> operation with <code>control = 0</code> and <code>target = 1</code>. This operation is often described with two different matrices:</p> \\[ \\text{CNOT(0, 1)} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ \\end{bmatrix} \\qquad \\text{or} \\qquad \\text{CNOT(0, 1)} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} \\] <p>The difference can be easily explained either by considering a different ordering of the qubit indices, or a different ordering of the basis states. In Qadence, both can be retrieved through the <code>endianness</code> argument:</p> <pre><code>from qadence import block_to_tensor, CNOT\nmatrix_big = block_to_tensor(CNOT(0, 1), endianness=Endianness.BIG)\nmatrix_little = block_to_tensor(CNOT(0, 1), endianness=Endianness.LITTLE)\n</code></pre> <pre><code>CNOT matrix in big endian =\ntensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]]])\nCNOT matrix in little endian =\ntensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]]])\n</code></pre>"},{"location":"tutorials/state_conventions/#backends","title":"Backends","text":"<p>An important part of having clear state conventions is that we need to make sure our results are consistent accross different computational backends, which may have their own conventions. In Qadence, this is taken care for automatically: by calling operations for different backends, the result is expected to be equivalent up to qubit ordering.</p> <pre><code>from qadence import BackendName, RX, run, sample\nimport torch\n# RX(pi/4) on qubit 1\nn_qubits = 2\nop = RX(1, torch.pi/4)\n</code></pre> <pre><code>Same sampling order in big endian:\nOn PyQTorch = [Counter({'00': 89, '01': 11})]\nOn Braket = [Counter({'00': 80, '01': 20})]\nOn Pulser = [Counter({'00': 87, '01': 13})]\nSame wavefunction order:\nOn PyQTorch = tensor([[0.9239+0.0000j, 0.0000-0.3827j, 0.0000+0.0000j, 0.0000+0.0000j]])\nOn Braket = tensor([[0.9239+0.0000j, 0.0000-0.3827j, 0.0000+0.0000j, 0.0000+0.0000j]])\nOn Pulser = tensor([[0.9223+0.0000j, 0.0000-0.3865j, 0.0000+0.0000j, 0.0000+0.0000j]])\n</code></pre>"},{"location":"tutorials/state_init/","title":"State initialization","text":"<p>Qadence offers convenience routines for preparing initial quantum states. These routines are divided into two approaches:</p> <ul> <li>As a dense matrix.</li> <li>From a suitable quantum circuit. This is available for every backend and it should be added in front of the desired quantum circuit to simulate.</li> </ul> <p>Let's illustrate the usage of the state preparation routine.</p> <pre><code>from qadence import random_state, product_state, is_normalized, StateGeneratorType\n# Random initial state.\n# the default `type` is StateGeneratorType.HaarMeasureFast\nstate = random_state(n_qubits=2, type=StateGeneratorType.RANDOM_ROTATIONS)\n# Check the normalization.\nassert is_normalized(state)\n# Product state from a given bitstring.\n# NB: Qadence follows the big endian convention.\nstate = product_state(\"01\")\n</code></pre> <pre><code>Random initial state generated with rotations:\nstate = [ 0.89790539+0.j -0.17791877+0.j -0.39495107+0.j  0.07825903+0.j]\nProduct state corresponding to bitstring '01':\nstate = [0.+0.j 1.+0.j 0.+0.j 0.+0.j]\n</code></pre> <p>Now we see how to generate the product state corresponding to the one above with a suitable quantum circuit.</p> <p><pre><code>from qadence import product_block, tag, hea, QuantumCircuit\nfrom qadence.draw import display\nstate_prep_block = product_block(\"01\")\ndisplay(state_prep_block)\n# Let's now prepare a circuit.\nn_qubits = 4\nstate_prep_block = product_block(\"0001\")\ntag(state_prep_block, \"Prep block\")\ncircuit_block = tag(hea(n_qubits, depth = 2), \"Circuit block\")\nqc_with_state_prep = QuantumCircuit(n_qubits, state_prep_block, circuit_block)\n</code></pre> %3 cluster_1101a68aa26e49218030e0127d8c1a04 Circuit block cluster_d63fc83829e640619e0dbd2b3f35d212 Prep block 6d2b9440f791492eb7b8233e0243bd98 0 74826676cd06473d8c1e37191135b948 6d2b9440f791492eb7b8233e0243bd98--74826676cd06473d8c1e37191135b948 1ada91a624c348488165841be79f48c3 1 4cb5842f52a4492c9db4a8d181541ce0 RX(theta\u2080) 74826676cd06473d8c1e37191135b948--4cb5842f52a4492c9db4a8d181541ce0 f83c55e2b9fd41339c722e6693c3ade8 RY(theta\u2084) 4cb5842f52a4492c9db4a8d181541ce0--f83c55e2b9fd41339c722e6693c3ade8 4f58b67aae284bb49f101ed7e94cc866 RX(theta\u2088) f83c55e2b9fd41339c722e6693c3ade8--4f58b67aae284bb49f101ed7e94cc866 c009d6fb222e4fe98768cc839a25b96e 4f58b67aae284bb49f101ed7e94cc866--c009d6fb222e4fe98768cc839a25b96e e01fb2ae970e4beabac715f7332dd3a6 c009d6fb222e4fe98768cc839a25b96e--e01fb2ae970e4beabac715f7332dd3a6 98c1ae999a73463eb938d15c19a32863 RX(theta\u2081\u2082) e01fb2ae970e4beabac715f7332dd3a6--98c1ae999a73463eb938d15c19a32863 378f0c1c97f944f7881152acfc07a08e RY(theta\u2081\u2086) 98c1ae999a73463eb938d15c19a32863--378f0c1c97f944f7881152acfc07a08e 755a9a8b37c44d02b9beb29b1808cf68 RX(theta\u2082\u2080) 378f0c1c97f944f7881152acfc07a08e--755a9a8b37c44d02b9beb29b1808cf68 4f247b7b76444a8b846976e43340a1ab 755a9a8b37c44d02b9beb29b1808cf68--4f247b7b76444a8b846976e43340a1ab d9018a4078e14eed95db3b928f53c6dc 4f247b7b76444a8b846976e43340a1ab--d9018a4078e14eed95db3b928f53c6dc c1ccb02974064ba1bad4c6e27d197f9b d9018a4078e14eed95db3b928f53c6dc--c1ccb02974064ba1bad4c6e27d197f9b 3a3911a030c94be8b210f4c8755c0ea8 7ea42b763000499b9dbd19a69322b6b7 1ada91a624c348488165841be79f48c3--7ea42b763000499b9dbd19a69322b6b7 96456103357f478aac935d2b8fc17c67 2 fb9324a7b0724ea884cdeff6a9c46941 RX(theta\u2081) 7ea42b763000499b9dbd19a69322b6b7--fb9324a7b0724ea884cdeff6a9c46941 bc98407a0d4e4fbe892ecf092a36697f RY(theta\u2085) fb9324a7b0724ea884cdeff6a9c46941--bc98407a0d4e4fbe892ecf092a36697f f1abe42231d6471da92bbe3f640a9017 RX(theta\u2089) bc98407a0d4e4fbe892ecf092a36697f--f1abe42231d6471da92bbe3f640a9017 c11073b507d648e3bb5ec40579162607 X f1abe42231d6471da92bbe3f640a9017--c11073b507d648e3bb5ec40579162607 c11073b507d648e3bb5ec40579162607--c009d6fb222e4fe98768cc839a25b96e aa3a681f50ba476b802493b3924412c5 c11073b507d648e3bb5ec40579162607--aa3a681f50ba476b802493b3924412c5 8554480d30da439093c003079bc51d67 RX(theta\u2081\u2083) aa3a681f50ba476b802493b3924412c5--8554480d30da439093c003079bc51d67 686e107ca9b14f48ab5731cfdd08688d RY(theta\u2081\u2087) 8554480d30da439093c003079bc51d67--686e107ca9b14f48ab5731cfdd08688d c86fb31129cc4629a9d3025f7c139065 RX(theta\u2082\u2081) 686e107ca9b14f48ab5731cfdd08688d--c86fb31129cc4629a9d3025f7c139065 57419287744e429a9b942e5dd72fe6b8 X c86fb31129cc4629a9d3025f7c139065--57419287744e429a9b942e5dd72fe6b8 57419287744e429a9b942e5dd72fe6b8--4f247b7b76444a8b846976e43340a1ab d70859a97c1b4e41880e0c099bc13e72 57419287744e429a9b942e5dd72fe6b8--d70859a97c1b4e41880e0c099bc13e72 d70859a97c1b4e41880e0c099bc13e72--3a3911a030c94be8b210f4c8755c0ea8 6ecb4e38b3a6482594aee5699879fd26 67dfe4fc214a462dbb2a7a0eb8252343 96456103357f478aac935d2b8fc17c67--67dfe4fc214a462dbb2a7a0eb8252343 f4a09b49edbe482e8e478595f23bb955 3 bedb01118a7843c5b40f14b89c471f19 RX(theta\u2082) 67dfe4fc214a462dbb2a7a0eb8252343--bedb01118a7843c5b40f14b89c471f19 d83f83393e4a4905bbfba73d66716ea9 RY(theta\u2086) bedb01118a7843c5b40f14b89c471f19--d83f83393e4a4905bbfba73d66716ea9 6450e41079754d3f931ee39df30d5b02 RX(theta\u2081\u2080) d83f83393e4a4905bbfba73d66716ea9--6450e41079754d3f931ee39df30d5b02 5667e93558b64cec89e30ab4ae9076be 6450e41079754d3f931ee39df30d5b02--5667e93558b64cec89e30ab4ae9076be 288ee51c326f421085beb29b111bef96 X 5667e93558b64cec89e30ab4ae9076be--288ee51c326f421085beb29b111bef96 288ee51c326f421085beb29b111bef96--aa3a681f50ba476b802493b3924412c5 b1ea7d9351304dafa27f37bbce0fc2ce RX(theta\u2081\u2084) 288ee51c326f421085beb29b111bef96--b1ea7d9351304dafa27f37bbce0fc2ce 0bfa32c0a4ba48a890a36518c6dbdf6e RY(theta\u2081\u2088) b1ea7d9351304dafa27f37bbce0fc2ce--0bfa32c0a4ba48a890a36518c6dbdf6e 34bb754d1ac0430da7afce3db5580565 RX(theta\u2082\u2082) 0bfa32c0a4ba48a890a36518c6dbdf6e--34bb754d1ac0430da7afce3db5580565 09f142b8a44544748b1c5ddeaac0ccdf 34bb754d1ac0430da7afce3db5580565--09f142b8a44544748b1c5ddeaac0ccdf 41c658cf929d4c7d839d46453ca323de X 09f142b8a44544748b1c5ddeaac0ccdf--41c658cf929d4c7d839d46453ca323de 41c658cf929d4c7d839d46453ca323de--d70859a97c1b4e41880e0c099bc13e72 41c658cf929d4c7d839d46453ca323de--6ecb4e38b3a6482594aee5699879fd26 269c0806b7eb480990bd4a881bb3c59d 8b3471fff2524dd68ea18e0d2c7f24da X f4a09b49edbe482e8e478595f23bb955--8b3471fff2524dd68ea18e0d2c7f24da 4c13db85fd7f461ab7f2fab1ca60b884 RX(theta\u2083) 8b3471fff2524dd68ea18e0d2c7f24da--4c13db85fd7f461ab7f2fab1ca60b884 b164931a9f5c4f2fb66eaac8a8c1ec0a RY(theta\u2087) 4c13db85fd7f461ab7f2fab1ca60b884--b164931a9f5c4f2fb66eaac8a8c1ec0a 6b3540d6aebe4c4fa0494fae14cb90a5 RX(theta\u2081\u2081) b164931a9f5c4f2fb66eaac8a8c1ec0a--6b3540d6aebe4c4fa0494fae14cb90a5 7364b3b6ce84404592731800b3dd0b81 X 6b3540d6aebe4c4fa0494fae14cb90a5--7364b3b6ce84404592731800b3dd0b81 7364b3b6ce84404592731800b3dd0b81--5667e93558b64cec89e30ab4ae9076be e367fe2e83c744a3a302cf7795bece78 7364b3b6ce84404592731800b3dd0b81--e367fe2e83c744a3a302cf7795bece78 e46fe8323e594880a9436e7a8cde5731 RX(theta\u2081\u2085) e367fe2e83c744a3a302cf7795bece78--e46fe8323e594880a9436e7a8cde5731 9fe63edf792745e5ae77ab9cd8ff7f11 RY(theta\u2081\u2089) e46fe8323e594880a9436e7a8cde5731--9fe63edf792745e5ae77ab9cd8ff7f11 c239a81f16bd47939e65c6ca7959ab70 RX(theta\u2082\u2083) 9fe63edf792745e5ae77ab9cd8ff7f11--c239a81f16bd47939e65c6ca7959ab70 8cf95ced097b4085beb3dea8245f36ed X c239a81f16bd47939e65c6ca7959ab70--8cf95ced097b4085beb3dea8245f36ed 8cf95ced097b4085beb3dea8245f36ed--09f142b8a44544748b1c5ddeaac0ccdf c149365aabd74be282c9bd718991718b 8cf95ced097b4085beb3dea8245f36ed--c149365aabd74be282c9bd718991718b c149365aabd74be282c9bd718991718b--269c0806b7eb480990bd4a881bb3c59d  Several standard quantum states can be conveniently initialized in Qadence, both in statevector form as well as in block form as shown in following.</p>"},{"location":"tutorials/state_init/#state-vector-initialization","title":"State vector initialization","text":"<p>Qadence offers a number of constructor functions for state vector preparation.</p> <pre><code>from qadence import uniform_state, zero_state, one_state\nn_qubits = 3\nbatch_size = 2\nuniform_state = uniform_state(n_qubits, batch_size)\nzero_state = zero_state(n_qubits, batch_size)\none_state = one_state(n_qubits, batch_size)\n</code></pre> <pre><code>Uniform state = tensor([[0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j,\n0.3536+0.j],\n[0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j,\n0.3536+0.j]])\nZero state = tensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\nOne state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre> <p>As already seen, product states can be easily created, even in batches:</p> <pre><code>from qadence import product_state, rand_product_state\n# From a bitsring \"100\"\nprod_state = product_state(\"100\", batch_size)\n# Or a random product state\nrand_state = rand_product_state(n_qubits, batch_size)\n</code></pre> <pre><code>Product state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\nRandom state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> <p>Creating a GHZ state:</p> <pre><code>from qadence import ghz_state\nghz = ghz_state(n_qubits, batch_size)\n</code></pre> <pre><code>GHZ state = tensor([[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n0.7071+0.j],\n[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n0.7071+0.j]])\n</code></pre> <p>Creating a random state uniformly sampled from a Haar measure:</p> <pre><code>from qadence import random_state\nrand_haar_state = random_state(n_qubits, batch_size)\n</code></pre> <pre><code>Random state from Haar = tensor([[ 0.0960-0.0362j, -0.1035+0.1122j,  0.0139+0.2543j,  0.2133+0.1648j,\n0.4687+0.2195j, -0.2819+0.0705j, -0.0940-0.0842j,  0.5079-0.4499j],\n[ 0.0447-0.2164j, -0.1827-0.2467j, -0.1432+0.0792j, -0.2743-0.1482j,\n-0.0855+0.2340j,  0.1316+0.4042j,  0.0874-0.5930j,  0.3484-0.0977j]])\n</code></pre> <p>Custom initial states can then be passed to either <code>run</code>, <code>sample</code> and <code>expectation</code> through the <code>state</code> argument</p> <pre><code>from qadence import random_state, product_state, CNOT, run\ninit_state = product_state(\"10\")\nfinal_state = run(CNOT(0, 1), state=init_state)\n</code></pre> <pre><code>Final state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre>"},{"location":"tutorials/state_init/#block-initialization","title":"Block initialization","text":"<p>Not all backends support custom statevector initialization, however previous utility functions have their counterparts to initialize the respective blocks:</p> <pre><code>from qadence import uniform_block, one_block\nn_qubits = 3\nuniform_block = uniform_block(n_qubits)\none_block = one_block(n_qubits)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 H(0)\n\u251c\u2500\u2500 H(1)\n\u2514\u2500\u2500 H(2)\nKronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> <p>Similarly, for product states:</p> <pre><code>from qadence import product_block, rand_product_block\nproduct_block = product_block(\"100\")\nrand_product_block = rand_product_block(n_qubits)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 I(1)\n\u2514\u2500\u2500 I(2)\nKronBlock(0,1,2)\n\u251c\u2500\u2500 I(0)\n\u251c\u2500\u2500 I(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> <p>And GHZ states:</p> <pre><code>from qadence import ghz_block\nghz_block = ghz_block(n_qubits)\n</code></pre> <pre><code>ChainBlock(0,1,2)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 ChainBlock(0,1,2)\n\u251c\u2500\u2500 CNOT(0,1)\n\u2514\u2500\u2500 CNOT(1,2)\n</code></pre> <p>Initial state blocks can simply be chained at the start of a given circuit.</p>"},{"location":"tutorials/state_init/#utility-functions","title":"Utility functions","text":"<p>Some state vector utility functions are also available. We can easily create the probability mass function of a given statevector using <code>torch.distributions.Categorical</code></p> <pre><code>from qadence import random_state, pmf\nn_qubits = 3\nstate = random_state(n_qubits)\ndistribution = pmf(state)\n</code></pre> <pre><code>Categorical(probs: torch.Size([1, 8]))\n</code></pre> <p>We can also check if a state is normalized:</p> <pre><code>from qadence import random_state, is_normalized\nstate = random_state(n_qubits)\nprint(is_normalized(state))\n</code></pre> <pre><code>True\n</code></pre> <p>Or normalize a state:</p> <pre><code>import torch\nfrom qadence import normalize, is_normalized\nstate = torch.tensor([[1, 1, 1, 1]], dtype = torch.cdouble)\nprint(normalize(state))\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre>"}]}