{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Qadence","text":"<p>Qadence is a Python package that provides a simple interface to build digital-analog quantum programs with tunable qubit interaction defined on arbitrary register topologies realizable on neutral atom devices.</p>"},{"location":"#feature-highlights","title":"Feature highlights","text":"<ul> <li> <p>A block-based system for composing complex digital-analog   programs in a flexible and scalable manner, inspired by the Julia quantum SDK   Yao.jl and functional programming concepts.</p> </li> <li> <p>A simple interface to work with interacting neutral-atom qubit systems   using arbitrary registers topologies.</p> </li> <li> <p>An intuitive expression-based system developed on top of the symbolic library Sympy to construct parametric quantum programs easily.</p> </li> <li> <p>High-order generalized parameter shift rules for differentiating parametrized quantum operations.</p> </li> <li> <p>Out-of-the-box automatic differentiability of quantum programs with PyTorch integration.</p> </li> <li> <p>Efficient execution on a variety of different purpose backends: from state vector simulators to tensor network emulators and real devices.</p> </li> </ul> <p>In following are some examples of Qadence possibilites in the analog, digital-analog and digital paradigms.</p>"},{"location":"#analog-emulation-of-a-perfect-state-transfer","title":"Analog emulation of a perfect state transfer","text":"<p>This next example showcases the construction and sampling of a system that admits a perfect state transfer between the two edge qubits of a three qubit register laid out in a line. This relies on time-evolving a Hamiltonian for a custom defined qubit interaction until \\(t=\\frac{\\pi}{\\sqrt 2}\\).</p> <pre><code>from torch import pi\nfrom qadence import X, Y, HamEvo, Register, product_state, sample, add\n# Define the qubit-qubit interaction term.\ndef interaction(i, j):\nreturn 0.5 * (X(i) @ X(j) + Y(i) @ Y(j))  # Compose gates in parallel and sum their contribution.\n# Initial state with left-most qubit in the 1 state.\ninit_state = product_state(\"100\")\n# Define a register of 3 qubits laid out in a line.\nregister = Register.line(n_qubits=3)\n# Define an interaction Hamiltonian by summing interactions on indexed qubits.\n# hamiltonian = interaction(0, 1) + interaction(1, 2)\nhamiltonian = add(interaction(*edge) for edge in register.edges)\n# Define and time-evolve the Hamiltonian until t=pi/sqrt(2).\nt = pi/(2**0.5)  # Dimensionless.\nevolution = HamEvo(hamiltonian, t)\n# Sample with 100 shots.\nsamples = sample(register, evolution, state=init_state, n_shots=100)\n</code></pre> <pre><code>samples = [Counter({'001': 100})]\n</code></pre>"},{"location":"#digital-analog-example","title":"Digital-analog example","text":"<p>This final example deals with the construction and sampling of an Ising Hamiltonian that includes a distance-based interaction between qubits and a global analog block of rotations around the \\(X\\)-axis. Here, global has to be understood as applied to the whole register for qubits.</p> <pre><code>from torch import pi\nfrom qadence import Register, AnalogRX, sample\n# Global analog RX block.\nblock = AnalogRX(pi)\n# Almost non-interacting qubits as too far apart.\nregister = Register.from_coordinates([(0,0), (0,15)])  # Dimensionless.\nsamples = sample(register, block)\n# Interacting qubits are close to each other.\nregister = Register.from_coordinates([(0,0), (0,5)])\nsamples = sample(register, AnalogRX(pi))\n</code></pre> <pre><code>distance = 15: samples = [Counter({'11': 100})]\ndistance =  5: samples = [Counter({'00': 43, '10': 31, '01': 25, '11': 1})]\n</code></pre>"},{"location":"#sampling-the-canonical-bell-state","title":"Sampling the canonical Bell state","text":"<p>This example illustrates how to prepare a Bell state using digital gates and sampling from the outcome bitstring distribution:</p> <pre><code>from qadence import CNOT, H, chain, sample\n# Preparing a Bell state by composing a Hadamard and CNOT gates in sequence.\nbell_state = chain(H(0), CNOT(0,1))\n# Sample with 100 shots.\nsamples = sample(bell_state, n_shots=100)\n</code></pre> <pre><code>samples = [Counter({'00': 53, '11': 47})]\n</code></pre>"},{"location":"#further-resources","title":"Further resources","text":"<p>For a more comprehensive introduction and advanced topics, please have a look at the following tutorials:</p> <ul> <li>Quantum state conventions used throughout Qadence.</li> <li>Basic tutorials for first hands-on.</li> <li>Digital-analog basics to build quantum programs in the digital-analog paradigm.</li> <li>Parametric quantum circuits for the generation and manipulation of parametric programs.</li> <li>Advanced features about low-level backend interface and differentiablity.</li> <li><code>QuantumModel</code> for defining custom models.</li> </ul>"},{"location":"#installation-guide","title":"Installation guide","text":"<p>Qadence can be installed from PyPI with <code>pip</code> as follows:</p> <pre><code>pip install qadence\n</code></pre> <p>The default backend for Qadence is PyQTorch, a differentiable state vector simulator for digital-analog simulation. It is possible to install additional backends and the circuit visualization library using the following extras:</p> <ul> <li><code>braket</code>: the Braket backend.</li> <li><code>pulser</code>: the Pulser backend for composing, simulating and executing pulse sequences for neutral-atom quantum devices.</li> <li><code>visualization</code>: to display diagrammatically quantum circuits.</li> </ul> <p>To just get qadence with the <code>pyqtorch</code> backend, simply run:</p> <pre><code>pip install qadence\n</code></pre> <p>To install other backends or the visualization tool, please use:</p> <pre><code>pip install \"qadence[braket,pulser,visualization]\"\n</code></pre> <p>Warning</p> <p>In order to correctly install the <code>visualization</code> extra, the <code>graphviz</code> package needs to be installed in your system:</p> <pre><code># on Ubuntu\nsudo apt install graphviz\n\n# on MacOS\nbrew install graphviz\n\n# via conda\nconda install python-graphviz\n</code></pre>"},{"location":"#install-from-source","title":"Install from source","text":"<p>We recommend to use the <code>hatch</code> environment manager to install <code>qadence</code> from source:</p> <pre><code>python -m pip install hatch\n\n# get into a shell with all the dependencies\npython -m hatch shell\n\n# run a command within the virtual environment with all the dependencies\npython -m hatch run python my_script.py\n</code></pre> <p>Warning</p> <p><code>hatch</code> will not combine nicely with other environment managers such Conda. If you want to use Conda, install it from source using <code>pip</code>:</p> <pre><code># within the Conda environment\npython -m pip install -e .\n</code></pre>"},{"location":"#citation","title":"Citation","text":"<p>If you use Qadence for a publication, we kindly ask you to cite our work using the following BibTex entry:</p> <pre><code>@misc{qadence2023pasqal,\n  url = {https://github.com/pasqal-io/qadence},\n  title = {Qadence: {A} {D}igital-analog quantum programming interface.},\n  year = {2023}\n}\n</code></pre>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CONTRIBUTING/","title":"How to contribute","text":"<p>We're grateful for your interest in participating in Qadence. Please follow our guidelines to ensure a smooth contribution process.</p>"},{"location":"CONTRIBUTING/#reporting-an-issue-or-proposing-a-feature","title":"Reporting an issue or proposing a feature","text":"<p>Your course of action will depend on your objective, but generally, you should start by creating an issue. If you've discovered a bug or have a feature you'd like to see added to qadence, feel free to create an issue on qadence's GitHub issue tracker. Here are some steps to take:</p> <ol> <li>Quickly search the existing issues using relevant keywords to ensure your issue hasn't been addressed already.</li> <li> <p>If your issue is not listed, create a new one. Try to be as detailed and clear as possible in your description.</p> </li> <li> <p>If you're merely suggesting an improvement or reporting a bug, that's already excellent! We thank you for it. Your issue will be listed and, hopefully, addressed at some point.</p> </li> <li>However, if you're willing to be the one solving the issue, that would be even better! In such instances, you would proceed by preparing a Pull Request.</li> </ol>"},{"location":"CONTRIBUTING/#submitting-a-pull-request","title":"Submitting a pull request","text":"<p>We're excited that you're eager to contribute to Qadence. To contribute, fork the <code>main</code> branch of qadence repository and once you are satisfied with your feature and all the tests pass create a Pull Request.</p> <p>Here's the process for making a contribution:</p> <p>Click the \"Fork\" button at the upper right corner of the repo page to create a new GitHub repo at <code>https://github.com/USERNAME/qadence</code>, where <code>USERNAME</code> is your GitHub ID. Then, <code>cd</code> into the directory where you want to place your new fork and clone it:</p> <pre><code>git clone https://github.com/USERNAME/qadence.git\n</code></pre> <p>Next, navigate to your new qadence fork directory and mark the main qadence repository as the <code>upstream</code>:</p> <pre><code>git remote add upstream https://github.com/pasqal-io/qadence.git\n</code></pre>"},{"location":"CONTRIBUTING/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>We recommended to use <code>hatch</code> for managing environments:</p> <p>To develop within qadence, use: <pre><code>pip install hatch\nhatch -v shell\n</code></pre></p> <p>To run qadence tests, use:</p> <pre><code>hatch -e tests run test\n</code></pre> <p>If you don't want to use <code>hatch</code>, you can use the environment manager of your choice (e.g. Conda) and execute the following:</p> <pre><code>pip install pytest\npip install -e .\npytest\n</code></pre>"},{"location":"CONTRIBUTING/#useful-things-for-your-workflow-linting-and-testing","title":"Useful things for your workflow: linting and testing","text":"<p>Use <code>pre-commit</code> to lint your code and run the unit tests before pushing a new commit.</p> <p>Using <code>hatch</code>, it's simply:</p> <pre><code>hatch -e tests run pre-commit run --all-files\nhatch -e tests run test\n</code></pre> <p>Our CI/CD pipeline will also test if the documentation can be built correctly. To test it locally, please run:</p> <pre><code>hatch -e docs run mkdocs build --clean --strict\n</code></pre> <p>Without <code>hatch</code>, <code>pip</code> install those libraries first: \"mkdocs\", \"mkdocs-material\", \"mkdocstrings\", \"mkdocstrings-python\", \"mkdocs-section-index\", \"mkdocs-jupyter\", \"mkdocs-exclude\", \"markdown-exec\"</p> <p>And then:</p> <pre><code> mkdocs build --clean --strict\n</code></pre>"},{"location":"models/","title":"Quantum models","text":""},{"location":"models/#qadence.models.quantum_model.QuantumModel","title":"<code>QuantumModel(circuit, observable=None, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, protocol=None, configuration=None)</code>","text":"<p>             Bases: <code>Module</code></p> <p>The central class of qadence that executes <code>QuantumCircuit</code>s and make them differentiable.</p> <p>This class should be used as base class for any new quantum model supported in the qadence framework for information on the implementation of custom models see here.</p> <p>Initialize a generic QuantumModel instance.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>The circuit that is executed.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>observable</code> <p>Optional observable(s) that are used only in the <code>expectation</code> method. You can also provide observables on the fly to the expectation call directly.</p> <p> TYPE: <code>list[AbstractBlock] | AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>A backend for circuit execution.</p> <p> TYPE: <code>BackendName | str</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>A differentiability mode. Parameter shift based modes work on all backends. AD based modes only on PyTorch based backends.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>protocol</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>Configuration for the backend.</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if the <code>diff_mode</code> argument is set to None</p> Source code in <code>qadence/models/quantum_model.py</code> <pre><code>def __init__(\nself,\ncircuit: QuantumCircuit,\nobservable: list[AbstractBlock] | AbstractBlock | None = None,\nbackend: BackendName | str = BackendName.PYQTORCH,\ndiff_mode: DiffMode = DiffMode.AD,\nprotocol: Measurements | None = None,\nconfiguration: BackendConfiguration | dict | None = None,\n):\n\"\"\"Initialize a generic QuantumModel instance.\n    Arguments:\n        circuit: The circuit that is executed.\n        observable: Optional observable(s) that are used only in the `expectation` method. You\n            can also provide observables on the fly to the expectation call directly.\n        backend: A backend for circuit execution.\n        diff_mode: A differentiability mode. Parameter shift based modes work on all backends.\n            AD based modes only on PyTorch based backends.\n        protocol: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        configuration: Configuration for the backend.\n    Raises:\n        ValueError: if the `diff_mode` argument is set to None\n    \"\"\"\nsuper().__init__()\nif not isinstance(circuit, QuantumCircuit):\nTypeError(\nf\"The circuit should be of type '&lt;class QuantumCircuit&gt;'. Got {type(circuit)}.\"\n)\nself.inputs = [p for p in circuit.unique_parameters if not p.trainable and not p.is_number]\nif diff_mode is None:\nraise ValueError(\"`diff_mode` cannot be `None` in a `QuantumModel`.\")\nself.backend = backend_factory(\nbackend=backend, diff_mode=diff_mode, configuration=configuration\n)\nif isinstance(observable, list) or observable is None:\nobservable = observable\nelse:\nobservable = [observable]\nconv = self.backend.convert(circuit, observable)\nself.embedding_fn = conv.embedding_fn\nself._circuit = conv.circuit\nself._observable = conv.observable\nself._backend_name = backend\nself._diff_mode = diff_mode\nself._protocol = protocol\nself._params = nn.ParameterDict(\n{\nstr(key): nn.Parameter(val, requires_grad=val.requires_grad)\nfor key, val in conv.params.items()\n}\n)\n</code></pre>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.in_features","title":"<code>in_features: int</code>  <code>property</code>","text":"<p>Number of inputs.</p>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.num_vparams","title":"<code>num_vparams: int</code>  <code>property</code>","text":"<p>The number of variational parameters</p>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.out_features","title":"<code>out_features: int | None</code>  <code>property</code>","text":"<p>Number of outputs</p>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.vals_vparams","title":"<code>vals_vparams: Tensor</code>  <code>property</code>","text":"<p>Dictionary with parameters which are actually updated during optimization</p>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.assign_parameters","title":"<code>assign_parameters(values)</code>","text":"<p>Return the final, assigned circuit that is used in e.g. <code>backend.run</code></p> Source code in <code>qadence/models/quantum_model.py</code> <pre><code>def assign_parameters(self, values: dict[str, Tensor]) -&gt; Any:\n\"\"\"Return the final, assigned circuit that is used in e.g. `backend.run`\"\"\"\nparams = self.embedding_fn(self._params, values)\nreturn self.backend.assign_parameters(self._circuit, params)\n</code></pre>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.expectation","title":"<code>expectation(values={}, observable=None, state=None, protocol=None, endianness=Endianness.BIG)</code>","text":"<p>Compute expectation using the given backend.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor of shape n_batches x n_obs</p> Source code in <code>qadence/models/quantum_model.py</code> <pre><code>def expectation(\nself,\nvalues: dict[str, Tensor] = {},\nobservable: list[ConvertedObservable] | ConvertedObservable | None = None,\nstate: Optional[Tensor] = None,\nprotocol: Measurements | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Compute expectation using the given backend.\n    Returns:\n        A torch.Tensor of shape n_batches x n_obs\n    \"\"\"\nif observable is None:\nif self._observable is None:\nraise ValueError(\n\"Provide an AbstractBlock as the observable to compute expectation.\"\n\"Either pass a 'native_observable' directly to 'QuantumModel.expectation'\"\n\"or pass a (non-native) '&lt;class AbstractBlock&gt;' to the 'QuantumModel.__init__'.\"\n)\nobservable = self._observable\nparams = self.embedding_fn(self._params, values)\nif protocol is None:\nprotocol = self._protocol\nreturn self.backend.expectation(\ncircuit=self._circuit,\nobservable=observable,\nparam_values=params,\nstate=state,\nprotocol=protocol,\nendianness=endianness,\n)\n</code></pre>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.reset_vparams","title":"<code>reset_vparams(values)</code>","text":"<p>Reset all the variational parameters with a given list of values</p> Source code in <code>qadence/models/quantum_model.py</code> <pre><code>def reset_vparams(self, values: Sequence) -&gt; None:\n\"\"\"Reset all the variational parameters with a given list of values\"\"\"\ncurrent_vparams = OrderedDict({k: v for k, v in self._params.items() if v.requires_grad})\nassert (\nlen(values) == self.num_vparams\n), \"Pass an iterable with the values of all variational parameters\"\nfor i, k in enumerate(current_vparams.keys()):\ncurrent_vparams[k].data = torch.tensor([values[i]])\n</code></pre>"},{"location":"models/#qadence.models.qnn.QNN","title":"<code>QNN(circuit, observable, transform=None, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, protocol=None, configuration=None)</code>","text":"<p>             Bases: <code>QuantumModel</code></p> <p>Quantum neural network model for n-dimensional inputs</p> <p>Examples: <pre><code>import torch\nfrom qadence import QuantumCircuit, QNN\nfrom qadence import hea, feature_map, hamiltonian_factory, Z\n# create the circuit\nn_qubits, depth = 2, 4\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nobs_base = hamiltonian_factory(n_qubits, detuning = Z)\n# the QNN will yield two outputs\nobs = [2.0 * obs_base, 4.0 * obs_base]\n# initialize and use the model\nqnn = QNN(circuit, obs, diff_mode=\"ad\", backend=\"pyqtorch\")\ny = qnn.expectation({\"phi\": torch.rand(3)})\n</code></pre> <pre><code>tensor([[0.7110, 1.4221],\n[1.6172, 3.2344],\n[1.1616, 2.3231]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> </p> <p>Initialize the QNN</p> <p>The number of inputs is determined by the feature parameters in the input quantum circuit while the number of outputs is determined by how many observables are provided as input</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>The quantum circuit to use for the QNN.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>transform</code> <p>A transformation applied to the output of the QNN.</p> <p> TYPE: <code>Callable[[Tensor], Tensor]</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>protocol</code> <p>optional measurement protocol. If None, use exact expectation value with a statevector simulator</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>optional configuration for the backend</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/models/qnn.py</code> <pre><code>def __init__(\nself,\ncircuit: QuantumCircuit,\nobservable: list[AbstractBlock] | AbstractBlock,\ntransform: Callable[[Tensor], Tensor] = None,  # transform output of the QNN\nbackend: BackendName = BackendName.PYQTORCH,\ndiff_mode: DiffMode = DiffMode.AD,\nprotocol: Measurements | None = None,\nconfiguration: BackendConfiguration | dict | None = None,\n):\n\"\"\"Initialize the QNN\n    The number of inputs is determined by the feature parameters in the input\n    quantum circuit while the number of outputs is determined by how many\n    observables are provided as input\n    Args:\n        circuit: The quantum circuit to use for the QNN.\n        transform: A transformation applied to the output of the QNN.\n        backend: The chosen quantum backend.\n        diff_mode: The differentiation engine to use. Choices 'gpsr' or 'ad'.\n        protocol: optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator\n        configuration: optional configuration for the backend\n    \"\"\"\nsuper().__init__(\ncircuit=circuit,\nobservable=observable,\nbackend=backend,\ndiff_mode=diff_mode,\nprotocol=protocol,\nconfiguration=configuration,\n)\nif self.out_features is None:\nraise ValueError(\"You need to provide at least one observable in the QNN constructor\")\nself.transform = transform if transform else lambda x: x\n</code></pre>"},{"location":"models/#qadence.models.qnn.QNN.forward","title":"<code>forward(values=None, state=None, protocol=None, endianness=Endianness.BIG)</code>","text":"<p>Forward pass of the model</p> <p>This returns the (differentiable) expectation value of the given observable operator defined in the constructor. Differently from the base QuantumModel class, the QNN accepts also a tensor as input for the forward pass. The tensor is expected to have shape: <code>n_batches x in_features</code> where <code>n_batches</code> is the number of data points and <code>in_features</code> is the dimensionality of the problem</p> <p>The output of the forward pass is the expectation value of the input observable(s). If a single observable is given, the output shape is <code>n_batches</code> while if multiple observables are given the output shape is instead <code>n_batches x n_observables</code></p> PARAMETER  DESCRIPTION <code>values</code> <p>the values of the feature parameters</p> <p> TYPE: <code>dict[str, Tensor] | Tensor</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a tensor with the expectation value of the observables passed in the constructor of the model</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/models/qnn.py</code> <pre><code>def forward(\nself,\nvalues: dict[str, Tensor] | Tensor = None,\nstate: Tensor | None = None,\nprotocol: Measurements | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Forward pass of the model\n    This returns the (differentiable) expectation value of the given observable\n    operator defined in the constructor. Differently from the base QuantumModel\n    class, the QNN accepts also a tensor as input for the forward pass. The\n    tensor is expected to have shape: `n_batches x in_features` where `n_batches`\n    is the number of data points and `in_features` is the dimensionality of the problem\n    The output of the forward pass is the expectation value of the input\n    observable(s). If a single observable is given, the output shape is\n    `n_batches` while if multiple observables are given the output shape\n    is instead `n_batches x n_observables`\n    Args:\n        values (dict[str, Tensor] | Tensor): the values of the feature parameters\n    Returns:\n        Tensor: a tensor with the expectation value of the observables passed\n            in the constructor of the model\n    \"\"\"\nif values is None:\nvalues = {}\nif not isinstance(values, dict):\nvalues = self._format_to_dict(values)\nif protocol is None:\nprotocol = self._protocol\nreturn self.transform(\nself.expectation(values=values, state=state, protocol=protocol, endianness=endianness)\n)\n</code></pre>"},{"location":"advanced_tutorials/custom-models/","title":"Custom quantum models","text":"<p>In <code>qadence</code>, the <code>QuantumModel</code> is the central class point for executing <code>QuantumCircuit</code>s.  The idea of a <code>QuantumModel</code> is to decouple the backend execution from the management of circuit parameters and desired quantum computation output.</p> <p>In the following, we create a custom <code>QuantumModel</code> instance which introduces some additional optimizable parameters: *  an adjustable scaling factor in front of the observable to measured *  adjustable scale and shift factors to be applied to the model output before returning the result</p> <p>This can be easily done using PyTorch flexible model definition, and it will automatically work with the rest of <code>qadence</code> infrastructure.</p> <pre><code>import torch\nfrom qadence import QuantumModel, QuantumCircuit\nclass CustomQuantumModel(QuantumModel):\ndef __init__(self, circuit: QuantumCircuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\"):\nsuper().__init__(circuit, observable=observable, backend=backend, diff_mode=diff_mode)\nself.n_qubits = circuit.n_qubits\n# define some additional parameters which will scale and shift (variationally) the\n# output of the QuantumModel\n# you can use all torch machinery for building those\nself.scale_out = torch.nn.Parameter(torch.ones(1))\nself.shift_out = torch.nn.Parameter(torch.ones(1))\n# override the forward pass of the model\n# the forward pass is the output of your QuantumModel and in this case\n# it's the (scaled) expectation value of the total magnetization with\n# a variable coefficient in front\ndef forward(self, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\n# scale the observable\nres = self.expectation(values)\n# scale and shift the result before returning\nreturn self.shift_out + res * self.scale_out\n</code></pre> <p>The custom model can be used like any other <code>QuantumModel</code>: <pre><code>from qadence import Parameter, RX, CNOT, QuantumCircuit\nfrom qadence import chain, kron, hamiltonian_factory, Z\nfrom sympy import acos\ndef quantum_circuit(n_qubits):\nx = Parameter(\"x\", trainable=False)\nfm = kron(RX(i, acos(x) * (i+1)) for i in range(n_qubits))\nansatz = kron(RX(i, f\"theta{i}\") for i in range(n_qubits))\nansatz = chain(ansatz, CNOT(0, n_qubits-1))\nblock = chain(fm, ansatz)\nblock.tag = \"circuit\"\nreturn QuantumCircuit(n_qubits, block)\nn_qubits = 4\nbatch_size = 10\ncircuit = quantum_circuit(n_qubits)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)  # Total magnetization\nmodel = CustomQuantumModel(circuit, observable, backend=\"pyqtorch\")\nvalues = {\"x\": torch.rand(batch_size)}\nres = model(values)\nprint(\"Model output: \", res)\nassert len(res) == batch_size\n</code></pre> <pre><code>Model output:  tensor([[ 1.0910],\n[-0.3106],\n[-0.0326],\n[-0.2145],\n[-0.1543],\n[-0.5374],\n[-0.5529],\n[-0.0691],\n[-0.0888],\n[-0.4947]], grad_fn=&lt;AddBackward0&gt;)\n</code></pre> </p>"},{"location":"advanced_tutorials/custom-models/#quantum-model-with-wavefunction-overlaps","title":"Quantum model with wavefunction overlaps","text":"<p><code>QuantumModel</code>'s can also use different quantum operations in their forward pass, such as wavefunction overlaps described here. Beware that the resulting overlap tensor has to be differentiable to apply gradient-based optimization. This is only applicable to the <code>\"EXACT\"</code> overlap method.</p> <p>Here we show how to use overlap calculation when fitting a parameterized quantum circuit to act as a standard Hadamard gate.</p> <pre><code>from qadence import RY, RX, H, Overlap\n# create a quantum model which acts as an Hadamard gate after training\nclass LearnHadamard(QuantumModel):\ndef __init__(\nself,\ntrain_circuit: QuantumCircuit,\ntarget_circuit: QuantumCircuit,\nbackend=\"pyqtorch\",\n):\nsuper().__init__(circuit=train_circuit, backend=backend)\nself.overlap_fn = Overlap(train_circuit, target_circuit, backend=backend, method=\"exact\", diff_mode='ad')\ndef forward(self):\nreturn self.overlap_fn()\n# compute the wavefunction of the associated train circuit\ndef wavefunction(self):\nreturn model.overlap_fn.run({})\ntrain_circuit = QuantumCircuit(1, chain(RX(0, \"phi\"), RY(0, \"theta\")))\ntarget_circuit = QuantumCircuit(1, H(0))\nmodel = LearnHadamard(train_circuit, target_circuit)\n# get the overlap between model and target circuit wavefunctions\nprint(model())\n</code></pre> <pre><code>tensor([[0.5337]], grad_fn=&lt;UnsqueezeBackward0&gt;)\n</code></pre> <p>This model can then be trained with the standard Qadence helper functions.</p> <pre><code>from qadence import run\nfrom qadence.ml_tools import train_with_grad, TrainConfig\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\ndef loss_fn(model: LearnHadamard, _unused) -&gt; tuple[torch.Tensor, dict]:\nloss = criterion(torch.tensor([[1.0]]), model())\nreturn loss, {}\nconfig = TrainConfig(max_iter=2500)\nmodel, optimizer = train_with_grad(\nmodel, None, optimizer, config, loss_fn=loss_fn\n)\nwf_target = run(target_circuit)\nassert torch.allclose(wf_target, model.wavefunction(), atol=1e-2)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"advanced_tutorials/differentiability/","title":"Differentiability","text":"<p>Many application in quantum computing and quantum machine learning more specifically requires the differentiation of a quantum circuit with respect to its parameters.</p> <p>In Qadence, we perform quantum computations via the <code>QuantumModel</code> interface. The derivative of the outputs of quantum models with respect to feature and variational parameters in the quantum circuit can be implemented in Qadence with two different modes:</p> <ul> <li>Automatic differentiation (AD) mode <sup>1</sup>. This mode allows to differentiation both <code>run()</code> and <code>expectation()</code> methods of the <code>QuantumModel</code> and it is the fastest available differentiation method. Under the hood, it is based on the PyTorch autograd engine wrapped by the <code>DifferentiableBackend</code> class. This mode is not working on quantum devices.</li> <li>Generalized parameter shift rule (GPSR) mode. This is general implementation of the well known parameter  shift rule algorithm <sup>2</sup> which works for arbitrary quantum operations <sup>3</sup>. This mode is only applicable to  the <code>expectation()</code> method of <code>QuantumModel</code> but it is compatible with execution or quantum devices.</li> </ul>"},{"location":"advanced_tutorials/differentiability/#automatic-differentiation","title":"Automatic differentiation","text":"<p>Automatic differentiation <sup>1</sup> is a procedure to derive a complex function defined as a sequence of elementary mathematical operations in the form of a computer program. Automatic differentiation is a cornerstone of modern machine learning and a crucial ingredient of its recent successes. In its so-called reverse mode, it follows this sequence of operations in reverse order by systematically applying the chain rule to recover the exact value of derivative. Reverse mode automatic differentiation is implemented in Qadence leveraging the PyTorch <code>autograd</code> engine.</p> <p>Only available with PyQTorch backend</p> <p>Currently, automatic differentiation mode is only available when the <code>pyqtorch</code> backend is selected.</p>"},{"location":"advanced_tutorials/differentiability/#generalized-parameter-shift-rule","title":"Generalized parameter shift rule","text":"<p>The generalized parameter shift rule implementation in Qadence was introduced in <sup>3</sup>. Here the standard parameter shift rules, which only works for quantum operations whose generator has a single gap in its eigenvalue spectrum, was generalized to work with arbitrary generators of quantum operations.</p> <p>For this, we define the differentiable function as quantum expectation value</p> \\[ f(x) = \\left\\langle 0\\right|\\hat{U}^{\\dagger}(x)\\hat{C}\\hat{U}(x)\\left|0\\right\\rangle \\] <p>where \\(\\hat{U}(x)={\\rm exp}{\\left( -i\\frac{x}{2}\\hat{G}\\right)}\\) is the quantum evolution operator with generator \\(\\hat{G}\\) representing the structure of the underlying quantum circuit and \\(\\hat{C}\\) is the cost operator. Then using the eigenvalue spectrum \\(\\left\\{ \\lambda_n\\right\\}\\) of the generator \\(\\hat{G}\\) we calculate the full set of corresponding unique non-zero spectral gaps \\(\\left\\{ \\Delta_s\\right\\}\\) (differences between eigenvalues). It can be shown that the final expression of derivative of \\(f(x)\\) is then given by the following expression:</p> <p>\\(\\begin{equation} \\frac{{\\rm d}f\\left(x\\right)}{{\\rm d}x}=\\overset{S}{\\underset{s=1}{\\sum}}\\Delta_{s}R_{s}, \\end{equation}\\)</p> <p>where \\(S\\) is the number of unique non-zero spectral gaps and \\(R_s\\) are real quantities that are solutions of a system of linear equations</p> <p>\\(\\begin{equation} \\begin{cases} F_{1} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{1}\\Delta_{s}}{2}\\right)R_{s},\\\\ F_{2} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{2}\\Delta_{s}}{2}\\right)R_{s},\\\\  &amp; ...\\\\ F_{S} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{M}\\Delta_{s}}{2}\\right)R_{s}. \\end{cases} \\end{equation}\\)</p> <p>Here \\(F_s=f(x+\\delta_s)-f(x-\\delta_s)\\) denotes the difference between values of functions evaluated at shifted arguments \\(x\\pm\\delta_s\\).</p>"},{"location":"advanced_tutorials/differentiability/#usage","title":"Usage","text":""},{"location":"advanced_tutorials/differentiability/#basics","title":"Basics","text":"<p>In Qadence, the GPSR differentiation engine can be selected by passing <code>diff_mode=\"gpsr\"</code> or, equivalently, <code>diff_mode=DiffMode.GPSR</code> to a <code>QuantumModel</code> instance. The code in the box below shows how to create <code>QuantumModel</code> instances with both AD and GPSR engines.</p> <pre><code>from qadence import (FeatureParameter, HamEvo, X, I, Z,\nhamiltonian_factory, QuantumCircuit,\nQuantumModel, BackendName, DiffMode)\nimport torch\nn_qubits = 2\n# define differentiation parameter\nx = FeatureParameter(\"x\")\n# define generator and HamEvo block\ngenerator = X(0) + X(1) + 0.2 * (Z(0) + I(1)) * (I(0) + Z(1))\nblock = HamEvo(generator, x)\n# create quantum circuit\ncircuit = QuantumCircuit(n_qubits, block)\n# create total magnetization cost operator\nobs = hamiltonian_factory(n_qubits, detuning=Z)\n# create models with AD and GPSR differentiation engines\nmodel_ad = QuantumModel(circuit, obs,\nbackend=BackendName.PYQTORCH,\ndiff_mode=DiffMode.AD)\nmodel_gpsr = QuantumModel(circuit, obs,\nbackend=BackendName.PYQTORCH,\ndiff_mode=DiffMode.GPSR)\n# generate value for circuit's parameter\nxs = torch.linspace(0, 2*torch.pi, 100, requires_grad=True)\nvalues = {\"x\": xs}\n# calculate function f(x)\nexp_val_ad = model_ad.expectation(values)\nexp_val_gpsr = model_gpsr.expectation(values)\n# calculate derivative df/dx using the PyTorch\n# autograd engine\ndexpval_x_ad = torch.autograd.grad(\nexp_val_ad, values[\"x\"], torch.ones_like(exp_val_ad), create_graph=True\n)[0]\ndexpval_x_gpsr = torch.autograd.grad(\nexp_val_gpsr, values[\"x\"], torch.ones_like(exp_val_gpsr), create_graph=True\n)[0]\n</code></pre> <p>We can plot the resulting derivatives and see that in both cases they coincide.</p> <pre><code>import matplotlib.pyplot as plt\n# plot f(x) and df/dx derivatives calculated using AD and GPSR\n# differentiation engines\nfig, ax = plt.subplots()\nax.scatter(xs.detach().numpy(),\nexp_val_ad.detach().numpy(),\nlabel=\"f(x)\")\nax.scatter(xs.detach().numpy(),\ndexpval_x_ad.detach().numpy(),\nlabel=\"df/dx AD\")\nax.scatter(xs.detach().numpy(),\ndexpval_x_gpsr.detach().numpy(),\ns=5,\nlabel=\"df/dx GPSR\")\nplt.legend()\n</code></pre> 2023-10-25T16:44:30.933954 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"advanced_tutorials/differentiability/#low-level-control-on-the-shift-values","title":"Low-level control on the shift values","text":"<p>In order to get a finer control over the GPSR differentiation engine we can use the low-level Qadence API to define a <code>DifferentiableBackend</code>.</p> <pre><code>from qadence import DifferentiableBackend\nfrom qadence.backends.pyqtorch import Backend as PyQBackend\n# define differentiable quantum backend\nquantum_backend = PyQBackend()\nconv = quantum_backend.convert(circuit, obs)\npyq_circ, pyq_obs, embedding_fn, params = conv\ndiff_backend = DifferentiableBackend(quantum_backend, diff_mode=DiffMode.GPSR, shift_prefac=0.2)\n# calculate function f(x)\nexpval = diff_backend.expectation(pyq_circ, pyq_obs, embedding_fn(params, values))\n</code></pre> <p>Here we passed an additional argument <code>shift_prefac</code> to the <code>DifferentiableBackend</code> instance that governs the magnitude of shifts \\(\\delta\\equiv\\alpha\\delta^\\prime\\) shown in equation (2) above. In this relation \\(\\delta^\\prime\\) is set internally and \\(\\alpha\\) is the value passed by <code>shift_prefac</code> and the resulting shift value \\(\\delta\\) is then used in all the following GPSR calculations.</p> <p>Tuning parameter \\(\\alpha\\) is useful to improve results when the generator \\(\\hat{G}\\) or the quantum operation is a dense matrix, for example a complex <code>HamEvo</code> operation; if many entries of this matrix are sufficiently larger than 0 the operation is equivalent to a strongly interacting system. In such case parameter \\(\\alpha\\) should be gradually lowered in order to achieve exact derivative values.</p>"},{"location":"advanced_tutorials/differentiability/#references","title":"References","text":"<ol> <li> <p>A. G. Baydin et al., Automatic Differentiation in Machine Learning: a Survey \u21a9\u21a9</p> </li> <li> <p>Schuld et al., Evaluating analytic gradients on quantum hardware (2018). \u21a9</p> </li> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9\u21a9</p> </li> </ol>"},{"location":"backends/backend/","title":"Abstract backend","text":""},{"location":"backends/backend/#qadence.backend.Backend","title":"<code>Backend</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ABC</code></p> <p>The abstract class that defines the interface for the backends</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>backend unique string identifier</p> <p> TYPE: <code>BackendName</code> </p> <code>supports_ad</code> <p>whether or not the backend has a native autograd</p> <p> TYPE: <code>bool</code> </p> <code>supports_bp</code> <p>whether or not the backend has a native backprop</p> <p> TYPE: <code>bool</code> </p> <code>is_remote</code> <p>whether computations are executed locally or remotely on this backend, useful when using cloud platforms where credentials are needed for example.</p> <p> TYPE: <code>bool</code> </p> <code>with_measurements</code> <p>whether it supports counts or not</p> <p> TYPE: <code>bool</code> </p> <code>with_noise</code> <p>whether to add realistic noise or not</p> <p> TYPE: <code>bool</code> </p>"},{"location":"backends/backend/#qadence.backend.Backend.circuit","title":"<code>circuit(circuit)</code>  <code>abstractmethod</code>","text":"<p>Converts an abstract <code>QuantumCircuit</code> to the native backend representation.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A circuit, for example: <code>QuantumCircuit(2, X(0))</code></p> <p> TYPE: <code>QuantumCircuit</code> </p> RETURNS DESCRIPTION <code>ConvertedCircuit</code> <p>A converted circuit <code>c</code>. You can access the original, arbstract circuit via <code>c.abstract</code></p> <code>ConvertedCircuit</code> <p>and the converted (or backend native) circuit via <code>c.native</code>.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef circuit(self, circuit: QuantumCircuit) -&gt; ConvertedCircuit:\n\"\"\"Converts an abstract `QuantumCircuit` to the native backend representation.\n    Arguments:\n        circuit: A circuit, for example: `QuantumCircuit(2, X(0))`\n    Returns:\n        A converted circuit `c`. You can access the original, arbstract circuit via `c.abstract`\n        and the converted (or backend *native*) circuit via `c.native`.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.convert","title":"<code>convert(circuit, observable=None)</code>","text":"<p>Convert an abstract circuit (and optionally and observable) to their native representation. Additionally this function constructs an embedding function which maps from user-facing parameters to device parameters (read more on parameter embedding here).</p> Source code in <code>qadence/backend.py</code> <pre><code>def convert(\nself, circuit: QuantumCircuit, observable: list[AbstractBlock] | AbstractBlock | None = None\n) -&gt; Converted:\n\"\"\"Convert an abstract circuit (and optionally and observable) to their native\n    representation. Additionally this function constructs an embedding function which maps from\n    user-facing parameters to device parameters (read more on parameter embedding\n    [here][qadence.blocks.embedding.embedding]).\n    \"\"\"\ndef check_observable(obs_obj: Any) -&gt; AbstractBlock:\nif isinstance(obs_obj, QubitOperator):\nfrom qadence.blocks.manipulate import from_openfermion\nassert len(obs_obj.terms) &gt; 0, \"Make sure to give a non-empty qubit hamiltonian\"\nreturn from_openfermion(obs_obj)\nelif isinstance(obs_obj, (CompositeBlock, PrimitiveBlock, ScaleBlock)):\nfrom qadence.blocks.utils import block_is_qubit_hamiltonian\nassert block_is_qubit_hamiltonian(\nobs_obj\n), \"Make sure the QubitHamiltonian consists only of Pauli operators X, Y, Z, I\"\nreturn obs_obj\nraise TypeError(\n\"qubit_hamiltonian should be a Pauli-like AbstractBlock or a QubitOperator\"\n)\nconv_circ = self.circuit(circuit)\ncirc_params, circ_embedding_fn = embedding(\nconv_circ.abstract.block, self.config._use_gate_params\n)\nparams = circ_params\nif observable is not None:\nobservable = observable if isinstance(observable, list) else [observable]\nconv_obs = []\nobs_embedding_fn_list = []\nfor obs in observable:\nobs = check_observable(obs)\nc_obs = self.observable(obs, max(circuit.n_qubits, obs.n_qubits))\nobs_params, obs_embedding_fn = embedding(\nc_obs.abstract, self.config._use_gate_params\n)\nparams.update(obs_params)\nobs_embedding_fn_list.append(obs_embedding_fn)\nconv_obs.append(c_obs)\ndef embedding_fn_dict(a: dict, b: dict) -&gt; dict:\nembedding_dict = circ_embedding_fn(a, b)\nfor o in obs_embedding_fn_list:\nembedding_dict.update(o(a, b))\nreturn embedding_dict\nreturn Converted(conv_circ, conv_obs, embedding_fn_dict, params)\ndef embedding_fn(a: dict, b: dict) -&gt; dict:\nreturn circ_embedding_fn(a, b)\nreturn Converted(conv_circ, None, embedding_fn, params)\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, protocol=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Compute the expectation value of the <code>circuit</code> with the given <code>observable</code>.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bitstrings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef expectation(\nself,\ncircuit: ConvertedCircuit,\nobservable: list[ConvertedObservable] | ConvertedObservable,\nparam_values: dict[str, Tensor] = {},\nstate: Tensor | None = None,\nprotocol: Measurements | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Compute the expectation value of the `circuit` with the given `observable`.\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        endianness: Endianness of the resulting bitstrings.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.observable","title":"<code>observable(observable, n_qubits)</code>  <code>abstractmethod</code>","text":"<p>Converts an abstract observable (which is just an <code>AbstractBlock</code>) to the native backend representation.</p> PARAMETER  DESCRIPTION <code>observable</code> <p>An observable.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>n_qubits</code> <p>Number of qubits the observable covers. This is typically <code>circuit.n_qubits</code>.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ConvertedObservable</code> <p>A converted observable <code>o</code>. You can access the original, arbstract observable via</p> <code>ConvertedObservable</code> <p><code>o.abstract</code> and the converted (or backend native) observable via <code>o.native</code>.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef observable(self, observable: AbstractBlock, n_qubits: int) -&gt; ConvertedObservable:\n\"\"\"Converts an abstract observable (which is just an `AbstractBlock`) to the native backend\n    representation.\n    Arguments:\n        observable: An observable.\n        n_qubits: Number of qubits the observable covers. This is typically `circuit.n_qubits`.\n    Returns:\n        A converted observable `o`. You can access the original, arbstract observable via\n        `o.abstract` and the converted (or backend *native*) observable via `o.native`.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.run","title":"<code>run(circuit, param_values={}, state=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Run a circuit and return the resulting wave function.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting samples.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A list of Counter objects where each key represents a bitstring</p> <code>Tensor</code> <p>and its value the number of times it has been sampled from the given wave function.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef run(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor] = {},\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Run a circuit and return the resulting wave function.\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        endianness: Endianness of the resulting samples.\n    Returns:\n        A list of Counter objects where each key represents a bitstring\n        and its value the number of times it has been sampled from the given wave function.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.sample","title":"<code>sample(circuit, param_values={}, n_shots=1000, state=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Sample bit strings.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>n_shots</code> <p>Number of shots to sample.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bitstrings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef sample(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor] = {},\nn_shots: int = 1000,\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n\"\"\"Sample bit strings.\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        n_shots: Number of shots to sample.\n        state: Initial state.\n        endianness: Endianness of the resulting bitstrings.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.BackendConfiguration","title":"<code>BackendConfiguration</code>  <code>dataclass</code>","text":""},{"location":"backends/backend/#qadence.backend.BackendConfiguration.available_options","title":"<code>available_options()</code>","text":"<p>Return as a string the available fields with types of the configuration</p> RETURNS DESCRIPTION <code>str</code> <p>a string with all the available fields, one per line</p> <p> TYPE: <code>str</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>def available_options(self) -&gt; str:\n\"\"\"Return as a string the available fields with types of the configuration\n    Returns:\n        str: a string with all the available fields, one per line\n    \"\"\"\nconf_msg = \"\"\nfor field in fields(self):\nif not field.name.startswith(\"_\"):\nconf_msg += (\nf\"Name: {field.name} - Type: {field.type} - Default value: {field.default}\\n\"\n)\nreturn conf_msg\n</code></pre>"},{"location":"backends/backend/#qadence.backend.BackendConfiguration.get_param_name","title":"<code>get_param_name(blk)</code>","text":"<p>Return parameter names for the current backend. Depending on which backend is in use this function returns either UUIDs or expressions of parameters.</p> Source code in <code>qadence/backend.py</code> <pre><code>def get_param_name(self, blk: AbstractBlock) -&gt; Tuple[str, ...]:\n\"\"\"Return parameter names for the current backend. Depending on which backend is in use this\n    function returns either UUIDs or expressions of parameters.\"\"\"\nparam_ids: Tuple\n# FIXME: better type hiearchy?\ntypes = (TimeEvolutionBlock, ParametricBlock, ConstantAnalogRotation, WaitBlock)\nif not isinstance(blk, types):\nraise TypeError(f\"Can not infer param name from {type(blk)}\")\nelse:\nif self._use_gate_params:\nparam_ids = tuple(blk.parameters.uuids())\nelse:\nparam_ids = tuple(map(stringify, blk.parameters.expressions()))\nreturn param_ids\n</code></pre>"},{"location":"backends/braket/","title":"Amazon Braket","text":""},{"location":"backends/braket/#braket-digital-backend","title":"Braket Digital backend","text":""},{"location":"backends/braket/#qadence.backends.braket.backend.Backend","title":"<code>Backend</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Backend</code></p>"},{"location":"backends/braket/#qadence.backends.braket.backend.Backend.assign_parameters","title":"<code>assign_parameters(circuit, param_values)</code>","text":"<p>Assign numerical values to the circuit parameters</p> Source code in <code>qadence/backends/braket/backend.py</code> <pre><code>def assign_parameters(\nself, circuit: ConvertedCircuit, param_values: dict[str, Tensor | float]\n) -&gt; BraketCircuit:\n\"\"\"Assign numerical values to the circuit parameters\"\"\"\nif param_values is None:\nreturn circuit.native()\nparams_copy = param_values.copy()\npnames = [p.name for p in circuit.native.parameters]\n# account for fixed parameters\nfor name in param_values.keys():\nif name not in pnames:\nparams_copy.pop(name)\n# make sure that all the parameters are single floats\n# otherwise it won't be accepted by Braket\nnative_params = promote_parameters(params_copy)\n# assign the parameters to the circuit\nassigned_circuit = circuit.native(**native_params)\nreturn assigned_circuit\n</code></pre>"},{"location":"backends/braket/#qadence.backends.braket.backend.Backend.run","title":"<code>run(circuit, param_values={}, state=None, endianness=Endianness.BIG)</code>","text":"<p>Execute the circuit and return a wavefunction in form of a statevector.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>The circuit that is executed.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Parameters of the circuit (after calling the embedding function on the user-facing parameters).</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>The endianness of the wave function.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backends/braket/backend.py</code> <pre><code>def run(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor] = {},\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"\n    Execute the circuit and return a wavefunction in form of a statevector.\n    Arguments:\n        circuit: The circuit that is executed.\n        param_values: Parameters of the circuit (after calling the embedding\n            function on the user-facing parameters).\n        state: Initial state.\n        endianness: The endianness of the wave function.\n    \"\"\"\nif state is not None:\nraise NotImplementedError\nif self.is_remote:\n# handle here, or different backends?\nraise NotImplementedError\n# loop over all values in the batch\nresults = []\nfor vals in to_list_of_dicts(param_values):\nfinal_circuit = self.assign_parameters(circuit, vals)\nfinal_circuit.state_vector()  # set simulation type\ntask = self._device.run(final_circuit, 0)\nresults.append(task.result().values[0])\nstates = torch.tensor(np.array(results))\nn_qubits = circuit.abstract.n_qubits\nif endianness != self.native_endianness and n_qubits &gt; 1:\nfrom qadence.transpile import invert_endianness\nstates = invert_endianness(states)\nreturn states\n</code></pre>"},{"location":"backends/braket/#qadence.backends.braket.backend.Backend.sample","title":"<code>sample(circuit, param_values={}, n_shots=1, state=None, endianness=Endianness.BIG)</code>","text":"<p>Execute the circuit and return samples of the resulting wavefunction.</p> Source code in <code>qadence/backends/braket/backend.py</code> <pre><code>def sample(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor] = {},\nn_shots: int = 1,\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n\"\"\"Execute the circuit and return samples of the resulting wavefunction.\"\"\"\nif state is not None:\nraise NotImplementedError(\"Braket cannot handle a custom initial state.\")\nif n_shots &lt; 1:\nraise ValueError(\"You can only call sample with n_shots&gt;0.\")\nif self.is_remote:\n# handle here, or different backends?\nraise NotImplementedError\n# loop over all values in the batch\nsamples = []\nfor vals in to_list_of_dicts(param_values):\nfinal_circuit = self.assign_parameters(circuit, vals)\ntask = self._device.run(final_circuit, n_shots)\nsamples.append(task.result().measurement_counts)\nif endianness != self.native_endianness:\nfrom qadence.transpile import invert_endianness\nsamples = invert_endianness(samples)\nreturn samples\n</code></pre>"},{"location":"backends/differentiable/","title":"DifferentiableBackend","text":""},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableBackend","title":"<code>DifferentiableBackend(backend, diff_mode=DiffMode.AD, **psr_args)</code>","text":"<p>             Bases: <code>Module</code></p> <p>A class to abstract the operations done by the autodiff engine</p> PARAMETER  DESCRIPTION <code>backend</code> <p>An instance of the QuantumBackend type perform execution.</p> <p> TYPE: <code>Backend</code> </p> <code>diff_mode</code> <p>A differentiable mode supported by the differentiation engine.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>**psr_args</code> <p>Arguments that will be passed on to <code>DifferentiableExpectation</code>.</p> <p> TYPE: <code>int | float | None</code> DEFAULT: <code>{}</code> </p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>def __init__(\nself,\nbackend: QuantumBackend,\ndiff_mode: DiffMode = DiffMode.AD,\n**psr_args: int | float | None,\n) -&gt; None:\nsuper().__init__()\nself.backend = backend\nself.diff_mode = diff_mode\nself.psr_args = psr_args\n# TODO: Add differentiable overlap calculation\nself._overlap: Callable = None  # type: ignore [assignment]\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableBackend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, protocol=None, endianness=Endianness.BIG)</code>","text":"<p>Compute the expectation value of a given observable.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A backend native quantum circuit to be executed.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>observable</code> <p>A backend native observable to compute the expectation value from.</p> <p> TYPE: <code>list[ConvertedObservable] | ConvertedObservable</code> </p> <code>param_values</code> <p>A dict of values for symbolic substitution.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>An initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>protocol</code> <p>A shot-based measurement protocol.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the state.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A tensor of expectation values.</p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>def expectation(\nself,\ncircuit: ConvertedCircuit,\nobservable: list[ConvertedObservable] | ConvertedObservable,\nparam_values: dict[str, Tensor] = {},\nstate: Tensor | None = None,\nprotocol: Measurements | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Compute the expectation value of a given observable.\n    Arguments:\n        circuit: A backend native quantum circuit to be executed.\n        observable: A backend native observable to compute the expectation value from.\n        param_values: A dict of values for symbolic substitution.\n        state: An initial state.\n        protocol: A shot-based measurement protocol.\n        endianness: Endianness of the state.\n    Returns:\n        A tensor of expectation values.\n    \"\"\"\nobservable = observable if isinstance(observable, list) else [observable]\ndifferentiable_expectation = DifferentiableExpectation(\nbackend=self.backend,\ncircuit=circuit,\nobservable=observable,\nparam_values=param_values,\nstate=state,\nprotocol=protocol,\nendianness=endianness,\n)\nif self.diff_mode == DiffMode.AD:\nexpectation = differentiable_expectation.ad\nelse:\ntry:\nfns = get_gpsr_fns()\npsr_fn = fns[self.diff_mode]\nexcept KeyError:\nraise ValueError(f\"{self.diff_mode} differentiation mode is not supported\")\nexpectation = partial(differentiable_expectation.psr, psr_fn=psr_fn, **self.psr_args)\nreturn expectation()\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableBackend.run","title":"<code>run(circuit, param_values={}, state=None, endianness=Endianness.BIG)</code>","text":"<p>Run on the underlying backend.</p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>def run(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict = {},\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Run on the underlying backend.\"\"\"\nreturn self.backend.run(\ncircuit=circuit, param_values=param_values, state=state, endianness=endianness\n)\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableBackend.sample","title":"<code>sample(circuit, param_values, state=None, n_shots=1, endianness=Endianness.BIG)</code>","text":"<p>Sample bitstring from the registered circuit.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A backend native quantum circuit to be executed.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>The values of the parameters after embedding</p> <p> TYPE: <code>dict[str, Tensor]</code> </p> <code>n_shots</code> <p>The number of shots. Defaults to 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>list[Counter]</code> <p>An iterable with all the sampled bitstrings</p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>def sample(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor],\nstate: Tensor | None = None,\nn_shots: int = 1,\nendianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n\"\"\"Sample bitstring from the registered circuit.\n    Arguments:\n        circuit: A backend native quantum circuit to be executed.\n        param_values: The values of the parameters after embedding\n        n_shots: The number of shots. Defaults to 1.\n    Returns:\n        An iterable with all the sampled bitstrings\n    \"\"\"\nwith torch.no_grad():\nreturn self.backend.sample(\ncircuit=circuit,\nparam_values=param_values,\nstate=state,\nn_shots=n_shots,\nendianness=endianness,\n)\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableExpectation","title":"<code>DifferentiableExpectation</code>  <code>dataclass</code>","text":"<p>A handler for differentiating expectation estimation using various engines.</p>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableExpectation.construct_rules","title":"<code>construct_rules(circuit, observable, psr_fn, **psr_args)</code>  <code>staticmethod</code>","text":"<p>Create a mapping between parameters and PSR functions.</p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>@staticmethod\ndef construct_rules(\ncircuit: QuantumCircuit,\nobservable: list[AbstractBlock],\npsr_fn: Callable,\n**psr_args: int | float | None,\n) -&gt; dict[str, Callable]:\n\"\"\"Create a mapping between parameters and PSR functions.\"\"\"\nuuid_to_eigs = uuid_to_eigen(circuit.block)\n# We currently rely on implicit ordering to match the PSR to the parameter,\n# because we want to cache PSRs.\nparam_to_psr = OrderedDict()\nfor param_id, eigenvalues in uuid_to_eigs.items():\nif eigenvalues is None:\nraise ValueError(\nf\"Eigenvalues are not defined for param_id {param_id}\\n\"\n# f\"of type {type(block)}.\\n\"\n\"PSR cannot be defined in that case.\"\n)\nparam_to_psr[param_id] = psr_fn(eigenvalues, **psr_args)\nfor obs in observable:\nfor param_id, _ in uuid_to_eigen(obs).items():\n# We need the embedded fixed params of the observable in the param_values dict\n# to be able to call expectation. Since torch backward requires\n# a list of param_ids and values of equal length, we need to pass them to PSR too.\n# Since they are constants their gradients are 0.\nparam_to_psr[param_id] = lambda x: torch.tensor([0.0], requires_grad=False)\nreturn param_to_psr\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.PSRExpectation","title":"<code>PSRExpectation</code>","text":"<p>             Bases: <code>Function</code></p> <p>Overloads the PyTorch AD system to perform parameter shift rule on quantum circuits.</p>"},{"location":"backends/pulser/","title":"Pulser","text":"<p>The Pulser backend features a basic integration with the pulse-level programming interface Pulser. This backend offers for now few simple operations which are translated into a valid, non time-dependent pulse sequence. In particular, one has access to:</p> <ul> <li>analog rotations: <code>AnalogRx</code> and <code>AnalogRy</code> blocks</li> <li>free evolution blocks (basically no pulse, just interaction): <code>AnalogWait</code> block</li> <li>a block for creating entangled states: <code>AnalogEntanglement</code></li> <li>digital rotation <code>Rx</code> and <code>Ry</code></li> </ul>"},{"location":"backends/pulser/#qadence.backends.pulser.backend.Backend","title":"<code>Backend</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Backend</code></p> <p>The Pulser backend</p>"},{"location":"backends/pulser/#qadence.backends.pulser.backend.create_register","title":"<code>create_register(register, spacing=DEFAULT_SPACING)</code>","text":"<p>Create Pulser register instance.</p> PARAMETER  DESCRIPTION <code>register</code> <p>graph representing a register with accompanying coordinate data</p> <p> TYPE: <code>Register</code> </p> <code>spacing</code> <p>distance between qubits in micrometers</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_SPACING</code> </p> RETURNS DESCRIPTION <code>Register</code> <p>Pulser register</p> <p> TYPE: <code>Register</code> </p> Source code in <code>qadence/backends/pulser/backend.py</code> <pre><code>def create_register(register: Register, spacing: float = DEFAULT_SPACING) -&gt; PulserRegister:\n\"\"\"Create Pulser register instance.\n    Args:\n        register (Register): graph representing a register with accompanying coordinate data\n        spacing (float): distance between qubits in micrometers\n    Returns:\n        Register: Pulser register\n    \"\"\"\n# create register from coordinates\ncoords = np.array(list(register.coords.values()))\nreturn PulserRegister.from_coordinates(coords * spacing)\n</code></pre>"},{"location":"backends/pulser/#qadence.backends.pulser.devices.Device","title":"<code>Device</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Supported types of devices for Pulser backend</p>"},{"location":"backends/pulser/#qadence.backends.pulser.devices.Device.IDEALIZED","title":"<code>IDEALIZED = IdealDevice</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>idealized device, least realistic</p>"},{"location":"backends/pulser/#qadence.backends.pulser.devices.Device.REALISTIC","title":"<code>REALISTIC = RealisticDevice</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>device with realistic specs</p>"},{"location":"backends/pyqtorch/","title":"PyQTorch","text":"<p>Fast differentiable statevector emulator based on PyTorch. The code is open source, hosted on Github and maintained by Pasqal.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend","title":"<code>Backend</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Backend</code></p> <p>PyQTorch backend.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend.convert","title":"<code>convert(circuit, observable=None)</code>","text":"<p>Convert an abstract circuit (and optionally and observable) to their native representation. Additionally this function constructs an embedding function which maps from user-facing parameters to device parameters (read more on parameter embedding here).</p> Source code in <code>qadence/backend.py</code> <pre><code>def convert(\nself, circuit: QuantumCircuit, observable: list[AbstractBlock] | AbstractBlock | None = None\n) -&gt; Converted:\n\"\"\"Convert an abstract circuit (and optionally and observable) to their native\n    representation. Additionally this function constructs an embedding function which maps from\n    user-facing parameters to device parameters (read more on parameter embedding\n    [here][qadence.blocks.embedding.embedding]).\n    \"\"\"\ndef check_observable(obs_obj: Any) -&gt; AbstractBlock:\nif isinstance(obs_obj, QubitOperator):\nfrom qadence.blocks.manipulate import from_openfermion\nassert len(obs_obj.terms) &gt; 0, \"Make sure to give a non-empty qubit hamiltonian\"\nreturn from_openfermion(obs_obj)\nelif isinstance(obs_obj, (CompositeBlock, PrimitiveBlock, ScaleBlock)):\nfrom qadence.blocks.utils import block_is_qubit_hamiltonian\nassert block_is_qubit_hamiltonian(\nobs_obj\n), \"Make sure the QubitHamiltonian consists only of Pauli operators X, Y, Z, I\"\nreturn obs_obj\nraise TypeError(\n\"qubit_hamiltonian should be a Pauli-like AbstractBlock or a QubitOperator\"\n)\nconv_circ = self.circuit(circuit)\ncirc_params, circ_embedding_fn = embedding(\nconv_circ.abstract.block, self.config._use_gate_params\n)\nparams = circ_params\nif observable is not None:\nobservable = observable if isinstance(observable, list) else [observable]\nconv_obs = []\nobs_embedding_fn_list = []\nfor obs in observable:\nobs = check_observable(obs)\nc_obs = self.observable(obs, max(circuit.n_qubits, obs.n_qubits))\nobs_params, obs_embedding_fn = embedding(\nc_obs.abstract, self.config._use_gate_params\n)\nparams.update(obs_params)\nobs_embedding_fn_list.append(obs_embedding_fn)\nconv_obs.append(c_obs)\ndef embedding_fn_dict(a: dict, b: dict) -&gt; dict:\nembedding_dict = circ_embedding_fn(a, b)\nfor o in obs_embedding_fn_list:\nembedding_dict.update(o(a, b))\nreturn embedding_dict\nreturn Converted(conv_circ, conv_obs, embedding_fn_dict, params)\ndef embedding_fn(a: dict, b: dict) -&gt; dict:\nreturn circ_embedding_fn(a, b)\nreturn Converted(conv_circ, None, embedding_fn, params)\n</code></pre>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration","title":"<code>Configuration</code>  <code>dataclass</code>","text":"<p>             Bases: <code>BackendConfiguration</code></p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.interaction","title":"<code>interaction: Callable | Interaction | str = Interaction.NN</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Digital-analog emulation interaction that is used for <code>AnalogBlock</code>s.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.loop_expectation","title":"<code>loop_expectation: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>When computing batches of expectation values, only allocate one wavefunction and loop over the batch of parameters to only allocate a single wavefunction at any given time.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.use_gradient_checkpointing","title":"<code>use_gradient_checkpointing: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use gradient checkpointing. Recommended for higher-order optimization tasks.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.use_single_qubit_composition","title":"<code>use_single_qubit_composition: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Composes chains of single qubit gates into a single matmul if possible.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.supported_gates","title":"<code>supported_gates = list(set(OpName.list()) - set([OpName.TDAGGER]))</code>  <code>module-attribute</code>","text":"<p>The set of supported gates. Tdagger is currently not supported.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.PyQComposedBlock","title":"<code>PyQComposedBlock(ops, qubits, n_qubits, config=None)</code>","text":"<p>             Bases: <code>Module</code></p> <p>Compose a chain of single qubit operations on the same qubit into a single call to _apply_batch_gate.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def __init__(\nself,\nops: list[Module],\nqubits: list[int] | tuple,\nn_qubits: int,\nconfig: Configuration = None,\n):\n\"\"\"Compose a chain of single qubit operations on the same qubit into a single\n    call to _apply_batch_gate.\"\"\"\nsuper().__init__()\nself.operations = ops\nself.qubits = qubits\nself.n_qubits = n_qubits\n</code></pre>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.ScalePyQOperation","title":"<code>ScalePyQOperation(n_qubits, block, config)</code>","text":"<p>             Bases: <code>Module</code></p> <p>Computes:</p> <pre><code>M = matrix(op, theta)\nscale * matmul(M, state)\n</code></pre> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def __init__(self, n_qubits: int, block: ScaleBlock, config: Configuration):\nsuper().__init__()\n(self.param_name,) = config.get_param_name(block)\nif not isinstance(block.block, PrimitiveBlock):\nraise NotImplementedError(\n\"The pyqtorch backend can currently only scale `PrimitiveBlock` types.\\\n            Please use the following transpile function on your circuit first:\\\n            from qadence.transpile import scale_primitive_blocks_only\"\n)\nself.operation = convert_block(block.block, n_qubits, config)[0]\ndef _fwd(state: torch.Tensor, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\nreturn values[self.param_name] * self.operation(state, values)\nif config.use_gradient_checkpointing:\ndef _forward(state: torch.Tensor, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\nreturn checkpoint(_fwd, state, values, use_reentrant=False)\nelse:\ndef _forward(state: torch.Tensor, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\nreturn _fwd(state, values)\nself._forward = _forward\n</code></pre>"},{"location":"development/architecture/","title":"Architecture and sharp bits","text":"<p>Qadence as a software library mixes functional and object-oriented programming. We do that by maintaining core objects and operating on them with functions.</p> <p>Furthermore, Qadence strives at keeping the lower level abstraction layers for automatic differentiation and quantum computation fully stateless while only the frontend layer which is the main user-facing interface is stateful.</p> <p>Code design philosopy</p> <p>Functional, stateless core with object-oriented, stateful user interface.</p>"},{"location":"development/architecture/#abstraction-layers","title":"Abstraction layers","text":"<p>In Qadence there are 4 main objects spread across 3 different levels of abstraction:</p> <ul> <li> <p>Frontend layer: The user facing layer and encompasses two objects:</p> <ul> <li><code>QuantumCircuit</code>: A class representing an abstract quantum   circuit not tight not any particular framework. Parameters are represented symbolically using   <code>sympy</code> expressions.</li> <li><code>QuantumModel</code>: The models are higher-level abstraction   providing an interface for executing different kinds of common quantum computing models such   quantum neural networks (QNNs), quantum kernels etc.</li> </ul> </li> <li> <p>Differentiation layer: Intermediate layer has the purpose of integrating quantum   computation with a given automatic differentiation engine. It is meant to be purely stateless and   contains one object:</p> <ul> <li><code>DifferentiableBackend</code>:   An abstract class whose concrete implementation wraps a quantum backend and make it   automatically differentiable using different engines (e.g. PyTorch or Jax).   Note, that today only PyTorch is supported but there is plan to add also a Jax   differentiable backend which will require some changes in the base class implementation.</li> </ul> </li> <li> <p>Quantum layer: The lower-level layer which directly interfaces with quantum emulators   and processing units. It is meant to be purely stateless and it contains one base object which is   specialized for each supported backend:</p> <ul> <li><code>Backend</code>: An abstract class whose concrete implementation   enables the execution of quantum circuit with a variety of quantum backends (normally non   automatically differentiable by default) such as PyQTorch, Pulser or Braket.</li> </ul> </li> </ul>"},{"location":"development/architecture/#main-components","title":"Main components","text":""},{"location":"development/architecture/#quantumcircuit","title":"<code>QuantumCircuit</code>","text":"<p>We consider <code>QuantumCircuit</code> to be an abstract object, i.e. it is not tied to any backend. However, it blocks are even more abstract. This is because we consider <code>QuantumCircuit</code>s \"real\", whereas the blocks are largely considered just syntax.</p> <p>Unitary <code>QuantumCircuits</code> (this encompasses digital, or gate-based, circuits as well as analog circuits) are constructed by [<code>PrimitiveBlocks</code>] using a syntax that allows you to execute them in sequence, dubbed <code>ChainBlock</code> in the code, or in parallel (i.e. at the same time) where applicable, dubbed <code>KronBlock</code> in the code. Notice that this differs from other packages by providing more control of the layout of the circuit than conventional packages like Qiskit, and from Yao where the blocks are the primary type.</p>"},{"location":"development/architecture/#quantummodel","title":"<code>QuantumModel</code>","text":"<p><code>QuantumModel</code>s are meant to be the main entry point for quantum computations in <code>qadence</code>. In general, they take one or more quantum circuit as input and they wrap all the necessary boiler plate code to make the circuit executable and differentiable on the chosen backend.</p> <p>Models are meant to be specific for a certain kind of quantum problem or algorithm and you can easily create new ones starting from the base class <code>QuantumModel</code>, as explained in the custom model tutorial. Currently, Qadence offers a <code>QNN</code> model class which provides convenient methods to work with quantum neural networks with multi-dimensional inputs and outputs.</p>"},{"location":"development/architecture/#differentiablebackend","title":"<code>DifferentiableBackend</code>","text":"<p>The differentiable backend is a thin wrapper which takes as input a <code>QuantumCircuit</code> instance and a chosen quantum backend and make the circuit execution routines (expectation value, overalap, etc.) differentiable. Currently, the only implemented differentiation engine is PyTorch but it is easy to add support to another one like Jax.</p>"},{"location":"development/architecture/#quantum-backend","title":"Quantum <code>Backend</code>","text":"<p>For execution the primary object is the <code>Backend</code>. Backends maintain the same user-facing interface, and internally connects to other libraries to execute circuits. Those other libraries can execute the code on QPUs and local or cloud-based emulators. The <code>Backends</code> use PyTorch tensors to represent data and leverages PyTorchs autograd to help compute derivatives of circuits.</p>"},{"location":"development/architecture/#symbolic-parameters","title":"Symbolic parameters","text":"<p>To illustrate how parameters work in Qadence, let's consider the following simple block composed of just two rotations:</p> <pre><code>import sympy\nfrom qadence import Parameter, RX\nparam = Parameter(\"phi\", trainable=False)\nblock = RX(0, param) * RX(1, sympy.acos(param))\n</code></pre> <p>The rotation angles assigned to <code>RX</code> (and to any Qadence quantum operation) are defined as arbitrary expressions of <code>Parameter</code>'s. <code>Parameter</code> is a subclass of <code>sympy.Symbol</code>, thus fully interoperable with it.</p> <p>To assign values of the parameter <code>phi</code> in a quantum model, one should use a dictionary containing the a key with parameter name and the corresponding values values:</p> <pre><code>import torch\nfrom qadence import run\nvalues = {\"phi\": torch.rand(10)}\nwf = run(block, values=values)\n</code></pre> <p>This is the only interface for parameter assignment exposed to the user. Under the hood, parameters applied to every quantum operation are identified in different ways:</p> <ul> <li> <p>By default, with a stringified version of the <code>sympy</code> expression supplied to the quantum operation. Notice that multiple operations can have the same expression.</p> </li> <li> <p>In certain case, e.g. for constructing parameter shift rules, one must access a unique identifier of the parameter for each quantum operation. Therefore, Qadence also creates unique identifiers for each parametrized operation (see the <code>ParamMap</code> class).</p> </li> </ul> <p>By default, when one constructs a new backend, the parameter identifiers are the <code>sympy</code> expressions which are used when converting an abstract block into a native circuit for the chosen backend. However, one can use the unique identifiers as parameter names by setting the private flag <code>_use_gate_params</code> to <code>True</code> in the backend configuration <code>BackendConfiguration</code>. This is automatically set when PSR differentiation is selected (see next section for more details).</p> <p>You can see the logic for choosing the parameter identifier in <code>get_param_name</code>.</p>"},{"location":"development/architecture/#differentiation-with-parameter-shift-rules-psr","title":"Differentiation with parameter shift rules (PSR)","text":"<p>In Qadence, parameter shift rules are implemented by extending the PyTorch autograd engine using custom <code>Function</code> objects. The implementation is based on this PyTorch guide.</p> <p>A custom PyTorch <code>Function</code> looks like this:</p> <pre><code>import torch\nfrom torch.autograd import Function\nclass CustomFunction(Function):\n# forward pass implementation giving the output of the module\n@staticmethod\ndef forward(ctx, inputs: torch.Tensor, params: torch.Tensor):\nctx.save_for_backward(inputs, params)\n...\n# backward pass implementation giving the derivative of the module\n# with respect to the parameters. This must return the whole vector-jacobian\n# product to integrate within the autograd engine\n@staticmethod\ndef backward(ctx, grad_output: torch.Tensor):\ninputs, params = ctx.saved_tensors\n...\n</code></pre> <p>The class <code>PSRExpectation</code> implements parameter shift rules for all parameters using a custom function as the one above. There are a few implementation details to keep in mind if you want to modify the PSR code:</p> <ul> <li> <p>PyTorch <code>Function</code> only works with tensor arguments. Parameters in Qadence are passed around as   dictionaries with parameter names as keys and current parameter values (tensors)   as values. This works for both variational and feature parameters. However, the <code>Function</code> class   only work with PyTorch tensors as input, not dictionaries. Therefore, the forward pass of   <code>PSRExpectation</code> accepts one argument <code>param_keys</code> with the   parameter keys and a variadic positional argument <code>param_values</code> with the parameter values one by   one. The dictionary is reconstructed within the <code>forward()</code> pass body.</p> </li> <li> <p>Higher-order derivatives with PSR. Higher-order PSR derivatives can be tricky. Parameter shift   rules calls, under the hood, the <code>QuantumBackend</code> expectation value routine that usually yield a   non-differentiable output. Therefore, a second call to the backward pass would not work. However,   Qadence employs a very simple trick to make higher-order derivatives work: instead of using   directly the expectation value of the quantum backend, the PSR backward pass uses the PSR forward   pass itself as expectation value function (see the code below). In this way, multiple calls to the   backward pass are allowed since the <code>expectation_fn</code> routine is always differentiable by   definition. Notice that this implementation is simple but suboptimal since, in some corner cases,   higher-order derivates might include some repeated terms that, with this implementation, are   always recomputed.</p> </li> </ul> <pre><code># expectation value used in the PSR backward pass\ndef expectation_fn(params: dict[str, Tensor]) -&gt; Tensor:\nreturn PSRExpectation.apply(\nctx.expectation_fn,\nctx.param_psrs,\nparams.keys(),\n*params.values(),\n)\n</code></pre> <ul> <li> <p>Operation parameters must be uniquely identified for PSR to work. Parameter shift rules work at the level of individual quantum operations. This means that, given a parameter <code>x</code>, one needs to sum the contributions from shifting the parameter values of all the operation where the parameter <code>x</code> appears. When constructing the PSR rules, one must access a unique parameter identifier for each operation even if the corresponding user-facing parameter is the same. Therefore, when PSR differentiation is selected, the flag <code>_use_gate_params</code> is automatically set to <code>True</code> in the backend configuration <code>BackendConfiguration</code> (see previous section).</p> </li> <li> <p>PSR must not be applied to observable parameters. In Qadence, Pauli observables can also be parametrized. However, the tunable parameters of observables are purely classical and should not be included in the differentiation with PSRs. However, the quantum expectation value depends on them, thus they still need to enter into the PSR evaluation. To solve this issue, the code sets the <code>requires_grad</code> attribute of all observable parameters to <code>False</code> when constructing the PSRs for the circuit as in the snippet below:</p> </li> </ul> <pre><code>for obs in observable:\nfor param_id, _ in uuid_to_eigen(obs).items():\nparam_to_psr[param_id] = lambda x: torch.tensor([0.0], requires_grad=False)\n</code></pre>"},{"location":"development/draw/","title":"<code>qadence.draw</code> example plots","text":"<p>Mostly for quick, manual checking of correct plotting output.</p> <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\nb = kron(X(0), Y(1))\n</code></pre> %3 b05385e2e0534ae8857d7cc39377d7aa 0 ec40ff3edaff49eb815a2d1604ada91c X b05385e2e0534ae8857d7cc39377d7aa--ec40ff3edaff49eb815a2d1604ada91c a769c85792e24ed999110f9f06037f2d 1 ddc2f30b5e524da984a105bd538ecb90 ec40ff3edaff49eb815a2d1604ada91c--ddc2f30b5e524da984a105bd538ecb90 194eb7b3d92048b08953e7007fe82f8a 1e79707a2d3b49ed999880f68db96f3d Y a769c85792e24ed999110f9f06037f2d--1e79707a2d3b49ed999880f68db96f3d 1e79707a2d3b49ed999880f68db96f3d--194eb7b3d92048b08953e7007fe82f8a <pre><code>from qadence import X, Y, chain\nfrom qadence.draw import display\nb = chain(X(0), Y(0))\n</code></pre> %3 925178f84de946e99baed64fb76a71f4 0 567fabdd30cb470a8bf3c4a8d32f249f X 925178f84de946e99baed64fb76a71f4--567fabdd30cb470a8bf3c4a8d32f249f b60d12098a7f44568ae9b1478f7251ca Y 567fabdd30cb470a8bf3c4a8d32f249f--b60d12098a7f44568ae9b1478f7251ca 6e3f31aa4c1544998e53112056b90431 b60d12098a7f44568ae9b1478f7251ca--6e3f31aa4c1544998e53112056b90431 <pre><code>from qadence import X, Y, chain\nfrom qadence.draw import display\nb = chain(X(0), Y(1))\n</code></pre> %3 a1f72007f6604e1cbcaf8f3595430839 0 71910e14a44c48d08e25bd8f3cfc8178 X a1f72007f6604e1cbcaf8f3595430839--71910e14a44c48d08e25bd8f3cfc8178 207cf61a95d9464395d68d7de56e045f 1 c84c45fc283a4c3d9bbb745b852d6f07 71910e14a44c48d08e25bd8f3cfc8178--c84c45fc283a4c3d9bbb745b852d6f07 902f5551e9c0414d813c89f55b57cdaa c84c45fc283a4c3d9bbb745b852d6f07--902f5551e9c0414d813c89f55b57cdaa 40bc5d5759394632a905289f76dd83b1 9d1cc08dfe82430798490ac010b67946 207cf61a95d9464395d68d7de56e045f--9d1cc08dfe82430798490ac010b67946 a530f1745b144758afde747c37387b26 Y 9d1cc08dfe82430798490ac010b67946--a530f1745b144758afde747c37387b26 a530f1745b144758afde747c37387b26--40bc5d5759394632a905289f76dd83b1 <pre><code>from qadence import X, Y, add\nfrom qadence.draw import display\nb = add(X(0), Y(1), X(2))\n</code></pre> %3 cluster_2e069a92b8e544de8b870a4ec5b98895 ccf88256dde54be8b652c6be61b73961 0 3458329416064af0a58240483188b632 ccf88256dde54be8b652c6be61b73961--3458329416064af0a58240483188b632 79e5352615e348249a48fb50ba6c6cae 1 fc5a81e1ba17416b9b45a1e0875168c6 3458329416064af0a58240483188b632--fc5a81e1ba17416b9b45a1e0875168c6 295979b1f4164805ba3d69ddad2c03ea bf1b16b5c63c446fa507ccf6b222da12 AddBlock 79e5352615e348249a48fb50ba6c6cae--bf1b16b5c63c446fa507ccf6b222da12 ad7d848aec164417b5ac95f385dd1b3a 2 bf1b16b5c63c446fa507ccf6b222da12--295979b1f4164805ba3d69ddad2c03ea 758b60441c724acba56a2e988e46f440 723eefdb7a8048ea8dd07e84bddc84d0 ad7d848aec164417b5ac95f385dd1b3a--723eefdb7a8048ea8dd07e84bddc84d0 723eefdb7a8048ea8dd07e84bddc84d0--758b60441c724acba56a2e988e46f440 <pre><code>from qadence import CNOT, RX, HamEvo, X, Y, Z, chain, kron\nrx = kron(RX(3,0.5), RX(2, \"x\"))\nrx.tag = \"rx\"\ngen = chain(Z(i) for i in range(4))\n# `chain` puts things in sequence\nblock = chain(\nkron(X(0), Y(1), rx),\nCNOT(2,3),\nHamEvo(gen, 10)\n)\n</code></pre> %3 cluster_1d00a7122cee453686f135991cf67cb5 cluster_dd01af9b55ac4c4c8f16b75420f9c41d rx ae1c37f8ec4a45a3ac5a45894af7e20c 0 2ccb61253bbd4010b40f58b219fbf8c9 X ae1c37f8ec4a45a3ac5a45894af7e20c--2ccb61253bbd4010b40f58b219fbf8c9 ccf1939d4aed45cf953c1bc8a0167a8b 1 f160a10a29ba447eba05b1fd631b906b 2ccb61253bbd4010b40f58b219fbf8c9--f160a10a29ba447eba05b1fd631b906b d02902e444074c628c6248b4c65ec59f f160a10a29ba447eba05b1fd631b906b--d02902e444074c628c6248b4c65ec59f a6d4bf6169e54b9b961343e8a026c235 d02902e444074c628c6248b4c65ec59f--a6d4bf6169e54b9b961343e8a026c235 529b30cf677f4137b29a9e315b7a2f97 10b0aca8415e4ad68fb31f940f55ed3e Y ccf1939d4aed45cf953c1bc8a0167a8b--10b0aca8415e4ad68fb31f940f55ed3e b836d590cd19437e9f9678c2a61fef25 2 c4d6319de1f14d44a0152b92a3a46ddc 10b0aca8415e4ad68fb31f940f55ed3e--c4d6319de1f14d44a0152b92a3a46ddc 9659328ff6354a80b05d5d64d900aa17 HamEvo c4d6319de1f14d44a0152b92a3a46ddc--9659328ff6354a80b05d5d64d900aa17 9659328ff6354a80b05d5d64d900aa17--529b30cf677f4137b29a9e315b7a2f97 b809bae91cd9413d950feb0d2a62df04 be4db7540c774a02aed3bb4c0c17f552 RX(x) b836d590cd19437e9f9678c2a61fef25--be4db7540c774a02aed3bb4c0c17f552 a631225fe31645108ac6a8348bf84916 3 4632b514edc44bfea9cdf129a4cf99f3 be4db7540c774a02aed3bb4c0c17f552--4632b514edc44bfea9cdf129a4cf99f3 c11f1d4f27284d238e7f72d630ddd3cf t = 10 4632b514edc44bfea9cdf129a4cf99f3--c11f1d4f27284d238e7f72d630ddd3cf c11f1d4f27284d238e7f72d630ddd3cf--b809bae91cd9413d950feb0d2a62df04 faa8d728cc6949439dd609683d818c63 4145a518634a40beb3a66e683a0134bc RX(0.5) a631225fe31645108ac6a8348bf84916--4145a518634a40beb3a66e683a0134bc 98daa82eedec4f9f834a5195d7e0cf8d X 4145a518634a40beb3a66e683a0134bc--98daa82eedec4f9f834a5195d7e0cf8d 98daa82eedec4f9f834a5195d7e0cf8d--4632b514edc44bfea9cdf129a4cf99f3 966f9b06da55476e92c90ee666c9d3ce 98daa82eedec4f9f834a5195d7e0cf8d--966f9b06da55476e92c90ee666c9d3ce 966f9b06da55476e92c90ee666c9d3ce--faa8d728cc6949439dd609683d818c63 <pre><code>from qadence import feature_map, hea, chain\nblock = chain(feature_map(4, reupload_scaling=\"Tower\"), hea(4,2))\n</code></pre> %3 cluster_bc99a8954973429bbba0cf0d3f8a387d HEA cluster_07ef22aaa7a149e6b02acc69c02c57e7 Tower Fourier FM f6d77154b86947339877e8c49fc3bcb1 0 4a21edb0594a4b1184383ab4733ba19e RX(1.0*phi) f6d77154b86947339877e8c49fc3bcb1--4a21edb0594a4b1184383ab4733ba19e f0c8873e5a874cdab3db53a1fc086662 1 9e8b49117c4f4a5e92812599aa4fc44b RX(theta\u2080) 4a21edb0594a4b1184383ab4733ba19e--9e8b49117c4f4a5e92812599aa4fc44b 2fee5fa91ce74b0bbeb3003fcaf998ad RY(theta\u2084) 9e8b49117c4f4a5e92812599aa4fc44b--2fee5fa91ce74b0bbeb3003fcaf998ad 44f13178ca894e2a9363b4751b5838ba RX(theta\u2088) 2fee5fa91ce74b0bbeb3003fcaf998ad--44f13178ca894e2a9363b4751b5838ba 1d51dcf9a75344b3b072d5c2750f012e 44f13178ca894e2a9363b4751b5838ba--1d51dcf9a75344b3b072d5c2750f012e 4e0b7ce394bf4bcd8d5bdfcf92cda64b 1d51dcf9a75344b3b072d5c2750f012e--4e0b7ce394bf4bcd8d5bdfcf92cda64b e540de393ef64e888b8cb1207b9e5460 RX(theta\u2081\u2082) 4e0b7ce394bf4bcd8d5bdfcf92cda64b--e540de393ef64e888b8cb1207b9e5460 d705b6ceede64893b4e6e8b78b5eddc3 RY(theta\u2081\u2086) e540de393ef64e888b8cb1207b9e5460--d705b6ceede64893b4e6e8b78b5eddc3 ede423a963ce4bbf8d91b9bb2a8d5249 RX(theta\u2082\u2080) d705b6ceede64893b4e6e8b78b5eddc3--ede423a963ce4bbf8d91b9bb2a8d5249 40d50368685a4c27b45ce643885dd937 ede423a963ce4bbf8d91b9bb2a8d5249--40d50368685a4c27b45ce643885dd937 3106035596bd4bd8b1aa2fbcbc8ab40b 40d50368685a4c27b45ce643885dd937--3106035596bd4bd8b1aa2fbcbc8ab40b 5795c4929f294320ae624b8940e26fb0 3106035596bd4bd8b1aa2fbcbc8ab40b--5795c4929f294320ae624b8940e26fb0 f92962abf10e40ce9478d5cecba1320d 74d6ecf3bffc4f41aa443bdd300719b2 RX(2.0*phi) f0c8873e5a874cdab3db53a1fc086662--74d6ecf3bffc4f41aa443bdd300719b2 0f28f610248a4e2795262a7ab090cd2f 2 1dbe4981079b43bb8191aee44db63910 RX(theta\u2081) 74d6ecf3bffc4f41aa443bdd300719b2--1dbe4981079b43bb8191aee44db63910 3ace9ffed6d2416c8cbb54dbba6666a6 RY(theta\u2085) 1dbe4981079b43bb8191aee44db63910--3ace9ffed6d2416c8cbb54dbba6666a6 0686d4a43f5f4187a989473e8e72cf2c RX(theta\u2089) 3ace9ffed6d2416c8cbb54dbba6666a6--0686d4a43f5f4187a989473e8e72cf2c 32221863915d4ea587d25ba76a97f0e6 X 0686d4a43f5f4187a989473e8e72cf2c--32221863915d4ea587d25ba76a97f0e6 32221863915d4ea587d25ba76a97f0e6--1d51dcf9a75344b3b072d5c2750f012e 66a8056dbf654117a5176c7c556ad93d 32221863915d4ea587d25ba76a97f0e6--66a8056dbf654117a5176c7c556ad93d 0d21ef17ffb54838bfb16dbb512f9aa3 RX(theta\u2081\u2083) 66a8056dbf654117a5176c7c556ad93d--0d21ef17ffb54838bfb16dbb512f9aa3 69857b621336481d83ffce020b7f545d RY(theta\u2081\u2087) 0d21ef17ffb54838bfb16dbb512f9aa3--69857b621336481d83ffce020b7f545d 0a3c9e28b6904e6985d937acccb7a53c RX(theta\u2082\u2081) 69857b621336481d83ffce020b7f545d--0a3c9e28b6904e6985d937acccb7a53c e2274bc536f947d584124987ea6eea23 X 0a3c9e28b6904e6985d937acccb7a53c--e2274bc536f947d584124987ea6eea23 e2274bc536f947d584124987ea6eea23--40d50368685a4c27b45ce643885dd937 faf80a2cb6be41409f22eb2682c00255 e2274bc536f947d584124987ea6eea23--faf80a2cb6be41409f22eb2682c00255 faf80a2cb6be41409f22eb2682c00255--f92962abf10e40ce9478d5cecba1320d 6f3d9aec531c4ec19401f39a5bc4938c 6b7cc4a722c54c50bf9f25a2730ebfa6 RX(3.0*phi) 0f28f610248a4e2795262a7ab090cd2f--6b7cc4a722c54c50bf9f25a2730ebfa6 36bd9efd9684450c8f2132c18e7b4183 3 f943a2713d7e4bec9b7ba6203dc20a56 RX(theta\u2082) 6b7cc4a722c54c50bf9f25a2730ebfa6--f943a2713d7e4bec9b7ba6203dc20a56 22eab67f6aa74d90b79826a21ef2c3e7 RY(theta\u2086) f943a2713d7e4bec9b7ba6203dc20a56--22eab67f6aa74d90b79826a21ef2c3e7 198ea0ab6c614df39d50b607da19a364 RX(theta\u2081\u2080) 22eab67f6aa74d90b79826a21ef2c3e7--198ea0ab6c614df39d50b607da19a364 03ec1f5465c74b6ca8ca9c92296f3774 198ea0ab6c614df39d50b607da19a364--03ec1f5465c74b6ca8ca9c92296f3774 87ccff8d170f47739764edd4f5b4a703 X 03ec1f5465c74b6ca8ca9c92296f3774--87ccff8d170f47739764edd4f5b4a703 87ccff8d170f47739764edd4f5b4a703--66a8056dbf654117a5176c7c556ad93d cdb3464bc03a40e59ce3311c44898f48 RX(theta\u2081\u2084) 87ccff8d170f47739764edd4f5b4a703--cdb3464bc03a40e59ce3311c44898f48 105bc73fae594e1bbfb98ad1d6204444 RY(theta\u2081\u2088) cdb3464bc03a40e59ce3311c44898f48--105bc73fae594e1bbfb98ad1d6204444 a2fe6fe6295d4967930247775fd123fe RX(theta\u2082\u2082) 105bc73fae594e1bbfb98ad1d6204444--a2fe6fe6295d4967930247775fd123fe 13b71bfe733b410e958aed357ec2c507 a2fe6fe6295d4967930247775fd123fe--13b71bfe733b410e958aed357ec2c507 588658765bfc4338b4036552112c17d1 X 13b71bfe733b410e958aed357ec2c507--588658765bfc4338b4036552112c17d1 588658765bfc4338b4036552112c17d1--faf80a2cb6be41409f22eb2682c00255 588658765bfc4338b4036552112c17d1--6f3d9aec531c4ec19401f39a5bc4938c 3d4a896274044b67b1967ea29b0f6a27 c9c359ac825b48beab132809c20464a1 RX(4.0*phi) 36bd9efd9684450c8f2132c18e7b4183--c9c359ac825b48beab132809c20464a1 a4808cc972b34fbebaa0a5f45b8ef06b RX(theta\u2083) c9c359ac825b48beab132809c20464a1--a4808cc972b34fbebaa0a5f45b8ef06b bf7546eb678f4d058d53faee7e6e3aad RY(theta\u2087) a4808cc972b34fbebaa0a5f45b8ef06b--bf7546eb678f4d058d53faee7e6e3aad 7072117372db498ea1c7349acf472996 RX(theta\u2081\u2081) bf7546eb678f4d058d53faee7e6e3aad--7072117372db498ea1c7349acf472996 7759f07b40c84474847392a450b2c534 X 7072117372db498ea1c7349acf472996--7759f07b40c84474847392a450b2c534 7759f07b40c84474847392a450b2c534--03ec1f5465c74b6ca8ca9c92296f3774 f0408396ae6945daa0550ecbe2e027f2 7759f07b40c84474847392a450b2c534--f0408396ae6945daa0550ecbe2e027f2 bd7cef4a448d4e4385323bf3ab8ced01 RX(theta\u2081\u2085) f0408396ae6945daa0550ecbe2e027f2--bd7cef4a448d4e4385323bf3ab8ced01 52e26ed2ce894fb6a909f0ab4562113a RY(theta\u2081\u2089) bd7cef4a448d4e4385323bf3ab8ced01--52e26ed2ce894fb6a909f0ab4562113a 1b717f875a24458cb5ce5fbf9e98ec62 RX(theta\u2082\u2083) 52e26ed2ce894fb6a909f0ab4562113a--1b717f875a24458cb5ce5fbf9e98ec62 e98ff394b9604059974f6605be16a8c6 X 1b717f875a24458cb5ce5fbf9e98ec62--e98ff394b9604059974f6605be16a8c6 e98ff394b9604059974f6605be16a8c6--13b71bfe733b410e958aed357ec2c507 c729cb7222064cd58085727800dff651 e98ff394b9604059974f6605be16a8c6--c729cb7222064cd58085727800dff651 c729cb7222064cd58085727800dff651--3d4a896274044b67b1967ea29b0f6a27"},{"location":"development/draw/#developer-documentation","title":"Developer documentation","text":"<p>This section contains examples in pure graphviz that can be used to understand roughly what is done in the actual drawing backend.</p> <pre><code>import graphviz\nfont_name = \"Sans-Serif\"\nfont_size = \"8\"\ngraph_attr = {\n\"rankdir\": \"LR\",  # LR = left to right, TB = top to bottom\n\"nodesep\": \"0.1\",  # In inches, tells distance between nodes without edges\n\"compound\": \"true\",  # Needed to draw properly edges in hamevo when content is hidden\n\"splines\": \"false\",  # Needed to draw control gates vertical lines one over the other\n}  # These are the default values for graphs\nnode_attr = {\n\"shape\": \"box\",  # 'box' for normal nodes, 'point' for control gates or 'plaintext' for starting nodes (the qubit label).\n\"style\": \"rounded\",  # Unfortunately we can't specify the radius of the rounded, at least for this version\n\"fontname\": font_name,\n\"fontsize\": font_size,\n\"width\": \"0.1\",  # In inches, it doesn't get tinier than the label font.\n\"height\": \"0.1\"  # In inches, it doesn't get tinier than the label font.\n}  # These are the defaults values that can be overridden at node declaration.\ndefault_cluster_attr = {\n\"fontname\": font_name,\n\"fontsize\": font_size,\n\"labelloc\": \"b\",  # location of cluster label. b as bottom, t as top\n\"style\": \"rounded\"\n} # These are the defaults values that can be overridden at sub graph declaration\nhamevo_cluster_attr = {\n\"label\": \"HamEvo(t=10)\"\n}\nhamevo_cluster_attr.update(default_cluster_attr)\nh = graphviz.Graph(graph_attr=graph_attr, node_attr=node_attr)\nh.node(\"Hello World!\")\nh\n</code></pre> <pre><code>\n</code></pre> <pre><code># Define graph\nh = graphviz.Graph(node_attr=node_attr, graph_attr=graph_attr)\n# Add start and end nodes\nfor i in range(4):\nh.node(f's{i}', shape=\"plaintext\", label=f'{i}', group=f\"{i}\")\nh.node(f'e{i}', style='invis', group=f\"{i}\")\n# Add nodes\nh.node('X', group=\"0\")\nh.node('Y', group=\"1\")\n# Add hamevo and its nodes\nhamevo = graphviz.Graph(name='cluster_hamevo', graph_attr=hamevo_cluster_attr)\nfor i in range(4):\nhamevo.node(f'z{i}', shape=\"box\", style=\"invis\", label=f'{i}', group=f\"{i}\")\nh.subgraph(hamevo)\n# Add rx gates cluster and its nodes\ncluster_attr = {\"label\": \"RX gates\"}\ncluster_attr.update(default_cluster_attr)\ncluster = graphviz.Graph(name=\"cluster_0\", graph_attr=cluster_attr)\ncluster.node('RX(x)', group=\"2\")\ncluster.node('RX(0.5)', group=\"3\")\nh.subgraph(cluster)\nh.node('cnot0', label='', shape='point', width='0.1', group='0')\nh.node('cnot1', label='X', group='1')\nh.node('cnot2', label='', shape='point', width='0.1', group='2')\nh.node('cnot3', label='', shape='point', width='0.1', group='3')\n# Add edges\nh.edge('s0', 'X')\nh.edge('X', 'cnot0')\nh.edge('cnot0', 'z0', lhead='cluster_hamevo')\nh.edge('z0', 'e0', ltail='cluster_hamevo')\nh.edge('s1', 'Y')\nh.edge('Y', 'cnot1')\nh.edge('cnot1', 'z1', lhead='cluster_hamevo')\nh.edge('z1', 'e1', ltail='cluster_hamevo')\nh.edge('s2', 'RX(x)')\nh.edge('RX(x)', 'cnot2')\nh.edge('cnot2', 'z2', lhead='cluster_hamevo')\nh.edge('z2', 'e2', ltail='cluster_hamevo')\nh.edge('s3', 'RX(0.5)')\nh.edge('RX(0.5)', 'cnot3')\nh.edge('cnot3', 'z3', lhead='cluster_hamevo')\nh.edge('z3', 'e3', ltail='cluster_hamevo')\nh.edge('cnot1', 'cnot0', constraint='false')  # constraint: false is needed to draw vertical edges\nh.edge('cnot1', 'cnot2', constraint='false')  # constraint: false is needed to draw vertical edges\nh.edge('cnot1', 'cnot3', constraint='false')  # constraint: false is needed to draw vertical edges\nh\n</code></pre> <pre><code>\n</code></pre>"},{"location":"development/draw/#example-of-cluster-of-clusters","title":"Example of cluster of clusters","text":"<pre><code># Define graph\nh = graphviz.Graph(node_attr=node_attr, graph_attr=graph_attr)\n# Define start and end nodes\nfor i in range(4):\nh.node(f's{i}', shape=\"plaintext\", label=f'{i}', group=f\"{i}\")\nh.node(f'e{i}', style='invis', group=f\"{i}\")\n# Define outer cluster\ncluster_attr = {\"label\": \"Outer cluster\"}\ncluster_attr.update(default_cluster_attr)\nouter_cluster = graphviz.Graph(name=\"cluster_outer\", graph_attr=cluster_attr)\n# Define inner cluster 1 and its nodes\ncluster_attr = {\"label\": \"Inner cluster 1\"}\ncluster_attr.update(default_cluster_attr)\ninner1_cluster = graphviz.Graph(name=\"cluster_inner1\", graph_attr=cluster_attr)\ninner1_cluster.node(\"a0\", group=\"0\")\ninner1_cluster.node(\"a1\", group=\"1\")\nouter_cluster.subgraph(inner1_cluster)\n# Define inner cluster 2 and its nodes\ncluster_attr = {\"label\": \"Inner cluster 2\"}\ncluster_attr.update(default_cluster_attr)\ninner2_cluster = graphviz.Graph(name=\"cluster_inner2\", graph_attr=cluster_attr)\ninner2_cluster.node(\"a2\", group=\"2\")\ninner2_cluster.node(\"a3\", group=\"3\")\nouter_cluster.subgraph(inner2_cluster)\n# This has to be done here, after inner clusters definitions\nh.subgraph(outer_cluster)\n# Define more nodes\nfor i in range(4):\nh.node(f\"b{i}\", group=f\"{i}\")\nfor i in range(4):\nh.edge(f's{i}', f'a{i}')\nh.edge(f'a{i}', f'b{i}')\nh.edge(f'b{i}', f'e{i}')\nh\n</code></pre> <pre><code>\n</code></pre>"},{"location":"digital_analog_qc/analog-basics/","title":"Digital-Analog Emulation","text":""},{"location":"digital_analog_qc/analog-basics/#from-theory-to-implementation","title":"From theory to implementation","text":"<p>Qadence includes primitives for the construction of Ising-like Hamiltonians to account for custom qubit interaction. This allows to simulate systems close to real quantum computing platforms such as neutral atoms. The general form for time-independent Ising Hamiltonians is</p> \\[ \\mathcal{H} = \\sum_{i} \\frac{\\hbar\\Omega}{2} \\hat\\sigma^x_i - \\sum_{i} \\hbar\\delta \\hat n_i  + \\mathcal{H}_{\\textrm{int}}, \\] <p>where \\(\\Omega\\) is the Rabi frequency, \\(\\delta\\) is the detuning, \\(\\hat n = \\frac{1-\\hat\\sigma_z}{2}\\) is the number operator, and \\(\\mathcal{H}_{\\textrm{int}}\\) a pair-wise interaction term. Two central operations implement this Hamiltonian as blocks:</p> <ul> <li><code>WaitBlock</code> by free-evolving \\(\\mathcal{H}_{\\textrm{int}}\\)</li> <li><code>ConstantAnalogRotation</code> by free-evolving \\(\\mathcal{H}\\)</li> </ul> <p>The <code>wait</code> operation can be emulated with an \\(ZZ\\)- (Ising) or an \\(XY\\)-interaction:</p> <pre><code>from qadence import Register, wait, add_interaction, run, Interaction\nblock = wait(duration=3000)\nreg = Register.from_coordinates([(0,0), (0,5)])  # Dimensionless.\nemulated = add_interaction(reg, block, interaction=Interaction.XY)  # or Interaction.ZZ for Ising.\n</code></pre> <pre><code>block = WaitBlock(t=3000.0, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,)) emulated.generator = AddBlock(0,1)\n\u2514\u2500\u2500 [mul: 29.600] \u2514\u2500\u2500 AddBlock(0,1)\n\u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u251c\u2500\u2500 X(0)\n\u2502   \u2514\u2500\u2500 X(1)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u251c\u2500\u2500 Y(0)\n\u2514\u2500\u2500 Y(1)\n</code></pre> <p>The <code>AnalogRot</code> constructor can be used to create a fully customizable <code>ConstantAnalogRotation</code> instances:</p> <pre><code>import torch\nfrom qadence import AnalogRot, AnalogRX\n# Implement a global RX rotation by setting all parameters.\nblock = AnalogRot(\nduration=1000., # [ns]\nomega=torch.pi, # [rad/\u03bcs]\ndelta=0,        # [rad/\u03bcs]\nphase=0,        # [rad]\n)\n# Or use the shortcut.\nblock = AnalogRX(torch.pi)\n</code></pre> <pre><code>AnalogRot = ConstantAnalogRotation(\u03b1=3.14159265358979, t=1000.00000000000, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,), \u03a9=3.14159265358979, \u03b4=0, \u03c6=0)\nAnalogRX = ConstantAnalogRotation(\u03b1=3.14159265358979, t=1000.00000000000, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,), \u03a9=3.14159265358979, \u03b4=0, \u03c6=0)\n</code></pre> <p>Automatic emulation in the PyQTorch backend</p> <p>All analog blocks are automatically translated to their emulated version when running them with the PyQTorch backend:</p> <p><pre><code>import torch\nfrom qadence import Register, AnalogRX, sample\nreg = Register.from_coordinates([(0,0), (0,5)])\nsample = sample(reg, AnalogRX(torch.pi))\n</code></pre> <pre><code>sample = [Counter({'00': 40, '10': 32, '01': 28})]\n</code></pre> </p> <p>To compose analog blocks, the regular <code>chain</code> and <code>kron</code> operations can be used under the following restrictions:</p> <ul> <li>The resulting <code>AnalogChain</code> type can only be constructed from <code>AnalogKron</code> blocks   or globally supported primitive analog blocks.</li> <li>The resulting <code>AnalogKron</code> type can only be constructed from non-global   analog blocks with the same duration.</li> </ul> <pre><code>import torch\nfrom qadence import AnalogRot, kron, chain, wait\n# Only analog blocks with a global qubit support can be composed\n# using chain.\nanalog_chain = chain(wait(duration=200), AnalogRot(duration=300, omega=2.0))\n# Only blocks with the same `duration` can be composed using kron.\nanalog_kron = kron(\nwait(duration=1000, qubit_support=(0,1)),\nAnalogRot(duration=1000, omega=2.0, qubit_support=(2,3))\n)\n</code></pre> <pre><code>Analog Chain block = AnalogChain(t=500.000000000000, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,))\n\u251c\u2500\u2500 WaitBlock(t=200.0, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,))\n\u2514\u2500\u2500 ConstantAnalogRotation(\u03b1=0.600000000000000, t=300, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,), \u03a9=2.00000000000000, \u03b4=0, \u03c6=0)\nAnalog Kron block = AnalogKron(t=1000, support=(0, 1, 2, 3))\n\u251c\u2500\u2500 WaitBlock(t=1000.0, support=(0, 1))\n\u2514\u2500\u2500 ConstantAnalogRotation(\u03b1=2.00000000000000, t=1000, support=(2, 3), \u03a9=2.00000000000000, \u03b4=0, \u03c6=0)\n</code></pre> <p>Composing digital &amp; analog blocks</p> <p>It is possible to compose digital and analog blocks where the additional restrictions for <code>chain</code> and <code>kron</code> only apply to composite blocks which contain analog blocks only. For further details, see <code>AnalogChain</code> and <code>AnalogKron</code>.</p>"},{"location":"digital_analog_qc/analog-basics/#fitting-a-simple-function","title":"Fitting a simple function","text":"<p>Analog blocks can be parametrized in the usual Qadence manner. Like any other parameters, they can be optimized. The next snippet examplifies the creation of an analog and paramertized ansatze to fit a sine function. First, define an ansatz block and an observable:</p> <pre><code>import torch\nfrom qadence import Register, FeatureParameter, VariationalParameter\nfrom qadence import AnalogRX, AnalogRZ, Z\nfrom qadence import wait, chain, add\npi = torch.pi\n# A two qubit register.\nreg = Register.from_coordinates([(0, 0), (0, 12)])\n# An analog ansatz with an input time parameter.\nt = FeatureParameter(\"t\")\nblock = chain(\nAnalogRX(pi/2.),\nAnalogRZ(t),\nwait(1000 * VariationalParameter(\"theta\", value=0.5)),\nAnalogRX(pi/2),\n)\n# Total magnetization observable.\nobs = add(Z(i) for i in range(reg.n_qubits))\n</code></pre> Plotting functions <code>plot</code> and <code>scatter</code> <p><pre><code>def plot(ax, x, y, **kwargs):\nxnp = x.detach().cpu().numpy().flatten()\nynp = y.detach().cpu().numpy().flatten()\nax.plot(xnp, ynp, **kwargs)\ndef scatter(ax, x, y, **kwargs):\nxnp = x.detach().cpu().numpy().flatten()\nynp = y.detach().cpu().numpy().flatten()\nax.scatter(xnp, ynp, **kwargs)\n</code></pre> </p> <p>Next, define the dataset to train on and plot the initial prediction. The differentiation mode can be set to either <code>DiffMode.AD</code> or <code>DiffMode.GPSR</code>.</p> <pre><code>import matplotlib.pyplot as plt\nfrom qadence import QuantumCircuit, QuantumModel, DiffMode\n# Define a quantum model including digital-analog emulation.\ncirc = QuantumCircuit(reg, block)\nmodel = QuantumModel(circ, obs, diff_mode=DiffMode.GPSR)\n# Time support dataset.\nx_train = torch.linspace(0, 6, steps=30)\n# Function to fit.\ny_train = -0.64 * torch.sin(x_train + 0.33) + 0.1\n# Initial prediction.\ny_pred_initial = model.expectation({\"t\": x_train})\n</code></pre> 2023-10-25T16:44:32.055436 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ <p>Finally, the classical optimization part is handled by PyTorch:</p> <pre><code># Use PyTorch built-in functionality.\nmse_loss = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-2)\n# Define a loss function.\ndef loss_fn(x_train, y_train):\nreturn mse_loss(model.expectation({\"t\": x_train}).squeeze(), y_train)\n# Number of epochs to train over.\nn_epochs = 200\n# Optimization loop.\nfor i in range(n_epochs):\noptimizer.zero_grad()\nloss = loss_fn(x_train, y_train)\nloss.backward()\noptimizer.step()\n# Get and visualize the final prediction.\ny_pred = model.expectation({\"t\": x_train})\n</code></pre> 2023-10-25T16:44:42.164298 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"digital_analog_qc/analog-qubo/","title":"Solve a QUBO problem","text":"<p>In this notebook we solve a quadratic unconstrained optimization problem with Qadence emulated analog interface using the QAOA variational algorithm. The problem is detailed in the Pulser documentation here.</p>"},{"location":"digital_analog_qc/analog-qubo/#define-and-solve-qubo","title":"Define and solve QUBO","text":"Pre-requisite: construct QUBO register <p>Before we start we have to define a register that fits into our device. <pre><code>import torch\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import pdist, squareform\nfrom pulser.devices import Chadoq2\nseed = 0\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ndef qubo_register_coords(Q):\n\"\"\"Compute coordinates for register.\"\"\"\nbitstrings = [np.binary_repr(i, len(Q)) for i in range(len(Q) ** 2)]\ncosts = []\n# this takes exponential time with the dimension of the QUBO\nfor b in bitstrings:\nz = np.array(list(b), dtype=int)\ncost = z.T @ Q @ z\ncosts.append(cost)\nzipped = zip(bitstrings, costs)\nsort_zipped = sorted(zipped, key=lambda x: x[1])\ndef evaluate_mapping(new_coords, *args):\n\"\"\"Cost function to minimize. Ideally, the pairwise\n        distances are conserved\"\"\"\nQ, shape = args\nnew_coords = np.reshape(new_coords, shape)\nnew_Q = squareform(Chadoq2.interaction_coeff / pdist(new_coords) ** 6)\nreturn np.linalg.norm(new_Q - Q)\nshape = (len(Q), 2)\ncosts = []\nnp.random.seed(0)\nx0 = np.random.random(shape).flatten()\nres = minimize(\nevaluate_mapping,\nx0,\nargs=(Q, shape),\nmethod=\"Nelder-Mead\",\ntol=1e-6,\noptions={\"maxiter\": 200000, \"maxfev\": None},\n)\nreturn [(x, y) for (x, y) in np.reshape(res.x, (len(Q), 2))]\n</code></pre> </p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom qadence import add_interaction, chain\nfrom qadence import QuantumModel, QuantumCircuit, AnalogRZ, AnalogRX, Register\nseed = 0\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n</code></pre> <p>The QUBO problem is initially defined by a graph of weighted connections <code>Q</code> and a cost function.</p> <pre><code>def cost_colouring(bitstring, Q):\nz = np.array(list(bitstring), dtype=int)\ncost = z.T @ Q @ z\nreturn cost\n# Cost function.\ndef cost_fn(counter, Q):\ncost = sum(counter[key] * cost_colouring(key, Q) for key in counter)\nreturn cost / sum(counter.values())  # Divide by total samples\n# Weights.\nQ = np.array(\n[\n[-10.0, 19.7365809, 19.7365809, 5.42015853, 5.42015853],\n[19.7365809, -10.0, 20.67626392, 0.17675796, 0.85604541],\n[19.7365809, 20.67626392, -10.0, 0.85604541, 0.17675796],\n[5.42015853, 0.17675796, 0.85604541, -10.0, 0.32306662],\n[5.42015853, 0.85604541, 0.17675796, 0.32306662, -10.0],\n]\n)\n</code></pre> <p>Now, build a weighted register graph from the QUBO definition similarly to what is done in Pulser.</p> <pre><code>reg = Register.from_coordinates(qubo_register_coords(Q))\n</code></pre> <p>The analog circuit is composed of two global rotations per layer.  The first rotation corresponds to the mixing Hamiltonian and the second one to the embedding Hamiltonian in the QAOA algorithm. Subsequently, there is an Ising interaction term to emulate the analog circuit. Please note that the Rydberg level is set to 70.</p> <pre><code>from qadence.transpile.emulate import ising_interaction\nlayers = 2\nblock = chain(*[AnalogRX(f\"t{i}\") * AnalogRZ(f\"s{i}\") for i in range(layers)])\nemulated = add_interaction(\nreg, block, interaction=lambda r, ps: ising_interaction(r, ps, rydberg_level=70)\n)\n</code></pre> <pre><code>emulated = ChainBlock(0,1,2,3,4)\n\u251c\u2500\u2500 ChainBlock(0,1,2,3,4)\n\u2502   \u251c\u2500\u2500 HamEvo(0,1,2,3,4) [params: ['51_4100727736005*t0']]\n\u2502   \u2514\u2500\u2500 HamEvo(0,1,2,3,4) [params: ['39_0388262113427*s0']]\n\u2514\u2500\u2500 ChainBlock(0,1,2,3,4)\n\u251c\u2500\u2500 HamEvo(0,1,2,3,4) [params: ['51_4100727736005*t1']]\n\u2514\u2500\u2500 HamEvo(0,1,2,3,4) [params: ['39_0388262113427*s1']]\n</code></pre> <p>Next, an initial solution is computed by sampling the model:</p> <pre><code>model = QuantumModel(QuantumCircuit(reg, emulated), backend=\"pyqtorch\", diff_mode='gpsr')\ninitial_counts = model.sample({}, n_shots=1000)[0]\n</code></pre> <pre><code>initial_counts = Counter({'00000': 470, '01000': 90, '00100': 88, '00001': 74, '00010': 71, '10000': 70, '00101': 19, '11000': 19, '10100': 14, '10001': 13, '10010': 12, '00110': 11, '01001': 11, '00011': 9, '01010': 8, '01100': 6, '01101': 3, '10110': 3, '01011': 2, '01110': 2, '10011': 2, '11010': 2, '00111': 1})\n</code></pre> <p>Then, the loss function is defined by averaging over the evaluated bitstrings.</p> <pre><code>def loss(param, *args):\nQ = args[0]\nparam = torch.tensor(param)\nmodel.reset_vparams(param)\nC = model.sample({}, n_shots=1000)[0]\nreturn cost_fn(C, Q)\n</code></pre> <p>And a gradient-free optimization loop is used to compute the optimal solution.</p> <pre><code># Optimization loop.\nfor i in range(20):\nres = minimize(\nloss,\nargs=Q,\nx0=np.random.uniform(1, 10, size=2 * layers),\nmethod=\"COBYLA\",\ntol=1e-8,\noptions={\"maxiter\": 20},\n)\n# Sample and visualize the optimal solution.\nmodel.reset_vparams(res.x)\noptimal_count = model.sample({}, n_shots=1000)[0]\n</code></pre> <pre><code>optimal_count = Counter({'00111': 299, '00011': 187, '01010': 94, '00010': 77, '00101': 62, '01011': 52, '00001': 49, '10010': 44, '00100': 42, '00110': 32, '01001': 15, '01000': 12, '10011': 10, '01111': 7, '10001': 6, '01110': 5, '00000': 3, '01100': 3, '01101': 1})\n</code></pre> <p>Finally, plot the solution:</p> <pre><code># Known solutions to the QUBO problem.\nsolution_bitstrings=[\"01011\", \"00111\"]\n</code></pre> 2023-10-25T16:44:45.254184 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"digital_analog_qc/daqc-basics/","title":"Digital-Analog Quantum Computation","text":"<p>Digital-analog quantum computation (DAQC) is a universal quantum computing paradigm<sup>1</sup>, based on two primary computations:</p> <ul> <li>Fast single-qubit operations (digital).</li> <li>Multi-partite entangling operations acting on all qubits (analog).</li> </ul> <p>The DAQC paradigm is typically implemented on quantum computing hardware based on neutral-atoms where both these computations are realizable.</p>"},{"location":"digital_analog_qc/daqc-basics/#digital-analog-emulation","title":"Digital-analog emulation","text":"<p>Qadence simplifies the execution of DAQC programs on either emulated or real neutral-atom devices by providing a simplified interface for customizing interactions and interfacing with pulse-level programming in <code>Pulser</code><sup>3</sup>.</p>"},{"location":"digital_analog_qc/daqc-basics/#digital-analog-transformation","title":"Digital-analog transformation","text":"<p>Furthermore, the essence of digital-analog computation is the ability to represent any analog operation, i.e. any arbitrary Hamiltonian, using an auxiliary device-amenable Hamiltonian, such as the ubiquitous Ising model<sup>2</sup>. This is at the core of the DAQC implementation in Qadence.</p>"},{"location":"digital_analog_qc/daqc-basics/#references","title":"References","text":"<ol> <li> <p>Dodd et al., Universal quantum computation and simulation using any entangling Hamiltonian and local unitaries, PRA 65, 040301 (2002). \u21a9</p> </li> <li> <p>Pulser: An open-source package for the design of pulse sequences in programmable neutral-atom arrays \u21a9</p> </li> <li> <p>Parra-Rodriguez et al., Digital-Analog Quantum Computation, PRA 101, 022305 (2020). \u21a9</p> </li> </ol>"},{"location":"digital_analog_qc/daqc-cnot/","title":"<code>CNOT</code> with interacting qubits","text":"<p>Digital-analog quantum computing focuses on using single qubit digital gates combined with more complex and device-dependent analog interactions to represent quantum programs. This paradigm has been shown to be universal for quantum computation<sup>1</sup>. However, while this approach may have advantages when adapting quantum programs to real devices, known quantum algorithms are very often expressed in a fully digital paradigm. As such, it is also important to have concrete ways to transform from one paradigm to another.</p> <p>This tutorial will exemplify the DAQC transformation starting with the representation of a simple digital <code>CNOT</code> using the universality of the Ising Hamiltonian<sup>2</sup>.</p>"},{"location":"digital_analog_qc/daqc-cnot/#cnot-with-cphase","title":"<code>CNOT</code> with <code>CPHASE</code>","text":"<p>Let's look at a single example of how the digital-analog transformation can be used to perform a <code>CNOT</code> on two qubits inside a register of globally interacting qubits.</p> <p>First, note that the <code>CNOT</code> can be decomposed with two Hadamard and a <code>CPHASE</code> gate with \\(\\phi=\\pi\\):</p> <pre><code>import torch\nfrom qadence import chain, sample, product_state\nfrom qadence.draw import display\nfrom qadence import X, I, Z, H, N, CPHASE, CNOT, HamEvo\nn_qubits = 2\n# CNOT gate\ncnot_gate = CNOT(0, 1)\n# CNOT decomposed\nphi = torch.pi\ncnot_decomp = chain(H(1), CPHASE(0, 1, phi), H(1))\ninit_state = product_state(\"10\")\n</code></pre> <pre><code>sample from CNOT gate and 100 shots = [Counter({'11': 100})]\nsample from decomposed CNOT gate and 100 shots = [Counter({'11': 100})]\n</code></pre> <p>The <code>CPHASE</code> matrix is diagonal, and can be implemented by exponentiating an Ising-like Hamiltonian, or generator,</p> \\[\\text{CPHASE}(i,j,\\phi)=\\text{exp}\\left(-i\\phi \\mathcal{H}_\\text{CP}(i, j)\\right)\\] \\[\\begin{aligned} \\mathcal{H}_\\text{CP}&amp;=-\\frac{1}{4}(I_i-Z_i)(I_j-Z_j)\\\\ &amp;=-N_iN_j \\end{aligned}\\] <p>where the number operator \\(N_i = \\frac{1}{2}(I_i-Z_i)=\\hat{n}_i\\) is used, leading to an Ising-like interaction \\(\\hat{n}_i\\hat{n}_j\\) realisable in neutral-atom systems. Let's rebuild the <code>CNOT</code> using this evolution.</p> <pre><code>from qadence import kron, block_to_tensor\n# Hamiltonian for the CPHASE gate\nh_cphase = (-1.0) * kron(N(0), N(1))\n# Exponentiating and time-evolving the Hamiltonian until t=phi.\ncphase_evo = HamEvo(h_cphase, phi)\n# Check that we have the CPHASE gate:\ncphase_matrix = block_to_tensor(CPHASE(0, 1, phi))\ncphase_evo_matrix = block_to_tensor(cphase_evo)\n</code></pre> <pre><code>cphase_matrix == cphase_evo_matrix: True\n</code></pre> <p>Now that the <code>CPHASE</code> generator is checked, it can be applied to the <code>CNOT</code>:</p> <pre><code># CNOT with Hamiltonian Evolution\ncnot_evo = chain(\nH(1),\ncphase_evo,\nH(1)\n)\n# Initialize state to check CNOTs sample outcomes.\ninit_state = product_state(\"10\")\n</code></pre> <pre><code>sample cnot_gate = [Counter({'11': 100})]\nsample cnot_evo = [Counter({'11': 100})]\n</code></pre> <p>Thus, a <code>CNOT</code> gate can be created by combining a few single-qubit gates together with a two-qubit Ising interaction between the control and the target qubit which is the essence of the Ising transform proposed in the seminal DAQC paper<sup>2</sup> for \\(ZZ\\) interactions. In Qadence, both \\(ZZ\\) and \\(NN\\) interactions are supported.</p>"},{"location":"digital_analog_qc/daqc-cnot/#cnot-in-an-interacting-system-of-three-qubits","title":"<code>CNOT</code> in an interacting system of three qubits","text":"<p>Consider a simple experimental setup with \\(n=3\\) interacting qubits laid out in a triangular grid. For the sake of simplicity, all qubits interact with each other with an \\(NN\\)-Ising interaction of constant strength \\(g_\\text{int}\\). The Hamiltonian for the system can be written by summing interaction terms over all pairs:</p> \\[\\mathcal{H}_\\text{sys}=\\sum_{i=0}^{n}\\sum_{j=0}^{i-1}g_\\text{int}N_iN_j,\\] <p>which in this case leads to only three interaction terms,</p> \\[\\mathcal{H}_\\text{sys}=g_\\text{int}(N_0N_1+N_1N_2+N_0N_2)\\] <p>This generator can be easily built in Qadence:</p> <pre><code>from qadence import add, kron\nn_qubits = 3\n# Interaction strength.\ng_int = 1.0\n# Build a list of interactions.\ninteraction_list = []\nfor i in range(n_qubits):\nfor j in range(i):\ninteraction_list.append(g_int * kron(N(i), N(j)))\nh_sys = add(*interaction_list)\n</code></pre> <pre><code>h_sys = AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(0)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(2)\n\u2502       \u2514\u2500\u2500 N(0)\n\u2514\u2500\u2500 [mul: 1.00000000000000] \u2514\u2500\u2500 KronBlock(1,2)\n\u251c\u2500\u2500 N(2)\n\u2514\u2500\u2500 N(1)\n</code></pre> <p>Now let's consider that the experimental system is fixed, and qubits can not be isolated one from another. The options are:</p> <ul> <li>Turn on or off the global system Hamiltonian.</li> <li>Perform local single-qubit rotations.</li> </ul> <p>To perform a fully digital <code>CNOT(0,1)</code>, the interacting control on qubit 0 and target on qubit 1 must be isolated from the third one to implement the gate directly. While this can be achieved for a three-qubit system, it becomes experimentally untractable when scaling the qubit count.</p> <p>However, this is not the case within the digital-analog paradigm. In fact, the two qubit Ising interaction required for the <code>CNOT</code> can be represented with a combination of the global system Hamiltonian and a specific set of single-qubit rotations. Full details about this transformation are to be found in the DAQC paper<sup>2</sup> but a more succint yet in-depth description takes place in the next section. It is conveniently available in Qadence by calling the <code>daqc_transform</code> function.</p> <p>In the most general sense, the <code>daqc_transform</code> function will return a circuit that represents the evolution of a target Hamiltonian \\(\\mathcal{H}_\\text{target}\\) (here the unitary of the gate) until a specified time \\(t_f\\) by using only the evolution of a build Hamiltonian \\(\\mathcal{H}_\\text{build}\\) (here \\(\\mathcal{H}_\\text{sys}\\)) together with local \\(X\\)-gates. In Qadence, <code>daqc_transform</code> is applicable for \\(\\mathcal{H}_\\text{target}\\) and \\(\\mathcal{H}_\\text{build}\\) composed only of \\(ZZ\\)- or \\(NN\\)-interactions. These generators are parsed by the <code>daqc_transform</code> function and the appropriate type is automatically determined together with the appropriate single-qubit detunings and global phases.</p> <p>Let's apply it for the <code>CNOT</code> implementation:</p> <pre><code>from qadence import daqc_transform, Strategy\n# Settings for the target CNOT operation\ni = 0  # Control qubit\nj = 1  # Target qubit\nk = 2  # The extra qubit\n# Define the target CNOT operation\n# by composing with identity on the extra qubit.\ncnot_target = kron(CNOT(i, j), I(k))\n# The two-qubit NN-Ising interaction term for the CPHASE\nh_int = (-1.0) * kron(N(i), N(j))\n# Transforming the two-qubit Ising interaction using only our system Hamiltonian\ntransformed_ising = daqc_transform(\nn_qubits=3,        # Total number of qubits in the transformation\ngen_target=h_int,  # The target Ising generator\nt_f=torch.pi,      # The target evolution time\ngen_build=h_sys,   # The building block Ising generator to be used\nstrategy=Strategy.SDAQC,   # Currently only sDAQC is implemented\nignore_global_phases=False  # Global phases from mapping between Z and N\n)\n# display(transformed_ising)\n</code></pre> %3 cluster_e061217bf248482c87a6d92dc054bef6 cluster_e52d9442142c436f83de456550cf43f5 cluster_812209e5106f4ab9bd78fb1a7c40a0be cluster_5d73ecc99bbd465986cb81602ff0be47 cluster_1dd45656162c4779bb28ed6179b5b9d8 cluster_0a5387cfc357472da4efabd60d5ff622 cluster_9b3c8e4e580943a780fafdec0059e47b b01963baddc14c98bda35d1950e31777 0 927d7d8bd2fe4d69b9eedd9c19b92b1e HamEvo b01963baddc14c98bda35d1950e31777--927d7d8bd2fe4d69b9eedd9c19b92b1e 7e2e3c8285e5473a9e771b90caab8a40 1 00f739b850e9451488fac1c1c1d6e36a HamEvo 927d7d8bd2fe4d69b9eedd9c19b92b1e--00f739b850e9451488fac1c1c1d6e36a 7277252dcac24bfdb460fabf9033d4fa HamEvo 00f739b850e9451488fac1c1c1d6e36a--7277252dcac24bfdb460fabf9033d4fa f3f6068388cf41c7bd0d9512872321ee X 7277252dcac24bfdb460fabf9033d4fa--f3f6068388cf41c7bd0d9512872321ee d826e6e6886d4c43b9387d14af826572 HamEvo f3f6068388cf41c7bd0d9512872321ee--d826e6e6886d4c43b9387d14af826572 005b253d84b94dc2a5aad29973ae44d3 HamEvo d826e6e6886d4c43b9387d14af826572--005b253d84b94dc2a5aad29973ae44d3 f2229401166a4153baec3481ae65ef8f X 005b253d84b94dc2a5aad29973ae44d3--f2229401166a4153baec3481ae65ef8f d613ce5130554027a039466f9ea5dc05 f2229401166a4153baec3481ae65ef8f--d613ce5130554027a039466f9ea5dc05 afc54bce9cab4bc9a68402c4cdf40477 HamEvo d613ce5130554027a039466f9ea5dc05--afc54bce9cab4bc9a68402c4cdf40477 0377808d78834f9c8dddfde1af81661a HamEvo afc54bce9cab4bc9a68402c4cdf40477--0377808d78834f9c8dddfde1af81661a f4e54a68c44f41b4a9da5b249bcdd1c0 0377808d78834f9c8dddfde1af81661a--f4e54a68c44f41b4a9da5b249bcdd1c0 b070d44024334c799fcf1a55a1db3618 f4e54a68c44f41b4a9da5b249bcdd1c0--b070d44024334c799fcf1a55a1db3618 b0734549bf354b888fe6122fe42db940 d0e8335db4a14602a01abeb6d9a91690 t = -3.142 7e2e3c8285e5473a9e771b90caab8a40--d0e8335db4a14602a01abeb6d9a91690 973ba4b448a84b58900bf470f61cd3b5 2 8c369256660f41b9a7385029ed99d74e t = 3.142 d0e8335db4a14602a01abeb6d9a91690--8c369256660f41b9a7385029ed99d74e 09f6e6b96e53433b8b6b08210302ca11 t = -3.142 8c369256660f41b9a7385029ed99d74e--09f6e6b96e53433b8b6b08210302ca11 9adfad882b2f441f9a132b63b26d7eb9 09f6e6b96e53433b8b6b08210302ca11--9adfad882b2f441f9a132b63b26d7eb9 611c4c7091e64c16b871e79e542f43bc t = 1.571 9adfad882b2f441f9a132b63b26d7eb9--611c4c7091e64c16b871e79e542f43bc d71f3375491f4e24b116e7209a632739 t = 1.571 611c4c7091e64c16b871e79e542f43bc--d71f3375491f4e24b116e7209a632739 47a9781b0583435585ad64c16fcb589f d71f3375491f4e24b116e7209a632739--47a9781b0583435585ad64c16fcb589f e3e53b8cc7fb4421a1fce3d924d87503 X 47a9781b0583435585ad64c16fcb589f--e3e53b8cc7fb4421a1fce3d924d87503 03dda32f6c274188a9a2cef84fd95d3e t = 1.571 e3e53b8cc7fb4421a1fce3d924d87503--03dda32f6c274188a9a2cef84fd95d3e e8bb192c2016405788029ae5f8b997eb t = 1.571 03dda32f6c274188a9a2cef84fd95d3e--e8bb192c2016405788029ae5f8b997eb 8284f49438574362b08ec5e465c52c1e X e8bb192c2016405788029ae5f8b997eb--8284f49438574362b08ec5e465c52c1e 8284f49438574362b08ec5e465c52c1e--b0734549bf354b888fe6122fe42db940 a4b00c0681e54eedbb61000736627bf4 7dab784ca7fc4299873c50a8c951dab9 973ba4b448a84b58900bf470f61cd3b5--7dab784ca7fc4299873c50a8c951dab9 0f4e84b069ff478d832b2834e4ded9ac 7dab784ca7fc4299873c50a8c951dab9--0f4e84b069ff478d832b2834e4ded9ac b584cd4c524d43748d4a3849fe0a893d 0f4e84b069ff478d832b2834e4ded9ac--b584cd4c524d43748d4a3849fe0a893d bb424477ea3940e7a894a511feffb950 X b584cd4c524d43748d4a3849fe0a893d--bb424477ea3940e7a894a511feffb950 a2fb193104934a45aa2ff7b0bef64034 bb424477ea3940e7a894a511feffb950--a2fb193104934a45aa2ff7b0bef64034 09324a3b5d6e4b46aa6d7461fbe68d93 a2fb193104934a45aa2ff7b0bef64034--09324a3b5d6e4b46aa6d7461fbe68d93 8365bc24fe00485482744a6eb69ac593 X 09324a3b5d6e4b46aa6d7461fbe68d93--8365bc24fe00485482744a6eb69ac593 d08937ebc3084c06ad023491182f2e24 X 8365bc24fe00485482744a6eb69ac593--d08937ebc3084c06ad023491182f2e24 8c6739710bcf4392ab7d81a8e6556cc2 d08937ebc3084c06ad023491182f2e24--8c6739710bcf4392ab7d81a8e6556cc2 b2417e6a43f44776996f9a4c98255d01 8c6739710bcf4392ab7d81a8e6556cc2--b2417e6a43f44776996f9a4c98255d01 b2f9d66f814f46c8b2acd2fc7ead2525 X b2417e6a43f44776996f9a4c98255d01--b2f9d66f814f46c8b2acd2fc7ead2525 b2f9d66f814f46c8b2acd2fc7ead2525--a4b00c0681e54eedbb61000736627bf4 <p>The output circuit displays three groups of system Hamiltonian evolutions which account for global-phases and single-qubit detunings related to the mapping between the \\(Z\\) and \\(N\\) operators. Optionally, global phases can be ignored.</p> <p>In general, the mapping of a \\(n\\)-qubit Ising Hamiltonian to another will require at most \\(n(n-1)\\) evolutions. The transformed circuit performs these evolutions for specific times that are computed from the solution of a linear system of equations involving the set of interactions in the target and build Hamiltonians.</p> <p>In this case, the mapping is exact when using the step-wise DAQC strategy (<code>Strategy.SDAQC</code>) available in Qadence. In banged DAQC (<code>Strategy.BDAQC</code>) the mapping is approximate, but easier to implement on a physical device with always-on interactions such as neutral-atom systems.</p> <p>Just as before, the transformed Ising circuit can be checked to exactly recover the <code>CPHASE</code> gate:</p> <pre><code># CPHASE on (i, j), Identity on third qubit:\ncphase_matrix = block_to_tensor(kron(CPHASE(i, j, phi), I(k)))\n# CPHASE using the transformed circuit:\ncphase_evo_matrix = block_to_tensor(transformed_ising)\n# Check that it implements the CPHASE.\n# Will fail if global phases are ignored.\n</code></pre> <pre><code>cphase_matrix == cphase_evo_matrix : True\n</code></pre> <p>The <code>CNOT</code> gate can now finally be built:</p> <pre><code>from qadence import equivalent_state, run, sample\ncnot_daqc = chain(\nH(j),\ntransformed_ising,\nH(j)\n)\n# And finally apply the CNOT on a specific 3-qubit initial state:\ninit_state = product_state(\"101\")\n# Check we get an equivalent wavefunction\nwf_cnot = run(n_qubits, block=cnot_target, state=init_state)\nwf_daqc = run(n_qubits, block=cnot_daqc, state=init_state)\n# Visualize the CNOT bit-flip in samples.\n</code></pre> <pre><code>wf_cnot == wf_dacq : True\nsample cnot_target = [Counter({'111': 100})]\nsample cnot_dacq = [Counter({'111': 100})]\n</code></pre> <p>As one can see, a <code>CNOT</code> operation has been succesfully implemented on the desired target qubits by using only the global system as the building block Hamiltonian and single-qubit rotations. Decomposing a single digital gate into an Ising Hamiltonian serves as a proof of principle for the potential of this technique to represent universal quantum computation.</p>"},{"location":"digital_analog_qc/daqc-cnot/#technical-details-on-the-daqc-transformation","title":"Technical details on the DAQC transformation","text":"<ul> <li>The mapping between target generator and final circuit is performed by solving a linear system of size \\(n(n-1)\\) where \\(n\\) is the number of qubits, so it can be computed efficiently (i.e., with a polynomial cost in the number of qubits).</li> <li>The linear system to be solved is actually not invertible for \\(n=4\\) qubits. This is very specific edge case requiring a workaround, that is currently not yet implemented.</li> <li>As mentioned, the final circuit has at most \\(n(n-1)\\) slices, so there is at most a quadratic overhead in circuit depth.</li> </ul> <p>Finally, and most important to its usage:</p> <ul> <li>The target Hamiltonian should be sufficiently represented in the building block Hamiltonian.</li> </ul> <p>To illustrate this point, consider the following target and build Hamiltonians:</p> <pre><code># Interaction between qubits 0 and 1\ngen_target = 1.0 * (Z(0) @ Z(1))\n# Fixed interaction between qubits 1 and 2, and customizable between 0 and 1\ndef gen_build(g_int):\nreturn g_int * (Z(0) @ Z(1)) + 1.0 * (Z(1) @ Z(2))\n</code></pre> <p>And now we perform the DAQC transform by setting <code>g_int=1.0</code>, exactly matching the target Hamiltonian:</p> <pre><code>transformed_ising = daqc_transform(\nn_qubits=3,\ngen_target=gen_target,\nt_f=1.0,\ngen_build=gen_build(g_int=1.0),\n)\n# display(transformed_ising)\n</code></pre> %3 cluster_104c4122548f4555ab5c932d0a644b3c cluster_a1ac2effd2cf45428b1b761c037e2503 d40c26d0d63046d888dadfc0e68bd1a4 0 fd3735ac76bc4e8ebae911524cf0f1bf X d40c26d0d63046d888dadfc0e68bd1a4--fd3735ac76bc4e8ebae911524cf0f1bf 055d93ac256d4ac9a0587425ec7b517e 1 d3387f6d8ae64e39877950f9f36c3861 HamEvo fd3735ac76bc4e8ebae911524cf0f1bf--d3387f6d8ae64e39877950f9f36c3861 099bbd9cd1034c768b0aa35d66b29066 X d3387f6d8ae64e39877950f9f36c3861--099bbd9cd1034c768b0aa35d66b29066 0a6f4acd6ad749afa28e9cd2be44caaf 099bbd9cd1034c768b0aa35d66b29066--0a6f4acd6ad749afa28e9cd2be44caaf 615d671af9454e53a9890902ff3c635f HamEvo 0a6f4acd6ad749afa28e9cd2be44caaf--615d671af9454e53a9890902ff3c635f e23fa32420fc4bf49e3aeb70bad0d534 615d671af9454e53a9890902ff3c635f--e23fa32420fc4bf49e3aeb70bad0d534 7bf7eb85e7cf40e9b832fd9787225e27 e23fa32420fc4bf49e3aeb70bad0d534--7bf7eb85e7cf40e9b832fd9787225e27 942dd15135414074927e1d4666923af2 25f22626700843afbaa5a0f73f2c91f9 055d93ac256d4ac9a0587425ec7b517e--25f22626700843afbaa5a0f73f2c91f9 ae7deaf4055f4899aacb90872463dac1 2 a5395c8aeaaa4eb3989d7041e7670dce t = -0.500 25f22626700843afbaa5a0f73f2c91f9--a5395c8aeaaa4eb3989d7041e7670dce f60a190848634680a69e3e6f0f543809 a5395c8aeaaa4eb3989d7041e7670dce--f60a190848634680a69e3e6f0f543809 834aec1ac0b542d0922a75d5cea2bd85 X f60a190848634680a69e3e6f0f543809--834aec1ac0b542d0922a75d5cea2bd85 9da60afb51134bdd9dca17968d2641e8 t = -0.500 834aec1ac0b542d0922a75d5cea2bd85--9da60afb51134bdd9dca17968d2641e8 75ac9d79a0c74888913626c808557739 X 9da60afb51134bdd9dca17968d2641e8--75ac9d79a0c74888913626c808557739 75ac9d79a0c74888913626c808557739--942dd15135414074927e1d4666923af2 22a6fe5ffd7840269b773cc8b108562c d36de44e91ab49148267c8c20acfbdf5 X ae7deaf4055f4899aacb90872463dac1--d36de44e91ab49148267c8c20acfbdf5 92227471a45c457b8bf171436ef61392 d36de44e91ab49148267c8c20acfbdf5--92227471a45c457b8bf171436ef61392 d94e960d6f4a4b6dbe47b01090a004e0 X 92227471a45c457b8bf171436ef61392--d94e960d6f4a4b6dbe47b01090a004e0 1a63fbc4d44d478793fd8f6db4b3cfa2 X d94e960d6f4a4b6dbe47b01090a004e0--1a63fbc4d44d478793fd8f6db4b3cfa2 1a1db1eb05c6446f94a23a3eae485863 1a63fbc4d44d478793fd8f6db4b3cfa2--1a1db1eb05c6446f94a23a3eae485863 097a77b2de1545c689367c0bb7cec472 X 1a1db1eb05c6446f94a23a3eae485863--097a77b2de1545c689367c0bb7cec472 097a77b2de1545c689367c0bb7cec472--22a6fe5ffd7840269b773cc8b108562c <p>Now, if the interaction between qubits 0 and 1 is weakened in the build Hamiltonian:</p> <pre><code>transformed_ising = daqc_transform(\nn_qubits=3,\ngen_target=gen_target,\nt_f=1.0,\ngen_build=gen_build(g_int=0.001),\n)\n# display(transformed_ising)\n</code></pre> %3 cluster_a8c49c8f7312460d9272024b1889cad2 cluster_ff2a6bc18abf4e6d8ced9bf0b0daa193 507973b2ae01464da4e40ebc6be56451 0 0dac5d7279094c1c8190061f1c6c0960 X 507973b2ae01464da4e40ebc6be56451--0dac5d7279094c1c8190061f1c6c0960 b774d063f69a4915b3a19c4744839c8a 1 64a5c25b0cc048c08cdfba85e6275b72 HamEvo 0dac5d7279094c1c8190061f1c6c0960--64a5c25b0cc048c08cdfba85e6275b72 b4885377abb24e64bd8b5a8ad5cbee00 X 64a5c25b0cc048c08cdfba85e6275b72--b4885377abb24e64bd8b5a8ad5cbee00 02354f611b174049ae2bc048ba590115 b4885377abb24e64bd8b5a8ad5cbee00--02354f611b174049ae2bc048ba590115 9409531a52d8438c8aa7e2b292af5121 HamEvo 02354f611b174049ae2bc048ba590115--9409531a52d8438c8aa7e2b292af5121 3cdc98c087a04ace808fdf4adb958a14 9409531a52d8438c8aa7e2b292af5121--3cdc98c087a04ace808fdf4adb958a14 592da8af1ee84a9784bf305671195554 3cdc98c087a04ace808fdf4adb958a14--592da8af1ee84a9784bf305671195554 614b7b3c8d704773ae55671f2dc79aec 10015766287b4b4db12cb60c9f6c319b b774d063f69a4915b3a19c4744839c8a--10015766287b4b4db12cb60c9f6c319b 5283241cd47744ac85f7c7499767e008 2 98270c7931284da7b1e739019a63a3ea t = -500.000000000000 10015766287b4b4db12cb60c9f6c319b--98270c7931284da7b1e739019a63a3ea 8370a119b2e649ffae91e43aaa337f85 98270c7931284da7b1e739019a63a3ea--8370a119b2e649ffae91e43aaa337f85 fa05068c1e3442a2b2d109ff7f0b7006 X 8370a119b2e649ffae91e43aaa337f85--fa05068c1e3442a2b2d109ff7f0b7006 86ea53a4f26c458f83f5511fa6a15099 t = -500.000000000000 fa05068c1e3442a2b2d109ff7f0b7006--86ea53a4f26c458f83f5511fa6a15099 fc7f2825aec3489ea9ff411e7962abf0 X 86ea53a4f26c458f83f5511fa6a15099--fc7f2825aec3489ea9ff411e7962abf0 fc7f2825aec3489ea9ff411e7962abf0--614b7b3c8d704773ae55671f2dc79aec 957f6f904886416bae1ab2e10f040cd7 62083a03ea32403a832d268334d034ca X 5283241cd47744ac85f7c7499767e008--62083a03ea32403a832d268334d034ca e8ea5e789f6f43368017637062b9ad31 62083a03ea32403a832d268334d034ca--e8ea5e789f6f43368017637062b9ad31 d605abe9c6024f0589b922fe71591e7e X e8ea5e789f6f43368017637062b9ad31--d605abe9c6024f0589b922fe71591e7e 0a323eadbfa34a8e8129d3ed3101db0e X d605abe9c6024f0589b922fe71591e7e--0a323eadbfa34a8e8129d3ed3101db0e b9648f7f14ee4b94b1124d56c4e4dcb0 0a323eadbfa34a8e8129d3ed3101db0e--b9648f7f14ee4b94b1124d56c4e4dcb0 1a03bf65a5834076860cd6a3a29688f2 X b9648f7f14ee4b94b1124d56c4e4dcb0--1a03bf65a5834076860cd6a3a29688f2 1a03bf65a5834076860cd6a3a29688f2--957f6f904886416bae1ab2e10f040cd7 <p>The times slices using the build Hamiltonian need now to evolve for much longer to represent the same interaction since it is not sufficiently represented in the building block Hamiltonian.</p> <p>In the limit where that interaction is not present, the transform will not work:</p> <pre><code>try:\ntransformed_ising = daqc_transform(\nn_qubits=3,\ngen_target=gen_target,\nt_f=1.0,\ngen_build=gen_build(g_int = 0.0),\n)\nexcept ValueError as error:\nprint(\"Error:\", error)\n</code></pre> <pre><code>Error: Incompatible interactions between target and build Hamiltonians.\n</code></pre>"},{"location":"digital_analog_qc/daqc-cnot/#references","title":"References","text":"<ol> <li> <p>Dodd et al., Universal quantum computation and simulation using any entangling Hamiltonian and local unitaries, PRA 65, 040301 (2002). \u21a9</p> </li> <li> <p>Parra-Rodriguez et al., Digital-Analog Quantum Computation, PRA 101, 022305 (2020). \u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"digital_analog_qc/pulser-basic/","title":"Pulse-level programming with Pulser","text":"<p>Qadence offers a direct interface with Pulser<sup>1</sup>, an open-source pulse-level interface written in Python and specifically designed for programming neutral atom quantum computers.</p> <p>Using directly Pulser requires advanced knowledge on pulse-level programming and on how neutral atom devices work. Qadence abstracts this complexity out by using the familiar block-based interface for building pulse sequences in Pulser while leaving the possibility to directly manipulate them if required by, for instance, optimal pulse shaping.</p> <p>Note</p> <p>The Pulser backend is still experimental and the interface might change in the future. Please note that it does not support <code>DiffMode.AD</code>.</p>"},{"location":"digital_analog_qc/pulser-basic/#default-qubit-interaction","title":"Default qubit interaction","text":"<p>When simulating pulse sequences written using Pulser, the underlying constructed Hamiltonian is equivalent to a digital-analog quantum computing program (see digital-analog emulation for more details) with the following interaction term:</p> \\[ \\mathcal{H}_{\\textrm{int}} = \\sum_{i&lt;j} \\frac{C_6}{|R_i - R_j|^6} \\hat{n}_i \\hat{n}_j \\] <p>where \\(C_6\\) is an interaction strength coefficient dependent on the principal quantum number of chosen the neutral atom system, \\(R_i\\) are atomic positions in Cartesian coordinates and \\(\\hat{n} = \\frac{1-\\sigma^z_i}{2}\\) the number operator.</p> <p>Note</p> <p>The Ising interaction is always-on for all computations performed with the Pulser backend. It cannot be switched off.</p>"},{"location":"digital_analog_qc/pulser-basic/#available-quantum-operations","title":"Available quantum operations","text":"<p>Currently, the Pulser backend supports the following operations:</p> gate description trainable parameter <code>RX</code>, <code>RY</code> Single qubit rotations. Notice that the interaction is on and this affects the resulting gate fidelity. rotation angle <code>AnalogRX</code>, <code>AnalogRY</code>, <code>AnalogRZ</code> Span a single qubit rotation among the entire register. rotation angle <code>entangle</code> Fully entangle the register. interaction time <code>wait</code> An idle block to wait for the system to free-evolve for a duration according to the interaction. free evolution time"},{"location":"digital_analog_qc/pulser-basic/#sequence-the-bell-state-on-a-two-qubit-register","title":"Sequence the Bell state on a two qubit register","text":"<p>The next example illustrates how to create a pulse sequence to prepare a Bell state. This is a sequence of an entanglement operation, represented as an <code>entangle</code> gate (using <code>CZ</code> interactions) in the \\(X\\)-basis and a \\(Y\\) rotation for readout in the \\(Z\\)-basis:</p> <pre><code>from qadence import chain, entangle, RY\nbell_state = chain(\nentangle(\"t\", qubit_support=(0,1)),\nRY(0, \"y\"),\n)\n</code></pre> <pre><code>bell_state = ChainBlock(0,1)\n\u251c\u2500\u2500 AnalogEntanglement(t=0.4033156033573492, support=(0, 1))\n\u2514\u2500\u2500 RY(0) [params: ['y']]\n</code></pre> <p>Next, a <code>Register</code> with two qubits is combined with the resulting <code>ChainBlock</code> to form a circuit. Then, the <code>QuantumModel</code> converts the circuit into a proper parametrized pulse sequence with the Pulser backend. Supplying the parameter values allows to sample the pulse sequence outcome:</p> <pre><code>import torch\nimport matplotlib.pyplot as plt\nfrom qadence import Register, QuantumCircuit, QuantumModel\nregister = Register(2)\ncircuit = QuantumCircuit(register, bell_state)\nmodel = QuantumModel(circuit, backend=\"pulser\", diff_mode=\"gpsr\")\nparams = {\n\"t\": torch.tensor([383]),  # ns\n\"y\": torch.tensor([3*torch.pi/2]),\n}\n# Return the final state vector\nfinal_vector = model.run(params)\n# Sample from the result state vector\nsample = model.sample(params, n_shots=50)[0]\n</code></pre> <pre><code>final_vector = tensor([[-0.7080-0.0207j,  0.0395+0.3061j,  0.0039-0.0540j,  0.6220-0.1151j]])\nsample = Counter({'00': 27, '11': 18, '01': 5})\n</code></pre> <p>Plot the distribution:</p> <p><pre><code>\n</code></pre> 2023-10-25T16:44:45.892288 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/  One can visualise the pulse sequence with different parameters using the <code>assign_paramters</code> method.</p> <pre><code>model.assign_parameters(params).draw(show=False)\n</code></pre> 2023-10-25T16:44:46.034826 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"digital_analog_qc/pulser-basic/#change-device-specifications","title":"Change device specifications","text":"<p>At variance with other backends, Pulser provides the concept of <code>Device</code>. A <code>Device</code> instance encapsulates all the properties for the definition of a real neutral atoms processor, including but not limited to the maximum laser amplitude for pulses, the maximum distance between two qubits and the maximum duration of the pulse. For more information, please check this tutorial.</p> <p>Qadence offers a simplified interface with only two devices which are detailed here:</p> <ul> <li><code>IDEALIZED</code> (default): ideal device which should be used only for testing purposes. It does not restrict the simulation of pulse sequences.</li> <li><code>REALISTIC</code>: device specification close to real neutral atom quantum processors.</li> </ul> <p>Note</p> <p>If you want to perform simulations closer to the specifications of real neutral atom machines, always select the <code>REALISTIC</code> device.</p> <p>One can use the <code>Configuration</code> of the Pulser backend to select the appropriate device:</p> <pre><code>from qadence import BackendName, DiffMode\nfrom qadence.backends.pulser.devices import Device\nregister = Register(2)\ncircuit = QuantumCircuit(register, bell_state)\n# Choose a realistic device\nmodel = QuantumModel(\ncircuit,\nbackend=BackendName.PULSER,\ndiff_mode=DiffMode.GPSR,\nconfiguration={\"device_type\": Device.REALISTIC}\n)\nparams = {\n\"t\": torch.tensor([383]),  # ns\n\"y\": torch.tensor([3*torch.pi/2]),\n}\n# Sample from the result state vector\nsample = model.sample(params, n_shots=50)[0]\n</code></pre> <pre><code>sample = Counter({'00': 26, '01': 18, '11': 6})\n</code></pre>"},{"location":"digital_analog_qc/pulser-basic/#create-a-custom-gate","title":"Create a custom gate","text":"<p>A major advantage of the block-based interface in Qadence is the ease to compose complex operations from a restricted set of primitive ones. In the following, a custom entanglement operation is used as an example.</p> <p>The operation consists of moving all the qubits to the \\(X\\)-basis. This is realized when the atomic interaction performs a controlled-\\(Z\\) operation during the free evolution. As seen before, this is implemented with the <code>wait</code> and <code>AnalogRY</code> blocks and appropriate parameters.</p> <pre><code>from qadence import AnalogRY, chain, wait\n# Custom entanglement operation.\ndef my_entanglement(duration):\nreturn chain(\nAnalogRY(-torch.pi / 2),\nwait(duration)\n)\nprotocol = chain(\nmy_entanglement(\"t\"),\nRY(0, \"y\"),\n)\nregister = Register(2)\ncircuit = QuantumCircuit(register, protocol)\nmodel = QuantumModel(circuit, backend=BackendName.PULSER, diff_mode=DiffMode.GPSR)\nparams = {\n\"t\": torch.tensor([383]),  # ns\n\"y\": torch.tensor([torch.pi / 2]),\n}\nsample = model.sample(params, n_shots=50)[0]\n</code></pre> 2023-10-25T16:44:46.628660 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"digital_analog_qc/pulser-basic/#digital-analog-qnn-circuit","title":"Digital-analog QNN circuit","text":"<p>Finally, let's put all together by constructing a digital-analog version of a quantum neural network circuit with feature map and variational ansatz.</p> <pre><code>from qadence import kron, fourier_feature_map\nfrom qadence.operations import RX, RY, AnalogRX\nhea_one_layer = chain(\nkron(RY(0, \"th00\"), RY(1, \"th01\")),\nkron(RX(0, \"th10\"), RX(1, \"th11\")),\nkron(RY(0, \"th20\"), RY(1, \"th21\")),\nentangle(\"t\", qubit_support=(0,1)),\n)\nprotocol = chain(\nfourier_feature_map(1, param=\"x\"),\nhea_one_layer,\nAnalogRX(torch.pi/4)\n)\nregister = Register(2)\ncircuit = QuantumCircuit(register, protocol)\nmodel = QuantumModel(circuit, backend=BackendName.PULSER, diff_mode=DiffMode.GPSR)\nparams = {\n\"x\": torch.tensor([0.8]), # rad\n\"t\": torch.tensor([900]), # ns\n\"th00\":  torch.rand(1), # rad\n\"th01\":  torch.rand(1), # rad\n\"th10\":  torch.rand(1), # rad\n\"th11\":  torch.rand(1), # rad\n\"th20\":  torch.rand(1), # rad\n\"th21\":  torch.rand(1), # rad\n}\nmodel.assign_parameters(params).draw(draw_phase_area=True, show=False)\n</code></pre> 2023-10-25T16:44:46.818795 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"digital_analog_qc/pulser-basic/#references","title":"References","text":"<ol> <li> <p>Pulser: An open-source package for the design of pulse sequences in programmable neutral-atom arrays \u21a9</p> </li> </ol>"},{"location":"qadence/blocks/","title":"Block system","text":"<p><code>qadence</code> offers a block-based system to construct quantum circuits in a flexible manner.</p>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock","title":"<code>AbstractBlock</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Base class for both primitive and composite blocks</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>A human-readable name attached to the block type. Notice, this is the same for all the class instances so it cannot be used for identifying different blocks</p> <p> TYPE: <code>str</code> </p> <code>qubit_support</code> <p>The qubit support of the block expressed as a tuple of integers</p> <p> TYPE: <code>tuple[int, ...]</code> </p> <code>tag</code> <p>A tag identifying a particular instance of the block which can be used for identification and pretty printing</p> <p> TYPE: <code>str | None</code> </p> <code>eigenvalues</code> <p>The eigenvalues of the matrix representing the block. This is used mainly for primitive blocks and it's needed for generalized parameter shift rule computations. Currently unused.</p> <p> TYPE: <code>list[float] | None</code> </p>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock.is_identity","title":"<code>is_identity: bool</code>  <code>property</code>","text":"<p>Identity predicate for blocks.</p>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock.n_qubits","title":"<code>n_qubits()</code>","text":"<p>The number of qubits in the whole system. A block acting on qubit N would has at least n_qubits &gt;= N + 1.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef n_qubits(self) -&gt; int:\n\"\"\"The number of qubits in the whole system.\n    A block acting on qubit N would has at least n_qubits &gt;= N + 1.\"\"\"\npass\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock.n_supports","title":"<code>n_supports()</code>","text":"<p>The number of qubits the block is acting on.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef n_supports(self) -&gt; int:\n\"\"\"The number of qubits the block is acting on.\"\"\"\npass\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock.qubit_support","title":"<code>qubit_support()</code>","text":"<p>The indices of the qubit(s) the block is acting on. Qadence uses the ordering [0..,N-1] for qubits.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef qubit_support(self) -&gt; Tuple[int, ...]:\n\"\"\"The indices of the qubit(s) the block is acting on.\n    Qadence uses the ordering [0..,N-1] for qubits.\"\"\"\npass\n</code></pre>"},{"location":"qadence/blocks/#primitive-blocks","title":"Primitive blocks","text":""},{"location":"qadence/blocks/#qadence.blocks.primitive.ControlBlock","title":"<code>ControlBlock(control, target_block)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The abstract ControlBlock</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, control: tuple[int, ...], target_block: PrimitiveBlock) -&gt; None:\nself.blocks = (target_block,)\n# using tuple expansion because some control operations could\n# have multiple targets, e.g. CSWAP\nsuper().__init__((*control, *target_block.qubit_support))  # target_block.qubit_support[0]))\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.ParametricBlock","title":"<code>ParametricBlock(qubit_support)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>Parameterized primitive blocks</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, qubit_support: tuple[int, ...]):\nself._qubit_support = qubit_support\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.ParametricBlock.num_parameters","title":"<code>num_parameters()</code>  <code>abstractmethod</code>","text":"<p>The number of parameters required by the block</p> <p>This is a class property since the number of parameters is defined automatically before instantiating the operation. Also, this could correspond to a larger number of actual user-facing parameters since any parameter expression is allowed</p> <p>Examples: - RX operation has 1 parameter - U operation has 3 parameters - HamEvo has 2 parameters (generator and time evolution)</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>@abstractmethod\ndef num_parameters(cls) -&gt; int:\n\"\"\"The number of parameters required by the block\n    This is a class property since the number of parameters is defined\n    automatically before instantiating the operation. Also, this could\n    correspond to a larger number of actual user-facing parameters\n    since any parameter expression is allowed\n    Examples:\n    - RX operation has 1 parameter\n    - U operation has 3 parameters\n    - HamEvo has 2 parameters (generator and time evolution)\n    \"\"\"\npass\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.ParametricControlBlock","title":"<code>ParametricControlBlock(control, target_block)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The abstract parametrized ControlBlock</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, control: tuple[int, ...], target_block: ParametricBlock) -&gt; None:\nself.blocks = (target_block,)\nself.parameters = target_block.parameters\nsuper().__init__((*control, target_block.qubit_support[0]))\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.PrimitiveBlock","title":"<code>PrimitiveBlock(qubit_support)</code>","text":"<p>             Bases: <code>AbstractBlock</code></p> <p>Primitive blocks represent elementary unitary operations such as single/multi-qubit gates or Hamiltonian evolution. See <code>qadence.operations</code> for a full list of primitive blocks.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, qubit_support: tuple[int, ...]):\nself._qubit_support = qubit_support\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.PrimitiveBlock.digital_decomposition","title":"<code>digital_decomposition()</code>","text":"<p>Decomposition into purely digital gates</p> <p>This method returns a decomposition of the Block in a combination of purely digital single-qubit and two-qubit 'gates', by manual/custom knowledge of how this can be done efficiently. :return:</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def digital_decomposition(self) -&gt; AbstractBlock:\n\"\"\"Decomposition into purely digital gates\n    This method returns a decomposition of the Block in a\n    combination of purely digital single-qubit and two-qubit\n    'gates', by manual/custom knowledge of how this can be done efficiently.\n    :return:\n    \"\"\"\nreturn self\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.ScaleBlock","title":"<code>ScaleBlock(block, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>Scale blocks are created when multiplying a block by a number or parameter.</p> <p>Example: <pre><code>from qadence import X\nprint(X(0) * 2)\n</code></pre> <pre><code>[mul: 2] \u2514\u2500\u2500 X(0)\n</code></pre> </p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, block: AbstractBlock, parameter: Any):\nself.block = block\n# TODO: more meaningful name like `scale`?\nself.parameters = (\nparameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n)\nsuper().__init__(block.qubit_support)\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.TimeEvolutionBlock","title":"<code>TimeEvolutionBlock(qubit_support)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>Simple time evolution block with time-independent Hamiltonian</p> <p>This class is just a convenience class which is used to label blocks which contains simple time evolution with time-independent Hamiltonian operators</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, qubit_support: tuple[int, ...]):\nself._qubit_support = qubit_support\n</code></pre>"},{"location":"qadence/blocks/#analog-blocks","title":"Analog blocks","text":"<p>To learn how to use analog blocks and how to mix digital &amp; analog blocks, check out the digital-analog section of the documentation.</p> <p>Examples on how to use digital-analog blocks can be found in the *examples folder of the qadence repo:</p> <ul> <li>Fit a simple sinus: <code>examples/digital-analog/fit-sin.py</code></li> <li>Solve a QUBO: <code>examples/digital-analog/qubo.py</code></li> </ul>"},{"location":"qadence/blocks/#qadence.blocks.analog.AnalogChain","title":"<code>AnalogChain(blocks)</code>  <code>dataclass</code>","text":"<p>             Bases: <code>AnalogComposite</code></p> <p>A chain of analog blocks. Needed because analog blocks require stricter validation than the general <code>ChainBlock</code>.</p> <p><code>AnalogChain</code>s can only be constructed from <code>AnalogKron</code> blocks or globally supported, primitive, analog blocks (like <code>WaitBlock</code>s and <code>ConstantAnalogRotation</code>s).</p> <p>Automatically constructed by the <code>chain</code> function if only analog blocks are given.</p> <p>Example: <pre><code>from qadence import X, chain, wait\nb = chain(wait(200), wait(200))\nprint(type(b))  # this is an `AnalogChain`\nb = chain(X(0), wait(200))\nprint(type(b))  # this is a general `ChainBlock`\n</code></pre> <pre><code>&lt;class 'qadence.blocks.analog.AnalogChain'&gt;\n&lt;class 'qadence.blocks.composite.ChainBlock'&gt;\n</code></pre> </p> Source code in <code>qadence/blocks/analog.py</code> <pre><code>def __init__(self, blocks: Tuple[AnalogBlock, ...]):\n\"\"\"A chain of analog blocks. Needed because analog blocks require\n    stricter validation than the general `ChainBlock`.\n    `AnalogChain`s can only be constructed from `AnalogKron` blocks or\n    _**globally supported**_, primitive, analog blocks (like `WaitBlock`s and\n    `ConstantAnalogRotation`s).\n    Automatically constructed by the [`chain`][qadence.blocks.utils.chain]\n    function if only analog blocks are given.\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, chain, wait\n    b = chain(wait(200), wait(200))\n    print(type(b))  # this is an `AnalogChain`\n    b = chain(X(0), wait(200))\n    print(type(b))  # this is a general `ChainBlock`\n    ```\n    \"\"\"\nfor b in blocks:\nif not (isinstance(b, AnalogKron) or b.qubit_support.is_global):\nraise ValueError(\"Only KronBlocks or global blocks can be chain'ed.\")\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.analog.AnalogKron","title":"<code>AnalogKron(blocks, interaction=Interaction.NN)</code>  <code>dataclass</code>","text":"<p>             Bases: <code>AnalogComposite</code></p> <p>Stack analog blocks vertically (i.e. in time). Needed because analog require stricter validation than the general <code>KronBlock</code>.</p> <p><code>AnalogKron</code>s can only be constructed from non-global, analog blocks with the same duration.</p> Source code in <code>qadence/blocks/analog.py</code> <pre><code>def __init__(self, blocks: Tuple[AnalogBlock, ...], interaction: Interaction = Interaction.NN):\n\"\"\"Stack analog blocks vertically (i.e. in time). Needed because analog require\n    stricter validation than the general `KronBlock`.\n    `AnalogKron`s can only be constructed from _**non-global**_, analog blocks\n    with the _**same duration**_.\n    \"\"\"\nif len(blocks) == 0:\nraise NotImplementedError(\"Empty KronBlocks not supported\")\nself.blocks = blocks\nself.interaction = interaction\nqubit_support = QubitSupport()\nduration = blocks[0].duration\nfor b in blocks:\nif not isinstance(b, AnalogBlock):\nraise ValueError(\"Can only kron `AnalgoBlock`s with other `AnalgoBlock`s.\")\nif b.qubit_support == QubitSupport(\"global\"):\nraise ValueError(\"Blocks with global support cannot be kron'ed.\")\nif not qubit_support.is_disjoint(b.qubit_support):\nraise ValueError(\"Make sure blocks act on distinct qubits!\")\nif not np.isclose(evaluate(duration), evaluate(b.duration)):\nraise ValueError(\"Kron'ed blocks have to have same duration.\")\nqubit_support += b.qubit_support\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.analog.ConstantAnalogRotation","title":"<code>ConstantAnalogRotation</code>  <code>dataclass</code>","text":"<p>             Bases: <code>AnalogBlock</code></p> <p>Implements a constant analog rotation with interaction dictated by the chosen Hamiltonian</p> <pre><code>H = \u2211\u1d62(h\u03a9/2 sin(\u03c6)*X\u1d62 - cos(\u03c6)*Y\u1d62 - h\u03b4n\u1d62) + H\u1d62\u2099\u209c.\n</code></pre> <p>To construct this block you can use of the following convenience wrappers: - The general rotation operation <code>AnalogRot</code> - Shorthands for rotatins around an axis:   <code>AnalogRX</code>,   <code>AnalogRY</code>,   <code>AnalogRZ</code></p> <p>Can be used with <code>add_interaction</code>. WARNING: do not use <code>ConstantAnalogRotation</code> with <code>alpha</code> as differentiable parameter - use the convenience wrappers mentioned above.</p>"},{"location":"qadence/blocks/#qadence.blocks.analog.WaitBlock","title":"<code>WaitBlock</code>  <code>dataclass</code>","text":"<p>             Bases: <code>AnalogBlock</code></p> <p>Waits. In real interacting quantum devices, it means letting the system evolve freely according to the time-dependent Schrodinger equation. With emulators, this block is translated to an appropriate interaction Hamiltonian, for example, an Ising interaction</p> <pre><code>H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2086/r\u1d62\u2c7c\u2076 n\u1d62n\u2c7c\n</code></pre> <p>or an XY-interaction</p> <pre><code>H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2083/r\u2c7c\u2c7c\u00b3 (X\u1d62X\u2c7c + Z\u1d62Z\u2c7c)\n</code></pre> <p>with <code>n\u1d62 = (1-Z\u1d62)/2</code>.</p> <p>To construct this block, use the <code>wait</code> function.</p> <p>Can be used with <code>add_interaction</code>.</p>"},{"location":"qadence/blocks/#composite-blocks","title":"Composite blocks","text":""},{"location":"qadence/blocks/#qadence.blocks.utils.chain","title":"<code>chain(*args)</code>","text":"<p>Chain blocks sequentially. On digital backends this can be interpreted loosely as a matrix mutliplication of blocks. In the analog case it chains blocks in time.</p> PARAMETER  DESCRIPTION <code>*args</code> <p>Blocks to chain. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator, List[AbstractBlock]]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>ChainBlock</p> <p>Example: <pre><code>from qadence import X, Y, chain\nb = chain(X(0), Y(0))\n# or use a generator\nb = chain(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>ChainBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def chain(*args: Union[AbstractBlock, Generator, List[AbstractBlock]]) -&gt; ChainBlock:\n\"\"\"Chain blocks sequentially. On digital backends this can be interpreted\n    loosely as a matrix mutliplication of blocks. In the analog case it chains\n    blocks in time.\n    Arguments:\n        *args: Blocks to chain. Can also be a generator.\n    Returns:\n        ChainBlock\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, chain\n    b = chain(X(0), Y(0))\n    # or use a generator\n    b = chain(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n# ugly hack to use `AnalogChain` if we are dealing only with analog blocks\nif len(args) and all(\nisinstance(a, AnalogBlock) or isinstance(a, AnalogComposite) for a in args\n):\nreturn analog_chain(*args)  # type: ignore[return-value,arg-type]\nreturn _construct(ChainBlock, args)\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.utils.kron","title":"<code>kron(*args)</code>","text":"<p>Stack blocks vertically. On digital backends this can be intepreted loosely as a kronecker product of blocks. In the analog case it executes blocks parallel in time.</p> PARAMETER  DESCRIPTION <code>*args</code> <p>Blocks to kron. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>KronBlock</p> <p>Example: <pre><code>from qadence import X, Y, kron\nb = kron(X(0), Y(1))\n# or use a generator\nb = kron(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def kron(*args: Union[AbstractBlock, Generator]) -&gt; KronBlock:\n\"\"\"Stack blocks vertically. On digital backends this can be intepreted\n    loosely as a kronecker product of blocks. In the analog case it executes\n    blocks parallel in time.\n    Arguments:\n        *args: Blocks to kron. Can also be a generator.\n    Returns:\n        KronBlock\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, kron\n    b = kron(X(0), Y(1))\n    # or use a generator\n    b = kron(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n# ugly hack to use `AnalogKron` if we are dealing only with analog blocks\nif len(args) and all(\nisinstance(a, AnalogBlock) or isinstance(a, AnalogComposite) for a in args\n):\nreturn analog_kron(*args)  # type: ignore[return-value,arg-type]\nreturn _construct(KronBlock, args)\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.utils.add","title":"<code>add(*args)</code>","text":"<p>Sums blocks.</p> PARAMETER  DESCRIPTION <code>*args</code> <p>Blocks to add. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>AddBlock</code> <p>AddBlock</p> <p>Example: <pre><code>from qadence import X, Y, add\nb = add(X(0), Y(0))\n# or use a generator\nb = add(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def add(*args: Union[AbstractBlock, Generator]) -&gt; AddBlock:\n\"\"\"Sums blocks.\n    Arguments:\n        *args: Blocks to add. Can also be a generator.\n    Returns:\n        AddBlock\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, add\n    b = add(X(0), Y(0))\n    # or use a generator\n    b = add(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\nreturn _construct(AddBlock, args)\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.composite.AddBlock","title":"<code>AddBlock(blocks)</code>","text":"<p>             Bases: <code>CompositeBlock</code></p> <p>Adds blocks. Constructed via <code>add</code>.</p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.composite.ChainBlock","title":"<code>ChainBlock(blocks)</code>","text":"<p>             Bases: <code>CompositeBlock</code></p> <p>Chains blocks sequentially. Constructed via <code>chain</code></p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.composite.CompositeBlock","title":"<code>CompositeBlock</code>","text":"<p>             Bases: <code>AbstractBlock</code></p> <p>Block which composes multiple blocks into one larger block (which can again be composed). Composite blocks are constructed via <code>chain</code>, <code>kron</code>, and <code>add</code>.</p>"},{"location":"qadence/blocks/#qadence.blocks.composite.KronBlock","title":"<code>KronBlock(blocks)</code>","text":"<p>             Bases: <code>CompositeBlock</code></p> <p>Stacks blocks horizontally. Constructed via <code>kron</code>.</p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\nif len(blocks) == 0:\nraise NotImplementedError(\"Empty KronBlocks not supported\")\nqubit_support = QubitSupport()\nfor b in blocks:\nassert (\nQubitSupportType.GLOBAL,\n) != b.qubit_support, \"Blocks with global support cannot be kron'ed.\"\nassert qubit_support.is_disjoint(\nb.qubit_support\n), \"Make sure blocks act on distinct qubits!\"\nqubit_support += b.qubit_support\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#converting-blocks-to-matrices","title":"Converting blocks to matrices","text":""},{"location":"qadence/blocks/#qadence.blocks.block_to_tensor.block_to_tensor","title":"<code>block_to_tensor(block, values={}, qubit_support=None, use_full_support=True, tensor_type=TensorType.DENSE, endianness=Endianness.BIG)</code>","text":"<p>Convert a block into a torch tensor.</p> PARAMETER  DESCRIPTION <code>block</code> <p>The block to convert.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>values</code> <p>A optional dict with values for parameters.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>qubit_support</code> <p>The qubit_support of the block.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>use_full_support</code> <p>True infers the total number of qubits.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>tensor_type</code> <p>the target tensor type.</p> <p> TYPE: <code>TensorType</code> DEFAULT: <code>DENSE</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence import hea, hamiltonian_factory, Z, block_to_tensor\nblock = hea(2,2)\nprint(block_to_tensor(block))\n# In case you have a diagonal observable, you can use\nobs = hamiltonian_factory(2, detuning = Z)\nprint(block_to_tensor(obs, tensor_type=\"SparseDiagonal\"))\n</code></pre> <pre><code>tensor([[[ 0.5034+0.1645j, -0.2575-0.4773j, -0.1863-0.2398j, -0.5771+0.0125j],\n[ 0.0301-0.4791j,  0.5561+0.0912j, -0.5891-0.2234j, -0.1547-0.1766j],\n[-0.1238-0.5348j, -0.3862-0.0394j,  0.2656+0.1068j, -0.1997-0.6528j],\n[-0.3733-0.2200j, -0.1777-0.4539j,  0.0268-0.6544j,  0.3337+0.1853j]]],\ngrad_fn=&lt;UnsafeViewBackward0&gt;)\ntensor(indices=tensor([[0, 3],\n[0, 3]]),\nvalues=tensor([ 2.+0.j, -2.+0.j]),\nsize=(4, 4), nnz=2, layout=torch.sparse_coo)\n</code></pre> </p> Source code in <code>qadence/blocks/block_to_tensor.py</code> <pre><code>def block_to_tensor(\nblock: AbstractBlock,\nvalues: dict[str, TNumber | torch.Tensor] = {},\nqubit_support: tuple | None = None,\nuse_full_support: bool = True,\ntensor_type: TensorType = TensorType.DENSE,\nendianness: Endianness = Endianness.BIG,\n) -&gt; torch.Tensor:\n\"\"\"\n    Convert a block into a torch tensor.\n    Arguments:\n        block (AbstractBlock): The block to convert.\n        values (dict): A optional dict with values for parameters.\n        qubit_support (tuple): The qubit_support of the block.\n        use_full_support (bool): True infers the total number of qubits.\n        tensor_type (TensorType): the target tensor type.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import hea, hamiltonian_factory, Z, block_to_tensor\n    block = hea(2,2)\n    print(block_to_tensor(block))\n    # In case you have a diagonal observable, you can use\n    obs = hamiltonian_factory(2, detuning = Z)\n    print(block_to_tensor(obs, tensor_type=\"SparseDiagonal\"))\n    ```\n    \"\"\"\n# FIXME: default use_full_support to False. In general, it would\n# be more efficient to do that, and make sure that computations such\n# as observables only do the matmul of the size of the qubit support.\nif tensor_type == TensorType.DENSE:\nfrom qadence.blocks import embedding\n(ps, embed) = embedding(block)\nreturn _block_to_tensor_embedded(\nblock, embed(ps, values), qubit_support, use_full_support, endianness=endianness\n)\nelif tensor_type == TensorType.SPARSEDIAGONAL:\nt = block_to_diagonal(block, endianness=endianness)\nindices, values, size = torch.nonzero(t), t[t != 0], len(t)\nindices = torch.stack((indices.flatten(), indices.flatten()))\nreturn torch.sparse_coo_tensor(indices, values, (size, size))\n</code></pre>"},{"location":"qadence/constructors/","title":"Constructors for common quantum circuits","text":""},{"location":"qadence/constructors/#qadence.constructors.feature_maps.chebyshev_feature_map","title":"<code>chebyshev_feature_map(n_qubits, support=None, param='phi', op=RX)</code>","text":"<p>Construct a Chebyshev feature map.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits across which the FM is created</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>The qubit support</p> <p> TYPE: <code>Iterable[int]</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>The base name for the feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'phi'</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def chebyshev_feature_map(\nn_qubits: int, support: tuple[int, ...] = None, param: str = \"phi\", op: RotationTypes = RX\n) -&gt; AbstractBlock:\n\"\"\"Construct a Chebyshev feature map.\n    Args:\n        n_qubits: number of qubits across which the FM is created\n        support (Iterable[int]): The qubit support\n        param: The base name for the feature `Parameter`\n    \"\"\"\nwarnings.warn(\n\"Function 'chebyshev_feature_map' is deprecated. Please use 'feature_map' directly.\",\nFutureWarning,\n)\nfm = feature_map(n_qubits, support=support, param=param, op=op, fm_type=BasisSet.CHEBYSHEV)\nreturn fm\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.feature_maps.exp_fourier_feature_map","title":"<code>exp_fourier_feature_map(n_qubits, support=None, param='x', feature_range=None)</code>","text":"<p>Exponential fourier feature map.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the feature</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>qubit support</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>name of feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'x'</code> </p> <code>feature_range</code> <p>min and max value of the feature, as floats in a Tuple</p> <p> TYPE: <code>tuple[float, float]</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def exp_fourier_feature_map(\nn_qubits: int,\nsupport: tuple[int, ...] = None,\nparam: str = \"x\",\nfeature_range: tuple[float, float] = None,\n) -&gt; AbstractBlock:\n\"\"\"\n    Exponential fourier feature map.\n    Args:\n        n_qubits: number of qubits in the feature\n        support: qubit support\n        param: name of feature `Parameter`\n        feature_range: min and max value of the feature, as floats in a Tuple\n    \"\"\"\nif feature_range is None:\nfeature_range = (0.0, 2.0**n_qubits)\nsupport = tuple(range(n_qubits)) if support is None else support\nhlayer = kron(H(qubit) for qubit in support)\nrlayer = feature_map(\nn_qubits,\nsupport=support,\nparam=param,\nop=RZ,\nfm_type=BasisSet.FOURIER,\nreupload_scaling=ReuploadScaling.EXP,\nfeature_range=feature_range,\ntarget_range=(0.0, 2 * pi),\n)\nrlayer.tag = None\nreturn tag(chain(hlayer, rlayer), f\"ExpFourierFM({param})\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.feature_maps.feature_map","title":"<code>feature_map(n_qubits, support=None, param='phi', op=RX, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.CONSTANT, feature_range=None, target_range=None, multiplier=None)</code>","text":"<p>Construct a feature map of a given type.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>Number of qubits the feature map covers. Results in <code>support=range(n_qubits)</code>.</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>Puts one feature-encoding rotation gate on every qubit in <code>support</code>. n_qubits in this case specifies the total overall qubits of the circuit, which may be wider than the support itself, but not narrower.</p> <p> TYPE: <code>tuple[int, ...] | None</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>Parameter of the feature map; you can pass a string or Parameter; it will be set as non-trainable (FeatureParameter) regardless.</p> <p> TYPE: <code>Parameter | str</code> DEFAULT: <code>'phi'</code> </p> <code>op</code> <p>Rotation operation of the feature map; choose from RX, RY, RZ or PHASE.</p> <p> TYPE: <code>RotationTypes</code> DEFAULT: <code>RX</code> </p> <code>fm_type</code> <p>Basis set for data encoding; choose from <code>BasisSet.FOURIER</code> for Fourier encoding, or <code>BasisSet.CHEBYSHEV</code> for Chebyshev polynomials of the first kind.</p> <p> TYPE: <code>BasisSet | type[Function] | str</code> DEFAULT: <code>FOURIER</code> </p> <code>reupload_scaling</code> <p>how the feature map scales the data that is re-uploaded for each qubit. choose from <code>ReuploadScaling</code> enumeration or provide your own function with a single int as input and int or float as output.</p> <p> TYPE: <code>ReuploadScaling | Callable | str</code> DEFAULT: <code>CONSTANT</code> </p> <code>feature_range</code> <p>range of data that the input data is assumed to come from.</p> <p> TYPE: <code>tuple[float, float] | None</code> DEFAULT: <code>None</code> </p> <code>target_range</code> <p>range of data the data encoder assumes as the natural range. For example, in Chebyshev polynomials it is (-1, 1), while for Fourier it may be chosen as (0, 2*pi).</p> <p> TYPE: <code>tuple[float, float] | None</code> DEFAULT: <code>None</code> </p> <code>multiplier</code> <p>overall multiplier; this is useful for reuploading the feature map serially with different scalings; can be a number or parameter/expression.</p> <p> TYPE: <code>Parameter | TParameter | None</code> DEFAULT: <code>None</code> </p> <p>Example: <pre><code>from qadence import feature_map, BasisSet, ReuploadScaling\nfm = feature_map(3, fm_type=BasisSet.FOURIER)\nprint(f\"{fm = }\")\nfm = feature_map(3, fm_type=BasisSet.CHEBYSHEV)\nprint(f\"{fm = }\")\nfm = feature_map(3, fm_type=BasisSet.FOURIER, reupload_scaling = ReuploadScaling.TOWER)\nprint(f\"{fm = }\")\n</code></pre> <pre><code>fm = KronBlock(0,1,2) [tag: Constant Fourier FM]\n\u251c\u2500\u2500 RX(0) [params: ['phi']]\n\u251c\u2500\u2500 RX(1) [params: ['phi']]\n\u2514\u2500\u2500 RX(2) [params: ['phi']]\nfm = KronBlock(0,1,2) [tag: Constant Chebyshev FM]\n\u251c\u2500\u2500 RX(0) [params: ['acos(phi)']]\n\u251c\u2500\u2500 RX(1) [params: ['acos(phi)']]\n\u2514\u2500\u2500 RX(2) [params: ['acos(phi)']]\nfm = KronBlock(0,1,2) [tag: Tower Fourier FM]\n\u251c\u2500\u2500 RX(0) [params: ['1_0*phi']]\n\u251c\u2500\u2500 RX(1) [params: ['2_0*phi']]\n\u2514\u2500\u2500 RX(2) [params: ['3_0*phi']]\n</code></pre> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def feature_map(\nn_qubits: int,\nsupport: tuple[int, ...] | None = None,\nparam: Parameter | str = \"phi\",\nop: RotationTypes = RX,\nfm_type: BasisSet | type[Function] | str = BasisSet.FOURIER,\nreupload_scaling: ReuploadScaling | Callable | str = ReuploadScaling.CONSTANT,\nfeature_range: tuple[float, float] | None = None,\ntarget_range: tuple[float, float] | None = None,\nmultiplier: Parameter | TParameter | None = None,\n) -&gt; KronBlock:\n\"\"\"Construct a feature map of a given type.\n    Arguments:\n        n_qubits: Number of qubits the feature map covers. Results in `support=range(n_qubits)`.\n        support: Puts one feature-encoding rotation gate on every qubit in `support`. n_qubits in\n            this case specifies the total overall qubits of the circuit, which may be wider than the\n            support itself, but not narrower.\n        param: Parameter of the feature map; you can pass a string or Parameter;\n            it will be set as non-trainable (FeatureParameter) regardless.\n        op: Rotation operation of the feature map; choose from RX, RY, RZ or PHASE.\n        fm_type: Basis set for data encoding; choose from `BasisSet.FOURIER` for Fourier\n            encoding, or `BasisSet.CHEBYSHEV` for Chebyshev polynomials of the first kind.\n        reupload_scaling: how the feature map scales the data that is re-uploaded for each qubit.\n            choose from `ReuploadScaling` enumeration or provide your own function with a single\n            int as input and int or float as output.\n        feature_range: range of data that the input data is assumed to come from.\n        target_range: range of data the data encoder assumes as the natural range. For example,\n            in Chebyshev polynomials it is (-1, 1), while for Fourier it may be chosen as (0, 2*pi).\n        multiplier: overall multiplier; this is useful for reuploading the feature map serially with\n            different scalings; can be a number or parameter/expression.\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import feature_map, BasisSet, ReuploadScaling\n    fm = feature_map(3, fm_type=BasisSet.FOURIER)\n    print(f\"{fm = }\")\n    fm = feature_map(3, fm_type=BasisSet.CHEBYSHEV)\n    print(f\"{fm = }\")\n    fm = feature_map(3, fm_type=BasisSet.FOURIER, reupload_scaling = ReuploadScaling.TOWER)\n    print(f\"{fm = }\")\n    ```\n    \"\"\"\n# Process input\nif support is None:\nsupport = tuple(range(n_qubits))\nelif len(support) != n_qubits:\nraise ValueError(\"Wrong qubit support supplied\")\nif op not in ROTATIONS:\nraise ValueError(\nf\"Operation {op} not supported. \"\nf\"Please provide one from {[rot.__name__ for rot in ROTATIONS]}.\"\n)\n# Backwards compatibility\nif fm_type in (\"fourier\", \"chebyshev\", \"tower\"):\nlogger.warning(\n\"Selecting `fm_type` as 'fourier', 'chebyshev' or 'tower' is deprecated. \"\n\"Please use the respective enumerations: 'fm_type = BasisSet.FOURIER', \"\n\"'fm_type = BasisSet.CHEBYSHEV' or 'reupload_scaling = ReuploadScaling.TOWER'.\"\n)\nif fm_type == \"fourier\":\nfm_type = BasisSet.FOURIER\nelif fm_type == \"chebyshev\":\nfm_type = BasisSet.CHEBYSHEV\nelif fm_type == \"tower\":\nfm_type = BasisSet.CHEBYSHEV\nreupload_scaling = ReuploadScaling.TOWER\nif isinstance(param, Parameter):\nfparam = param\nfparam.trainable = False\nelse:\nfparam = FeatureParameter(param)\n# Set feature and target range\nfeature_range = _set_range(fm_type) if feature_range is None else feature_range\ntarget_range = _set_range(fm_type) if target_range is None else target_range\n# Rescale the feature parameter\nscaling = (max(target_range) - min(target_range)) / (max(feature_range) - min(feature_range))\nshift = min(target_range) - min(feature_range) * scaling\nif isclose(scaling, 1.0):\n# So we don't get 1.0 factor in visualization\nscaled_fparam = fparam + shift\nelse:\nscaled_fparam = scaling * fparam + shift\n# Transform feature parameter\nif fm_type == BasisSet.FOURIER:\ntransformed_feature = scaled_fparam\nelif fm_type == BasisSet.CHEBYSHEV:\ntransformed_feature = acos(scaled_fparam)\nelif inspect.isclass(fm_type) and issubclass(fm_type, Function):\ntransformed_feature = fm_type(scaled_fparam)\nelse:\nraise NotImplementedError(\nf\"Feature map type {fm_type} not implemented. Choose an item from the BasisSet \"\nf\"enum: {[bs.name for bs in BasisSet]}, or your own sympy.Function to wrap \"\n\"the given feature parameter with.\"\n)\nbasis_tag = fm_type.value if isinstance(fm_type, BasisSet) else str(fm_type)\n# Set reupload scaling function\nif callable(reupload_scaling):\nrs_func = reupload_scaling\nrs_tag = \"Custom\"\nelse:\nrs_func = RS_FUNC_DICT.get(reupload_scaling, None)  # type: ignore [call-overload]\nif rs_func is None:\nraise NotImplementedError(\nf\"Reupload scaling {reupload_scaling} not implemented; choose an item from \"\nf\"the ReuploadScaling enum: {[rs.name for rs in ReuploadScaling]}, or your own \"\n\"python function with a single int arg as input and int or float output.\"\n)\nif isinstance(reupload_scaling, ReuploadScaling):\nrs_tag = reupload_scaling.value\nelse:\nrs_tag = reupload_scaling\n# Set overall multiplier\nmultiplier = 1 if multiplier is None else multiplier\n# Build feature map\nop_list = []\nfor i, qubit in enumerate(support):\nop_list.append(op(qubit, multiplier * rs_func(i) * transformed_feature))\nfm = kron(*op_list)\nfm.tag = rs_tag + \" \" + basis_tag + \" FM\"\nreturn fm\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.feature_maps.fourier_feature_map","title":"<code>fourier_feature_map(n_qubits, support=None, param='phi', op=RX)</code>","text":"<p>Construct a Fourier feature map.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits across which the FM is created</p> <p> TYPE: <code>int</code> </p> <code>param</code> <p>The base name for the feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'phi'</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def fourier_feature_map(\nn_qubits: int, support: tuple[int, ...] = None, param: str = \"phi\", op: RotationTypes = RX\n) -&gt; AbstractBlock:\n\"\"\"Construct a Fourier feature map.\n    Args:\n        n_qubits: number of qubits across which the FM is created\n        param: The base name for the feature `Parameter`\n    \"\"\"\nwarnings.warn(\n\"Function 'fourier_feature_map' is deprecated. Please use 'feature_map' directly.\",\nFutureWarning,\n)\nfm = feature_map(n_qubits, support=support, param=param, op=op, fm_type=BasisSet.FOURIER)\nreturn fm\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.feature_maps.tower_feature_map","title":"<code>tower_feature_map(n_qubits, support=None, param='phi', op=RX)</code>","text":"<p>Construct a Chebyshev tower feature map.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits across which the FM is created</p> <p> TYPE: <code>int</code> </p> <code>param</code> <p>The base name for the feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'phi'</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def tower_feature_map(\nn_qubits: int, support: tuple[int, ...] = None, param: str = \"phi\", op: RotationTypes = RX\n) -&gt; AbstractBlock:\n\"\"\"Construct a Chebyshev tower feature map.\n    Args:\n        n_qubits: number of qubits across which the FM is created\n        param: The base name for the feature `Parameter`\n    \"\"\"\nwarnings.warn(\n\"Function 'tower_feature_map' is deprecated. Please use feature_map directly.\",\nFutureWarning,\n)\nfm = feature_map(\nn_qubits,\nsupport=support,\nparam=param,\nop=op,\nfm_type=BasisSet.CHEBYSHEV,\nreupload_scaling=ReuploadScaling.TOWER,\n)\nreturn fm\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.ansatze.build_qnn","title":"<code>build_qnn(n_qubits, n_features, depth=None, ansatz=None, fm_pauli=RY, spectrum='simple', basis='fourier', fm_strategy='parallel')</code>","text":"<p>Helper function to build a qadence QNN quantum circuit</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>n_features</code> <p>The number of input dimensions.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>The depth of the ansatz.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>ansatz</code> <p>An optional argument to pass a custom qadence ansatz.</p> <p> TYPE: <code>Optional[AbstractBlock]</code> DEFAULT: <code>None</code> </p> <code>fm_pauli</code> <p>The type of Pauli gate for the feature map. Must be one of 'RX', 'RY', or 'RZ'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>RY</code> </p> <code>spectrum</code> <p>The desired spectrum of the feature map generator. The options simple, tower and exponential produce a spectrum with linear, quadratic and exponential eigenvalues with respect to the number of qubits.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'simple'</code> </p> <code>basis</code> <p>The encoding function. The options fourier and chebyshev correspond to \u03a6(x)=x and arcos(x) respectively.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'fourier'</code> </p> <code>fm_strategy</code> <p>The feature map encoding strategy. If \"parallel\", the features are encoded in one block of rotation gates, with each feature given an equal number of qubits. If \"serial\", the features are encoded sequentially, with a HEA block between.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'parallel'</code> </p> RETURNS DESCRIPTION <code>list[AbstractBlock]</code> <p>A list of Abstract blocks to be used for constructing a quantum circuit</p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def build_qnn(\nn_qubits: int,\nn_features: int,\ndepth: int = None,\nansatz: Optional[AbstractBlock] = None,\nfm_pauli: Type[RY] = RY,\nspectrum: str = \"simple\",\nbasis: str = \"fourier\",\nfm_strategy: str = \"parallel\",\n) -&gt; list[AbstractBlock]:\n\"\"\"Helper function to build a qadence QNN quantum circuit\n    Args:\n        n_qubits (int): The number of qubits.\n        n_features (int): The number of input dimensions.\n        depth (int): The depth of the ansatz.\n        ansatz (Optional[AbstractBlock]):  An optional argument to pass a custom qadence ansatz.\n        fm_pauli (str): The type of Pauli gate for the feature map. Must be one of 'RX',\n            'RY', or 'RZ'.\n        spectrum (str): The desired spectrum of the feature map generator. The options simple,\n            tower and exponential produce a spectrum with linear, quadratic and exponential\n            eigenvalues with respect to the number of qubits.\n        basis (str): The encoding function. The options fourier and chebyshev correspond to \u03a6(x)=x\n            and arcos(x) respectively.\n        fm_strategy (str): The feature map encoding strategy. If \"parallel\", the features\n            are encoded in one block of rotation gates, with each feature given\n            an equal number of qubits. If \"serial\", the features are encoded\n            sequentially, with a HEA block between.\n    Returns:\n        A list of Abstract blocks to be used for constructing a quantum circuit\n    \"\"\"\ndepth = n_qubits if depth is None else depth\nidx_fms = build_idx_fms(basis, fm_pauli, fm_strategy, n_features, n_qubits, spectrum)\nif fm_strategy == \"parallel\":\n_fm = kron(*idx_fms)\nfm = tag(_fm, tag=\"FM\")\nelif fm_strategy == \"serial\":\nfm_components: list[AbstractBlock] = []\nfor j, fm_idx in enumerate(idx_fms[:-1]):\nfm_idx = tag(fm_idx, tag=f\"FM{j}\")  # type: ignore[assignment]\nfm_component = (fm_idx, hea(n_qubits, 1, f\"theta_{j}\"))\nfm_components.extend(fm_component)\nfm_components.append(tag(idx_fms[-1], tag=f\"FM{len(idx_fms) - 1}\"))\nfm = chain(*fm_components)  # type: ignore[assignment]\nansatz = hea(n_qubits, depth=depth) if ansatz is None else ansatz\nreturn [fm, ansatz]\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.ansatze.hea","title":"<code>hea(n_qubits, depth=1, param_prefix='theta', support=None, strategy=Strategy.DIGITAL, **strategy_args)</code>","text":"<p>Factory function for the Hardware Efficient Ansatz (HEA).</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indexes where the HEA is applied</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>strategy</code> <p>Strategy.Digital or Strategy.DigitalAnalog</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>**strategy_args</code> <p>see below</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> PARAMETER DESCRIPTION <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer. Valid for Digital and DigitalAnalog HEA.</p> <p> TYPE: <code>list</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. periodic=False is not supported in emu-c. Valid for only for Digital HEA.</p> <p> TYPE: <code>bool</code> </p> <code>entangler</code> <ul> <li>Digital: 2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational parameters on the rotation angles.</li> <li>DigitaAnalog | Analog: Hamiltonian generator for the analog entangling layer. Defaults to global ZZ Hamiltonian. Time parameter is considered variational.</li> </ul> <p> TYPE: <code>AbstractBlock</code> </p> <p>Examples: <pre><code>from qadence import RZ, RX\nfrom qadence import hea\n# create the circuit\nn_qubits, depth = 2, 4\nansatz = hea(\nn_qubits=n_qubits,\ndepth=depth,\nstrategy=\"sDAQC\",\noperations=[RZ,RX,RZ]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def hea(\nn_qubits: int,\ndepth: int = 1,\nparam_prefix: str = \"theta\",\nsupport: tuple[int, ...] = None,\nstrategy: Strategy = Strategy.DIGITAL,\n**strategy_args: Any,\n) -&gt; AbstractBlock:\n\"\"\"\n    Factory function for the Hardware Efficient Ansatz (HEA).\n    Args:\n        n_qubits: number of qubits in the block\n        depth: number of layers of the HEA\n        param_prefix: the base name of the variational parameters\n        support: qubit indexes where the HEA is applied\n        strategy: Strategy.Digital or Strategy.DigitalAnalog\n        **strategy_args: see below\n    Keyword Arguments:\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer. Valid for\n            Digital and DigitalAnalog HEA.\n        periodic (bool): if the qubits should be linked periodically.\n            periodic=False is not supported in emu-c. Valid for only\n            for Digital HEA.\n        entangler (AbstractBlock):\n            - Digital: 2-qubit entangling operation. Supports CNOT, CZ,\n            CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational\n            parameters on the rotation angles.\n            - DigitaAnalog | Analog: Hamiltonian generator for the\n            analog entangling layer. Defaults to global ZZ Hamiltonian.\n            Time parameter is considered variational.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import RZ, RX\n    from qadence import hea\n    # create the circuit\n    n_qubits, depth = 2, 4\n    ansatz = hea(\n        n_qubits=n_qubits,\n        depth=depth,\n        strategy=\"sDAQC\",\n        operations=[RZ,RX,RZ]\n    )\n    ```\n    \"\"\"\nif support is None:\nsupport = tuple(range(n_qubits))\nhea_func_dict = {\nStrategy.DIGITAL: hea_digital,\nStrategy.SDAQC: hea_sDAQC,\nStrategy.BDAQC: hea_bDAQC,\nStrategy.ANALOG: hea_analog,\n}\ntry:\nhea_func = hea_func_dict[strategy]\nexcept KeyError:\nraise KeyError(f\"Strategy {strategy} not recognized.\")\nhea_block: AbstractBlock = hea_func(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=param_prefix,\nsupport=support,\n**strategy_args,\n)  # type: ignore\nreturn hea_block\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.ansatze.hea_digital","title":"<code>hea_digital(n_qubits, depth=1, param_prefix='theta', periodic=False, operations=[RX, RY, RX], support=None, entangler=CNOT)</code>","text":"<p>Construct the Digital Hardware Efficient Ansatz (HEA).</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. periodic=False is not supported in emu-c.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY, RX]</code> </p> <code>support</code> <p>qubit indexes where the HEA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>entangler</code> <p>2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations will have variational parameters on the rotation angles.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>CNOT</code> </p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def hea_digital(\nn_qubits: int,\ndepth: int = 1,\nparam_prefix: str = \"theta\",\nperiodic: bool = False,\noperations: list[type[AbstractBlock]] = [RX, RY, RX],\nsupport: tuple[int, ...] = None,\nentangler: Type[DigitalEntanglers] = CNOT,\n) -&gt; AbstractBlock:\n\"\"\"\n    Construct the Digital Hardware Efficient Ansatz (HEA).\n    Args:\n        n_qubits (int): number of qubits in the block.\n        depth (int): number of layers of the HEA.\n        param_prefix (str): the base name of the variational parameters\n        periodic (bool): if the qubits should be linked periodically.\n            periodic=False is not supported in emu-c.\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        support (tuple): qubit indexes where the HEA is applied.\n        entangler (AbstractBlock): 2-qubit entangling operation.\n            Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations\n            will have variational parameters on the rotation angles.\n    \"\"\"\ntry:\nif entangler not in [CNOT, CZ, CRX, CRY, CRZ, CPHASE]:\nraise ValueError(\n\"Please provide a valid two-qubit entangler operation for digital HEA.\"\n)\nexcept TypeError:\nraise ValueError(\"Please provide a valid two-qubit entangler operation for digital HEA.\")\nrot_list = _rotations_digital(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=param_prefix,\nsupport=support,\noperations=operations,\n)\nent_list = _entanglers_digital(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=param_prefix,\nsupport=support,\nperiodic=periodic,\nentangler=entangler,\n)\nlayers = []\nfor d in range(depth):\nlayers.append(rot_list[d])\nlayers.append(ent_list[d])\nreturn tag(chain(*layers), \"HEA\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.ansatze.hea_sDAQC","title":"<code>hea_sDAQC(n_qubits, depth=1, param_prefix='theta', operations=[RX, RY, RX], support=None, entangler=None)</code>","text":"<p>Construct the Hardware Efficient Ansatz (HEA) with analog entangling layers using step-wise digital-analog computation.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY, RX]</code> </p> <code>support</code> <p>qubit indexes where the HEA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>entangler</code> <p>Hamiltonian generator for the analog entangling layer. Defaults to global ZZ Hamiltonian. Time parameter is considered variational.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def hea_sDAQC(\nn_qubits: int,\ndepth: int = 1,\nparam_prefix: str = \"theta\",\noperations: list[type[AbstractBlock]] = [RX, RY, RX],\nsupport: tuple[int, ...] = None,\nentangler: AbstractBlock | None = None,\n) -&gt; AbstractBlock:\n\"\"\"\n    Construct the Hardware Efficient Ansatz (HEA) with analog entangling layers\n    using step-wise digital-analog computation.\n    Args:\n        n_qubits (int): number of qubits in the block.\n        depth (int): number of layers of the HEA.\n        param_prefix (str): the base name of the variational parameters\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        support (tuple): qubit indexes where the HEA is applied.\n        entangler (AbstractBlock): Hamiltonian generator for the\n            analog entangling layer. Defaults to global ZZ Hamiltonian.\n            Time parameter is considered variational.\n    \"\"\"\n# TODO: Add qubit support\nif entangler is None:\nentangler = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\ntry:\nif not block_is_qubit_hamiltonian(entangler):\nraise ValueError(\n\"Please provide a valid Pauli Hamiltonian generator for digital-analog HEA.\"\n)\nexcept NotImplementedError:\nraise ValueError(\n\"Please provide a valid Pauli Hamiltonian generator for digital-analog HEA.\"\n)\nrot_list = _rotations_digital(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=param_prefix,\nsupport=support,\noperations=operations,\n)\nent_list = _entanglers_analog(\ndepth=depth,\nparam_prefix=param_prefix,\nentangler=entangler,\n)\nlayers = []\nfor d in range(depth):\nlayers.append(rot_list[d])\nlayers.append(ent_list[d])\nreturn tag(chain(*layers), \"HEA-sDA\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.hamiltonian_factory","title":"<code>hamiltonian_factory(register, interaction=None, detuning=None, interaction_strength=None, detuning_strength=None, random_strength=False, force_update=False)</code>","text":"<p>General Hamiltonian creation function. Can be used to create Hamiltonians with 2-qubit interactions and single-qubit detunings, both with arbitrary strength or parameterized.</p> PARAMETER  DESCRIPTION <code>register</code> <p>register of qubits with a specific graph topology, or number of qubits. When passing a number of qubits a register with all-to-all connectivity is created.</p> <p> TYPE: <code>Register | int</code> </p> <code>interaction</code> <p>Interaction.ZZ, Interaction.NN, Interaction.XY, or Interacton.XYZ.</p> <p> TYPE: <code>Interaction | None</code> DEFAULT: <code>None</code> </p> <code>detuning</code> <p>single-qubit operator N, X, Y, or Z.</p> <p> TYPE: <code>TDetuning | None</code> DEFAULT: <code>None</code> </p> <code>interaction_strength</code> <p>list of values to be used as the interaction strength for each pair of qubits. Should be ordered following the order of <code>Register(n_qubits).edges</code>. Alternatively, some string \"x\" can be passed, which will create a parameterized interactions for each pair of qubits, each labelled as <code>\"x_ij\"</code>.</p> <p> TYPE: <code>TArray | str | None</code> DEFAULT: <code>None</code> </p> <code>detuning_strength</code> <p>list of values to be used as the detuning strength for each qubit. Alternatively, some string \"x\" can be passed, which will create a parameterized detuning for each qubit, each labelled as <code>\"x_i\"</code>.</p> <p> TYPE: <code>TArray | str | None</code> DEFAULT: <code>None</code> </p> <code>random_strength</code> <p>set random interaction and detuning strengths between -1 and 1.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>force_update</code> <p>force override register detuning and interaction strengths.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Examples:</p> <pre><code>from qadence import hamiltonian_factory, Interaction, Register, Z\nn_qubits = 3\n# Constant total magnetization observable:\nobservable = hamiltonian_factory(n_qubits, detuning = Z)\n# Parameterized total magnetization observable:\nobservable = hamiltonian_factory(n_qubits, detuning = Z, detuning_strength = \"z\")\n# Random all-to-all XY Hamiltonian generator:\ngenerator = hamiltonian_factory(\nn_qubits,\ninteraction = Interaction.XY,\nrandom_strength = True,\n)\n# Parameterized NN Hamiltonian generator with a square grid interaction topology:\nregister = Register.square(qubits_side = n_qubits)\ngenerator = hamiltonian_factory(\nregister,\ninteraction = Interaction.NN,\ninteraction_strength = \"theta\"\n)\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def hamiltonian_factory(\nregister: Register | int,\ninteraction: Interaction | None = None,\ndetuning: TDetuning | None = None,\ninteraction_strength: TArray | str | None = None,\ndetuning_strength: TArray | str | None = None,\nrandom_strength: bool = False,\nforce_update: bool = False,\n) -&gt; AbstractBlock:\n\"\"\"\n    General Hamiltonian creation function. Can be used to create Hamiltonians with 2-qubit\n    interactions and single-qubit detunings, both with arbitrary strength or parameterized.\n    Arguments:\n        register: register of qubits with a specific graph topology, or number of qubits.\n            When passing a number of qubits a register with all-to-all connectivity\n            is created.\n        interaction: Interaction.ZZ, Interaction.NN, Interaction.XY, or Interacton.XYZ.\n        detuning: single-qubit operator N, X, Y, or Z.\n        interaction_strength: list of values to be used as the interaction strength for each\n            pair of qubits. Should be ordered following the order of `Register(n_qubits).edges`.\n            Alternatively, some string \"x\" can be passed, which will create a parameterized\n            interactions for each pair of qubits, each labelled as `\"x_ij\"`.\n        detuning_strength: list of values to be used as the detuning strength for each qubit.\n            Alternatively, some string \"x\" can be passed, which will create a parameterized\n            detuning for each qubit, each labelled as `\"x_i\"`.\n        random_strength: set random interaction and detuning strengths between -1 and 1.\n        force_update: force override register detuning and interaction strengths.\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import hamiltonian_factory, Interaction, Register, Z\n        n_qubits = 3\n        # Constant total magnetization observable:\n        observable = hamiltonian_factory(n_qubits, detuning = Z)\n        # Parameterized total magnetization observable:\n        observable = hamiltonian_factory(n_qubits, detuning = Z, detuning_strength = \"z\")\n        # Random all-to-all XY Hamiltonian generator:\n        generator = hamiltonian_factory(\n            n_qubits,\n            interaction = Interaction.XY,\n            random_strength = True,\n            )\n        # Parameterized NN Hamiltonian generator with a square grid interaction topology:\n        register = Register.square(qubits_side = n_qubits)\n        generator = hamiltonian_factory(\n            register,\n            interaction = Interaction.NN,\n            interaction_strength = \"theta\"\n            )\n        ```\n    \"\"\"\nif interaction is None and detuning is None:\nraise ValueError(\"Please provide an interaction and/or detuning for the Hamiltonian.\")\n# If number of qubits is given, creates all-to-all register\nregister = Register(register) if isinstance(register, int) else register\n# Get interaction function\ntry:\nint_fn = INTERACTION_DICT[interaction]  # type: ignore [index]\nexcept (KeyError, ValueError) as error:\nif interaction is None:\npass\nelse:\nraise KeyError(f\"Interaction {interaction} not supported.\")\n# Check single-qubit detuning\nif (detuning is not None) and (detuning not in DETUNINGS):\nraise TypeError(f\"Detuning of type {type(detuning)} not supported.\")\n# Pre-process detuning and interaction strengths and update register\nhas_detuning_strength, detuning_strength = _preprocess_strengths(\nregister, detuning_strength, \"nodes\", force_update, random_strength\n)\nhas_interaction_strength, interaction_strength = _preprocess_strengths(\nregister, interaction_strength, \"edges\", force_update, random_strength\n)\nif (not has_detuning_strength) or force_update:\nregister = _update_detuning_strength(register, detuning_strength)\nif (not has_interaction_strength) or force_update:\nregister = _update_interaction_strength(register, interaction_strength)\n# Create single-qubit detunings:\nsingle_qubit_terms: List[AbstractBlock] = []\nif detuning is not None:\nfor node in register.nodes:\nblock_sq = detuning(node)  # type: ignore [operator]\nstrength_sq = register.nodes[node][\"strength\"]\nsingle_qubit_terms.append(strength_sq * block_sq)\n# Create two-qubit interactions:\ntwo_qubit_terms: List[AbstractBlock] = []\nif interaction is not None:\nfor edge in register.edges:\nblock_tq = int_fn(*edge)  # type: ignore [operator]\nstrength_tq = register.edges[edge][\"strength\"]\ntwo_qubit_terms.append(strength_tq * block_tq)\nreturn add(*single_qubit_terms, *two_qubit_terms)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.interaction_nn","title":"<code>interaction_nn(i, j)</code>","text":"<p>Ising NN interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_nn(i: int, j: int) -&gt; AbstractBlock:\n\"\"\"Ising NN interaction.\"\"\"\nreturn N(i) @ N(j)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.interaction_xy","title":"<code>interaction_xy(i, j)</code>","text":"<p>XY interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_xy(i: int, j: int) -&gt; AbstractBlock:\n\"\"\"XY interaction.\"\"\"\nreturn X(i) @ X(j) + Y(i) @ Y(j)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.interaction_xyz","title":"<code>interaction_xyz(i, j)</code>","text":"<p>Heisenberg XYZ interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_xyz(i: int, j: int) -&gt; AbstractBlock:\n\"\"\"Heisenberg XYZ interaction.\"\"\"\nreturn X(i) @ X(j) + Y(i) @ Y(j) + Z(i) @ Z(j)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.interaction_zz","title":"<code>interaction_zz(i, j)</code>","text":"<p>Ising ZZ interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_zz(i: int, j: int) -&gt; AbstractBlock:\n\"\"\"Ising ZZ interaction.\"\"\"\nreturn Z(i) @ Z(j)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.qft.qft","title":"<code>qft(n_qubits, support=None, inverse=False, reverse_in=False, swaps_out=False, strategy=Strategy.DIGITAL, gen_build=None)</code>","text":"<p>The Quantum Fourier Transform</p> <p>Depending on the application, user should be careful with qubit ordering in the input and output. This can be controlled with reverse_in and swaps_out arguments.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the QFT</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>qubit support to use</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>inverse</code> <p>True performs the inverse QFT</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>reverse_in</code> <p>Reverses the input qubits to account for endianness</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>swaps_out</code> <p>Performs swaps on the output qubits to match the \"textbook\" QFT.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>strategy</code> <p>Strategy.Digital or Strategy.sDAQC</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>gen_build</code> <p>building block Ising Hamiltonian for the DAQC transform. Defaults to constant all-to-all Ising.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>from qadence import qft\nn_qubits = 3\nqft_circuit = qft(n_qubits, strategy = \"sDAQC\")\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/qft.py</code> <pre><code>def qft(\nn_qubits: int,\nsupport: tuple[int, ...] = None,\ninverse: bool = False,\nreverse_in: bool = False,\nswaps_out: bool = False,\nstrategy: Strategy = Strategy.DIGITAL,\ngen_build: AbstractBlock | None = None,\n) -&gt; AbstractBlock:\n\"\"\"\n    The Quantum Fourier Transform\n    Depending on the application, user should be careful with qubit ordering\n    in the input and output. This can be controlled with reverse_in and swaps_out\n    arguments.\n    Args:\n        n_qubits: number of qubits in the QFT\n        support: qubit support to use\n        inverse: True performs the inverse QFT\n        reverse_in: Reverses the input qubits to account for endianness\n        swaps_out: Performs swaps on the output qubits to match the \"textbook\" QFT.\n        strategy: Strategy.Digital or Strategy.sDAQC\n        gen_build: building block Ising Hamiltonian for the DAQC transform.\n            Defaults to constant all-to-all Ising.\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import qft\n        n_qubits = 3\n        qft_circuit = qft(n_qubits, strategy = \"sDAQC\")\n        ```\n    \"\"\"\nif support is None:\nsupport = tuple(range(n_qubits))\nassert len(support) &lt;= n_qubits, \"Wrong qubit support supplied\"\nif reverse_in:\nsupport = support[::-1]\nqft_layer_dict = {\nStrategy.DIGITAL: _qft_layer_digital,\nStrategy.SDAQC: _qft_layer_sDAQC,\nStrategy.BDAQC: _qft_layer_bDAQC,\nStrategy.ANALOG: _qft_layer_analog,\n}\ntry:\nlayer_func = qft_layer_dict[strategy]\nexcept KeyError:\nraise KeyError(f\"Strategy {strategy} not recognized.\")\nqft_layers = reversed(range(n_qubits)) if inverse else range(n_qubits)\nqft_circ = chain(\nlayer_func(\nn_qubits=n_qubits, support=support, layer=layer, inverse=inverse, gen_build=gen_build\n)  # type: ignore\nfor layer in qft_layers\n)\nif swaps_out:\nswap_ops = [SWAP(support[i], support[n_qubits - i - 1]) for i in range(n_qubits // 2)]\nqft_circ = chain(*swap_ops, qft_circ) if inverse else chain(qft_circ, *swap_ops)\nreturn tag(qft_circ, tag=\"iQFT\") if inverse else tag(qft_circ, tag=\"QFT\")\n</code></pre>"},{"location":"qadence/constructors/#the-daqc-transform","title":"The DAQC Transform","text":""},{"location":"qadence/constructors/#qadence.constructors.daqc.daqc.daqc_transform","title":"<code>daqc_transform(n_qubits, gen_target, t_f, gen_build=None, zero_tol=1e-08, strategy=Strategy.SDAQC, ignore_global_phases=False)</code>","text":"<p>Implements the DAQC transform for representing an arbitrary 2-body Hamiltonian with another fixed 2-body Hamiltonian.</p> <p>Reference for universality of 2-body Hamiltonians:</p> <p>-- https://arxiv.org/abs/quant-ph/0106064</p> <p>Based on the transformation for Ising (ZZ) interactions, as described in the paper</p> <p>-- https://arxiv.org/abs/1812.03637</p> <p>The transform translates a target weighted generator of the type:</p> <pre><code>`gen_target = add(g_jk * kron(op(j), op(k)) for j &lt; k)`\n</code></pre> <p>To a circuit using analog evolutions with a fixed building block generator:</p> <pre><code>`gen_build = add(f_jk * kron(op(j), op(k)) for j &lt; k)`\n</code></pre> <p>where <code>op = Z</code> or <code>op = N</code>.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>total number of qubits to use.</p> <p> TYPE: <code>int</code> </p> <code>gen_target</code> <p>target generator built with the structure above. The type of the generator will be automatically evaluated when parsing.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>t_f</code> <p>total time for the gen_target evolution.</p> <p> TYPE: <code>float</code> </p> <code>gen_build</code> <p>fixed generator to act as a building block. Defaults to constant NN: add(1.0 * kron(N(j), N(k)) for j &lt; k). The type of the generator will be automatically evaluated when parsing.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <code>zero_tol</code> <p>default \"zero\" for a missing interaction. Included for numerical reasons, see notes below.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-08</code> </p> <code>strategy</code> <p>sDAQC or bDAQC, following definitions in the reference paper.</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>SDAQC</code> </p> <code>ignore_global_phases</code> <p>if <code>True</code> the transform does not correct the global phases coming from the mapping between ZZ and NN interactions.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Notes:</p> <pre><code>The paper follows an index convention of running from 1 to N. A few functions\nhere also use that convention to be consistent with the paper. However, for qadence\nrelated things the indices are converted to [0, N-1].\n\nThe case for `n_qubits = 4` is an edge case where the sign matrix is not invertible.\nThere is a workaround for this described in the paper, but it is currently not implemented.\n\nThe current implementation may result in evolution times that are both positive or\nnegative. In practice, both can be represented by simply changing the signs of the\ninteractions. However, for a real implementation where the interactions should remain\nfixed, the paper discusses a workaround that is not currently implemented.\n\nThe transformation works by representing each interaction in the target hamiltonian by\na set of evolutions using the build hamiltonian. As a consequence, some care must be\ntaken when choosing the build hamiltonian. Some cases:\n\n- The target hamiltonian can have any interaction, as long as it is sufficiently\nrepresented in the build hamiltonian. E.g., if the interaction `g_01 * kron(Z(0), Z(1))`\nis in the target hamiltonian, the corresponding interaction `f_01 * kron(Z(0), Z(1))`\nneeds to be in the build hamiltonian. This is checked when the generators are parsed.\n\n- The build hamiltonian can have any interaction, irrespectively of it being needed\nfor the target hamiltonian. This is especially useful for designing local operations\nthrough the repeated evolution of a \"global\" hamiltonian.\n\n- The parameter `zero_tol` controls what it means for an interaction to be \"missing\".\nAny interaction strength smaller than `zero_tol` in the build hamiltonian will not be\nconsidered, and thus that interaction is missing.\n\n- The various ratios `g_jk / f_jk` will influence the time parameter for the various\nevolution slices, meaning that if there is a big discrepancy in the interaction strength\nfor a given qubit pair (j, k), the output circuit may require the usage of hamiltonian\nevolutions with very large times.\n\n- A warning will be issued for evolution times larger than `1/sqrt(zero_tol)`. Evolution\ntimes smaller than `zero_tol` will not be represented.\n</code></pre> <p>Examples:</p> <pre><code>from qadence import Z, N, daqc_transform\nn_qubits = 3\ngen_build = 0.5 * (N(0)@N(1)) + 0.7 * (N(1)@N(2)) + 0.2 * (N(0)@N(2))\ngen_target = 0.1 * (Z(1)@Z(2))\nt_f = 2.0\ntransformed_circuit = daqc_transform(\nn_qubits = n_qubits,\ngen_target = gen_target,\nt_f = t_f,\ngen_build = gen_build,\n)\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/daqc/daqc.py</code> <pre><code>def daqc_transform(\nn_qubits: int,\ngen_target: AbstractBlock,\nt_f: float,\ngen_build: AbstractBlock | None = None,\nzero_tol: float = 1e-08,\nstrategy: Strategy = Strategy.SDAQC,\nignore_global_phases: bool = False,\n) -&gt; AbstractBlock:\n\"\"\"\n    Implements the DAQC transform for representing an arbitrary 2-body Hamiltonian\n    with another fixed 2-body Hamiltonian.\n    Reference for universality of 2-body Hamiltonians:\n    -- https://arxiv.org/abs/quant-ph/0106064\n    Based on the transformation for Ising (ZZ) interactions, as described in the paper\n    -- https://arxiv.org/abs/1812.03637\n    The transform translates a target weighted generator of the type:\n        `gen_target = add(g_jk * kron(op(j), op(k)) for j &lt; k)`\n    To a circuit using analog evolutions with a fixed building block generator:\n        `gen_build = add(f_jk * kron(op(j), op(k)) for j &lt; k)`\n    where `op = Z` or `op = N`.\n    Args:\n        n_qubits: total number of qubits to use.\n        gen_target: target generator built with the structure above. The type\n            of the generator will be automatically evaluated when parsing.\n        t_f (float): total time for the gen_target evolution.\n        gen_build: fixed generator to act as a building block. Defaults to\n            constant NN: add(1.0 * kron(N(j), N(k)) for j &lt; k). The type\n            of the generator will be automatically evaluated when parsing.\n        zero_tol: default \"zero\" for a missing interaction. Included for\n            numerical reasons, see notes below.\n        strategy: sDAQC or bDAQC, following definitions in the reference paper.\n        ignore_global_phases: if `True` the transform does not correct the global\n            phases coming from the mapping between ZZ and NN interactions.\n    Notes:\n        The paper follows an index convention of running from 1 to N. A few functions\n        here also use that convention to be consistent with the paper. However, for qadence\n        related things the indices are converted to [0, N-1].\n        The case for `n_qubits = 4` is an edge case where the sign matrix is not invertible.\n        There is a workaround for this described in the paper, but it is currently not implemented.\n        The current implementation may result in evolution times that are both positive or\n        negative. In practice, both can be represented by simply changing the signs of the\n        interactions. However, for a real implementation where the interactions should remain\n        fixed, the paper discusses a workaround that is not currently implemented.\n        The transformation works by representing each interaction in the target hamiltonian by\n        a set of evolutions using the build hamiltonian. As a consequence, some care must be\n        taken when choosing the build hamiltonian. Some cases:\n        - The target hamiltonian can have any interaction, as long as it is sufficiently\n        represented in the build hamiltonian. E.g., if the interaction `g_01 * kron(Z(0), Z(1))`\n        is in the target hamiltonian, the corresponding interaction `f_01 * kron(Z(0), Z(1))`\n        needs to be in the build hamiltonian. This is checked when the generators are parsed.\n        - The build hamiltonian can have any interaction, irrespectively of it being needed\n        for the target hamiltonian. This is especially useful for designing local operations\n        through the repeated evolution of a \"global\" hamiltonian.\n        - The parameter `zero_tol` controls what it means for an interaction to be \"missing\".\n        Any interaction strength smaller than `zero_tol` in the build hamiltonian will not be\n        considered, and thus that interaction is missing.\n        - The various ratios `g_jk / f_jk` will influence the time parameter for the various\n        evolution slices, meaning that if there is a big discrepancy in the interaction strength\n        for a given qubit pair (j, k), the output circuit may require the usage of hamiltonian\n        evolutions with very large times.\n        - A warning will be issued for evolution times larger than `1/sqrt(zero_tol)`. Evolution\n        times smaller than `zero_tol` will not be represented.\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import Z, N, daqc_transform\n        n_qubits = 3\n        gen_build = 0.5 * (N(0)@N(1)) + 0.7 * (N(1)@N(2)) + 0.2 * (N(0)@N(2))\n        gen_target = 0.1 * (Z(1)@Z(2))\n        t_f = 2.0\n        transformed_circuit = daqc_transform(\n            n_qubits = n_qubits,\n            gen_target = gen_target,\n            t_f = t_f,\n            gen_build = gen_build,\n        )\n        ```\n    \"\"\"\n##################\n# Input controls #\n##################\nif strategy != Strategy.SDAQC:\nraise NotImplementedError(\"Currently only the sDAQC transform is implemented.\")\nif n_qubits == 4:\nraise NotImplementedError(\"DAQC transform 4-qubit edge case not implemented.\")\nif gen_build is None:\ngen_build = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\ntry:\nif (not block_is_qubit_hamiltonian(gen_target)) or (\nnot block_is_qubit_hamiltonian(gen_build)\n):\nraise ValueError(\n\"Generator block is not a qubit Hamiltonian. Only ZZ or NN interactions allowed.\"\n)\nexcept NotImplementedError:\n# Happens when block_is_qubit_hamiltonian is called on something that is not a block.\nraise TypeError(\n\"Generator block is not a qubit Hamiltonian. Only ZZ or NN interactions allowed.\"\n)\n#####################\n# Generator parsing #\n#####################\ng_jk_target, mat_jk_target, target_type = _parse_generator(n_qubits, gen_target, 0.0)\ng_jk_build, mat_jk_build, build_type = _parse_generator(n_qubits, gen_build, zero_tol)\n# Get the global phase hamiltonian and single-qubit detuning hamiltonian\nif build_type == GenDAQC.NN:\nh_phase_build, h_sq_build = _nn_phase_and_detunings(n_qubits, mat_jk_build)\nif target_type == GenDAQC.NN:\nh_phase_target, h_sq_target = _nn_phase_and_detunings(n_qubits, mat_jk_target)\n# Time re-scalings\nif build_type == GenDAQC.ZZ and target_type == GenDAQC.NN:\nt_star = t_f / 4.0\nelif build_type == GenDAQC.NN and target_type == GenDAQC.ZZ:\nt_star = 4.0 * t_f\nelse:\nt_star = t_f\n# Check if target Hamiltonian can be mapped with the build Hamiltonian\nassert _check_compatibility(g_jk_target, g_jk_build, zero_tol)\n##################\n# DAQC Transform #\n##################\n# Section III A of https://arxiv.org/abs/1812.03637:\n# Matrix M for the linear system, exemplified in Table I:\nmatrix_M = _build_matrix_M(n_qubits)\n# Linear system mapping interaction ratios -&gt; evolution times.\nt_slices = torch.linalg.solve(matrix_M, g_jk_target / g_jk_build) * t_star\n# ZZ-DAQC with ZZ or NN build Hamiltonian\ndaqc_slices = []\nfor m in range(2, n_qubits + 1):\nfor n in range(1, m):\nalpha = _ix_map(n_qubits, n, m)\nt = t_slices[alpha - 1]\nif abs(t) &gt; zero_tol:\nif abs(t) &gt; (1 / (zero_tol**0.5)):\nlogger.warning(\n\"\"\"\nTransformed circuit with very long evolution time.\nMake sure your target interactions are sufficiently\nrepresented in the build Hamiltonian.\"\"\"\n)\nx_gates = kron(X(n - 1), X(m - 1))\nanalog_evo = HamEvo(gen_build, t)\n# TODO: Fix repeated X-gates\nif build_type == GenDAQC.NN:\n# Local detuning at each DAQC layer for NN build Hamiltonian\nsq_detuning_build = HamEvo(h_sq_build, t)\ndaqc_slices.append(chain(x_gates, sq_detuning_build, analog_evo, x_gates))\nelif build_type == GenDAQC.ZZ:\ndaqc_slices.append(chain(x_gates, analog_evo, x_gates))\ndaqc_circuit = chain(*daqc_slices)\n########################\n# Phases and Detunings #\n########################\nif target_type == GenDAQC.NN:\n# Local detuning given a NN target Hamiltonian\nsq_detuning_target = HamEvo(h_sq_target, t_f).dagger()\ndaqc_circuit = chain(sq_detuning_target, daqc_circuit)\nif not ignore_global_phases:\nif build_type == GenDAQC.NN:\n# Constant global phase given a NN build Hamiltonian\nglobal_phase_build = HamEvo(h_phase_build, t_slices.sum())\ndaqc_circuit = chain(global_phase_build, daqc_circuit)\nif target_type == GenDAQC.NN:\n# Constant global phase and given a NN target Hamiltonian\nglobal_phase_target = HamEvo(h_phase_target, t_f).dagger()\ndaqc_circuit = chain(global_phase_target, daqc_circuit)\nreturn daqc_circuit\n</code></pre>"},{"location":"qadence/constructors/#some-utility-functions","title":"Some utility functions","text":""},{"location":"qadence/constructors/#qadence.constructors.utils.build_idx_fms","title":"<code>build_idx_fms(basis, fm_pauli, fm_strategy, n_features, n_qubits, spectrum)</code>","text":"<p>Builds the index feature maps based on the given parameters.</p> PARAMETER  DESCRIPTION <code>basis</code> <p>Type of basis chosen for the feature map.</p> <p> TYPE: <code>str</code> </p> <code>fm_pauli</code> <p>The chosen Pauli rotation type.</p> <p> TYPE: <code>PrimitiveBlock type</code> </p> <code>fm_strategy</code> <p>The feature map strategy to be used. Possible values are 'parallel' or 'serial'.</p> <p> TYPE: <code>str</code> </p> <code>n_features</code> <p>The number of features.</p> <p> TYPE: <code>int</code> </p> <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>spectrum</code> <p>The chosen spectrum.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>list[KronBlock]</code> <p>List[KronBlock]: The list of index feature maps.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def build_idx_fms(\nbasis: str,\nfm_pauli: Type[RY],\nfm_strategy: str,\nn_features: int,\nn_qubits: int,\nspectrum: str,\n) -&gt; list[KronBlock]:\n\"\"\"Builds the index feature maps based on the given parameters.\n    Args:\n        basis (str): Type of basis chosen for the feature map.\n        fm_pauli (PrimitiveBlock type): The chosen Pauli rotation type.\n        fm_strategy (str): The feature map strategy to be used. Possible values are\n            'parallel' or 'serial'.\n        n_features (int): The number of features.\n        n_qubits (int): The number of qubits.\n        spectrum (str): The chosen spectrum.\n    Returns:\n        List[KronBlock]: The list of index feature maps.\n    \"\"\"\nidx_fms = []\nfor i in range(n_features):\ntarget_qubits = get_fm_qubits(fm_strategy, i, n_qubits, n_features)\nparam = FeatureParameter(f\"x{i}\")\nblock = kron(\n*[\nfm_pauli(qubit, generator_prefactor(spectrum, j) * basis_func(basis, param))\nfor j, qubit in enumerate(target_qubits)\n]\n)\nidx_fm = block\nidx_fms.append(idx_fm)\nreturn idx_fms\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.utils.generator_prefactor","title":"<code>generator_prefactor(spectrum, qubit_index)</code>","text":"<p>Converts a spectrum string (e.g., tower or exponential) to the correct generator prefactor.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def generator_prefactor(spectrum: str, qubit_index: int) -&gt; float | int:\n\"\"\"\n    Converts a spectrum string (e.g., tower or exponential) to the correct generator prefactor.\n    \"\"\"\nspectrum = spectrum.lower()\nconversion_dict: dict[str, float | int] = {\n\"simple\": 1,\n\"tower\": qubit_index + 1,\n\"exponential\": 2 * np.pi / (2 ** (qubit_index + 1)),\n}\nreturn conversion_dict[spectrum]\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.utils.get_fm_qubits","title":"<code>get_fm_qubits(fm_strategy, i, n_qubits, n_features)</code>","text":"<p>Returns the list of target qubits for the given feature map strategy and feature index</p> PARAMETER  DESCRIPTION <code>fm_strategy</code> <p>The feature map strategy to be used. Possible values are 'parallel' or 'serial'.</p> <p> TYPE: <code>str</code> </p> <code>i</code> <p>The feature index.</p> <p> TYPE: <code>int</code> </p> <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>n_features</code> <p>The number of features.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Iterable</code> <p>List[int]: The list of target qubits.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the feature map strategy is not implemented.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def get_fm_qubits(fm_strategy: str, i: int, n_qubits: int, n_features: int) -&gt; Iterable:\n\"\"\"Returns the list of target qubits for the given feature map strategy and feature index\n    Args:\n        fm_strategy (str): The feature map strategy to be used. Possible values\n            are 'parallel' or 'serial'.\n        i (int): The feature index.\n        n_qubits (int): The number of qubits.\n        n_features (int): The number of features.\n    Returns:\n        List[int]: The list of target qubits.\n    Raises:\n        ValueError: If the feature map strategy is not implemented.\n    \"\"\"\nif fm_strategy == \"parallel\":\nn_qubits_per_feature = int(n_qubits / n_features)\ntarget_qubits = range(i * n_qubits_per_feature, (i + 1) * n_qubits_per_feature)\nelif fm_strategy == \"serial\":\ntarget_qubits = range(0, n_qubits)\nelse:\nraise ValueError(f\"Feature map strategy {fm_strategy} not implemented.\")\nreturn target_qubits\n</code></pre>"},{"location":"qadence/execution/","title":"Execution","text":""},{"location":"qadence/execution/#qadence.execution.expectation","title":"<code>expectation(x, observable, values={}, state=None, backend=BackendName.PYQTORCH, diff_mode=None, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.expectation</code> method.  This is a <code>functools.singledispatch</code>ed function so it can be called with a number of different arguments (see in the examples).</p> PARAMETER  DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>observable</code> <p>Observable(s) w.r.t. which the expectation is computed.</p> <p> TYPE: <code>Union[list[AbstractBlock], AbstractBlock]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>Which differentiation mode to use.</p> <p> TYPE: <code>Union[DiffMode, str, None]</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A wavefunction</p> <pre><code>from qadence import RX, Z, Register, QuantumCircuit, expectation\nreg = Register(1)\nblock = RX(0, 0.5)\nobservable = Z(0)\ncirc = QuantumCircuit(reg, block)\n# You can compute the expectation for a\n# QuantumCircuit with a given observable.\nexpectation(circ, observable)\n# You can also use only a block.\n# In this case the register is constructed automatically to\n# Register.line(block.n_qubits)\nexpectation(block, observable)\n# Or a register and block\nexpectation(reg, block, observable)\n</code></pre> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef expectation(\nx: Union[QuantumCircuit, AbstractBlock, Register, int],\nobservable: Union[list[AbstractBlock], AbstractBlock],\nvalues: dict = {},\nstate: Tensor = None,\nbackend: BackendName = BackendName.PYQTORCH,\ndiff_mode: Union[DiffMode, str, None] = None,\nendianness: Endianness = Endianness.BIG,\nconfiguration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; Tensor:\n\"\"\"Convenience wrapper for the `QuantumModel.expectation` method.  This is a\n    `functools.singledispatch`ed function so it can be called with a number of different arguments\n    (see in the examples).\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        observable: Observable(s) w.r.t. which the expectation is computed.\n        values: User-facing parameter dict.\n        state: Initial state.\n        backend: Name of the backend to run on.\n        diff_mode: Which differentiation mode to use.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n    Returns:\n        A wavefunction\n    ```python exec=\"on\" source=\"material-block\"\n    from qadence import RX, Z, Register, QuantumCircuit, expectation\n    reg = Register(1)\n    block = RX(0, 0.5)\n    observable = Z(0)\n    circ = QuantumCircuit(reg, block)\n    # You can compute the expectation for a\n    # QuantumCircuit with a given observable.\n    expectation(circ, observable)\n    # You can also use only a block.\n    # In this case the register is constructed automatically to\n    # Register.line(block.n_qubits)\n    expectation(block, observable)\n    # Or a register and block\n    expectation(reg, block, observable)\n    ```\"\"\"\nraise ValueError(f\"Cannot execute {type(x)}\")\n</code></pre>"},{"location":"qadence/execution/#qadence.execution.run","title":"<code>run(x, *args, values={}, state=None, backend=BackendName.PYQTORCH, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.run</code> method.  This is a <code>functools.singledispatch</code>ed function so it can be called with a number of different arguments. See the examples of the <code>expectation</code> function. This function works exactly the same.</p> PARAMETER  DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A wavefunction</p> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef run(\nx: Union[QuantumCircuit, AbstractBlock, Register, int],\n*args: Any,\nvalues: dict = {},\nstate: Tensor = None,\nbackend: BackendName = BackendName.PYQTORCH,\nendianness: Endianness = Endianness.BIG,\nconfiguration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; Tensor:\n\"\"\"Convenience wrapper for the `QuantumModel.run` method.  This is a\n    `functools.singledispatch`ed function so it can be called with a number of different arguments.\n    See the examples of the [`expectation`][qadence.execution.expectation] function. This function\n    works exactly the same.\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        values: User-facing parameter dict.\n        state: Initial state.\n        backend: Name of the backend to run on.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n    Returns:\n        A wavefunction\n    \"\"\"\nraise ValueError(f\"Cannot run {type(x)}\")\n</code></pre>"},{"location":"qadence/execution/#qadence.execution.sample","title":"<code>sample(x, *args, values={}, state=None, n_shots=100, backend=BackendName.PYQTORCH, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.sample</code> method.  This is a <code>functools.singledispatch</code>ed function so it can be called with a number of different arguments. See the examples of the <code>expectation</code> function. This function works exactly the same.</p> PARAMETER  DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Union[Tensor, None]</code> DEFAULT: <code>None</code> </p> <code>n_shots</code> <p>Number of shots per element in the batch.</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[Counter]</code> <p>A list of Counter instances with the sample results</p> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef sample(\nx: Union[QuantumCircuit, AbstractBlock, Register, int],\n*args: Any,\nvalues: dict = {},\nstate: Union[Tensor, None] = None,\nn_shots: int = 100,\nbackend: BackendName = BackendName.PYQTORCH,\nendianness: Endianness = Endianness.BIG,\nconfiguration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; list[Counter]:\n\"\"\"Convenience wrapper for the `QuantumModel.sample` method.  This is a\n    `functools.singledispatch`ed function so it can be called with a number of different arguments.\n    See the examples of the [`expectation`][qadence.execution.expectation] function. This function\n    works exactly the same.\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        values: User-facing parameter dict.\n        state: Initial state.\n        n_shots: Number of shots per element in the batch.\n        backend: Name of the backend to run on.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n    Returns:\n        A list of Counter instances with the sample results\n    \"\"\"\nraise ValueError(f\"Cannot sample from {type(x)}\")\n</code></pre>"},{"location":"qadence/ml_tools/","title":"QML tools","text":""},{"location":"qadence/ml_tools/#ml-tools","title":"ML Tools","text":"<p>This module implements gradient-free and gradient-based training loops for torch Modules and QuantumModel.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig","title":"<code>TrainConfig</code>  <code>dataclass</code>","text":"<p>Default config for the train function. The default value of each field can be customized with the constructor:</p> <pre><code>from qadence.ml_tools import TrainConfig\nc = TrainConfig(folder=\"/tmp/train\")\n</code></pre> <pre><code>TrainConfig(max_iter=10000, print_every=1000, write_every=50, checkpoint_every=5000, folder=PosixPath('/tmp/train'), create_subfolder_per_run=False, checkpoint_best_only=False, validation_criterion=&lt;function TrainConfig.__post_init__.&lt;locals&gt;.&lt;lambda&gt; at 0x7fa329747880&gt;, trainstop_criterion=&lt;function TrainConfig.__post_init__.&lt;locals&gt;.&lt;lambda&gt; at 0x7fa3297477f0&gt;, batch_size=1, verbose=True)\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.batch_size","title":"<code>batch_size: int = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The batch_size to use when passing a list/tuple of torch.Tensors.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.checkpoint_best_only","title":"<code>checkpoint_best_only: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Write model/optimizer checkpoint only if a metric has improved</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.checkpoint_every","title":"<code>checkpoint_every: int = 5000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Write model/optimizer checkpoint</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.create_subfolder_per_run","title":"<code>create_subfolder_per_run: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Checkpoint/tensorboard logs stored in subfolder with name <code>&lt;timestamp&gt;_&lt;PID&gt;</code>. Prevents continuing from previous checkpoint, useful for fast prototyping.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.folder","title":"<code>folder: Optional[Path] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Checkpoint/tensorboard logs folder</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.max_iter","title":"<code>max_iter: int = 10000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of training iterations.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.print_every","title":"<code>print_every: int = 1000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Print loss/metrics.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.trainstop_criterion","title":"<code>trainstop_criterion: Optional[Callable] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A boolean function which evaluates a given training stopping metric is satisfied</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.validation_criterion","title":"<code>validation_criterion: Optional[Callable] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A boolean function which evaluates a given validation metric is satisfied</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.verbose","title":"<code>verbose: bool = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether or not to print out metrics values during training.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.write_every","title":"<code>write_every: int = 50</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Write tensorboard logs</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.parameters.get_parameters","title":"<code>get_parameters(model)</code>","text":"<p>Retrieve all trainable model parameters in a single vector</p> PARAMETER  DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a 1-dimensional tensor with the parameters</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def get_parameters(model: Module) -&gt; Tensor:\n\"\"\"Retrieve all trainable model parameters in a single vector\n    Args:\n        model (Module): the input PyTorch model\n    Returns:\n        Tensor: a 1-dimensional tensor with the parameters\n    \"\"\"\nps = [p.reshape(-1) for p in model.parameters() if p.requires_grad]\nreturn torch.concat(ps)\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.parameters.num_parameters","title":"<code>num_parameters(model)</code>","text":"<p>Return the total number of parameters of the given model</p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def num_parameters(model: Module) -&gt; int:\n\"\"\"Return the total number of parameters of the given model\"\"\"\nreturn len(get_parameters(model))\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.parameters.set_parameters","title":"<code>set_parameters(model, theta)</code>","text":"<p>Set all trainable parameters of a model from a single vector</p> <p>Notice that this function assumes prior knowledge of right number of parameters in the model</p> PARAMETER  DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> <code>theta</code> <p>the parameters to assign</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def set_parameters(model: Module, theta: Tensor) -&gt; None:\n\"\"\"Set all trainable parameters of a model from a single vector\n    Notice that this function assumes prior knowledge of right number\n    of parameters in the model\n    Args:\n        model (Module): the input PyTorch model\n        theta (Tensor): the parameters to assign\n    \"\"\"\nwith torch.no_grad():\nidx = 0\nfor ps in model.parameters():\nif ps.requires_grad:\nn = torch.numel(ps)\nif ps.ndim == 0:\nps[()] = theta[idx : idx + n]\nelse:\nps[:] = theta[idx : idx + n].reshape(ps.size())\nidx += n\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.optimize_step.data_to_model","title":"<code>data_to_model(xs, device='cpu')</code>","text":"<p>Default behavior for single-dispatched function</p> <p>Just return the given data independently on the type</p> PARAMETER  DESCRIPTION <code>xs</code> <p>the input data</p> <p> TYPE: <code>Any</code> </p> <code>device</code> <p>The torch device. Not used in this implementation.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>the <code>xs</code> argument untouched</p> <p> TYPE: <code>Any</code> </p> Source code in <code>qadence/ml_tools/optimize_step.py</code> <pre><code>@singledispatch\ndef data_to_model(xs: Any, device: str = \"cpu\") -&gt; Any:\n\"\"\"Default behavior for single-dispatched function\n    Just return the given data independently on the type\n    Args:\n        xs (Any): the input data\n        device (str, optional): The torch device. Not used in this implementation.\n    Returns:\n        Any: the `xs` argument untouched\n    \"\"\"\nreturn xs\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.optimize_step.optimize_step","title":"<code>optimize_step(model, optimizer, loss_fn, xs, device='cpu')</code>","text":"<p>Default Torch optimize step with closure</p> <p>This is the default optimization step which should work for most of the standard use cases of optimization of Torch models</p> PARAMETER  DESCRIPTION <code>model</code> <p>The input model</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>The chosen Torch optimizer</p> <p> TYPE: <code>Optimizer</code> </p> <code>loss_fn</code> <p>A custom loss function</p> <p> TYPE: <code>Callable</code> </p> <code>xs</code> <p>the input data. If None it means that the given model does not require any input data</p> <p> TYPE: <code>dict | list | Tensor | None</code> </p> <code>device</code> <p>The device were computations are executed. Defaults to \"cpu\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> RETURNS DESCRIPTION <code>tuple</code> <p>tuple containing the model, the optimizer, a dictionary with the collected metrics and the compute value loss</p> <p> TYPE: <code>tuple[Tensor | float, dict | None]</code> </p> Source code in <code>qadence/ml_tools/optimize_step.py</code> <pre><code>def optimize_step(\nmodel: Module,\noptimizer: Optimizer,\nloss_fn: Callable,\nxs: dict | list | torch.Tensor | None,\ndevice: str = \"cpu\",\n) -&gt; tuple[torch.Tensor | float, dict | None]:\n\"\"\"Default Torch optimize step with closure\n    This is the default optimization step which should work for most\n    of the standard use cases of optimization of Torch models\n    Args:\n        model (Module): The input model\n        optimizer (Optimizer): The chosen Torch optimizer\n        loss_fn (Callable): A custom loss function\n        xs (dict | list | torch.Tensor | None): the input data. If None it means\n            that the given model does not require any input data\n        device (str, optional): The device were computations are executed.\n            Defaults to \"cpu\".\n    Returns:\n        tuple: tuple containing the model, the optimizer, a dictionary with\n            the collected metrics and the compute value loss\n    \"\"\"\nloss, metrics = None, {}\ndef closure() -&gt; Any:\n# NOTE: We need the nonlocal as we can't return a metric dict and\n# because e.g. LBFGS calls this closure multiple times but for some\n# reason the returned loss is always the first one...\nnonlocal metrics, loss\noptimizer.zero_grad()\nloss, metrics = loss_fn(model, xs)\nloss.backward(retain_graph=True)\nreturn loss.item()\noptimizer.step(closure)\n# return the loss/metrics that are being mutated inside the closure...\nreturn loss, metrics\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.train_grad.train","title":"<code>train(model, dataloader, optimizer, config, loss_fn, device='cpu', optimize_step=optimize_step, write_tensorboard=write_tensorboard)</code>","text":"<p>Runs the training loop with gradient-based optimizer</p> <p>Assumes that <code>loss_fn</code> returns a tuple of (loss, metrics: dict), where <code>metrics</code> is a dict of scalars. Loss and metrics are written to tensorboard. Checkpoints are written every <code>config.checkpoint_every</code> steps (and after the last training step).  If a checkpoint is found at <code>config.folder</code> we resume training from there.  The tensorboard logs can be viewed via <code>tensorboard --logdir /path/to/folder</code>.</p> PARAMETER  DESCRIPTION <code>model</code> <p>The model to train.</p> <p> TYPE: <code>Module</code> </p> <code>dataloader</code> <p>dataloader of different types. If None, no data is required by the model</p> <p> TYPE: <code>DictDataLoader | DataLoader | list[Tensor] | tuple[Tensor, Tensor] | None</code> </p> <code>optimizer</code> <p>The optimizer to use.</p> <p> TYPE: <code>Optimizer</code> </p> <code>config</code> <p><code>TrainConfig</code> with additional training options.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>loss_fn</code> <p>Loss function returning (loss: float, metrics: dict[str, float])</p> <p> TYPE: <code>Callable</code> </p> <code>device</code> <p>String defining device to train on, pass 'cuda' for GPU.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> <code>optimize_step</code> <p>Customizable optimization callback which is called at every iteration.= The function must have the signature <code>optimize_step(model, optimizer, loss_fn, xs, device=\"cpu\")</code> (see the example below). Apart from the default we already supply three other optimization functions <code>optimize_step_evo</code>, <code>optimize_step_grad_norm</code>, and <code>optimize_step_inv_dirichlet</code>. Learn more about how to use this in the Advancded features tutorial of the documentation.</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>optimize_step</code> </p> <code>write_tensorboard</code> <p>Customizable tensorboard logging callback which is called every <code>config.write_every</code> iterations. The function must have the signature <code>write_tensorboard(writer, loss, metrics, iteration)</code> (see the example below).</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>write_tensorboard</code> </p> <p>Example: <pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence.models import QNN\nfrom qadence.ml_tools import train_with_grad, TrainConfig\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning = Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\n## lets prepare the train routine\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\nnext(cnt)\nx, y = data[0], data[1]\nout = model(x)\nloss = criterion(out, y)\nreturn loss, {}\ntmp_path = Path(\"/tmp\")\nn_epochs = 5\nconfig = TrainConfig(\nfolder=tmp_path,\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\nbatch_size = 25\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\ntrain_with_grad(model, (x, y), optimizer, config, loss_fn=loss_fn)\n</code></pre> </p> Source code in <code>qadence/ml_tools/train_grad.py</code> <pre><code>def train(\nmodel: Module,\ndataloader: DictDataLoader | DataLoader | list[Tensor] | tuple[Tensor, Tensor] | None,\noptimizer: Optimizer,\nconfig: TrainConfig,\nloss_fn: Callable,\ndevice: str = \"cpu\",\noptimize_step: Callable = optimize_step,\nwrite_tensorboard: Callable = write_tensorboard,\n) -&gt; tuple[Module, Optimizer]:\n\"\"\"Runs the training loop with gradient-based optimizer\n    Assumes that `loss_fn` returns a tuple of (loss,\n    metrics: dict), where `metrics` is a dict of scalars. Loss and metrics are\n    written to tensorboard. Checkpoints are written every\n    `config.checkpoint_every` steps (and after the last training step).  If a\n    checkpoint is found at `config.folder` we resume training from there.  The\n    tensorboard logs can be viewed via `tensorboard --logdir /path/to/folder`.\n    Args:\n        model: The model to train.\n        dataloader: dataloader of different types. If None, no data is required by\n            the model\n        optimizer: The optimizer to use.\n        config: `TrainConfig` with additional training options.\n        loss_fn: Loss function returning (loss: float, metrics: dict[str, float])\n        device: String defining device to train on, pass 'cuda' for GPU.\n        optimize_step: Customizable optimization callback which is called at every iteration.=\n            The function must have the signature `optimize_step(model,\n            optimizer, loss_fn, xs, device=\"cpu\")` (see the example below).\n            Apart from the default we already supply three other optimization\n            functions `optimize_step_evo`, `optimize_step_grad_norm`, and\n            `optimize_step_inv_dirichlet`. Learn more about how to use this in\n            the [Advancded features](../../tutorials/advanced) tutorial of the\n            documentation.\n        write_tensorboard: Customizable tensorboard logging callback which is\n            called every `config.write_every` iterations. The function must have\n            the signature `write_tensorboard(writer, loss, metrics, iteration)`\n            (see the example below).\n    Example:\n    ```python exec=\"on\" source=\"material-block\"\n    from pathlib import Path\n    import torch\n    from itertools import count\n    from qadence.constructors import hamiltonian_factory, hea, feature_map\n    from qadence import chain, Parameter, QuantumCircuit, Z\n    from qadence.models import QNN\n    from qadence.ml_tools import train_with_grad, TrainConfig\n    n_qubits = 2\n    fm = feature_map(n_qubits)\n    ansatz = hea(n_qubits=n_qubits, depth=3)\n    observable = hamiltonian_factory(n_qubits, detuning = Z)\n    circuit = QuantumCircuit(n_qubits, fm, ansatz)\n    model = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\n    batch_size = 1\n    input_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\n    pred = model(input_values)\n    ## lets prepare the train routine\n    cnt = count()\n    criterion = torch.nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n    def loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n        next(cnt)\n        x, y = data[0], data[1]\n        out = model(x)\n        loss = criterion(out, y)\n        return loss, {}\n    tmp_path = Path(\"/tmp\")\n    n_epochs = 5\n    config = TrainConfig(\n        folder=tmp_path,\n        max_iter=n_epochs,\n        checkpoint_every=100,\n        write_every=100,\n        batch_size=batch_size,\n    )\n    batch_size = 25\n    x = torch.linspace(0, 1, batch_size).reshape(-1, 1)\n    y = torch.sin(x)\n    train_with_grad(model, (x, y), optimizer, config, loss_fn=loss_fn)\n    ```\n    \"\"\"\nassert loss_fn is not None, \"Provide a valid loss function\"\n# Move model to device before optimizer is loaded\nmodel = model.to(device)\n# load available checkpoint\ninit_iter = 0\nif config.folder:\nmodel, optimizer, init_iter = load_checkpoint(config.folder, model, optimizer)\nlogger.debug(f\"Loaded model and optimizer from {config.folder}\")\n# initialize tensorboard\nwriter = SummaryWriter(config.folder, purge_step=init_iter)\n## Training\nprogress = Progress(\nTextColumn(\"[progress.description]{task.description}\"),\nBarColumn(),\nTaskProgressColumn(),\nTimeRemainingColumn(elapsed_when_finished=True),\n)\nif isinstance(dataloader, (list, tuple)):\nfrom qadence.ml_tools.data import to_dataloader\nassert len(dataloader) == 2, \"Please provide exactly two torch tensors.\"\nx, y = dataloader\ndataloader = to_dataloader(x=x, y=y, batch_size=config.batch_size)\nwith progress:\ndl_iter = iter(dataloader) if isinstance(dataloader, DictDataLoader) else None\n# outer epoch loop\nfor iteration in progress.track(range(init_iter, init_iter + config.max_iter)):\ntry:\n# in case there is not data needed by the model\n# this is the case, for example, of quantum models\n# which do not have classical input data (e.g. chemistry)\nif dataloader is None:\nloss, metrics = optimize_step(\nmodel, optimizer, loss_fn, dataloader, device=device\n)\nloss = loss.item()\n# single epoch with DictDataloader using a single iteration method\n# DictDataloader returns a single sample of the data\n# with a given batch size decided when the dataloader is defined\nelif isinstance(dataloader, DictDataLoader):\n# resample all the time from the dataloader\n# by creating a fresh iterator if the dataloader\n# does not support automatically iterating datasets\nif not dataloader.has_automatic_iter:\ndl_iter = iter(dataloader)\ndata = next(dl_iter)  # type: ignore[arg-type]\nloss, metrics = optimize_step(model, optimizer, loss_fn, data, device=device)\nelif isinstance(dataloader, DataLoader):\n# single-epoch with standard DataLoader\n# otherwise a standard PyTorch DataLoader behavior\n# is assumed with optional mini-batches\nrunning_loss = 0.0\nfor i, data in enumerate(dataloader):\n# TODO: make sure to average metrics as well\nloss, metrics = optimize_step(\nmodel, optimizer, loss_fn, data, device=device\n)\nrunning_loss += loss.item()\nloss = running_loss / (i + 1)\nelse:\nraise NotImplementedError(\"Unsupported dataloader type!\")\nif iteration % config.print_every == 0 and config.verbose:\nprint_metrics(loss, metrics, iteration)\nif iteration % config.write_every == 0:\nwrite_tensorboard(writer, loss, metrics, iteration)\nif config.folder:\nif iteration % config.checkpoint_every == 0:\nwrite_checkpoint(config.folder, model, optimizer, iteration)\nexcept KeyboardInterrupt:\nprint(\"Terminating training gracefully after the current iteration.\")\nbreak\n# Final writing and checkpointing\nif config.folder:\nwrite_checkpoint(config.folder, model, optimizer, iteration)\nwrite_tensorboard(writer, loss, metrics, iteration)\nwriter.close()\nreturn model, optimizer\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.train_no_grad.train","title":"<code>train(model, dataloader, optimizer, config, loss_fn)</code>","text":"<p>Runs the training loop with a gradient-free optimizer</p> <p>Assumes that <code>loss_fn</code> returns a tuple of (loss, metrics: dict), where <code>metrics</code> is a dict of scalars. Loss and metrics are written to tensorboard. Checkpoints are written every <code>config.checkpoint_every</code> steps (and after the last training step).  If a checkpoint is found at <code>config.folder</code> we resume training from there.  The tensorboard logs can be viewed via <code>tensorboard --logdir /path/to/folder</code>.</p> PARAMETER  DESCRIPTION <code>model</code> <p>The model to train</p> <p> TYPE: <code>Module</code> </p> <code>dataloader</code> <p>Dataloader constructed via <code>dictdataloader</code></p> <p> TYPE: <code>DictDataLoader | DataLoader | None</code> </p> <code>optimizer</code> <p>The optimizer to use taken from the Nevergrad library. If this is not the case the function will raise an AssertionError</p> <p> TYPE: <code>Optimizer</code> </p> <code>loss_fn</code> <p>Loss function returning (loss: float, metrics: dict[str, float])</p> <p> TYPE: <code>Callable</code> </p> Source code in <code>qadence/ml_tools/train_no_grad.py</code> <pre><code>def train(\nmodel: Module,\ndataloader: DictDataLoader | DataLoader | None,\noptimizer: NGOptimizer,\nconfig: TrainConfig,\nloss_fn: Callable,\n) -&gt; tuple[Module, NGOptimizer]:\n\"\"\"Runs the training loop with a gradient-free optimizer\n    Assumes that `loss_fn` returns a tuple of (loss, metrics: dict), where\n    `metrics` is a dict of scalars. Loss and metrics are written to\n    tensorboard. Checkpoints are written every `config.checkpoint_every` steps\n    (and after the last training step).  If a checkpoint is found at `config.folder`\n    we resume training from there.  The tensorboard logs can be viewed via\n    `tensorboard --logdir /path/to/folder`.\n    Args:\n        model: The model to train\n        dataloader: Dataloader constructed via `dictdataloader`\n        optimizer: The optimizer to use taken from the Nevergrad library. If this is not\n            the case the function will raise an AssertionError\n        loss_fn: Loss function returning (loss: float, metrics: dict[str, float])\n    \"\"\"\ninit_iter = 0\nif config.folder:\nmodel, optimizer, init_iter = load_checkpoint(config.folder, model, optimizer)\nlogger.debug(f\"Loaded model and optimizer from {config.folder}\")\ndef _update_parameters(\ndata: Tensor | None, ng_params: ng.p.Array\n) -&gt; tuple[float, dict, ng.p.Array]:\nloss, metrics = loss_fn(model, data)  # type: ignore[misc]\noptimizer.tell(ng_params, float(loss))\nng_params = optimizer.ask()  # type: ignore [assignment]\nparams = promote_to_tensor(ng_params.value, requires_grad=False)\nset_parameters(model, params)\nreturn loss, metrics, ng_params\nassert loss_fn is not None, \"Provide a valid loss function\"\n# TODO: support also Scipy optimizers\nassert isinstance(optimizer, NGOptimizer), \"Use only optimizers from the Nevergrad library\"\n# initialize tensorboard\nwriter = SummaryWriter(config.folder, purge_step=init_iter)\n# set optimizer configuration and initial parameters\noptimizer.budget = config.max_iter\noptimizer.enable_pickling()\n# TODO: Make it GPU compatible if possible\nparams = get_parameters(model).detach().numpy()\nng_params = ng.p.Array(init=params)\n# serial training\n# TODO: Add a parallelization using the num_workers argument in Nevergrad\nprogress = Progress(\nTextColumn(\"[progress.description]{task.description}\"),\nBarColumn(),\nTaskProgressColumn(),\nTimeRemainingColumn(elapsed_when_finished=True),\n)\nwith progress:\ndl_iter = iter(dataloader) if isinstance(dataloader, DictDataLoader) else None\nfor iteration in progress.track(range(init_iter, init_iter + config.max_iter)):\nif dataloader is None:\nloss, metrics, ng_params = _update_parameters(None, ng_params)\nelif isinstance(dataloader, DictDataLoader):\n# resample all the time from the dataloader\n# by creating a fresh iterator if the dataloader\n# does not support automatically iterating datasets\nif not dataloader.has_automatic_iter:\ndl_iter = iter(dataloader)\ndata = next(dl_iter)  # type: ignore[arg-type]\nloss, metrics, ng_params = _update_parameters(data, ng_params)\nelif isinstance(dataloader, DataLoader):\n# single-epoch with standard DataLoader\n# otherwise a standard PyTorch DataLoader behavior\n# is assumed with optional mini-batches\nrunning_loss = 0.0\nfor i, data in enumerate(dataloader):\nloss, metrics, ng_params = _update_parameters(data, ng_params)\nrunning_loss += loss\nloss = running_loss / (i + 1)\nelse:\nraise NotImplementedError(\"Unsupported dataloader type!\")\nif iteration % config.print_every == 0 and config.verbose:\nprint_metrics(loss, metrics, iteration)\nif iteration % config.write_every == 0:\nwrite_tensorboard(writer, loss, metrics, iteration)\nif config.folder:\nif iteration % config.checkpoint_every == 0:\nwrite_checkpoint(config.folder, model, optimizer, iteration)\nif iteration &gt;= init_iter + config.max_iter:\nbreak\n## Final writing and stuff\nif config.folder:\nwrite_checkpoint(config.folder, model, optimizer, iteration)\nwrite_tensorboard(writer, loss, metrics, iteration)\nwriter.close()\nreturn model, optimizer\n</code></pre>"},{"location":"qadence/operations/","title":"Operations","text":"<p>Operations are common <code>PrimitiveBlocks</code>, these are often called gates elsewhere.</p>"},{"location":"qadence/operations/#constant-blocks","title":"Constant blocks","text":"<p>CY gate not implemented</p>"},{"location":"qadence/operations/#qadence.operations.X","title":"<code>X(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The X gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.Y","title":"<code>Y(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Y gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.Z","title":"<code>Z(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Z gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.I","title":"<code>I(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The identity gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.H","title":"<code>H(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Hadamard or H gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = (1 / np.sqrt(2)) * (X(target) + Z(target) - np.sqrt(2) * I(target))\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.S","title":"<code>S(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The S / Phase gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.SDagger","title":"<code>SDagger(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Hermitian adjoint/conjugate transpose of the S / Phase gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.SWAP","title":"<code>SWAP(control, target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The SWAP gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, control: int, target: int) -&gt; None:\na11 = 0.5 * (Z(control) - I(control))\na22 = -0.5 * (Z(target) + I(target))\na12 = 0.5 * (chain(X(control), Z(control)) + X(control))\na21 = 0.5 * (chain(Z(target), X(target)) + X(target))\nself.generator = (\nkron(-1.0 * a22, a11) + kron(-1.0 * a11, a22) + kron(a12, a21) + kron(a21, a12)\n)\nsuper().__init__((control, target))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.T","title":"<code>T(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The T gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.TDagger","title":"<code>TDagger(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Hermitian adjoint/conjugate transpose of the T gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CNOT","title":"<code>CNOT(control, target)</code>","text":"<p>             Bases: <code>ControlBlock</code></p> <p>The CNot, or CX, gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, control: int, target: int) -&gt; None:\nself.generator = kron((I(control) - Z(control)) * 0.5, X(target) - I(target))\nsuper().__init__((control,), X(target))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CZ","title":"<code>CZ(control, target)</code>","text":"<p>             Bases: <code>MCZ</code></p> <p>The CZ gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, control: int, target: int) -&gt; None:\nsuper().__init__((control,), target)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CPHASE","title":"<code>CPHASE(control, target, parameter)</code>","text":"<p>             Bases: <code>MCPHASE</code></p> <p>The CPHASE gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ncontrol: int,\ntarget: int,\nparameter: Parameter | TNumber | sympy.Expr | str,\n):\nsuper().__init__((control,), target, parameter)\n</code></pre>"},{"location":"qadence/operations/#parametrized-blocks","title":"Parametrized blocks","text":""},{"location":"qadence/operations/#qadence.operations.RX","title":"<code>RX(target, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The Rx gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TParameter | ParamMap):\n# TODO: should we give them more meaningful names? like 'angle'?\nself.parameters = (\nparameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n)\nself.generator = X(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.RY","title":"<code>RY(target, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The Ry gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TParameter | ParamMap):\nself.parameters = (\nparameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n)\nself.generator = Y(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.RZ","title":"<code>RZ(target, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The Rz gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TParameter | ParamMap):\nself.parameters = (\nparameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n)\nself.generator = Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CRX","title":"<code>CRX(control, target, parameter)</code>","text":"<p>             Bases: <code>MCRX</code></p> <p>The CRX gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ncontrol: int,\ntarget: int,\nparameter: Parameter | TNumber | sympy.Expr | str,\n):\nsuper().__init__((control,), target, parameter)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CRY","title":"<code>CRY(control, target, parameter)</code>","text":"<p>             Bases: <code>MCRY</code></p> <p>The CRY gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ncontrol: int,\ntarget: int,\nparameter: Parameter | TNumber | sympy.Expr | str,\n):\nsuper().__init__((control,), target, parameter)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CRZ","title":"<code>CRZ(control, target, parameter)</code>","text":"<p>             Bases: <code>MCRZ</code></p> <p>The CRZ gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ncontrol: int,\ntarget: int,\nparameter: Parameter | TNumber | sympy.Expr | str,\n):\nsuper().__init__((control,), target, parameter)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.PHASE","title":"<code>PHASE(target, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The Parametric Phase / S gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TNumber | sympy.Expr | str):\nself.parameters = ParamMap(parameter=parameter)\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#hamiltonian-evolution","title":"Hamiltonian Evolution","text":"<p>AnalogSWAP should be turned into a proper analog block</p>"},{"location":"qadence/operations/#qadence.operations.HamEvo","title":"<code>HamEvo(generator, parameter, qubit_support=None)</code>","text":"<p>             Bases: <code>TimeEvolutionBlock</code></p> A block implementing the Hamiltonian evolution operation H where <p>H = exp(-iG, t)</p> <p>where G represents a square generator and t represents the time parameter which can be parametrized.</p> PARAMETER  DESCRIPTION <code>generator</code> <p>Either a AbstractBlock, torch.Tensor or numpy.ndarray.</p> <p> TYPE: <code>Union[TGenerator, AbstractBlock]</code> </p> <code>parameter</code> <p>A scalar or vector of numeric or torch.Tensor type.</p> <p> TYPE: <code>TParameter</code> </p> <code>qubit_support</code> <p>The qubits on which the evolution will be performed on.</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>from qadence import RX, HamEvo, run\nimport torch\nhevo = HamEvo(generator=RX(0, torch.pi), parameter=torch.rand(2))\nprint(run(hevo))\n# Now lets use a torch.Tensor as a generator, Now we have to pass the support\ngen = torch.rand(2,2, dtype=torch.complex128)\nhevo = HamEvo(generator=gen, parameter=torch.rand(2), qubit_support=(0,))\nprint(run(hevo))\n</code></pre> <pre><code>tensor([[ 1.2374-5.1225e-17j, -0.7288+3.0170e-17j],\n[ 1.1660-4.0583e-17j, -0.5995+2.0868e-17j]])\ntensor([[1.7414-1.2075j, 0.7742-1.1094j],\n[1.3634-0.3266j, 0.4083-0.2874j]])\n</code></pre> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ngenerator: Union[TGenerator, AbstractBlock],\nparameter: TParameter,\nqubit_support: tuple[int, ...] = None,\n):\ngen_exprs = {}\nif qubit_support is None and not isinstance(generator, AbstractBlock):\nraise ValueError(\"You have to supply a qubit support for non-block generators.\")\nsuper().__init__(qubit_support if qubit_support else generator.qubit_support)\nif isinstance(generator, AbstractBlock):\nqubit_support = generator.qubit_support\nif generator.is_parametric:\ngen_exprs = {str(e): e for e in expressions(generator)}\nelif isinstance(generator, torch.Tensor):\nmsg = \"Please provide a square generator.\"\nif len(generator.shape) == 2:\nassert generator.shape[0] == generator.shape[1], msg\nelif len(generator.shape) == 3:\nassert generator.shape[1] == generator.shape[2], msg\nassert generator.shape[0] == 1, \"Qadence doesnt support batched generators.\"\nelse:\nraise TypeError(\n\"Only 2D or 3D generators are supported.\\\n                            In case of a 3D generator, the batch dim\\\n                            is expected to be at dim 0.\"\n)\ngen_exprs = {str(generator.__hash__()): generator}\nelif isinstance(generator, (sympy.Basic, sympy.Array)):\ngen_exprs = {str(generator): generator}\nelse:\nraise TypeError(\nf\"Generator of type {type(generator)} not supported.\\\n                        If you're using a numpy.ndarray, please cast it to a torch tensor.\"\n)\nps = {\"parameter\": Parameter(parameter), **gen_exprs}\nself.parameters = ParamMap(**ps)\nself.generator = generator\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.HamEvo.digital_decomposition","title":"<code>digital_decomposition(approximation=LTSOrder.ST4)</code>","text":"<p>Decompose the Hamiltonian evolution into digital gates</p> PARAMETER  DESCRIPTION <code>approximation</code> <p>Choose the type of decomposition. Defaults to \"st4\". Available types are: * 'basic' = apply first-order Trotter formula and decompose each term of     the exponential into digital gates. It is exact only if applied to an     operator whose terms are mutually commuting. * 'st2' = Trotter-Suzuki 2nd order formula for approximating non-commuting     Hamiltonians. * 'st4' = Trotter-Suzuki 4th order formula for approximating non-commuting     Hamiltonians.</p> <p> TYPE: <code>str</code> DEFAULT: <code>ST4</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>a block with the digital decomposition</p> <p> TYPE: <code>AbstractBlock</code> </p> Source code in <code>qadence/operations.py</code> <pre><code>def digital_decomposition(self, approximation: LTSOrder = LTSOrder.ST4) -&gt; AbstractBlock:\n\"\"\"Decompose the Hamiltonian evolution into digital gates\n    Args:\n        approximation (str, optional): Choose the type of decomposition. Defaults to \"st4\".\n            Available types are:\n            * 'basic' = apply first-order Trotter formula and decompose each term of\n                the exponential into digital gates. It is exact only if applied to an\n                operator whose terms are mutually commuting.\n            * 'st2' = Trotter-Suzuki 2nd order formula for approximating non-commuting\n                Hamiltonians.\n            * 'st4' = Trotter-Suzuki 4th order formula for approximating non-commuting\n                Hamiltonians.\n    Returns:\n        AbstractBlock: a block with the digital decomposition\n    \"\"\"\n# psi(t) = exp(-i * H * t * psi0)\n# psi(t) = exp(-i * lambda * t * psi0)\n# H = sum(Paulin) + sum(Pauli1*Pauli2)\nlogger.info(\"Quantum simulation of the time-independent Schr\u00f6dinger equation.\")\nblocks = []\n# how to change the type/dict to enum effectively\n# when there is a term including non-commuting matrices use st2 or st4\n# 1) should check that the given generator respects the constraints\n# single-qubit gates\nassert isinstance(\nself.generator, AbstractBlock\n), \"Only a generator represented as a block can be decomposed\"\nif block_is_qubit_hamiltonian(self.generator):\ntry:\nblock_is_commuting_hamiltonian(self.generator)\napproximation = LTSOrder.BASIC  # use the simpler approach if the H is commuting\nexcept TypeError:\nlogger.warning(\n\"\"\"Non-commuting terms in the Pauli operator.\n                The Suzuki-Trotter approximation is applied.\"\"\"\n)\nblocks.extend(\nlie_trotter_suzuki(\nblock=self.generator,\nparameter=self.parameters.parameter,\norder=LTSOrder[approximation],\n)\n)\n# 2) return an AbstractBlock instance with the set of gates\n# resulting from the decomposition\nreturn chain(*blocks)\nelse:\nraise NotImplementedError(\n\"The current digital decomposition can be applied only to Pauli Hamiltonians.\"\n)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.AnalogSWAP","title":"<code>AnalogSWAP(control, target, parameter=3 * np.pi / 4)</code>","text":"<p>             Bases: <code>HamEvo</code></p> <p>Single time-independent Hamiltonian evolution over a Rydberg Ising hamiltonian yielding a SWAP (up to global phase).</p> <p>Derived from Bapat et al. where it is applied to XX-type Hamiltonian</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, control: int, target: int, parameter: TParameter = 3 * np.pi / 4):\nrydberg_ising_hamiltonian_generator = (\n4.0 * kron((I(control) - Z(control)) / 2.0, (I(target) - Z(target)) / 2.0)\n+ (2.0 / 3.0) * np.sqrt(2.0) * X(control)\n+ (2.0 / 3.0) * np.sqrt(2.0) * X(target)\n+ (1.0 + np.sqrt(5.0) / 3) * Z(control)\n+ (1.0 + np.sqrt(5.0) / 3) * Z(target)\n)\nsuper().__init__(rydberg_ising_hamiltonian_generator, parameter, (control, target))\n</code></pre>"},{"location":"qadence/operations/#analog-blocks","title":"Analog blocks","text":""},{"location":"qadence/operations/#qadence.operations.AnalogRX","title":"<code>AnalogRX(angle, qubit_support='global')</code>","text":"<p>Analog X rotation. Shorthand for <code>AnalogRot</code>:</p> <pre><code>\u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\nAnalogRot(duration=t, omega=\u03a9)\n</code></pre> PARAMETER  DESCRIPTION <code>angle</code> <p>Rotation angle [rad]</p> <p> TYPE: <code>float | str | Parameter</code> </p> <code>qubit_support</code> <p>Defines the (local/global) qubit support</p> <p> TYPE: <code>str | QubitSupport | Tuple</code> DEFAULT: <code>'global'</code> </p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations.py</code> <pre><code>def AnalogRX(\nangle: float | str | Parameter,\nqubit_support: str | QubitSupport | Tuple = \"global\",\n) -&gt; ConstantAnalogRotation:\n\"\"\"Analog X rotation. Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n    ```python\n    \u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\n    AnalogRot(duration=t, omega=\u03a9)\n    ```\n    Arguments:\n        angle: Rotation angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\nreturn _analog_rot(angle, qubit_support, phase=0)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.AnalogRY","title":"<code>AnalogRY(angle, qubit_support='global')</code>","text":"<p>Analog Y rotation. Shorthand for <code>AnalogRot</code>:</p> <p><pre><code>\u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\nAnalogRot(duration=t, omega=\u03a9, phase=-\u03c0/2)\n</code></pre> Arguments:     angle: Rotation angle [rad]     qubit_support: Defines the (local/global) qubit support</p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations.py</code> <pre><code>def AnalogRY(\nangle: float | str | Parameter,\nqubit_support: str | QubitSupport | Tuple = \"global\",\n) -&gt; ConstantAnalogRotation:\n\"\"\"Analog Y rotation. Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n    ```python\n    \u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\n    AnalogRot(duration=t, omega=\u03a9, phase=-\u03c0/2)\n    ```\n    Arguments:\n        angle: Rotation angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\nreturn _analog_rot(angle, qubit_support, phase=-np.pi / 2)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.AnalogRZ","title":"<code>AnalogRZ(angle, qubit_support='global')</code>","text":"<p>Analog Z rotation. Shorthand for <code>AnalogRot</code>: <pre><code>\u03c6=2.4; \u03b4=\u03c0; t = \u03c6/\u03b4 * 100)\nAnalogRot(duration=t, delta=\u03b4, phase=\u03c0/2)\n</code></pre></p> Source code in <code>qadence/operations.py</code> <pre><code>def AnalogRZ(\nangle: float | str | Parameter,\nqubit_support: str | QubitSupport | Tuple = \"global\",\n) -&gt; ConstantAnalogRotation:\n\"\"\"Analog Z rotation. Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n    ```\n    \u03c6=2.4; \u03b4=\u03c0; t = \u03c6/\u03b4 * 100)\n    AnalogRot(duration=t, delta=\u03b4, phase=\u03c0/2)\n    ```\n    \"\"\"\nq = _cast(QubitSupport, qubit_support)\nalpha = _cast(Parameter, angle)\ndelta = np.pi\nduration = alpha / delta * 1000\nps = ParamMap(alpha=alpha, duration=duration, omega=0, delta=delta, phase=np.pi / 2)\nreturn ConstantAnalogRotation(qubit_support=q, parameters=ps)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.AnalogRot","title":"<code>AnalogRot(duration=1000.0, omega=0, delta=0, phase=0, qubit_support='global')</code>","text":"<p>General analog rotation operation.</p> PARAMETER  DESCRIPTION <code>duration</code> <p>Duration of the rotation [ns].</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>1000.0</code> </p> <code>omega</code> <p>Rotation frequency [rad/\u03bcs]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>delta</code> <p>Rotation frequency [rad/\u03bcs]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>phase</code> <p>Phase angle [rad]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>qubit_support</code> <p>Defines the (local/global) qubit support</p> <p> TYPE: <code>str | QubitSupport | Tuple</code> DEFAULT: <code>'global'</code> </p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations.py</code> <pre><code>def AnalogRot(\nduration: float | str | Parameter = 1000.0,\nomega: float | str | Parameter = 0,\ndelta: float | str | Parameter = 0,\nphase: float | str | Parameter = 0,\nqubit_support: str | QubitSupport | Tuple = \"global\",\n) -&gt; ConstantAnalogRotation:\n\"\"\"General analog rotation operation.\n    Arguments:\n        duration: Duration of the rotation [ns].\n        omega: Rotation frequency [rad/\u03bcs]\n        delta: Rotation frequency [rad/\u03bcs]\n        phase: Phase angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\nq = _cast(QubitSupport, qubit_support)\nif isinstance(duration, str):\nduration = Parameter(duration)\nalpha = duration * sympy.sqrt(omega**2 + delta**2) / 1000  # type: ignore [operator]\nps = ParamMap(alpha=alpha, duration=duration, omega=omega, delta=delta, phase=phase)\nreturn ConstantAnalogRotation(parameters=ps, qubit_support=q)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.wait","title":"<code>wait(duration, qubit_support='global')</code>","text":"<p>Constructs a <code>WaitBlock</code>.</p> PARAMETER  DESCRIPTION <code>duration</code> <p>Time to wait in nanoseconds.</p> <p> TYPE: <code>TNumber | Basic</code> </p> <code>qubit_support</code> <p>Qubits the <code>WaitBlock</code> is applied to. Can be either <code>\"global\"</code> to apply the wait block to all qubits or a tuple of integers.</p> <p> TYPE: <code>str | QubitSupport | tuple</code> DEFAULT: <code>'global'</code> </p> RETURNS DESCRIPTION <code>WaitBlock</code> <p>a <code>WaitBlock</code></p> Source code in <code>qadence/operations.py</code> <pre><code>def wait(\nduration: TNumber | sympy.Basic,\nqubit_support: str | QubitSupport | tuple = \"global\",\n) -&gt; WaitBlock:\n\"\"\"Constructs a [`WaitBlock`][qadence.blocks.analog.WaitBlock].\n    Arguments:\n        duration: Time to wait in nanoseconds.\n        qubit_support: Qubits the `WaitBlock` is applied to. Can be either\n            `\"global\"` to apply the wait block to all qubits or a tuple of integers.\n    Returns:\n        a `WaitBlock`\n    \"\"\"\nq = _cast(QubitSupport, qubit_support)\nps = ParamMap(duration=duration)\nreturn WaitBlock(parameters=ps, qubit_support=q)\n</code></pre>"},{"location":"qadence/parameters/","title":"Parameters","text":""},{"location":"qadence/parameters/#parameters","title":"Parameters","text":""},{"location":"qadence/parameters/#qadence.parameters.ParamMap","title":"<code>ParamMap(**kwargs)</code>","text":"<p>Connects UUIDs of parameters to their expressions and names. This class is not user-facing and only needed for more complex block definitions. It provides convenient access to expressions/UUIDs/names needed in different backends.</p> PARAMETER  DESCRIPTION <code>kwargs</code> <p>Parameters.</p> <p> TYPE: <code>str | TNumber | Tensor | Basic | Parameter</code> DEFAULT: <code>{}</code> </p> <p>Example: <pre><code>import sympy\nfrom qadence.parameters import ParamMap\n(x,y) = sympy.symbols(\"x y\")\nps = ParamMap(omega=2.0, duration=x+y)\nprint(f\"{ps.names() = }\")\nprint(f\"{ps.expressions() = }\")\nprint(f\"{ps.uuids() = }\")\n</code></pre> <pre><code>ps.names() = dict_keys(['omega', 'duration'])\nps.expressions() = dict_values([2.00000000000000, x + y])\nps.uuids() = dict_keys(['86a62893-817a-4963-b701-51f84ee465b3', 'e966847c-02e8-460f-bc5e-c94903d7c6f7'])\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def __init__(self, **kwargs: str | TNumber | Tensor | Basic | Parameter):\nself._name_dict: dict[str, tuple[str, Basic]] = {}\nself._uuid_dict: dict[str, str] = {}\nfor name, v in kwargs.items():\nparam = v if isinstance(v, sympy.Basic) else Parameter(v)\nuuid = str(uuid4())\nself._name_dict[name] = (uuid, param)\nself._uuid_dict[uuid] = param\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.Parameter","title":"<code>Parameter</code>","text":"<p>             Bases: <code>Symbol</code></p> <p>A wrapper on top of <code>sympy.Symbol</code> to include two additional keywords: <code>trainable</code> and <code>value</code>. This class is to define both feature parameter and variational parameters.</p>"},{"location":"qadence/parameters/#qadence.parameters.Parameter.trainable","title":"<code>trainable: bool</code>  <code>instance-attribute</code>","text":"<p>Trainable parameters are variational parameters. Non-trainable parameters are feature parameters.</p>"},{"location":"qadence/parameters/#qadence.parameters.Parameter.value","title":"<code>value: TNumber</code>  <code>instance-attribute</code>","text":"<p>(Initial) value of the parameter.</p>"},{"location":"qadence/parameters/#qadence.parameters.Parameter.__new__","title":"<code>__new__(name, **assumptions)</code>","text":"PARAMETER  DESCRIPTION <code>name</code> <p>When given a string only, the class constructs a trainable Parameter with a a randomly initialized value.</p> <p> TYPE: <code>str | TNumber | Tensor | Basic | Parameter</code> </p> <code>**assumptions</code> <p>are passed on to the parent class <code>sympy.Symbol</code>. Two new assumption kwargs are supported by this constructor: <code>trainable: bool</code>, and <code>value: TNumber</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> <p>Example: <pre><code>from qadence import Parameter, VariationalParameter\ntheta = Parameter(\"theta\")\nprint(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\nassert not theta.is_number\n# you can specify both trainable/value in the constructor\ntheta = Parameter(\"theta\", trainable=True, value=2.0)\nprint(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n# VariationalParameter/FeatureParameter are constructing\n# trainable/untrainable Parameters\ntheta = VariationalParameter(\"theta\", value=2.0)\nassert theta == Parameter(\"theta\", trainable=True, value=2.0)\n# When provided with a numeric type, Parameter constructs a sympy numeric type\":\nconstant_zero = Parameter(0)\nassert constant_zero.is_number\n# When passed a Parameter or a sympy expression, it just returns it.\nexpr = Parameter(\"x\") * Parameter(\"y\")\nprint(f\"{expr=} : {expr.free_symbols}\")\n</code></pre> <pre><code>theta: trainable=True value=0.854665659675864\ntheta: trainable=True value=2.0\nexpr=x*y : {x, y}\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def __new__(\ncls, name: str | TNumber | Tensor | Basic | Parameter, **assumptions: Any\n) -&gt; Parameter | Basic | Expr | Array:\n\"\"\"\n    Arguments:\n        name: When given a string only, the class\n            constructs a trainable Parameter with a a randomly initialized value.\n        **assumptions: are passed on to the parent class `sympy.Symbol`. Two new assumption\n            kwargs are supported by this constructor: `trainable: bool`, and `value: TNumber`.\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import Parameter, VariationalParameter\n    theta = Parameter(\"theta\")\n    print(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n    assert not theta.is_number\n    # you can specify both trainable/value in the constructor\n    theta = Parameter(\"theta\", trainable=True, value=2.0)\n    print(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n    # VariationalParameter/FeatureParameter are constructing\n    # trainable/untrainable Parameters\n    theta = VariationalParameter(\"theta\", value=2.0)\n    assert theta == Parameter(\"theta\", trainable=True, value=2.0)\n    # When provided with a numeric type, Parameter constructs a sympy numeric type\":\n    constant_zero = Parameter(0)\n    assert constant_zero.is_number\n    # When passed a Parameter or a sympy expression, it just returns it.\n    expr = Parameter(\"x\") * Parameter(\"y\")\n    print(f\"{expr=} : {expr.free_symbols}\")\n    ```\n    \"\"\"\np: Parameter\nif isinstance(name, get_args(TNumber)):\nreturn sympify(name)\nelif isinstance(name, Tensor):\nif name.numel() == 1:\nreturn sympify(name)\nelse:\nreturn Array(name.detach().numpy())\nelif isinstance(name, Parameter):\np = super().__new__(cls, name.name, **assumptions)\np.name = name.name\np.trainable = name.trainable\np.value = name.value\nreturn p\nelif isinstance(name, (Basic, Expr)):\nif name.is_number:\nreturn sympify(evaluate(name))\nreturn name\nelif isinstance(name, str):\np = super().__new__(cls, name, **assumptions)\np.trainable = assumptions.get(\"trainable\", True)\np.value = assumptions.get(\"value\", None)\nif p.value is None:\np.value = torch.rand(1).item()\nreturn p\nelse:\nraise TypeError(f\"Parameter does not support type {type(name)}\")\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.FeatureParameter","title":"<code>FeatureParameter(name, **kwargs)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=False)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def FeatureParameter(name: str, **kwargs: Any) -&gt; Parameter:\n\"\"\"Shorthand for `Parameter(..., trainable=False)`.\"\"\"\nreturn Parameter(name, trainable=False, **kwargs)\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.VariationalParameter","title":"<code>VariationalParameter(name, **kwargs)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=True)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def VariationalParameter(name: str, **kwargs: Any) -&gt; Parameter:\n\"\"\"Shorthand for `Parameter(..., trainable=True)`.\"\"\"\nreturn Parameter(name, trainable=True, **kwargs)\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.evaluate","title":"<code>evaluate(expr, values={}, as_torch=False)</code>","text":"PARAMETER  DESCRIPTION <code>expr</code> <p>An expression consisting of Parameters.</p> <p> TYPE: <code>Expr</code> </p> <code>values</code> <p>values dict which contains values for the Parameters, if empty, Parameter.value will be used.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>as_torch</code> <p>Whether to retrieve a torch-differentiable expression result.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Example: <pre><code>from qadence.parameters import Parameter, evaluate\nexpr = Parameter(\"x\") * Parameter(\"y\")\n# Unless specified, Parameter initialized random values\n# Lets evaluate this expression and see what the result is\nres = evaluate(expr)\nprint(res)\n# We can also evaluate the expr using a custom dict\nd = {\"x\": 1, \"y\":2}\nres = evaluate(expr, d)\nprint(res)\n# Lastly, if we want a differentiable result, lets put the as_torch flag\nres = evaluate(expr, d, as_torch=True)\nprint(res)\n</code></pre> <pre><code>0.013496193764961003\n2.0\ntensor([2])\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def evaluate(expr: Expr, values: dict = {}, as_torch: bool = False) -&gt; TNumber | Tensor:\n\"\"\"\n    Arguments:\n        expr: An expression consisting of Parameters.\n        values: values dict which contains values for the Parameters,\n            if empty, Parameter.value will be used.\n        as_torch: Whether to retrieve a torch-differentiable expression result.\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.parameters import Parameter, evaluate\n    expr = Parameter(\"x\") * Parameter(\"y\")\n    # Unless specified, Parameter initialized random values\n    # Lets evaluate this expression and see what the result is\n    res = evaluate(expr)\n    print(res)\n    # We can also evaluate the expr using a custom dict\n    d = {\"x\": 1, \"y\":2}\n    res = evaluate(expr, d)\n    print(res)\n    # Lastly, if we want a differentiable result, lets put the as_torch flag\n    res = evaluate(expr, d, as_torch=True)\n    print(res)\n    ```\n    \"\"\"\nres: Basic\nres_value: TNumber | Tensor\nquery: dict[Parameter, TNumber | Tensor] = {}\nif isinstance(expr, Array):\nreturn torch.Tensor(expr.tolist())\nelse:\nif not expr.is_number:\nfor s in expr.free_symbols:\nif s.name in values.keys():\nquery[s] = values[s.name]\nelif hasattr(s, \"value\"):\nquery[s] = s.value\nelse:\nraise ValueError(f\"No value provided for symbol {s.name}\")\nif as_torch:\nres_value = torchify(expr)(**{s.name: torch.tensor(v) for s, v in query.items()})\nelse:\nres = expr.subs(query)\nres_value = sympy_to_numeric(res)\nreturn res_value\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.extract_original_param_entry","title":"<code>extract_original_param_entry(param)</code>","text":"<p>Given an Expression, what was the original \"param\" given by the user? It is either going to be a numeric value, or a sympy Expression (in case a string was given, it was converted via Parameter(\"string\").</p> Source code in <code>qadence/parameters.py</code> <pre><code>def extract_original_param_entry(\nparam: Expr,\n) -&gt; TNumber | Tensor | Expr:\n\"\"\"\n    Given an Expression, what was the original \"param\" given by the user? It is either\n    going to be a numeric value, or a sympy Expression (in case a string was given,\n    it was converted via Parameter(\"string\").\n    \"\"\"\nreturn param if not param.is_number else evaluate(param)\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.torchify","title":"<code>torchify(expr)</code>","text":"PARAMETER  DESCRIPTION <code>expr</code> <p>An expression consisting of Parameters.</p> <p> TYPE: <code>Expr</code> </p> RETURNS DESCRIPTION <code>SymPyModule</code> <p>A torchified, differentiable Expression.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def torchify(expr: Expr) -&gt; SymPyModule:\n\"\"\"\n    Arguments:\n        expr: An expression consisting of Parameters.\n    Returns:\n        A torchified, differentiable Expression.\n    \"\"\"\nextra_funcs = {sympy.core.numbers.ImaginaryUnit: 1.0j}\nreturn SymPyModule(expressions=[sympy.N(expr)], extra_funcs=extra_funcs)\n</code></pre>"},{"location":"qadence/parameters/#parameter-embedding","title":"Parameter embedding","text":""},{"location":"qadence/parameters/#qadence.blocks.embedding.embedding","title":"<code>embedding(block, to_gate_params=False)</code>","text":"<p>Construct embedding function which maps user-facing parameters to either expression-level parameters or gate-level parameters. The construced embedding function has the signature:</p> <pre><code> embedding_fn(params: StrTensorDict, inputs: StrTensorDict) -&gt; StrTensorDict:\n</code></pre> <p>which means that it maps the variational parameter dict <code>params</code> and the feature parameter dict <code>inputs</code> to one new parameter dict <code>embedded_dict</code> which holds all parameters that are needed to execute a circuit on a given backend. There are two different modes for this mapping:</p> <ul> <li>Expression-level parameters: For AD-based optimization. For every unique expression we end   up with one entry in the embedded dict:   <code>len(embedded_dict) == len(unique_parameter_expressions)</code>.</li> <li>Gate-level parameters: For PSR-based optimization or real devices. One parameter for each   gate parameter, regardless if they are based on the same expression. <code>len(embedded_dict) ==   len(parametric_gates)</code>. This is needed because PSR requires to shift the angles of every   gate where the same parameter appears.</li> </ul> PARAMETER  DESCRIPTION <code>block</code> <p>parametrized block into which we want to embed parameters.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>to_gate_params</code> <p>A boolean flag whether to generate gate-level parameters or expression-level parameters.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>tuple[StrTensorDict, Callable[[StrTensorDict, StrTensorDict], StrTensorDict]]</code> <p>A tuple with variational parameter dict and the embedding function.</p> Source code in <code>qadence/blocks/embedding.py</code> <pre><code>def embedding(\nblock: AbstractBlock, to_gate_params: bool = False\n) -&gt; tuple[StrTensorDict, Callable[[StrTensorDict, StrTensorDict], StrTensorDict],]:\n\"\"\"Construct embedding function which maps user-facing parameters to either *expression-level*\n    parameters or *gate-level* parameters. The construced embedding function has the signature:\n         embedding_fn(params: StrTensorDict, inputs: StrTensorDict) -&gt; StrTensorDict:\n    which means that it maps the *variational* parameter dict `params` and the *feature* parameter\n    dict `inputs` to one new parameter dict `embedded_dict` which holds all parameters that are\n    needed to execute a circuit on a given backend. There are two different *modes* for this\n    mapping:\n    - *Expression-level* parameters: For AD-based optimization. For every unique expression we end\n      up with one entry in the embedded dict:\n      `len(embedded_dict) == len(unique_parameter_expressions)`.\n    - *Gate-level* parameters: For PSR-based optimization or real devices. One parameter for each\n      gate parameter, regardless if they are based on the same expression. `len(embedded_dict) ==\n      len(parametric_gates)`. This is needed because PSR requires to shift the angles of **every**\n      gate where the same parameter appears.\n    Arguments:\n        block: parametrized block into which we want to embed parameters.\n        to_gate_params: A boolean flag whether to generate gate-level parameters or\n            expression-level parameters.\n    Returns:\n        A tuple with variational parameter dict and the embedding function.\n    \"\"\"\nunique_expressions = unique(expressions(block))\nunique_symbols = [p for p in unique(parameters(block)) if not isinstance(p, sympy.Array)]\nunique_const_matrices = [e for e in unique_expressions if isinstance(e, sympy.Array)]\nunique_expressions = [e for e in unique_expressions if not isinstance(e, sympy.Array)]\n# NOTE\n# there are 3 kinds of parameters in qadence\n# - non-trainable which are considered as inputs for classical data\n# - trainable which are the variational parameters to be optimized\n# - fixed: which are non-trainable parameters with fixed value (e.g. pi/2)\n#\n# both non-trainable and trainable parameters can have the same element applied\n# to different operations in the quantum circuit, e.g. assigning the same parameter\n# to multiple gates.\nnon_numeric_symbols = [p for p in unique_symbols if not p.is_number]\ntrainable_symbols = [p for p in non_numeric_symbols if p.trainable]\nconstant_expressions = [expr for expr in unique_expressions if expr.is_number]\n# we dont need to care about constant symbols if they are contained in an symbolic expression\n# we only care about gate params which are ONLY a constant\nembeddings: dict[sympy.Expr, sympytorch.SymPyModule] = {\nexpr: torchify(expr) for expr in unique_expressions if not expr.is_number\n}\nuuid_to_expr = uuid_to_expression(block)\ndef embedding_fn(params: StrTensorDict, inputs: StrTensorDict) -&gt; StrTensorDict:\nembedded_params: dict[sympy.Expr, Tensor] = {}\nfor expr, fn in embeddings.items():\nangle: Tensor\nvalues = {}\nfor symbol in expr.free_symbols:\nif symbol.name in inputs:\nvalue = inputs[symbol.name]\nelif symbol.name in params:\nvalue = params[symbol.name]\nelse:\nmsg_trainable = \"Trainable\" if symbol.trainable else \"Non-trainable\"\nraise KeyError(\nf\"{msg_trainable} parameter '{symbol.name}' not found in the \"\nf\"inputs list: {list(inputs.keys())} nor the \"\nf\"params list: {list(params.keys())}.\"\n)\nvalues[symbol.name] = value\nangle = fn(**values)\n# do not reshape parameters which are multi-dimensional\n# tensors, such as for example generator matrices\nif not len(angle.squeeze().shape) &gt; 1:\nangle = angle.reshape(-1)\nembedded_params[expr] = angle\nfor e in constant_expressions + unique_const_matrices:\nembedded_params[e] = params[stringify(e)]\nif to_gate_params:\ngate_lvl_params: StrTensorDict = {}\nfor uuid, e in uuid_to_expr.items():\ngate_lvl_params[uuid] = embedded_params[e]\nreturn gate_lvl_params\nelse:\nreturn {stringify(k): v for k, v in embedded_params.items()}\nparams: StrTensorDict\nparams = {p.name: torch.tensor([p.value], requires_grad=True) for p in trainable_symbols}\nparams.update(\n{\nstringify(expr): torch.tensor([evaluate(expr)], requires_grad=False)\nfor expr in constant_expressions\n}\n)\nparams.update(\n{\nstringify(expr): torch.tensor(\nnp.array(expr.tolist(), dtype=np.cdouble), requires_grad=False\n)\nfor expr in unique_const_matrices\n}\n)\nreturn params, embedding_fn\n</code></pre>"},{"location":"qadence/quantumcircuit/","title":"QuantumCircuit","text":""},{"location":"qadence/quantumcircuit/#quantumcircuit","title":"QuantumCircuit","text":"<p>The abstract <code>QuantumCircuit</code> is the key object in Qadence, as it is what can be executed.</p>"},{"location":"qadence/quantumcircuit/#qadence.circuit.QuantumCircuit","title":"<code>QuantumCircuit(support, *blocks)</code>  <code>dataclass</code>","text":"<p>A QuantumCircuit instance is completely abstract and it needs to be passed to a quantum backend in order to be executed.</p> PARAMETER  DESCRIPTION <code>support</code> <p><code>Register</code> or number of qubits. If an integer is provided, a register is constructed with <code>Register.all_to_all(x)</code></p> <p> TYPE: <code>int | Register</code> </p> <code>*blocks</code> <p>(Possibly multiple) blocks to construct the circuit from.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>()</code> </p> Source code in <code>qadence/circuit.py</code> <pre><code>def __init__(self, support: int | Register, *blocks: AbstractBlock):\n\"\"\"\n    Arguments:\n        support: `Register` or number of qubits. If an integer is provided, a register is\n            constructed with `Register.all_to_all(x)`\n        *blocks: (Possibly multiple) blocks to construct the circuit from.\n    \"\"\"\nself.block = chain(*blocks) if len(blocks) != 1 else blocks[0]\nself.register = Register(support) if isinstance(support, int) else support\nglobal_block = isinstance(self.block, AnalogBlock) and self.block.qubit_support.is_global\nif not global_block and len(self.block) and self.block.n_qubits &gt; self.register.n_qubits:\nraise ValueError(\nf\"Register with {self.register.n_qubits} qubits is too small for the \"\nf\"given block with {self.block.n_qubits} qubits\"\n)\n</code></pre>"},{"location":"qadence/quantumcircuit/#qadence.circuit.QuantumCircuit.unique_parameters","title":"<code>unique_parameters: list[Parameter]</code>  <code>property</code>","text":"<p>Return the unique parameters in the circuit</p> <p>These parameters are the actual user-facing parameters which can be assigned by the user. Multiple gates can contain the same unique parameter</p> RETURNS DESCRIPTION <code>list[Parameter]</code> <p>list[Parameter]: List of unique parameters in the circuit</p>"},{"location":"qadence/quantumcircuit/#qadence.circuit.QuantumCircuit.dagger","title":"<code>dagger()</code>","text":"<p>Reverse the QuantumCircuit by calling dagger on the block.</p> Source code in <code>qadence/circuit.py</code> <pre><code>def dagger(self) -&gt; QuantumCircuit:\n\"\"\"Reverse the QuantumCircuit by calling dagger on the block.\"\"\"\nreturn QuantumCircuit(self.n_qubits, self.block.dagger())\n</code></pre>"},{"location":"qadence/quantumcircuit/#qadence.circuit.QuantumCircuit.get_blocks_by_tag","title":"<code>get_blocks_by_tag(tag)</code>","text":"<p>Extract one or more blocks using the human-readable tag</p> <p>This function recursively explores all composite blocks to find all the occurrences of a certain tag in the blocks.</p> PARAMETER  DESCRIPTION <code>tag</code> <p>the tag to look for</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>list[AbstractBlock]</code> <p>list[AbstractBlock]: The block(s) corresponding to the given tag</p> Source code in <code>qadence/circuit.py</code> <pre><code>def get_blocks_by_tag(self, tag: str) -&gt; list[AbstractBlock]:\n\"\"\"Extract one or more blocks using the human-readable tag\n    This function recursively explores all composite blocks to find\n    all the occurrences of a certain tag in the blocks.\n    Args:\n        tag (str): the tag to look for\n    Returns:\n        list[AbstractBlock]: The block(s) corresponding to the given tag\n    \"\"\"\ndef _get_block(block: AbstractBlock) -&gt; list[AbstractBlock]:\nblocks = []\nif block.tag == tag:\nblocks += [block]\nif isinstance(block, CompositeBlock):\nblocks += flatten(*[_get_block(b) for b in block.blocks])\nreturn blocks\nreturn _get_block(self.block)\n</code></pre>"},{"location":"qadence/quantumcircuit/#qadence.circuit.QuantumCircuit.parameters","title":"<code>parameters()</code>","text":"<p>Extract all parameters for primitive blocks in the circuit</p> <p>Notice that this function returns all the unique Parameters used in the quantum circuit. These can correspond to constants too.</p> RETURNS DESCRIPTION <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>List[tuple[Parameter]]: A list of tuples containing the Parameter</p> <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>instance of each of the primitive blocks in the circuit or, if the <code>flatten</code></p> <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>flag is set to True, a flattened list of all circuit parameters</p> Source code in <code>qadence/circuit.py</code> <pre><code>def parameters(self) -&gt; list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]:\n\"\"\"Extract all parameters for primitive blocks in the circuit\n    Notice that this function returns all the unique Parameters used\n    in the quantum circuit. These can correspond to constants too.\n    Returns:\n        List[tuple[Parameter]]: A list of tuples containing the Parameter\n        instance of each of the primitive blocks in the circuit or, if the `flatten`\n        flag is set to True, a flattened list of all circuit parameters\n    \"\"\"\nreturn parameters(self.block)\n</code></pre>"},{"location":"qadence/register/","title":"Register","text":""},{"location":"qadence/register/#quantum-registers","title":"Quantum Registers","text":""},{"location":"qadence/register/#qadence.register.Register","title":"<code>Register(support)</code>","text":"<p>A 2D register of qubits which includes their coordinates (needed for e.g. analog computing). The coordinates are ignored in backends that don't need them. The easiest way to construct a register is via its classmethods like <code>Register.triangular_lattice</code>.</p> PARAMETER  DESCRIPTION <code>support</code> <p>A graph or number of qubits. Nodes can include a <code>\"pos\"</code> attribute such that e.g.: <code>graph.nodes = {0: {\"pos\": (2,3)}, 1: {\"pos\": (0,0)}, ...}</code> which will be used in backends that need qubit coordinates. See the classmethods for simple construction of some predefined lattices if you don't want to build a graph manually. If you pass an integer the resulting register is the same as <code>Register.all_to_all(n_qubits)</code>.</p> <p> TYPE: <code>Graph | int</code> </p> <p>Examples: <pre><code>from qadence import Register\nreg = Register.honeycomb_lattice(2,3)\nreg.draw()\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/register.py</code> <pre><code>def __init__(self, support: nx.Graph | int):\n\"\"\"A 2D register of qubits which includes their coordinates (needed for e.g. analog\n    computing). The coordinates are ignored in backends that don't need them. The easiest\n    way to construct a register is via its classmethods like `Register.triangular_lattice`.\n    Arguments:\n        support: A graph or number of qubits. Nodes can include a `\"pos\"` attribute\n            such that e.g.: `graph.nodes = {0: {\"pos\": (2,3)}, 1: {\"pos\": (0,0)}, ...}` which\n            will be used in backends that need qubit coordinates.\n            See the classmethods for simple construction of some predefined lattices if you\n            don't want to build a graph manually.\n            If you pass an integer the resulting register is the same as\n            `Register.all_to_all(n_qubits)`.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import Register\n    reg = Register.honeycomb_lattice(2,3)\n    reg.draw()\n    ```\n    \"\"\"\nself.graph = support if isinstance(support, nx.Graph) else alltoall_graph(support)\n</code></pre>"},{"location":"qadence/register/#qadence.register.line_graph","title":"<code>line_graph(n_qubits, spacing=1.0)</code>","text":"<p>Create graph representing linear lattice.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of nodes in the graph</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Graph</code> <p>graph instance</p> Source code in <code>qadence/register.py</code> <pre><code>def line_graph(n_qubits: int, spacing: float = 1.0) -&gt; nx.Graph:\n\"\"\"Create graph representing linear lattice.\n    Args:\n        n_qubits (int): number of nodes in the graph\n    Returns:\n        graph instance\n    \"\"\"\ngraph = nx.Graph()\nfor i in range(n_qubits):\ngraph.add_node(i, pos=(i * spacing, 0.0))\nfor i, j in zip(range(n_qubits - 1), range(1, n_qubits)):\ngraph.add_edge(i, j)\nreturn graph\n</code></pre>"},{"location":"qadence/serialization/","title":"Serialization","text":""},{"location":"qadence/serialization/#serialization","title":"Serialization","text":""},{"location":"qadence/serialization/#qadence.serialization.deserialize","title":"<code>deserialize(d, as_torch=False)</code>","text":"<p>Supported Types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | Module Deserializes a dict to one of the supported types.</p> PARAMETER  DESCRIPTION <code>d</code> <p>A dict containing a serialized object.</p> <p> TYPE: <code>dict</code> </p> <p>Returns:     AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register, Module.</p> <p>Examples: <pre><code>import torch\nfrom qadence import serialize, deserialize, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nblock_dict = serialize(myblock)\nprint(block_dict)\n## Lets use myblock in a QuantumCircuit and serialize it.\nqc = QuantumCircuit(n_qubits, myblock)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n## Finally, let's wrap it in a QuantumModel\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Lets check if the loaded QuantumModel returns the same expectation\nassert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n</code></pre> <pre><code>{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': 'HEA', 'blocks': [{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('14e85711-51a8-4bbb-b1bc-d0b73a480453', {'name': 'theta_0', 'expression': \"Parameter('theta_0')\", 'symbols': {'theta_0': {'name': 'theta_0', 'trainable': 'True', 'value': '0.9649102256983412'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('9b77fbdf-5886-44c8-8258-6749cb369d8a', {'name': 'theta_1', 'expression': \"Parameter('theta_1')\", 'symbols': {'theta_1': {'name': 'theta_1', 'trainable': 'True', 'value': '0.855299175233669'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RY', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('1b1b0b66-cdb3-4c99-95d0-92b71ef52b4f', {'name': 'theta_2', 'expression': \"Parameter('theta_2')\", 'symbols': {'theta_2': {'name': 'theta_2', 'trainable': 'True', 'value': '0.4821242625372467'}}})}}}, {'type': 'RY', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('fb93ba8b-298a-4a00-ac09-25ee855d7793', {'name': 'theta_3', 'expression': \"Parameter('theta_3')\", 'symbols': {'theta_3': {'name': 'theta_3', 'trainable': 'True', 'value': '0.7216139771883192'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('fa6fa739-29b5-4c79-b8ed-65f617f9b0d0', {'name': 'theta_4', 'expression': \"Parameter('theta_4')\", 'symbols': {'theta_4': {'name': 'theta_4', 'trainable': 'True', 'value': '0.5520005343296959'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('a7b0c5fb-2bd0-45d9-b474-7602c7479f89', {'name': 'theta_5', 'expression': \"Parameter('theta_5')\", 'symbols': {'theta_5': {'name': 'theta_5', 'trainable': 'True', 'value': '0.5128236248712018'}}})}}}]}]}, {'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'CNOT', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'X', 'qubit_support': (1,), 'tag': None}]}]}]}]}\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def deserialize(d: dict, as_torch: bool = False) -&gt; SUPPORTED_TYPES:\n\"\"\"\n    Supported Types:\n    AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | Module\n    Deserializes a dict to one of the supported types.\n    Arguments:\n        d (dict): A dict containing a serialized object.\n    Returns:\n        AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register, Module.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence import serialize, deserialize, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    block_dict = serialize(myblock)\n    print(block_dict)\n    ## Lets use myblock in a QuantumCircuit and serialize it.\n    qc = QuantumCircuit(n_qubits, myblock)\n    qc_dict = serialize(qc)\n    qc_deserialized = deserialize(qc_dict)\n    assert qc == qc_deserialized\n    ## Finally, let's wrap it in a QuantumModel\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    qm_dict = serialize(qm)\n    qm_deserialized = deserialize(qm_dict)\n    # Lets check if the loaded QuantumModel returns the same expectation\n    assert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n    ```\n    \"\"\"\nobj: Any\nif d.get(\"expression\"):\nexpr = eval(d[\"expression\"])\nif hasattr(expr, \"free_symbols\"):\nfor symb in expr.free_symbols:\nsymb.value = float(d[\"symbols\"][symb.name][\"value\"])\nobj = expr\nelif d.get(\"QuantumModel\"):\nobj = QuantumModel._from_dict(d, as_torch)\nelif d.get(\"QNN\"):\nobj = QNN._from_dict(d, as_torch)\nelif d.get(\"TransformedModule\"):\nobj = TransformedModule._from_dict(d, as_torch)\nelif d.get(\"block\") and d.get(\"register\"):\nobj = QuantumCircuit._from_dict(d)\nelif d.get(\"graph\"):\nobj = Register._from_dict(d)\nelif d.get(\"type\"):\nif d[\"type\"] in ALL_BLOCK_NAMES:\nblock: AbstractBlock = (\ngetattr(operations, d[\"type\"])._from_dict(d)\nif hasattr(operations, d[\"type\"])\nelse getattr(qadenceblocks, d[\"type\"])._from_dict(d)\n)\nif d[\"tag\"] is not None:\nblock = tag(block, d[\"tag\"])\nobj = block\nelse:\nimport warnings\nmsg = warnings.warn(\n\"In order to load a custom torch.nn.Module, make sure its imported in the namespace.\"\n)\ntry:\nmodule_name = list(d.keys())[0]\nobj = getattr(globals(), module_name)\nobj.load_state_dict(d[module_name])\nexcept Exception as e:\nlogger.error(\nTypeError(\nf\"{msg}. Unable to deserialize object due to {e}.\\\n                    Supported objects are: {SUPPORTED_OBJECTS}\"\n)\n)\nreturn obj\n</code></pre>"},{"location":"qadence/serialization/#qadence.serialization.load","title":"<code>load(file_path, map_location='cpu')</code>","text":"<p>Same as serialize/deserialize but for storing/loading files. Supported types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register Loads a .json or .pt file to one of the supported types.</p> PARAMETER  DESCRIPTION <code>file_path</code> <p>The name of the file.</p> <p> TYPE: <code>str</code> </p> <code>map_location</code> <p>In case of a .pt file, on which device to load the object (cpu,cuda).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> <p>Returns:     A object of type AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register.</p> <p>Examples: <pre><code>import torch\nfrom pathlib import Path\nimport os\nfrom qadence import save, load, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nqc = QuantumCircuit(n_qubits, myblock)\n# Lets store the circuit in a json file\nsave(qc, '.', 'circ')\nloaded_qc = load(Path('circ.json'))\nqc == loaded_qc\nos.remove('circ.json')\n## Let's wrap it in a QuantumModel and store that\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nsave(qm, folder= '.',file_name= 'quantum_model')\nqm_loaded = load('quantum_model.json')\nos.remove('quantum_model.json')\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def load(file_path: str | Path, map_location: str = \"cpu\") -&gt; SUPPORTED_TYPES:\n\"\"\"\n    Same as serialize/deserialize but for storing/loading files.\n    Supported types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register\n    Loads a .json or .pt file to one of the supported types.\n    Arguments:\n        file_path (str): The name of the file.\n        map_location (str): In case of a .pt file, on which device to load the object (cpu,cuda).\n    Returns:\n        A object of type AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from pathlib import Path\n    import os\n    from qadence import save, load, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    qc = QuantumCircuit(n_qubits, myblock)\n    # Lets store the circuit in a json file\n    save(qc, '.', 'circ')\n    loaded_qc = load(Path('circ.json'))\n    qc == loaded_qc\n    os.remove('circ.json')\n    ## Let's wrap it in a QuantumModel and store that\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    save(qm, folder= '.',file_name= 'quantum_model')\n    qm_loaded = load('quantum_model.json')\n    os.remove('quantum_model.json')\n    ```\n    \"\"\"\nd = {}\nif isinstance(file_path, str):\nfile_path = Path(file_path)\nif not os.path.exists(file_path):\nlogger.error(f\"File {file_path} not found.\")\nraise FileNotFoundError\nFORMAT = file_extension(file_path)\n_, _, load_fn, _ = FORMAT_DICT[FORMAT]  # type: ignore[index]\ntry:\nd = load_fn(file_path, map_location)\nlogger.debug(f\"Successfully loaded {d} from {file_path}.\")\nexcept Exception as e:\nlogger.error(f\"Unable to load Object from {file_path} due to {e}\")\nreturn deserialize(d)\n</code></pre>"},{"location":"qadence/serialization/#qadence.serialization.save","title":"<code>save(obj, folder, file_name='', format=SerializationFormat.JSON)</code>","text":"<p>Same as serialize/deserialize but for storing/loading files. Supported types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | torch.nn.Module Saves a qadence object to a json/.pt.</p> PARAMETER  DESCRIPTION <code>obj</code> <pre><code>Either AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register.\n</code></pre> <p> TYPE: <code>AbstractBlock | QuantumCircuit | QuantumModel | Register</code> </p> <code>file_name</code> <p>The name of the file.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>format</code> <p>The type of file to save.</p> <p> TYPE: <code>str</code> DEFAULT: <code>JSON</code> </p> <p>Returns:     None.</p> <p>Examples: <pre><code>import torch\nfrom pathlib import Path\nimport os\nfrom qadence import save, load, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nqc = QuantumCircuit(n_qubits, myblock)\n# Lets store the circuit in a json file\nsave(qc, '.', 'circ')\nloaded_qc = load(Path('circ.json'))\nqc == loaded_qc\nos.remove('circ.json')\n## Let's wrap it in a QuantumModel and store that\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nsave(qm, folder= '.',file_name= 'quantum_model')\nqm_loaded = load('quantum_model.json')\nos.remove('quantum_model.json')\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def save(\nobj: SUPPORTED_TYPES,\nfolder: str | Path,\nfile_name: str = \"\",\nformat: SerializationFormat = SerializationFormat.JSON,\n) -&gt; None:\n\"\"\"\n    Same as serialize/deserialize but for storing/loading files.\n    Supported types:\n    AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | torch.nn.Module\n    Saves a qadence object to a json/.pt.\n    Arguments:\n        obj (AbstractBlock | QuantumCircuit | QuantumModel | Register):\n                Either AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register.\n        file_name (str): The name of the file.\n        format (str): The type of file to save.\n    Returns:\n        None.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from pathlib import Path\n    import os\n    from qadence import save, load, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    qc = QuantumCircuit(n_qubits, myblock)\n    # Lets store the circuit in a json file\n    save(qc, '.', 'circ')\n    loaded_qc = load(Path('circ.json'))\n    qc == loaded_qc\n    os.remove('circ.json')\n    ## Let's wrap it in a QuantumModel and store that\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    save(qm, folder= '.',file_name= 'quantum_model')\n    qm_loaded = load('quantum_model.json')\n    os.remove('quantum_model.json')\n    ```\n    \"\"\"\nif not isinstance(obj, get_args(SUPPORTED_TYPES)):\nlogger.error(f\"Serialization of object type {type(obj)} not supported.\")\nfolder = Path(folder)\nif not folder.is_dir():\nlogger.error(NotADirectoryError)\nif file_name == \"\":\nfile_name = type(obj).__name__\ntry:\nsuffix, save_fn, _, save_params = FORMAT_DICT[format]\nd = serialize(obj, save_params)\nfile_path = folder / Path(file_name + suffix)\nsave_fn(d, file_path)\nlogger.debug(f\"Successfully saved {obj} from to {folder}.\")\nexcept Exception as e:\nlogger.error(f\"Unable to write {type(obj)} to disk due to {e}\")\n</code></pre>"},{"location":"qadence/serialization/#qadence.serialization.serialize","title":"<code>serialize(obj, save_params=False)</code>","text":"<p>Supported Types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | Module Serializes a qadence object to a dictionary.</p> PARAMETER  DESCRIPTION <code>obj</code> <p> TYPE: <code>AbstractBlock | QuantumCircuit | QuantumModel | Register | Module</code> </p> <p>Returns:     A dict.</p> <p>Examples: <pre><code>import torch\nfrom qadence import serialize, deserialize, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nblock_dict = serialize(myblock)\nprint(block_dict)\n## Lets use myblock in a QuantumCircuit and serialize it.\nqc = QuantumCircuit(n_qubits, myblock)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n## Finally, let's wrap it in a QuantumModel\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Lets check if the loaded QuantumModel returns the same expectation\nassert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n</code></pre> <pre><code>{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': 'HEA', 'blocks': [{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('5fa5db85-016d-41be-bd91-c1ee82413d16', {'name': 'theta_0', 'expression': \"Parameter('theta_0')\", 'symbols': {'theta_0': {'name': 'theta_0', 'trainable': 'True', 'value': '0.7262773469971591'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('2e57a24e-f337-4818-b7dc-33e8f7691f6d', {'name': 'theta_1', 'expression': \"Parameter('theta_1')\", 'symbols': {'theta_1': {'name': 'theta_1', 'trainable': 'True', 'value': '0.9592730319839947'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RY', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('1afecf68-80a2-4569-991b-d7825a7f3c22', {'name': 'theta_2', 'expression': \"Parameter('theta_2')\", 'symbols': {'theta_2': {'name': 'theta_2', 'trainable': 'True', 'value': '0.29853362350562773'}}})}}}, {'type': 'RY', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('a928f434-4e6d-4164-a0e2-e7673601f0c5', {'name': 'theta_3', 'expression': \"Parameter('theta_3')\", 'symbols': {'theta_3': {'name': 'theta_3', 'trainable': 'True', 'value': '0.8358036266838368'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('6a228197-0d02-490d-b1bc-6412cc562f49', {'name': 'theta_4', 'expression': \"Parameter('theta_4')\", 'symbols': {'theta_4': {'name': 'theta_4', 'trainable': 'True', 'value': '0.5395678859265043'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('5377fd18-e81d-489a-a0bf-23923166e684', {'name': 'theta_5', 'expression': \"Parameter('theta_5')\", 'symbols': {'theta_5': {'name': 'theta_5', 'trainable': 'True', 'value': '0.3978401946895035'}}})}}}]}]}, {'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'CNOT', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'X', 'qubit_support': (1,), 'tag': None}]}]}]}]}\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def serialize(obj: SUPPORTED_TYPES, save_params: bool = False) -&gt; dict:\n\"\"\"\n    Supported Types:\n    AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | Module\n    Serializes a qadence object to a dictionary.\n    Arguments:\n        obj (AbstractBlock | QuantumCircuit | QuantumModel | Register | Module):\n    Returns:\n        A dict.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence import serialize, deserialize, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    block_dict = serialize(myblock)\n    print(block_dict)\n    ## Lets use myblock in a QuantumCircuit and serialize it.\n    qc = QuantumCircuit(n_qubits, myblock)\n    qc_dict = serialize(qc)\n    qc_deserialized = deserialize(qc_dict)\n    assert qc == qc_deserialized\n    ## Finally, let's wrap it in a QuantumModel\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    qm_dict = serialize(qm)\n    qm_deserialized = deserialize(qm_dict)\n    # Lets check if the loaded QuantumModel returns the same expectation\n    assert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n    ```\n    \"\"\"\nif not isinstance(obj, get_args(SUPPORTED_TYPES)):\nlogger.error(TypeError(f\"Serialization of object type {type(obj)} not supported.\"))\nd: dict = {}\ntry:\nif isinstance(obj, Expr):\nsymb_dict = {}\nexpr_dict = {\"name\": str(obj), \"expression\": srepr(obj)}\nsymbs: set[Parameter | Basic] = obj.free_symbols\nif symbs:\nsymb_dict = {\"symbols\": {str(s): s._to_dict() for s in symbs}}\nd = {**expr_dict, **symb_dict}\nelif isinstance(obj, (QuantumModel, QNN, TransformedModule)):\nd = obj._to_dict(save_params)\nelif isinstance(obj, torch.nn.Module):\nd = {type(obj).__name__: obj.state_dict()}\nelse:\nd = obj._to_dict()\nexcept Exception as e:\nlogger.error(f\"Serialization of object {obj} failed due to {e}\")\nreturn d\n</code></pre>"},{"location":"qadence/states/","title":"State preparation","text":""},{"location":"qadence/states/#state-preparation-routines","title":"State Preparation Routines","text":""},{"location":"qadence/states/#qadence.states.ghz_block","title":"<code>ghz_block(n_qubits)</code>","text":"<p>Generates the abstract ghz state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>A ChainBlock representing the GHZ state.</p> <p>Examples: <pre><code>from qadence.states import ghz_block\nblock = ghz_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 ChainBlock(0,1)\n\u2514\u2500\u2500 CNOT(0,1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def ghz_block(n_qubits: int) -&gt; ChainBlock:\n\"\"\"\n    Generates the abstract ghz state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A ChainBlock representing the GHZ state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import ghz_block\n    block = ghz_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\ncnots = chain(CNOT(i - 1, i) for i in range(1, n_qubits))\nreturn chain(H(0), cnots)\n</code></pre>"},{"location":"qadence/states/#qadence.states.ghz_state","title":"<code>ghz_state(n_qubits, batch_size=1)</code>","text":"<p>Creates a GHZ state.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>How many bitstrings to use.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import ghz_state\nprint(ghz_state(n_qubits=2, batch_size=2))\n</code></pre> <pre><code>tensor([[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j],\n[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def ghz_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Creates a GHZ state.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): How many bitstrings to use.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import ghz_state\n    print(ghz_state(n_qubits=2, batch_size=2))\n    ```\n    \"\"\"\nnorm = 1 / torch.sqrt(torch.tensor(2))\nreturn norm * (zero_state(n_qubits, batch_size) + one_state(n_qubits, batch_size))\n</code></pre>"},{"location":"qadence/states/#qadence.states.is_normalized","title":"<code>is_normalized(wf, atol=NORMALIZATION_ATOL)</code>","text":"<p>Checks if a wave function is normalized.</p> PARAMETER  DESCRIPTION <code>wf</code> <p>The wave function as a torch tensor.</p> <p> TYPE: <code>Tensor</code> </p> <code>atol</code> <p>The tolerance.</p> <p> TYPE: <code>float) </code> DEFAULT: <code>NORMALIZATION_ATOL</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>A bool.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, is_normalized\nprint(is_normalized(uniform_state(2)))\n</code></pre> <pre><code>True\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def is_normalized(wf: Tensor, atol: float = NORMALIZATION_ATOL) -&gt; bool:\n\"\"\"\n    Checks if a wave function is normalized.\n    Arguments:\n        wf (torch.Tensor): The wave function as a torch tensor.\n        atol (float) : The tolerance.\n    Returns:\n        A bool.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, is_normalized\n    print(is_normalized(uniform_state(2)))\n    ```\n    \"\"\"\nif wf.dim() == 1:\nwf = wf.unsqueeze(0)\nsum_probs: Tensor = (wf.abs() ** 2).sum(dim=1)\nones = torch.ones_like(sum_probs)\nreturn torch.allclose(sum_probs, ones, rtol=0.0, atol=atol)  # type: ignore[no-any-return]\n</code></pre>"},{"location":"qadence/states/#qadence.states.normalize","title":"<code>normalize(wf)</code>","text":"<p>Normalizes a wavefunction or batch of wave functions.</p> PARAMETER  DESCRIPTION <code>wf</code> <p>Normalized wavefunctions.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, normalize\nprint(normalize(uniform_state(2, 2)))\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j],\n[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def normalize(wf: Tensor) -&gt; Tensor:\n\"\"\"\n    Normalizes a wavefunction or batch of wave functions.\n    Arguments:\n        wf (torch.Tensor): Normalized wavefunctions.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, normalize\n    print(normalize(uniform_state(2, 2)))\n    ```\n    \"\"\"\nif wf.dim() == 1:\nreturn wf / torch.sqrt((wf.abs() ** 2).sum())\nelse:\nreturn wf / torch.sqrt((wf.abs() ** 2).sum(1)).unsqueeze(1)\n</code></pre>"},{"location":"qadence/states/#qadence.states.one_block","title":"<code>one_block(n_qubits)</code>","text":"<p>Generates the abstract one state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the one state.</p> <p>Examples: <pre><code>from qadence.states import one_block\nblock = one_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def one_block(n_qubits: int) -&gt; KronBlock:\n\"\"\"\n    Generates the abstract one state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A KronBlock representing the one state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import one_block\n    block = one_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\nreturn _from_op(X, n_qubits=n_qubits)\n</code></pre>"},{"location":"qadence/states/#qadence.states.one_state","title":"<code>one_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the one state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import one_state\nstate = one_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def one_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Generates the one state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): The batch size.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import one_state\n    state = one_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\nbitstring = \"1\" * n_qubits\nreturn _state_from_bitstring(bitstring, batch_size)\n</code></pre>"},{"location":"qadence/states/#qadence.states.pmf","title":"<code>pmf(wf)</code>","text":"<p>Converts a wave function into a torch Distribution.</p> PARAMETER  DESCRIPTION <code>wf</code> <p>The wave function as a torch tensor.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Distribution</code> <p>A torch.distributions.Distribution.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, pmf\nprint(pmf(uniform_state(2)).probs)\n</code></pre> <pre><code>tensor([[0.2500, 0.2500, 0.2500, 0.2500]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def pmf(wf: Tensor) -&gt; Distribution:\n\"\"\"\n    Converts a wave function into a torch Distribution.\n    Arguments:\n        wf (torch.Tensor): The wave function as a torch tensor.\n    Returns:\n        A torch.distributions.Distribution.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, pmf\n    print(pmf(uniform_state(2)).probs)\n    ```\n    \"\"\"\nreturn Categorical(torch.abs(torch.pow(wf, 2)))\n</code></pre>"},{"location":"qadence/states/#qadence.states.product_block","title":"<code>product_block(bitstring)</code>","text":"<p>Creates an abstract product state from a bitstring.</p> PARAMETER  DESCRIPTION <code>bitstring</code> <p>A bitstring.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the product state.</p> <p>Examples: <pre><code>from qadence.states import product_block\nprint(product_block(\"1100\"))\n</code></pre> <pre><code>KronBlock(0,1,2,3)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u251c\u2500\u2500 I(2)\n\u2514\u2500\u2500 I(3)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def product_block(bitstring: str) -&gt; KronBlock:\n\"\"\"\n    Creates an abstract product state from a bitstring.\n    Arguments:\n        bitstring (str): A bitstring.\n    Returns:\n        A KronBlock representing the product state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import product_block\n    print(product_block(\"1100\"))\n    ```\n    \"\"\"\nreturn _block_from_bitstring(bitstring)\n</code></pre>"},{"location":"qadence/states/#qadence.states.product_state","title":"<code>product_state(bitstring, batch_size=1, endianness=Endianness.BIG)</code>","text":"<p>Creates a product state from a bitstring.</p> PARAMETER  DESCRIPTION <code>bitstring</code> <p>A bitstring.</p> <p> TYPE: <code>str</code> </p> <code>batch_size</code> <p>Batch size.</p> <p> TYPE: <code>int) </code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import product_state\nprint(product_state(\"1100\"))\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>@singledispatch\ndef product_state(\nbitstring: str, batch_size: int = 1, endianness: Endianness = Endianness.BIG\n) -&gt; Tensor:\n\"\"\"\n    Creates a product state from a bitstring.\n    Arguments:\n        bitstring (str): A bitstring.\n        batch_size (int) : Batch size.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import product_state\n    print(product_state(\"1100\"))\n    ```\n    \"\"\"\nreturn _state_from_bitstring(bitstring, batch_size, endianness=endianness)\n</code></pre>"},{"location":"qadence/states/#qadence.states.rand_bitstring","title":"<code>rand_bitstring(N)</code>","text":"<p>Creates a random bistring.</p> PARAMETER  DESCRIPTION <code>N</code> <p>The length of the bitstring.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>str</code> <p>A string.</p> <p>Examples: <pre><code>from qadence.states import rand_bitstring\nprint(rand_bitstring(N=8))\n</code></pre> <pre><code>00000101\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_bitstring(N: int) -&gt; str:\n\"\"\"\n    Creates a random bistring.\n    Arguments:\n        N (int): The length of the bitstring.\n    Returns:\n        A string.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_bitstring\n    print(rand_bitstring(N=8))\n    ```\n    \"\"\"\nreturn \"\".join(str(random.randint(0, 1)) for _ in range(N))\n</code></pre>"},{"location":"qadence/states/#qadence.states.rand_product_block","title":"<code>rand_product_block(n_qubits)</code>","text":"<p>Creates a block representing a random abstract product state.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the product state.</p> <p>Examples: <pre><code>from qadence.states import rand_product_block\nprint(rand_product_block(n_qubits=2))\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 I(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_product_block(n_qubits: int) -&gt; KronBlock:\n\"\"\"\n    Creates a block representing a random abstract product state.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A KronBlock representing the product state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_product_block\n    print(rand_product_block(n_qubits=2))\n    ```\n    \"\"\"\nreturn product_block(rand_bitstring(n_qubits))\n</code></pre>"},{"location":"qadence/states/#qadence.states.rand_product_state","title":"<code>rand_product_state(n_qubits, batch_size=1)</code>","text":"<p>Creates a random product state.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>How many bitstrings to use.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import rand_product_state\nprint(rand_product_state(n_qubits=2, batch_size=2))\n</code></pre> <pre><code>tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_product_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Creates a random product state.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): How many bitstrings to use.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_product_state\n    print(rand_product_state(n_qubits=2, batch_size=2))\n    ```\n    \"\"\"\nwf_batch = torch.zeros(batch_size, 2**n_qubits, dtype=DTYPE)\nrand_pos = torch.randint(0, 2**n_qubits, (batch_size,))\nwf_batch[torch.arange(batch_size), rand_pos] = torch.tensor(1.0 + 0j, dtype=DTYPE)\nreturn wf_batch\n</code></pre>"},{"location":"qadence/states/#qadence.states.random_state","title":"<code>random_state(n_qubits, batch_size=1, backend=BackendName.PYQTORCH, type=StateGeneratorType.HAAR_MEASURE_FAST)</code>","text":"<p>Generates a random state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>backend</code> <p>The backend to use.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PYQTORCH</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>type</code> <p>StateGeneratorType.</p> <p> DEFAULT: <code>HAAR_MEASURE_FAST</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import random_state, StateGeneratorType\nfrom qadence.states import random_state, is_normalized, pmf\nfrom qadence.backend import BackendName\nfrom torch.distributions import Distribution\n### We have the following options:\nprint([g.value for g in StateGeneratorType])\nn_qubits = 2\n# The default is StateGeneratorType.HAAR_MEASURE_FAST\nstate = random_state(n_qubits=n_qubits)\nprint(state)\n### Lets initialize a state using random rotations, i.e., StateGeneratorType.RANDOM_ROTATIONS.\nrandom = random_state(n_qubits=n_qubits, type=StateGeneratorType.RANDOM_ROTATIONS)\nprint(random)\n</code></pre> <pre><code>['RandomRotations', 'HaarMeasureFast', 'HaarMeasureSlow']\ntensor([[0.3686-0.0605j, 0.2386+0.1186j, 0.0478+0.7804j, 0.0436-0.4199j]])\ntensor([[ 0.9877+0.1036j, -0.0122+0.1162j,  0.0000+0.0000j,  0.0000+0.0000j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def random_state(\nn_qubits: int,\nbatch_size: int = 1,\nbackend: str = BackendName.PYQTORCH,\ntype: StateGeneratorType = StateGeneratorType.HAAR_MEASURE_FAST,\n) -&gt; Tensor:\n\"\"\"\n    Generates a random state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        backend (str): The backend to use.\n        batch_size (int): The batch size.\n        type : StateGeneratorType.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import random_state, StateGeneratorType\n    from qadence.states import random_state, is_normalized, pmf\n    from qadence.backend import BackendName\n    from torch.distributions import Distribution\n    ### We have the following options:\n    print([g.value for g in StateGeneratorType])\n    n_qubits = 2\n    # The default is StateGeneratorType.HAAR_MEASURE_FAST\n    state = random_state(n_qubits=n_qubits)\n    print(state)\n    ### Lets initialize a state using random rotations, i.e., StateGeneratorType.RANDOM_ROTATIONS.\n    random = random_state(n_qubits=n_qubits, type=StateGeneratorType.RANDOM_ROTATIONS)\n    print(random)\n    ```\n    \"\"\"\nif type == StateGeneratorType.HAAR_MEASURE_FAST:\nstate = concat(tuple(_rand_haar_fast(n_qubits) for _ in range(batch_size)), dim=0)\nelif type == StateGeneratorType.HAAR_MEASURE_SLOW:\nstate = concat(tuple(_rand_haar_slow(n_qubits) for _ in range(batch_size)), dim=0)\nelif type == StateGeneratorType.RANDOM_ROTATIONS:\nstate = _run_state(_abstract_random_state(n_qubits, batch_size), backend)  # type: ignore\nassert all(list(map(is_normalized, state)))\nreturn state\n</code></pre>"},{"location":"qadence/states/#qadence.states.uniform_block","title":"<code>uniform_block(n_qubits)</code>","text":"<p>Generates the abstract uniform state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the uniform state.</p> <p>Examples: <pre><code>from qadence.states import uniform_block\nblock = uniform_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 H(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def uniform_block(n_qubits: int) -&gt; KronBlock:\n\"\"\"\n    Generates the abstract uniform state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A KronBlock representing the uniform state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_block\n    block = uniform_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\nreturn _from_op(H, n_qubits=n_qubits)\n</code></pre>"},{"location":"qadence/states/#qadence.states.uniform_state","title":"<code>uniform_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the uniform state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import uniform_state\nstate = uniform_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def uniform_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Generates the uniform state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): The batch size.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state\n    state = uniform_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\nnorm = 1 / torch.sqrt(torch.tensor(2**n_qubits))\nreturn norm * torch.ones(batch_size, 2**n_qubits, dtype=DTYPE)\n</code></pre>"},{"location":"qadence/states/#qadence.states.zero_block","title":"<code>zero_block(n_qubits)</code>","text":"<p>Generates the abstract zero state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the zero state.</p> <p>Examples: <pre><code>from qadence.states import zero_block\nblock = zero_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 I(0)\n\u2514\u2500\u2500 I(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def zero_block(n_qubits: int) -&gt; KronBlock:\n\"\"\"\n    Generates the abstract zero state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A KronBlock representing the zero state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import zero_block\n    block = zero_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\nreturn _from_op(I, n_qubits=n_qubits)\n</code></pre>"},{"location":"qadence/states/#qadence.states.zero_state","title":"<code>zero_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the zero state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits for which the zero state is to be generated.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size for the zero state.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import zero_state\nstate = zero_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def zero_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Generates the zero state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits for which the zero state is to be generated.\n        batch_size (int): The batch size for the zero state.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import zero_state\n    state = zero_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\nbitstring = \"0\" * n_qubits\nreturn _state_from_bitstring(bitstring, batch_size)\n</code></pre>"},{"location":"qadence/transpile/","title":"Transpilation","text":"<p>Contains functions that operate on blocks and circuits to <code>transpile</code> them to new blocks/circuits.</p>"},{"location":"qadence/transpile/#qadence.transpile.transpile.transpile","title":"<code>transpile(*fs)</code>","text":"<p><code>AbstractBlock</code> or <code>QuantumCircuit</code> transpilation. Compose functions that accept a circuit/block and returns a circuit/block.</p> PARAMETER  DESCRIPTION <code>*fs</code> <p>composable functions that either map blocks to blocks (<code>Callable[[AbstractBlock], AbstractBlock]</code>) or circuits to circuits (<code>Callable[[QuantumCircuit], QuantumCircuit]</code>).</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>Composed function.</p> <p>Examples:</p> <p>Flatten a block of nested chains and krons: <pre><code>from qadence import *\nfrom qadence.transpile import transpile, flatten, scale_primitive_blocks_only\nb = chain(2 * chain(chain(X(0), Y(0))), kron(kron(X(0), X(1))))\nprint(b)\n# both flatten and scale_primitive_blocks_only are functions that accept and\n# return a block\nt = transpile(flatten, scale_primitive_blocks_only)(b)\nprint(t)\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 [mul: 2] \u2502   \u2514\u2500\u2500 ChainBlock(0)\n\u2502       \u2514\u2500\u2500 ChainBlock(0)\n\u2502           \u251c\u2500\u2500 X(0)\n\u2502           \u2514\u2500\u2500 Y(0)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\nChainBlock(0,1)\n\u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2514\u2500\u2500 X(0)\n\u251c\u2500\u2500 Y(0)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> <p>We also proved a decorator to easily turn a function <code>Callable[[AbstractBlock], AbstractBlock]</code> into a <code>Callable[[QuantumCircuit], QuantumCircuit]</code> to be used in circuit transpilation. <pre><code>from qadence import *\nfrom qadence.transpile import transpile, blockfn_to_circfn, flatten\n# We want to pass this circuit to `transpile` instead of a block,\n# so we need functions that map from a circuit to a circuit.\ncirc = QuantumCircuit(2, chain(chain(X(0), chain(X(1)))))\n@blockfn_to_circfn\ndef fn(block):\n# un-decorated function accepts a block and returns a block\nreturn block * block\ntransp = transpile(\n# the decorated function accepts a circuit and returns a circuit\nfn,\n# already existing functions can also be decorated\nblockfn_to_circfn(flatten)\n)\nprint(transp(circ))\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 X(0)\n\u2502   \u2514\u2500\u2500 X(1)\n\u2514\u2500\u2500 ChainBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/transpile/transpile.py</code> <pre><code>def transpile(*fs: Callable) -&gt; Callable:\n\"\"\"`AbstractBlock` or `QuantumCircuit` transpilation. Compose functions that\n    accept a circuit/block and returns a circuit/block.\n    Arguments:\n        *fs: composable functions that either map blocks to blocks\n            (`Callable[[AbstractBlock], AbstractBlock]`)\n            or circuits to circuits (`Callable[[QuantumCircuit], QuantumCircuit]`).\n    Returns:\n        Composed function.\n    Examples:\n    Flatten a block of nested chains and krons:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import *\n    from qadence.transpile import transpile, flatten, scale_primitive_blocks_only\n    b = chain(2 * chain(chain(X(0), Y(0))), kron(kron(X(0), X(1))))\n    print(b)\n    print() # markdown-exec: hide\n    # both flatten and scale_primitive_blocks_only are functions that accept and\n    # return a block\n    t = transpile(flatten, scale_primitive_blocks_only)(b)\n    print(t)\n    ```\n    We also proved a decorator to easily turn a function `Callable[[AbstractBlock], AbstractBlock]`\n    into a `Callable[[QuantumCircuit], QuantumCircuit]` to be used in circuit transpilation.\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import *\n    from qadence.transpile import transpile, blockfn_to_circfn, flatten\n    # We want to pass this circuit to `transpile` instead of a block,\n    # so we need functions that map from a circuit to a circuit.\n    circ = QuantumCircuit(2, chain(chain(X(0), chain(X(1)))))\n    @blockfn_to_circfn\n    def fn(block):\n        # un-decorated function accepts a block and returns a block\n        return block * block\n    transp = transpile(\n        # the decorated function accepts a circuit and returns a circuit\n        fn,\n        # already existing functions can also be decorated\n        blockfn_to_circfn(flatten)\n    )\n    print(transp(circ))\n    ```\n    \"\"\"\nreturn lambda x: reduce(lambda acc, f: f(acc), reversed(fs), x)\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.chain_single_qubit_ops","title":"<code>chain_single_qubit_ops(block)</code>","text":"<p>Transpile a chain of krons into a kron of chains of single qubit operations.</p> <p>Examples: <pre><code>from qadence import hea\nfrom qadence.transpile.block import chain_single_qubit_ops\n# Consider a single HEA layer\nblock = hea(2,1)\nprint(block)\n# After applying chain_single_qubit_ops, we get:\nprint(chain_single_qubit_ops(block))\n</code></pre> <pre><code>ChainBlock(0,1) [tag: HEA]\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502   \u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_2']]\n\u2502   \u2502   \u2514\u2500\u2500 RY(1) [params: ['theta_3']]\n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 RX(0) [params: ['theta_4']]\n\u2502       \u2514\u2500\u2500 RX(1) [params: ['theta_5']]\n\u2514\u2500\u2500 ChainBlock(0,1)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u2514\u2500\u2500 CNOT(0,1)\nChainBlock(0,1)\n\u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u251c\u2500\u2500 ChainBlock(0)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_2']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(0) [params: ['theta_4']]\n\u2502   \u2514\u2500\u2500 ChainBlock(1)\n\u2502       \u251c\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502       \u251c\u2500\u2500 RY(1) [params: ['theta_3']]\n\u2502       \u2514\u2500\u2500 RX(1) [params: ['theta_5']]\n\u2514\u2500\u2500 ChainBlock(0,1)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u2514\u2500\u2500 CNOT(0,1)\n</code></pre></p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def chain_single_qubit_ops(block: AbstractBlock) -&gt; AbstractBlock:\n\"\"\"Transpile a chain of krons into a kron of chains of single qubit operations.\n    Examples:\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import hea\n    from qadence.transpile.block import chain_single_qubit_ops\n    # Consider a single HEA layer\n    block = hea(2,1)\n    print(block)\n    # After applying chain_single_qubit_ops, we get:\n    print(chain_single_qubit_ops(block))\n    ```\n    \"\"\"\nif is_chain_of_primitivekrons(block):\ntry:\nreturn kron(*map(lambda bs: chain(*bs), zip(*block)))  # type: ignore[misc]\nexcept Exception as e:\nlogger.debug(\nf\"Unable to transpile {block} using chain_single_qubit_ops\\\n                         due to {e}. Returning original circuit.\"\n)\nreturn block\nelif isinstance(block, CompositeBlock):\nreturn _construct(type(block), tuple(chain_single_qubit_ops(b) for b in block.blocks))\nelse:\nreturn block\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.flatten","title":"<code>flatten(block, types=[ChainBlock, KronBlock, AddBlock])</code>","text":"<p>Flattens the given types of <code>CompositeBlock</code>s if possible.</p> <p>Example: <pre><code>from qadence import chain, kron, X\nfrom qadence.transpile import flatten\nfrom qadence.blocks import ChainBlock, KronBlock, AddBlock\nx = chain(chain(chain(X(0))), kron(kron(X(0))))\n# flatten only `ChainBlock`s\nassert flatten(x, [ChainBlock]) == chain(X(0), kron(kron(X(0))))\n# flatten `ChainBlock`s and `KronBlock`s\nassert flatten(x, [ChainBlock, KronBlock]) == chain(X(0), kron(X(0)))\n# flatten `AddBlock`s (does nothing in this case)\nassert flatten(x, [AddBlock]) == x\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def flatten(block: AbstractBlock, types: list = [ChainBlock, KronBlock, AddBlock]) -&gt; AbstractBlock:\n\"\"\"Flattens the given types of `CompositeBlock`s if possible.\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import chain, kron, X\n    from qadence.transpile import flatten\n    from qadence.blocks import ChainBlock, KronBlock, AddBlock\n    x = chain(chain(chain(X(0))), kron(kron(X(0))))\n    # flatten only `ChainBlock`s\n    assert flatten(x, [ChainBlock]) == chain(X(0), kron(kron(X(0))))\n    # flatten `ChainBlock`s and `KronBlock`s\n    assert flatten(x, [ChainBlock, KronBlock]) == chain(X(0), kron(X(0)))\n    # flatten `AddBlock`s (does nothing in this case)\n    assert flatten(x, [AddBlock]) == x\n    ```\n    \"\"\"\nif isinstance(block, CompositeBlock):\ndef fn(b: AbstractBlock, T: Type) -&gt; AbstractBlock:\nreturn _construct(type(block), tuple(_flat_blocks(b, T)))\nreturn reduce(fn, types, block)  # type: ignore[arg-type]\nelif isinstance(block, ScaleBlock):\nblk = deepcopy(block)\nblk.block = flatten(block.block, types=types)\nreturn blk\nelse:\nreturn block\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.scale_primitive_blocks_only","title":"<code>scale_primitive_blocks_only(block, scale=None)</code>","text":"<p>When given a scaled CompositeBlock consisting of several PrimitiveBlocks, move the scale all the way down into the leaves of the block tree.</p> PARAMETER  DESCRIPTION <code>block</code> <p>The block to be transpiled.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>scale</code> <p>An optional scale parameter. Only to be used for recursive calls internally.</p> <p> TYPE: <code>Basic</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>A block of the same type where the scales have been moved into the subblocks.</p> <p> TYPE: <code>AbstractBlock</code> </p> <p>Examples:</p> <p>There are two different cases: <code>ChainBlock</code>s/<code>KronBlock</code>s: Only the first subblock needs to be scaled because chains/krons represent multiplications. <pre><code>from qadence import chain, X, RX\nfrom qadence.transpile import scale_primitive_blocks_only\nb = 2 * chain(X(0), RX(0, \"theta\"))\nprint(b)\n# After applying scale_primitive_blocks_only\nprint(scale_primitive_blocks_only(b))\n</code></pre> <pre><code>[mul: 2] \u2514\u2500\u2500 ChainBlock(0)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 RX(0) [params: ['theta']]\nChainBlock(0)\n\u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 RX(0) [params: ['theta']]\n</code></pre></p> <p><code>AddBlock</code>s: Consider 2 * add(X(0), RX(0, \"theta\")).  The scale needs to be added to all subblocks.  We get add(2 * X(0), 2 * RX(0, \"theta\")). <pre><code>from qadence import add, X, RX\nfrom qadence.transpile import scale_primitive_blocks_only\nb = 2 * add(X(0), RX(0, \"theta\"))\nprint(b)\n# After applying scale_primitive_blocks_only\nprint(scale_primitive_blocks_only(b))\n</code></pre> <pre><code>[mul: 2] \u2514\u2500\u2500 AddBlock(0)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 RX(0) [params: ['theta']]\nAddBlock(0)\n\u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 [mul: 2.00000000000000] \u2514\u2500\u2500 RX(0) [params: ['theta']]\n</code></pre></p> Source code in <code>qadence/transpile/block.py</code> <pre><code>@singledispatch\ndef scale_primitive_blocks_only(block: AbstractBlock, scale: sympy.Basic = None) -&gt; AbstractBlock:\n\"\"\"When given a scaled CompositeBlock consisting of several PrimitiveBlocks,\n    move the scale all the way down into the leaves of the block tree.\n    Arguments:\n        block: The block to be transpiled.\n        scale: An optional scale parameter. Only to be used for recursive calls internally.\n    Returns:\n        AbstractBlock: A block of the same type where the scales have been moved into the subblocks.\n    Examples:\n    There are two different cases:\n    `ChainBlock`s/`KronBlock`s: Only the first subblock needs to be scaled because chains/krons\n    represent multiplications.\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import chain, X, RX\n    from qadence.transpile import scale_primitive_blocks_only\n    b = 2 * chain(X(0), RX(0, \"theta\"))\n    print(b)\n    # After applying scale_primitive_blocks_only\n    print(scale_primitive_blocks_only(b))\n    ```\n    `AddBlock`s: Consider 2 * add(X(0), RX(0, \"theta\")).  The scale needs to be added to all\n    subblocks.  We get add(2 * X(0), 2 * RX(0, \"theta\")).\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import add, X, RX\n    from qadence.transpile import scale_primitive_blocks_only\n    b = 2 * add(X(0), RX(0, \"theta\"))\n    print(b)\n    # After applying scale_primitive_blocks_only\n    print(scale_primitive_blocks_only(b))\n    ```\n    \"\"\"\nraise NotImplementedError(f\"scale_primitive_blocks_only is not implemented for {type(block)}\")\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.set_trainable","title":"<code>set_trainable(blocks, value=True, inplace=True)</code>","text":"<p>Set the trainability of all parameters in a block to a given value</p> PARAMETER  DESCRIPTION <code>blocks</code> <p>Block or list of blocks for which to set the trainable attribute</p> <p> TYPE: <code>AbstractBlock | list[AbstractBlock]</code> </p> <code>value</code> <p>The value of the trainable attribute to assign to the input blocks</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>inplace</code> <p>Whether to modify the block(s) in place or not. Currently, only</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>if the <code>inplace</code> argument is set to False, the function will raise  this exception</p> RETURNS DESCRIPTION <code>AbstractBlock | list[AbstractBlock]</code> <p>AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable attribute set to the given value</p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def set_trainable(\nblocks: AbstractBlock | list[AbstractBlock], value: bool = True, inplace: bool = True\n) -&gt; AbstractBlock | list[AbstractBlock]:\n\"\"\"Set the trainability of all parameters in a block to a given value\n    Args:\n        blocks (AbstractBlock | list[AbstractBlock]): Block or list of blocks for which\n            to set the trainable attribute\n        value (bool, optional): The value of the trainable attribute to assign to the input blocks\n        inplace (bool, optional): Whether to modify the block(s) in place or not. Currently, only\n    Raises:\n        NotImplementedError: if the `inplace` argument is set to False, the function will\n            raise  this exception\n    Returns:\n        AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable\n            attribute set to the given value\n    \"\"\"\nif isinstance(blocks, AbstractBlock):\nblocks = [blocks]\nif inplace:\nfor block in blocks:\nparams: list[sympy.Basic] = parameters(block)\nfor p in params:\nif not p.is_number:\np.trainable = value\nelse:\nraise NotImplementedError(\"Not inplace set_trainable is not yet available\")\nreturn blocks if len(blocks) &gt; 1 else blocks[0]\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.validate","title":"<code>validate(block)</code>","text":"<p>Moves a block from global to local qubit numbers by adding PutBlocks and reassigning qubit locations approriately.</p>"},{"location":"qadence/transpile/#qadence.transpile.block.validate--example","title":"Example","text":"<pre><code>from qadence.blocks import chain\nfrom qadence.operations import X\nfrom qadence.transpile import validate\nx = chain(chain(X(0)), chain(X(1)))\nprint(x)\nprint(validate(x))\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 ChainBlock(0)\n\u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 ChainBlock(1)\n\u2514\u2500\u2500 X(1)\nChainBlock(0,1)\n\u251c\u2500\u2500 put on (0)\n\u2502   \u2514\u2500\u2500 ChainBlock(0)\n\u2502       \u2514\u2500\u2500 put on (0)\n\u2502           \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 put on (1)\n\u2514\u2500\u2500 ChainBlock(0)\n\u2514\u2500\u2500 put on (0)\n\u2514\u2500\u2500 X(0)\n</code></pre> Source code in <code>qadence/transpile/block.py</code> <pre><code>def validate(block: AbstractBlock) -&gt; AbstractBlock:\n\"\"\"Moves a block from global to local qubit numbers by adding PutBlocks and reassigning\n    qubit locations approriately.\n    # Example\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence.blocks import chain\n    from qadence.operations import X\n    from qadence.transpile import validate\n    x = chain(chain(X(0)), chain(X(1)))\n    print(x)\n    print(validate(x))\n    ```\n    \"\"\"\nvblock: AbstractBlock\nfrom qadence.transpile import reassign\nif isinstance(block, ControlBlock):\nvblock = deepcopy(block)\nb: AbstractBlock\n(b,) = block.blocks\nb = reassign(b, {i: i - min(b.qubit_support) for i in b.qubit_support})\nb = validate(b)\nvblock.blocks = (b,)  # type: ignore[assignment]\nelif isinstance(block, CompositeBlock):\nblocks = []\nfor b in block.blocks:\nmi, ma = min(b.qubit_support), max(b.qubit_support)\nnb = reassign(b, {i: i - min(b.qubit_support) for i in b.qubit_support})\nnb = validate(nb)\nnb = PutBlock(nb, tuple(range(mi, ma + 1)))\nblocks.append(nb)\ntry:\nvblock = _construct(type(block), tuple(blocks))\nexcept AssertionError as e:\nif str(e) == \"Make sure blocks act on distinct qubits!\":\nvblock = chain(*blocks)\nelse:\nraise e\nelif isinstance(block, PrimitiveBlock):\nvblock = deepcopy(block)\nelse:\nraise NotImplementedError\nvblock.tag = block.tag\nreturn vblock\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.emulate.add_interaction","title":"<code>add_interaction(x, *args, interaction=Interaction.NN, spacing=1.0)</code>","text":"<p>Turns blocks or circuits into (a chain of) <code>HamEvo</code> blocks including a chosen interaction term.</p> <p>This is a <code>@singledipatch</code>ed function which can be called in three ways:</p> <ul> <li>With a <code>QuantumCircuit</code> which contains all necessary information: <code>add_interaction(circuit)</code></li> <li>With a <code>Register</code> and an <code>AbstractBlock</code>: <code>add_interaction(reg, block)</code></li> <li>With an <code>AbstractBlock</code> only: <code>add_interaction(block)</code></li> </ul> <p>See the section about analog blocks for detailed information about how which types of blocks are translated.</p> PARAMETER  DESCRIPTION <code>x</code> <p>Circuit or block to be emulated. See the examples on which argument combinations are accepted.</p> <p> TYPE: <code>Register | QuantumCircuit | AbstractBlock</code> </p> <code>interaction</code> <p>Type of interaction that is added. Can also be a function that accepts a register and a list of edges that define which qubits interact (see the examples).</p> <p> TYPE: <code>Interaction | Callable</code> DEFAULT: <code>NN</code> </p> <code>spacing</code> <p>All qubit coordinates are multiplied by <code>spacing</code>.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <p>Examples: <pre><code>from qadence import QuantumCircuit, AnalogRX, add_interaction\nc = QuantumCircuit(2, AnalogRX(2.0))\ne = add_interaction(c)\n</code></pre> <pre><code>[mul: 0.0] \u2514\u2500\u2500 AddBlock(0,1)\n\u251c\u2500\u2500 AddBlock(0,1)\n\u2502   \u2514\u2500\u2500 AddBlock(0,1)\n\u2502       \u251c\u2500\u2500 [mul: 1.571] \u2502       \u2502   \u2514\u2500\u2500 AddBlock(0,1)\n\u2502       \u2502       \u251c\u2500\u2500 AddBlock(0)\n\u2502       \u2502       \u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502       \u2502       \u2502   \u2502   \u2514\u2500\u2500 X(0)\n\u2502       \u2502       \u2502   \u2514\u2500\u2500 [mul: 0.0] \u2502       \u2502       \u2502       \u2514\u2500\u2500 Y(0)\n\u2502       \u2502       \u2514\u2500\u2500 AddBlock(1)\n\u2502       \u2502           \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502       \u2502           \u2502   \u2514\u2500\u2500 X(1)\n\u2502       \u2502           \u2514\u2500\u2500 [mul: 0.0] \u2502       \u2502               \u2514\u2500\u2500 Y(1)\n\u2502       \u2514\u2500\u2500 [mul: 0.0] \u2502           \u2514\u2500\u2500 AddBlock(0,1)\n\u2502               \u251c\u2500\u2500 N(0)\n\u2502               \u2514\u2500\u2500 N(1)\n\u2514\u2500\u2500 AddBlock(0,1)\n\u2514\u2500\u2500 [mul: 865723.020] \u2514\u2500\u2500 KronBlock(0,1)\n\u251c\u2500\u2500 N(0)\n\u2514\u2500\u2500 N(1)\n</code></pre>  You can also use <code>add_interaction</code> directly on a block, but you have to provide either the <code>Register</code> or define a non-global qubit support. <pre><code>from qadence import AnalogRX, Register, add_interaction\nb = AnalogRX(2.0)\nr = Register(1)\ne = add_interaction(r, b)\n# or provide only the block with local qubit support\n# in this case the register is created via `Register(b.n_qubits)`\ne = add_interaction(AnalogRX(2.0, qubit_support=(0,)))\nprint(e.generator)\n</code></pre> <pre><code>[mul: 0.450] \u2514\u2500\u2500 AddBlock(0)\n\u2514\u2500\u2500 AddBlock(0)\n\u251c\u2500\u2500 [mul: 1.571] \u2502   \u2514\u2500\u2500 AddBlock(0)\n\u2502       \u2514\u2500\u2500 AddBlock(0)\n\u2502           \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502           \u2502   \u2514\u2500\u2500 X(0)\n\u2502           \u2514\u2500\u2500 [mul: 0.0] \u2502               \u2514\u2500\u2500 Y(0)\n\u2514\u2500\u2500 [mul: 0.0] \u2514\u2500\u2500 AddBlock(0)\n\u2514\u2500\u2500 N(0)\n[mul: 0.450] \u2514\u2500\u2500 AddBlock(0)\n\u2514\u2500\u2500 AddBlock(0)\n\u251c\u2500\u2500 [mul: 1.571] \u2502   \u2514\u2500\u2500 AddBlock(0)\n\u2502       \u2514\u2500\u2500 AddBlock(0)\n\u2502           \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502           \u2502   \u2514\u2500\u2500 X(0)\n\u2502           \u2514\u2500\u2500 [mul: 0.0] \u2502               \u2514\u2500\u2500 Y(0)\n\u2514\u2500\u2500 [mul: 0.0] \u2514\u2500\u2500 AddBlock(0)\n\u2514\u2500\u2500 N(0)\n</code></pre>  You can specify a custom <code>interaction</code> function which has to accept a <code>Register</code> and a list of <code>edges: list[tuple[int, int]]</code>: <pre><code>from qadence import AnalogRX, Register, add_interaction\nfrom qadence.transpile.emulate import ising_interaction\ndef int_fn(r: Register, pairs: list[tuple[int, int]]) -&gt; AbstractBlock:\n# do either something completely custom\n# ...\n# or e.g. change the default kwargs to `ising_interaction`\nreturn ising_interaction(r, pairs, rydberg_level=70)\nb = AnalogRX(2.0)\nr = Register(1)\ne = add_interaction(r, b, interaction=int_fn)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/transpile/emulate.py</code> <pre><code>@singledispatch\ndef add_interaction(\nx: Register | QuantumCircuit | AbstractBlock,\n*args: Any,\ninteraction: Interaction | Callable = Interaction.NN,\nspacing: float = 1.0,\n) -&gt; QuantumCircuit | AbstractBlock:\n\"\"\"Turns blocks or circuits into (a chain of) `HamEvo` blocks including a\n    chosen interaction term.\n    This is a `@singledipatch`ed function which can be called in three ways:\n    * With a `QuantumCircuit` which contains all necessary information: `add_interaction(circuit)`\n    * With a `Register` and an `AbstractBlock`: `add_interaction(reg, block)`\n    * With an `AbstractBlock` only: `add_interaction(block)`\n    See the section about [analog blocks](/digital_analog_qc/analog-basics.md) for\n    detailed information about how which types of blocks are translated.\n    Arguments:\n        x: Circuit or block to be emulated. See the examples on which argument\n            combinations are accepted.\n        interaction: Type of interaction that is added. Can also be a function that accepts a\n            register and a list of edges that define which qubits interact (see the examples).\n        spacing: All qubit coordinates are multiplied by `spacing`.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import QuantumCircuit, AnalogRX, add_interaction\n    c = QuantumCircuit(2, AnalogRX(2.0))\n    e = add_interaction(c)\n    print(str(e.block.generator)) # markdown-exec: hide\n    ```\n    You can also use `add_interaction` directly on a block, but you have to provide either\n    the `Register` or define a non-global qubit support.\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import AnalogRX, Register, add_interaction\n    b = AnalogRX(2.0)\n    r = Register(1)\n    e = add_interaction(r, b)\n    print(e.generator) # markdown-exec: hide\n    # or provide only the block with local qubit support\n    # in this case the register is created via `Register(b.n_qubits)`\n    e = add_interaction(AnalogRX(2.0, qubit_support=(0,)))\n    print(e.generator)\n    ```\n    You can specify a custom `interaction` function which has to accept a `Register` and a list\n    of `edges: list[tuple[int, int]]`:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import AnalogRX, Register, add_interaction\n    from qadence.transpile.emulate import ising_interaction\n    def int_fn(r: Register, pairs: list[tuple[int, int]]) -&gt; AbstractBlock:\n        # do either something completely custom\n        # ...\n        # or e.g. change the default kwargs to `ising_interaction`\n        return ising_interaction(r, pairs, rydberg_level=70)\n    b = AnalogRX(2.0)\n    r = Register(1)\n    e = add_interaction(r, b, interaction=int_fn)\n    ```\n    \"\"\"\nraise ValueError(f\"`add_interaction` is not implemented for {type(x)}\")\n</code></pre>"},{"location":"qadence/types/","title":"Types","text":""},{"location":"qadence/types/#qadence-types","title":"Qadence Types","text":""},{"location":"qadence/types/#qadence.types.TArray","title":"<code>TArray = Union[Iterable, torch.Tensor, np.ndarray]</code>  <code>module-attribute</code>","text":"<p>Union of common array types.</p>"},{"location":"qadence/types/#qadence.types.TGenerator","title":"<code>TGenerator = Union[torch.Tensor, sympy.Array, sympy.Basic]</code>  <code>module-attribute</code>","text":"<p>Union of torch tensors and numpy arrays.</p>"},{"location":"qadence/types/#qadence.types.TNumber","title":"<code>TNumber = Union[int, float, complex]</code>  <code>module-attribute</code>","text":"<p>Union of python number types.</p>"},{"location":"qadence/types/#qadence.types.TParameter","title":"<code>TParameter = Union[TNumber, torch.Tensor, sympy.Basic, str]</code>  <code>module-attribute</code>","text":"<p>Union of numbers, tensors, and parameter types.</p>"},{"location":"qadence/types/#qadence.types.AlgoHEvo","title":"<code>AlgoHEvo</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Hamiltonian Evolution algorithms that can be used by the backend.</p>"},{"location":"qadence/types/#qadence.types.AlgoHEvo.EIG","title":"<code>EIG = 'EIG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using Hamiltonian diagonalization.</p>"},{"location":"qadence/types/#qadence.types.AlgoHEvo.EXP","title":"<code>EXP = 'EXP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using torch.matrix_exp on the generator matrix.</p>"},{"location":"qadence/types/#qadence.types.AlgoHEvo.RK4","title":"<code>RK4 = 'RK4'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>4th order Runge-Kutta approximation.</p>"},{"location":"qadence/types/#qadence.types.BasisSet","title":"<code>BasisSet</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Basis set for feature maps.</p>"},{"location":"qadence/types/#qadence.types.BasisSet.CHEBYSHEV","title":"<code>CHEBYSHEV = 'Chebyshev'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Chebyshev polynomials of the first kind.</p>"},{"location":"qadence/types/#qadence.types.BasisSet.FOURIER","title":"<code>FOURIER = 'Fourier'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Fourier basis set.</p>"},{"location":"qadence/types/#qadence.types.Endianness","title":"<code>Endianness</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>The endianness convention to use.</p>"},{"location":"qadence/types/#qadence.types.Endianness.BIG","title":"<code>BIG = 'Big'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use Big endianness.</p>"},{"location":"qadence/types/#qadence.types.Endianness.LITTLE","title":"<code>LITTLE = 'Little'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use little endianness.</p>"},{"location":"qadence/types/#qadence.types.FigFormat","title":"<code>FigFormat</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Available output formats for exporting visualized circuits to a file.</p>"},{"location":"qadence/types/#qadence.types.FigFormat.PDF","title":"<code>PDF = 'PDF'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>PDF format.</p>"},{"location":"qadence/types/#qadence.types.FigFormat.PNG","title":"<code>PNG = 'PNG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>PNG format.</p>"},{"location":"qadence/types/#qadence.types.FigFormat.SVG","title":"<code>SVG = 'SVG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>SVG format.</p>"},{"location":"qadence/types/#qadence.types.GenDAQC","title":"<code>GenDAQC</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>The type of interaction for the DAQC transform.</p>"},{"location":"qadence/types/#qadence.types.GenDAQC.NN","title":"<code>NN = 'NN'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NN</p>"},{"location":"qadence/types/#qadence.types.GenDAQC.ZZ","title":"<code>ZZ = 'ZZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZZ</p>"},{"location":"qadence/types/#qadence.types.Interaction","title":"<code>Interaction</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Interaction types used in - <code>add_interaction</code>. - <code>hamiltonian_factory</code>.</p>"},{"location":"qadence/types/#qadence.types.Interaction.NN","title":"<code>NN = 'NN'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NN-Ising Interaction, N=(I-Z)/2</p>"},{"location":"qadence/types/#qadence.types.Interaction.XY","title":"<code>XY = 'XY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>XY Interaction</p>"},{"location":"qadence/types/#qadence.types.Interaction.XYZ","title":"<code>XYZ = 'XYZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>XYZ Interaction</p>"},{"location":"qadence/types/#qadence.types.Interaction.ZZ","title":"<code>ZZ = 'ZZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZZ-Ising Interaction</p>"},{"location":"qadence/types/#qadence.types.LTSOrder","title":"<code>LTSOrder</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Lie-Trotter-Suzuki approximation order.</p>"},{"location":"qadence/types/#qadence.types.LTSOrder.BASIC","title":"<code>BASIC = 'BASIC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Basic.</p>"},{"location":"qadence/types/#qadence.types.LTSOrder.ST2","title":"<code>ST2 = 'ST2'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ST2.</p>"},{"location":"qadence/types/#qadence.types.LTSOrder.ST4","title":"<code>ST4 = 'ST4'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ST4.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology","title":"<code>LatticeTopology</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Lattice topologies to choose from for the register.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.ALL_TO_ALL","title":"<code>ALL_TO_ALL = 'all_to_all'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>All to all- connected lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.ARBITRARY","title":"<code>ARBITRARY = 'arbitrary'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Arbitrarily-shaped lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.CIRCLE","title":"<code>CIRCLE = 'circle'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Circular lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.HONEYCOMB_LATTICE","title":"<code>HONEYCOMB_LATTICE = 'honeycomb_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Honeycomb-shaped lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.LINE","title":"<code>LINE = 'line'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Line-format lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.RECTANGULAR_LATTICE","title":"<code>RECTANGULAR_LATTICE = 'rectangular_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Rectangular-shaped lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.SQUARE","title":"<code>SQUARE = 'square'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Square lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.TRIANGULAR_LATTICE","title":"<code>TRIANGULAR_LATTICE = 'triangular_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Triangular-shaped shape.</p>"},{"location":"qadence/types/#qadence.types.OpName","title":"<code>OpName</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>A list of all available of digital-analog operations.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGENTANG","title":"<code>ANALOGENTANG = 'AnalogEntanglement'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog entanglement operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGRX","title":"<code>ANALOGRX = 'AnalogRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RX operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGRY","title":"<code>ANALOGRY = 'AnalogRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RY operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGRZ","title":"<code>ANALOGRZ = 'AnalogRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RZ operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGSWAP","title":"<code>ANALOGSWAP = 'AnalogSWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog SWAP operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.CNOT","title":"<code>CNOT = 'CNOT'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The CNOT gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CPHASE","title":"<code>CPHASE = 'CPHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The controlled PHASE gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CRX","title":"<code>CRX = 'CRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control RX gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CRY","title":"<code>CRY = 'CRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Controlled RY gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CRZ","title":"<code>CRZ = 'CRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control RZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CSWAP","title":"<code>CSWAP = 'CSWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control SWAP gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CZ","title":"<code>CZ = 'CZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The CZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.ENTANG","title":"<code>ENTANG = 'entangle'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The entanglement operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.H","title":"<code>H = 'H'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Hadamard gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.HAMEVO","title":"<code>HAMEVO = 'HamEvo'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Hamiltonian Evolution operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.I","title":"<code>I = 'I'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Identity gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCPHASE","title":"<code>MCPHASE = 'MCPHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol PHASE gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCRX","title":"<code>MCRX = 'MCRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RX gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCRY","title":"<code>MCRY = 'MCRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RY gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCRZ","title":"<code>MCRZ = 'MCRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCZ","title":"<code>MCZ = 'MCZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol CZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.N","title":"<code>N = 'N'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The N = (1/2)(I-Z) operator</p>"},{"location":"qadence/types/#qadence.types.OpName.PHASE","title":"<code>PHASE = 'PHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The PHASE gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.RX","title":"<code>RX = 'RX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RX gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.RY","title":"<code>RY = 'RY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RY gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.RZ","title":"<code>RZ = 'RZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.S","title":"<code>S = 'S'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The S gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.SDAGGER","title":"<code>SDAGGER = 'SDagger'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The S dagger gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.SWAP","title":"<code>SWAP = 'SWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The SWAP gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.T","title":"<code>T = 'T'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The T gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.TDAGGER","title":"<code>TDAGGER = 'TDagger'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The T dagger gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.TOFFOLI","title":"<code>TOFFOLI = 'Toffoli'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Toffoli gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.U","title":"<code>U = 'U'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The U gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.WAIT","title":"<code>WAIT = 'wait'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The wait operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.X","title":"<code>X = 'X'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The X gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.Y","title":"<code>Y = 'Y'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Y gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.Z","title":"<code>Z = 'Z'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Z gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.ZERO","title":"<code>ZERO = 'Zero'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The zero gate.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod","title":"<code>OverlapMethod</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Overlap Methods to choose from.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.COMPUTE_UNCOMPUTE","title":"<code>COMPUTE_UNCOMPUTE = 'compute_uncompute'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Compute-uncompute.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.EXACT","title":"<code>EXACT = 'exact'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Exact.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.HADAMARD_TEST","title":"<code>HADAMARD_TEST = 'hadamard_test'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Hadamard-test.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.JENSEN_SHANNON","title":"<code>JENSEN_SHANNON = 'jensen_shannon'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Jensen-shannon.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.SWAP_TEST","title":"<code>SWAP_TEST = 'swap_test'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Swap-test.</p>"},{"location":"qadence/types/#qadence.types.ParameterType","title":"<code>ParameterType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Parameter types available in qadence.</p>"},{"location":"qadence/types/#qadence.types.ParameterType.FEATURE","title":"<code>FEATURE = 'Feature'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>FeatureParameters act as input and are not trainable.</p>"},{"location":"qadence/types/#qadence.types.ParameterType.FIXED","title":"<code>FIXED = 'Fixed'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Fixed/ constant parameters are neither trainable nor act as input.</p>"},{"location":"qadence/types/#qadence.types.ParameterType.VARIATIONAL","title":"<code>VARIATIONAL = 'Variational'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>VariationalParameters are trainable.</p>"},{"location":"qadence/types/#qadence.types.QubitSupportType","title":"<code>QubitSupportType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Qubit support types.</p>"},{"location":"qadence/types/#qadence.types.QubitSupportType.GLOBAL","title":"<code>GLOBAL = 'global'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use global qubit support.</p>"},{"location":"qadence/types/#qadence.types.ResultType","title":"<code>ResultType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Available data types for generating certain results.</p>"},{"location":"qadence/types/#qadence.types.ResultType.NUMPY","title":"<code>NUMPY = 'Numpy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Numpy Array Type.</p>"},{"location":"qadence/types/#qadence.types.ResultType.STRING","title":"<code>STRING = 'String'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String Type.</p>"},{"location":"qadence/types/#qadence.types.ResultType.TORCH","title":"<code>TORCH = 'Torch'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Torch Tensor Type.</p>"},{"location":"qadence/types/#qadence.types.ReuploadScaling","title":"<code>ReuploadScaling</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Scaling for data reuploads in feature maps.</p>"},{"location":"qadence/types/#qadence.types.ReuploadScaling.CONSTANT","title":"<code>CONSTANT = 'Constant'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Constant scaling.</p>"},{"location":"qadence/types/#qadence.types.ReuploadScaling.EXP","title":"<code>EXP = 'Exponential'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Exponentially increasing scaling.</p>"},{"location":"qadence/types/#qadence.types.ReuploadScaling.TOWER","title":"<code>TOWER = 'Tower'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Linearly increasing scaling.</p>"},{"location":"qadence/types/#qadence.types.SerializationFormat","title":"<code>SerializationFormat</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Available serialization formats for circuits.</p>"},{"location":"qadence/types/#qadence.types.SerializationFormat.JSON","title":"<code>JSON = 'JSON'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Json format.</p>"},{"location":"qadence/types/#qadence.types.SerializationFormat.PT","title":"<code>PT = 'PT'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The PT format used by Torch.</p>"},{"location":"qadence/types/#qadence.types.StateGeneratorType","title":"<code>StateGeneratorType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Methods to generate random states.</p>"},{"location":"qadence/types/#qadence.types.StateGeneratorType.HAAR_MEASURE_FAST","title":"<code>HAAR_MEASURE_FAST = 'HaarMeasureFast'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>HaarMeasure.</p>"},{"location":"qadence/types/#qadence.types.StateGeneratorType.HAAR_MEASURE_SLOW","title":"<code>HAAR_MEASURE_SLOW = 'HaarMeasureSlow'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>HaarMeasure non-optimized version.</p>"},{"location":"qadence/types/#qadence.types.StateGeneratorType.RANDOM_ROTATIONS","title":"<code>RANDOM_ROTATIONS = 'RandomRotations'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Random Rotations.</p>"},{"location":"qadence/types/#qadence.types.StrEnum","title":"<code>StrEnum</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"qadence/types/#qadence.types.StrEnum.__str__","title":"<code>__str__()</code>","text":"<p>Used when dumping enum fields in a schema.</p> Source code in <code>qadence/types.py</code> <pre><code>def __str__(self) -&gt; str:\n\"\"\"Used when dumping enum fields in a schema.\"\"\"\nret: str = self.value\nreturn ret\n</code></pre>"},{"location":"qadence/types/#qadence.types.Strategy","title":"<code>Strategy</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Computing paradigm.</p>"},{"location":"qadence/types/#qadence.types.Strategy.ANALOG","title":"<code>ANALOG = 'Analog'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the analog paradigm.</p>"},{"location":"qadence/types/#qadence.types.Strategy.BDAQC","title":"<code>BDAQC = 'bDAQC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the banged digital-analog QC paradigm.</p>"},{"location":"qadence/types/#qadence.types.Strategy.DIGITAL","title":"<code>DIGITAL = 'Digital'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the digital paradigm.</p>"},{"location":"qadence/types/#qadence.types.Strategy.SDAQC","title":"<code>SDAQC = 'sDAQC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the step-wise digital-analog QC paradigm.</p>"},{"location":"qadence/types/#qadence.types.TensorType","title":"<code>TensorType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Tensor Types for converting blocks to tensors.</p>"},{"location":"qadence/types/#qadence.types.TensorType.DENSE","title":"<code>DENSE = 'Dense'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a block to a dense tensor.</p>"},{"location":"qadence/types/#qadence.types.TensorType.SPARSE","title":"<code>SPARSE = 'Sparse'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a observable block to a sparse tensor.</p>"},{"location":"qadence/types/#qadence.types.TensorType.SPARSEDIAGONAL","title":"<code>SPARSEDIAGONAL = 'SparseDiagonal'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a diagonal observable block to a sparse diagonal if possible.</p>"},{"location":"qml/","title":"Variational quantum algorithms","text":"<p>Variational algorithms on noisy devices and quantum machine learning (QML)[^1] in particular are one of the main target applications for Qadence. For this purpose, the library offers both flexible symbolic expressions for the quantum circuit parameters via <code>sympy</code> (see here for more details) and native automatic differentiation via integration with PyTorch deep learning framework.</p> <p>Furthermore, Qadence offers a wide range of utilities for helping building and researching quantum machine learning algorithms, including:</p> <ul> <li>a set of constructors for circuits commonly used in quantum machine learning such as feature maps and ansatze</li> <li>a set of tools for training and optimizing quantum neural networks and loading classical data into a QML algorithm</li> </ul>"},{"location":"qml/#some-simple-examples","title":"Some simple examples","text":"<p>Qadence symbolic parameter interface allows to create arbitrary feature maps to encode classical data into quantum circuits with an arbitrary non-linear function embedding for the input values:</p> <pre><code>import qadence as qd\nfrom qadence.operations import *\nimport torch\nfrom sympy import acos\nn_qubits = 4\n# Example feature map, also directly available with the `feature_map` function\nfp = qd.FeatureParameter(\"phi\")\nfm = qd.kron(RX(i, acos(fp)) for i in range(n_qubits))\n# the key in the dictionary must correspond to\n# the name of the assigned to the feature parameter\ninputs = {\"phi\": torch.rand(3)}\nsamples = qd.sample(fm, values=inputs)\n</code></pre> <pre><code>samples = Counter({'0000': 17, '1000': 14, '0100': 11, '0010': 9, '0011': 6, '0110': 6, '1010': 5, '1011': 5, '1100': 5, '1110': 5, '0001': 4, '1101': 4, '1001': 3, '0101': 2, '0111': 2, '1111': 2})\n</code></pre> <p>The <code>constructors.feature_map</code> module provides convenience functions to build commonly used feature maps where the input parameter is encoded in the single-qubit gates rotation angle. This function will be further demonstrated in the QML constructors tutorial.</p> <p>Furthermore, Qadence is natively integrated with PyTorch automatic differentiation engine thus Qadence quantum models can be used seamlessly in a PyTorch workflow.</p> <p>Let's create a quantum neural network model using the feature map just defined, a digital-analog variational ansatz (also explained here) and a simple observable \\(X(0) \\otimes X(1)\\). We use the convenience <code>QNN</code> quantum model abstraction.</p> <pre><code>ansatz = qd.hea(n_qubits, strategy=\"sDAQC\")\ncircuit = qd.QuantumCircuit(n_qubits, fm, ansatz)\nobservable = qd.kron(X(0), X(1))\nmodel = qd.QNN(circuit, observable)\n# NOTE: the `QNN` is a torch.nn.Module\nassert isinstance(model, torch.nn.Module)\n</code></pre> <pre><code>True\n</code></pre> <p>Differentiation works the same way as any other PyTorch module:</p> <pre><code>values = {\"phi\": torch.rand(10, requires_grad=True)}\n# the forward pass of the quantum model returns the expectation\n# value of the input observable\nout = model(values)\n# you can compute the gradient with respect to inputs using\n# PyTorch autograd differentiation engine\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: \\n{dout}\")\n# you can also call directly a backward pass to compute derivatives with respect\n# to the variational parameters and use it for implementing variational\n# optimization\nout.sum().backward()\n</code></pre> <pre><code>Quantum model output: tensor([[0.3667],\n[0.2050],\n[0.3449],\n[0.0755],\n[0.3173],\n[0.2709],\n[0.0777],\n[0.0627],\n[0.0870],\n[0.0496]], grad_fn=&lt;CatBackward0&gt;)\nFirst-order derivative w.r.t. the feature parameter: tensor([-0.4283, -0.5675, -0.4635,  0.9309, -0.4996, -0.5424,  0.9636, -0.3908,\n-0.4656, -0.3263], grad_fn=&lt;MulBackward0&gt;)\n</code></pre> <p>To run QML on real devices, Qadence offers generalized parameter shift rules (GPSR) <sup>1</sup> for arbitrary quantum operations which can be selected when constructing the <code>QNN</code> model:</p> <pre><code>model = qd.QNN(circuit, observable, diff_mode=\"gpsr\")\nout = model(values)\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: \\n{dout}\")\n</code></pre> <pre><code>First-order derivative w.r.t. the feature parameter: tensor([-0.4283, -0.5675, -0.4635,  0.9309, -0.4996, -0.5424,  0.9636, -0.3908,\n-0.4656, -0.3263], grad_fn=&lt;MulBackward0&gt;)\n</code></pre> <p>See here for more details on how the parameter shift rules implementation works in Qadence.</p>"},{"location":"qml/#references","title":"References","text":"<p>[^1] Schuld, Petruccione, Machine learning on Quantum Computers, Springer Nature (2021)</p> <ol> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9</p> </li> </ol>"},{"location":"qml/ml_tools/","title":"Training tools","text":""},{"location":"qml/ml_tools/#dataloaders","title":"Dataloaders","text":"<p>When using Qadence, you can supply classical data to a quantum machine learning algorithm by using a standard PyTorch <code>DataLoader</code> instance. Qadence also provides the <code>DictDataLoader</code> convenience class which allows to build dictionaries of <code>DataLoader</code>s instances and easily iterate over them.</p> <pre><code>import torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom qadence.ml_tools import DictDataLoader\ndef dataloader() -&gt; DataLoader:\nbatch_size = 5\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\ndataset = TensorDataset(x, y)\nreturn DataLoader(dataset, batch_size=batch_size)\ndef dictdataloader() -&gt; DictDataLoader:\nbatch_size = 5\nkeys = [\"y1\", \"y2\"]\ndls = {}\nfor k in keys:\nx = torch.rand(batch_size, 1)\ny = torch.sin(x)\ndataset = TensorDataset(x, y)\ndataloader = DataLoader(dataset, batch_size=batch_size)\ndls[k] = dataloader\nreturn DictDataLoader(dls)\nn_epochs = 2\n# iterate standard DataLoader\ndl = dataloader()\nfor i in range(n_epochs):\ndata = next(iter(dl))\n# iterate DictDataLoader\nddl = dictdataloader()\nfor i in range(n_epochs):\ndata = next(iter(ddl))\n</code></pre>"},{"location":"qml/ml_tools/#optimization-routines","title":"Optimization routines","text":"<p>For training QML models, Qadence also offers a few out-of-the-box routines for optimizing differentiable models, e.g. <code>QNN</code>s and <code>QuantumModel</code>, containing either trainable and/or non-trainable parameters (see the parameters tutorial for detailed information about parameter types):</p> <ul> <li><code>train_with_grad</code> for gradient-based optimization using PyTorch native optimizers</li> <li><code>train_gradient_free</code> for gradient-free optimization using the Nevergrad library.</li> </ul> <p>These routines performs training, logging/printing loss metrics and storing intermediate checkpoints of models. In the following, we use <code>train_with_grad</code> as example but the code can be used directly with the gradient-free routine.</p> <p>As every other training routine commonly used in Machine Learning, it requires <code>model</code>, <code>data</code> and an <code>optimizer</code> as input arguments. However, in addition, it requires a <code>loss_fn</code> and a <code>TrainConfig</code>. A <code>loss_fn</code> is required to be a function which expects both a model and data and returns a tuple of (loss, metrics: <code>&lt;dict&gt;</code>), where <code>metrics</code> is a dict of scalars which can be customized too.</p> <pre><code>import torch\nfrom itertools import count\ncnt = count()\ncriterion = torch.nn.MSELoss()\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\nnext(cnt)\nx, y = data[0], data[1]\nout = model(x)\nloss = criterion(out, y)\nreturn loss, {}\n</code></pre> <p>The <code>TrainConfig</code> tells <code>train_with_grad</code> what batch_size should be used, how many epochs to train, in which intervals to print/log metrics and how often to store intermediate checkpoints.</p> <pre><code>from qadence.ml_tools import TrainConfig\nbatch_size = 5\nn_epochs = 100\nconfig = TrainConfig(\nfolder=\"some_path/\",\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\n</code></pre> <p>Let's see it in action with a simple example.</p>"},{"location":"qml/ml_tools/#fitting-a-funtion-with-a-qnn-using-ml_tools","title":"Fitting a funtion with a QNN using <code>ml_tools</code>","text":"<p>Let's look at a complete example of how to use <code>train_with_grad</code> now.</p> <pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence.models import QNN\nfrom qadence.ml_tools import train_with_grad, TrainConfig\nimport matplotlib.pyplot as plt\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\nnext(cnt)\nx, y = data[0], data[1]\nout = model(x)\nloss = criterion(out, y)\nreturn loss, {}\ntmp_path = Path(\"/tmp\")\nn_epochs = 50\nconfig = TrainConfig(\nfolder=tmp_path,\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\nbatch_size = 25\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\ntrain_with_grad(model, (x, y), optimizer, config, loss_fn=loss_fn)\nplt.plot(x.numpy(), y.numpy())\nplt.plot(x.numpy(), model(x).detach().numpy())\n</code></pre> 2023-10-25T16:45:08.238343 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ <p>For users who want to use the low-level API of <code>qadence</code>, here is the example from above written without <code>train_with_grad</code>.</p>"},{"location":"qml/ml_tools/#fitting-a-function-low-level-api","title":"Fitting a function - Low-level API","text":"<pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence.models import QNN\nfrom qadence.ml_tools import train_with_grad, TrainConfig\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\nn_epochs=50\ncnt = count()\ntmp_path = Path(\"/tmp\")\nconfig = TrainConfig(\nfolder=tmp_path,\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\nfor i in range(n_epochs):\nout = model(x)\nloss = criterion(out, y)\nloss.backward()\noptimizer.step()\n</code></pre>"},{"location":"qml/qaoa/","title":"Solving MaxCut with QAOA","text":"<p>This tutorial shows how to solve the maximum cut (MaxCut) combinatorial optimization problem on a graph using the Quantum Approximate Optimization Algorithm (QAOA), first introduced by Farhi et al. in 2014 <sup>1</sup>.</p> <p>Given an arbitrary graph, the MaxCut problem consists in finding a graph cut which partitions the nodes into two disjoint sets, such that the number of edges in the cut is maximized. This is a very common combinatorial optimization problem which is computationally hard.</p> <p>The graph used for this tutorial is a randomly generated using the <code>networkx</code> library with a \\(0.5\\) probability of having an edge between two arbitrary nodes.</p> <pre><code>import numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\n# ensure reproducibility\nseed = 10\nnp.random.seed(seed)\nn_nodes = 8\nedge_prob = 0.5\ngraph = nx.gnp_random_graph(n_nodes, edge_prob)\nnx.draw(graph)\n</code></pre> 2023-10-25T16:45:09.028745 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ <p>The goal of the MaxCut algorithm is to maximize the following cost function:</p> \\[\\mathcal{C}(p) = \\sum_{\\alpha}^m \\mathcal{C}_{\\alpha}(p)\\] <p>where \\(p\\) is the given partition of the graph, \\(\\alpha\\) is an index over the edges and \\(\\mathcal{C}_{\\alpha}(p)\\) is written such that if the nodes connected by the \\(\\alpha\\) edge are in the same set, it returns \\(0\\), otherwise it returns \\(1\\).</p>"},{"location":"qml/qaoa/#the-qaoa-quantum-circuit","title":"The QAOA quantum circuit","text":"<p>This problem can be solved by using a parametrized quantum circuit with the QAOA algorithm. This requires a circuit with two main components:</p> <ul> <li>the cost component: a circuit generated by a diagonal Hamiltonian which   encodes the cost function described above into a quantum circuit.</li> <li>the mixing component: a simple set of single-qubit rotations with adjustable   angles which are tuned during the classical optimization loop to minimize the cost</li> </ul> <p>Below, the QAOA quantum circuit with the cost and mixing components is defined using <code>qadence</code> operations. The cost component of each layer of the circuit is decomposed into digital single and two-qubits operations via the <code>.digital_decomposition()</code> method. The decomposition is exact since the Hamiltonian generator is diagonal.</p> <pre><code>from qadence import Zero, I, HamEvo, tag, kron, chain, QuantumCircuit, RX, Z\n# generators associated with the edges of the given graph\nzz_ops = [kron(Z(edge[0]), Z(edge[1])) for edge in graph.edges()]\nn_qubits = graph.number_of_nodes()\nn_layers = 2\ncost_ham = Zero()\nfor op in zz_ops:\ncost_ham += 0.5 * op\ncost_ham = 0.5 * kron(I(i) for i in range(n_qubits)) - cost_ham\nlayers = []\nfor layer in range(n_layers):\n# cost layer with digital decomposition\ncost_layer = HamEvo(cost_ham, f\"g{layer}\").digital_decomposition()\ncost_layer = tag(cost_layer, \"cost\")\n# mixing layer with single qubit rotations\nmixing_layer = kron(RX(i, f\"b{layer}{i}\") for i in range(n_qubits))\nmixing_layer = tag(mixing_layer, \"mixing\")\n# putting all together in a single ChainBlock\nlayers.append(chain(cost_layer, mixing_layer))\nfinal_b = chain(*layers)\ncircuit = QuantumCircuit(n_qubits, final_b)\n</code></pre> %3 cluster_290677b43b4e45a888728e0d6c24fc51 mixing cluster_c93ff263c52e4b488e2a9b811cc54598 cost cluster_9e8cf9a788994f02a6f96a0456433b97 mixing cluster_c93ea20d045f42898443c00d4e5e4686 cost 36dcb28a830341a78f866d298d6fc8d1 0 934d352c2dd1441884a35aae55d56f92 36dcb28a830341a78f866d298d6fc8d1--934d352c2dd1441884a35aae55d56f92 3d0ebe460b5147c2bd7e2ab80ae4aafb 1 4fceb6f52ca343378149cbcfd272a744 934d352c2dd1441884a35aae55d56f92--4fceb6f52ca343378149cbcfd272a744 76425ff9d7d24355b2519f35207330c3 4fceb6f52ca343378149cbcfd272a744--76425ff9d7d24355b2519f35207330c3 0acaa70445284231a235016795788ed1 76425ff9d7d24355b2519f35207330c3--0acaa70445284231a235016795788ed1 bb0eb7ab888746e696c33143017cfe41 0acaa70445284231a235016795788ed1--bb0eb7ab888746e696c33143017cfe41 fe7475e123f24f86a4e8aa283e8fbd94 bb0eb7ab888746e696c33143017cfe41--fe7475e123f24f86a4e8aa283e8fbd94 36cec6b8e59e4675843c4d73e2730b47 fe7475e123f24f86a4e8aa283e8fbd94--36cec6b8e59e4675843c4d73e2730b47 53d4e88eb4074a7eb454369836feb09a 36cec6b8e59e4675843c4d73e2730b47--53d4e88eb4074a7eb454369836feb09a 437767848739461094055494d5048541 53d4e88eb4074a7eb454369836feb09a--437767848739461094055494d5048541 93bb72c6a18d43babfc3a0affccf2751 437767848739461094055494d5048541--93bb72c6a18d43babfc3a0affccf2751 ebf96c3bd2944f68b5fba6d2171df533 93bb72c6a18d43babfc3a0affccf2751--ebf96c3bd2944f68b5fba6d2171df533 9567b8049cd64a91843f58555034fc77 ebf96c3bd2944f68b5fba6d2171df533--9567b8049cd64a91843f58555034fc77 95950cf8369e4a48b8ff4d6bb19f1785 9567b8049cd64a91843f58555034fc77--95950cf8369e4a48b8ff4d6bb19f1785 90e0f6f01aa24a1da233d5a6843f69bb 95950cf8369e4a48b8ff4d6bb19f1785--90e0f6f01aa24a1da233d5a6843f69bb a3188dd989544db9853323a6641d747a 90e0f6f01aa24a1da233d5a6843f69bb--a3188dd989544db9853323a6641d747a b655c06a4ca14d408611df20c923162b a3188dd989544db9853323a6641d747a--b655c06a4ca14d408611df20c923162b ba2bf16210014bbbba672f485d622771 b655c06a4ca14d408611df20c923162b--ba2bf16210014bbbba672f485d622771 abeb56fa3e8e48788961e16d733256ab ba2bf16210014bbbba672f485d622771--abeb56fa3e8e48788961e16d733256ab c87c8b719e714ee8b704de581227fc3e abeb56fa3e8e48788961e16d733256ab--c87c8b719e714ee8b704de581227fc3e c7f10c035f6d4b6d881fa2c42e6e25f6 c87c8b719e714ee8b704de581227fc3e--c7f10c035f6d4b6d881fa2c42e6e25f6 c80cd55191ca47579d65dd5ea6125099 c7f10c035f6d4b6d881fa2c42e6e25f6--c80cd55191ca47579d65dd5ea6125099 19280bb4e33446ee82c4e90eef92c7e9 c80cd55191ca47579d65dd5ea6125099--19280bb4e33446ee82c4e90eef92c7e9 29807e8f8cd84df48fb0ba7df695312e 19280bb4e33446ee82c4e90eef92c7e9--29807e8f8cd84df48fb0ba7df695312e b8cc389cd2754d8fa68d61b142ba707c 29807e8f8cd84df48fb0ba7df695312e--b8cc389cd2754d8fa68d61b142ba707c 7f70650e82c249ceb7c24c503452a1d1 b8cc389cd2754d8fa68d61b142ba707c--7f70650e82c249ceb7c24c503452a1d1 132e4ef12e834614b45b44778db4726d 7f70650e82c249ceb7c24c503452a1d1--132e4ef12e834614b45b44778db4726d 9334853769304403b4b2f03efb39d606 132e4ef12e834614b45b44778db4726d--9334853769304403b4b2f03efb39d606 65a0db6807bc449fb8fd06c779a46cad 9334853769304403b4b2f03efb39d606--65a0db6807bc449fb8fd06c779a46cad ba70e1366223484db5ba9d351cd7922a 65a0db6807bc449fb8fd06c779a46cad--ba70e1366223484db5ba9d351cd7922a 7033aff6d61446438f4331fd5db92df1 ba70e1366223484db5ba9d351cd7922a--7033aff6d61446438f4331fd5db92df1 780edf55fa054c60b17e9f63b0159001 7033aff6d61446438f4331fd5db92df1--780edf55fa054c60b17e9f63b0159001 a9fd94146f6f41f3be095fac98813db1 780edf55fa054c60b17e9f63b0159001--a9fd94146f6f41f3be095fac98813db1 b87e7e6dbefc4c188f7439f098074960 a9fd94146f6f41f3be095fac98813db1--b87e7e6dbefc4c188f7439f098074960 27269fe6d8934fc8b6bb0121b7e5aeec b87e7e6dbefc4c188f7439f098074960--27269fe6d8934fc8b6bb0121b7e5aeec 4f75a0652b3c48bc9951b46cf211e84d 27269fe6d8934fc8b6bb0121b7e5aeec--4f75a0652b3c48bc9951b46cf211e84d ce252522de0242a1ae751f9d632580b4 4f75a0652b3c48bc9951b46cf211e84d--ce252522de0242a1ae751f9d632580b4 a7cd9a83ae6342e09b815b6afee76e43 ce252522de0242a1ae751f9d632580b4--a7cd9a83ae6342e09b815b6afee76e43 a78ad2df23ed4c0b919d946ec5597645 a7cd9a83ae6342e09b815b6afee76e43--a78ad2df23ed4c0b919d946ec5597645 0022f5b9305648f186d82441b357c5fa a78ad2df23ed4c0b919d946ec5597645--0022f5b9305648f186d82441b357c5fa 1e8d0bdb8161483bbfe3c0172f72776d 0022f5b9305648f186d82441b357c5fa--1e8d0bdb8161483bbfe3c0172f72776d f3d8781770d74c0ca05d07bdcefcb644 1e8d0bdb8161483bbfe3c0172f72776d--f3d8781770d74c0ca05d07bdcefcb644 d273db5bbeb44bd58637808cff431734 f3d8781770d74c0ca05d07bdcefcb644--d273db5bbeb44bd58637808cff431734 0b2a0ffa4f0043948de87bd07c38b3c5 d273db5bbeb44bd58637808cff431734--0b2a0ffa4f0043948de87bd07c38b3c5 8780644252c946c1a39305af6e083e9c 0b2a0ffa4f0043948de87bd07c38b3c5--8780644252c946c1a39305af6e083e9c d6517d2e6a3749df93470d888f1ae3f1 8780644252c946c1a39305af6e083e9c--d6517d2e6a3749df93470d888f1ae3f1 30a7f92f26554d73afd9149f38ab1a3c d6517d2e6a3749df93470d888f1ae3f1--30a7f92f26554d73afd9149f38ab1a3c 28032b17cda64903a935702d80e778ba 30a7f92f26554d73afd9149f38ab1a3c--28032b17cda64903a935702d80e778ba 2bdec34dc37a41c5b2e173d89341f35e 28032b17cda64903a935702d80e778ba--2bdec34dc37a41c5b2e173d89341f35e 19130bac9fd04967a0fcd6ca551b74a1 2bdec34dc37a41c5b2e173d89341f35e--19130bac9fd04967a0fcd6ca551b74a1 8978aed4c8e341cd8574a76cb76cf632 19130bac9fd04967a0fcd6ca551b74a1--8978aed4c8e341cd8574a76cb76cf632 d0fdaa2b90984f919b7f1db4b1950b92 8978aed4c8e341cd8574a76cb76cf632--d0fdaa2b90984f919b7f1db4b1950b92 45dddcb337014f7188ab761effc9a153 d0fdaa2b90984f919b7f1db4b1950b92--45dddcb337014f7188ab761effc9a153 375c40dbb1d94c729599bdf533085b90 45dddcb337014f7188ab761effc9a153--375c40dbb1d94c729599bdf533085b90 6761e563affc45459ee36a82199ffa75 375c40dbb1d94c729599bdf533085b90--6761e563affc45459ee36a82199ffa75 3a6e61b0047b4db897df27e1c2a99d66 6761e563affc45459ee36a82199ffa75--3a6e61b0047b4db897df27e1c2a99d66 99775d53a2a942199335e547e6aa36a5 3a6e61b0047b4db897df27e1c2a99d66--99775d53a2a942199335e547e6aa36a5 c03c2774ef784db280bf9d9c8b315987 99775d53a2a942199335e547e6aa36a5--c03c2774ef784db280bf9d9c8b315987 fb685a8fb9c145028cf64eee5e31d1b4 c03c2774ef784db280bf9d9c8b315987--fb685a8fb9c145028cf64eee5e31d1b4 ea6576448beb4fe3bd4a2db81b8a8a6e fb685a8fb9c145028cf64eee5e31d1b4--ea6576448beb4fe3bd4a2db81b8a8a6e 209778a8a6c74cdf98804894fdcb58e1 ea6576448beb4fe3bd4a2db81b8a8a6e--209778a8a6c74cdf98804894fdcb58e1 5e1febec13db4556b30e76065bd462ac 209778a8a6c74cdf98804894fdcb58e1--5e1febec13db4556b30e76065bd462ac 1992057be23841ebb06f5866aaff62fe 5e1febec13db4556b30e76065bd462ac--1992057be23841ebb06f5866aaff62fe dc18671ecbf7461591343ea32736d8a7 1992057be23841ebb06f5866aaff62fe--dc18671ecbf7461591343ea32736d8a7 27eb6cef5c0a415585ba468ad91c6904 dc18671ecbf7461591343ea32736d8a7--27eb6cef5c0a415585ba468ad91c6904 2f99dc894d394ebdac1aaa9291739f49 27eb6cef5c0a415585ba468ad91c6904--2f99dc894d394ebdac1aaa9291739f49 73a1d760815545d9bdcc6a269a2b3f1c 2f99dc894d394ebdac1aaa9291739f49--73a1d760815545d9bdcc6a269a2b3f1c e392a693e6ce4924ba7901a82b073dae 73a1d760815545d9bdcc6a269a2b3f1c--e392a693e6ce4924ba7901a82b073dae 01bc06a611714897af3b1e0535332d37 e392a693e6ce4924ba7901a82b073dae--01bc06a611714897af3b1e0535332d37 612718205f4941368826a6e5cfa0aaec 01bc06a611714897af3b1e0535332d37--612718205f4941368826a6e5cfa0aaec 081f8d88d8dc45d283083804d2adb791 612718205f4941368826a6e5cfa0aaec--081f8d88d8dc45d283083804d2adb791 7e0579b5092f4ef8b0a49ecb1f2a819e 081f8d88d8dc45d283083804d2adb791--7e0579b5092f4ef8b0a49ecb1f2a819e 23dd839486774447b8885462dbf97f79 7e0579b5092f4ef8b0a49ecb1f2a819e--23dd839486774447b8885462dbf97f79 f716fc225ef741dca245bd68f5043936 23dd839486774447b8885462dbf97f79--f716fc225ef741dca245bd68f5043936 5de75c358f524667b5d157558e8569e1 f716fc225ef741dca245bd68f5043936--5de75c358f524667b5d157558e8569e1 c6fef81d18ca4b569ce331fa694bc641 5de75c358f524667b5d157558e8569e1--c6fef81d18ca4b569ce331fa694bc641 681b74b45c5e4befab8b80b53c933049 c6fef81d18ca4b569ce331fa694bc641--681b74b45c5e4befab8b80b53c933049 a574d1722c3345b98d4e5ccde2a0344b 681b74b45c5e4befab8b80b53c933049--a574d1722c3345b98d4e5ccde2a0344b fde32645da8846f09ec4cd9af5e52b1c a574d1722c3345b98d4e5ccde2a0344b--fde32645da8846f09ec4cd9af5e52b1c 18f38bc5040241aeab69b89bee64949d fde32645da8846f09ec4cd9af5e52b1c--18f38bc5040241aeab69b89bee64949d 1428de1481884d608c9888be5a0c2122 18f38bc5040241aeab69b89bee64949d--1428de1481884d608c9888be5a0c2122 de71b9d7f938465c87a8a0505aba4fa7 1428de1481884d608c9888be5a0c2122--de71b9d7f938465c87a8a0505aba4fa7 172989b72ae045e29892f98ff248164c de71b9d7f938465c87a8a0505aba4fa7--172989b72ae045e29892f98ff248164c 335e4e40aeeb4d4d9dffc2ac80ac961a 172989b72ae045e29892f98ff248164c--335e4e40aeeb4d4d9dffc2ac80ac961a 45666d02295641da94cf0a2b6c9ec3ac 335e4e40aeeb4d4d9dffc2ac80ac961a--45666d02295641da94cf0a2b6c9ec3ac bf632bb4c90e4ef0b60b9f9928780799 45666d02295641da94cf0a2b6c9ec3ac--bf632bb4c90e4ef0b60b9f9928780799 20aa2071d37944f2a0af890e8b44d7c0 bf632bb4c90e4ef0b60b9f9928780799--20aa2071d37944f2a0af890e8b44d7c0 47c7c22921e14b8786c9c6bec1f7ca74 20aa2071d37944f2a0af890e8b44d7c0--47c7c22921e14b8786c9c6bec1f7ca74 34eb2dd8b090412084f920e16db5fe5a 47c7c22921e14b8786c9c6bec1f7ca74--34eb2dd8b090412084f920e16db5fe5a ccad5ce62e974f378b62effab54c8e46 34eb2dd8b090412084f920e16db5fe5a--ccad5ce62e974f378b62effab54c8e46 b8a567b923ad446f9a3d8eff99304c33 ccad5ce62e974f378b62effab54c8e46--b8a567b923ad446f9a3d8eff99304c33 69472a2d166d42509db70502c1cf012e b8a567b923ad446f9a3d8eff99304c33--69472a2d166d42509db70502c1cf012e 5a61a2e79adc496ba78c3fbac669f841 69472a2d166d42509db70502c1cf012e--5a61a2e79adc496ba78c3fbac669f841 0a05555b9f5845cdae406c4b13e30e5a 5a61a2e79adc496ba78c3fbac669f841--0a05555b9f5845cdae406c4b13e30e5a 8884f4e94f1a4bafb57bcf19941defc4 0a05555b9f5845cdae406c4b13e30e5a--8884f4e94f1a4bafb57bcf19941defc4 61f3d25478f04722802fa8f30306860f 8884f4e94f1a4bafb57bcf19941defc4--61f3d25478f04722802fa8f30306860f d995281f289a42f7b98629a179f944ce 61f3d25478f04722802fa8f30306860f--d995281f289a42f7b98629a179f944ce 81ca78261bd64e5c8d012a4e6944316e d995281f289a42f7b98629a179f944ce--81ca78261bd64e5c8d012a4e6944316e b086092a435a4b569e77b4ccc97cd9e2 81ca78261bd64e5c8d012a4e6944316e--b086092a435a4b569e77b4ccc97cd9e2 df7d21dafdf842f89534023361d9c6cb b086092a435a4b569e77b4ccc97cd9e2--df7d21dafdf842f89534023361d9c6cb 94d50403fe56485cad90b66e18fd4b98 df7d21dafdf842f89534023361d9c6cb--94d50403fe56485cad90b66e18fd4b98 fc7aea5f8ab444308817119baf0891f9 94d50403fe56485cad90b66e18fd4b98--fc7aea5f8ab444308817119baf0891f9 3535ee21552a43b480c748c6077c8858 fc7aea5f8ab444308817119baf0891f9--3535ee21552a43b480c748c6077c8858 d45c57c6ecab4568b234b588bb68e804 3535ee21552a43b480c748c6077c8858--d45c57c6ecab4568b234b588bb68e804 c3caea5b3dac4d1a815f6928109d531e d45c57c6ecab4568b234b588bb68e804--c3caea5b3dac4d1a815f6928109d531e e1f370cc492c4ac1a85bdc7e0a10504f c3caea5b3dac4d1a815f6928109d531e--e1f370cc492c4ac1a85bdc7e0a10504f f13331ed078f41a1a7c959583ab5641d e1f370cc492c4ac1a85bdc7e0a10504f--f13331ed078f41a1a7c959583ab5641d c55ca92a2bd14bfb9abb3f513837f3fc f13331ed078f41a1a7c959583ab5641d--c55ca92a2bd14bfb9abb3f513837f3fc 85429436b7d0400a96ca3560c7d57f59 c55ca92a2bd14bfb9abb3f513837f3fc--85429436b7d0400a96ca3560c7d57f59 67db42ffbba6488cb84894c6a7a2d07d 85429436b7d0400a96ca3560c7d57f59--67db42ffbba6488cb84894c6a7a2d07d 6ceb6561da9c4f099b5755889777bcfd 67db42ffbba6488cb84894c6a7a2d07d--6ceb6561da9c4f099b5755889777bcfd ceee937090bc4dca958173e12896f036 6ceb6561da9c4f099b5755889777bcfd--ceee937090bc4dca958173e12896f036 8ed36df5b18942baabf885cc53b3c9c1 ceee937090bc4dca958173e12896f036--8ed36df5b18942baabf885cc53b3c9c1 131c6f5fd25a4f3984f7c5eb8fb44812 8ed36df5b18942baabf885cc53b3c9c1--131c6f5fd25a4f3984f7c5eb8fb44812 639eade1405043e2b9b96d462ff0d69c 131c6f5fd25a4f3984f7c5eb8fb44812--639eade1405043e2b9b96d462ff0d69c b7c29e35efbf49dc9db86602f1a22476 639eade1405043e2b9b96d462ff0d69c--b7c29e35efbf49dc9db86602f1a22476 bb33e079ed014e68bed5c870f53573b6 b7c29e35efbf49dc9db86602f1a22476--bb33e079ed014e68bed5c870f53573b6 32f27ae674d2452a8927050ba16c1b4a bb33e079ed014e68bed5c870f53573b6--32f27ae674d2452a8927050ba16c1b4a fa5976f7f94d47ce89c2bdf2fb111ff4 32f27ae674d2452a8927050ba16c1b4a--fa5976f7f94d47ce89c2bdf2fb111ff4 8ffb4c9fcc87467fb1c45272563c4a4b fa5976f7f94d47ce89c2bdf2fb111ff4--8ffb4c9fcc87467fb1c45272563c4a4b ad596fe71ef042ed80ad01fcffd89998 8ffb4c9fcc87467fb1c45272563c4a4b--ad596fe71ef042ed80ad01fcffd89998 50f385427d0046caa6c6b7a507dcf703 ad596fe71ef042ed80ad01fcffd89998--50f385427d0046caa6c6b7a507dcf703 e2acbdf6953748319a5d4ef408f2eb93 50f385427d0046caa6c6b7a507dcf703--e2acbdf6953748319a5d4ef408f2eb93 47ba1248ce0c4aa99be45d3dbc1953f4 e2acbdf6953748319a5d4ef408f2eb93--47ba1248ce0c4aa99be45d3dbc1953f4 0c6e439eee4b45fc9e44fcc9b4550693 47ba1248ce0c4aa99be45d3dbc1953f4--0c6e439eee4b45fc9e44fcc9b4550693 b1635733e7534e4e958bce98cbbcbaa7 0c6e439eee4b45fc9e44fcc9b4550693--b1635733e7534e4e958bce98cbbcbaa7 51adb4817ffa4f6bb37531ae91d30df9 b1635733e7534e4e958bce98cbbcbaa7--51adb4817ffa4f6bb37531ae91d30df9 a65b2df8dc1f41588cc5ed2500f00b67 51adb4817ffa4f6bb37531ae91d30df9--a65b2df8dc1f41588cc5ed2500f00b67 d613da2e3eda47d4a2aeb79f9553fd1d a65b2df8dc1f41588cc5ed2500f00b67--d613da2e3eda47d4a2aeb79f9553fd1d e2f4e57c406a4721ba368d0e48cc3fe8 d613da2e3eda47d4a2aeb79f9553fd1d--e2f4e57c406a4721ba368d0e48cc3fe8 02cf099f985e425eb8363e385bc14572 e2f4e57c406a4721ba368d0e48cc3fe8--02cf099f985e425eb8363e385bc14572 cf7943772f1749dd9d54aec2c8700420 02cf099f985e425eb8363e385bc14572--cf7943772f1749dd9d54aec2c8700420 2372d598ce6a489e84ee65b2695ca375 RX(b00) cf7943772f1749dd9d54aec2c8700420--2372d598ce6a489e84ee65b2695ca375 221193174a914ff28cd652935e379dcb 2372d598ce6a489e84ee65b2695ca375--221193174a914ff28cd652935e379dcb 7d4c37b5f13445ae96d3299f18026e2c 221193174a914ff28cd652935e379dcb--7d4c37b5f13445ae96d3299f18026e2c 332a2ddef1ab42cfbbc78a93776a5130 7d4c37b5f13445ae96d3299f18026e2c--332a2ddef1ab42cfbbc78a93776a5130 89d98554744d46a5a47d75c702724fa7 332a2ddef1ab42cfbbc78a93776a5130--89d98554744d46a5a47d75c702724fa7 d60be31be93542f389cda7fbffd6d1e8 89d98554744d46a5a47d75c702724fa7--d60be31be93542f389cda7fbffd6d1e8 221bb36978134d489907d4bf14b6416d d60be31be93542f389cda7fbffd6d1e8--221bb36978134d489907d4bf14b6416d 8227c4953db54c8db84bbd898d28bf86 221bb36978134d489907d4bf14b6416d--8227c4953db54c8db84bbd898d28bf86 ce3340e87dd2496487a6234ee86050df 8227c4953db54c8db84bbd898d28bf86--ce3340e87dd2496487a6234ee86050df 964d69cda5d74396819be266441ca8a8 ce3340e87dd2496487a6234ee86050df--964d69cda5d74396819be266441ca8a8 fc3bb4e857f74d6fbf4adafaa44d1914 964d69cda5d74396819be266441ca8a8--fc3bb4e857f74d6fbf4adafaa44d1914 8d20cab1336c4982b2aaeb4f9c01a48f fc3bb4e857f74d6fbf4adafaa44d1914--8d20cab1336c4982b2aaeb4f9c01a48f 0749fc0567c84dfbafc7dc3f92d26bd7 8d20cab1336c4982b2aaeb4f9c01a48f--0749fc0567c84dfbafc7dc3f92d26bd7 29b5b071c80e46768962fe3f1bb0f430 0749fc0567c84dfbafc7dc3f92d26bd7--29b5b071c80e46768962fe3f1bb0f430 873b03f64d194b798a210476bed080a3 29b5b071c80e46768962fe3f1bb0f430--873b03f64d194b798a210476bed080a3 4763fb1d35574d41bd54bc725a145afa 873b03f64d194b798a210476bed080a3--4763fb1d35574d41bd54bc725a145afa 683f4caf24224643a58232d989d18d32 4763fb1d35574d41bd54bc725a145afa--683f4caf24224643a58232d989d18d32 ff28b91394cf4f44b05d56d9a2446d08 683f4caf24224643a58232d989d18d32--ff28b91394cf4f44b05d56d9a2446d08 920c179e935c4ad5ab44c0e13777e4ad ff28b91394cf4f44b05d56d9a2446d08--920c179e935c4ad5ab44c0e13777e4ad 79c5995a8b164b82b020a31393b6b574 920c179e935c4ad5ab44c0e13777e4ad--79c5995a8b164b82b020a31393b6b574 d51b56f9694e43de8e186292d47cc542 79c5995a8b164b82b020a31393b6b574--d51b56f9694e43de8e186292d47cc542 a809037d3c9a4732b56253ec64d17fd8 d51b56f9694e43de8e186292d47cc542--a809037d3c9a4732b56253ec64d17fd8 f3ee9295816243cfb92964fb1bec8dd7 a809037d3c9a4732b56253ec64d17fd8--f3ee9295816243cfb92964fb1bec8dd7 09260be8123e4beebbedd3aee5dd1176 f3ee9295816243cfb92964fb1bec8dd7--09260be8123e4beebbedd3aee5dd1176 d3f3a55c8fd5479cb1ae6cf1333148ad 09260be8123e4beebbedd3aee5dd1176--d3f3a55c8fd5479cb1ae6cf1333148ad 788d1970d52540c192bfd8e217765b32 d3f3a55c8fd5479cb1ae6cf1333148ad--788d1970d52540c192bfd8e217765b32 a3634b4127a64592bf4e77946d29da7f 788d1970d52540c192bfd8e217765b32--a3634b4127a64592bf4e77946d29da7f 40316cc4de5046ca8ffa40eaf7b1082d a3634b4127a64592bf4e77946d29da7f--40316cc4de5046ca8ffa40eaf7b1082d d5f2435c1fc34f3ba1364d8d7f0ca813 40316cc4de5046ca8ffa40eaf7b1082d--d5f2435c1fc34f3ba1364d8d7f0ca813 1922eda6556a4d908ee1634b9f9fdfb3 d5f2435c1fc34f3ba1364d8d7f0ca813--1922eda6556a4d908ee1634b9f9fdfb3 ee53751bd02849678b7ede6c8d040b4b 1922eda6556a4d908ee1634b9f9fdfb3--ee53751bd02849678b7ede6c8d040b4b 947fa2d4645d47f29ab5868894dfc905 ee53751bd02849678b7ede6c8d040b4b--947fa2d4645d47f29ab5868894dfc905 894cf97626834d2998f836a64018200e 947fa2d4645d47f29ab5868894dfc905--894cf97626834d2998f836a64018200e 2d96aedaaea34118a036f3e94a301805 894cf97626834d2998f836a64018200e--2d96aedaaea34118a036f3e94a301805 c8e80c13640c4ff7b6675233987ebefa 2d96aedaaea34118a036f3e94a301805--c8e80c13640c4ff7b6675233987ebefa c4f6d190a94942ff8e6240b6f8c30e84 c8e80c13640c4ff7b6675233987ebefa--c4f6d190a94942ff8e6240b6f8c30e84 bfba0276b5644a378677cd06081c513f c4f6d190a94942ff8e6240b6f8c30e84--bfba0276b5644a378677cd06081c513f 5da7db47d6a3417f9897b1757ea3598f bfba0276b5644a378677cd06081c513f--5da7db47d6a3417f9897b1757ea3598f e3cce6ea5c7543298a7c0c267fe0df0d 5da7db47d6a3417f9897b1757ea3598f--e3cce6ea5c7543298a7c0c267fe0df0d 1eed421aadfd4c53b08a5b6865978b6d e3cce6ea5c7543298a7c0c267fe0df0d--1eed421aadfd4c53b08a5b6865978b6d f2b9cda5cdba4d2e95befa893585b0e5 1eed421aadfd4c53b08a5b6865978b6d--f2b9cda5cdba4d2e95befa893585b0e5 f45be8fbc2e94406830fe28e83c9e622 f2b9cda5cdba4d2e95befa893585b0e5--f45be8fbc2e94406830fe28e83c9e622 1bcc0351f3ee489e8a961bcadcdf4480 f45be8fbc2e94406830fe28e83c9e622--1bcc0351f3ee489e8a961bcadcdf4480 8893690935b641dd90f6d9c985dbb9e5 1bcc0351f3ee489e8a961bcadcdf4480--8893690935b641dd90f6d9c985dbb9e5 4ed8f2dbaf254d14b49c962e323dbd40 8893690935b641dd90f6d9c985dbb9e5--4ed8f2dbaf254d14b49c962e323dbd40 cd8dc792eb644290bc4c0355d7781d26 4ed8f2dbaf254d14b49c962e323dbd40--cd8dc792eb644290bc4c0355d7781d26 effc6405295045818554ef309e4a92fe cd8dc792eb644290bc4c0355d7781d26--effc6405295045818554ef309e4a92fe b607df83547243cd8fae32ca0c1832e3 effc6405295045818554ef309e4a92fe--b607df83547243cd8fae32ca0c1832e3 faf40b9230544ebab09c785566975878 b607df83547243cd8fae32ca0c1832e3--faf40b9230544ebab09c785566975878 c3c865574fb34f1fb2a00dd7efad02a4 faf40b9230544ebab09c785566975878--c3c865574fb34f1fb2a00dd7efad02a4 ae4a1b2092b743599acac67bf6693398 c3c865574fb34f1fb2a00dd7efad02a4--ae4a1b2092b743599acac67bf6693398 fb025df70aed4f26b5b2eddce956e611 ae4a1b2092b743599acac67bf6693398--fb025df70aed4f26b5b2eddce956e611 5940548b8f5042679ea87b2b77dbda20 fb025df70aed4f26b5b2eddce956e611--5940548b8f5042679ea87b2b77dbda20 939eb61851ed45d892a8fde2ad914dea 5940548b8f5042679ea87b2b77dbda20--939eb61851ed45d892a8fde2ad914dea 8aa476ccc0db46a792298300a63d46c6 939eb61851ed45d892a8fde2ad914dea--8aa476ccc0db46a792298300a63d46c6 be0ce0f24b7e4c16b0db80e95488054c 8aa476ccc0db46a792298300a63d46c6--be0ce0f24b7e4c16b0db80e95488054c d5b31a1a5f64467dba88d323e4f2f676 be0ce0f24b7e4c16b0db80e95488054c--d5b31a1a5f64467dba88d323e4f2f676 a7b15c4a43f24fe7ad924236fd2fef40 d5b31a1a5f64467dba88d323e4f2f676--a7b15c4a43f24fe7ad924236fd2fef40 1d0aee92a7d54456a5b0e27b918ee805 a7b15c4a43f24fe7ad924236fd2fef40--1d0aee92a7d54456a5b0e27b918ee805 d29144f3c53f493eb54cc17fdcece887 1d0aee92a7d54456a5b0e27b918ee805--d29144f3c53f493eb54cc17fdcece887 805b8b2891ae4703a4dfaa6f303d49fe d29144f3c53f493eb54cc17fdcece887--805b8b2891ae4703a4dfaa6f303d49fe 14e29c5853014a9fbe10c2ff1ac2a751 805b8b2891ae4703a4dfaa6f303d49fe--14e29c5853014a9fbe10c2ff1ac2a751 07847224ca7f4e3aa5f21ada82d6d548 14e29c5853014a9fbe10c2ff1ac2a751--07847224ca7f4e3aa5f21ada82d6d548 ef207fee7b4a49e9a4fde171cf0e1556 07847224ca7f4e3aa5f21ada82d6d548--ef207fee7b4a49e9a4fde171cf0e1556 a9a33b2adf424b05a4cc4b6a40e14b87 ef207fee7b4a49e9a4fde171cf0e1556--a9a33b2adf424b05a4cc4b6a40e14b87 37b38b29f9ab437389fdc36192471fef a9a33b2adf424b05a4cc4b6a40e14b87--37b38b29f9ab437389fdc36192471fef c904f020d7b44cb2bbd83e91e00e6477 37b38b29f9ab437389fdc36192471fef--c904f020d7b44cb2bbd83e91e00e6477 73044d8f93c94a1c9dd57ac8215c86fb c904f020d7b44cb2bbd83e91e00e6477--73044d8f93c94a1c9dd57ac8215c86fb 9bbdc0e4a0214588b739228ccb9caf4f 73044d8f93c94a1c9dd57ac8215c86fb--9bbdc0e4a0214588b739228ccb9caf4f db25958d04244888a467cb9578348631 9bbdc0e4a0214588b739228ccb9caf4f--db25958d04244888a467cb9578348631 53087909808849239e9b56e6c84a79e0 db25958d04244888a467cb9578348631--53087909808849239e9b56e6c84a79e0 7726262ce86848e2903519c2601cd990 53087909808849239e9b56e6c84a79e0--7726262ce86848e2903519c2601cd990 4d7bb15e6d8742d6b266e6e82996c9a4 7726262ce86848e2903519c2601cd990--4d7bb15e6d8742d6b266e6e82996c9a4 2d79ca76195c41ff8252f47e73ceee97 4d7bb15e6d8742d6b266e6e82996c9a4--2d79ca76195c41ff8252f47e73ceee97 47067380d1e1477b8add240acdc60b05 2d79ca76195c41ff8252f47e73ceee97--47067380d1e1477b8add240acdc60b05 87c1cdbd02c44ff79ef442745ce7f4c8 47067380d1e1477b8add240acdc60b05--87c1cdbd02c44ff79ef442745ce7f4c8 89aa15d770994710bdd77f877da9324e 87c1cdbd02c44ff79ef442745ce7f4c8--89aa15d770994710bdd77f877da9324e 1b78a3cacf1449408aafc17d83c1b86a 89aa15d770994710bdd77f877da9324e--1b78a3cacf1449408aafc17d83c1b86a 957cb058cb614d018add75246915fa2e 1b78a3cacf1449408aafc17d83c1b86a--957cb058cb614d018add75246915fa2e 771f0705f5e943c486dc14b2da863c55 957cb058cb614d018add75246915fa2e--771f0705f5e943c486dc14b2da863c55 f2b38386743646c9aa751ebdbcf91b26 771f0705f5e943c486dc14b2da863c55--f2b38386743646c9aa751ebdbcf91b26 1f97ab3e1807450980b6f1bb352f1552 f2b38386743646c9aa751ebdbcf91b26--1f97ab3e1807450980b6f1bb352f1552 6167e6012a0a443090b6a6c9f8dcee4d 1f97ab3e1807450980b6f1bb352f1552--6167e6012a0a443090b6a6c9f8dcee4d 68844a6fe44b4f73a5285c3bcb3ac079 6167e6012a0a443090b6a6c9f8dcee4d--68844a6fe44b4f73a5285c3bcb3ac079 b81698dc11fe4053a2f01bc12d74ad49 68844a6fe44b4f73a5285c3bcb3ac079--b81698dc11fe4053a2f01bc12d74ad49 139d9779316c47fea64490e9226b1826 b81698dc11fe4053a2f01bc12d74ad49--139d9779316c47fea64490e9226b1826 d671fa9af5d844c9b8d5f17a8016aa84 139d9779316c47fea64490e9226b1826--d671fa9af5d844c9b8d5f17a8016aa84 7154f1937a0a4b209bdeb3e6054fbda3 d671fa9af5d844c9b8d5f17a8016aa84--7154f1937a0a4b209bdeb3e6054fbda3 73f8a50826f14e0ba73f7f81586a111f 7154f1937a0a4b209bdeb3e6054fbda3--73f8a50826f14e0ba73f7f81586a111f 7a09959356264d74bc8244f2bd4e35f2 73f8a50826f14e0ba73f7f81586a111f--7a09959356264d74bc8244f2bd4e35f2 a327b1f19fe545cb81171f80c4abd0b1 7a09959356264d74bc8244f2bd4e35f2--a327b1f19fe545cb81171f80c4abd0b1 6e7fe37c4b1d4bdbac8df1de82523dcb a327b1f19fe545cb81171f80c4abd0b1--6e7fe37c4b1d4bdbac8df1de82523dcb c495e07be50a46ae99ade0c24eba3dd2 6e7fe37c4b1d4bdbac8df1de82523dcb--c495e07be50a46ae99ade0c24eba3dd2 78d23828b3ae4436b4bd8d462ea7a340 c495e07be50a46ae99ade0c24eba3dd2--78d23828b3ae4436b4bd8d462ea7a340 9ed245ffb7a54cd2aaa34c0a8f83d0c4 78d23828b3ae4436b4bd8d462ea7a340--9ed245ffb7a54cd2aaa34c0a8f83d0c4 82283f0503aa4de383d74bd3dbac9536 9ed245ffb7a54cd2aaa34c0a8f83d0c4--82283f0503aa4de383d74bd3dbac9536 bf6243467b1e4626a151dd341546ab58 82283f0503aa4de383d74bd3dbac9536--bf6243467b1e4626a151dd341546ab58 053d2198d7674665b066a675cdaeecbc bf6243467b1e4626a151dd341546ab58--053d2198d7674665b066a675cdaeecbc b1f0114cf80c4193931f6eb48925f95b 053d2198d7674665b066a675cdaeecbc--b1f0114cf80c4193931f6eb48925f95b 3acca83c7fc04ef3bcbd5c5b34076847 b1f0114cf80c4193931f6eb48925f95b--3acca83c7fc04ef3bcbd5c5b34076847 b46cd7eca5cd439cbaf029b5c6240b72 3acca83c7fc04ef3bcbd5c5b34076847--b46cd7eca5cd439cbaf029b5c6240b72 655f9d048153407c846982003d2089d3 b46cd7eca5cd439cbaf029b5c6240b72--655f9d048153407c846982003d2089d3 fa9d3440a1f04bd2a5e8d6997dad04a0 655f9d048153407c846982003d2089d3--fa9d3440a1f04bd2a5e8d6997dad04a0 a9d21ec34d58498ab6384c16feaea32b fa9d3440a1f04bd2a5e8d6997dad04a0--a9d21ec34d58498ab6384c16feaea32b d29c69d2eaca4715ba31d8843d6bc80e a9d21ec34d58498ab6384c16feaea32b--d29c69d2eaca4715ba31d8843d6bc80e 85abfce58d5e416abcee2222e5eca2cc d29c69d2eaca4715ba31d8843d6bc80e--85abfce58d5e416abcee2222e5eca2cc dff729ebac3849a9afa9c191eb4326cc 85abfce58d5e416abcee2222e5eca2cc--dff729ebac3849a9afa9c191eb4326cc 2cfe25313dd341a1a4d113526c8ec214 dff729ebac3849a9afa9c191eb4326cc--2cfe25313dd341a1a4d113526c8ec214 42cd9b0489734d7f936815da1eae1bf5 2cfe25313dd341a1a4d113526c8ec214--42cd9b0489734d7f936815da1eae1bf5 820de2d7e9714d138afced1806256bde 42cd9b0489734d7f936815da1eae1bf5--820de2d7e9714d138afced1806256bde 1264dc71851348c6ad8517e0c53c8797 820de2d7e9714d138afced1806256bde--1264dc71851348c6ad8517e0c53c8797 ed3eca7bf9704016b43314ee97e46065 1264dc71851348c6ad8517e0c53c8797--ed3eca7bf9704016b43314ee97e46065 05e221dcd1954318ab73a9c8b892bc66 ed3eca7bf9704016b43314ee97e46065--05e221dcd1954318ab73a9c8b892bc66 6b8a75c8fb274d10af5891d4c8cb677b 05e221dcd1954318ab73a9c8b892bc66--6b8a75c8fb274d10af5891d4c8cb677b 013845bd178841ffb49a694ed2d00514 6b8a75c8fb274d10af5891d4c8cb677b--013845bd178841ffb49a694ed2d00514 3541b525df664187928c9714c3a477fa 013845bd178841ffb49a694ed2d00514--3541b525df664187928c9714c3a477fa 2e4a14fb437b42edb7dbf98933106a21 3541b525df664187928c9714c3a477fa--2e4a14fb437b42edb7dbf98933106a21 8dd637e35b904c3eaa51cea4cc7ddd4f 2e4a14fb437b42edb7dbf98933106a21--8dd637e35b904c3eaa51cea4cc7ddd4f e130e7a5a74b405dbfd6d5db937347a1 8dd637e35b904c3eaa51cea4cc7ddd4f--e130e7a5a74b405dbfd6d5db937347a1 cd5512c29bc644dab52c87f5b663915d e130e7a5a74b405dbfd6d5db937347a1--cd5512c29bc644dab52c87f5b663915d 74d97eeed49d41b19c0068573e86ccc3 cd5512c29bc644dab52c87f5b663915d--74d97eeed49d41b19c0068573e86ccc3 3c16a1adbe47414c9c99a088a4a8706f 74d97eeed49d41b19c0068573e86ccc3--3c16a1adbe47414c9c99a088a4a8706f 920bd022d24e4dee8437262919276221 3c16a1adbe47414c9c99a088a4a8706f--920bd022d24e4dee8437262919276221 f6a9bb9e89854da88dea267a10cd3a0a 920bd022d24e4dee8437262919276221--f6a9bb9e89854da88dea267a10cd3a0a ea5c3f13e1fa4baab990b7f027221ab0 f6a9bb9e89854da88dea267a10cd3a0a--ea5c3f13e1fa4baab990b7f027221ab0 bd64f336c6934e38803165fa3bdaf634 ea5c3f13e1fa4baab990b7f027221ab0--bd64f336c6934e38803165fa3bdaf634 92d590f09aa6457cbf98137e3e820780 bd64f336c6934e38803165fa3bdaf634--92d590f09aa6457cbf98137e3e820780 459067090f554d048423a56877b0a8eb 92d590f09aa6457cbf98137e3e820780--459067090f554d048423a56877b0a8eb da39167be959417eb1ad7dd1790b26a8 459067090f554d048423a56877b0a8eb--da39167be959417eb1ad7dd1790b26a8 4141b5a3adbf438fb773d9ba6339966a da39167be959417eb1ad7dd1790b26a8--4141b5a3adbf438fb773d9ba6339966a c0a25e4d2daf401c81f663f543eb9898 4141b5a3adbf438fb773d9ba6339966a--c0a25e4d2daf401c81f663f543eb9898 eab138e7d4f246d88e151daa3c31b20a c0a25e4d2daf401c81f663f543eb9898--eab138e7d4f246d88e151daa3c31b20a 6587160bfbe045e680f98ed4cd68c971 RX(b10) eab138e7d4f246d88e151daa3c31b20a--6587160bfbe045e680f98ed4cd68c971 e50939415ad7489bb46ecfafa9fe2118 6587160bfbe045e680f98ed4cd68c971--e50939415ad7489bb46ecfafa9fe2118 d4e26c58a7b84dfcba4d4f58793e4b17 4491a87639374719b4534f05977e487c X 3d0ebe460b5147c2bd7e2ab80ae4aafb--4491a87639374719b4534f05977e487c bca82a3db7ac4088a6bc067d09337cdb 2 4491a87639374719b4534f05977e487c--934d352c2dd1441884a35aae55d56f92 4720c2c66f7744feaa6bcde54fad2812 4491a87639374719b4534f05977e487c--4720c2c66f7744feaa6bcde54fad2812 b12921a6ffa849b3bc1ea3c009fb8326 4720c2c66f7744feaa6bcde54fad2812--b12921a6ffa849b3bc1ea3c009fb8326 4ff2e1ca29194102b05a4978b5aea22e b12921a6ffa849b3bc1ea3c009fb8326--4ff2e1ca29194102b05a4978b5aea22e 72eea72b6d2c4a00bcd217ab4a5fe635 4ff2e1ca29194102b05a4978b5aea22e--72eea72b6d2c4a00bcd217ab4a5fe635 f3f62221acfc45ba8a597e1a88de95ef 72eea72b6d2c4a00bcd217ab4a5fe635--f3f62221acfc45ba8a597e1a88de95ef 03693b1b9b744077a1a7cf219f024c7e f3f62221acfc45ba8a597e1a88de95ef--03693b1b9b744077a1a7cf219f024c7e a119ba5e18604616b07e9caa181bc677 03693b1b9b744077a1a7cf219f024c7e--a119ba5e18604616b07e9caa181bc677 027ef4865d6741c29b126820f606b5d0 a119ba5e18604616b07e9caa181bc677--027ef4865d6741c29b126820f606b5d0 e1272f65377a4382b1fa9fc19ef4c009 027ef4865d6741c29b126820f606b5d0--e1272f65377a4382b1fa9fc19ef4c009 0d44e3701eb545089f96f755497114e3 e1272f65377a4382b1fa9fc19ef4c009--0d44e3701eb545089f96f755497114e3 ae79c4e9972440b98e5ac3b0b04a89d8 0d44e3701eb545089f96f755497114e3--ae79c4e9972440b98e5ac3b0b04a89d8 78757f8fa2744d4997b93a2077731c59 ae79c4e9972440b98e5ac3b0b04a89d8--78757f8fa2744d4997b93a2077731c59 7d64ceebb8c2430d9eff9a9822d329ba 78757f8fa2744d4997b93a2077731c59--7d64ceebb8c2430d9eff9a9822d329ba 4641d73a7ec34f698f93e19492822095 X 7d64ceebb8c2430d9eff9a9822d329ba--4641d73a7ec34f698f93e19492822095 4641d73a7ec34f698f93e19492822095--a3188dd989544db9853323a6641d747a 15d69afb3e4c479f99511514eb872e34 X 4641d73a7ec34f698f93e19492822095--15d69afb3e4c479f99511514eb872e34 15d69afb3e4c479f99511514eb872e34--b655c06a4ca14d408611df20c923162b cdb50b7347aa4af1a6503b6504d914fa 15d69afb3e4c479f99511514eb872e34--cdb50b7347aa4af1a6503b6504d914fa c6c2a6503231479a82cf8aacbf9b04c8 cdb50b7347aa4af1a6503b6504d914fa--c6c2a6503231479a82cf8aacbf9b04c8 e086760c76ee4229b59f1d8720f5f63c c6c2a6503231479a82cf8aacbf9b04c8--e086760c76ee4229b59f1d8720f5f63c ce9a03311e2f4fccbaa19e660f41d7d9 e086760c76ee4229b59f1d8720f5f63c--ce9a03311e2f4fccbaa19e660f41d7d9 12acad06f9dc487b87d243fe8499970a ce9a03311e2f4fccbaa19e660f41d7d9--12acad06f9dc487b87d243fe8499970a dd4f6ea04bbb4ebfbd6f01f5fe553b17 12acad06f9dc487b87d243fe8499970a--dd4f6ea04bbb4ebfbd6f01f5fe553b17 17a3751c76994f23af9b7c141d141d20 dd4f6ea04bbb4ebfbd6f01f5fe553b17--17a3751c76994f23af9b7c141d141d20 348da5c1244f467396787adf3c9f3811 X 17a3751c76994f23af9b7c141d141d20--348da5c1244f467396787adf3c9f3811 348da5c1244f467396787adf3c9f3811--b8cc389cd2754d8fa68d61b142ba707c 52eea677a6754e389b911b5f65fdb6d0 X 348da5c1244f467396787adf3c9f3811--52eea677a6754e389b911b5f65fdb6d0 52eea677a6754e389b911b5f65fdb6d0--7f70650e82c249ceb7c24c503452a1d1 e304de226371408eb86b7f11ef95735a 52eea677a6754e389b911b5f65fdb6d0--e304de226371408eb86b7f11ef95735a 3eae92c735e742e481260fe474764c13 e304de226371408eb86b7f11ef95735a--3eae92c735e742e481260fe474764c13 da22be3fb4d44929887ec232ee32b278 3eae92c735e742e481260fe474764c13--da22be3fb4d44929887ec232ee32b278 1385899e10644c8a997bb9210c0f3f61 da22be3fb4d44929887ec232ee32b278--1385899e10644c8a997bb9210c0f3f61 76fe1d6600ce4f5db0541070bb5f3dc0 1385899e10644c8a997bb9210c0f3f61--76fe1d6600ce4f5db0541070bb5f3dc0 e44994eed03f422bb68cdff26c003bdb 76fe1d6600ce4f5db0541070bb5f3dc0--e44994eed03f422bb68cdff26c003bdb 53bbbfdcd83e471bae99a2032e1e32a8 e44994eed03f422bb68cdff26c003bdb--53bbbfdcd83e471bae99a2032e1e32a8 fda47cd43c5b4a02ac4d6915735b408c 53bbbfdcd83e471bae99a2032e1e32a8--fda47cd43c5b4a02ac4d6915735b408c 1f44f9bbe68547c6a7c58368643f0f40 fda47cd43c5b4a02ac4d6915735b408c--1f44f9bbe68547c6a7c58368643f0f40 401c634968464d4ca33a82e8a964fcbc X 1f44f9bbe68547c6a7c58368643f0f40--401c634968464d4ca33a82e8a964fcbc 401c634968464d4ca33a82e8a964fcbc--4f75a0652b3c48bc9951b46cf211e84d 3050e77f719a4be9a7b099b550854459 X 401c634968464d4ca33a82e8a964fcbc--3050e77f719a4be9a7b099b550854459 3050e77f719a4be9a7b099b550854459--ce252522de0242a1ae751f9d632580b4 7ea4370d0b0e4e4498f27a6e5faf203b 3050e77f719a4be9a7b099b550854459--7ea4370d0b0e4e4498f27a6e5faf203b e52e38097cb54585b0b48c6d1e32c345 7ea4370d0b0e4e4498f27a6e5faf203b--e52e38097cb54585b0b48c6d1e32c345 d21c4001dc524a48b165175d765aa8c0 e52e38097cb54585b0b48c6d1e32c345--d21c4001dc524a48b165175d765aa8c0 b90fffc7243a41f18d4f25f3d33ae3a1 d21c4001dc524a48b165175d765aa8c0--b90fffc7243a41f18d4f25f3d33ae3a1 dc59bc0a77714aa0b6b6531f8eab992a b90fffc7243a41f18d4f25f3d33ae3a1--dc59bc0a77714aa0b6b6531f8eab992a 397847fb3d8d4b5e9acc0fdb2129f920 dc59bc0a77714aa0b6b6531f8eab992a--397847fb3d8d4b5e9acc0fdb2129f920 69fb510a027e4102a2902f823f014338 397847fb3d8d4b5e9acc0fdb2129f920--69fb510a027e4102a2902f823f014338 f3004c872e13461cb05a59fd1bc5af57 69fb510a027e4102a2902f823f014338--f3004c872e13461cb05a59fd1bc5af57 558106dd3a534df1b070b35825fc73af f3004c872e13461cb05a59fd1bc5af57--558106dd3a534df1b070b35825fc73af 7d98d0f9b0454f09b3e5f5d8874d9e8e 558106dd3a534df1b070b35825fc73af--7d98d0f9b0454f09b3e5f5d8874d9e8e 84ba85233a064f869211162bc3c96e08 7d98d0f9b0454f09b3e5f5d8874d9e8e--84ba85233a064f869211162bc3c96e08 32bc6d22cd484f8bb2a092ac6683b718 X 84ba85233a064f869211162bc3c96e08--32bc6d22cd484f8bb2a092ac6683b718 32bc6d22cd484f8bb2a092ac6683b718--2bdec34dc37a41c5b2e173d89341f35e 7ef49130c7c74c6e8dae213a9ce662c4 X 32bc6d22cd484f8bb2a092ac6683b718--7ef49130c7c74c6e8dae213a9ce662c4 7ef49130c7c74c6e8dae213a9ce662c4--19130bac9fd04967a0fcd6ca551b74a1 a7e93ddf9d394f1a8c122b5e9fcce1cc 7ef49130c7c74c6e8dae213a9ce662c4--a7e93ddf9d394f1a8c122b5e9fcce1cc fc7a8684b9c64e68aca853320946f6e7 a7e93ddf9d394f1a8c122b5e9fcce1cc--fc7a8684b9c64e68aca853320946f6e7 41339789b9fd4d209c32dcb28e28bb3f fc7a8684b9c64e68aca853320946f6e7--41339789b9fd4d209c32dcb28e28bb3f 5e2543552d1642929c89a0e9f5253b0f 41339789b9fd4d209c32dcb28e28bb3f--5e2543552d1642929c89a0e9f5253b0f dfc34eacb8d74a5f91885bc67a0127af 5e2543552d1642929c89a0e9f5253b0f--dfc34eacb8d74a5f91885bc67a0127af b00a42f6353e4c7485d28b7a28ddb5b2 dfc34eacb8d74a5f91885bc67a0127af--b00a42f6353e4c7485d28b7a28ddb5b2 e527b34ead8f4435b0e14111c505028d b00a42f6353e4c7485d28b7a28ddb5b2--e527b34ead8f4435b0e14111c505028d 303f817054de459c8befcc77af80bccf e527b34ead8f4435b0e14111c505028d--303f817054de459c8befcc77af80bccf 5e2cdd8272fe40bdabfeb7854c8de5e0 303f817054de459c8befcc77af80bccf--5e2cdd8272fe40bdabfeb7854c8de5e0 edad8736944348468da7918d27ac531d 5e2cdd8272fe40bdabfeb7854c8de5e0--edad8736944348468da7918d27ac531d af504e1417214174aba0c7637970add4 edad8736944348468da7918d27ac531d--af504e1417214174aba0c7637970add4 4fdff1bb244e4c6f8f44d0b7a19e1ff4 af504e1417214174aba0c7637970add4--4fdff1bb244e4c6f8f44d0b7a19e1ff4 e7e1b1b449e34b869bab75c0f465eaae 4fdff1bb244e4c6f8f44d0b7a19e1ff4--e7e1b1b449e34b869bab75c0f465eaae 2f7e73c87994477b9b29a8d24f1ebb0e X e7e1b1b449e34b869bab75c0f465eaae--2f7e73c87994477b9b29a8d24f1ebb0e 2f7e73c87994477b9b29a8d24f1ebb0e--dc18671ecbf7461591343ea32736d8a7 90d096888e024fcf91b93f850e044731 2f7e73c87994477b9b29a8d24f1ebb0e--90d096888e024fcf91b93f850e044731 3fbd2e082ba8427396d3f7c4f5326b17 90d096888e024fcf91b93f850e044731--3fbd2e082ba8427396d3f7c4f5326b17 fb0ab88856fe48fca1414cf341e80574 3fbd2e082ba8427396d3f7c4f5326b17--fb0ab88856fe48fca1414cf341e80574 ee566142154b41e2b75ed85e526ef9c0 fb0ab88856fe48fca1414cf341e80574--ee566142154b41e2b75ed85e526ef9c0 c54e53896130424d85fa8cf8c8570560 ee566142154b41e2b75ed85e526ef9c0--c54e53896130424d85fa8cf8c8570560 df994ff20e0445ffabf24cbf9058c865 c54e53896130424d85fa8cf8c8570560--df994ff20e0445ffabf24cbf9058c865 d420e43b162c4cbf89f824ce6eb9392e df994ff20e0445ffabf24cbf9058c865--d420e43b162c4cbf89f824ce6eb9392e 22eadf0e653c43368c6574f6163cfe69 d420e43b162c4cbf89f824ce6eb9392e--22eadf0e653c43368c6574f6163cfe69 2a1e439c0bad484ba41f9cf739b7502d 22eadf0e653c43368c6574f6163cfe69--2a1e439c0bad484ba41f9cf739b7502d 715e4da02d994f299d95eb002c0a82ac 2a1e439c0bad484ba41f9cf739b7502d--715e4da02d994f299d95eb002c0a82ac 60f85cb2df784a55a56e5fcb29695f96 715e4da02d994f299d95eb002c0a82ac--60f85cb2df784a55a56e5fcb29695f96 38d462c51d0545a5a54226d3b7e87174 60f85cb2df784a55a56e5fcb29695f96--38d462c51d0545a5a54226d3b7e87174 fe2272ed3fdb4f99856cb2f5b01f9cc3 38d462c51d0545a5a54226d3b7e87174--fe2272ed3fdb4f99856cb2f5b01f9cc3 1ee3ab608b7f4ac986965e0ad2055059 fe2272ed3fdb4f99856cb2f5b01f9cc3--1ee3ab608b7f4ac986965e0ad2055059 2240cbc0250c4900b8c8b2fc6afd441c 1ee3ab608b7f4ac986965e0ad2055059--2240cbc0250c4900b8c8b2fc6afd441c a57cf06408a441c2ab31984134f64ff9 2240cbc0250c4900b8c8b2fc6afd441c--a57cf06408a441c2ab31984134f64ff9 3c7fd8b34a6a4e3b8898d7a24fb5b031 a57cf06408a441c2ab31984134f64ff9--3c7fd8b34a6a4e3b8898d7a24fb5b031 4a00cfecf4b546bda3b516ee9f3f84cf 3c7fd8b34a6a4e3b8898d7a24fb5b031--4a00cfecf4b546bda3b516ee9f3f84cf b17c538203ee479f873f9fc672cd707b 4a00cfecf4b546bda3b516ee9f3f84cf--b17c538203ee479f873f9fc672cd707b 672665b6f2764a529d64abe5356c616b b17c538203ee479f873f9fc672cd707b--672665b6f2764a529d64abe5356c616b 38f718d3fe84468da28179f131c1e8a8 672665b6f2764a529d64abe5356c616b--38f718d3fe84468da28179f131c1e8a8 d71e637097a4403f8e6916102216334c 38f718d3fe84468da28179f131c1e8a8--d71e637097a4403f8e6916102216334c a10adff104d644e18069d281e2ad7d9f d71e637097a4403f8e6916102216334c--a10adff104d644e18069d281e2ad7d9f 5fb10d2b746140a1b8f3745c8650c77b a10adff104d644e18069d281e2ad7d9f--5fb10d2b746140a1b8f3745c8650c77b c4566f1b385b466fb79686d1c66e2fb8 5fb10d2b746140a1b8f3745c8650c77b--c4566f1b385b466fb79686d1c66e2fb8 10d613eeac25465e9f98c9933d4286d6 c4566f1b385b466fb79686d1c66e2fb8--10d613eeac25465e9f98c9933d4286d6 ff5761caa99147bfa3364c767066a6e1 10d613eeac25465e9f98c9933d4286d6--ff5761caa99147bfa3364c767066a6e1 09fefa18bd19480a9e150032ddc1fe7b ff5761caa99147bfa3364c767066a6e1--09fefa18bd19480a9e150032ddc1fe7b 6f64d62bd81e4477a8484acfece9a042 09fefa18bd19480a9e150032ddc1fe7b--6f64d62bd81e4477a8484acfece9a042 12dde247a35542959beb92be51bea306 6f64d62bd81e4477a8484acfece9a042--12dde247a35542959beb92be51bea306 8e7abb7d601d44a194a159a0f98c8ac5 12dde247a35542959beb92be51bea306--8e7abb7d601d44a194a159a0f98c8ac5 814a168728b74ed988e6a73260ab85e5 8e7abb7d601d44a194a159a0f98c8ac5--814a168728b74ed988e6a73260ab85e5 5f7bacbadb904d09ada2baa6bd6e3b87 814a168728b74ed988e6a73260ab85e5--5f7bacbadb904d09ada2baa6bd6e3b87 d202be797f63498dbb718299f6c2ed84 5f7bacbadb904d09ada2baa6bd6e3b87--d202be797f63498dbb718299f6c2ed84 3f85addfd70e43698f8d94c7f212a70d d202be797f63498dbb718299f6c2ed84--3f85addfd70e43698f8d94c7f212a70d e95c90902a38491fa10179bf80f55572 3f85addfd70e43698f8d94c7f212a70d--e95c90902a38491fa10179bf80f55572 5356beb880f144cea5bdc0899968a051 e95c90902a38491fa10179bf80f55572--5356beb880f144cea5bdc0899968a051 f836140ce64e4bde8b6d16f820cfd729 5356beb880f144cea5bdc0899968a051--f836140ce64e4bde8b6d16f820cfd729 db360015da7d41829b73214a55fcc1c4 f836140ce64e4bde8b6d16f820cfd729--db360015da7d41829b73214a55fcc1c4 74ec55534f424548800338a5908b03e4 db360015da7d41829b73214a55fcc1c4--74ec55534f424548800338a5908b03e4 974ef2b1f43b40a0bcd64d7078462831 74ec55534f424548800338a5908b03e4--974ef2b1f43b40a0bcd64d7078462831 be09212d0edf46599008005957d388ae 974ef2b1f43b40a0bcd64d7078462831--be09212d0edf46599008005957d388ae 3afda58a096346f5b3dd0c7420fa628a be09212d0edf46599008005957d388ae--3afda58a096346f5b3dd0c7420fa628a 2951dbf11eb04155ada32f1946e3c886 3afda58a096346f5b3dd0c7420fa628a--2951dbf11eb04155ada32f1946e3c886 a645e1fa45d54b9a9e22381ebb57f226 2951dbf11eb04155ada32f1946e3c886--a645e1fa45d54b9a9e22381ebb57f226 6a5a7409ead54fc5bca9c1557d4db255 a645e1fa45d54b9a9e22381ebb57f226--6a5a7409ead54fc5bca9c1557d4db255 d3d463043005437191ae49d95bc487ff 6a5a7409ead54fc5bca9c1557d4db255--d3d463043005437191ae49d95bc487ff 4a5f02d6279341908d34e86fa9cb5b70 d3d463043005437191ae49d95bc487ff--4a5f02d6279341908d34e86fa9cb5b70 8d890a968da0487fb71f21d72232d52d 4a5f02d6279341908d34e86fa9cb5b70--8d890a968da0487fb71f21d72232d52d 1d44a7db6ef54227ad3609b11c2cbf1c 8d890a968da0487fb71f21d72232d52d--1d44a7db6ef54227ad3609b11c2cbf1c 8c0592bc7ef94b46b64c44441bbc3557 1d44a7db6ef54227ad3609b11c2cbf1c--8c0592bc7ef94b46b64c44441bbc3557 230f3f8e450f4bc1ad5db9a856b4cd6e 8c0592bc7ef94b46b64c44441bbc3557--230f3f8e450f4bc1ad5db9a856b4cd6e a88cebc235a54092850b3c2ed27043bc 230f3f8e450f4bc1ad5db9a856b4cd6e--a88cebc235a54092850b3c2ed27043bc 185624dcd73d4d74a5f136da5fe8c9c9 a88cebc235a54092850b3c2ed27043bc--185624dcd73d4d74a5f136da5fe8c9c9 eb3ff9bc60af49e3860da5cab34d3b8f 185624dcd73d4d74a5f136da5fe8c9c9--eb3ff9bc60af49e3860da5cab34d3b8f a152f59189644776bb429a14c17e16fd eb3ff9bc60af49e3860da5cab34d3b8f--a152f59189644776bb429a14c17e16fd e2799a1003a44d2c8403ae682e36a9e5 a152f59189644776bb429a14c17e16fd--e2799a1003a44d2c8403ae682e36a9e5 549a5f27e8e3445f8653c7215c439880 e2799a1003a44d2c8403ae682e36a9e5--549a5f27e8e3445f8653c7215c439880 e2f9cf6493694e12af0068fa38f1be55 549a5f27e8e3445f8653c7215c439880--e2f9cf6493694e12af0068fa38f1be55 325892dfd6f74baf9d4631d75133b7e5 e2f9cf6493694e12af0068fa38f1be55--325892dfd6f74baf9d4631d75133b7e5 e1f64fb55ee24497ada9291cf14958e1 325892dfd6f74baf9d4631d75133b7e5--e1f64fb55ee24497ada9291cf14958e1 56de305e08d940848ac947bc04158ef4 e1f64fb55ee24497ada9291cf14958e1--56de305e08d940848ac947bc04158ef4 67fe8989201448bb9a85b47ebc5960f6 56de305e08d940848ac947bc04158ef4--67fe8989201448bb9a85b47ebc5960f6 c3b791657be845569d97bf218477979f 67fe8989201448bb9a85b47ebc5960f6--c3b791657be845569d97bf218477979f 1ac9d8d9deb94785958fbbfb3c22fcc9 c3b791657be845569d97bf218477979f--1ac9d8d9deb94785958fbbfb3c22fcc9 50ff01d12dd7492887f473ec4731a755 1ac9d8d9deb94785958fbbfb3c22fcc9--50ff01d12dd7492887f473ec4731a755 66322ebf0e9f4da687d725376ff3701f 50ff01d12dd7492887f473ec4731a755--66322ebf0e9f4da687d725376ff3701f 06b202124b0d47c491f816fe3dfdc5d7 66322ebf0e9f4da687d725376ff3701f--06b202124b0d47c491f816fe3dfdc5d7 57a5a2a333454402a0d861b5486e35ed RX(b01) 06b202124b0d47c491f816fe3dfdc5d7--57a5a2a333454402a0d861b5486e35ed 23108234e6d042e1990b695dafeea91a X 57a5a2a333454402a0d861b5486e35ed--23108234e6d042e1990b695dafeea91a 23108234e6d042e1990b695dafeea91a--221193174a914ff28cd652935e379dcb d11b515f10734ecd925caf855abd1518 23108234e6d042e1990b695dafeea91a--d11b515f10734ecd925caf855abd1518 d46d8d501c254de1bb6f53ab8ce930ae d11b515f10734ecd925caf855abd1518--d46d8d501c254de1bb6f53ab8ce930ae 2b969488fd3f44a4b84fee346ab773ac d46d8d501c254de1bb6f53ab8ce930ae--2b969488fd3f44a4b84fee346ab773ac 1fb63c610eff4941ba00431b57691383 2b969488fd3f44a4b84fee346ab773ac--1fb63c610eff4941ba00431b57691383 92248e96962346e381fb81c133096cc0 1fb63c610eff4941ba00431b57691383--92248e96962346e381fb81c133096cc0 0c3e053bc76240458048c0e7b04a6960 92248e96962346e381fb81c133096cc0--0c3e053bc76240458048c0e7b04a6960 e0fb14f4ae954eba88870bcc588f1d7f 0c3e053bc76240458048c0e7b04a6960--e0fb14f4ae954eba88870bcc588f1d7f ff44e7e90a714c86873e93a1eeadb35e e0fb14f4ae954eba88870bcc588f1d7f--ff44e7e90a714c86873e93a1eeadb35e d9377d60bd6e410695192215e450baea ff44e7e90a714c86873e93a1eeadb35e--d9377d60bd6e410695192215e450baea b153c9eb85b44e889557e772abc44166 d9377d60bd6e410695192215e450baea--b153c9eb85b44e889557e772abc44166 61a4547b40b84917a9a24c32cbbb5354 b153c9eb85b44e889557e772abc44166--61a4547b40b84917a9a24c32cbbb5354 5a1d323cb4b2446db9060f6ae0bc8d8b 61a4547b40b84917a9a24c32cbbb5354--5a1d323cb4b2446db9060f6ae0bc8d8b 3b7efacb0e324f63beea043b13fa23b3 5a1d323cb4b2446db9060f6ae0bc8d8b--3b7efacb0e324f63beea043b13fa23b3 ac47b7d2c7d24e3e975316973fd32729 X 3b7efacb0e324f63beea043b13fa23b3--ac47b7d2c7d24e3e975316973fd32729 ac47b7d2c7d24e3e975316973fd32729--4763fb1d35574d41bd54bc725a145afa f9965e75cab44f41a1dbb4efc8dce83f X ac47b7d2c7d24e3e975316973fd32729--f9965e75cab44f41a1dbb4efc8dce83f f9965e75cab44f41a1dbb4efc8dce83f--683f4caf24224643a58232d989d18d32 f2b5981bbb834a66a80032927fef470c f9965e75cab44f41a1dbb4efc8dce83f--f2b5981bbb834a66a80032927fef470c 2a19c8e488e44edb8eb99ce6b4be8e4e f2b5981bbb834a66a80032927fef470c--2a19c8e488e44edb8eb99ce6b4be8e4e 9ee9f5c8208b4ce68add95b1c75483fe 2a19c8e488e44edb8eb99ce6b4be8e4e--9ee9f5c8208b4ce68add95b1c75483fe 7be4228b998a4cd1b124ad62db2770f4 9ee9f5c8208b4ce68add95b1c75483fe--7be4228b998a4cd1b124ad62db2770f4 b480960815894151933ffb5718252a68 7be4228b998a4cd1b124ad62db2770f4--b480960815894151933ffb5718252a68 67edb5b6889642ca97d9baeb7773d843 b480960815894151933ffb5718252a68--67edb5b6889642ca97d9baeb7773d843 255f149ae2e4498699477f07a44504cc 67edb5b6889642ca97d9baeb7773d843--255f149ae2e4498699477f07a44504cc 161d34edec34465d86776a7b3d11c70b X 255f149ae2e4498699477f07a44504cc--161d34edec34465d86776a7b3d11c70b 161d34edec34465d86776a7b3d11c70b--d3f3a55c8fd5479cb1ae6cf1333148ad 7eedab3164694002b35774fb0c64b188 X 161d34edec34465d86776a7b3d11c70b--7eedab3164694002b35774fb0c64b188 7eedab3164694002b35774fb0c64b188--788d1970d52540c192bfd8e217765b32 1d76bc43541e4066a5931051b6918e03 7eedab3164694002b35774fb0c64b188--1d76bc43541e4066a5931051b6918e03 fb8d7aa62f1e4ad58ff7b9252886ad12 1d76bc43541e4066a5931051b6918e03--fb8d7aa62f1e4ad58ff7b9252886ad12 2abf41ae932e4965aaaf716b16638868 fb8d7aa62f1e4ad58ff7b9252886ad12--2abf41ae932e4965aaaf716b16638868 737480a4345243139ff3d0e5b8221138 2abf41ae932e4965aaaf716b16638868--737480a4345243139ff3d0e5b8221138 5a0825f7a7554797a30d0c7d298fb6cb 737480a4345243139ff3d0e5b8221138--5a0825f7a7554797a30d0c7d298fb6cb edecc635acfe49f196102300592ed573 5a0825f7a7554797a30d0c7d298fb6cb--edecc635acfe49f196102300592ed573 5d7bff8b4eaf40f49780e3dfd7b40529 edecc635acfe49f196102300592ed573--5d7bff8b4eaf40f49780e3dfd7b40529 4560dddd7d4f4799a29f7428a5120406 5d7bff8b4eaf40f49780e3dfd7b40529--4560dddd7d4f4799a29f7428a5120406 25837f8f75f44a5a99bf7f39f48e5d1e 4560dddd7d4f4799a29f7428a5120406--25837f8f75f44a5a99bf7f39f48e5d1e c5527cfbd68f4db0a393d6dc2255f5eb X 25837f8f75f44a5a99bf7f39f48e5d1e--c5527cfbd68f4db0a393d6dc2255f5eb c5527cfbd68f4db0a393d6dc2255f5eb--c4f6d190a94942ff8e6240b6f8c30e84 6f3a4d51edad4407828aa35c0fc36982 X c5527cfbd68f4db0a393d6dc2255f5eb--6f3a4d51edad4407828aa35c0fc36982 6f3a4d51edad4407828aa35c0fc36982--bfba0276b5644a378677cd06081c513f 409cdbd838e34939a2ff9dafd712708e 6f3a4d51edad4407828aa35c0fc36982--409cdbd838e34939a2ff9dafd712708e e991930a4d4740e4a15f44a41b034409 409cdbd838e34939a2ff9dafd712708e--e991930a4d4740e4a15f44a41b034409 44c998ff989b4aafb6d618642ec22093 e991930a4d4740e4a15f44a41b034409--44c998ff989b4aafb6d618642ec22093 c1daceb742fb482b9965d0c827749c56 44c998ff989b4aafb6d618642ec22093--c1daceb742fb482b9965d0c827749c56 4071feb57dbf4e96b95279a30aea3f31 c1daceb742fb482b9965d0c827749c56--4071feb57dbf4e96b95279a30aea3f31 886da674f8744246b8d45b208ea8e239 4071feb57dbf4e96b95279a30aea3f31--886da674f8744246b8d45b208ea8e239 54ed282816b442ecb901096a79a20ba2 886da674f8744246b8d45b208ea8e239--54ed282816b442ecb901096a79a20ba2 ca74195888464f58a283971ee443b2b1 54ed282816b442ecb901096a79a20ba2--ca74195888464f58a283971ee443b2b1 3421eeb19ca74ebdb47beda5d47c5786 ca74195888464f58a283971ee443b2b1--3421eeb19ca74ebdb47beda5d47c5786 ff3775f618564ad3977bbcad5bee1a78 3421eeb19ca74ebdb47beda5d47c5786--ff3775f618564ad3977bbcad5bee1a78 34226bd1c54c4bbe8d9b211c0b8b0b97 ff3775f618564ad3977bbcad5bee1a78--34226bd1c54c4bbe8d9b211c0b8b0b97 bd0eb9b574304422b72009aed60ebcfa X 34226bd1c54c4bbe8d9b211c0b8b0b97--bd0eb9b574304422b72009aed60ebcfa bd0eb9b574304422b72009aed60ebcfa--faf40b9230544ebab09c785566975878 0c8e1b8de9f04faa90260592b4658403 X bd0eb9b574304422b72009aed60ebcfa--0c8e1b8de9f04faa90260592b4658403 0c8e1b8de9f04faa90260592b4658403--c3c865574fb34f1fb2a00dd7efad02a4 38706492d2144934835df01106f8fff8 0c8e1b8de9f04faa90260592b4658403--38706492d2144934835df01106f8fff8 2d8f4818daa941f9858b29e4026f2385 38706492d2144934835df01106f8fff8--2d8f4818daa941f9858b29e4026f2385 7395164ad1a94e41828da978a29ebb26 2d8f4818daa941f9858b29e4026f2385--7395164ad1a94e41828da978a29ebb26 8c830b1e1bd54ac2bd623445061f9f4a 7395164ad1a94e41828da978a29ebb26--8c830b1e1bd54ac2bd623445061f9f4a 79dd203db0b843f1a973b67add2576a4 8c830b1e1bd54ac2bd623445061f9f4a--79dd203db0b843f1a973b67add2576a4 b9ab61bed6744354b41377fe7abfd83a 79dd203db0b843f1a973b67add2576a4--b9ab61bed6744354b41377fe7abfd83a 12525301aa544a75951f24876e1ff78f b9ab61bed6744354b41377fe7abfd83a--12525301aa544a75951f24876e1ff78f 38d8d726f3c945788bcd9ed1f661dd8b 12525301aa544a75951f24876e1ff78f--38d8d726f3c945788bcd9ed1f661dd8b 6698ce33f5284678a17a4c20b55fc26e 38d8d726f3c945788bcd9ed1f661dd8b--6698ce33f5284678a17a4c20b55fc26e 643b10fcc5ad453d99afbc879ef61787 6698ce33f5284678a17a4c20b55fc26e--643b10fcc5ad453d99afbc879ef61787 9b02c26645d443818091a49ca4bcc289 643b10fcc5ad453d99afbc879ef61787--9b02c26645d443818091a49ca4bcc289 c70f37d7befe4b989c81a18a8eaac0a0 9b02c26645d443818091a49ca4bcc289--c70f37d7befe4b989c81a18a8eaac0a0 f4de4fef465c43528a4c9bccd88c308f c70f37d7befe4b989c81a18a8eaac0a0--f4de4fef465c43528a4c9bccd88c308f c21ee8efd2274ad0b8906e89915c29a0 X f4de4fef465c43528a4c9bccd88c308f--c21ee8efd2274ad0b8906e89915c29a0 c21ee8efd2274ad0b8906e89915c29a0--ef207fee7b4a49e9a4fde171cf0e1556 f99d4ab42cee4904ad6d8486fad1e5e3 c21ee8efd2274ad0b8906e89915c29a0--f99d4ab42cee4904ad6d8486fad1e5e3 efb4c148a00e40e8abf164126b6fa269 f99d4ab42cee4904ad6d8486fad1e5e3--efb4c148a00e40e8abf164126b6fa269 2414dc1b91cd4895906957488c2625a9 efb4c148a00e40e8abf164126b6fa269--2414dc1b91cd4895906957488c2625a9 3eedfcaaf9a0470b989292d68d4066f3 2414dc1b91cd4895906957488c2625a9--3eedfcaaf9a0470b989292d68d4066f3 7d79bc9da99d4b89b0347c84755c2253 3eedfcaaf9a0470b989292d68d4066f3--7d79bc9da99d4b89b0347c84755c2253 03a85c77ebed4d91b7b53efba9a48782 7d79bc9da99d4b89b0347c84755c2253--03a85c77ebed4d91b7b53efba9a48782 db2151fa53f94f0bb40235fcadf90d86 03a85c77ebed4d91b7b53efba9a48782--db2151fa53f94f0bb40235fcadf90d86 39e9a4ed5b81424d9d260a1fedf09586 db2151fa53f94f0bb40235fcadf90d86--39e9a4ed5b81424d9d260a1fedf09586 76d9bd79a8b14d609e3cf178e2694f4b 39e9a4ed5b81424d9d260a1fedf09586--76d9bd79a8b14d609e3cf178e2694f4b 8aae0d6d2b6541ec94ad564670775d2b 76d9bd79a8b14d609e3cf178e2694f4b--8aae0d6d2b6541ec94ad564670775d2b f9aedf8335174e32947c57444cf5a14c 8aae0d6d2b6541ec94ad564670775d2b--f9aedf8335174e32947c57444cf5a14c 238c7e12859f458d9b68df0acae0872a f9aedf8335174e32947c57444cf5a14c--238c7e12859f458d9b68df0acae0872a ba9ecb51418843f6a2e2b25baa0002a3 238c7e12859f458d9b68df0acae0872a--ba9ecb51418843f6a2e2b25baa0002a3 e1939570ebdf43589103166588bac322 ba9ecb51418843f6a2e2b25baa0002a3--e1939570ebdf43589103166588bac322 e558989bb3c14932a72d20371d400427 e1939570ebdf43589103166588bac322--e558989bb3c14932a72d20371d400427 69cab1d1222f439e92b4b83561c5377c e558989bb3c14932a72d20371d400427--69cab1d1222f439e92b4b83561c5377c 7273562c21244a50b0ad7e10ad5a4c66 69cab1d1222f439e92b4b83561c5377c--7273562c21244a50b0ad7e10ad5a4c66 f5ddd7fafba94627a9fbcc1f5f72f427 7273562c21244a50b0ad7e10ad5a4c66--f5ddd7fafba94627a9fbcc1f5f72f427 a515a836f50044ed80961b020f594a32 f5ddd7fafba94627a9fbcc1f5f72f427--a515a836f50044ed80961b020f594a32 edb87052493e4aeabcced2299ddc1310 a515a836f50044ed80961b020f594a32--edb87052493e4aeabcced2299ddc1310 be560749b45d4a149cb8c066f1837c7f edb87052493e4aeabcced2299ddc1310--be560749b45d4a149cb8c066f1837c7f 2154c54ed5f94e8a853613df549b768b be560749b45d4a149cb8c066f1837c7f--2154c54ed5f94e8a853613df549b768b f4fb46d7304943d59246a9cc6fa4ca49 2154c54ed5f94e8a853613df549b768b--f4fb46d7304943d59246a9cc6fa4ca49 70f7271ceb1a467dbaf45fb05ab7bd02 f4fb46d7304943d59246a9cc6fa4ca49--70f7271ceb1a467dbaf45fb05ab7bd02 09a6dd7f5f9c430f8b695f270bb9e503 70f7271ceb1a467dbaf45fb05ab7bd02--09a6dd7f5f9c430f8b695f270bb9e503 28fec28be633426287dc8fb122cba255 09a6dd7f5f9c430f8b695f270bb9e503--28fec28be633426287dc8fb122cba255 3e1e3a115ffc48fbbcb55ff7391a0771 28fec28be633426287dc8fb122cba255--3e1e3a115ffc48fbbcb55ff7391a0771 6c55e99f2bc64055882ebd61d38daffd 3e1e3a115ffc48fbbcb55ff7391a0771--6c55e99f2bc64055882ebd61d38daffd a2a85bdd6812435f855aac78c15480b6 6c55e99f2bc64055882ebd61d38daffd--a2a85bdd6812435f855aac78c15480b6 650959dde3464c61b4fa4150a4be0fc4 a2a85bdd6812435f855aac78c15480b6--650959dde3464c61b4fa4150a4be0fc4 70b674d721694f54969f80f193833fac 650959dde3464c61b4fa4150a4be0fc4--70b674d721694f54969f80f193833fac 6b9432d2685740f7aa898135629ec6db 70b674d721694f54969f80f193833fac--6b9432d2685740f7aa898135629ec6db 50a9d79c35da4bb8867cd594de41691b 6b9432d2685740f7aa898135629ec6db--50a9d79c35da4bb8867cd594de41691b 9e5ec640e0e045138d79c31278698521 50a9d79c35da4bb8867cd594de41691b--9e5ec640e0e045138d79c31278698521 fe789c4bd50741199109564727cc9c59 9e5ec640e0e045138d79c31278698521--fe789c4bd50741199109564727cc9c59 d238a28743b144d589a3d85a3df174f5 fe789c4bd50741199109564727cc9c59--d238a28743b144d589a3d85a3df174f5 c06482a4c6b7480092f8245509ad950f d238a28743b144d589a3d85a3df174f5--c06482a4c6b7480092f8245509ad950f 1d52b22239314919b6587b06dabc0f0b c06482a4c6b7480092f8245509ad950f--1d52b22239314919b6587b06dabc0f0b c193f3b3f2df41568cd4dd33c154a291 1d52b22239314919b6587b06dabc0f0b--c193f3b3f2df41568cd4dd33c154a291 64ec031138304f7299876ff30a410866 c193f3b3f2df41568cd4dd33c154a291--64ec031138304f7299876ff30a410866 e983530ec565456d91f0dd74bda90e74 64ec031138304f7299876ff30a410866--e983530ec565456d91f0dd74bda90e74 fd85741348ef4dec818dde115f75db06 e983530ec565456d91f0dd74bda90e74--fd85741348ef4dec818dde115f75db06 c3f6eb6877c24353be97c4b118d4ad90 fd85741348ef4dec818dde115f75db06--c3f6eb6877c24353be97c4b118d4ad90 a30a79573f7541cdb1495fddf4740d79 c3f6eb6877c24353be97c4b118d4ad90--a30a79573f7541cdb1495fddf4740d79 2c98a4e717554c08b68ba50214fcfba3 a30a79573f7541cdb1495fddf4740d79--2c98a4e717554c08b68ba50214fcfba3 0bdc8a594b7d4a1ea9e9b24090f2b7b2 2c98a4e717554c08b68ba50214fcfba3--0bdc8a594b7d4a1ea9e9b24090f2b7b2 58257d4e15264d33bba34942dbdb384e 0bdc8a594b7d4a1ea9e9b24090f2b7b2--58257d4e15264d33bba34942dbdb384e 26158509a4c24d629e9c5fe773d5bb51 58257d4e15264d33bba34942dbdb384e--26158509a4c24d629e9c5fe773d5bb51 926d3206fe924509bb0ffa836135c916 26158509a4c24d629e9c5fe773d5bb51--926d3206fe924509bb0ffa836135c916 c9f90c5c286e4046a22cefa86754e92f 926d3206fe924509bb0ffa836135c916--c9f90c5c286e4046a22cefa86754e92f 626c2e96d7844df48673da5607ab6c4d c9f90c5c286e4046a22cefa86754e92f--626c2e96d7844df48673da5607ab6c4d ae336b1e89aa4a70ac135fe6d404a91b 626c2e96d7844df48673da5607ab6c4d--ae336b1e89aa4a70ac135fe6d404a91b 3f98876259924a5aa81ecbcdec623975 ae336b1e89aa4a70ac135fe6d404a91b--3f98876259924a5aa81ecbcdec623975 f609205e6d6f43289743153933b986d2 3f98876259924a5aa81ecbcdec623975--f609205e6d6f43289743153933b986d2 b4d2699e53fc407eb1f4e0f053d838da f609205e6d6f43289743153933b986d2--b4d2699e53fc407eb1f4e0f053d838da a4131ef5625149d39f21f5876106064a b4d2699e53fc407eb1f4e0f053d838da--a4131ef5625149d39f21f5876106064a 144afb41310045eabe26d6ec4f563d2f a4131ef5625149d39f21f5876106064a--144afb41310045eabe26d6ec4f563d2f 99d3433b10e14f22b6c649902e8ed9ba 144afb41310045eabe26d6ec4f563d2f--99d3433b10e14f22b6c649902e8ed9ba 4c757d8c7bc54c94b4fd1634c5509557 99d3433b10e14f22b6c649902e8ed9ba--4c757d8c7bc54c94b4fd1634c5509557 d0c9047550dd4436b921c7384ebe9afb 4c757d8c7bc54c94b4fd1634c5509557--d0c9047550dd4436b921c7384ebe9afb d222a54891aa420a80128416b132f2ff d0c9047550dd4436b921c7384ebe9afb--d222a54891aa420a80128416b132f2ff 6187830851264e6c87fe9380cb4f4dcd d222a54891aa420a80128416b132f2ff--6187830851264e6c87fe9380cb4f4dcd 970a125c52ae44a2a209dc0094db99ec 6187830851264e6c87fe9380cb4f4dcd--970a125c52ae44a2a209dc0094db99ec 81352763a82748a1ad41bf6d9a93d339 970a125c52ae44a2a209dc0094db99ec--81352763a82748a1ad41bf6d9a93d339 e1e557875269429bb6a5e556e4786eb6 81352763a82748a1ad41bf6d9a93d339--e1e557875269429bb6a5e556e4786eb6 40ce0bfd1882471c9009748643ddf93f e1e557875269429bb6a5e556e4786eb6--40ce0bfd1882471c9009748643ddf93f 597684c436cb4151abf122e3a4297fdd 40ce0bfd1882471c9009748643ddf93f--597684c436cb4151abf122e3a4297fdd 33a82ddbc48a4b079d8c146c3a8b5617 597684c436cb4151abf122e3a4297fdd--33a82ddbc48a4b079d8c146c3a8b5617 57d2e438870f44df90f1fc396bc0ab02 RX(b11) 33a82ddbc48a4b079d8c146c3a8b5617--57d2e438870f44df90f1fc396bc0ab02 57d2e438870f44df90f1fc396bc0ab02--d4e26c58a7b84dfcba4d4f58793e4b17 f89b8de474cb4e3ba470284df0724fe4 8ab506e9809945479a559eaa856a7237 bca82a3db7ac4088a6bc067d09337cdb--8ab506e9809945479a559eaa856a7237 b820125e7a704a8c9bff9a0233c7d09f 3 4cd47aec933e4dd09f19f6c4f4512958 X 8ab506e9809945479a559eaa856a7237--4cd47aec933e4dd09f19f6c4f4512958 4cd47aec933e4dd09f19f6c4f4512958--4720c2c66f7744feaa6bcde54fad2812 b049b7015eea4c57a1f1fd98a3d72679 4cd47aec933e4dd09f19f6c4f4512958--b049b7015eea4c57a1f1fd98a3d72679 e66c3204497d4f4080e5e1dab9a37a09 b049b7015eea4c57a1f1fd98a3d72679--e66c3204497d4f4080e5e1dab9a37a09 5648977b7f82451a8f40077a91c9081c e66c3204497d4f4080e5e1dab9a37a09--5648977b7f82451a8f40077a91c9081c 19f77a248e144c00b90d0559500cdc9b 5648977b7f82451a8f40077a91c9081c--19f77a248e144c00b90d0559500cdc9b 2b98a15c345445c19720cce4209414ea 19f77a248e144c00b90d0559500cdc9b--2b98a15c345445c19720cce4209414ea 3e176d22ae644e0e90e9c65532925965 2b98a15c345445c19720cce4209414ea--3e176d22ae644e0e90e9c65532925965 3f84a719698f45259293f056945d6c1d 3e176d22ae644e0e90e9c65532925965--3f84a719698f45259293f056945d6c1d 55e86744994e4d268440eceee3c114ee 3f84a719698f45259293f056945d6c1d--55e86744994e4d268440eceee3c114ee 9f525e2f5c2e4d47bba8a82495ccaa6e 55e86744994e4d268440eceee3c114ee--9f525e2f5c2e4d47bba8a82495ccaa6e 763a26de6842414385f2a09816099fee 9f525e2f5c2e4d47bba8a82495ccaa6e--763a26de6842414385f2a09816099fee 4e9daf998c1d473480b0a9f9992ae31e 763a26de6842414385f2a09816099fee--4e9daf998c1d473480b0a9f9992ae31e cdb1125d8ecb495ab79106c08bbad805 X 4e9daf998c1d473480b0a9f9992ae31e--cdb1125d8ecb495ab79106c08bbad805 cdb1125d8ecb495ab79106c08bbad805--7d64ceebb8c2430d9eff9a9822d329ba 8c78f0b526ce4a3e9887de62f16a59a0 cdb1125d8ecb495ab79106c08bbad805--8c78f0b526ce4a3e9887de62f16a59a0 06d2717b99fe4d4a944ba3ba62b9818b 8c78f0b526ce4a3e9887de62f16a59a0--06d2717b99fe4d4a944ba3ba62b9818b 6cf86cb18c804182819f64d3b6db1046 X 06d2717b99fe4d4a944ba3ba62b9818b--6cf86cb18c804182819f64d3b6db1046 6cf86cb18c804182819f64d3b6db1046--cdb50b7347aa4af1a6503b6504d914fa 9e430b8ba70345aeb153ed3bdb139169 6cf86cb18c804182819f64d3b6db1046--9e430b8ba70345aeb153ed3bdb139169 6b9178d026dd481b9764f777d0cea735 9e430b8ba70345aeb153ed3bdb139169--6b9178d026dd481b9764f777d0cea735 cb70dcce45444d84a5047aa6b938a809 6b9178d026dd481b9764f777d0cea735--cb70dcce45444d84a5047aa6b938a809 4a717a0c3d094e1ab01d27547ba8aa01 cb70dcce45444d84a5047aa6b938a809--4a717a0c3d094e1ab01d27547ba8aa01 30189dcf5bb44a4aa4e81fa115701b07 4a717a0c3d094e1ab01d27547ba8aa01--30189dcf5bb44a4aa4e81fa115701b07 69bcead5c99a45b0bee877099bc43fce X 30189dcf5bb44a4aa4e81fa115701b07--69bcead5c99a45b0bee877099bc43fce 69bcead5c99a45b0bee877099bc43fce--17a3751c76994f23af9b7c141d141d20 9322d438f33f45a794cfb4f4709af15c 69bcead5c99a45b0bee877099bc43fce--9322d438f33f45a794cfb4f4709af15c 56954429b521474f96461bd78031e97e 9322d438f33f45a794cfb4f4709af15c--56954429b521474f96461bd78031e97e 704918d9c33e4ef58062eb44b21e6624 X 56954429b521474f96461bd78031e97e--704918d9c33e4ef58062eb44b21e6624 704918d9c33e4ef58062eb44b21e6624--e304de226371408eb86b7f11ef95735a 3fa042e168544969a157252a27cf57dd 704918d9c33e4ef58062eb44b21e6624--3fa042e168544969a157252a27cf57dd dfe6fc860ae74ae58c5c74dfe9b53c64 3fa042e168544969a157252a27cf57dd--dfe6fc860ae74ae58c5c74dfe9b53c64 956484f14c3946198cf8659753c7a82a dfe6fc860ae74ae58c5c74dfe9b53c64--956484f14c3946198cf8659753c7a82a 290d2d2566114d34902d08ec17f907cd 956484f14c3946198cf8659753c7a82a--290d2d2566114d34902d08ec17f907cd 8b43f4175fe04df895ad5bb53ae05455 290d2d2566114d34902d08ec17f907cd--8b43f4175fe04df895ad5bb53ae05455 cd90e5af18294270bdc4e5f35b3aec7c 8b43f4175fe04df895ad5bb53ae05455--cd90e5af18294270bdc4e5f35b3aec7c ce5a6a42af654dfa9524f0e1a66205c3 cd90e5af18294270bdc4e5f35b3aec7c--ce5a6a42af654dfa9524f0e1a66205c3 89c1fb856ffe43649b265e304a22bec6 X ce5a6a42af654dfa9524f0e1a66205c3--89c1fb856ffe43649b265e304a22bec6 89c1fb856ffe43649b265e304a22bec6--1f44f9bbe68547c6a7c58368643f0f40 c103f50f73bc41ddac14063abfd28bb9 89c1fb856ffe43649b265e304a22bec6--c103f50f73bc41ddac14063abfd28bb9 533bba839f794b82bc685800571bc62a c103f50f73bc41ddac14063abfd28bb9--533bba839f794b82bc685800571bc62a f2f949a77e854fcd8053255ccbce8bf8 X 533bba839f794b82bc685800571bc62a--f2f949a77e854fcd8053255ccbce8bf8 f2f949a77e854fcd8053255ccbce8bf8--7ea4370d0b0e4e4498f27a6e5faf203b 9ea803d172884bd4850363a79e7d8c90 f2f949a77e854fcd8053255ccbce8bf8--9ea803d172884bd4850363a79e7d8c90 363052a184d54952a224e7cf7677ea44 9ea803d172884bd4850363a79e7d8c90--363052a184d54952a224e7cf7677ea44 feabfd49f5d9450799ebd6c9c5d86ab4 363052a184d54952a224e7cf7677ea44--feabfd49f5d9450799ebd6c9c5d86ab4 3283b650612c4a99bbc771ae50ce4b1b feabfd49f5d9450799ebd6c9c5d86ab4--3283b650612c4a99bbc771ae50ce4b1b ac1d59b696ad468db76e43c2fe8cd482 3283b650612c4a99bbc771ae50ce4b1b--ac1d59b696ad468db76e43c2fe8cd482 f0b18f9a9ffb41aa896609b106dce76c ac1d59b696ad468db76e43c2fe8cd482--f0b18f9a9ffb41aa896609b106dce76c 6a4b987c9d894dc2a9f2b183faf6d5b0 f0b18f9a9ffb41aa896609b106dce76c--6a4b987c9d894dc2a9f2b183faf6d5b0 625161773b62475e88dc560fe64b3572 6a4b987c9d894dc2a9f2b183faf6d5b0--625161773b62475e88dc560fe64b3572 4ed45399c71848a7883bf7f892bd464b 625161773b62475e88dc560fe64b3572--4ed45399c71848a7883bf7f892bd464b c0426e80a27946428d47ef2ffef79d20 X 4ed45399c71848a7883bf7f892bd464b--c0426e80a27946428d47ef2ffef79d20 c0426e80a27946428d47ef2ffef79d20--84ba85233a064f869211162bc3c96e08 f0b3e0a052df489c823e86119bc0e2ad c0426e80a27946428d47ef2ffef79d20--f0b3e0a052df489c823e86119bc0e2ad c348d913cc4247e3b6d7f4c4ee91c1f0 f0b3e0a052df489c823e86119bc0e2ad--c348d913cc4247e3b6d7f4c4ee91c1f0 2aa930b3a076491db886d685ba54539f X c348d913cc4247e3b6d7f4c4ee91c1f0--2aa930b3a076491db886d685ba54539f 2aa930b3a076491db886d685ba54539f--a7e93ddf9d394f1a8c122b5e9fcce1cc 675aba70349b47c58753949152478cd7 2aa930b3a076491db886d685ba54539f--675aba70349b47c58753949152478cd7 1791a45a37eb48999f788e0d5d0565c4 675aba70349b47c58753949152478cd7--1791a45a37eb48999f788e0d5d0565c4 da6c5218852f481c946c1b65aa6a099b 1791a45a37eb48999f788e0d5d0565c4--da6c5218852f481c946c1b65aa6a099b d7068abac57043f2b437846bb26b35ec da6c5218852f481c946c1b65aa6a099b--d7068abac57043f2b437846bb26b35ec a3e36d0732d34a9488d23f6a675c8f92 d7068abac57043f2b437846bb26b35ec--a3e36d0732d34a9488d23f6a675c8f92 ad5a40867fca491cafd3944f5bb666e5 a3e36d0732d34a9488d23f6a675c8f92--ad5a40867fca491cafd3944f5bb666e5 431a5d882f7844999e03cc330c22955f ad5a40867fca491cafd3944f5bb666e5--431a5d882f7844999e03cc330c22955f 3fe01fb02dc0498389a44bcd0401f7fd 431a5d882f7844999e03cc330c22955f--3fe01fb02dc0498389a44bcd0401f7fd ed553925397c4e13974ef2a215f97130 3fe01fb02dc0498389a44bcd0401f7fd--ed553925397c4e13974ef2a215f97130 9343a35f36db4e1f9bf6aaee73d4beb6 ed553925397c4e13974ef2a215f97130--9343a35f36db4e1f9bf6aaee73d4beb6 7174e5df966648a78dfa2b36ddf357ac 9343a35f36db4e1f9bf6aaee73d4beb6--7174e5df966648a78dfa2b36ddf357ac 821a8760379144ba881d217c14590408 X 7174e5df966648a78dfa2b36ddf357ac--821a8760379144ba881d217c14590408 821a8760379144ba881d217c14590408--e7e1b1b449e34b869bab75c0f465eaae bd9a5a3c326b49f1b64d9e6cc7be41d6 821a8760379144ba881d217c14590408--bd9a5a3c326b49f1b64d9e6cc7be41d6 83c451c85f1d460cb523228a655b4a60 X bd9a5a3c326b49f1b64d9e6cc7be41d6--83c451c85f1d460cb523228a655b4a60 83c451c85f1d460cb523228a655b4a60--90d096888e024fcf91b93f850e044731 0911531cde364a7caa2ce47765c7ac2a 83c451c85f1d460cb523228a655b4a60--0911531cde364a7caa2ce47765c7ac2a aec79da2e2af466b807eefaecc990d22 0911531cde364a7caa2ce47765c7ac2a--aec79da2e2af466b807eefaecc990d22 7ffb35795c18442d80f832ba13e08716 aec79da2e2af466b807eefaecc990d22--7ffb35795c18442d80f832ba13e08716 e5ea802961bf42edbc51fd3a5312e01c X 7ffb35795c18442d80f832ba13e08716--e5ea802961bf42edbc51fd3a5312e01c e5ea802961bf42edbc51fd3a5312e01c--c54e53896130424d85fa8cf8c8570560 afa8cd7d46f64156bead207fa06323a1 X e5ea802961bf42edbc51fd3a5312e01c--afa8cd7d46f64156bead207fa06323a1 afa8cd7d46f64156bead207fa06323a1--df994ff20e0445ffabf24cbf9058c865 9f5ad83bb9a340aba10f422a0da5ce1c afa8cd7d46f64156bead207fa06323a1--9f5ad83bb9a340aba10f422a0da5ce1c 50dbf9e88a864328a759eebca3e525e2 9f5ad83bb9a340aba10f422a0da5ce1c--50dbf9e88a864328a759eebca3e525e2 94afe4da19dc417a92cfd75c4945a89a 50dbf9e88a864328a759eebca3e525e2--94afe4da19dc417a92cfd75c4945a89a 2c9fca89f14140b28f5f272aac5486a4 94afe4da19dc417a92cfd75c4945a89a--2c9fca89f14140b28f5f272aac5486a4 bce7547d07b847e7b060355510d74087 2c9fca89f14140b28f5f272aac5486a4--bce7547d07b847e7b060355510d74087 163a328ed25541f9a70032ccccc021db X bce7547d07b847e7b060355510d74087--163a328ed25541f9a70032ccccc021db 163a328ed25541f9a70032ccccc021db--38d462c51d0545a5a54226d3b7e87174 9f6afcc74381421d91add60bd0e15059 X 163a328ed25541f9a70032ccccc021db--9f6afcc74381421d91add60bd0e15059 9f6afcc74381421d91add60bd0e15059--fe2272ed3fdb4f99856cb2f5b01f9cc3 a8c672ec4fc54d75860a69a3afdb2671 9f6afcc74381421d91add60bd0e15059--a8c672ec4fc54d75860a69a3afdb2671 a48c96c65a3c41eb969da4b9ef97c86d a8c672ec4fc54d75860a69a3afdb2671--a48c96c65a3c41eb969da4b9ef97c86d 26c2308d2a4e435ea82f69bdce53ec70 a48c96c65a3c41eb969da4b9ef97c86d--26c2308d2a4e435ea82f69bdce53ec70 5babbde4c7784cea83fa07891ed18148 26c2308d2a4e435ea82f69bdce53ec70--5babbde4c7784cea83fa07891ed18148 83b0a8d110564e7ea558bf28726508fd 5babbde4c7784cea83fa07891ed18148--83b0a8d110564e7ea558bf28726508fd 864088c82bf449368743174f932f185c 83b0a8d110564e7ea558bf28726508fd--864088c82bf449368743174f932f185c 6e50fbd1f4cb48e2bd115551898b3b80 864088c82bf449368743174f932f185c--6e50fbd1f4cb48e2bd115551898b3b80 dcce60e3da50454ab5bc4d202ac9934a 6e50fbd1f4cb48e2bd115551898b3b80--dcce60e3da50454ab5bc4d202ac9934a 46c3a3e196b94097bf58fc85c17c68b3 dcce60e3da50454ab5bc4d202ac9934a--46c3a3e196b94097bf58fc85c17c68b3 4371e28be17d43fd8d8c66c36bf1ad25 X 46c3a3e196b94097bf58fc85c17c68b3--4371e28be17d43fd8d8c66c36bf1ad25 4371e28be17d43fd8d8c66c36bf1ad25--a10adff104d644e18069d281e2ad7d9f 2d584d877f96478a97ef3f6e62cc309b 4371e28be17d43fd8d8c66c36bf1ad25--2d584d877f96478a97ef3f6e62cc309b 2c51e0b250b94e819f02d745770c6c9f 2d584d877f96478a97ef3f6e62cc309b--2c51e0b250b94e819f02d745770c6c9f f8171f62163248d6afebfaffc46ca194 2c51e0b250b94e819f02d745770c6c9f--f8171f62163248d6afebfaffc46ca194 413bc4af024d44b0a0b82ba271544949 f8171f62163248d6afebfaffc46ca194--413bc4af024d44b0a0b82ba271544949 e47c29f9d4d0441fbb0582ff7d0516f2 413bc4af024d44b0a0b82ba271544949--e47c29f9d4d0441fbb0582ff7d0516f2 84f414abe6694349b6650ca8f20e8457 e47c29f9d4d0441fbb0582ff7d0516f2--84f414abe6694349b6650ca8f20e8457 2696630341794796ba62dc0aadad2a93 84f414abe6694349b6650ca8f20e8457--2696630341794796ba62dc0aadad2a93 250e799c75be470d8a40475539cfb662 2696630341794796ba62dc0aadad2a93--250e799c75be470d8a40475539cfb662 b82ac5400a4b4f57963376308d55de6c 250e799c75be470d8a40475539cfb662--b82ac5400a4b4f57963376308d55de6c 6415e48d64e5488e9ddec99c772c0127 b82ac5400a4b4f57963376308d55de6c--6415e48d64e5488e9ddec99c772c0127 fb5eb72178ac42c8af0e258844e45879 6415e48d64e5488e9ddec99c772c0127--fb5eb72178ac42c8af0e258844e45879 1c80667018f34da2b1c23da34858a461 fb5eb72178ac42c8af0e258844e45879--1c80667018f34da2b1c23da34858a461 0d8f42bcacfd4373a6e3463779db43fc 1c80667018f34da2b1c23da34858a461--0d8f42bcacfd4373a6e3463779db43fc 864c91c90f254fc8af1555ed3357a089 0d8f42bcacfd4373a6e3463779db43fc--864c91c90f254fc8af1555ed3357a089 1438096d95bc4885bb815359d314dc89 864c91c90f254fc8af1555ed3357a089--1438096d95bc4885bb815359d314dc89 67eacd7b5f794c8593bf701037d32d46 1438096d95bc4885bb815359d314dc89--67eacd7b5f794c8593bf701037d32d46 47bedfd928d34c709524d611bd69e521 67eacd7b5f794c8593bf701037d32d46--47bedfd928d34c709524d611bd69e521 639dbcf3128145a18700a89457ff8ca6 47bedfd928d34c709524d611bd69e521--639dbcf3128145a18700a89457ff8ca6 4f9fce9f662a423188bea819c0801af4 639dbcf3128145a18700a89457ff8ca6--4f9fce9f662a423188bea819c0801af4 b55eedbd863f46739bd62463511511f0 4f9fce9f662a423188bea819c0801af4--b55eedbd863f46739bd62463511511f0 5c9be5844f0f46b899f79ddabc23b726 b55eedbd863f46739bd62463511511f0--5c9be5844f0f46b899f79ddabc23b726 5e7e46fbaab0499f8ec79a4d07f6362a 5c9be5844f0f46b899f79ddabc23b726--5e7e46fbaab0499f8ec79a4d07f6362a 40797b805c2c4b7db90e8dcfc13119dd 5e7e46fbaab0499f8ec79a4d07f6362a--40797b805c2c4b7db90e8dcfc13119dd a3fb54ed428b4e6c9487e36c02108387 40797b805c2c4b7db90e8dcfc13119dd--a3fb54ed428b4e6c9487e36c02108387 769e158fa7834ea5bbe75a5255b68095 a3fb54ed428b4e6c9487e36c02108387--769e158fa7834ea5bbe75a5255b68095 80d93dcb53bc454e815b8b06ecf315b0 769e158fa7834ea5bbe75a5255b68095--80d93dcb53bc454e815b8b06ecf315b0 d64ce046bfc542f7a252d53751b88a49 80d93dcb53bc454e815b8b06ecf315b0--d64ce046bfc542f7a252d53751b88a49 998d65ff9bd0436bb5652671638452fa d64ce046bfc542f7a252d53751b88a49--998d65ff9bd0436bb5652671638452fa 74325f9c2249484e92cb38a6406e64b8 998d65ff9bd0436bb5652671638452fa--74325f9c2249484e92cb38a6406e64b8 28819a35f0d041cf8fef8d8ba8386c45 74325f9c2249484e92cb38a6406e64b8--28819a35f0d041cf8fef8d8ba8386c45 16c191cf599344f4beee13b6900b6a24 28819a35f0d041cf8fef8d8ba8386c45--16c191cf599344f4beee13b6900b6a24 734ee5705e8d48598e425e678d8a0c43 16c191cf599344f4beee13b6900b6a24--734ee5705e8d48598e425e678d8a0c43 7bfb930332b74d03b9ae869162514efd 734ee5705e8d48598e425e678d8a0c43--7bfb930332b74d03b9ae869162514efd a3a8f21f2c6d4e8aac70b07f38f9f616 7bfb930332b74d03b9ae869162514efd--a3a8f21f2c6d4e8aac70b07f38f9f616 615702aaf00546d7b4ac10b2b3cd22b5 a3a8f21f2c6d4e8aac70b07f38f9f616--615702aaf00546d7b4ac10b2b3cd22b5 a75190572f46410183b155fc4e917388 615702aaf00546d7b4ac10b2b3cd22b5--a75190572f46410183b155fc4e917388 09ac340a803d4b20a4c50f2c31b1cbdf a75190572f46410183b155fc4e917388--09ac340a803d4b20a4c50f2c31b1cbdf f661f05fdc164cce8f22d53182a88e85 09ac340a803d4b20a4c50f2c31b1cbdf--f661f05fdc164cce8f22d53182a88e85 970134d5abbd448582c6192c5724c5e8 f661f05fdc164cce8f22d53182a88e85--970134d5abbd448582c6192c5724c5e8 d275c9efc3ce438884484103e9db52d8 970134d5abbd448582c6192c5724c5e8--d275c9efc3ce438884484103e9db52d8 40d96ea320b34c00b5afff546b920993 d275c9efc3ce438884484103e9db52d8--40d96ea320b34c00b5afff546b920993 e24cae4ce8474b0aa6c2dcc497b562bc 40d96ea320b34c00b5afff546b920993--e24cae4ce8474b0aa6c2dcc497b562bc 2544ba15da40484aad0dbec17babc1db e24cae4ce8474b0aa6c2dcc497b562bc--2544ba15da40484aad0dbec17babc1db 4385d47811c843b6a6f59ff4b4fbe034 2544ba15da40484aad0dbec17babc1db--4385d47811c843b6a6f59ff4b4fbe034 646e75e592d74f31ab74dc6dd877765e 4385d47811c843b6a6f59ff4b4fbe034--646e75e592d74f31ab74dc6dd877765e 78323081927f470f9b4126f5f29d5387 RX(b02) 646e75e592d74f31ab74dc6dd877765e--78323081927f470f9b4126f5f29d5387 19fcf5a07b9c45e9be9cbea72d1fd2f9 78323081927f470f9b4126f5f29d5387--19fcf5a07b9c45e9be9cbea72d1fd2f9 4195421a0e3d4e1c8bcbcdaf6bc9d139 X 19fcf5a07b9c45e9be9cbea72d1fd2f9--4195421a0e3d4e1c8bcbcdaf6bc9d139 4195421a0e3d4e1c8bcbcdaf6bc9d139--d11b515f10734ecd925caf855abd1518 e9e3e1f910314086b3ca50436f6ffc32 4195421a0e3d4e1c8bcbcdaf6bc9d139--e9e3e1f910314086b3ca50436f6ffc32 3d87ccce94ca4e3581d85a5b2f9de135 e9e3e1f910314086b3ca50436f6ffc32--3d87ccce94ca4e3581d85a5b2f9de135 c0d2b9254c0542ad92a908f06ae6091c 3d87ccce94ca4e3581d85a5b2f9de135--c0d2b9254c0542ad92a908f06ae6091c 5dfcb38662d94031aad0fa5df82153c5 c0d2b9254c0542ad92a908f06ae6091c--5dfcb38662d94031aad0fa5df82153c5 6eca62bf7b644ee983a551f3a92cf7f9 5dfcb38662d94031aad0fa5df82153c5--6eca62bf7b644ee983a551f3a92cf7f9 d1ddcca82af649b6af81771c0e768c5c 6eca62bf7b644ee983a551f3a92cf7f9--d1ddcca82af649b6af81771c0e768c5c 72499c93ac7f41819403ba1b6f0786de d1ddcca82af649b6af81771c0e768c5c--72499c93ac7f41819403ba1b6f0786de a0a65441086844beb1449e3753520dc9 72499c93ac7f41819403ba1b6f0786de--a0a65441086844beb1449e3753520dc9 e45894a32e8b4bfc989e8a8be311ef99 a0a65441086844beb1449e3753520dc9--e45894a32e8b4bfc989e8a8be311ef99 44678468fff343bf82e274c6f0af27b9 e45894a32e8b4bfc989e8a8be311ef99--44678468fff343bf82e274c6f0af27b9 4cafd2c368b845e085e1d2bf9993e387 44678468fff343bf82e274c6f0af27b9--4cafd2c368b845e085e1d2bf9993e387 34845d6754ba4ac98730098c0a7abca1 X 4cafd2c368b845e085e1d2bf9993e387--34845d6754ba4ac98730098c0a7abca1 34845d6754ba4ac98730098c0a7abca1--3b7efacb0e324f63beea043b13fa23b3 76c74830b07a49fb9d11044f111bc0df 34845d6754ba4ac98730098c0a7abca1--76c74830b07a49fb9d11044f111bc0df 90102d787e304b7e8ab1f9abf865451a 76c74830b07a49fb9d11044f111bc0df--90102d787e304b7e8ab1f9abf865451a 44e2f7dc60964cd2a858316bb3949609 X 90102d787e304b7e8ab1f9abf865451a--44e2f7dc60964cd2a858316bb3949609 44e2f7dc60964cd2a858316bb3949609--f2b5981bbb834a66a80032927fef470c 3542d38876704bd1a052d9b3614e6550 44e2f7dc60964cd2a858316bb3949609--3542d38876704bd1a052d9b3614e6550 717769a72cd947e1b0edcd63aca637d1 3542d38876704bd1a052d9b3614e6550--717769a72cd947e1b0edcd63aca637d1 52a8256e67a442c1bd627fb9241f2118 717769a72cd947e1b0edcd63aca637d1--52a8256e67a442c1bd627fb9241f2118 d2c9b5e52c814ba2a0cafdb92a3e87a7 52a8256e67a442c1bd627fb9241f2118--d2c9b5e52c814ba2a0cafdb92a3e87a7 d3ac927270794a00a9506319c5b58611 d2c9b5e52c814ba2a0cafdb92a3e87a7--d3ac927270794a00a9506319c5b58611 01feff2aee644573bf6081175bf79dc3 X d3ac927270794a00a9506319c5b58611--01feff2aee644573bf6081175bf79dc3 01feff2aee644573bf6081175bf79dc3--255f149ae2e4498699477f07a44504cc 130e79729a5949468420a156dc5f610e 01feff2aee644573bf6081175bf79dc3--130e79729a5949468420a156dc5f610e 204fa3f7eb7d46649ddd66345833d27d 130e79729a5949468420a156dc5f610e--204fa3f7eb7d46649ddd66345833d27d a2b00ba51f4e4f12ac7738a88c343120 X 204fa3f7eb7d46649ddd66345833d27d--a2b00ba51f4e4f12ac7738a88c343120 a2b00ba51f4e4f12ac7738a88c343120--1d76bc43541e4066a5931051b6918e03 62daf4d3b0a14a9c86576412580698f8 a2b00ba51f4e4f12ac7738a88c343120--62daf4d3b0a14a9c86576412580698f8 d7d8aff865f8447abad9602fcb71f8ba 62daf4d3b0a14a9c86576412580698f8--d7d8aff865f8447abad9602fcb71f8ba 78b35ea4086e4462aa9a04003530b9b0 d7d8aff865f8447abad9602fcb71f8ba--78b35ea4086e4462aa9a04003530b9b0 9b4157d04a9d4591a02858ef8be2f883 78b35ea4086e4462aa9a04003530b9b0--9b4157d04a9d4591a02858ef8be2f883 cfba5f91380b45508431144ce11cc5ce 9b4157d04a9d4591a02858ef8be2f883--cfba5f91380b45508431144ce11cc5ce c73f7e6593b94e6784977d766ca62425 cfba5f91380b45508431144ce11cc5ce--c73f7e6593b94e6784977d766ca62425 73448513b009403abfc4feed50bd7dfb c73f7e6593b94e6784977d766ca62425--73448513b009403abfc4feed50bd7dfb 3e9c03555a6341e8ae40cc720c107549 X 73448513b009403abfc4feed50bd7dfb--3e9c03555a6341e8ae40cc720c107549 3e9c03555a6341e8ae40cc720c107549--25837f8f75f44a5a99bf7f39f48e5d1e 479ec7f8ba0d481f91e657a69ef40ce2 3e9c03555a6341e8ae40cc720c107549--479ec7f8ba0d481f91e657a69ef40ce2 f585fb6dbcd944a1903cb91cbbbf1c76 479ec7f8ba0d481f91e657a69ef40ce2--f585fb6dbcd944a1903cb91cbbbf1c76 d3a177c23dd84db3aad7e0cb9dde20c9 X f585fb6dbcd944a1903cb91cbbbf1c76--d3a177c23dd84db3aad7e0cb9dde20c9 d3a177c23dd84db3aad7e0cb9dde20c9--409cdbd838e34939a2ff9dafd712708e 07b26541d1b94077b3582c6549bed05f d3a177c23dd84db3aad7e0cb9dde20c9--07b26541d1b94077b3582c6549bed05f 48f351fb154b440ead72e2fd92df0c77 07b26541d1b94077b3582c6549bed05f--48f351fb154b440ead72e2fd92df0c77 b8b442a7ea8443578a4dc3d6ce7eef88 48f351fb154b440ead72e2fd92df0c77--b8b442a7ea8443578a4dc3d6ce7eef88 17150091cdfa496ab3d3e2b0b8f59966 b8b442a7ea8443578a4dc3d6ce7eef88--17150091cdfa496ab3d3e2b0b8f59966 b8e92da8522f4a1d8a0766898ae99f87 17150091cdfa496ab3d3e2b0b8f59966--b8e92da8522f4a1d8a0766898ae99f87 ac52547697314541b75fd19798facd7a b8e92da8522f4a1d8a0766898ae99f87--ac52547697314541b75fd19798facd7a 42699f12fd8944e7b31a368f3815dadf ac52547697314541b75fd19798facd7a--42699f12fd8944e7b31a368f3815dadf 7c3487e5d9d942aa8d08bfae35450f28 42699f12fd8944e7b31a368f3815dadf--7c3487e5d9d942aa8d08bfae35450f28 3b3d1b8f1d944455b962dda0be139d39 7c3487e5d9d942aa8d08bfae35450f28--3b3d1b8f1d944455b962dda0be139d39 c3fa94e7b971465b92b21aa9ab596e25 X 3b3d1b8f1d944455b962dda0be139d39--c3fa94e7b971465b92b21aa9ab596e25 c3fa94e7b971465b92b21aa9ab596e25--34226bd1c54c4bbe8d9b211c0b8b0b97 83f7f4c8377b4225a91a080c57cd41e4 c3fa94e7b971465b92b21aa9ab596e25--83f7f4c8377b4225a91a080c57cd41e4 4250c318c5f44241aaaae2fd27ed5db0 83f7f4c8377b4225a91a080c57cd41e4--4250c318c5f44241aaaae2fd27ed5db0 cef7b981b8714aa5a36e382b0d8af71d X 4250c318c5f44241aaaae2fd27ed5db0--cef7b981b8714aa5a36e382b0d8af71d cef7b981b8714aa5a36e382b0d8af71d--38706492d2144934835df01106f8fff8 1604b4a378284b9691b967b412a5964f cef7b981b8714aa5a36e382b0d8af71d--1604b4a378284b9691b967b412a5964f 452dcfee5b494e16a25d53d6231eaa05 1604b4a378284b9691b967b412a5964f--452dcfee5b494e16a25d53d6231eaa05 87bde261764b453784392945754ef65a 452dcfee5b494e16a25d53d6231eaa05--87bde261764b453784392945754ef65a 03ad716f9030459d8d22f8a16a6ad113 87bde261764b453784392945754ef65a--03ad716f9030459d8d22f8a16a6ad113 0e850d9012414706a7411c3da9e8bdcc 03ad716f9030459d8d22f8a16a6ad113--0e850d9012414706a7411c3da9e8bdcc e50e3165588746d695720fdad56976bb 0e850d9012414706a7411c3da9e8bdcc--e50e3165588746d695720fdad56976bb fc93eae12fa34a3d9407754d402f776b e50e3165588746d695720fdad56976bb--fc93eae12fa34a3d9407754d402f776b a6c9d83feee049c2ab32690e6af0339b fc93eae12fa34a3d9407754d402f776b--a6c9d83feee049c2ab32690e6af0339b 9ca86e92a3224cfd8e51241459c1626c a6c9d83feee049c2ab32690e6af0339b--9ca86e92a3224cfd8e51241459c1626c 2434a01ef2ae451088ef25572b32f59b 9ca86e92a3224cfd8e51241459c1626c--2434a01ef2ae451088ef25572b32f59b adb8141aa7fc47988443a68ce6181025 2434a01ef2ae451088ef25572b32f59b--adb8141aa7fc47988443a68ce6181025 22bb15a5ee5848c697a51eb3a81b564f X adb8141aa7fc47988443a68ce6181025--22bb15a5ee5848c697a51eb3a81b564f 22bb15a5ee5848c697a51eb3a81b564f--f4de4fef465c43528a4c9bccd88c308f 10546a0009614b5fa43b106f75c5a533 22bb15a5ee5848c697a51eb3a81b564f--10546a0009614b5fa43b106f75c5a533 04ccd40e350b495e9c606ed3d5b151ca X 10546a0009614b5fa43b106f75c5a533--04ccd40e350b495e9c606ed3d5b151ca 04ccd40e350b495e9c606ed3d5b151ca--f99d4ab42cee4904ad6d8486fad1e5e3 47331bccc7ac42e8b5065f6607a411d8 04ccd40e350b495e9c606ed3d5b151ca--47331bccc7ac42e8b5065f6607a411d8 3cc49e952c2a4bd48329195fe516a67e 47331bccc7ac42e8b5065f6607a411d8--3cc49e952c2a4bd48329195fe516a67e 84a58fcdf81f447fbc80629506c8f6da 3cc49e952c2a4bd48329195fe516a67e--84a58fcdf81f447fbc80629506c8f6da d12ac47fe1a74a91811e002e5b2326c5 X 84a58fcdf81f447fbc80629506c8f6da--d12ac47fe1a74a91811e002e5b2326c5 d12ac47fe1a74a91811e002e5b2326c5--7d79bc9da99d4b89b0347c84755c2253 b330770b099a4556830f4e22051abe68 X d12ac47fe1a74a91811e002e5b2326c5--b330770b099a4556830f4e22051abe68 b330770b099a4556830f4e22051abe68--03a85c77ebed4d91b7b53efba9a48782 f398555d72bd491b9b72df893e6c38ea b330770b099a4556830f4e22051abe68--f398555d72bd491b9b72df893e6c38ea 40bc17d005b44a08b95a18a1fe6362a5 f398555d72bd491b9b72df893e6c38ea--40bc17d005b44a08b95a18a1fe6362a5 c1d604046d1a4aef9c2bb8c4fcceedfb 40bc17d005b44a08b95a18a1fe6362a5--c1d604046d1a4aef9c2bb8c4fcceedfb 4f08fc74e0b2438787ea5cc4fbc94c2b c1d604046d1a4aef9c2bb8c4fcceedfb--4f08fc74e0b2438787ea5cc4fbc94c2b 55241a1e5d4a4b39993358b0ec5fc8db 4f08fc74e0b2438787ea5cc4fbc94c2b--55241a1e5d4a4b39993358b0ec5fc8db f4c3c9c92d7a4f46971899fb33f632ee X 55241a1e5d4a4b39993358b0ec5fc8db--f4c3c9c92d7a4f46971899fb33f632ee f4c3c9c92d7a4f46971899fb33f632ee--238c7e12859f458d9b68df0acae0872a e8aff279c6d5467483d69592e9109ba0 X f4c3c9c92d7a4f46971899fb33f632ee--e8aff279c6d5467483d69592e9109ba0 e8aff279c6d5467483d69592e9109ba0--ba9ecb51418843f6a2e2b25baa0002a3 945d84b9908e48f2b5c899ee2c1ac139 e8aff279c6d5467483d69592e9109ba0--945d84b9908e48f2b5c899ee2c1ac139 bc670937ac3b478b99895981432dee9a 945d84b9908e48f2b5c899ee2c1ac139--bc670937ac3b478b99895981432dee9a b6b692c74f1b47858c109cfe65d1204f bc670937ac3b478b99895981432dee9a--b6b692c74f1b47858c109cfe65d1204f 12e1e87c064e4ac4a73af5eaa9f7aced b6b692c74f1b47858c109cfe65d1204f--12e1e87c064e4ac4a73af5eaa9f7aced 5c7614aef21048f1840a2c65159ee8ae 12e1e87c064e4ac4a73af5eaa9f7aced--5c7614aef21048f1840a2c65159ee8ae 3614cec8006d4e79bad84f508596b761 5c7614aef21048f1840a2c65159ee8ae--3614cec8006d4e79bad84f508596b761 3341e47a819b4239ad52e35dbe3e9541 3614cec8006d4e79bad84f508596b761--3341e47a819b4239ad52e35dbe3e9541 ea7071a190b84809a30a6b8c71a4340d 3341e47a819b4239ad52e35dbe3e9541--ea7071a190b84809a30a6b8c71a4340d f81ed691ad64439495e17ba614582b72 ea7071a190b84809a30a6b8c71a4340d--f81ed691ad64439495e17ba614582b72 24b6be86aa5b4b29a4fd98903d1cce98 X f81ed691ad64439495e17ba614582b72--24b6be86aa5b4b29a4fd98903d1cce98 24b6be86aa5b4b29a4fd98903d1cce98--f4fb46d7304943d59246a9cc6fa4ca49 9f1c9abbf3854d018d6825469509b9c5 24b6be86aa5b4b29a4fd98903d1cce98--9f1c9abbf3854d018d6825469509b9c5 543b188a0666447b879216e6add8c988 9f1c9abbf3854d018d6825469509b9c5--543b188a0666447b879216e6add8c988 a85b19ed900745a0bc168240a1ac6e88 543b188a0666447b879216e6add8c988--a85b19ed900745a0bc168240a1ac6e88 a3a1e6550b9c4a5487772a5e22311def a85b19ed900745a0bc168240a1ac6e88--a3a1e6550b9c4a5487772a5e22311def f37febc0df4a46b0bba09a5a0ee175a5 a3a1e6550b9c4a5487772a5e22311def--f37febc0df4a46b0bba09a5a0ee175a5 e7234e52019c4a3a8e1807c4c9b3968f f37febc0df4a46b0bba09a5a0ee175a5--e7234e52019c4a3a8e1807c4c9b3968f e4b7424f8c48494cb0bdb7bffbd461df e7234e52019c4a3a8e1807c4c9b3968f--e4b7424f8c48494cb0bdb7bffbd461df 365ae088293e4947b1f0cbe5583f2034 e4b7424f8c48494cb0bdb7bffbd461df--365ae088293e4947b1f0cbe5583f2034 1d2fccc3e5254a30b3df0c96bf4c7557 365ae088293e4947b1f0cbe5583f2034--1d2fccc3e5254a30b3df0c96bf4c7557 cdab8bc7672e451ca125d5afee611ba7 1d2fccc3e5254a30b3df0c96bf4c7557--cdab8bc7672e451ca125d5afee611ba7 42a5706f9287470abf15505ce35e30e5 cdab8bc7672e451ca125d5afee611ba7--42a5706f9287470abf15505ce35e30e5 b733b0f7af96435c864513e6698e300f 42a5706f9287470abf15505ce35e30e5--b733b0f7af96435c864513e6698e300f 4183529dfd0649008adda43d1f103def b733b0f7af96435c864513e6698e300f--4183529dfd0649008adda43d1f103def d67a41c562134b6aa96e7484e16bdfc5 4183529dfd0649008adda43d1f103def--d67a41c562134b6aa96e7484e16bdfc5 14800354aac349c9bb1225ccc5d05697 d67a41c562134b6aa96e7484e16bdfc5--14800354aac349c9bb1225ccc5d05697 64254b4a642b4c058794dad5828c92db 14800354aac349c9bb1225ccc5d05697--64254b4a642b4c058794dad5828c92db fd504d4ba6004f36960ffb579fac7f5e 64254b4a642b4c058794dad5828c92db--fd504d4ba6004f36960ffb579fac7f5e 9ffe291fd4a94094bf7bdaa2549188d6 fd504d4ba6004f36960ffb579fac7f5e--9ffe291fd4a94094bf7bdaa2549188d6 f78d846d277940ad873b4b832e5d88b0 9ffe291fd4a94094bf7bdaa2549188d6--f78d846d277940ad873b4b832e5d88b0 220d918675e24dcaa9b3c1aced5e3a0c f78d846d277940ad873b4b832e5d88b0--220d918675e24dcaa9b3c1aced5e3a0c 1de8a10767844e40a7e8a8e21acdcb01 220d918675e24dcaa9b3c1aced5e3a0c--1de8a10767844e40a7e8a8e21acdcb01 6f96499918e741dfa7af5f6edc7655e0 1de8a10767844e40a7e8a8e21acdcb01--6f96499918e741dfa7af5f6edc7655e0 9580e4ccb0df41c78a2d1ff693e33f2b 6f96499918e741dfa7af5f6edc7655e0--9580e4ccb0df41c78a2d1ff693e33f2b b310883e75454bc29a1a334590c95e56 9580e4ccb0df41c78a2d1ff693e33f2b--b310883e75454bc29a1a334590c95e56 f254eabf6234488f895723f13c625ae0 b310883e75454bc29a1a334590c95e56--f254eabf6234488f895723f13c625ae0 2b578f32b05246b4a1b2573a1c306e98 f254eabf6234488f895723f13c625ae0--2b578f32b05246b4a1b2573a1c306e98 a8fa6a3321944d588468d54754df61a8 2b578f32b05246b4a1b2573a1c306e98--a8fa6a3321944d588468d54754df61a8 884032e040eb472795344420e52e960b a8fa6a3321944d588468d54754df61a8--884032e040eb472795344420e52e960b de748fefe7644223bb00327cbac165aa 884032e040eb472795344420e52e960b--de748fefe7644223bb00327cbac165aa 44aa53b9183d4c5d952252cf041944ef de748fefe7644223bb00327cbac165aa--44aa53b9183d4c5d952252cf041944ef 8a30682debb04daa83d14fa83451762b 44aa53b9183d4c5d952252cf041944ef--8a30682debb04daa83d14fa83451762b 000b071422104ec4a927568ade87a71a 8a30682debb04daa83d14fa83451762b--000b071422104ec4a927568ade87a71a fdb57598bf7e47e2b7cf7df657e0cdc9 000b071422104ec4a927568ade87a71a--fdb57598bf7e47e2b7cf7df657e0cdc9 9350680d23f4426aabd93ab3791393ae fdb57598bf7e47e2b7cf7df657e0cdc9--9350680d23f4426aabd93ab3791393ae d3abead6d3bc47ddac9cedcc5253abb0 9350680d23f4426aabd93ab3791393ae--d3abead6d3bc47ddac9cedcc5253abb0 d392de219d714f5ba3796df8b63df832 d3abead6d3bc47ddac9cedcc5253abb0--d392de219d714f5ba3796df8b63df832 27b78167f2d84c67bc106d04fd3f7dc3 d392de219d714f5ba3796df8b63df832--27b78167f2d84c67bc106d04fd3f7dc3 77c0313a8bde4cce9990f0481e42c401 27b78167f2d84c67bc106d04fd3f7dc3--77c0313a8bde4cce9990f0481e42c401 beb33670823c4bfdbe931da0cf469a27 77c0313a8bde4cce9990f0481e42c401--beb33670823c4bfdbe931da0cf469a27 3ff60f1edfd34d67ab167c07f8026c53 beb33670823c4bfdbe931da0cf469a27--3ff60f1edfd34d67ab167c07f8026c53 2fd7ce51e79141eb98a7ec67a2bf686d 3ff60f1edfd34d67ab167c07f8026c53--2fd7ce51e79141eb98a7ec67a2bf686d 6c9b5b248a314a4db744d1298e9b6305 2fd7ce51e79141eb98a7ec67a2bf686d--6c9b5b248a314a4db744d1298e9b6305 d4d822e5b3ca48b0898071ea05dfc2e6 6c9b5b248a314a4db744d1298e9b6305--d4d822e5b3ca48b0898071ea05dfc2e6 b0a7f4585f46465a90e9f0f562e1c377 d4d822e5b3ca48b0898071ea05dfc2e6--b0a7f4585f46465a90e9f0f562e1c377 c07737a14a56473cbfae8f56f28d0ebe b0a7f4585f46465a90e9f0f562e1c377--c07737a14a56473cbfae8f56f28d0ebe 8559ef89f7ff4d788a10f3010c9434c2 RX(b12) c07737a14a56473cbfae8f56f28d0ebe--8559ef89f7ff4d788a10f3010c9434c2 8559ef89f7ff4d788a10f3010c9434c2--f89b8de474cb4e3ba470284df0724fe4 290e9bc7f6cb411da9001ab0c0829b15 fa5ebdf82444490fa00b84727ca3a9ca b820125e7a704a8c9bff9a0233c7d09f--fa5ebdf82444490fa00b84727ca3a9ca bfe458081d65449ba06828a2dde2f0ee 4 27e0b50e3e314fb8953edcd2b8a82984 fa5ebdf82444490fa00b84727ca3a9ca--27e0b50e3e314fb8953edcd2b8a82984 2dec136cbfd04b3296a82f31ed5b78aa X 27e0b50e3e314fb8953edcd2b8a82984--2dec136cbfd04b3296a82f31ed5b78aa 2dec136cbfd04b3296a82f31ed5b78aa--b049b7015eea4c57a1f1fd98a3d72679 edd8dccb3c3e42c78926ce5c1bd6dab7 2dec136cbfd04b3296a82f31ed5b78aa--edd8dccb3c3e42c78926ce5c1bd6dab7 8304b38fb6eb47a591d98636644037f8 edd8dccb3c3e42c78926ce5c1bd6dab7--8304b38fb6eb47a591d98636644037f8 909f2bab51f04414a5e0b0028deda162 8304b38fb6eb47a591d98636644037f8--909f2bab51f04414a5e0b0028deda162 6cd28750ffd64cc9a2d4ad42850c0299 909f2bab51f04414a5e0b0028deda162--6cd28750ffd64cc9a2d4ad42850c0299 39ad543e3cef481a92aa35d5cf1047e8 6cd28750ffd64cc9a2d4ad42850c0299--39ad543e3cef481a92aa35d5cf1047e8 dfc5d06a82cd49848a5677c9c7052a64 39ad543e3cef481a92aa35d5cf1047e8--dfc5d06a82cd49848a5677c9c7052a64 7bc3c9b26af84da893e0065e112914b2 dfc5d06a82cd49848a5677c9c7052a64--7bc3c9b26af84da893e0065e112914b2 fd5c43121d9d4d52b4735873110b55bd 7bc3c9b26af84da893e0065e112914b2--fd5c43121d9d4d52b4735873110b55bd 6b783de5d092473aab051f381efac3e6 fd5c43121d9d4d52b4735873110b55bd--6b783de5d092473aab051f381efac3e6 3c876434370b442da0528711e326f765 X 6b783de5d092473aab051f381efac3e6--3c876434370b442da0528711e326f765 3c876434370b442da0528711e326f765--4e9daf998c1d473480b0a9f9992ae31e 1edb81b5f57147a5917b2048026c3b2d 3c876434370b442da0528711e326f765--1edb81b5f57147a5917b2048026c3b2d 682b68748d25410ebd184a88fa6a2069 1edb81b5f57147a5917b2048026c3b2d--682b68748d25410ebd184a88fa6a2069 be4bb16ed6254df1a89d8023cf6936b1 682b68748d25410ebd184a88fa6a2069--be4bb16ed6254df1a89d8023cf6936b1 730b90d6a11e4e9f94627e339014a291 be4bb16ed6254df1a89d8023cf6936b1--730b90d6a11e4e9f94627e339014a291 009d7c0bfee54d90835408fd3f296eae X 730b90d6a11e4e9f94627e339014a291--009d7c0bfee54d90835408fd3f296eae 009d7c0bfee54d90835408fd3f296eae--9e430b8ba70345aeb153ed3bdb139169 e3c891fda632466c8b03d0d271319967 009d7c0bfee54d90835408fd3f296eae--e3c891fda632466c8b03d0d271319967 2bc8d95f482242618d4b17b9107e93b0 e3c891fda632466c8b03d0d271319967--2bc8d95f482242618d4b17b9107e93b0 d325af2a2db345e3ae297b5276257ebc 2bc8d95f482242618d4b17b9107e93b0--d325af2a2db345e3ae297b5276257ebc f2bb720060ae4011996a5406bb4156f4 X d325af2a2db345e3ae297b5276257ebc--f2bb720060ae4011996a5406bb4156f4 f2bb720060ae4011996a5406bb4156f4--30189dcf5bb44a4aa4e81fa115701b07 bfa994cf8e4f424a9f2e0025aec032c4 f2bb720060ae4011996a5406bb4156f4--bfa994cf8e4f424a9f2e0025aec032c4 07b99dcf3ac04edd80b577fda9ad806d bfa994cf8e4f424a9f2e0025aec032c4--07b99dcf3ac04edd80b577fda9ad806d 77b0ce82b3794e67bc12866bb8f03747 07b99dcf3ac04edd80b577fda9ad806d--77b0ce82b3794e67bc12866bb8f03747 1b6a4b0c7bd14731bc8f677b46bd4d08 77b0ce82b3794e67bc12866bb8f03747--1b6a4b0c7bd14731bc8f677b46bd4d08 9c9131f87e1d4e29835043755ed39df0 X 1b6a4b0c7bd14731bc8f677b46bd4d08--9c9131f87e1d4e29835043755ed39df0 9c9131f87e1d4e29835043755ed39df0--3fa042e168544969a157252a27cf57dd b4e3449d40b04b9bb968ce3fb5afe091 9c9131f87e1d4e29835043755ed39df0--b4e3449d40b04b9bb968ce3fb5afe091 6bd6af649ada49b1b438a5b18746e098 b4e3449d40b04b9bb968ce3fb5afe091--6bd6af649ada49b1b438a5b18746e098 15ce35ad13844ab8bf8f1963eca60084 6bd6af649ada49b1b438a5b18746e098--15ce35ad13844ab8bf8f1963eca60084 5ee1753ade224e7598cfcca3b32bbaf1 15ce35ad13844ab8bf8f1963eca60084--5ee1753ade224e7598cfcca3b32bbaf1 4329a360fd4d42b18768c0b3ae7d041a 5ee1753ade224e7598cfcca3b32bbaf1--4329a360fd4d42b18768c0b3ae7d041a 847da497c32d4247abdf7437a6a0cb41 X 4329a360fd4d42b18768c0b3ae7d041a--847da497c32d4247abdf7437a6a0cb41 847da497c32d4247abdf7437a6a0cb41--ce5a6a42af654dfa9524f0e1a66205c3 5d3494079f5349ecaa148db70bd342bd 847da497c32d4247abdf7437a6a0cb41--5d3494079f5349ecaa148db70bd342bd 3d0141e8d5b74112b782454d3c96f8a9 5d3494079f5349ecaa148db70bd342bd--3d0141e8d5b74112b782454d3c96f8a9 c5b5f41f9712410b9b311fb6a7308755 3d0141e8d5b74112b782454d3c96f8a9--c5b5f41f9712410b9b311fb6a7308755 a05d5b02770f417c90d6680dad7996f9 c5b5f41f9712410b9b311fb6a7308755--a05d5b02770f417c90d6680dad7996f9 c99180c1ad2a4294b5da7e34a4540f99 X a05d5b02770f417c90d6680dad7996f9--c99180c1ad2a4294b5da7e34a4540f99 c99180c1ad2a4294b5da7e34a4540f99--9ea803d172884bd4850363a79e7d8c90 6735550a431d42d090d3e6465cd012c3 c99180c1ad2a4294b5da7e34a4540f99--6735550a431d42d090d3e6465cd012c3 430e419081ee445d8e7d23e960c32f1c 6735550a431d42d090d3e6465cd012c3--430e419081ee445d8e7d23e960c32f1c ad16a33c670d4900984dd2b80ff7dab7 430e419081ee445d8e7d23e960c32f1c--ad16a33c670d4900984dd2b80ff7dab7 da1bc7cc59074ce3b5172d61139a5d2a ad16a33c670d4900984dd2b80ff7dab7--da1bc7cc59074ce3b5172d61139a5d2a 98c63cf5fb3547ad8211772e9e6f2a7b da1bc7cc59074ce3b5172d61139a5d2a--98c63cf5fb3547ad8211772e9e6f2a7b 5d73eefecca04d55a5e3d5e66f247599 98c63cf5fb3547ad8211772e9e6f2a7b--5d73eefecca04d55a5e3d5e66f247599 87dcc2aa95f34bea820660c8817f8d88 5d73eefecca04d55a5e3d5e66f247599--87dcc2aa95f34bea820660c8817f8d88 732f85167fcf4f578f032dc210a12af2 X 87dcc2aa95f34bea820660c8817f8d88--732f85167fcf4f578f032dc210a12af2 732f85167fcf4f578f032dc210a12af2--4ed45399c71848a7883bf7f892bd464b b5390e64bdac436aabcb693394284b19 732f85167fcf4f578f032dc210a12af2--b5390e64bdac436aabcb693394284b19 8a4e57cd847c4245ae34d8d5cd397ad8 b5390e64bdac436aabcb693394284b19--8a4e57cd847c4245ae34d8d5cd397ad8 a795da55cf4d4a4e8acba1cf25a29531 8a4e57cd847c4245ae34d8d5cd397ad8--a795da55cf4d4a4e8acba1cf25a29531 5c12c417f5224213b4ac8a705646d9b5 a795da55cf4d4a4e8acba1cf25a29531--5c12c417f5224213b4ac8a705646d9b5 c950283e1f9c4e199ed638504fb59589 X 5c12c417f5224213b4ac8a705646d9b5--c950283e1f9c4e199ed638504fb59589 c950283e1f9c4e199ed638504fb59589--675aba70349b47c58753949152478cd7 8fa7a6ae722f4f1c8b28a915b78bda2b c950283e1f9c4e199ed638504fb59589--8fa7a6ae722f4f1c8b28a915b78bda2b 7ec5b3bbf35845778fc483bb0e1929ff 8fa7a6ae722f4f1c8b28a915b78bda2b--7ec5b3bbf35845778fc483bb0e1929ff a6b5fcefe006477784cacd20eb9d8140 7ec5b3bbf35845778fc483bb0e1929ff--a6b5fcefe006477784cacd20eb9d8140 2d245b676a0d4de1ab657a203f9219c9 a6b5fcefe006477784cacd20eb9d8140--2d245b676a0d4de1ab657a203f9219c9 a6c965ca062c46c89afcc61456591133 2d245b676a0d4de1ab657a203f9219c9--a6c965ca062c46c89afcc61456591133 a57b02f0d60b4637ac92c4004aaef4d5 a6c965ca062c46c89afcc61456591133--a57b02f0d60b4637ac92c4004aaef4d5 0193f2fbc1e74aae92d7b423b486ff84 a57b02f0d60b4637ac92c4004aaef4d5--0193f2fbc1e74aae92d7b423b486ff84 932420609c8a4ccdab2533716650d8db 0193f2fbc1e74aae92d7b423b486ff84--932420609c8a4ccdab2533716650d8db b9c0848354fc49f0adae719caf6c1974 932420609c8a4ccdab2533716650d8db--b9c0848354fc49f0adae719caf6c1974 27e18d63a6d346f8b9d663dd21accfeb X b9c0848354fc49f0adae719caf6c1974--27e18d63a6d346f8b9d663dd21accfeb 27e18d63a6d346f8b9d663dd21accfeb--7174e5df966648a78dfa2b36ddf357ac 3a7dfec245284d53b371165e2de09bc3 27e18d63a6d346f8b9d663dd21accfeb--3a7dfec245284d53b371165e2de09bc3 b5f00dcf5d794a08aad340905521ff29 3a7dfec245284d53b371165e2de09bc3--b5f00dcf5d794a08aad340905521ff29 c318d35a9a6942bfa452e38508ee6abe b5f00dcf5d794a08aad340905521ff29--c318d35a9a6942bfa452e38508ee6abe f3d7ac36de3949c28f270527e4c7f7e5 X c318d35a9a6942bfa452e38508ee6abe--f3d7ac36de3949c28f270527e4c7f7e5 f3d7ac36de3949c28f270527e4c7f7e5--0911531cde364a7caa2ce47765c7ac2a 58d1b805d1d648b994777282638cf1ae RZ(-1.0*g0) f3d7ac36de3949c28f270527e4c7f7e5--58d1b805d1d648b994777282638cf1ae 109eb0b8f5fe4ae59f9751f8bb8075ce X 58d1b805d1d648b994777282638cf1ae--109eb0b8f5fe4ae59f9751f8bb8075ce 109eb0b8f5fe4ae59f9751f8bb8075ce--7ffb35795c18442d80f832ba13e08716 a13e5c187cad455cbcdd7312e16404c6 109eb0b8f5fe4ae59f9751f8bb8075ce--a13e5c187cad455cbcdd7312e16404c6 516a766760fd4c4faa7cd47fbe79c197 a13e5c187cad455cbcdd7312e16404c6--516a766760fd4c4faa7cd47fbe79c197 0c1e3c6b4e9b4666b5cfcacc3448ab44 X 516a766760fd4c4faa7cd47fbe79c197--0c1e3c6b4e9b4666b5cfcacc3448ab44 0c1e3c6b4e9b4666b5cfcacc3448ab44--9f5ad83bb9a340aba10f422a0da5ce1c 20a8ca325e944ca7b84688277e4c86c8 0c1e3c6b4e9b4666b5cfcacc3448ab44--20a8ca325e944ca7b84688277e4c86c8 0e47a782384b4ce293477e9fd1d488fd 20a8ca325e944ca7b84688277e4c86c8--0e47a782384b4ce293477e9fd1d488fd c3dcff7ed56f43b3a8e9a890ad1322e9 0e47a782384b4ce293477e9fd1d488fd--c3dcff7ed56f43b3a8e9a890ad1322e9 071027e2be2a46af8d2990f4ff4f0bc6 X c3dcff7ed56f43b3a8e9a890ad1322e9--071027e2be2a46af8d2990f4ff4f0bc6 071027e2be2a46af8d2990f4ff4f0bc6--bce7547d07b847e7b060355510d74087 302aacd8b92846b6b1bf8808fac9e309 071027e2be2a46af8d2990f4ff4f0bc6--302aacd8b92846b6b1bf8808fac9e309 0841a183704d4dc8b4d671253600a15c 302aacd8b92846b6b1bf8808fac9e309--0841a183704d4dc8b4d671253600a15c af6c3e2f9dcc482c8397c0569cc769cc X 0841a183704d4dc8b4d671253600a15c--af6c3e2f9dcc482c8397c0569cc769cc af6c3e2f9dcc482c8397c0569cc769cc--a8c672ec4fc54d75860a69a3afdb2671 a4082cb183664662bce6c097932bd87f af6c3e2f9dcc482c8397c0569cc769cc--a4082cb183664662bce6c097932bd87f 1054a0f471c74812bbbe4ea35e340b92 a4082cb183664662bce6c097932bd87f--1054a0f471c74812bbbe4ea35e340b92 049eb70bd9ef4799bedbeee7ff317bbc 1054a0f471c74812bbbe4ea35e340b92--049eb70bd9ef4799bedbeee7ff317bbc c6ef2879f206426dbd005c765c19136d 049eb70bd9ef4799bedbeee7ff317bbc--c6ef2879f206426dbd005c765c19136d c0088153e38046d6a48209766448d7ad c6ef2879f206426dbd005c765c19136d--c0088153e38046d6a48209766448d7ad 09e7a5edcc9c4b4e8aa0856dedf78f01 c0088153e38046d6a48209766448d7ad--09e7a5edcc9c4b4e8aa0856dedf78f01 60daa37f81d84cc6bf639a43034b1487 09e7a5edcc9c4b4e8aa0856dedf78f01--60daa37f81d84cc6bf639a43034b1487 aaf2021e2c8441aab317d1d97d3fe0e7 X 60daa37f81d84cc6bf639a43034b1487--aaf2021e2c8441aab317d1d97d3fe0e7 aaf2021e2c8441aab317d1d97d3fe0e7--46c3a3e196b94097bf58fc85c17c68b3 3c082484e8334d719f90739befa3eb20 aaf2021e2c8441aab317d1d97d3fe0e7--3c082484e8334d719f90739befa3eb20 f5429116649d4885b23536a029474cb2 X 3c082484e8334d719f90739befa3eb20--f5429116649d4885b23536a029474cb2 f5429116649d4885b23536a029474cb2--2d584d877f96478a97ef3f6e62cc309b 27777b3ccdaf45229837542bc3bb30d4 f5429116649d4885b23536a029474cb2--27777b3ccdaf45229837542bc3bb30d4 402d9fc1a9e848a9a416ec948a1d3417 27777b3ccdaf45229837542bc3bb30d4--402d9fc1a9e848a9a416ec948a1d3417 54684a18096144bea2fb07df0e7a8f99 402d9fc1a9e848a9a416ec948a1d3417--54684a18096144bea2fb07df0e7a8f99 cbcf366419054ce59857880a4d82b77c X 54684a18096144bea2fb07df0e7a8f99--cbcf366419054ce59857880a4d82b77c cbcf366419054ce59857880a4d82b77c--e47c29f9d4d0441fbb0582ff7d0516f2 d902852ece3d40438a2de55637dae6d2 X cbcf366419054ce59857880a4d82b77c--d902852ece3d40438a2de55637dae6d2 d902852ece3d40438a2de55637dae6d2--84f414abe6694349b6650ca8f20e8457 1d86f940f75b4bbba078e9a5933f9bc5 d902852ece3d40438a2de55637dae6d2--1d86f940f75b4bbba078e9a5933f9bc5 e7a96a1d0fd34366b44c0f7653ae33f0 1d86f940f75b4bbba078e9a5933f9bc5--e7a96a1d0fd34366b44c0f7653ae33f0 b0806cc9db924ebf8b54629f122bc0b1 e7a96a1d0fd34366b44c0f7653ae33f0--b0806cc9db924ebf8b54629f122bc0b1 0c0f4d715f2d4fb387a01cae46e50bef b0806cc9db924ebf8b54629f122bc0b1--0c0f4d715f2d4fb387a01cae46e50bef 280afa086ec349878f5a1356e4f683b7 0c0f4d715f2d4fb387a01cae46e50bef--280afa086ec349878f5a1356e4f683b7 33d70fad7b4b41a7a3d1baffac8e6c31 X 280afa086ec349878f5a1356e4f683b7--33d70fad7b4b41a7a3d1baffac8e6c31 33d70fad7b4b41a7a3d1baffac8e6c31--1c80667018f34da2b1c23da34858a461 9f9f0b4bb7094a3f9ce33c0db8589f00 X 33d70fad7b4b41a7a3d1baffac8e6c31--9f9f0b4bb7094a3f9ce33c0db8589f00 9f9f0b4bb7094a3f9ce33c0db8589f00--0d8f42bcacfd4373a6e3463779db43fc ad9ea59908b84d62abf3f3118b9fa108 9f9f0b4bb7094a3f9ce33c0db8589f00--ad9ea59908b84d62abf3f3118b9fa108 7cda672994fe4ccf8c199785f87716df ad9ea59908b84d62abf3f3118b9fa108--7cda672994fe4ccf8c199785f87716df 614080774046444894925eac8ec44777 7cda672994fe4ccf8c199785f87716df--614080774046444894925eac8ec44777 159a3f2b234f46e78cbf49cf03ecf8a2 614080774046444894925eac8ec44777--159a3f2b234f46e78cbf49cf03ecf8a2 d962895b724840e59c521153fe96a963 159a3f2b234f46e78cbf49cf03ecf8a2--d962895b724840e59c521153fe96a963 1328442fc0e64bd69cc74203e6906eed d962895b724840e59c521153fe96a963--1328442fc0e64bd69cc74203e6906eed 3a268ae221a94e12a60b2dd7d4fb548f 1328442fc0e64bd69cc74203e6906eed--3a268ae221a94e12a60b2dd7d4fb548f a3e4acce8e2f44eb93e5a17c904d3d4b X 3a268ae221a94e12a60b2dd7d4fb548f--a3e4acce8e2f44eb93e5a17c904d3d4b a3e4acce8e2f44eb93e5a17c904d3d4b--5c9be5844f0f46b899f79ddabc23b726 024cb3dd2ca94d0b91f7f4e7b5f20b8a a3e4acce8e2f44eb93e5a17c904d3d4b--024cb3dd2ca94d0b91f7f4e7b5f20b8a 00d09d5130d541ba8df7e4d4c7dedc85 024cb3dd2ca94d0b91f7f4e7b5f20b8a--00d09d5130d541ba8df7e4d4c7dedc85 b868ca205dff43d2a891eb27d4e2224b 00d09d5130d541ba8df7e4d4c7dedc85--b868ca205dff43d2a891eb27d4e2224b 5df3c1a5e382438082f4ed0e97ee0fd6 b868ca205dff43d2a891eb27d4e2224b--5df3c1a5e382438082f4ed0e97ee0fd6 8ae668c6b19944b4a34bf2efdebc7dbc 5df3c1a5e382438082f4ed0e97ee0fd6--8ae668c6b19944b4a34bf2efdebc7dbc b98baf7805734f87944395dd86254242 8ae668c6b19944b4a34bf2efdebc7dbc--b98baf7805734f87944395dd86254242 9399e9fcdce74c399fee89ed074e97e7 b98baf7805734f87944395dd86254242--9399e9fcdce74c399fee89ed074e97e7 97e23cf0f84f455395502b59197d4086 9399e9fcdce74c399fee89ed074e97e7--97e23cf0f84f455395502b59197d4086 96cc1015fd0348f6bbda928c2b6774db 97e23cf0f84f455395502b59197d4086--96cc1015fd0348f6bbda928c2b6774db 49f8fe61b5334d7ab884d9d91b1c9885 96cc1015fd0348f6bbda928c2b6774db--49f8fe61b5334d7ab884d9d91b1c9885 ea0188624b7b41f1bcbf0fb879e08560 49f8fe61b5334d7ab884d9d91b1c9885--ea0188624b7b41f1bcbf0fb879e08560 32c06359f4f64e6a82d66be87d155a01 ea0188624b7b41f1bcbf0fb879e08560--32c06359f4f64e6a82d66be87d155a01 58c1af9051f14586a59eb3e303123a39 32c06359f4f64e6a82d66be87d155a01--58c1af9051f14586a59eb3e303123a39 c9f7bbd0f8454aec93194c9926fd25a1 58c1af9051f14586a59eb3e303123a39--c9f7bbd0f8454aec93194c9926fd25a1 d1a534165e0a44a9b24bcd48828b29a3 c9f7bbd0f8454aec93194c9926fd25a1--d1a534165e0a44a9b24bcd48828b29a3 977f906553234ef192e447f52f9ecf87 d1a534165e0a44a9b24bcd48828b29a3--977f906553234ef192e447f52f9ecf87 d2a05449f22e4852a070e64a9b82f9ee 977f906553234ef192e447f52f9ecf87--d2a05449f22e4852a070e64a9b82f9ee 2f57fac4ebd74939b43aa593c62550b6 d2a05449f22e4852a070e64a9b82f9ee--2f57fac4ebd74939b43aa593c62550b6 07ae950ad33f4fe28692e32537227e59 2f57fac4ebd74939b43aa593c62550b6--07ae950ad33f4fe28692e32537227e59 1783317f21414cd6908fb5261f98d81a 07ae950ad33f4fe28692e32537227e59--1783317f21414cd6908fb5261f98d81a e037d73ad6d943158d476fdcc625b55f 1783317f21414cd6908fb5261f98d81a--e037d73ad6d943158d476fdcc625b55f 31b482c71460495ba6b021fa429a5158 e037d73ad6d943158d476fdcc625b55f--31b482c71460495ba6b021fa429a5158 c608eb21e3854f9bbc42d740cff1d1b2 31b482c71460495ba6b021fa429a5158--c608eb21e3854f9bbc42d740cff1d1b2 8b3bc53e26e042f3b5b1ee7bced95881 c608eb21e3854f9bbc42d740cff1d1b2--8b3bc53e26e042f3b5b1ee7bced95881 178022dc53ab4ad9abee8d027791b95a RX(b03) 8b3bc53e26e042f3b5b1ee7bced95881--178022dc53ab4ad9abee8d027791b95a 1ee7af63be894ace922bd06cb2c16674 178022dc53ab4ad9abee8d027791b95a--1ee7af63be894ace922bd06cb2c16674 225e6b2c54654209a76e5eaf8b0fc403 1ee7af63be894ace922bd06cb2c16674--225e6b2c54654209a76e5eaf8b0fc403 322e7d9bf0114d8fb89eaff8d9b7badd X 225e6b2c54654209a76e5eaf8b0fc403--322e7d9bf0114d8fb89eaff8d9b7badd 322e7d9bf0114d8fb89eaff8d9b7badd--e9e3e1f910314086b3ca50436f6ffc32 b4606bcfc00f4c9d8e4dcc1a231e38cf 322e7d9bf0114d8fb89eaff8d9b7badd--b4606bcfc00f4c9d8e4dcc1a231e38cf 92f6d5fe9af748c6a39ed1d4c9b1603c b4606bcfc00f4c9d8e4dcc1a231e38cf--92f6d5fe9af748c6a39ed1d4c9b1603c 070ac489f4be4e87ac103824a3c56f96 92f6d5fe9af748c6a39ed1d4c9b1603c--070ac489f4be4e87ac103824a3c56f96 7ade60898afe4db78960ffebe36995c2 070ac489f4be4e87ac103824a3c56f96--7ade60898afe4db78960ffebe36995c2 46df88dd323345f29002f41e9100a347 7ade60898afe4db78960ffebe36995c2--46df88dd323345f29002f41e9100a347 25064036c9ef481eaa56702b8b3c5f48 46df88dd323345f29002f41e9100a347--25064036c9ef481eaa56702b8b3c5f48 0b7d0e12547b4c9a8b753d7ef6616298 25064036c9ef481eaa56702b8b3c5f48--0b7d0e12547b4c9a8b753d7ef6616298 fc4718c7055444a6b646c35024f538fb 0b7d0e12547b4c9a8b753d7ef6616298--fc4718c7055444a6b646c35024f538fb 0c1255173b2c475f9781e9273e5bb5f0 fc4718c7055444a6b646c35024f538fb--0c1255173b2c475f9781e9273e5bb5f0 68c9e4bc7c67485582702538ba95dda1 X 0c1255173b2c475f9781e9273e5bb5f0--68c9e4bc7c67485582702538ba95dda1 68c9e4bc7c67485582702538ba95dda1--4cafd2c368b845e085e1d2bf9993e387 ad19cd4b06314ed28195964f82a1855e 68c9e4bc7c67485582702538ba95dda1--ad19cd4b06314ed28195964f82a1855e 0102ea47a4bb43ed814a551487587a61 ad19cd4b06314ed28195964f82a1855e--0102ea47a4bb43ed814a551487587a61 abfa0cea73f7460aa09160bf1a62b31d 0102ea47a4bb43ed814a551487587a61--abfa0cea73f7460aa09160bf1a62b31d a97737139dfc4f7b84d2a258d10000ae abfa0cea73f7460aa09160bf1a62b31d--a97737139dfc4f7b84d2a258d10000ae adc743909cd04f2d8ff53de5873ce343 X a97737139dfc4f7b84d2a258d10000ae--adc743909cd04f2d8ff53de5873ce343 adc743909cd04f2d8ff53de5873ce343--3542d38876704bd1a052d9b3614e6550 5cbf14ad6978400db2b55963158b6600 adc743909cd04f2d8ff53de5873ce343--5cbf14ad6978400db2b55963158b6600 420bc3369b8040c4b521afe4bc7eed00 5cbf14ad6978400db2b55963158b6600--420bc3369b8040c4b521afe4bc7eed00 ace204dd95fe40878738cd8900ee8d86 420bc3369b8040c4b521afe4bc7eed00--ace204dd95fe40878738cd8900ee8d86 b1fc7253cb584dc89c306f57be95deda X ace204dd95fe40878738cd8900ee8d86--b1fc7253cb584dc89c306f57be95deda b1fc7253cb584dc89c306f57be95deda--d3ac927270794a00a9506319c5b58611 54a50a0f87bb486aa7a5723c5e4a2fab b1fc7253cb584dc89c306f57be95deda--54a50a0f87bb486aa7a5723c5e4a2fab 76e6dd7700a54ed28d636843f144e6cd 54a50a0f87bb486aa7a5723c5e4a2fab--76e6dd7700a54ed28d636843f144e6cd a8ff67c7911445eca123126dd0c702cf 76e6dd7700a54ed28d636843f144e6cd--a8ff67c7911445eca123126dd0c702cf 9e28c68e0a814c8188582370e2a1e5eb a8ff67c7911445eca123126dd0c702cf--9e28c68e0a814c8188582370e2a1e5eb 095c580705f84242a685d684ca1561db X 9e28c68e0a814c8188582370e2a1e5eb--095c580705f84242a685d684ca1561db 095c580705f84242a685d684ca1561db--62daf4d3b0a14a9c86576412580698f8 1df272e7e7894bf68310723171bc6f44 095c580705f84242a685d684ca1561db--1df272e7e7894bf68310723171bc6f44 db7e9b3157ab4a779973c89cae08915f 1df272e7e7894bf68310723171bc6f44--db7e9b3157ab4a779973c89cae08915f 2c58e970682b4d14b4522eb81d6a9b19 db7e9b3157ab4a779973c89cae08915f--2c58e970682b4d14b4522eb81d6a9b19 0163e78111374e5ca43290b398d2a7cd 2c58e970682b4d14b4522eb81d6a9b19--0163e78111374e5ca43290b398d2a7cd ed761a651734435d891ed41a32819c54 0163e78111374e5ca43290b398d2a7cd--ed761a651734435d891ed41a32819c54 964446f2fb074be88865200625a9f949 X ed761a651734435d891ed41a32819c54--964446f2fb074be88865200625a9f949 964446f2fb074be88865200625a9f949--73448513b009403abfc4feed50bd7dfb c1d3554244f34a58b360215e322e0fe8 964446f2fb074be88865200625a9f949--c1d3554244f34a58b360215e322e0fe8 15e443b5eb74480a936e10a9603d7356 c1d3554244f34a58b360215e322e0fe8--15e443b5eb74480a936e10a9603d7356 d071a460d91f41e8ae64a0935954ede9 15e443b5eb74480a936e10a9603d7356--d071a460d91f41e8ae64a0935954ede9 d3ab0910ad674a35b371fefd66cf4f2a d071a460d91f41e8ae64a0935954ede9--d3ab0910ad674a35b371fefd66cf4f2a b90eab55fa434117be6b2b8338cef9bc X d3ab0910ad674a35b371fefd66cf4f2a--b90eab55fa434117be6b2b8338cef9bc b90eab55fa434117be6b2b8338cef9bc--07b26541d1b94077b3582c6549bed05f 8a59666dd1a94370847534b7afd3ca5a b90eab55fa434117be6b2b8338cef9bc--8a59666dd1a94370847534b7afd3ca5a eaeae354b2554842b0513b083759302e 8a59666dd1a94370847534b7afd3ca5a--eaeae354b2554842b0513b083759302e 3032c1598bf74a838f3175ece2d9690a eaeae354b2554842b0513b083759302e--3032c1598bf74a838f3175ece2d9690a a3c32bc382a2493cb4e962e9c61bf1f1 3032c1598bf74a838f3175ece2d9690a--a3c32bc382a2493cb4e962e9c61bf1f1 0a5cbca864ca44caba9e9d8de802f161 a3c32bc382a2493cb4e962e9c61bf1f1--0a5cbca864ca44caba9e9d8de802f161 f3faad4b20f4421b934bc75f711d08e6 0a5cbca864ca44caba9e9d8de802f161--f3faad4b20f4421b934bc75f711d08e6 10f2dcd58fc84120835126877d4222ad f3faad4b20f4421b934bc75f711d08e6--10f2dcd58fc84120835126877d4222ad a16c00a88a0248408e4805f1e44ad0ee X 10f2dcd58fc84120835126877d4222ad--a16c00a88a0248408e4805f1e44ad0ee a16c00a88a0248408e4805f1e44ad0ee--3b3d1b8f1d944455b962dda0be139d39 9542cda0db9744f6843791558037786a a16c00a88a0248408e4805f1e44ad0ee--9542cda0db9744f6843791558037786a 50709ff7e732482bb07969bfcf426bbc 9542cda0db9744f6843791558037786a--50709ff7e732482bb07969bfcf426bbc 0211702ef9e7472b860a4ccf36b74f5a 50709ff7e732482bb07969bfcf426bbc--0211702ef9e7472b860a4ccf36b74f5a 3176008b1d5a441094af867f67c9ddb8 0211702ef9e7472b860a4ccf36b74f5a--3176008b1d5a441094af867f67c9ddb8 ca3e3971ec924a4487327a1a4b31cd11 X 3176008b1d5a441094af867f67c9ddb8--ca3e3971ec924a4487327a1a4b31cd11 ca3e3971ec924a4487327a1a4b31cd11--1604b4a378284b9691b967b412a5964f e34e55a1b9e94d3c8fac871874e94058 ca3e3971ec924a4487327a1a4b31cd11--e34e55a1b9e94d3c8fac871874e94058 217d25f083544652b1e89ac3294ef595 e34e55a1b9e94d3c8fac871874e94058--217d25f083544652b1e89ac3294ef595 0c7aa78600fa495596750f03d9d837e1 217d25f083544652b1e89ac3294ef595--0c7aa78600fa495596750f03d9d837e1 9db4b4a3e07840bc9169d3b1c491cae6 0c7aa78600fa495596750f03d9d837e1--9db4b4a3e07840bc9169d3b1c491cae6 439c91890408404b8e69a17038d191de 9db4b4a3e07840bc9169d3b1c491cae6--439c91890408404b8e69a17038d191de 5d3a991e70a542578c3457ba95fb3674 439c91890408404b8e69a17038d191de--5d3a991e70a542578c3457ba95fb3674 18322aa6a9ff41afb064e105a21bbbb6 5d3a991e70a542578c3457ba95fb3674--18322aa6a9ff41afb064e105a21bbbb6 9a0548aac05947469054706234af6c78 18322aa6a9ff41afb064e105a21bbbb6--9a0548aac05947469054706234af6c78 4f81595e6c254d8c8e7adfa42ee66326 9a0548aac05947469054706234af6c78--4f81595e6c254d8c8e7adfa42ee66326 33192c2ce637480db73e9d13e49826b6 X 4f81595e6c254d8c8e7adfa42ee66326--33192c2ce637480db73e9d13e49826b6 33192c2ce637480db73e9d13e49826b6--adb8141aa7fc47988443a68ce6181025 dc79efd3513047b3b55e3a437badb24d 33192c2ce637480db73e9d13e49826b6--dc79efd3513047b3b55e3a437badb24d c35ba959b00d4e75a4a3740b5aaad5d3 dc79efd3513047b3b55e3a437badb24d--c35ba959b00d4e75a4a3740b5aaad5d3 b4e1b6d2f3944b09b25795efccc339e7 c35ba959b00d4e75a4a3740b5aaad5d3--b4e1b6d2f3944b09b25795efccc339e7 50028d11d1794c33b55238b29d84f59a X b4e1b6d2f3944b09b25795efccc339e7--50028d11d1794c33b55238b29d84f59a 50028d11d1794c33b55238b29d84f59a--47331bccc7ac42e8b5065f6607a411d8 176c7765b5e94a59b7ecbd13d1dee925 RZ(-1.0*g1) 50028d11d1794c33b55238b29d84f59a--176c7765b5e94a59b7ecbd13d1dee925 65f65ae551394078a286278cf16d0f95 X 176c7765b5e94a59b7ecbd13d1dee925--65f65ae551394078a286278cf16d0f95 65f65ae551394078a286278cf16d0f95--84a58fcdf81f447fbc80629506c8f6da 4d529bfeb5d54c039fca3a40ace5320b 65f65ae551394078a286278cf16d0f95--4d529bfeb5d54c039fca3a40ace5320b 7139973da6234a729ff825f78998095d 4d529bfeb5d54c039fca3a40ace5320b--7139973da6234a729ff825f78998095d 57ed1f3cb1b340ffae4cf9416cd8de99 X 7139973da6234a729ff825f78998095d--57ed1f3cb1b340ffae4cf9416cd8de99 57ed1f3cb1b340ffae4cf9416cd8de99--f398555d72bd491b9b72df893e6c38ea fcf9ee10497c4aac93d265b1f3412484 57ed1f3cb1b340ffae4cf9416cd8de99--fcf9ee10497c4aac93d265b1f3412484 d82db5cb8158407fad05300d8a0c90bd fcf9ee10497c4aac93d265b1f3412484--d82db5cb8158407fad05300d8a0c90bd 27dd09116cde4acfbf704e94b9ba99ef d82db5cb8158407fad05300d8a0c90bd--27dd09116cde4acfbf704e94b9ba99ef eaaf2279311f4034b9bcc431d7c405bb X 27dd09116cde4acfbf704e94b9ba99ef--eaaf2279311f4034b9bcc431d7c405bb eaaf2279311f4034b9bcc431d7c405bb--55241a1e5d4a4b39993358b0ec5fc8db 666bee120c1a4cdc9fd117bc8ccea045 eaaf2279311f4034b9bcc431d7c405bb--666bee120c1a4cdc9fd117bc8ccea045 4439ed4fe686473c85ca21c1818610a7 666bee120c1a4cdc9fd117bc8ccea045--4439ed4fe686473c85ca21c1818610a7 2beb65f3b32b43f18bd1996dad942fdd X 4439ed4fe686473c85ca21c1818610a7--2beb65f3b32b43f18bd1996dad942fdd 2beb65f3b32b43f18bd1996dad942fdd--945d84b9908e48f2b5c899ee2c1ac139 5004dee9323f498ca7135ea913a7bd83 2beb65f3b32b43f18bd1996dad942fdd--5004dee9323f498ca7135ea913a7bd83 52714329fd3642e6b6d9fe4281e57767 5004dee9323f498ca7135ea913a7bd83--52714329fd3642e6b6d9fe4281e57767 5b3672a0de8b4554856e559db1daad73 52714329fd3642e6b6d9fe4281e57767--5b3672a0de8b4554856e559db1daad73 4e5241a5b50c4a8f94a9754d7c490ac0 5b3672a0de8b4554856e559db1daad73--4e5241a5b50c4a8f94a9754d7c490ac0 f9ea4cc52b8f41bf9f2220f5e4dec7fd 4e5241a5b50c4a8f94a9754d7c490ac0--f9ea4cc52b8f41bf9f2220f5e4dec7fd eb3b0887bd9b4095a2a17e74741a7393 f9ea4cc52b8f41bf9f2220f5e4dec7fd--eb3b0887bd9b4095a2a17e74741a7393 0aba677c2af042028a22c62d6f1eb477 eb3b0887bd9b4095a2a17e74741a7393--0aba677c2af042028a22c62d6f1eb477 67273a200395442aaf5ecaadab12d06a X 0aba677c2af042028a22c62d6f1eb477--67273a200395442aaf5ecaadab12d06a 67273a200395442aaf5ecaadab12d06a--f81ed691ad64439495e17ba614582b72 e2134ec00a74469a89f0bb36dd1a92f2 67273a200395442aaf5ecaadab12d06a--e2134ec00a74469a89f0bb36dd1a92f2 53ac7a637d49450eb3001ee894c93daf X e2134ec00a74469a89f0bb36dd1a92f2--53ac7a637d49450eb3001ee894c93daf 53ac7a637d49450eb3001ee894c93daf--9f1c9abbf3854d018d6825469509b9c5 c63b81d90d1e45029cd0229d854793b1 53ac7a637d49450eb3001ee894c93daf--c63b81d90d1e45029cd0229d854793b1 eace2f7236cb4fa280606a59d541b87e c63b81d90d1e45029cd0229d854793b1--eace2f7236cb4fa280606a59d541b87e 821ac1f871004c169354a2fa3e1d2d36 eace2f7236cb4fa280606a59d541b87e--821ac1f871004c169354a2fa3e1d2d36 d492ce7511404518a7820b73346ef4e9 X 821ac1f871004c169354a2fa3e1d2d36--d492ce7511404518a7820b73346ef4e9 d492ce7511404518a7820b73346ef4e9--f37febc0df4a46b0bba09a5a0ee175a5 600fa97c1af54071873f325e467b27f1 X d492ce7511404518a7820b73346ef4e9--600fa97c1af54071873f325e467b27f1 600fa97c1af54071873f325e467b27f1--e7234e52019c4a3a8e1807c4c9b3968f ffc8e33d0ca9467ab20cbcc9303e1de6 600fa97c1af54071873f325e467b27f1--ffc8e33d0ca9467ab20cbcc9303e1de6 803f8ca393b647b589d383ed7c40541f ffc8e33d0ca9467ab20cbcc9303e1de6--803f8ca393b647b589d383ed7c40541f 412b0cb78e9a427eb47fc6965ce3bff9 803f8ca393b647b589d383ed7c40541f--412b0cb78e9a427eb47fc6965ce3bff9 c716f79784b6479eb0ff7f6423e29fd4 412b0cb78e9a427eb47fc6965ce3bff9--c716f79784b6479eb0ff7f6423e29fd4 7ee95d66f5a44eaf8fabe3036ed42e54 c716f79784b6479eb0ff7f6423e29fd4--7ee95d66f5a44eaf8fabe3036ed42e54 419eb2292ed443e1babfbec97511c11b X 7ee95d66f5a44eaf8fabe3036ed42e54--419eb2292ed443e1babfbec97511c11b 419eb2292ed443e1babfbec97511c11b--b733b0f7af96435c864513e6698e300f 88de739044f845f5b8a759b26f389158 X 419eb2292ed443e1babfbec97511c11b--88de739044f845f5b8a759b26f389158 88de739044f845f5b8a759b26f389158--4183529dfd0649008adda43d1f103def bc2ab03f576240268112c8cbfc3867b9 88de739044f845f5b8a759b26f389158--bc2ab03f576240268112c8cbfc3867b9 7a35f78bab1041bb8c6ed70f46624c49 bc2ab03f576240268112c8cbfc3867b9--7a35f78bab1041bb8c6ed70f46624c49 9968870bc106478c9c781b1cfdd519a0 7a35f78bab1041bb8c6ed70f46624c49--9968870bc106478c9c781b1cfdd519a0 0998e18dde1b4e44a6de4c0637b72aeb 9968870bc106478c9c781b1cfdd519a0--0998e18dde1b4e44a6de4c0637b72aeb dc9579011a0b44a1b595f1a79e07831a 0998e18dde1b4e44a6de4c0637b72aeb--dc9579011a0b44a1b595f1a79e07831a 5b83d02736a44ab5a3fa296b405b1c15 dc9579011a0b44a1b595f1a79e07831a--5b83d02736a44ab5a3fa296b405b1c15 4336bed3a9ec404d9fbc5d3daeff341d 5b83d02736a44ab5a3fa296b405b1c15--4336bed3a9ec404d9fbc5d3daeff341d 0fc7dadb7a1d436ba88b3d42f38db021 X 4336bed3a9ec404d9fbc5d3daeff341d--0fc7dadb7a1d436ba88b3d42f38db021 0fc7dadb7a1d436ba88b3d42f38db021--1de8a10767844e40a7e8a8e21acdcb01 d9bf63e909e84ffe9c8a4db552d15431 0fc7dadb7a1d436ba88b3d42f38db021--d9bf63e909e84ffe9c8a4db552d15431 b8e01149a6b4482080a631da64270b53 d9bf63e909e84ffe9c8a4db552d15431--b8e01149a6b4482080a631da64270b53 190621832eaf4d9c8dd46cb961d58018 b8e01149a6b4482080a631da64270b53--190621832eaf4d9c8dd46cb961d58018 8c19a3384a694cee9c14c9c6bcbc78ab 190621832eaf4d9c8dd46cb961d58018--8c19a3384a694cee9c14c9c6bcbc78ab cef0c51efbe54ce2b5164b1641a6ad3f 8c19a3384a694cee9c14c9c6bcbc78ab--cef0c51efbe54ce2b5164b1641a6ad3f 5708987367c2482a93b0895abc60816f cef0c51efbe54ce2b5164b1641a6ad3f--5708987367c2482a93b0895abc60816f 46c5db6d69e14b00bfb0dd60bb5ef4a0 5708987367c2482a93b0895abc60816f--46c5db6d69e14b00bfb0dd60bb5ef4a0 6b5ff4f780924fdb98e1ec40c77bba32 46c5db6d69e14b00bfb0dd60bb5ef4a0--6b5ff4f780924fdb98e1ec40c77bba32 d4e49809f7cc443582569e3463d3e2cc 6b5ff4f780924fdb98e1ec40c77bba32--d4e49809f7cc443582569e3463d3e2cc 072dd10d2ba948c9b2c1395e09b9f5a2 d4e49809f7cc443582569e3463d3e2cc--072dd10d2ba948c9b2c1395e09b9f5a2 6501cba6177a43cd8c418ff51611e58b 072dd10d2ba948c9b2c1395e09b9f5a2--6501cba6177a43cd8c418ff51611e58b 471a10c11e504912b358a2e58cb4ea9c 6501cba6177a43cd8c418ff51611e58b--471a10c11e504912b358a2e58cb4ea9c 9553fc74d11c426fbe9abffcb6c58b3a 471a10c11e504912b358a2e58cb4ea9c--9553fc74d11c426fbe9abffcb6c58b3a 37f0b194dfd34a54a7e635059e07e4f2 9553fc74d11c426fbe9abffcb6c58b3a--37f0b194dfd34a54a7e635059e07e4f2 df2b826455024579b5943d8f3898e1fd 37f0b194dfd34a54a7e635059e07e4f2--df2b826455024579b5943d8f3898e1fd 321fadc1d95145b181cbc113eab01133 df2b826455024579b5943d8f3898e1fd--321fadc1d95145b181cbc113eab01133 a4d64094b8a1470b8b8d040d8894278e 321fadc1d95145b181cbc113eab01133--a4d64094b8a1470b8b8d040d8894278e 37269cce60d644d98c1799fe085a8b45 a4d64094b8a1470b8b8d040d8894278e--37269cce60d644d98c1799fe085a8b45 149f415272ca4989a14930d96830fb1b 37269cce60d644d98c1799fe085a8b45--149f415272ca4989a14930d96830fb1b fd7eb25fcc0940d28d5819da0febc22e 149f415272ca4989a14930d96830fb1b--fd7eb25fcc0940d28d5819da0febc22e 85c81bbad89c4998b735d47aed9204ee fd7eb25fcc0940d28d5819da0febc22e--85c81bbad89c4998b735d47aed9204ee 5747521866ce43a3bb7b47d2a1814d0d 85c81bbad89c4998b735d47aed9204ee--5747521866ce43a3bb7b47d2a1814d0d 458e02acc7cd4eecad4b7db61948919a 5747521866ce43a3bb7b47d2a1814d0d--458e02acc7cd4eecad4b7db61948919a 866c8a0054ef44199069631ddef62c99 458e02acc7cd4eecad4b7db61948919a--866c8a0054ef44199069631ddef62c99 a777e0c522e64170b941823e25190a76 RX(b13) 866c8a0054ef44199069631ddef62c99--a777e0c522e64170b941823e25190a76 a777e0c522e64170b941823e25190a76--290e9bc7f6cb411da9001ab0c0829b15 057fb3b8a7bf4ab58105fdd5327b61c7 e93ba82677904f0580822357ee6dd904 bfe458081d65449ba06828a2dde2f0ee--e93ba82677904f0580822357ee6dd904 18ddba92c69b4b82822cfba037795535 5 64ff076979f54624bb858d724cae956f e93ba82677904f0580822357ee6dd904--64ff076979f54624bb858d724cae956f 94d343a686b247d2b762d76b2d738781 64ff076979f54624bb858d724cae956f--94d343a686b247d2b762d76b2d738781 9c2f2d30ac72480f8333bfd550a95a90 X 94d343a686b247d2b762d76b2d738781--9c2f2d30ac72480f8333bfd550a95a90 9c2f2d30ac72480f8333bfd550a95a90--edd8dccb3c3e42c78926ce5c1bd6dab7 90c618179f4d4644bc019db1818ca711 9c2f2d30ac72480f8333bfd550a95a90--90c618179f4d4644bc019db1818ca711 6a88759ce4cb4107bc5407be2dcd9847 90c618179f4d4644bc019db1818ca711--6a88759ce4cb4107bc5407be2dcd9847 023781981bd0464bbb7080634b5bf079 6a88759ce4cb4107bc5407be2dcd9847--023781981bd0464bbb7080634b5bf079 c00a489d676345198ee0fec8be2d8d2c 023781981bd0464bbb7080634b5bf079--c00a489d676345198ee0fec8be2d8d2c ea167bf3c05044929fb5899c06140ac5 c00a489d676345198ee0fec8be2d8d2c--ea167bf3c05044929fb5899c06140ac5 646cbaa212b34e8487bc0708e5ee85fe ea167bf3c05044929fb5899c06140ac5--646cbaa212b34e8487bc0708e5ee85fe f1bee105ebc04fb68cf94bfe29fed8bb 646cbaa212b34e8487bc0708e5ee85fe--f1bee105ebc04fb68cf94bfe29fed8bb b354a7a3c63240bfaca4d1daab315fed X f1bee105ebc04fb68cf94bfe29fed8bb--b354a7a3c63240bfaca4d1daab315fed b354a7a3c63240bfaca4d1daab315fed--6b783de5d092473aab051f381efac3e6 d8946a307baa4fc493b6636e486d6c88 b354a7a3c63240bfaca4d1daab315fed--d8946a307baa4fc493b6636e486d6c88 a4c5b7e6b807434db9b4468e3172b2df d8946a307baa4fc493b6636e486d6c88--a4c5b7e6b807434db9b4468e3172b2df 89ffb87333c94cc6a839ba363f939760 a4c5b7e6b807434db9b4468e3172b2df--89ffb87333c94cc6a839ba363f939760 f674bac54cb54415b6f0719b67f7b747 89ffb87333c94cc6a839ba363f939760--f674bac54cb54415b6f0719b67f7b747 0f564ae0eace4cf0a4b428313366bc81 f674bac54cb54415b6f0719b67f7b747--0f564ae0eace4cf0a4b428313366bc81 d5ce5683714f4e5594e49fd7e573ae80 0f564ae0eace4cf0a4b428313366bc81--d5ce5683714f4e5594e49fd7e573ae80 00856612ce594ef9ab6d9b9f8f85c6bf X d5ce5683714f4e5594e49fd7e573ae80--00856612ce594ef9ab6d9b9f8f85c6bf 00856612ce594ef9ab6d9b9f8f85c6bf--e3c891fda632466c8b03d0d271319967 4d968488b96044b98ceedf89100bc6ca RZ(-1.0*g0) 00856612ce594ef9ab6d9b9f8f85c6bf--4d968488b96044b98ceedf89100bc6ca e6c77cad95bc49ce91fbf8bba6ad8e21 X 4d968488b96044b98ceedf89100bc6ca--e6c77cad95bc49ce91fbf8bba6ad8e21 e6c77cad95bc49ce91fbf8bba6ad8e21--d325af2a2db345e3ae297b5276257ebc 5db95033b33f4999be66bbf14b15d4e5 e6c77cad95bc49ce91fbf8bba6ad8e21--5db95033b33f4999be66bbf14b15d4e5 c3f9154007734040babe8f268f8e8aa0 5db95033b33f4999be66bbf14b15d4e5--c3f9154007734040babe8f268f8e8aa0 fcf675675b554abd92c6304c5caf0b7d c3f9154007734040babe8f268f8e8aa0--fcf675675b554abd92c6304c5caf0b7d 06819884e46042b5b026d2d5342d90e7 fcf675675b554abd92c6304c5caf0b7d--06819884e46042b5b026d2d5342d90e7 cd5c4f423ddd4c9584f5b458082ff8da 06819884e46042b5b026d2d5342d90e7--cd5c4f423ddd4c9584f5b458082ff8da 8ca1dc21cfb94e89a48226e9f5ee6aed cd5c4f423ddd4c9584f5b458082ff8da--8ca1dc21cfb94e89a48226e9f5ee6aed ff13d08a2a5b4eedae9f6b9d1eefbbfa X 8ca1dc21cfb94e89a48226e9f5ee6aed--ff13d08a2a5b4eedae9f6b9d1eefbbfa ff13d08a2a5b4eedae9f6b9d1eefbbfa--b4e3449d40b04b9bb968ce3fb5afe091 7fd4eab27b024a398fa5352c95d95de0 ff13d08a2a5b4eedae9f6b9d1eefbbfa--7fd4eab27b024a398fa5352c95d95de0 90e78b9b8d9c4a73b2ae61ed1a3be852 7fd4eab27b024a398fa5352c95d95de0--90e78b9b8d9c4a73b2ae61ed1a3be852 de20080d19c249619c8c844efe79809a 90e78b9b8d9c4a73b2ae61ed1a3be852--de20080d19c249619c8c844efe79809a 9d015235519548ec909512774f7db657 X de20080d19c249619c8c844efe79809a--9d015235519548ec909512774f7db657 9d015235519548ec909512774f7db657--4329a360fd4d42b18768c0b3ae7d041a b20a74a744d74b1485a3b7e131c7b865 9d015235519548ec909512774f7db657--b20a74a744d74b1485a3b7e131c7b865 9429b5e96ebf4e018e5693842160bddd b20a74a744d74b1485a3b7e131c7b865--9429b5e96ebf4e018e5693842160bddd e5eb5b81f4684691b2bc486adad8e680 9429b5e96ebf4e018e5693842160bddd--e5eb5b81f4684691b2bc486adad8e680 a396c0b7088840ae931ff293b7197a6d e5eb5b81f4684691b2bc486adad8e680--a396c0b7088840ae931ff293b7197a6d fec451b40bb74dc2959f1c0037982c67 a396c0b7088840ae931ff293b7197a6d--fec451b40bb74dc2959f1c0037982c67 b3a0d72e55b84c62acaacf2980f4fdc5 fec451b40bb74dc2959f1c0037982c67--b3a0d72e55b84c62acaacf2980f4fdc5 0e953c9c7ddd444e9d5d196b0659a4ed X b3a0d72e55b84c62acaacf2980f4fdc5--0e953c9c7ddd444e9d5d196b0659a4ed 0e953c9c7ddd444e9d5d196b0659a4ed--6735550a431d42d090d3e6465cd012c3 638c2ddc5aa64de1a9bf141a1331bf91 0e953c9c7ddd444e9d5d196b0659a4ed--638c2ddc5aa64de1a9bf141a1331bf91 9e15be4944c54d1f98b3d367b4629c9b 638c2ddc5aa64de1a9bf141a1331bf91--9e15be4944c54d1f98b3d367b4629c9b 70bc1a3c7dd14e18ad73ec4aa83a3698 9e15be4944c54d1f98b3d367b4629c9b--70bc1a3c7dd14e18ad73ec4aa83a3698 751c4060ca2e4dfb959db106387320eb 70bc1a3c7dd14e18ad73ec4aa83a3698--751c4060ca2e4dfb959db106387320eb d4a293ae2c3d48fcab33b4534be5b5f5 751c4060ca2e4dfb959db106387320eb--d4a293ae2c3d48fcab33b4534be5b5f5 be3fe9e41c0441d2ab7face291db7483 X d4a293ae2c3d48fcab33b4534be5b5f5--be3fe9e41c0441d2ab7face291db7483 be3fe9e41c0441d2ab7face291db7483--87dcc2aa95f34bea820660c8817f8d88 0cb2ba95f2eb45e483901045d98c6525 be3fe9e41c0441d2ab7face291db7483--0cb2ba95f2eb45e483901045d98c6525 1bfb90ee0dee40a38b8f70dc9bc9f0cb 0cb2ba95f2eb45e483901045d98c6525--1bfb90ee0dee40a38b8f70dc9bc9f0cb 41a1f47ced5748d08562a3fff46df653 1bfb90ee0dee40a38b8f70dc9bc9f0cb--41a1f47ced5748d08562a3fff46df653 719779f58d904327944eb1dee1f65c2c 41a1f47ced5748d08562a3fff46df653--719779f58d904327944eb1dee1f65c2c cba4796fefed4e479c2f6b93e30b9e31 719779f58d904327944eb1dee1f65c2c--cba4796fefed4e479c2f6b93e30b9e31 171d03c9b0b24580a58e6ed0d6d3a75a cba4796fefed4e479c2f6b93e30b9e31--171d03c9b0b24580a58e6ed0d6d3a75a cea351a9c4e14e31afbc3fc82a2fd2e6 X 171d03c9b0b24580a58e6ed0d6d3a75a--cea351a9c4e14e31afbc3fc82a2fd2e6 cea351a9c4e14e31afbc3fc82a2fd2e6--8fa7a6ae722f4f1c8b28a915b78bda2b 878d1e3d81d849c4a117abc05816fdc5 cea351a9c4e14e31afbc3fc82a2fd2e6--878d1e3d81d849c4a117abc05816fdc5 e2508d293e834ed0be56b8ddee95f4ee 878d1e3d81d849c4a117abc05816fdc5--e2508d293e834ed0be56b8ddee95f4ee fc922fcbf15748baa4891e8ec3398f25 e2508d293e834ed0be56b8ddee95f4ee--fc922fcbf15748baa4891e8ec3398f25 c2b3d945439240ab86690502e0c37702 fc922fcbf15748baa4891e8ec3398f25--c2b3d945439240ab86690502e0c37702 fdf9e4a5f0d243abb39a81ed2abcb6ff c2b3d945439240ab86690502e0c37702--fdf9e4a5f0d243abb39a81ed2abcb6ff 7517873fb1c449b3aab780085c073a6e fdf9e4a5f0d243abb39a81ed2abcb6ff--7517873fb1c449b3aab780085c073a6e c9302885dd524fea9a869b5bc2114dec 7517873fb1c449b3aab780085c073a6e--c9302885dd524fea9a869b5bc2114dec e15bbd1f3283489c80df6192494e08e3 X c9302885dd524fea9a869b5bc2114dec--e15bbd1f3283489c80df6192494e08e3 e15bbd1f3283489c80df6192494e08e3--b9c0848354fc49f0adae719caf6c1974 9d360ca84fb940ff8422197693163bfb e15bbd1f3283489c80df6192494e08e3--9d360ca84fb940ff8422197693163bfb 6bff52f07cf24c69b9f78f955d6a9422 9d360ca84fb940ff8422197693163bfb--6bff52f07cf24c69b9f78f955d6a9422 2fb2761c6b3f4f91bb7d6965761a9ff1 6bff52f07cf24c69b9f78f955d6a9422--2fb2761c6b3f4f91bb7d6965761a9ff1 c6ef70523e3c45309d8422f567ee3b56 2fb2761c6b3f4f91bb7d6965761a9ff1--c6ef70523e3c45309d8422f567ee3b56 22a2807228cb40ff8e79845e111f6d5a c6ef70523e3c45309d8422f567ee3b56--22a2807228cb40ff8e79845e111f6d5a 811ba40fbe234218ab8c573fb1049970 22a2807228cb40ff8e79845e111f6d5a--811ba40fbe234218ab8c573fb1049970 e9777ff5b5474a8ba7232d4e389c26ee 811ba40fbe234218ab8c573fb1049970--e9777ff5b5474a8ba7232d4e389c26ee b9bd18a8266640579ee478fe44683170 e9777ff5b5474a8ba7232d4e389c26ee--b9bd18a8266640579ee478fe44683170 56bd931d122f4e3a9d96746bfcacd1a1 b9bd18a8266640579ee478fe44683170--56bd931d122f4e3a9d96746bfcacd1a1 6d1bc5507d384f9d8267cbcc7bb88d2c 56bd931d122f4e3a9d96746bfcacd1a1--6d1bc5507d384f9d8267cbcc7bb88d2c 90470236152d4fbf916d5685e8c68999 X 6d1bc5507d384f9d8267cbcc7bb88d2c--90470236152d4fbf916d5685e8c68999 90470236152d4fbf916d5685e8c68999--20a8ca325e944ca7b84688277e4c86c8 04c26ea2b2e74896b1d9a01da11bcdd5 RZ(-1.0*g0) 90470236152d4fbf916d5685e8c68999--04c26ea2b2e74896b1d9a01da11bcdd5 19d68a57cf1f445792a22d5ca7a26dda X 04c26ea2b2e74896b1d9a01da11bcdd5--19d68a57cf1f445792a22d5ca7a26dda 19d68a57cf1f445792a22d5ca7a26dda--c3dcff7ed56f43b3a8e9a890ad1322e9 8098186b86d04c03a15c159aaf959584 19d68a57cf1f445792a22d5ca7a26dda--8098186b86d04c03a15c159aaf959584 f7c68dd9650646c5a34cdb8f5c217345 8098186b86d04c03a15c159aaf959584--f7c68dd9650646c5a34cdb8f5c217345 eddc22544b124bef8a58ab0e1ffd794c f7c68dd9650646c5a34cdb8f5c217345--eddc22544b124bef8a58ab0e1ffd794c 6f29051c3ad9416bb36f02fb202ad132 eddc22544b124bef8a58ab0e1ffd794c--6f29051c3ad9416bb36f02fb202ad132 9610d74453dd4329beb490f6c6aed2a3 X 6f29051c3ad9416bb36f02fb202ad132--9610d74453dd4329beb490f6c6aed2a3 9610d74453dd4329beb490f6c6aed2a3--a4082cb183664662bce6c097932bd87f 7800baba8bbd483597c42121d335439f 9610d74453dd4329beb490f6c6aed2a3--7800baba8bbd483597c42121d335439f deb16b0aa7f4417d8566e943c0afe951 7800baba8bbd483597c42121d335439f--deb16b0aa7f4417d8566e943c0afe951 3e00e97f7a5c486c8c3524eb476a205a deb16b0aa7f4417d8566e943c0afe951--3e00e97f7a5c486c8c3524eb476a205a deb8b6527f874b7f83b307351d0e0819 3e00e97f7a5c486c8c3524eb476a205a--deb8b6527f874b7f83b307351d0e0819 a411739d597846269feff6dfbc1e247c deb8b6527f874b7f83b307351d0e0819--a411739d597846269feff6dfbc1e247c 6f2040d1ca1646d685f67617b63f6681 X a411739d597846269feff6dfbc1e247c--6f2040d1ca1646d685f67617b63f6681 6f2040d1ca1646d685f67617b63f6681--60daa37f81d84cc6bf639a43034b1487 9b9cca3128fc4860a15d6d2c972a3902 6f2040d1ca1646d685f67617b63f6681--9b9cca3128fc4860a15d6d2c972a3902 132f02f768854c908efb72c7015207e9 9b9cca3128fc4860a15d6d2c972a3902--132f02f768854c908efb72c7015207e9 3b51a00e6ee944269da6a08f9b9eb5bf 132f02f768854c908efb72c7015207e9--3b51a00e6ee944269da6a08f9b9eb5bf 517a27d385e6480ea2e3f93c7d54c49c X 3b51a00e6ee944269da6a08f9b9eb5bf--517a27d385e6480ea2e3f93c7d54c49c 517a27d385e6480ea2e3f93c7d54c49c--27777b3ccdaf45229837542bc3bb30d4 e00ebe91b3634c08b761a97ab0ac8f85 RZ(-1.0*g0) 517a27d385e6480ea2e3f93c7d54c49c--e00ebe91b3634c08b761a97ab0ac8f85 36f43476d810492992a70b14cd236060 X e00ebe91b3634c08b761a97ab0ac8f85--36f43476d810492992a70b14cd236060 36f43476d810492992a70b14cd236060--54684a18096144bea2fb07df0e7a8f99 6cb95390cb7a435d8d6873fcf4765188 36f43476d810492992a70b14cd236060--6cb95390cb7a435d8d6873fcf4765188 d98c910de08e42cba2738a83489f426c 6cb95390cb7a435d8d6873fcf4765188--d98c910de08e42cba2738a83489f426c 4747105b3fda4a30bd580ef7c5f8ed99 X d98c910de08e42cba2738a83489f426c--4747105b3fda4a30bd580ef7c5f8ed99 4747105b3fda4a30bd580ef7c5f8ed99--1d86f940f75b4bbba078e9a5933f9bc5 bd984605ccda43d499abfce4babeaae0 4747105b3fda4a30bd580ef7c5f8ed99--bd984605ccda43d499abfce4babeaae0 52033b8912aa4ec7ada8385d167d7f04 bd984605ccda43d499abfce4babeaae0--52033b8912aa4ec7ada8385d167d7f04 e379e95e7c5c42b6abf0b9335ecc7e90 52033b8912aa4ec7ada8385d167d7f04--e379e95e7c5c42b6abf0b9335ecc7e90 bedd14cb329d4f1bb11df73ea03d178e X e379e95e7c5c42b6abf0b9335ecc7e90--bedd14cb329d4f1bb11df73ea03d178e bedd14cb329d4f1bb11df73ea03d178e--280afa086ec349878f5a1356e4f683b7 d6cc344382d1403ca6686a7cbc3e64e7 bedd14cb329d4f1bb11df73ea03d178e--d6cc344382d1403ca6686a7cbc3e64e7 5d8acf4a9a864cfa8a38c6cc43cc6317 d6cc344382d1403ca6686a7cbc3e64e7--5d8acf4a9a864cfa8a38c6cc43cc6317 b8828a851daf4074a0810ae93aa7a8d7 X 5d8acf4a9a864cfa8a38c6cc43cc6317--b8828a851daf4074a0810ae93aa7a8d7 b8828a851daf4074a0810ae93aa7a8d7--ad9ea59908b84d62abf3f3118b9fa108 27c50dc7dfca4b63855114cc8994ac52 b8828a851daf4074a0810ae93aa7a8d7--27c50dc7dfca4b63855114cc8994ac52 5ceeb1ef2c434a9cb5e180dbd64ed74b 27c50dc7dfca4b63855114cc8994ac52--5ceeb1ef2c434a9cb5e180dbd64ed74b b45812247e814fcc99badc97e99edc64 5ceeb1ef2c434a9cb5e180dbd64ed74b--b45812247e814fcc99badc97e99edc64 becbcc2890964946a0a8a73623f36f40 b45812247e814fcc99badc97e99edc64--becbcc2890964946a0a8a73623f36f40 08d82f23bc674f1cade20d1f9a1f8434 becbcc2890964946a0a8a73623f36f40--08d82f23bc674f1cade20d1f9a1f8434 e11ffe8efd3c4ef48d7b6f2ef039ec10 X 08d82f23bc674f1cade20d1f9a1f8434--e11ffe8efd3c4ef48d7b6f2ef039ec10 e11ffe8efd3c4ef48d7b6f2ef039ec10--3a268ae221a94e12a60b2dd7d4fb548f a8d62caa221a406880a1d3524684d2ac e11ffe8efd3c4ef48d7b6f2ef039ec10--a8d62caa221a406880a1d3524684d2ac 8d03b844a5404a768d1ce78680dd296f X a8d62caa221a406880a1d3524684d2ac--8d03b844a5404a768d1ce78680dd296f 8d03b844a5404a768d1ce78680dd296f--024cb3dd2ca94d0b91f7f4e7b5f20b8a ccda2f0d2c15441e805cb59f84d2c145 8d03b844a5404a768d1ce78680dd296f--ccda2f0d2c15441e805cb59f84d2c145 3deb5f92a57f4f56a8bbc828d92fba29 ccda2f0d2c15441e805cb59f84d2c145--3deb5f92a57f4f56a8bbc828d92fba29 9fc9d144aa384012bd8e02b8fb686a88 3deb5f92a57f4f56a8bbc828d92fba29--9fc9d144aa384012bd8e02b8fb686a88 d112753337b441a6a307c37894fca20f X 9fc9d144aa384012bd8e02b8fb686a88--d112753337b441a6a307c37894fca20f d112753337b441a6a307c37894fca20f--8ae668c6b19944b4a34bf2efdebc7dbc 6ec7eda4245a45d78946737e15ca40f1 X d112753337b441a6a307c37894fca20f--6ec7eda4245a45d78946737e15ca40f1 6ec7eda4245a45d78946737e15ca40f1--b98baf7805734f87944395dd86254242 7e6948f819dc4ebea1660f53acf6664c 6ec7eda4245a45d78946737e15ca40f1--7e6948f819dc4ebea1660f53acf6664c b213f6f3973f4343a581bee43078d8ea 7e6948f819dc4ebea1660f53acf6664c--b213f6f3973f4343a581bee43078d8ea 8efe65219ee34d06b95bf2dec8078028 b213f6f3973f4343a581bee43078d8ea--8efe65219ee34d06b95bf2dec8078028 5edab17b58b842398cc67e46ed505303 8efe65219ee34d06b95bf2dec8078028--5edab17b58b842398cc67e46ed505303 75ca44bb02c64f6b90a414edc40dc12b 5edab17b58b842398cc67e46ed505303--75ca44bb02c64f6b90a414edc40dc12b 8f34450fd778468f839b3cd7775ef6a2 X 75ca44bb02c64f6b90a414edc40dc12b--8f34450fd778468f839b3cd7775ef6a2 8f34450fd778468f839b3cd7775ef6a2--32c06359f4f64e6a82d66be87d155a01 75deec189f234e7e863d6d5b249c18c4 X 8f34450fd778468f839b3cd7775ef6a2--75deec189f234e7e863d6d5b249c18c4 75deec189f234e7e863d6d5b249c18c4--58c1af9051f14586a59eb3e303123a39 7bf474d45d604012a2d80495fd5a12f5 75deec189f234e7e863d6d5b249c18c4--7bf474d45d604012a2d80495fd5a12f5 758e122a3458484aa7a11d2780aa8760 7bf474d45d604012a2d80495fd5a12f5--758e122a3458484aa7a11d2780aa8760 a373c811a05545d3835dd2f175f990e9 758e122a3458484aa7a11d2780aa8760--a373c811a05545d3835dd2f175f990e9 cb4c11d17700421786247b8d48d2de95 a373c811a05545d3835dd2f175f990e9--cb4c11d17700421786247b8d48d2de95 cd6715a7b39b4aacaa90d82fdcb3395d cb4c11d17700421786247b8d48d2de95--cd6715a7b39b4aacaa90d82fdcb3395d 6aca8643440144c7ab35d3e42faae37b cd6715a7b39b4aacaa90d82fdcb3395d--6aca8643440144c7ab35d3e42faae37b 63f2bebf98464d9ca1bbc9c462a65d81 6aca8643440144c7ab35d3e42faae37b--63f2bebf98464d9ca1bbc9c462a65d81 7b418b19299c4c61952838c0e6b4eac4 X 63f2bebf98464d9ca1bbc9c462a65d81--7b418b19299c4c61952838c0e6b4eac4 7b418b19299c4c61952838c0e6b4eac4--e037d73ad6d943158d476fdcc625b55f b5a09f67d3f848018e3e313c565af478 7b418b19299c4c61952838c0e6b4eac4--b5a09f67d3f848018e3e313c565af478 04b2815994af442ab792a3eac22a7a78 b5a09f67d3f848018e3e313c565af478--04b2815994af442ab792a3eac22a7a78 4a327c628b3248b1b498eb2810a7c540 04b2815994af442ab792a3eac22a7a78--4a327c628b3248b1b498eb2810a7c540 c3f941287049465d8f358ddd8084fc94 RX(b04) 4a327c628b3248b1b498eb2810a7c540--c3f941287049465d8f358ddd8084fc94 b4357e0889a0403ba338f9e6351b584c c3f941287049465d8f358ddd8084fc94--b4357e0889a0403ba338f9e6351b584c 86f8fbcdcfb64b7b92b0520e476fa701 b4357e0889a0403ba338f9e6351b584c--86f8fbcdcfb64b7b92b0520e476fa701 851f76ce4d8a49d1b341173c3b03c115 86f8fbcdcfb64b7b92b0520e476fa701--851f76ce4d8a49d1b341173c3b03c115 79993f42ab714122939a614ca3ba4742 X 851f76ce4d8a49d1b341173c3b03c115--79993f42ab714122939a614ca3ba4742 79993f42ab714122939a614ca3ba4742--b4606bcfc00f4c9d8e4dcc1a231e38cf 6774bb6402254dec8998ee917cc6b6a3 79993f42ab714122939a614ca3ba4742--6774bb6402254dec8998ee917cc6b6a3 d4bc2345ec0b4c538b8efdbabe899204 6774bb6402254dec8998ee917cc6b6a3--d4bc2345ec0b4c538b8efdbabe899204 d446912b3d904f6a9355c65bfe3fc0cd d4bc2345ec0b4c538b8efdbabe899204--d446912b3d904f6a9355c65bfe3fc0cd a15a9b2c4a654849818db53a8bfa4f1d d446912b3d904f6a9355c65bfe3fc0cd--a15a9b2c4a654849818db53a8bfa4f1d b597b577e0a14557a217ead5a1e0c819 a15a9b2c4a654849818db53a8bfa4f1d--b597b577e0a14557a217ead5a1e0c819 a3429da86f0542dabb56c36ccf99947f b597b577e0a14557a217ead5a1e0c819--a3429da86f0542dabb56c36ccf99947f 31de7dc3d3e7450b8afea37312b9c100 a3429da86f0542dabb56c36ccf99947f--31de7dc3d3e7450b8afea37312b9c100 12e4e8e18f9f4d558980a5392c1ae108 X 31de7dc3d3e7450b8afea37312b9c100--12e4e8e18f9f4d558980a5392c1ae108 12e4e8e18f9f4d558980a5392c1ae108--0c1255173b2c475f9781e9273e5bb5f0 fd55f586c1d64b7ba018fc3266c39d86 12e4e8e18f9f4d558980a5392c1ae108--fd55f586c1d64b7ba018fc3266c39d86 61173a38491a402389bee2379c3b342c fd55f586c1d64b7ba018fc3266c39d86--61173a38491a402389bee2379c3b342c ebe6bd4767274a938d95b0ea30f1c893 61173a38491a402389bee2379c3b342c--ebe6bd4767274a938d95b0ea30f1c893 dad6e13851894b52975f70b0b3b7269a ebe6bd4767274a938d95b0ea30f1c893--dad6e13851894b52975f70b0b3b7269a 110ee31160f84cd2bbf7668aaebd4c12 dad6e13851894b52975f70b0b3b7269a--110ee31160f84cd2bbf7668aaebd4c12 29c258df2e71400bb8ebc07d7baac617 110ee31160f84cd2bbf7668aaebd4c12--29c258df2e71400bb8ebc07d7baac617 62193392087b4aadbe1b2b158fd938cd X 29c258df2e71400bb8ebc07d7baac617--62193392087b4aadbe1b2b158fd938cd 62193392087b4aadbe1b2b158fd938cd--5cbf14ad6978400db2b55963158b6600 c5f3e027cdb849aa8cbccb6c4050c092 RZ(-1.0*g1) 62193392087b4aadbe1b2b158fd938cd--c5f3e027cdb849aa8cbccb6c4050c092 eef943607c8e436baad8c60373998f1c X c5f3e027cdb849aa8cbccb6c4050c092--eef943607c8e436baad8c60373998f1c eef943607c8e436baad8c60373998f1c--ace204dd95fe40878738cd8900ee8d86 38bf524b876c46539bdcdb4523e411f3 eef943607c8e436baad8c60373998f1c--38bf524b876c46539bdcdb4523e411f3 89849d6305984e3ab75f20bbad31a177 38bf524b876c46539bdcdb4523e411f3--89849d6305984e3ab75f20bbad31a177 67a174d0a0174c8195e6641794a6d3f8 89849d6305984e3ab75f20bbad31a177--67a174d0a0174c8195e6641794a6d3f8 e6e031a063fb45428f401741abf6e200 67a174d0a0174c8195e6641794a6d3f8--e6e031a063fb45428f401741abf6e200 f2453b2085bf49218326c3cf78489471 e6e031a063fb45428f401741abf6e200--f2453b2085bf49218326c3cf78489471 7807f92b86894dc4b2d1981bcfb6297e f2453b2085bf49218326c3cf78489471--7807f92b86894dc4b2d1981bcfb6297e 37967b217c1446a0a1b288b1e4e11af4 X 7807f92b86894dc4b2d1981bcfb6297e--37967b217c1446a0a1b288b1e4e11af4 37967b217c1446a0a1b288b1e4e11af4--1df272e7e7894bf68310723171bc6f44 ff3c2de5039f45e6bcb750c7398e8afd 37967b217c1446a0a1b288b1e4e11af4--ff3c2de5039f45e6bcb750c7398e8afd 1c8d89477f18485496ee55452d280df2 ff3c2de5039f45e6bcb750c7398e8afd--1c8d89477f18485496ee55452d280df2 57a97f69d7014c9cb4777272a8ce27ea 1c8d89477f18485496ee55452d280df2--57a97f69d7014c9cb4777272a8ce27ea 3d3b58b983144a3eac6258b070a3a01a X 57a97f69d7014c9cb4777272a8ce27ea--3d3b58b983144a3eac6258b070a3a01a 3d3b58b983144a3eac6258b070a3a01a--ed761a651734435d891ed41a32819c54 25f5c8de4b9748d9b0d126f0f5a33e01 3d3b58b983144a3eac6258b070a3a01a--25f5c8de4b9748d9b0d126f0f5a33e01 5e006e8f7e08453184d411dc28a6f522 25f5c8de4b9748d9b0d126f0f5a33e01--5e006e8f7e08453184d411dc28a6f522 e48f3f5717aa48d4a978f947dd18987b 5e006e8f7e08453184d411dc28a6f522--e48f3f5717aa48d4a978f947dd18987b bf23d15ee1d44301a75a89687ab4302a e48f3f5717aa48d4a978f947dd18987b--bf23d15ee1d44301a75a89687ab4302a 66a604ced991410fb63e1daf053581ee bf23d15ee1d44301a75a89687ab4302a--66a604ced991410fb63e1daf053581ee ec4679627db54d379b835addd67c2f60 66a604ced991410fb63e1daf053581ee--ec4679627db54d379b835addd67c2f60 2ef9301fe1fd4c79bf75b02b92dd8678 X ec4679627db54d379b835addd67c2f60--2ef9301fe1fd4c79bf75b02b92dd8678 2ef9301fe1fd4c79bf75b02b92dd8678--8a59666dd1a94370847534b7afd3ca5a 91ad4931c11e4512b8baf669d67b2e57 2ef9301fe1fd4c79bf75b02b92dd8678--91ad4931c11e4512b8baf669d67b2e57 94ea8d39fe154af49e9ccab78ba203e9 91ad4931c11e4512b8baf669d67b2e57--94ea8d39fe154af49e9ccab78ba203e9 c52b37c3f00c45558e43d32302b17a22 94ea8d39fe154af49e9ccab78ba203e9--c52b37c3f00c45558e43d32302b17a22 3365da87669b47c48c4766ae059ab91c c52b37c3f00c45558e43d32302b17a22--3365da87669b47c48c4766ae059ab91c ac6c4b60422249d4ab7e60a9675a2240 3365da87669b47c48c4766ae059ab91c--ac6c4b60422249d4ab7e60a9675a2240 1eba4d5c07944cadb5257969f5556e91 X ac6c4b60422249d4ab7e60a9675a2240--1eba4d5c07944cadb5257969f5556e91 1eba4d5c07944cadb5257969f5556e91--10f2dcd58fc84120835126877d4222ad ed2a97919ab84feb8b22e425a1b8474e 1eba4d5c07944cadb5257969f5556e91--ed2a97919ab84feb8b22e425a1b8474e 4c4b448a15ad4842ad5eabfca3d4a1df ed2a97919ab84feb8b22e425a1b8474e--4c4b448a15ad4842ad5eabfca3d4a1df 3c7173e59464418e84659ab7d3ac8334 4c4b448a15ad4842ad5eabfca3d4a1df--3c7173e59464418e84659ab7d3ac8334 fb7bf13e79514c4c9a18a236d933b76d 3c7173e59464418e84659ab7d3ac8334--fb7bf13e79514c4c9a18a236d933b76d 6f0691cd868e4e8da941a8dedc66d77c fb7bf13e79514c4c9a18a236d933b76d--6f0691cd868e4e8da941a8dedc66d77c e59493a359f2417db7ecfe14fffa80bb 6f0691cd868e4e8da941a8dedc66d77c--e59493a359f2417db7ecfe14fffa80bb 607c8d04a7ed4ffc9c8158c5b3ca2ccc X e59493a359f2417db7ecfe14fffa80bb--607c8d04a7ed4ffc9c8158c5b3ca2ccc 607c8d04a7ed4ffc9c8158c5b3ca2ccc--e34e55a1b9e94d3c8fac871874e94058 e9c074522930425abfe96a431b732dff 607c8d04a7ed4ffc9c8158c5b3ca2ccc--e9c074522930425abfe96a431b732dff 4c027c9b4e7c49138c20f8c4a9e78650 e9c074522930425abfe96a431b732dff--4c027c9b4e7c49138c20f8c4a9e78650 1627da4ef8cb491bbd929e927f2a7c2b 4c027c9b4e7c49138c20f8c4a9e78650--1627da4ef8cb491bbd929e927f2a7c2b 637d954906dd4a93b5911bb6406d4961 1627da4ef8cb491bbd929e927f2a7c2b--637d954906dd4a93b5911bb6406d4961 9579e9647fa8431daeeb7f5fd8bbe97e 637d954906dd4a93b5911bb6406d4961--9579e9647fa8431daeeb7f5fd8bbe97e 511b1378a61d475fbe96a27d28d72cc1 9579e9647fa8431daeeb7f5fd8bbe97e--511b1378a61d475fbe96a27d28d72cc1 f6de34640f6f44d79d2606c8df7c3d88 511b1378a61d475fbe96a27d28d72cc1--f6de34640f6f44d79d2606c8df7c3d88 a8fe3e0c26c94696b014705b0a5a43cc X f6de34640f6f44d79d2606c8df7c3d88--a8fe3e0c26c94696b014705b0a5a43cc a8fe3e0c26c94696b014705b0a5a43cc--4f81595e6c254d8c8e7adfa42ee66326 0cc2d95b4dee4e55aa513dfd96852c0d a8fe3e0c26c94696b014705b0a5a43cc--0cc2d95b4dee4e55aa513dfd96852c0d 7987980ae3a84701ba2db6803a83438d 0cc2d95b4dee4e55aa513dfd96852c0d--7987980ae3a84701ba2db6803a83438d 4b8d45ada5d54739bcdb66084f5c1e18 7987980ae3a84701ba2db6803a83438d--4b8d45ada5d54739bcdb66084f5c1e18 08126c7df5ec4b78bb457962f6bc31e2 4b8d45ada5d54739bcdb66084f5c1e18--08126c7df5ec4b78bb457962f6bc31e2 b41f89c2e3414f798c7773581f3a9548 08126c7df5ec4b78bb457962f6bc31e2--b41f89c2e3414f798c7773581f3a9548 4263ae029e2c47f3bd36b3154a49997c b41f89c2e3414f798c7773581f3a9548--4263ae029e2c47f3bd36b3154a49997c c23508e124214ccf8601c5bd29bce299 4263ae029e2c47f3bd36b3154a49997c--c23508e124214ccf8601c5bd29bce299 e9fbcb2d32fe4578933b8a0f231c3a4f c23508e124214ccf8601c5bd29bce299--e9fbcb2d32fe4578933b8a0f231c3a4f 003f38401f2e4033bd17802a3360996d e9fbcb2d32fe4578933b8a0f231c3a4f--003f38401f2e4033bd17802a3360996d b48b34159cf34c7ab31560f11a1228cd 003f38401f2e4033bd17802a3360996d--b48b34159cf34c7ab31560f11a1228cd 4becd96a7dbc43c4979febed0cc30ad5 X b48b34159cf34c7ab31560f11a1228cd--4becd96a7dbc43c4979febed0cc30ad5 4becd96a7dbc43c4979febed0cc30ad5--fcf9ee10497c4aac93d265b1f3412484 33b1fc33e5f34389a11bb1f417d61a7c RZ(-1.0*g1) 4becd96a7dbc43c4979febed0cc30ad5--33b1fc33e5f34389a11bb1f417d61a7c 8e69b8a1416a4173a6e9422ecea2a934 X 33b1fc33e5f34389a11bb1f417d61a7c--8e69b8a1416a4173a6e9422ecea2a934 8e69b8a1416a4173a6e9422ecea2a934--27dd09116cde4acfbf704e94b9ba99ef 4a1ed6d1f5cc43868d0eeb0dabad8300 8e69b8a1416a4173a6e9422ecea2a934--4a1ed6d1f5cc43868d0eeb0dabad8300 ffa4187336ac436d8d980d036ffd7366 4a1ed6d1f5cc43868d0eeb0dabad8300--ffa4187336ac436d8d980d036ffd7366 c2ae9bdde10740cf926ac710c87e0d2e ffa4187336ac436d8d980d036ffd7366--c2ae9bdde10740cf926ac710c87e0d2e 07e32ea723d24cac874570ae4076a7ae c2ae9bdde10740cf926ac710c87e0d2e--07e32ea723d24cac874570ae4076a7ae 9b96493da4d2443993fdb41d98326dc3 X 07e32ea723d24cac874570ae4076a7ae--9b96493da4d2443993fdb41d98326dc3 9b96493da4d2443993fdb41d98326dc3--5004dee9323f498ca7135ea913a7bd83 bbb14248df784e77a4fbc2024edc674f 9b96493da4d2443993fdb41d98326dc3--bbb14248df784e77a4fbc2024edc674f 3976602d4b064b8dbc2f417a240f4a83 bbb14248df784e77a4fbc2024edc674f--3976602d4b064b8dbc2f417a240f4a83 faacc141df5f4e08bec69b41e3aac7ae 3976602d4b064b8dbc2f417a240f4a83--faacc141df5f4e08bec69b41e3aac7ae 84b20539aa4447d5b8f55f8786de63fe faacc141df5f4e08bec69b41e3aac7ae--84b20539aa4447d5b8f55f8786de63fe 916836bfad7748a39bdd39c9e116ae1b 84b20539aa4447d5b8f55f8786de63fe--916836bfad7748a39bdd39c9e116ae1b 856c60b0fd804e14b0cb5386b4c1a0fe X 916836bfad7748a39bdd39c9e116ae1b--856c60b0fd804e14b0cb5386b4c1a0fe 856c60b0fd804e14b0cb5386b4c1a0fe--0aba677c2af042028a22c62d6f1eb477 eafcb3a4f342466888216ebb3c010f5f 856c60b0fd804e14b0cb5386b4c1a0fe--eafcb3a4f342466888216ebb3c010f5f 93daf7613e7549d8b009d01ac31c102f eafcb3a4f342466888216ebb3c010f5f--93daf7613e7549d8b009d01ac31c102f 4825f1cf25e64c4a953d07c736fba588 93daf7613e7549d8b009d01ac31c102f--4825f1cf25e64c4a953d07c736fba588 e349c3d9b82e45989d9eb0ce3e523689 X 4825f1cf25e64c4a953d07c736fba588--e349c3d9b82e45989d9eb0ce3e523689 e349c3d9b82e45989d9eb0ce3e523689--c63b81d90d1e45029cd0229d854793b1 1a377e5d74734d7b8386e3c4021d88fe RZ(-1.0*g1) e349c3d9b82e45989d9eb0ce3e523689--1a377e5d74734d7b8386e3c4021d88fe e55b981da7b943f6b7b5ca4ae8734747 X 1a377e5d74734d7b8386e3c4021d88fe--e55b981da7b943f6b7b5ca4ae8734747 e55b981da7b943f6b7b5ca4ae8734747--821ac1f871004c169354a2fa3e1d2d36 072957caf9d945a9b7aed215d0776038 e55b981da7b943f6b7b5ca4ae8734747--072957caf9d945a9b7aed215d0776038 9e0bc577a168468bb2fe9f9f557c846b 072957caf9d945a9b7aed215d0776038--9e0bc577a168468bb2fe9f9f557c846b 1490218143874c9db01c662d76611412 X 9e0bc577a168468bb2fe9f9f557c846b--1490218143874c9db01c662d76611412 1490218143874c9db01c662d76611412--ffc8e33d0ca9467ab20cbcc9303e1de6 adb3275046f6419a90f86cd90a7cb456 1490218143874c9db01c662d76611412--adb3275046f6419a90f86cd90a7cb456 5876e7a5a2fb4967979adfe9de7ccfb0 adb3275046f6419a90f86cd90a7cb456--5876e7a5a2fb4967979adfe9de7ccfb0 818506bcaa944f8fa4b240ea43a14eec 5876e7a5a2fb4967979adfe9de7ccfb0--818506bcaa944f8fa4b240ea43a14eec af4dd88a539344ddbef7c58525601a06 X 818506bcaa944f8fa4b240ea43a14eec--af4dd88a539344ddbef7c58525601a06 af4dd88a539344ddbef7c58525601a06--7ee95d66f5a44eaf8fabe3036ed42e54 129aefadae044e749d85dba94b7f5b15 af4dd88a539344ddbef7c58525601a06--129aefadae044e749d85dba94b7f5b15 244ef12113e84ef3b17283a7d987fe8a 129aefadae044e749d85dba94b7f5b15--244ef12113e84ef3b17283a7d987fe8a 863b442675024d6f9796fea074020679 X 244ef12113e84ef3b17283a7d987fe8a--863b442675024d6f9796fea074020679 863b442675024d6f9796fea074020679--bc2ab03f576240268112c8cbfc3867b9 f1c750245d1b4398bc13a56de7861c4e 863b442675024d6f9796fea074020679--f1c750245d1b4398bc13a56de7861c4e 10026b23df6b4bba9188bb5132c1974d f1c750245d1b4398bc13a56de7861c4e--10026b23df6b4bba9188bb5132c1974d 9e3dd70ce64b4c03a6958b0a673c69f6 10026b23df6b4bba9188bb5132c1974d--9e3dd70ce64b4c03a6958b0a673c69f6 1229bc5065904bc08e952fc61d420537 9e3dd70ce64b4c03a6958b0a673c69f6--1229bc5065904bc08e952fc61d420537 b10d4208efe04efb8297db5bb15e2f46 1229bc5065904bc08e952fc61d420537--b10d4208efe04efb8297db5bb15e2f46 ccaf5dd3e23046a2b68fc40f4eebc628 X b10d4208efe04efb8297db5bb15e2f46--ccaf5dd3e23046a2b68fc40f4eebc628 ccaf5dd3e23046a2b68fc40f4eebc628--4336bed3a9ec404d9fbc5d3daeff341d e96aa2463d194ee786f2ff73967df85e ccaf5dd3e23046a2b68fc40f4eebc628--e96aa2463d194ee786f2ff73967df85e a4f092a5b2544c71926f03afdfb759b7 X e96aa2463d194ee786f2ff73967df85e--a4f092a5b2544c71926f03afdfb759b7 a4f092a5b2544c71926f03afdfb759b7--d9bf63e909e84ffe9c8a4db552d15431 51303e4e60f4405aba691e18b7e54d7d a4f092a5b2544c71926f03afdfb759b7--51303e4e60f4405aba691e18b7e54d7d cdb3e40f42e94ae0beb63225de52be39 51303e4e60f4405aba691e18b7e54d7d--cdb3e40f42e94ae0beb63225de52be39 947ebbb0325647869dee64f15f3a32c7 cdb3e40f42e94ae0beb63225de52be39--947ebbb0325647869dee64f15f3a32c7 84404f39dfcf40c7967f747d96286225 X 947ebbb0325647869dee64f15f3a32c7--84404f39dfcf40c7967f747d96286225 84404f39dfcf40c7967f747d96286225--cef0c51efbe54ce2b5164b1641a6ad3f a2c6377fd4604f85a5ca6a5b93cbb16d X 84404f39dfcf40c7967f747d96286225--a2c6377fd4604f85a5ca6a5b93cbb16d a2c6377fd4604f85a5ca6a5b93cbb16d--5708987367c2482a93b0895abc60816f 198b14ecfac44cfaba6b8f2c135821fa a2c6377fd4604f85a5ca6a5b93cbb16d--198b14ecfac44cfaba6b8f2c135821fa a0e70f3baf6f4edd8356e1f5779e48f1 198b14ecfac44cfaba6b8f2c135821fa--a0e70f3baf6f4edd8356e1f5779e48f1 a39dc4189bc74a2fa9641b9f8facb0e8 a0e70f3baf6f4edd8356e1f5779e48f1--a39dc4189bc74a2fa9641b9f8facb0e8 0bdd876f6be743149145587d2ba0d009 a39dc4189bc74a2fa9641b9f8facb0e8--0bdd876f6be743149145587d2ba0d009 10912a4acf65498ebe77b83b7be3bea7 0bdd876f6be743149145587d2ba0d009--10912a4acf65498ebe77b83b7be3bea7 118016509b754b85b3837d834327e702 X 10912a4acf65498ebe77b83b7be3bea7--118016509b754b85b3837d834327e702 118016509b754b85b3837d834327e702--471a10c11e504912b358a2e58cb4ea9c 8117c192207b49b1bf66a777e83f06d5 X 118016509b754b85b3837d834327e702--8117c192207b49b1bf66a777e83f06d5 8117c192207b49b1bf66a777e83f06d5--9553fc74d11c426fbe9abffcb6c58b3a cf23562f7d6f4e2fa316d5ede47fc0d8 8117c192207b49b1bf66a777e83f06d5--cf23562f7d6f4e2fa316d5ede47fc0d8 60741d2535da423eb180c525418815d0 cf23562f7d6f4e2fa316d5ede47fc0d8--60741d2535da423eb180c525418815d0 8aaef6d621ef424481c5a9e2ab821fab 60741d2535da423eb180c525418815d0--8aaef6d621ef424481c5a9e2ab821fab 305141f81c7d498d8c6365c44e31759b 8aaef6d621ef424481c5a9e2ab821fab--305141f81c7d498d8c6365c44e31759b af0856f2e9434e7caaba0f47ec9ecc53 305141f81c7d498d8c6365c44e31759b--af0856f2e9434e7caaba0f47ec9ecc53 9cf1806f83a24e13aadfaaf96abf42f8 af0856f2e9434e7caaba0f47ec9ecc53--9cf1806f83a24e13aadfaaf96abf42f8 e07b8483587447a2ac9ec42c34c81c95 9cf1806f83a24e13aadfaaf96abf42f8--e07b8483587447a2ac9ec42c34c81c95 5dcad0f8ef774f0ab7dd8d373441ea2c X e07b8483587447a2ac9ec42c34c81c95--5dcad0f8ef774f0ab7dd8d373441ea2c 5dcad0f8ef774f0ab7dd8d373441ea2c--85c81bbad89c4998b735d47aed9204ee f264fb8ce69c409286c7ee76b819eba5 5dcad0f8ef774f0ab7dd8d373441ea2c--f264fb8ce69c409286c7ee76b819eba5 8650f91fd38346129960d565a7e7751b f264fb8ce69c409286c7ee76b819eba5--8650f91fd38346129960d565a7e7751b 1a000595686a444bafc1177a0f5dc903 8650f91fd38346129960d565a7e7751b--1a000595686a444bafc1177a0f5dc903 6ff4d13e015f41c4aab8480535a938ee RX(b14) 1a000595686a444bafc1177a0f5dc903--6ff4d13e015f41c4aab8480535a938ee 6ff4d13e015f41c4aab8480535a938ee--057fb3b8a7bf4ab58105fdd5327b61c7 ac5fea30bd1e4d5bbcd8ee109deb7e52 b35daf0dd6cb4feebd4d626c3bb8e99b 18ddba92c69b4b82822cfba037795535--b35daf0dd6cb4feebd4d626c3bb8e99b b9790715ab1e4ffc9b05c624f1323a49 6 85360fbbcf0d47388fa8880b8acfb473 b35daf0dd6cb4feebd4d626c3bb8e99b--85360fbbcf0d47388fa8880b8acfb473 eab25f7e299147fca68b43aaa5ae2f73 85360fbbcf0d47388fa8880b8acfb473--eab25f7e299147fca68b43aaa5ae2f73 e417f3ad01844acdaa644fe9bc037e95 eab25f7e299147fca68b43aaa5ae2f73--e417f3ad01844acdaa644fe9bc037e95 83780836fb0c4d6492dccd48f43d7543 X e417f3ad01844acdaa644fe9bc037e95--83780836fb0c4d6492dccd48f43d7543 83780836fb0c4d6492dccd48f43d7543--90c618179f4d4644bc019db1818ca711 825e79003b604d5daa7097e2eabfd79e 83780836fb0c4d6492dccd48f43d7543--825e79003b604d5daa7097e2eabfd79e 734a7e1c989947818cc9fe288f141a01 825e79003b604d5daa7097e2eabfd79e--734a7e1c989947818cc9fe288f141a01 8194ec449ede46078b50f93e6e1cb584 734a7e1c989947818cc9fe288f141a01--8194ec449ede46078b50f93e6e1cb584 904e99394369443ea01165f1eb61cd4b 8194ec449ede46078b50f93e6e1cb584--904e99394369443ea01165f1eb61cd4b f8176358874c4d5888e53652b06c3269 904e99394369443ea01165f1eb61cd4b--f8176358874c4d5888e53652b06c3269 5470dfc0bafd4978946cd3eb22a4fcaa X f8176358874c4d5888e53652b06c3269--5470dfc0bafd4978946cd3eb22a4fcaa 5470dfc0bafd4978946cd3eb22a4fcaa--f1bee105ebc04fb68cf94bfe29fed8bb 7d3c8fef10ef44aaa7c36f2656ced3fd 5470dfc0bafd4978946cd3eb22a4fcaa--7d3c8fef10ef44aaa7c36f2656ced3fd 0e5fba89602542cabea6d447d5267a8a 7d3c8fef10ef44aaa7c36f2656ced3fd--0e5fba89602542cabea6d447d5267a8a 8afc2ac1e7cc4aaab8f6dcc7a85d3c27 0e5fba89602542cabea6d447d5267a8a--8afc2ac1e7cc4aaab8f6dcc7a85d3c27 add10900684f418f954178ad64492029 8afc2ac1e7cc4aaab8f6dcc7a85d3c27--add10900684f418f954178ad64492029 ddc3976eb39f4f61a9203d9b4ab1e86b add10900684f418f954178ad64492029--ddc3976eb39f4f61a9203d9b4ab1e86b ff439a8993bd490f8bf091e35ab6c89a ddc3976eb39f4f61a9203d9b4ab1e86b--ff439a8993bd490f8bf091e35ab6c89a b5f045bb75f5463b80e6c8a231d4f459 ff439a8993bd490f8bf091e35ab6c89a--b5f045bb75f5463b80e6c8a231d4f459 f35811d044b64aa2a1bad3cb1ed981a9 b5f045bb75f5463b80e6c8a231d4f459--f35811d044b64aa2a1bad3cb1ed981a9 9613135e72e64330971ac324956e36c3 f35811d044b64aa2a1bad3cb1ed981a9--9613135e72e64330971ac324956e36c3 1fc36b2075634d3eb86a153fb7542326 9613135e72e64330971ac324956e36c3--1fc36b2075634d3eb86a153fb7542326 5856a683a69741b4931596730ba00bb8 1fc36b2075634d3eb86a153fb7542326--5856a683a69741b4931596730ba00bb8 5d174c89d50a4965abbc8e68a54a8905 5856a683a69741b4931596730ba00bb8--5d174c89d50a4965abbc8e68a54a8905 eed705755dfa4cc28a166a950db7ea28 5d174c89d50a4965abbc8e68a54a8905--eed705755dfa4cc28a166a950db7ea28 2fc3a4ac7e5445f1943858da40343560 eed705755dfa4cc28a166a950db7ea28--2fc3a4ac7e5445f1943858da40343560 b8591f40bcf6456080292f8baf3b7738 2fc3a4ac7e5445f1943858da40343560--b8591f40bcf6456080292f8baf3b7738 367c7062b47c41bda6262d00e554af97 b8591f40bcf6456080292f8baf3b7738--367c7062b47c41bda6262d00e554af97 b353d3413dbc428f9470cdb71310298f 367c7062b47c41bda6262d00e554af97--b353d3413dbc428f9470cdb71310298f ba185675c3904c168cd1e0b2f560e25b X b353d3413dbc428f9470cdb71310298f--ba185675c3904c168cd1e0b2f560e25b ba185675c3904c168cd1e0b2f560e25b--7fd4eab27b024a398fa5352c95d95de0 e1e922fa2f7f46b9bf172353feb78c74 RZ(-1.0*g0) ba185675c3904c168cd1e0b2f560e25b--e1e922fa2f7f46b9bf172353feb78c74 14bf2f0961d64e80aa855ce2ecedf07e X e1e922fa2f7f46b9bf172353feb78c74--14bf2f0961d64e80aa855ce2ecedf07e 14bf2f0961d64e80aa855ce2ecedf07e--de20080d19c249619c8c844efe79809a 4781574e3c654a78a6a619ff972a6ccb 14bf2f0961d64e80aa855ce2ecedf07e--4781574e3c654a78a6a619ff972a6ccb ac1bc58df4a6483c88f871928a5eaf58 4781574e3c654a78a6a619ff972a6ccb--ac1bc58df4a6483c88f871928a5eaf58 f04b68fc41d34fee89e9a578d62529e7 ac1bc58df4a6483c88f871928a5eaf58--f04b68fc41d34fee89e9a578d62529e7 b9164132750c4242a9fa05a781953445 f04b68fc41d34fee89e9a578d62529e7--b9164132750c4242a9fa05a781953445 672fc05a50a44520a23f27ea3f73a210 b9164132750c4242a9fa05a781953445--672fc05a50a44520a23f27ea3f73a210 2f9bad67fd614309887b19a53e20887c 672fc05a50a44520a23f27ea3f73a210--2f9bad67fd614309887b19a53e20887c 105aefdba3014bc7bd1b02339b84b387 2f9bad67fd614309887b19a53e20887c--105aefdba3014bc7bd1b02339b84b387 f0d0e8738a474a75a4576427ed7bbeae 105aefdba3014bc7bd1b02339b84b387--f0d0e8738a474a75a4576427ed7bbeae 36937ffeed424d18b6f7357ec4d7bc5e X f0d0e8738a474a75a4576427ed7bbeae--36937ffeed424d18b6f7357ec4d7bc5e 36937ffeed424d18b6f7357ec4d7bc5e--638c2ddc5aa64de1a9bf141a1331bf91 22d0ee9bcc5d4860868bc5d5b0508850 36937ffeed424d18b6f7357ec4d7bc5e--22d0ee9bcc5d4860868bc5d5b0508850 3a59e15ea9574c698342fd7091a87c6b 22d0ee9bcc5d4860868bc5d5b0508850--3a59e15ea9574c698342fd7091a87c6b 512395f4bc78449e8f2597e4ed6a8ce5 3a59e15ea9574c698342fd7091a87c6b--512395f4bc78449e8f2597e4ed6a8ce5 5f72c7cb5bf742db9d69bf10e85fe5e7 X 512395f4bc78449e8f2597e4ed6a8ce5--5f72c7cb5bf742db9d69bf10e85fe5e7 5f72c7cb5bf742db9d69bf10e85fe5e7--d4a293ae2c3d48fcab33b4534be5b5f5 5ed3b31cf5e84de089d7b7a8e306cb33 5f72c7cb5bf742db9d69bf10e85fe5e7--5ed3b31cf5e84de089d7b7a8e306cb33 fe9ba37a996c4c1f801feed22488b2aa 5ed3b31cf5e84de089d7b7a8e306cb33--fe9ba37a996c4c1f801feed22488b2aa e5df3123f773445d8db803545e4b2446 fe9ba37a996c4c1f801feed22488b2aa--e5df3123f773445d8db803545e4b2446 a5f4ae4792854342b4630a9957f5ccb0 e5df3123f773445d8db803545e4b2446--a5f4ae4792854342b4630a9957f5ccb0 881b5f037f284da59cbdd64a450d70e6 a5f4ae4792854342b4630a9957f5ccb0--881b5f037f284da59cbdd64a450d70e6 921a5de7ac9d4972a754212d18d682dd 881b5f037f284da59cbdd64a450d70e6--921a5de7ac9d4972a754212d18d682dd c40d1e1dfd0e4674a48997d1af7cf2c4 921a5de7ac9d4972a754212d18d682dd--c40d1e1dfd0e4674a48997d1af7cf2c4 20d03d76011c41339d27b900428055a6 c40d1e1dfd0e4674a48997d1af7cf2c4--20d03d76011c41339d27b900428055a6 9c3ba8379f834657b2fc2bd9f4fb3314 X 20d03d76011c41339d27b900428055a6--9c3ba8379f834657b2fc2bd9f4fb3314 9c3ba8379f834657b2fc2bd9f4fb3314--878d1e3d81d849c4a117abc05816fdc5 2eebc6011bfa4c9583a24a7705135e07 9c3ba8379f834657b2fc2bd9f4fb3314--2eebc6011bfa4c9583a24a7705135e07 bdf5da1d0617410da97b7a30911ff8ab 2eebc6011bfa4c9583a24a7705135e07--bdf5da1d0617410da97b7a30911ff8ab 399fb893d9744146ba65391efc3d87fc bdf5da1d0617410da97b7a30911ff8ab--399fb893d9744146ba65391efc3d87fc 7adfb839b736436db5cbe96e059c01b9 399fb893d9744146ba65391efc3d87fc--7adfb839b736436db5cbe96e059c01b9 9a1e2a8635b848a5bd7d78fbfe84d226 7adfb839b736436db5cbe96e059c01b9--9a1e2a8635b848a5bd7d78fbfe84d226 5bcea2d08b0f4f24a53699d2ac059d2a X 9a1e2a8635b848a5bd7d78fbfe84d226--5bcea2d08b0f4f24a53699d2ac059d2a 5bcea2d08b0f4f24a53699d2ac059d2a--c9302885dd524fea9a869b5bc2114dec 8b3aa9ea2b364b0db6f43675df315ec1 5bcea2d08b0f4f24a53699d2ac059d2a--8b3aa9ea2b364b0db6f43675df315ec1 d594a209bb28434e9239b786d62ead9a 8b3aa9ea2b364b0db6f43675df315ec1--d594a209bb28434e9239b786d62ead9a 3d1679a9f31949c6999eb5178a3f470a d594a209bb28434e9239b786d62ead9a--3d1679a9f31949c6999eb5178a3f470a 21aa8a2da12a4de3a2fc3c38e16bc59d 3d1679a9f31949c6999eb5178a3f470a--21aa8a2da12a4de3a2fc3c38e16bc59d 767a014c6c74476ea8ade1040812c70e 21aa8a2da12a4de3a2fc3c38e16bc59d--767a014c6c74476ea8ade1040812c70e 4e0fc99b5c3b4f39a19f41a520a2a671 767a014c6c74476ea8ade1040812c70e--4e0fc99b5c3b4f39a19f41a520a2a671 4075423730a44b73a1eb5ba646cce4c5 4e0fc99b5c3b4f39a19f41a520a2a671--4075423730a44b73a1eb5ba646cce4c5 5495652f0a5e45d19cced8338b4d9d1d 4075423730a44b73a1eb5ba646cce4c5--5495652f0a5e45d19cced8338b4d9d1d a7c1a6b2206240cd8dc3d3605b7c0163 5495652f0a5e45d19cced8338b4d9d1d--a7c1a6b2206240cd8dc3d3605b7c0163 9768c7c8abb246efb3c4a58d591377d2 a7c1a6b2206240cd8dc3d3605b7c0163--9768c7c8abb246efb3c4a58d591377d2 4dbda44a115c425194334ecac57d0f09 9768c7c8abb246efb3c4a58d591377d2--4dbda44a115c425194334ecac57d0f09 5fa43f7dd4024063bd26e3cd1e9e27cc 4dbda44a115c425194334ecac57d0f09--5fa43f7dd4024063bd26e3cd1e9e27cc 4771490058574128a106339faa6506e0 5fa43f7dd4024063bd26e3cd1e9e27cc--4771490058574128a106339faa6506e0 d484dd6c65c5479b9ce08a1000f635ee 4771490058574128a106339faa6506e0--d484dd6c65c5479b9ce08a1000f635ee 66eeca3def9f44429a0291425124931e d484dd6c65c5479b9ce08a1000f635ee--66eeca3def9f44429a0291425124931e aa300cfc3a2e4d7daba8d594b49e25bc 66eeca3def9f44429a0291425124931e--aa300cfc3a2e4d7daba8d594b49e25bc 371144a1e15e4ca4b10b279a734da728 aa300cfc3a2e4d7daba8d594b49e25bc--371144a1e15e4ca4b10b279a734da728 1758c7a9a4ce4a60950a38ae8bdab440 371144a1e15e4ca4b10b279a734da728--1758c7a9a4ce4a60950a38ae8bdab440 9a015fb3010f4c229e2374372ce02c44 1758c7a9a4ce4a60950a38ae8bdab440--9a015fb3010f4c229e2374372ce02c44 45febe3891c842278ed4168159858c15 X 9a015fb3010f4c229e2374372ce02c44--45febe3891c842278ed4168159858c15 45febe3891c842278ed4168159858c15--7800baba8bbd483597c42121d335439f a21c4d5c55ba417c8de3a4524c054130 45febe3891c842278ed4168159858c15--a21c4d5c55ba417c8de3a4524c054130 9f4e628ed1654082bf34b8538715c099 a21c4d5c55ba417c8de3a4524c054130--9f4e628ed1654082bf34b8538715c099 79d2b2a5342642f2b9c2cdb3288d4ce0 9f4e628ed1654082bf34b8538715c099--79d2b2a5342642f2b9c2cdb3288d4ce0 fab65c9d6b9549abac9026a1debe8ed1 X 79d2b2a5342642f2b9c2cdb3288d4ce0--fab65c9d6b9549abac9026a1debe8ed1 fab65c9d6b9549abac9026a1debe8ed1--a411739d597846269feff6dfbc1e247c 131fb398254b40a89079eb9fb07ca867 fab65c9d6b9549abac9026a1debe8ed1--131fb398254b40a89079eb9fb07ca867 c87f97bc0ed64eee9e6b7ec4435e9e46 131fb398254b40a89079eb9fb07ca867--c87f97bc0ed64eee9e6b7ec4435e9e46 faccbc4c1ebf47a88b0d90de91b79cbf c87f97bc0ed64eee9e6b7ec4435e9e46--faccbc4c1ebf47a88b0d90de91b79cbf 22d97e3461b743bf992786a6c038d252 faccbc4c1ebf47a88b0d90de91b79cbf--22d97e3461b743bf992786a6c038d252 c26cff7a67c5419fa5e33604033e4e4b 22d97e3461b743bf992786a6c038d252--c26cff7a67c5419fa5e33604033e4e4b a0d490b6d8a6415da6302a436d4d2e36 c26cff7a67c5419fa5e33604033e4e4b--a0d490b6d8a6415da6302a436d4d2e36 5c2e79b77d784112aad30c38362a6365 a0d490b6d8a6415da6302a436d4d2e36--5c2e79b77d784112aad30c38362a6365 f81df558d1624399a5959f7d200189b6 5c2e79b77d784112aad30c38362a6365--f81df558d1624399a5959f7d200189b6 a3748e4e80774e8c801ae9eb199a57e6 f81df558d1624399a5959f7d200189b6--a3748e4e80774e8c801ae9eb199a57e6 fc9131cb816d44c6af1b2c0ac187fb11 a3748e4e80774e8c801ae9eb199a57e6--fc9131cb816d44c6af1b2c0ac187fb11 3eefa16a00544693b68287f02067fe3d X fc9131cb816d44c6af1b2c0ac187fb11--3eefa16a00544693b68287f02067fe3d 3eefa16a00544693b68287f02067fe3d--bd984605ccda43d499abfce4babeaae0 9c125d0f7a514a01a36b2ba5011b5cc2 RZ(-1.0*g0) 3eefa16a00544693b68287f02067fe3d--9c125d0f7a514a01a36b2ba5011b5cc2 e46032832c324696941c424d6cdcfac3 X 9c125d0f7a514a01a36b2ba5011b5cc2--e46032832c324696941c424d6cdcfac3 e46032832c324696941c424d6cdcfac3--e379e95e7c5c42b6abf0b9335ecc7e90 1e8bd9f581cf41abb97e42200c989e24 e46032832c324696941c424d6cdcfac3--1e8bd9f581cf41abb97e42200c989e24 8e2ae1573d374f4ba4fcae3cb54acc2d 1e8bd9f581cf41abb97e42200c989e24--8e2ae1573d374f4ba4fcae3cb54acc2d 6d87a63f7cc54043a99f6f770587283c 8e2ae1573d374f4ba4fcae3cb54acc2d--6d87a63f7cc54043a99f6f770587283c 056a0f3d0922422cb5880e0dee35a10a 6d87a63f7cc54043a99f6f770587283c--056a0f3d0922422cb5880e0dee35a10a 9b97ced04f5248b5b88fb6b809ac3648 X 056a0f3d0922422cb5880e0dee35a10a--9b97ced04f5248b5b88fb6b809ac3648 9b97ced04f5248b5b88fb6b809ac3648--27c50dc7dfca4b63855114cc8994ac52 fa6c539c34bd4102a4ae1547ce67a45a 9b97ced04f5248b5b88fb6b809ac3648--fa6c539c34bd4102a4ae1547ce67a45a 753ff55071b4422096dc4cccce916e84 fa6c539c34bd4102a4ae1547ce67a45a--753ff55071b4422096dc4cccce916e84 7fde87e3782443a7a31a2233265b0635 753ff55071b4422096dc4cccce916e84--7fde87e3782443a7a31a2233265b0635 c403c0fcb1224444a676b25bf48f292c X 7fde87e3782443a7a31a2233265b0635--c403c0fcb1224444a676b25bf48f292c c403c0fcb1224444a676b25bf48f292c--08d82f23bc674f1cade20d1f9a1f8434 0ee696db633f4ac7ad1a5c5ecb7177dd c403c0fcb1224444a676b25bf48f292c--0ee696db633f4ac7ad1a5c5ecb7177dd bd4f7206b23c4297b5724ce5cb83ae63 0ee696db633f4ac7ad1a5c5ecb7177dd--bd4f7206b23c4297b5724ce5cb83ae63 89da47e8060e45fa87a3d2cf76dbb2ba bd4f7206b23c4297b5724ce5cb83ae63--89da47e8060e45fa87a3d2cf76dbb2ba d6ba2715608647f3b3a14b151635aa92 X 89da47e8060e45fa87a3d2cf76dbb2ba--d6ba2715608647f3b3a14b151635aa92 d6ba2715608647f3b3a14b151635aa92--ccda2f0d2c15441e805cb59f84d2c145 7fa05bfcb3b44d8cbe68bc1743f67efc RZ(-1.0*g0) d6ba2715608647f3b3a14b151635aa92--7fa05bfcb3b44d8cbe68bc1743f67efc 526f553cefd1452d942989e6c1c2db18 X 7fa05bfcb3b44d8cbe68bc1743f67efc--526f553cefd1452d942989e6c1c2db18 526f553cefd1452d942989e6c1c2db18--9fc9d144aa384012bd8e02b8fb686a88 771e322688264cf1b2fee47414a9470a 526f553cefd1452d942989e6c1c2db18--771e322688264cf1b2fee47414a9470a 616c58d9536844d481b217bf719fe382 771e322688264cf1b2fee47414a9470a--616c58d9536844d481b217bf719fe382 c50e607a59f746a39991d85a2f91c520 X 616c58d9536844d481b217bf719fe382--c50e607a59f746a39991d85a2f91c520 c50e607a59f746a39991d85a2f91c520--7e6948f819dc4ebea1660f53acf6664c ffb642e43a0e4fad8fb24a41431b660f c50e607a59f746a39991d85a2f91c520--ffb642e43a0e4fad8fb24a41431b660f 11c767de91f648b0bd9d6965d5565212 ffb642e43a0e4fad8fb24a41431b660f--11c767de91f648b0bd9d6965d5565212 fbbd14f5c22c43039d469db1f81ace3f 11c767de91f648b0bd9d6965d5565212--fbbd14f5c22c43039d469db1f81ace3f 213e1c6ae82242b38f01cf58ec3022b9 X fbbd14f5c22c43039d469db1f81ace3f--213e1c6ae82242b38f01cf58ec3022b9 213e1c6ae82242b38f01cf58ec3022b9--75ca44bb02c64f6b90a414edc40dc12b b657456188a44b02a803c04323900768 213e1c6ae82242b38f01cf58ec3022b9--b657456188a44b02a803c04323900768 69ee0d09280e427ca5344cea38ca548d b657456188a44b02a803c04323900768--69ee0d09280e427ca5344cea38ca548d 64233a6487634b4fad8e4dd0936b7484 X 69ee0d09280e427ca5344cea38ca548d--64233a6487634b4fad8e4dd0936b7484 64233a6487634b4fad8e4dd0936b7484--7bf474d45d604012a2d80495fd5a12f5 6cc304acb1074ec6a7dd76b4a4e3bceb 64233a6487634b4fad8e4dd0936b7484--6cc304acb1074ec6a7dd76b4a4e3bceb c497e30c75cc4729b04fb10fea96642a 6cc304acb1074ec6a7dd76b4a4e3bceb--c497e30c75cc4729b04fb10fea96642a 62dc4fd9709343b28a5de88b985af19a c497e30c75cc4729b04fb10fea96642a--62dc4fd9709343b28a5de88b985af19a e0d5ce5227934c20943b092118bafe0f 62dc4fd9709343b28a5de88b985af19a--e0d5ce5227934c20943b092118bafe0f 32042453ff2c4f5f9e420a8a41a11439 e0d5ce5227934c20943b092118bafe0f--32042453ff2c4f5f9e420a8a41a11439 17deac6acdbd4e6faa2d61acc1be70dd X 32042453ff2c4f5f9e420a8a41a11439--17deac6acdbd4e6faa2d61acc1be70dd 17deac6acdbd4e6faa2d61acc1be70dd--63f2bebf98464d9ca1bbc9c462a65d81 f0362c0e48884df98b80738466fefbd0 17deac6acdbd4e6faa2d61acc1be70dd--f0362c0e48884df98b80738466fefbd0 af1feb9edb324bbb9832fd23e47b0da2 f0362c0e48884df98b80738466fefbd0--af1feb9edb324bbb9832fd23e47b0da2 072523f4c3c5449da2b352d82b2b39fd af1feb9edb324bbb9832fd23e47b0da2--072523f4c3c5449da2b352d82b2b39fd 79ca97e29282473cb44c17f1e1e53725 072523f4c3c5449da2b352d82b2b39fd--79ca97e29282473cb44c17f1e1e53725 bdfaa9897b124b8f86e93551849868bd RX(b05) 79ca97e29282473cb44c17f1e1e53725--bdfaa9897b124b8f86e93551849868bd efabb8f774494f27ac782ddd30b2e0d4 bdfaa9897b124b8f86e93551849868bd--efabb8f774494f27ac782ddd30b2e0d4 74981e84a3c34446adf4989a2fc89737 efabb8f774494f27ac782ddd30b2e0d4--74981e84a3c34446adf4989a2fc89737 86792c3c511549f29e7268d398066f96 74981e84a3c34446adf4989a2fc89737--86792c3c511549f29e7268d398066f96 40865a3c7d2c49cc97696e72be3a0b06 86792c3c511549f29e7268d398066f96--40865a3c7d2c49cc97696e72be3a0b06 4f7c887dac5e464a850a9312c228bc5f X 40865a3c7d2c49cc97696e72be3a0b06--4f7c887dac5e464a850a9312c228bc5f 4f7c887dac5e464a850a9312c228bc5f--6774bb6402254dec8998ee917cc6b6a3 8853e97231eb4f1697b6bb913cf173e5 4f7c887dac5e464a850a9312c228bc5f--8853e97231eb4f1697b6bb913cf173e5 af31cdd0dc9942b3b4389ce811c53665 8853e97231eb4f1697b6bb913cf173e5--af31cdd0dc9942b3b4389ce811c53665 11213e9e865e452d96c3b25a7abf932e af31cdd0dc9942b3b4389ce811c53665--11213e9e865e452d96c3b25a7abf932e 38f499887f1d4912ad8330f565d48489 11213e9e865e452d96c3b25a7abf932e--38f499887f1d4912ad8330f565d48489 1df0c701bcab4d52b058051f52b15d4c 38f499887f1d4912ad8330f565d48489--1df0c701bcab4d52b058051f52b15d4c 9c3e60a6808145818aa8fe51bb8abd54 X 1df0c701bcab4d52b058051f52b15d4c--9c3e60a6808145818aa8fe51bb8abd54 9c3e60a6808145818aa8fe51bb8abd54--31de7dc3d3e7450b8afea37312b9c100 85fec0ad383f4259a19a5878c9973d35 9c3e60a6808145818aa8fe51bb8abd54--85fec0ad383f4259a19a5878c9973d35 66cd040b51c14dd596acf8c181d961a1 85fec0ad383f4259a19a5878c9973d35--66cd040b51c14dd596acf8c181d961a1 8af93b3e063f44529055a8612b943649 66cd040b51c14dd596acf8c181d961a1--8af93b3e063f44529055a8612b943649 6f09d116b3cd455098a06cc254ec02fb 8af93b3e063f44529055a8612b943649--6f09d116b3cd455098a06cc254ec02fb 0799c8bd9b844bb49a34d64223b86a8b 6f09d116b3cd455098a06cc254ec02fb--0799c8bd9b844bb49a34d64223b86a8b cd491d0527fd4c1fbed40e0f833843b4 0799c8bd9b844bb49a34d64223b86a8b--cd491d0527fd4c1fbed40e0f833843b4 d92a16749a884ab3a3198a3c81f3d2e0 cd491d0527fd4c1fbed40e0f833843b4--d92a16749a884ab3a3198a3c81f3d2e0 668db7d41d094afbb6dece225db59e5c d92a16749a884ab3a3198a3c81f3d2e0--668db7d41d094afbb6dece225db59e5c bfdea0d727b64cde86ad77303cf9975d 668db7d41d094afbb6dece225db59e5c--bfdea0d727b64cde86ad77303cf9975d c918b7bbef5a4959ab079b305a9bf526 bfdea0d727b64cde86ad77303cf9975d--c918b7bbef5a4959ab079b305a9bf526 de2c89f4e542421e9f8875b7e65d46e4 c918b7bbef5a4959ab079b305a9bf526--de2c89f4e542421e9f8875b7e65d46e4 ad8e5d57d0874c16a4ff49e3339fead1 de2c89f4e542421e9f8875b7e65d46e4--ad8e5d57d0874c16a4ff49e3339fead1 8742f948dd1645f28b8da05e936d9489 ad8e5d57d0874c16a4ff49e3339fead1--8742f948dd1645f28b8da05e936d9489 add669f5d08d41e48c1c514ae8466f22 8742f948dd1645f28b8da05e936d9489--add669f5d08d41e48c1c514ae8466f22 e9e43700a4bd4c5daf63d9026db7c067 add669f5d08d41e48c1c514ae8466f22--e9e43700a4bd4c5daf63d9026db7c067 ef4caeea22c7431eb2be9675dfbff8d2 e9e43700a4bd4c5daf63d9026db7c067--ef4caeea22c7431eb2be9675dfbff8d2 ace9c6d1eae84387b905178e95ad5186 ef4caeea22c7431eb2be9675dfbff8d2--ace9c6d1eae84387b905178e95ad5186 8b65fa359a214bfcb61189b179a39651 X ace9c6d1eae84387b905178e95ad5186--8b65fa359a214bfcb61189b179a39651 8b65fa359a214bfcb61189b179a39651--ff3c2de5039f45e6bcb750c7398e8afd e590b51debd541e2bc1de93f3404dc95 RZ(-1.0*g1) 8b65fa359a214bfcb61189b179a39651--e590b51debd541e2bc1de93f3404dc95 efd83a89b9614e92a9cf8dcb3a961316 X e590b51debd541e2bc1de93f3404dc95--efd83a89b9614e92a9cf8dcb3a961316 efd83a89b9614e92a9cf8dcb3a961316--57a97f69d7014c9cb4777272a8ce27ea 84cafef04b4e49ea97bbff31d85e1205 efd83a89b9614e92a9cf8dcb3a961316--84cafef04b4e49ea97bbff31d85e1205 09e9ebcd91de42a485319053ca14261e 84cafef04b4e49ea97bbff31d85e1205--09e9ebcd91de42a485319053ca14261e 0749a1c39d4f4338befd24123f996055 09e9ebcd91de42a485319053ca14261e--0749a1c39d4f4338befd24123f996055 ea429ec3c00c4f33b90ab9c1b2c7f222 0749a1c39d4f4338befd24123f996055--ea429ec3c00c4f33b90ab9c1b2c7f222 eca7854d7c0942cba475711822fd1938 ea429ec3c00c4f33b90ab9c1b2c7f222--eca7854d7c0942cba475711822fd1938 cc17aaf41f574ed09de15fce9cd86e36 eca7854d7c0942cba475711822fd1938--cc17aaf41f574ed09de15fce9cd86e36 7f841ee5f44c475c830099691564736c cc17aaf41f574ed09de15fce9cd86e36--7f841ee5f44c475c830099691564736c 132505cd63b54cb6b9ce862c3ef81bb0 7f841ee5f44c475c830099691564736c--132505cd63b54cb6b9ce862c3ef81bb0 103d4ee518dc4f4ab22ce6a3b9e657df X 132505cd63b54cb6b9ce862c3ef81bb0--103d4ee518dc4f4ab22ce6a3b9e657df 103d4ee518dc4f4ab22ce6a3b9e657df--91ad4931c11e4512b8baf669d67b2e57 69ccbd23e0dd4cd6ae72435f7a382649 103d4ee518dc4f4ab22ce6a3b9e657df--69ccbd23e0dd4cd6ae72435f7a382649 a87cd150aa424e909ae83a069aa79da8 69ccbd23e0dd4cd6ae72435f7a382649--a87cd150aa424e909ae83a069aa79da8 c663ff35b16544dabcb4ffb3402e01f1 a87cd150aa424e909ae83a069aa79da8--c663ff35b16544dabcb4ffb3402e01f1 015e3c1ea28b4dc79d699bae2a6f652c X c663ff35b16544dabcb4ffb3402e01f1--015e3c1ea28b4dc79d699bae2a6f652c 015e3c1ea28b4dc79d699bae2a6f652c--ac6c4b60422249d4ab7e60a9675a2240 fd76134e6b634985afdb1bac2d5f387e 015e3c1ea28b4dc79d699bae2a6f652c--fd76134e6b634985afdb1bac2d5f387e 4197e01336194e738fbe2672f5304567 fd76134e6b634985afdb1bac2d5f387e--4197e01336194e738fbe2672f5304567 fc27f8c8cf1940429e17623ed3a6a5b2 4197e01336194e738fbe2672f5304567--fc27f8c8cf1940429e17623ed3a6a5b2 9f25fde4f7024a0a9ef5436bcbec5ec6 fc27f8c8cf1940429e17623ed3a6a5b2--9f25fde4f7024a0a9ef5436bcbec5ec6 3650b166eebe42bc93eef3d01b6b5dbb 9f25fde4f7024a0a9ef5436bcbec5ec6--3650b166eebe42bc93eef3d01b6b5dbb d6b69dec5ccc4d7e843388b29858ddd7 3650b166eebe42bc93eef3d01b6b5dbb--d6b69dec5ccc4d7e843388b29858ddd7 4c54084adf054078b38629fbb50343f6 d6b69dec5ccc4d7e843388b29858ddd7--4c54084adf054078b38629fbb50343f6 37d629c252f94011960e851faa38ebff 4c54084adf054078b38629fbb50343f6--37d629c252f94011960e851faa38ebff 3aa8d5c7577a41079f27b040c01c64e7 X 37d629c252f94011960e851faa38ebff--3aa8d5c7577a41079f27b040c01c64e7 3aa8d5c7577a41079f27b040c01c64e7--e9c074522930425abfe96a431b732dff 222efcb9cb3149fca3fad3aa440584b5 3aa8d5c7577a41079f27b040c01c64e7--222efcb9cb3149fca3fad3aa440584b5 e3bddd93ab9d4309b92a0c49ea015554 222efcb9cb3149fca3fad3aa440584b5--e3bddd93ab9d4309b92a0c49ea015554 192ae6e6913b417cbcee4e5cf16c907e e3bddd93ab9d4309b92a0c49ea015554--192ae6e6913b417cbcee4e5cf16c907e 053ac78e58934c4b98d6726fc449a5c5 192ae6e6913b417cbcee4e5cf16c907e--053ac78e58934c4b98d6726fc449a5c5 1c9ab65d202943a7b3e09037561063b2 053ac78e58934c4b98d6726fc449a5c5--1c9ab65d202943a7b3e09037561063b2 a4ddf7678bf345a7bec2eea2d72539f6 X 1c9ab65d202943a7b3e09037561063b2--a4ddf7678bf345a7bec2eea2d72539f6 a4ddf7678bf345a7bec2eea2d72539f6--f6de34640f6f44d79d2606c8df7c3d88 a7582932eea540b08f359aece0b42b0b a4ddf7678bf345a7bec2eea2d72539f6--a7582932eea540b08f359aece0b42b0b 54dad13ca3d840299b83a32e00bad062 a7582932eea540b08f359aece0b42b0b--54dad13ca3d840299b83a32e00bad062 3818abbb87284341a738f4eaebf95adb 54dad13ca3d840299b83a32e00bad062--3818abbb87284341a738f4eaebf95adb eb920582debf47788639e959d0556302 3818abbb87284341a738f4eaebf95adb--eb920582debf47788639e959d0556302 2dc20fbd0b5745639b098986a1d45546 eb920582debf47788639e959d0556302--2dc20fbd0b5745639b098986a1d45546 d2ad0447e4294ac9af956525c1e900d7 2dc20fbd0b5745639b098986a1d45546--d2ad0447e4294ac9af956525c1e900d7 e68b5f0e7dec483e8fcf7a3df151708d d2ad0447e4294ac9af956525c1e900d7--e68b5f0e7dec483e8fcf7a3df151708d f16d1c3cf4e14cb0a2d0880aba423c66 e68b5f0e7dec483e8fcf7a3df151708d--f16d1c3cf4e14cb0a2d0880aba423c66 b7a22176976d46e196e264b827045c70 f16d1c3cf4e14cb0a2d0880aba423c66--b7a22176976d46e196e264b827045c70 57371d8643f14c86b7a79a49d04abfba b7a22176976d46e196e264b827045c70--57371d8643f14c86b7a79a49d04abfba 4f572c180e0d4a9ca14b4489c180a5e2 57371d8643f14c86b7a79a49d04abfba--4f572c180e0d4a9ca14b4489c180a5e2 26015c275b1542d98f6ad7358460fe36 4f572c180e0d4a9ca14b4489c180a5e2--26015c275b1542d98f6ad7358460fe36 a8e27358430d4f4a9ab06c3f6d8f1dc7 26015c275b1542d98f6ad7358460fe36--a8e27358430d4f4a9ab06c3f6d8f1dc7 6c2b3d665e4d4c9d91a951024fa0ef0b a8e27358430d4f4a9ab06c3f6d8f1dc7--6c2b3d665e4d4c9d91a951024fa0ef0b 9aff671f46f9410eb018791fbdb6af97 6c2b3d665e4d4c9d91a951024fa0ef0b--9aff671f46f9410eb018791fbdb6af97 15d19937af8c457ea728d84df84f54f4 9aff671f46f9410eb018791fbdb6af97--15d19937af8c457ea728d84df84f54f4 e6b7331c8dc6468f9750e23c01db61b4 15d19937af8c457ea728d84df84f54f4--e6b7331c8dc6468f9750e23c01db61b4 1ee39cf7dfa74f4f8352309227bf8c5b e6b7331c8dc6468f9750e23c01db61b4--1ee39cf7dfa74f4f8352309227bf8c5b e6708e2da01c4568aaf5d9f022a461c1 1ee39cf7dfa74f4f8352309227bf8c5b--e6708e2da01c4568aaf5d9f022a461c1 105cb456a9bf4a51a30c9ed39944bbb7 X e6708e2da01c4568aaf5d9f022a461c1--105cb456a9bf4a51a30c9ed39944bbb7 105cb456a9bf4a51a30c9ed39944bbb7--bbb14248df784e77a4fbc2024edc674f d3e73b4375694409a58816e5a3f0d666 105cb456a9bf4a51a30c9ed39944bbb7--d3e73b4375694409a58816e5a3f0d666 f57b2eecd97a4dfd8da6a9669be71ad0 d3e73b4375694409a58816e5a3f0d666--f57b2eecd97a4dfd8da6a9669be71ad0 45a8136d6cd343e7bff2e3f78ac7c762 f57b2eecd97a4dfd8da6a9669be71ad0--45a8136d6cd343e7bff2e3f78ac7c762 11ca5d54cc444e7daa4f3782df916b87 X 45a8136d6cd343e7bff2e3f78ac7c762--11ca5d54cc444e7daa4f3782df916b87 11ca5d54cc444e7daa4f3782df916b87--916836bfad7748a39bdd39c9e116ae1b 394d13d6e9f0454b9c9762336ec8e50f 11ca5d54cc444e7daa4f3782df916b87--394d13d6e9f0454b9c9762336ec8e50f 1b297f97e66c40789f67bef03de8a43a 394d13d6e9f0454b9c9762336ec8e50f--1b297f97e66c40789f67bef03de8a43a 1c4699d36c0a43c0b1c4b915e1cc089f 1b297f97e66c40789f67bef03de8a43a--1c4699d36c0a43c0b1c4b915e1cc089f c2da631dc8b64450972d24864a6dd471 1c4699d36c0a43c0b1c4b915e1cc089f--c2da631dc8b64450972d24864a6dd471 ddddd34d70b84e439fad21bade94b6db c2da631dc8b64450972d24864a6dd471--ddddd34d70b84e439fad21bade94b6db cd3e386a80f24d0abe02f0f756612903 ddddd34d70b84e439fad21bade94b6db--cd3e386a80f24d0abe02f0f756612903 ee24004b5df84e99af8c1be5745ffb04 cd3e386a80f24d0abe02f0f756612903--ee24004b5df84e99af8c1be5745ffb04 eac45be2b91e4a5daf69128c32218fb8 ee24004b5df84e99af8c1be5745ffb04--eac45be2b91e4a5daf69128c32218fb8 4dd277e4f9c74a92ba9c184c563119a4 eac45be2b91e4a5daf69128c32218fb8--4dd277e4f9c74a92ba9c184c563119a4 fe10983a137146fbb22b3547a82db784 4dd277e4f9c74a92ba9c184c563119a4--fe10983a137146fbb22b3547a82db784 f0e7c3ad6e0a47febb8df878190da727 X fe10983a137146fbb22b3547a82db784--f0e7c3ad6e0a47febb8df878190da727 f0e7c3ad6e0a47febb8df878190da727--adb3275046f6419a90f86cd90a7cb456 2b9268bcada946e08bd4d5644006a0a7 RZ(-1.0*g1) f0e7c3ad6e0a47febb8df878190da727--2b9268bcada946e08bd4d5644006a0a7 4c9f43325e6c48ff938c0d62cb0ffcc9 X 2b9268bcada946e08bd4d5644006a0a7--4c9f43325e6c48ff938c0d62cb0ffcc9 4c9f43325e6c48ff938c0d62cb0ffcc9--818506bcaa944f8fa4b240ea43a14eec fd658b5671834f3fbfbc325014f645bd 4c9f43325e6c48ff938c0d62cb0ffcc9--fd658b5671834f3fbfbc325014f645bd aba06d3179734774a0b7605b7b8fdcb3 fd658b5671834f3fbfbc325014f645bd--aba06d3179734774a0b7605b7b8fdcb3 5ad91707fcb440ee8eb565eda33e6a65 aba06d3179734774a0b7605b7b8fdcb3--5ad91707fcb440ee8eb565eda33e6a65 821bba993076415297e70b98ba90a348 5ad91707fcb440ee8eb565eda33e6a65--821bba993076415297e70b98ba90a348 ad08b2c2673b40ddb60745078dd65709 X 821bba993076415297e70b98ba90a348--ad08b2c2673b40ddb60745078dd65709 ad08b2c2673b40ddb60745078dd65709--f1c750245d1b4398bc13a56de7861c4e 8c4fe497a1004f6ba15adc73ed87551a ad08b2c2673b40ddb60745078dd65709--8c4fe497a1004f6ba15adc73ed87551a 1ba9253f305749038d110b6cfe0afef0 8c4fe497a1004f6ba15adc73ed87551a--1ba9253f305749038d110b6cfe0afef0 04f19e29674240bfbb879523294d5cef 1ba9253f305749038d110b6cfe0afef0--04f19e29674240bfbb879523294d5cef 90b16204cd724cffaed451b39273418f X 04f19e29674240bfbb879523294d5cef--90b16204cd724cffaed451b39273418f 90b16204cd724cffaed451b39273418f--b10d4208efe04efb8297db5bb15e2f46 e40cfc39fafd48e3b5e5ddc0e071c612 90b16204cd724cffaed451b39273418f--e40cfc39fafd48e3b5e5ddc0e071c612 0103bf1693ea43b48b9dca94739b5928 e40cfc39fafd48e3b5e5ddc0e071c612--0103bf1693ea43b48b9dca94739b5928 8bb61151674b48d499a909db035a1812 0103bf1693ea43b48b9dca94739b5928--8bb61151674b48d499a909db035a1812 5597f3200e464cc2bb81cd410ef49f0a X 8bb61151674b48d499a909db035a1812--5597f3200e464cc2bb81cd410ef49f0a 5597f3200e464cc2bb81cd410ef49f0a--51303e4e60f4405aba691e18b7e54d7d 692ca05b75b1419e8b8a5ba1cfc10aec RZ(-1.0*g1) 5597f3200e464cc2bb81cd410ef49f0a--692ca05b75b1419e8b8a5ba1cfc10aec b33c2ef2ed1642d2af2aed346779870c X 692ca05b75b1419e8b8a5ba1cfc10aec--b33c2ef2ed1642d2af2aed346779870c b33c2ef2ed1642d2af2aed346779870c--947ebbb0325647869dee64f15f3a32c7 3df20612a98e4c43ae6393bc4d452e55 b33c2ef2ed1642d2af2aed346779870c--3df20612a98e4c43ae6393bc4d452e55 445f3f1f64914b25aecdc2ef4b6021f9 3df20612a98e4c43ae6393bc4d452e55--445f3f1f64914b25aecdc2ef4b6021f9 df9263d5e4e1431399779647ebc1deb4 X 445f3f1f64914b25aecdc2ef4b6021f9--df9263d5e4e1431399779647ebc1deb4 df9263d5e4e1431399779647ebc1deb4--198b14ecfac44cfaba6b8f2c135821fa 8825a6cda02047e0826809317e89802a df9263d5e4e1431399779647ebc1deb4--8825a6cda02047e0826809317e89802a d328940b800d4b7fbb81349a04afc165 8825a6cda02047e0826809317e89802a--d328940b800d4b7fbb81349a04afc165 0cef7a9070a340bab2b5cc1629de2628 d328940b800d4b7fbb81349a04afc165--0cef7a9070a340bab2b5cc1629de2628 cbda482b50dd4615a60b131bc2f4576b X 0cef7a9070a340bab2b5cc1629de2628--cbda482b50dd4615a60b131bc2f4576b cbda482b50dd4615a60b131bc2f4576b--10912a4acf65498ebe77b83b7be3bea7 cc4b9e6e7bd74cdd84e7ac43f70219d7 cbda482b50dd4615a60b131bc2f4576b--cc4b9e6e7bd74cdd84e7ac43f70219d7 61834f93b6ce4be48673221bbf996f99 cc4b9e6e7bd74cdd84e7ac43f70219d7--61834f93b6ce4be48673221bbf996f99 e6803e12492848f5be4c1da3e59bbfb2 X 61834f93b6ce4be48673221bbf996f99--e6803e12492848f5be4c1da3e59bbfb2 e6803e12492848f5be4c1da3e59bbfb2--cf23562f7d6f4e2fa316d5ede47fc0d8 46596ae739fd496fad9bb2611dbed244 e6803e12492848f5be4c1da3e59bbfb2--46596ae739fd496fad9bb2611dbed244 1f5981b12e0c4a56a79248a778160741 46596ae739fd496fad9bb2611dbed244--1f5981b12e0c4a56a79248a778160741 887cf888b3c84daea5fdff2c75e97f7d 1f5981b12e0c4a56a79248a778160741--887cf888b3c84daea5fdff2c75e97f7d 65e9ac13892f4ed08063e611a4616e55 887cf888b3c84daea5fdff2c75e97f7d--65e9ac13892f4ed08063e611a4616e55 ea5bdcaa0d1d4098af24c1145c985ee2 65e9ac13892f4ed08063e611a4616e55--ea5bdcaa0d1d4098af24c1145c985ee2 986692527ff74912909d07b0a72a0362 X ea5bdcaa0d1d4098af24c1145c985ee2--986692527ff74912909d07b0a72a0362 986692527ff74912909d07b0a72a0362--e07b8483587447a2ac9ec42c34c81c95 507f3b320c9f41e096459bc1d4afa74c 986692527ff74912909d07b0a72a0362--507f3b320c9f41e096459bc1d4afa74c 0d4cefe93979456b890912bdd7c01fe2 507f3b320c9f41e096459bc1d4afa74c--0d4cefe93979456b890912bdd7c01fe2 bc0adba92e6341aa91cf7fbba36accaa 0d4cefe93979456b890912bdd7c01fe2--bc0adba92e6341aa91cf7fbba36accaa 18bd23dcadee4c7b9f62609023f90d03 bc0adba92e6341aa91cf7fbba36accaa--18bd23dcadee4c7b9f62609023f90d03 a672d1e0833d495a84d81aefc61d6286 RX(b15) 18bd23dcadee4c7b9f62609023f90d03--a672d1e0833d495a84d81aefc61d6286 a672d1e0833d495a84d81aefc61d6286--ac5fea30bd1e4d5bbcd8ee109deb7e52 5c691db1e3f24c64965a4d748ac3f520 f3185614baf34291a7cd7c7da68a499b b9790715ab1e4ffc9b05c624f1323a49--f3185614baf34291a7cd7c7da68a499b 4cdb48a2e54e4f29959af1be7141117c 7 fb3c0e31d951411590f650761f63e259 f3185614baf34291a7cd7c7da68a499b--fb3c0e31d951411590f650761f63e259 49cc00fbb1bd499396e9754b664cbfc2 fb3c0e31d951411590f650761f63e259--49cc00fbb1bd499396e9754b664cbfc2 e16238c773774464af0f259ea6ae377a 49cc00fbb1bd499396e9754b664cbfc2--e16238c773774464af0f259ea6ae377a d55f357b0226405b8e22566b69c1f873 e16238c773774464af0f259ea6ae377a--d55f357b0226405b8e22566b69c1f873 b03b9e98c7dc41f3831ab6dd37bddc74 X d55f357b0226405b8e22566b69c1f873--b03b9e98c7dc41f3831ab6dd37bddc74 b03b9e98c7dc41f3831ab6dd37bddc74--825e79003b604d5daa7097e2eabfd79e c46ddba7f1454a87bfebbde97940a9a5 b03b9e98c7dc41f3831ab6dd37bddc74--c46ddba7f1454a87bfebbde97940a9a5 9e16723115da49f88473f99be25f5943 c46ddba7f1454a87bfebbde97940a9a5--9e16723115da49f88473f99be25f5943 a2d7af6084984fdfa9b1812d9420c3b8 9e16723115da49f88473f99be25f5943--a2d7af6084984fdfa9b1812d9420c3b8 1f0bed0912c7498a93945dae1575dc91 X a2d7af6084984fdfa9b1812d9420c3b8--1f0bed0912c7498a93945dae1575dc91 1f0bed0912c7498a93945dae1575dc91--f8176358874c4d5888e53652b06c3269 3a56a47f392543ab826b3903f194b42a 1f0bed0912c7498a93945dae1575dc91--3a56a47f392543ab826b3903f194b42a 30a61b41985c4ca2bc62540211a445e5 3a56a47f392543ab826b3903f194b42a--30a61b41985c4ca2bc62540211a445e5 c05b3a97c93949138e7b78b739b19e68 30a61b41985c4ca2bc62540211a445e5--c05b3a97c93949138e7b78b739b19e68 044f75b406214af4906fea78e0c0bad0 c05b3a97c93949138e7b78b739b19e68--044f75b406214af4906fea78e0c0bad0 4496bbb447cb440483b07f633a144167 044f75b406214af4906fea78e0c0bad0--4496bbb447cb440483b07f633a144167 68a737ec7b7d436f92c73cbba01f56e8 4496bbb447cb440483b07f633a144167--68a737ec7b7d436f92c73cbba01f56e8 e08e23a8406e449aaafaaac9597fb59e 68a737ec7b7d436f92c73cbba01f56e8--e08e23a8406e449aaafaaac9597fb59e fffb0064432345e49f5aed650779dcf1 e08e23a8406e449aaafaaac9597fb59e--fffb0064432345e49f5aed650779dcf1 acf19306da0f493b8da2ebe232ceaf4a fffb0064432345e49f5aed650779dcf1--acf19306da0f493b8da2ebe232ceaf4a d962c67c7ea8466bafbbdb11c8a72cef acf19306da0f493b8da2ebe232ceaf4a--d962c67c7ea8466bafbbdb11c8a72cef 22bd1247ec7b4790bce77608cf8f8f9a d962c67c7ea8466bafbbdb11c8a72cef--22bd1247ec7b4790bce77608cf8f8f9a 2ec45b8937f54cfcb82b4149f4cbde50 22bd1247ec7b4790bce77608cf8f8f9a--2ec45b8937f54cfcb82b4149f4cbde50 03cd89992b1948fcbaf479ec777afdfe 2ec45b8937f54cfcb82b4149f4cbde50--03cd89992b1948fcbaf479ec777afdfe 02600139e997499eab22c9398c6e0204 03cd89992b1948fcbaf479ec777afdfe--02600139e997499eab22c9398c6e0204 e1356f48d15f44c58da758d080f43339 02600139e997499eab22c9398c6e0204--e1356f48d15f44c58da758d080f43339 c27e9e63754d4f7999b3eca8fe1b26f5 e1356f48d15f44c58da758d080f43339--c27e9e63754d4f7999b3eca8fe1b26f5 dad0b8016391487daed7aaa02087ae83 c27e9e63754d4f7999b3eca8fe1b26f5--dad0b8016391487daed7aaa02087ae83 bd836372a2c0405fa64c0bd18810d723 dad0b8016391487daed7aaa02087ae83--bd836372a2c0405fa64c0bd18810d723 7cac036cfcac4ade92a1f1bbe4ca76c8 bd836372a2c0405fa64c0bd18810d723--7cac036cfcac4ade92a1f1bbe4ca76c8 0d1780f392bc4637b34b19db188a7088 7cac036cfcac4ade92a1f1bbe4ca76c8--0d1780f392bc4637b34b19db188a7088 0ce48f3958ec411f82c58b75cea0d8bc 0d1780f392bc4637b34b19db188a7088--0ce48f3958ec411f82c58b75cea0d8bc 3617259f2b764701b51df99a2cfc2f7e 0ce48f3958ec411f82c58b75cea0d8bc--3617259f2b764701b51df99a2cfc2f7e a6dabf8565e6426fb413495f2c64d9f2 3617259f2b764701b51df99a2cfc2f7e--a6dabf8565e6426fb413495f2c64d9f2 e0695c1681694cfda4bb4de3875e0bb0 a6dabf8565e6426fb413495f2c64d9f2--e0695c1681694cfda4bb4de3875e0bb0 c6b59f789db8405da7907faefa33c995 e0695c1681694cfda4bb4de3875e0bb0--c6b59f789db8405da7907faefa33c995 25b14bd35f7443cfa1c781b9412cc128 c6b59f789db8405da7907faefa33c995--25b14bd35f7443cfa1c781b9412cc128 ea79d9919f0e4a84907acd6f2aa589a0 25b14bd35f7443cfa1c781b9412cc128--ea79d9919f0e4a84907acd6f2aa589a0 6865dd20a1df4009850559636a5c2329 ea79d9919f0e4a84907acd6f2aa589a0--6865dd20a1df4009850559636a5c2329 28570292fe5c42cfa2cca4699c089cda 6865dd20a1df4009850559636a5c2329--28570292fe5c42cfa2cca4699c089cda 7d8606cbded840aeaacff49830f6e594 28570292fe5c42cfa2cca4699c089cda--7d8606cbded840aeaacff49830f6e594 2b321ba131aa4833be97c48333dcd87a X 7d8606cbded840aeaacff49830f6e594--2b321ba131aa4833be97c48333dcd87a 2b321ba131aa4833be97c48333dcd87a--22d0ee9bcc5d4860868bc5d5b0508850 756029c5391f4356a6e6fb9aea8c8c86 RZ(-1.0*g0) 2b321ba131aa4833be97c48333dcd87a--756029c5391f4356a6e6fb9aea8c8c86 b8275006dcd249a499a24e881ab87e20 X 756029c5391f4356a6e6fb9aea8c8c86--b8275006dcd249a499a24e881ab87e20 b8275006dcd249a499a24e881ab87e20--512395f4bc78449e8f2597e4ed6a8ce5 8872c50f23cb46639564b67f7faa6522 b8275006dcd249a499a24e881ab87e20--8872c50f23cb46639564b67f7faa6522 63932f312d8746e5a184ace37e166bee 8872c50f23cb46639564b67f7faa6522--63932f312d8746e5a184ace37e166bee 3e37d86613da49d5bd8e9debef0510f9 63932f312d8746e5a184ace37e166bee--3e37d86613da49d5bd8e9debef0510f9 2188c66629f3463b9cb0b709a526b5e1 3e37d86613da49d5bd8e9debef0510f9--2188c66629f3463b9cb0b709a526b5e1 8c3bb07857444b2e8cc64ea1e888c483 2188c66629f3463b9cb0b709a526b5e1--8c3bb07857444b2e8cc64ea1e888c483 58ebd161cf4c4202ae4eadc15a774bf9 8c3bb07857444b2e8cc64ea1e888c483--58ebd161cf4c4202ae4eadc15a774bf9 889411fb697e4e3eb9161c955f67aa85 58ebd161cf4c4202ae4eadc15a774bf9--889411fb697e4e3eb9161c955f67aa85 7c03614eeba149c69d963981f5397e81 889411fb697e4e3eb9161c955f67aa85--7c03614eeba149c69d963981f5397e81 00c4366efb0040d0baa80b43564eaaec 7c03614eeba149c69d963981f5397e81--00c4366efb0040d0baa80b43564eaaec dfd6cd37efd049d0a310a24813ddee5b 00c4366efb0040d0baa80b43564eaaec--dfd6cd37efd049d0a310a24813ddee5b 9ded66260e7241bcacd35796d1a6b2be X dfd6cd37efd049d0a310a24813ddee5b--9ded66260e7241bcacd35796d1a6b2be 9ded66260e7241bcacd35796d1a6b2be--2eebc6011bfa4c9583a24a7705135e07 e7fbb2a3969849758d405b45787fb8df 9ded66260e7241bcacd35796d1a6b2be--e7fbb2a3969849758d405b45787fb8df 619b2e95010541c4b85b5ff6a8ebb96a e7fbb2a3969849758d405b45787fb8df--619b2e95010541c4b85b5ff6a8ebb96a 1ad939f52d20440192fd144beb0840ad 619b2e95010541c4b85b5ff6a8ebb96a--1ad939f52d20440192fd144beb0840ad 0624d104a5cc4cbb9794fc0fd1281e88 X 1ad939f52d20440192fd144beb0840ad--0624d104a5cc4cbb9794fc0fd1281e88 0624d104a5cc4cbb9794fc0fd1281e88--9a1e2a8635b848a5bd7d78fbfe84d226 6ed871b36c9f45878df7ba0c876d99b9 0624d104a5cc4cbb9794fc0fd1281e88--6ed871b36c9f45878df7ba0c876d99b9 6961bf381eee4a7ead47c72e458a1688 6ed871b36c9f45878df7ba0c876d99b9--6961bf381eee4a7ead47c72e458a1688 aa544caa948149659ac459c58c6d6d86 6961bf381eee4a7ead47c72e458a1688--aa544caa948149659ac459c58c6d6d86 5aa6c493bc074f459bf1b0c50c5d6ef9 aa544caa948149659ac459c58c6d6d86--5aa6c493bc074f459bf1b0c50c5d6ef9 1e4de0d1ab4f45c29be1e8eaf8e87852 5aa6c493bc074f459bf1b0c50c5d6ef9--1e4de0d1ab4f45c29be1e8eaf8e87852 8c04bafcf9b44d118199c20a9f2ae496 1e4de0d1ab4f45c29be1e8eaf8e87852--8c04bafcf9b44d118199c20a9f2ae496 4a1edd5337df4d36872d8f85cadf7cb1 8c04bafcf9b44d118199c20a9f2ae496--4a1edd5337df4d36872d8f85cadf7cb1 19f7df68333f4c9283cdace1f9215386 4a1edd5337df4d36872d8f85cadf7cb1--19f7df68333f4c9283cdace1f9215386 1daea4b7649945ba8c3fd881626f0dac 19f7df68333f4c9283cdace1f9215386--1daea4b7649945ba8c3fd881626f0dac 7c7d5b58d6104bc094cee29e16b1cfab 1daea4b7649945ba8c3fd881626f0dac--7c7d5b58d6104bc094cee29e16b1cfab a2963aa252a44310833232fbbe414164 7c7d5b58d6104bc094cee29e16b1cfab--a2963aa252a44310833232fbbe414164 2f35e6ae6266406e841335f43b78a3a3 a2963aa252a44310833232fbbe414164--2f35e6ae6266406e841335f43b78a3a3 17061ef5a85a4faf8c5896df89385b23 2f35e6ae6266406e841335f43b78a3a3--17061ef5a85a4faf8c5896df89385b23 b7e69978f34644b0b379d5245f009558 17061ef5a85a4faf8c5896df89385b23--b7e69978f34644b0b379d5245f009558 02d09ec4437745abb3984121f26fde8f b7e69978f34644b0b379d5245f009558--02d09ec4437745abb3984121f26fde8f 0378053b267c477a88eb71206386f4a3 02d09ec4437745abb3984121f26fde8f--0378053b267c477a88eb71206386f4a3 4f0ff4fbbc7d4511a53e9becace0225c 0378053b267c477a88eb71206386f4a3--4f0ff4fbbc7d4511a53e9becace0225c c0955e84b61b4ecb98ddcf7fd9bf0f35 4f0ff4fbbc7d4511a53e9becace0225c--c0955e84b61b4ecb98ddcf7fd9bf0f35 4fad3f32abea4ad28eb3934964b20955 c0955e84b61b4ecb98ddcf7fd9bf0f35--4fad3f32abea4ad28eb3934964b20955 56c292d555214a78b74877d97cfcf266 4fad3f32abea4ad28eb3934964b20955--56c292d555214a78b74877d97cfcf266 53653eb7ca834bad989773f761f07471 56c292d555214a78b74877d97cfcf266--53653eb7ca834bad989773f761f07471 85f4a7b6cf524b1da83e434e559e871b X 53653eb7ca834bad989773f761f07471--85f4a7b6cf524b1da83e434e559e871b 85f4a7b6cf524b1da83e434e559e871b--a21c4d5c55ba417c8de3a4524c054130 c4c5cfcd5204427ea84f20b0a337fdbd RZ(-1.0*g0) 85f4a7b6cf524b1da83e434e559e871b--c4c5cfcd5204427ea84f20b0a337fdbd 91ffcbccfb2048189c3be6060e81716c X c4c5cfcd5204427ea84f20b0a337fdbd--91ffcbccfb2048189c3be6060e81716c 91ffcbccfb2048189c3be6060e81716c--79d2b2a5342642f2b9c2cdb3288d4ce0 aa8f3394f3b349ce8655a487f647f0f9 91ffcbccfb2048189c3be6060e81716c--aa8f3394f3b349ce8655a487f647f0f9 906f7050af064d079440ffcc31998037 aa8f3394f3b349ce8655a487f647f0f9--906f7050af064d079440ffcc31998037 96b1b4922264466dbde194e5004a5b1f 906f7050af064d079440ffcc31998037--96b1b4922264466dbde194e5004a5b1f c149be512c5e4a10a8e083da39ab9f84 96b1b4922264466dbde194e5004a5b1f--c149be512c5e4a10a8e083da39ab9f84 f7feb0f4a5be4f86b53b5bee40296073 c149be512c5e4a10a8e083da39ab9f84--f7feb0f4a5be4f86b53b5bee40296073 cf2e246ef1a34350a3903752ae211ae0 f7feb0f4a5be4f86b53b5bee40296073--cf2e246ef1a34350a3903752ae211ae0 12739e19f42d41cba012bc17abe3f34d cf2e246ef1a34350a3903752ae211ae0--12739e19f42d41cba012bc17abe3f34d c77b4359837f48678ddafd1351274393 12739e19f42d41cba012bc17abe3f34d--c77b4359837f48678ddafd1351274393 c1f0b7e448f74331971a0130ad7f5e16 c77b4359837f48678ddafd1351274393--c1f0b7e448f74331971a0130ad7f5e16 066f938b5abe4a26bafdcbddfc7291f4 c1f0b7e448f74331971a0130ad7f5e16--066f938b5abe4a26bafdcbddfc7291f4 5aac418fad3c46ce91c0c0696d754a6f 066f938b5abe4a26bafdcbddfc7291f4--5aac418fad3c46ce91c0c0696d754a6f 063884e4b381489aa8d4f49b29a7e1b7 5aac418fad3c46ce91c0c0696d754a6f--063884e4b381489aa8d4f49b29a7e1b7 8beb3043c3bf4de6a1b208d3c12fd9ba 063884e4b381489aa8d4f49b29a7e1b7--8beb3043c3bf4de6a1b208d3c12fd9ba f53773a44a564ef696edfe13a1f238c7 8beb3043c3bf4de6a1b208d3c12fd9ba--f53773a44a564ef696edfe13a1f238c7 44d789ffd8bd40da86f4c16a4c8dc4c8 f53773a44a564ef696edfe13a1f238c7--44d789ffd8bd40da86f4c16a4c8dc4c8 852bed0a491e46129afc33f00a5efb5b 44d789ffd8bd40da86f4c16a4c8dc4c8--852bed0a491e46129afc33f00a5efb5b 4adbc2e3222849cf9aa8562c6f71b9e4 852bed0a491e46129afc33f00a5efb5b--4adbc2e3222849cf9aa8562c6f71b9e4 06e5537c525c466696b5d26fd5711fc3 4adbc2e3222849cf9aa8562c6f71b9e4--06e5537c525c466696b5d26fd5711fc3 d079d1d9413d438385f1a91ab8bffdf8 06e5537c525c466696b5d26fd5711fc3--d079d1d9413d438385f1a91ab8bffdf8 bcf41906ccc743cbbae073c442b811ef X d079d1d9413d438385f1a91ab8bffdf8--bcf41906ccc743cbbae073c442b811ef bcf41906ccc743cbbae073c442b811ef--fa6c539c34bd4102a4ae1547ce67a45a d545cbed4a7b4d218af249ca77befb04 RZ(-1.0*g0) bcf41906ccc743cbbae073c442b811ef--d545cbed4a7b4d218af249ca77befb04 0972948423614362993febefe0f4e000 X d545cbed4a7b4d218af249ca77befb04--0972948423614362993febefe0f4e000 0972948423614362993febefe0f4e000--7fde87e3782443a7a31a2233265b0635 494b0fcec0804eb28d2c0483dd4b9efa 0972948423614362993febefe0f4e000--494b0fcec0804eb28d2c0483dd4b9efa 07b9a213cee84250946c80e6cbfecae6 494b0fcec0804eb28d2c0483dd4b9efa--07b9a213cee84250946c80e6cbfecae6 9ca18f1a5410411b80977e0d2f8a7120 07b9a213cee84250946c80e6cbfecae6--9ca18f1a5410411b80977e0d2f8a7120 4a6cc9a0f5434ae7864dd44c3d7d69f5 9ca18f1a5410411b80977e0d2f8a7120--4a6cc9a0f5434ae7864dd44c3d7d69f5 d7029b20bcd44250b7b3aa4705b97052 4a6cc9a0f5434ae7864dd44c3d7d69f5--d7029b20bcd44250b7b3aa4705b97052 0b6020cf83b04771807dd4a1a857a418 d7029b20bcd44250b7b3aa4705b97052--0b6020cf83b04771807dd4a1a857a418 f4c22998c66a4c2f8d8f129b266a866f 0b6020cf83b04771807dd4a1a857a418--f4c22998c66a4c2f8d8f129b266a866f c0d0fff172f84c4bb3beed11529a6070 f4c22998c66a4c2f8d8f129b266a866f--c0d0fff172f84c4bb3beed11529a6070 b500f1c64e86435fab914ec66e26d480 c0d0fff172f84c4bb3beed11529a6070--b500f1c64e86435fab914ec66e26d480 8935ceeb24c344128cf95d7a48cce94d b500f1c64e86435fab914ec66e26d480--8935ceeb24c344128cf95d7a48cce94d fd6c3fd7187844798b0bffdac683ef29 X 8935ceeb24c344128cf95d7a48cce94d--fd6c3fd7187844798b0bffdac683ef29 fd6c3fd7187844798b0bffdac683ef29--ffb642e43a0e4fad8fb24a41431b660f 6ada7895d2274f53bacd94f1fb873988 RZ(-1.0*g0) fd6c3fd7187844798b0bffdac683ef29--6ada7895d2274f53bacd94f1fb873988 a558379ed12940cea51b2b1bd02c2a02 X 6ada7895d2274f53bacd94f1fb873988--a558379ed12940cea51b2b1bd02c2a02 a558379ed12940cea51b2b1bd02c2a02--fbbd14f5c22c43039d469db1f81ace3f f6c92f55bdf24bb48704fa44f3545122 a558379ed12940cea51b2b1bd02c2a02--f6c92f55bdf24bb48704fa44f3545122 a0c0d7fc80cc4dc18e2d0e0e93a25e37 f6c92f55bdf24bb48704fa44f3545122--a0c0d7fc80cc4dc18e2d0e0e93a25e37 54e132be0b904ac5b45867d5cf1d9ec6 a0c0d7fc80cc4dc18e2d0e0e93a25e37--54e132be0b904ac5b45867d5cf1d9ec6 c9d1ff40100a4266924b05cba72749ea 54e132be0b904ac5b45867d5cf1d9ec6--c9d1ff40100a4266924b05cba72749ea 0bab895c536f48e9b83710088b7ab92f X c9d1ff40100a4266924b05cba72749ea--0bab895c536f48e9b83710088b7ab92f 0bab895c536f48e9b83710088b7ab92f--6cc304acb1074ec6a7dd76b4a4e3bceb 3365c0bce07741098a2d2a7dd16131c0 0bab895c536f48e9b83710088b7ab92f--3365c0bce07741098a2d2a7dd16131c0 347bcfe6291c4bd0a89922a58bc90027 3365c0bce07741098a2d2a7dd16131c0--347bcfe6291c4bd0a89922a58bc90027 c7ec30d813c6415cb26aa6c61e1b3bf3 347bcfe6291c4bd0a89922a58bc90027--c7ec30d813c6415cb26aa6c61e1b3bf3 9743a41fc7584daa8159ad8271be26f4 X c7ec30d813c6415cb26aa6c61e1b3bf3--9743a41fc7584daa8159ad8271be26f4 9743a41fc7584daa8159ad8271be26f4--32042453ff2c4f5f9e420a8a41a11439 75a10737b6024d05815b65f8c82f058c 9743a41fc7584daa8159ad8271be26f4--75a10737b6024d05815b65f8c82f058c 849acc9c83464279bfff38cd4814a371 75a10737b6024d05815b65f8c82f058c--849acc9c83464279bfff38cd4814a371 cf3312d008274bb8b92890bdb1ab6753 849acc9c83464279bfff38cd4814a371--cf3312d008274bb8b92890bdb1ab6753 a8be9fce3f014c63a3d977df00a735d0 cf3312d008274bb8b92890bdb1ab6753--a8be9fce3f014c63a3d977df00a735d0 27c744042dab4ce48b2bd62fbd6dce7c a8be9fce3f014c63a3d977df00a735d0--27c744042dab4ce48b2bd62fbd6dce7c 0efc81516051425a9b14357f0dcdeb49 RX(b06) 27c744042dab4ce48b2bd62fbd6dce7c--0efc81516051425a9b14357f0dcdeb49 87a470ba9a394862b9771b043e71bd6b 0efc81516051425a9b14357f0dcdeb49--87a470ba9a394862b9771b043e71bd6b 91196da43d9d4539a6cc1bb5c007099c 87a470ba9a394862b9771b043e71bd6b--91196da43d9d4539a6cc1bb5c007099c 8844eb60dace45bda33b766a6f078b59 91196da43d9d4539a6cc1bb5c007099c--8844eb60dace45bda33b766a6f078b59 1647ed6fb9634902bd199b9e70ef4c2c 8844eb60dace45bda33b766a6f078b59--1647ed6fb9634902bd199b9e70ef4c2c ae524cfe64b44998a7f4cdec00f23b22 1647ed6fb9634902bd199b9e70ef4c2c--ae524cfe64b44998a7f4cdec00f23b22 cca7f12087e94f4da5f5e4deeb468655 X ae524cfe64b44998a7f4cdec00f23b22--cca7f12087e94f4da5f5e4deeb468655 cca7f12087e94f4da5f5e4deeb468655--8853e97231eb4f1697b6bb913cf173e5 6ea2e505b9644db495e8d4be0eeb0c44 cca7f12087e94f4da5f5e4deeb468655--6ea2e505b9644db495e8d4be0eeb0c44 3e616b31189546338edc1114c611bc28 6ea2e505b9644db495e8d4be0eeb0c44--3e616b31189546338edc1114c611bc28 17224f3c49a343f6b34e102663299edc 3e616b31189546338edc1114c611bc28--17224f3c49a343f6b34e102663299edc 3b64f06a3b5e411ba77e73c57bda8c68 X 17224f3c49a343f6b34e102663299edc--3b64f06a3b5e411ba77e73c57bda8c68 3b64f06a3b5e411ba77e73c57bda8c68--1df0c701bcab4d52b058051f52b15d4c 41b745c72e6245ed993ddc388c7b35f5 3b64f06a3b5e411ba77e73c57bda8c68--41b745c72e6245ed993ddc388c7b35f5 002a9bdc7a5d4bd7ae67a429368c18e3 41b745c72e6245ed993ddc388c7b35f5--002a9bdc7a5d4bd7ae67a429368c18e3 ffddfdf62acb4168af712c4b0d568099 002a9bdc7a5d4bd7ae67a429368c18e3--ffddfdf62acb4168af712c4b0d568099 cc2e2e3dd3314f338b615d9d727cfa89 ffddfdf62acb4168af712c4b0d568099--cc2e2e3dd3314f338b615d9d727cfa89 5f5ce402568b48ed95fdf7ddc289c8d8 cc2e2e3dd3314f338b615d9d727cfa89--5f5ce402568b48ed95fdf7ddc289c8d8 86d029ef64964d329e432e69b13416c6 5f5ce402568b48ed95fdf7ddc289c8d8--86d029ef64964d329e432e69b13416c6 9c3c6d66410f4a9bbfbac85c83cb85f8 86d029ef64964d329e432e69b13416c6--9c3c6d66410f4a9bbfbac85c83cb85f8 8d497aea9aa949e8816b82b55cec8f10 9c3c6d66410f4a9bbfbac85c83cb85f8--8d497aea9aa949e8816b82b55cec8f10 f469a54caa9c43c7a10000976d923056 8d497aea9aa949e8816b82b55cec8f10--f469a54caa9c43c7a10000976d923056 9f371563747749c6ac6297dfc3da75ca f469a54caa9c43c7a10000976d923056--9f371563747749c6ac6297dfc3da75ca cf99c93cd0994efab2d864a449c4299a 9f371563747749c6ac6297dfc3da75ca--cf99c93cd0994efab2d864a449c4299a 73f7c43a5134409089febc51962f5b67 cf99c93cd0994efab2d864a449c4299a--73f7c43a5134409089febc51962f5b67 4e10f9156ef74cbcaa96a848ca054a67 73f7c43a5134409089febc51962f5b67--4e10f9156ef74cbcaa96a848ca054a67 ba3b918acab04a6f99b9bc271208d1b2 4e10f9156ef74cbcaa96a848ca054a67--ba3b918acab04a6f99b9bc271208d1b2 f670b6d57cba4da58b29867c074facd4 ba3b918acab04a6f99b9bc271208d1b2--f670b6d57cba4da58b29867c074facd4 d7275d5e84704117a0bef2811736b663 f670b6d57cba4da58b29867c074facd4--d7275d5e84704117a0bef2811736b663 c06546e5355940bdb257e5dbcd46a74f d7275d5e84704117a0bef2811736b663--c06546e5355940bdb257e5dbcd46a74f 613a8ce0d5dc44db9b861723db24651c c06546e5355940bdb257e5dbcd46a74f--613a8ce0d5dc44db9b861723db24651c 83639fe617f34ed19ff12dd8e044c4c5 613a8ce0d5dc44db9b861723db24651c--83639fe617f34ed19ff12dd8e044c4c5 0463c682c8eb4854b727dee8411f023e 83639fe617f34ed19ff12dd8e044c4c5--0463c682c8eb4854b727dee8411f023e 190b41b8af4044e298bbaeef457a6715 0463c682c8eb4854b727dee8411f023e--190b41b8af4044e298bbaeef457a6715 1e97f4751d3447e891474b0052d3d7d0 190b41b8af4044e298bbaeef457a6715--1e97f4751d3447e891474b0052d3d7d0 cf8079594ad0412ebeb54cd9620c9f60 1e97f4751d3447e891474b0052d3d7d0--cf8079594ad0412ebeb54cd9620c9f60 36b0266dd86b4869ad8ef1f2fdf684b7 cf8079594ad0412ebeb54cd9620c9f60--36b0266dd86b4869ad8ef1f2fdf684b7 a5386154b2304d58b6c76474159f746a 36b0266dd86b4869ad8ef1f2fdf684b7--a5386154b2304d58b6c76474159f746a a60675710c78463d8099268e0cc59bc3 a5386154b2304d58b6c76474159f746a--a60675710c78463d8099268e0cc59bc3 fdcc9c2302b9408a8be363fa9582963f a60675710c78463d8099268e0cc59bc3--fdcc9c2302b9408a8be363fa9582963f 4d3b07fe81794a91a259f39c201176ef fdcc9c2302b9408a8be363fa9582963f--4d3b07fe81794a91a259f39c201176ef d9f1b3cbeb2c44eaba941339472c85c3 4d3b07fe81794a91a259f39c201176ef--d9f1b3cbeb2c44eaba941339472c85c3 cee12955e68a409fa69d15d22913f52a d9f1b3cbeb2c44eaba941339472c85c3--cee12955e68a409fa69d15d22913f52a a49181d73741486f9017dd715102b12f X cee12955e68a409fa69d15d22913f52a--a49181d73741486f9017dd715102b12f a49181d73741486f9017dd715102b12f--69ccbd23e0dd4cd6ae72435f7a382649 9b335cbbed534c0db316bc68b095808d RZ(-1.0*g1) a49181d73741486f9017dd715102b12f--9b335cbbed534c0db316bc68b095808d 23bfe4c456eb4a8dacd8c927e2ff15ee X 9b335cbbed534c0db316bc68b095808d--23bfe4c456eb4a8dacd8c927e2ff15ee 23bfe4c456eb4a8dacd8c927e2ff15ee--c663ff35b16544dabcb4ffb3402e01f1 4bbece61d9aa432d879c243466161562 23bfe4c456eb4a8dacd8c927e2ff15ee--4bbece61d9aa432d879c243466161562 81e970fbf75b424b97e228d9d776474d 4bbece61d9aa432d879c243466161562--81e970fbf75b424b97e228d9d776474d a80c9941942f4496951979a1a6043c93 81e970fbf75b424b97e228d9d776474d--a80c9941942f4496951979a1a6043c93 c1eea71899ee45168cfa5dff2cf8d9b0 a80c9941942f4496951979a1a6043c93--c1eea71899ee45168cfa5dff2cf8d9b0 e58ff781312d403eb856adbca94f76fe c1eea71899ee45168cfa5dff2cf8d9b0--e58ff781312d403eb856adbca94f76fe d8b30c4a1480439ba90c8c3fb6535c09 e58ff781312d403eb856adbca94f76fe--d8b30c4a1480439ba90c8c3fb6535c09 39de1f09f9a94920aa18cf989cf2f5a8 d8b30c4a1480439ba90c8c3fb6535c09--39de1f09f9a94920aa18cf989cf2f5a8 42db3037b3984fb7af72bc4f9a0d3cac 39de1f09f9a94920aa18cf989cf2f5a8--42db3037b3984fb7af72bc4f9a0d3cac b1208d1602c247a4b86c88f42d51270c 42db3037b3984fb7af72bc4f9a0d3cac--b1208d1602c247a4b86c88f42d51270c 3334329d09b444ec8c956f7d5910c9e9 b1208d1602c247a4b86c88f42d51270c--3334329d09b444ec8c956f7d5910c9e9 066aa7dbc54c4a2a8fef092ccc6eb6f0 X 3334329d09b444ec8c956f7d5910c9e9--066aa7dbc54c4a2a8fef092ccc6eb6f0 066aa7dbc54c4a2a8fef092ccc6eb6f0--222efcb9cb3149fca3fad3aa440584b5 b3b387e2c81f43159605fb2b65bee098 066aa7dbc54c4a2a8fef092ccc6eb6f0--b3b387e2c81f43159605fb2b65bee098 0f0f8aeb26a047c793b6893a558eb96f b3b387e2c81f43159605fb2b65bee098--0f0f8aeb26a047c793b6893a558eb96f da84a19d943340bba36b6c44eff423f5 0f0f8aeb26a047c793b6893a558eb96f--da84a19d943340bba36b6c44eff423f5 54931c69a8664099bc9a22985ecd370e X da84a19d943340bba36b6c44eff423f5--54931c69a8664099bc9a22985ecd370e 54931c69a8664099bc9a22985ecd370e--1c9ab65d202943a7b3e09037561063b2 13ec4d948a2f44de8f314e996aca91bb 54931c69a8664099bc9a22985ecd370e--13ec4d948a2f44de8f314e996aca91bb bcfde802e39a4cc8853ec26a1c3bb6b3 13ec4d948a2f44de8f314e996aca91bb--bcfde802e39a4cc8853ec26a1c3bb6b3 8d4ae35ab0f048feb989aed39c0040fb bcfde802e39a4cc8853ec26a1c3bb6b3--8d4ae35ab0f048feb989aed39c0040fb 534aec2fd47b4bf3b01f4639a2335158 8d4ae35ab0f048feb989aed39c0040fb--534aec2fd47b4bf3b01f4639a2335158 31659b9ec3894506b87d7f834abbeebc 534aec2fd47b4bf3b01f4639a2335158--31659b9ec3894506b87d7f834abbeebc 0c8eacd8fc5a43b192256ac2dc0a23c3 31659b9ec3894506b87d7f834abbeebc--0c8eacd8fc5a43b192256ac2dc0a23c3 f6bcdf3d7dd240e390df1df83f996bf7 0c8eacd8fc5a43b192256ac2dc0a23c3--f6bcdf3d7dd240e390df1df83f996bf7 50d89f3389a444b59b40a2987d4e2df0 f6bcdf3d7dd240e390df1df83f996bf7--50d89f3389a444b59b40a2987d4e2df0 e10a1d35a9f348caa81bf21cbdbb4ff8 50d89f3389a444b59b40a2987d4e2df0--e10a1d35a9f348caa81bf21cbdbb4ff8 ca5525ae5d62467084c96d69b3a04b7c e10a1d35a9f348caa81bf21cbdbb4ff8--ca5525ae5d62467084c96d69b3a04b7c eb03e3c8fbad4107bd9234ea4e1a192f ca5525ae5d62467084c96d69b3a04b7c--eb03e3c8fbad4107bd9234ea4e1a192f 48497f9071b9462f8f5a78f7ffc108ee eb03e3c8fbad4107bd9234ea4e1a192f--48497f9071b9462f8f5a78f7ffc108ee 07988ec18e9d4dd6aac01c0cf533d089 48497f9071b9462f8f5a78f7ffc108ee--07988ec18e9d4dd6aac01c0cf533d089 d09b6b52a2284557a640de114f20d68e 07988ec18e9d4dd6aac01c0cf533d089--d09b6b52a2284557a640de114f20d68e 8753e0e2c02c498db1b483ea13ccadff d09b6b52a2284557a640de114f20d68e--8753e0e2c02c498db1b483ea13ccadff 695131c285264cf285dd6612871e8e0c 8753e0e2c02c498db1b483ea13ccadff--695131c285264cf285dd6612871e8e0c e46edc5484714ff8a723c3bbd41d847f 695131c285264cf285dd6612871e8e0c--e46edc5484714ff8a723c3bbd41d847f 946833720459423dad9e11e96ab58db3 e46edc5484714ff8a723c3bbd41d847f--946833720459423dad9e11e96ab58db3 c00105c8544e4ce68e96810cb83967b4 946833720459423dad9e11e96ab58db3--c00105c8544e4ce68e96810cb83967b4 9f079b2a8f9b4611a317e4f36702e069 c00105c8544e4ce68e96810cb83967b4--9f079b2a8f9b4611a317e4f36702e069 9c0d32619a2440b5b29a4774a9277c16 9f079b2a8f9b4611a317e4f36702e069--9c0d32619a2440b5b29a4774a9277c16 5a4b43d993ab4ca3951356e6aa3ccb9c X 9c0d32619a2440b5b29a4774a9277c16--5a4b43d993ab4ca3951356e6aa3ccb9c 5a4b43d993ab4ca3951356e6aa3ccb9c--d3e73b4375694409a58816e5a3f0d666 4f5a3589f5ac4e67a0737385180b7f50 RZ(-1.0*g1) 5a4b43d993ab4ca3951356e6aa3ccb9c--4f5a3589f5ac4e67a0737385180b7f50 b97ccc5096024b698407e05bdf4066a4 X 4f5a3589f5ac4e67a0737385180b7f50--b97ccc5096024b698407e05bdf4066a4 b97ccc5096024b698407e05bdf4066a4--45a8136d6cd343e7bff2e3f78ac7c762 a47e4e224316408a9055b62c4be8ae1b b97ccc5096024b698407e05bdf4066a4--a47e4e224316408a9055b62c4be8ae1b c40cc334391547848dfe38533ca5a1e8 a47e4e224316408a9055b62c4be8ae1b--c40cc334391547848dfe38533ca5a1e8 1b6344f10b92472a9bde15b9a9b0b0dd c40cc334391547848dfe38533ca5a1e8--1b6344f10b92472a9bde15b9a9b0b0dd 4d3e769672d247188f7e58d81715246a 1b6344f10b92472a9bde15b9a9b0b0dd--4d3e769672d247188f7e58d81715246a 7afdf10cffb04697845a0426a5eaca3e 4d3e769672d247188f7e58d81715246a--7afdf10cffb04697845a0426a5eaca3e 363f0b17c47a4c51b296723d7a78fe13 7afdf10cffb04697845a0426a5eaca3e--363f0b17c47a4c51b296723d7a78fe13 e0d9aa176cdf4b3aa1c559cb1cd6e6c5 363f0b17c47a4c51b296723d7a78fe13--e0d9aa176cdf4b3aa1c559cb1cd6e6c5 0cf2da7dda4a49a7998273e0cb8f493a e0d9aa176cdf4b3aa1c559cb1cd6e6c5--0cf2da7dda4a49a7998273e0cb8f493a 42ad1ff9d3da48eeb7c3201a32efbfbc 0cf2da7dda4a49a7998273e0cb8f493a--42ad1ff9d3da48eeb7c3201a32efbfbc c7f9a6d89cb64e1f900f9fc0c27adb1b 42ad1ff9d3da48eeb7c3201a32efbfbc--c7f9a6d89cb64e1f900f9fc0c27adb1b fb88150d34854c718bfe3eb4b2d81cb8 c7f9a6d89cb64e1f900f9fc0c27adb1b--fb88150d34854c718bfe3eb4b2d81cb8 053d03f9074f4540bf1e20aeb1f7e8cd fb88150d34854c718bfe3eb4b2d81cb8--053d03f9074f4540bf1e20aeb1f7e8cd a43fa0beda814edd9fec29df7f872b0c 053d03f9074f4540bf1e20aeb1f7e8cd--a43fa0beda814edd9fec29df7f872b0c ade700e359fe44288bca63d7721b1d23 a43fa0beda814edd9fec29df7f872b0c--ade700e359fe44288bca63d7721b1d23 cd85588b1bd24245808d4a0fb876b209 ade700e359fe44288bca63d7721b1d23--cd85588b1bd24245808d4a0fb876b209 4ade8d30c16a4299a3da3b330cae5013 cd85588b1bd24245808d4a0fb876b209--4ade8d30c16a4299a3da3b330cae5013 70ec21917a5a4754ac36f4ecbd838353 4ade8d30c16a4299a3da3b330cae5013--70ec21917a5a4754ac36f4ecbd838353 c14777f8c5fb412bb23641209fe0cbde 70ec21917a5a4754ac36f4ecbd838353--c14777f8c5fb412bb23641209fe0cbde 9d714dece8624ad887e8aea22c029a03 c14777f8c5fb412bb23641209fe0cbde--9d714dece8624ad887e8aea22c029a03 c1df2b47145b456ba940377dd67d829f X 9d714dece8624ad887e8aea22c029a03--c1df2b47145b456ba940377dd67d829f c1df2b47145b456ba940377dd67d829f--8c4fe497a1004f6ba15adc73ed87551a 204e42cee8ae4e13a4ed173bc55b3e79 RZ(-1.0*g1) c1df2b47145b456ba940377dd67d829f--204e42cee8ae4e13a4ed173bc55b3e79 30b5a101e18a48e09895cfe23c13ef6c X 204e42cee8ae4e13a4ed173bc55b3e79--30b5a101e18a48e09895cfe23c13ef6c 30b5a101e18a48e09895cfe23c13ef6c--04f19e29674240bfbb879523294d5cef 182ffcb00f82414485733868e1e4836f 30b5a101e18a48e09895cfe23c13ef6c--182ffcb00f82414485733868e1e4836f 448e3d357dba44e49ee4d7c81ea77edc 182ffcb00f82414485733868e1e4836f--448e3d357dba44e49ee4d7c81ea77edc 8c1aace5fca2452a84cbf8d280096819 448e3d357dba44e49ee4d7c81ea77edc--8c1aace5fca2452a84cbf8d280096819 1365751d645a4c6aaa9152e1179e603a 8c1aace5fca2452a84cbf8d280096819--1365751d645a4c6aaa9152e1179e603a 5ca5fec61a1b46cf80f1e878766b0ca7 1365751d645a4c6aaa9152e1179e603a--5ca5fec61a1b46cf80f1e878766b0ca7 2520ffed4f8e4fb1afa8020edc0b685e 5ca5fec61a1b46cf80f1e878766b0ca7--2520ffed4f8e4fb1afa8020edc0b685e f6c01c140d374b57916c88b03b67c8d5 2520ffed4f8e4fb1afa8020edc0b685e--f6c01c140d374b57916c88b03b67c8d5 2347de1be7e74549b35160b8470e3146 f6c01c140d374b57916c88b03b67c8d5--2347de1be7e74549b35160b8470e3146 4d61891806364ec487ceb34f52a93ffd 2347de1be7e74549b35160b8470e3146--4d61891806364ec487ceb34f52a93ffd 77ed2ac72d1c470e8301c862da2b42e5 4d61891806364ec487ceb34f52a93ffd--77ed2ac72d1c470e8301c862da2b42e5 9279ed413dbb44579315ccea4bbab636 X 77ed2ac72d1c470e8301c862da2b42e5--9279ed413dbb44579315ccea4bbab636 9279ed413dbb44579315ccea4bbab636--8825a6cda02047e0826809317e89802a 785828b03134472dadcc2d798dd4d4d8 RZ(-1.0*g1) 9279ed413dbb44579315ccea4bbab636--785828b03134472dadcc2d798dd4d4d8 1fa9cc9fd96f469c96954ddd197b1533 X 785828b03134472dadcc2d798dd4d4d8--1fa9cc9fd96f469c96954ddd197b1533 1fa9cc9fd96f469c96954ddd197b1533--0cef7a9070a340bab2b5cc1629de2628 6c8d07c62be74d43805fbceeda94535c 1fa9cc9fd96f469c96954ddd197b1533--6c8d07c62be74d43805fbceeda94535c 82d70fff5dcd4d8e881d1a84f8364064 6c8d07c62be74d43805fbceeda94535c--82d70fff5dcd4d8e881d1a84f8364064 8ec70a4e653e4744b1fb49c60e41cdf0 82d70fff5dcd4d8e881d1a84f8364064--8ec70a4e653e4744b1fb49c60e41cdf0 5b57a23907db4b1bbe9896909362deca 8ec70a4e653e4744b1fb49c60e41cdf0--5b57a23907db4b1bbe9896909362deca da32c02205c541fab775e65ea45f422c X 5b57a23907db4b1bbe9896909362deca--da32c02205c541fab775e65ea45f422c da32c02205c541fab775e65ea45f422c--46596ae739fd496fad9bb2611dbed244 e46c0f9f15a04644949b1b4f851c6b17 da32c02205c541fab775e65ea45f422c--e46c0f9f15a04644949b1b4f851c6b17 8f3ef22a63bf494db08cde642439e59a e46c0f9f15a04644949b1b4f851c6b17--8f3ef22a63bf494db08cde642439e59a 410dd6eae6a14dada868cf8e194bf15c 8f3ef22a63bf494db08cde642439e59a--410dd6eae6a14dada868cf8e194bf15c 88cc5de2462e49b19d4f27be26536f2e X 410dd6eae6a14dada868cf8e194bf15c--88cc5de2462e49b19d4f27be26536f2e 88cc5de2462e49b19d4f27be26536f2e--ea5bdcaa0d1d4098af24c1145c985ee2 b751bf8e0c764029b45288695de09450 88cc5de2462e49b19d4f27be26536f2e--b751bf8e0c764029b45288695de09450 1e451f4e1ff246cc9d0e9ac5ef1fe358 b751bf8e0c764029b45288695de09450--1e451f4e1ff246cc9d0e9ac5ef1fe358 bfdedc92658349ecb7ed6a12b6e737e7 1e451f4e1ff246cc9d0e9ac5ef1fe358--bfdedc92658349ecb7ed6a12b6e737e7 d03d15a50dd04891b8f8e91a4ba8be5d bfdedc92658349ecb7ed6a12b6e737e7--d03d15a50dd04891b8f8e91a4ba8be5d 7430aed30eb544e4b1470026d4816b66 d03d15a50dd04891b8f8e91a4ba8be5d--7430aed30eb544e4b1470026d4816b66 8861edd78db14aea853338131af32868 RX(b16) 7430aed30eb544e4b1470026d4816b66--8861edd78db14aea853338131af32868 8861edd78db14aea853338131af32868--5c691db1e3f24c64965a4d748ac3f520 45c3535a0895459cbad9aa2a1fee5552 bc4a7f9852584a65ac9a2771c05836e1 4cdb48a2e54e4f29959af1be7141117c--bc4a7f9852584a65ac9a2771c05836e1 d0cb7084682e435999d135feeaed3102 bc4a7f9852584a65ac9a2771c05836e1--d0cb7084682e435999d135feeaed3102 87656b92ac9d45cba331351d0ada9216 d0cb7084682e435999d135feeaed3102--87656b92ac9d45cba331351d0ada9216 6998b4994d104acc83115f9e22534d32 87656b92ac9d45cba331351d0ada9216--6998b4994d104acc83115f9e22534d32 01f78b48145b42068ce32e2c661ebec9 6998b4994d104acc83115f9e22534d32--01f78b48145b42068ce32e2c661ebec9 60ca61a0d6e5485d96e9e480f3a3d23d 01f78b48145b42068ce32e2c661ebec9--60ca61a0d6e5485d96e9e480f3a3d23d b9542d08f0ea4dda9c81f860dab42566 X 60ca61a0d6e5485d96e9e480f3a3d23d--b9542d08f0ea4dda9c81f860dab42566 b9542d08f0ea4dda9c81f860dab42566--c46ddba7f1454a87bfebbde97940a9a5 40651f5f70184187983e6b2537a0d02e RZ(1.0*g0) b9542d08f0ea4dda9c81f860dab42566--40651f5f70184187983e6b2537a0d02e fff2c9da43b34ec081baf95b233778bc X 40651f5f70184187983e6b2537a0d02e--fff2c9da43b34ec081baf95b233778bc fff2c9da43b34ec081baf95b233778bc--a2d7af6084984fdfa9b1812d9420c3b8 cae758411ec14d72b6eaefbab36a4125 fff2c9da43b34ec081baf95b233778bc--cae758411ec14d72b6eaefbab36a4125 e3e40986c5f9415c9d9a0c6672600605 cae758411ec14d72b6eaefbab36a4125--e3e40986c5f9415c9d9a0c6672600605 8f9e71605d154cbd86af9a0f0f27bfc4 e3e40986c5f9415c9d9a0c6672600605--8f9e71605d154cbd86af9a0f0f27bfc4 7a5b154aad0e4812be886a208086c938 8f9e71605d154cbd86af9a0f0f27bfc4--7a5b154aad0e4812be886a208086c938 6baf238c86144bb198117c4b3712f4e6 7a5b154aad0e4812be886a208086c938--6baf238c86144bb198117c4b3712f4e6 6433d80d785f47d9abd6301f8d77f29f 6baf238c86144bb198117c4b3712f4e6--6433d80d785f47d9abd6301f8d77f29f 3d121abe978247f7ac879dee8f702f74 6433d80d785f47d9abd6301f8d77f29f--3d121abe978247f7ac879dee8f702f74 76fc4eb6fe2744e49136a1c0dfbde823 3d121abe978247f7ac879dee8f702f74--76fc4eb6fe2744e49136a1c0dfbde823 1d52c9a937a24e3fade60fd6d4e86b67 76fc4eb6fe2744e49136a1c0dfbde823--1d52c9a937a24e3fade60fd6d4e86b67 55c415e10d194f56ba512e481b32cd33 1d52c9a937a24e3fade60fd6d4e86b67--55c415e10d194f56ba512e481b32cd33 0bdb914935834c38a7c0a56b6bca5364 55c415e10d194f56ba512e481b32cd33--0bdb914935834c38a7c0a56b6bca5364 990fd1723011416b852041460c9c1997 0bdb914935834c38a7c0a56b6bca5364--990fd1723011416b852041460c9c1997 bce37bd0ef8b4bb8ac7aba7ad735a3a9 990fd1723011416b852041460c9c1997--bce37bd0ef8b4bb8ac7aba7ad735a3a9 0327f9050211475a99eed6862da2034a bce37bd0ef8b4bb8ac7aba7ad735a3a9--0327f9050211475a99eed6862da2034a 61e5a4a358eb432a8d6b1529c5c142c9 0327f9050211475a99eed6862da2034a--61e5a4a358eb432a8d6b1529c5c142c9 dde6a2c4e623491aa26e489ed3008141 61e5a4a358eb432a8d6b1529c5c142c9--dde6a2c4e623491aa26e489ed3008141 67a5154207d64cf0a4dc09a445555340 dde6a2c4e623491aa26e489ed3008141--67a5154207d64cf0a4dc09a445555340 196e1a3b74de4c53a5951deb13e63f7e 67a5154207d64cf0a4dc09a445555340--196e1a3b74de4c53a5951deb13e63f7e aba1fef904644bf383d292193cb63ae6 196e1a3b74de4c53a5951deb13e63f7e--aba1fef904644bf383d292193cb63ae6 8b1f130131584e47a7ba9c629862fc1a aba1fef904644bf383d292193cb63ae6--8b1f130131584e47a7ba9c629862fc1a 076210b55f944ac4b62e2bee9dadc684 8b1f130131584e47a7ba9c629862fc1a--076210b55f944ac4b62e2bee9dadc684 294a623a035e4c27b6bf8939b35643af 076210b55f944ac4b62e2bee9dadc684--294a623a035e4c27b6bf8939b35643af 9917c22007ed42cb9349e59542005598 294a623a035e4c27b6bf8939b35643af--9917c22007ed42cb9349e59542005598 6e8ee287ba7b4648a4f64f3d57f7ac73 9917c22007ed42cb9349e59542005598--6e8ee287ba7b4648a4f64f3d57f7ac73 0559c2a4d9df49f3b09b8d589a662abc 6e8ee287ba7b4648a4f64f3d57f7ac73--0559c2a4d9df49f3b09b8d589a662abc 1de141834da54cb99a3235c2cc68ff3c 0559c2a4d9df49f3b09b8d589a662abc--1de141834da54cb99a3235c2cc68ff3c 64be6de695d84476bb87a816c5a07b47 1de141834da54cb99a3235c2cc68ff3c--64be6de695d84476bb87a816c5a07b47 317cb0d65dbf49ae8344f268eb1c7fb2 64be6de695d84476bb87a816c5a07b47--317cb0d65dbf49ae8344f268eb1c7fb2 77bf65964053472689559bbe93368f78 317cb0d65dbf49ae8344f268eb1c7fb2--77bf65964053472689559bbe93368f78 7daf8da0658f460986b40a81269b5e6e 77bf65964053472689559bbe93368f78--7daf8da0658f460986b40a81269b5e6e 8e32bd1a6a1d4be78332e9c4ad0fc670 7daf8da0658f460986b40a81269b5e6e--8e32bd1a6a1d4be78332e9c4ad0fc670 b662e0fa4b0f46a0bef2c0dd84bb2b61 8e32bd1a6a1d4be78332e9c4ad0fc670--b662e0fa4b0f46a0bef2c0dd84bb2b61 fed4d87aa02e4704af6addf9dfd24b54 b662e0fa4b0f46a0bef2c0dd84bb2b61--fed4d87aa02e4704af6addf9dfd24b54 43d03afaeadf4fe3a993b92abbb5b12b fed4d87aa02e4704af6addf9dfd24b54--43d03afaeadf4fe3a993b92abbb5b12b 3d69629dc71f4c3f9d46172764d8f9ee 43d03afaeadf4fe3a993b92abbb5b12b--3d69629dc71f4c3f9d46172764d8f9ee 2e6366d4dc6c48ffb9f447f06151a206 3d69629dc71f4c3f9d46172764d8f9ee--2e6366d4dc6c48ffb9f447f06151a206 5742f89c388f4c2187cfd51681c032e3 2e6366d4dc6c48ffb9f447f06151a206--5742f89c388f4c2187cfd51681c032e3 e51956df48604bc7802b82de20f9dba0 5742f89c388f4c2187cfd51681c032e3--e51956df48604bc7802b82de20f9dba0 b1ffc1cd3b1544f49cf79270bfcd8009 e51956df48604bc7802b82de20f9dba0--b1ffc1cd3b1544f49cf79270bfcd8009 3e388b65a45640d3b8d0e0137e49af32 b1ffc1cd3b1544f49cf79270bfcd8009--3e388b65a45640d3b8d0e0137e49af32 11767443b3384692ab418f005936fec7 3e388b65a45640d3b8d0e0137e49af32--11767443b3384692ab418f005936fec7 9ff57983e1fe4931b15e3825b9dbddb6 11767443b3384692ab418f005936fec7--9ff57983e1fe4931b15e3825b9dbddb6 4eca26305c5247079519600a849d665c 9ff57983e1fe4931b15e3825b9dbddb6--4eca26305c5247079519600a849d665c 3022ef0a61e345709b2774d43b14df0c 4eca26305c5247079519600a849d665c--3022ef0a61e345709b2774d43b14df0c 3ffdec3c5e1f47f68ef21b2222c54b48 3022ef0a61e345709b2774d43b14df0c--3ffdec3c5e1f47f68ef21b2222c54b48 9c372e7a747548818b489d8d0e9ce6ba X 3ffdec3c5e1f47f68ef21b2222c54b48--9c372e7a747548818b489d8d0e9ce6ba 9c372e7a747548818b489d8d0e9ce6ba--e7fbb2a3969849758d405b45787fb8df e975a822cf714133add434bf4f8f1b75 RZ(-1.0*g0) 9c372e7a747548818b489d8d0e9ce6ba--e975a822cf714133add434bf4f8f1b75 531976d1052a404fa5d994334c238285 X e975a822cf714133add434bf4f8f1b75--531976d1052a404fa5d994334c238285 531976d1052a404fa5d994334c238285--1ad939f52d20440192fd144beb0840ad b6f0e3bc7f94424f98865252d324ffda 531976d1052a404fa5d994334c238285--b6f0e3bc7f94424f98865252d324ffda 8c7e9b7e16ec4f509c8c9daf2a1a5722 b6f0e3bc7f94424f98865252d324ffda--8c7e9b7e16ec4f509c8c9daf2a1a5722 195a5a3219654fe7a388e4d994bd256a 8c7e9b7e16ec4f509c8c9daf2a1a5722--195a5a3219654fe7a388e4d994bd256a 4818ed1bae7741349afc0f67f31c34ba 195a5a3219654fe7a388e4d994bd256a--4818ed1bae7741349afc0f67f31c34ba ad66b387f7f247ef886849315bb48f95 4818ed1bae7741349afc0f67f31c34ba--ad66b387f7f247ef886849315bb48f95 a42d9d7d10d6438fb172f6c2fb8f7dca ad66b387f7f247ef886849315bb48f95--a42d9d7d10d6438fb172f6c2fb8f7dca 2bad08b27d0741d3bd1d60d68fcc9b9f a42d9d7d10d6438fb172f6c2fb8f7dca--2bad08b27d0741d3bd1d60d68fcc9b9f 5005548271ae401a8da39ac50f760f5e 2bad08b27d0741d3bd1d60d68fcc9b9f--5005548271ae401a8da39ac50f760f5e b411835f8db84f28ad8c6c6601a33891 5005548271ae401a8da39ac50f760f5e--b411835f8db84f28ad8c6c6601a33891 bb2900062dfa4d4db78517fe3b5e2427 b411835f8db84f28ad8c6c6601a33891--bb2900062dfa4d4db78517fe3b5e2427 378d85329bb2436da127c547d7d7b9c7 bb2900062dfa4d4db78517fe3b5e2427--378d85329bb2436da127c547d7d7b9c7 d6831f2ef07b4aafa160e5bd0bec484c 378d85329bb2436da127c547d7d7b9c7--d6831f2ef07b4aafa160e5bd0bec484c c9511565d0964918a72a4a29339ba596 d6831f2ef07b4aafa160e5bd0bec484c--c9511565d0964918a72a4a29339ba596 374725f75a0444528385bde0002eaa44 c9511565d0964918a72a4a29339ba596--374725f75a0444528385bde0002eaa44 e70e5eea70f04d1e8e2b46fc85699154 374725f75a0444528385bde0002eaa44--e70e5eea70f04d1e8e2b46fc85699154 f6a78836052241ccb1541d8f2754dcf6 e70e5eea70f04d1e8e2b46fc85699154--f6a78836052241ccb1541d8f2754dcf6 24eaf80da0bd433794a25fcdc8ae7cb8 f6a78836052241ccb1541d8f2754dcf6--24eaf80da0bd433794a25fcdc8ae7cb8 b55b11cbb06541648a16b6a46c8990f1 24eaf80da0bd433794a25fcdc8ae7cb8--b55b11cbb06541648a16b6a46c8990f1 6f57990996b641919fbcea389c1fddf2 b55b11cbb06541648a16b6a46c8990f1--6f57990996b641919fbcea389c1fddf2 632a6db422704f77925d5b0c65350946 6f57990996b641919fbcea389c1fddf2--632a6db422704f77925d5b0c65350946 1a8834a5ed4948fdb94626881945511e 632a6db422704f77925d5b0c65350946--1a8834a5ed4948fdb94626881945511e 81aaaec8dd3c4f97b943340bc48c73a0 1a8834a5ed4948fdb94626881945511e--81aaaec8dd3c4f97b943340bc48c73a0 19750624e3f944a6b19ea4266a2e4b7d 81aaaec8dd3c4f97b943340bc48c73a0--19750624e3f944a6b19ea4266a2e4b7d aeda593509d94c47842fea6e8949a5c4 19750624e3f944a6b19ea4266a2e4b7d--aeda593509d94c47842fea6e8949a5c4 3582172d467246abb802ba774bbd729e aeda593509d94c47842fea6e8949a5c4--3582172d467246abb802ba774bbd729e 1934e38bea3845a79cbb6ddd67214892 3582172d467246abb802ba774bbd729e--1934e38bea3845a79cbb6ddd67214892 0a00da2f20ba4c809ae7062848095093 1934e38bea3845a79cbb6ddd67214892--0a00da2f20ba4c809ae7062848095093 8f55ae0658b647a59b064c180dc90307 0a00da2f20ba4c809ae7062848095093--8f55ae0658b647a59b064c180dc90307 f66805aadcef4d9686b6f80065a1559b 8f55ae0658b647a59b064c180dc90307--f66805aadcef4d9686b6f80065a1559b fc046b6331e6493093e8f61b955b6364 f66805aadcef4d9686b6f80065a1559b--fc046b6331e6493093e8f61b955b6364 7966e1a882664c47b11170b368005391 fc046b6331e6493093e8f61b955b6364--7966e1a882664c47b11170b368005391 f8e5ee9eb60244f5909462b5db46b108 7966e1a882664c47b11170b368005391--f8e5ee9eb60244f5909462b5db46b108 212681c20f6f4412853262ae7e5cb637 f8e5ee9eb60244f5909462b5db46b108--212681c20f6f4412853262ae7e5cb637 d31c327575244851ad9a0fc882c82f6f 212681c20f6f4412853262ae7e5cb637--d31c327575244851ad9a0fc882c82f6f 36c63d364688422eb1fe5e2a186dec07 d31c327575244851ad9a0fc882c82f6f--36c63d364688422eb1fe5e2a186dec07 a8f7c30d5ce7436f9767ea050762b238 36c63d364688422eb1fe5e2a186dec07--a8f7c30d5ce7436f9767ea050762b238 f52a2997be0e4964a03cf3ec5e6f506d a8f7c30d5ce7436f9767ea050762b238--f52a2997be0e4964a03cf3ec5e6f506d 379da6db44274f5c8b9078fa0fe481cc f52a2997be0e4964a03cf3ec5e6f506d--379da6db44274f5c8b9078fa0fe481cc 99f6ca392869400882670fbb2358faa3 379da6db44274f5c8b9078fa0fe481cc--99f6ca392869400882670fbb2358faa3 05dc3909028449b68f5b0f42e2619832 99f6ca392869400882670fbb2358faa3--05dc3909028449b68f5b0f42e2619832 c1b29149de7b4733a642cf216c5ae523 05dc3909028449b68f5b0f42e2619832--c1b29149de7b4733a642cf216c5ae523 7e8107a0479b49cb8d072c10afccd812 c1b29149de7b4733a642cf216c5ae523--7e8107a0479b49cb8d072c10afccd812 d635db140c094628800d65867fc55957 7e8107a0479b49cb8d072c10afccd812--d635db140c094628800d65867fc55957 8b9c446cea4041018b80969060b6c2d8 d635db140c094628800d65867fc55957--8b9c446cea4041018b80969060b6c2d8 ac7f816c55884520b5cae9ed34d051e1 8b9c446cea4041018b80969060b6c2d8--ac7f816c55884520b5cae9ed34d051e1 0c4affc796394019b4d0cac915c7d093 ac7f816c55884520b5cae9ed34d051e1--0c4affc796394019b4d0cac915c7d093 4b9f6236fce64faaaa708d2a2924217f 0c4affc796394019b4d0cac915c7d093--4b9f6236fce64faaaa708d2a2924217f d33ad0a517604626afbaeac88e88344b 4b9f6236fce64faaaa708d2a2924217f--d33ad0a517604626afbaeac88e88344b 7924987f3fcd4e6ea15ea75fcd65a870 d33ad0a517604626afbaeac88e88344b--7924987f3fcd4e6ea15ea75fcd65a870 b71d57071021417da38a74ceb9dcecd2 7924987f3fcd4e6ea15ea75fcd65a870--b71d57071021417da38a74ceb9dcecd2 aa02807108a7431f95bf33af00fb2c43 b71d57071021417da38a74ceb9dcecd2--aa02807108a7431f95bf33af00fb2c43 5ec8f28533014b7d93334a71262f13b0 aa02807108a7431f95bf33af00fb2c43--5ec8f28533014b7d93334a71262f13b0 77dcbbe0767c4bf1bb1e7f0053374c30 5ec8f28533014b7d93334a71262f13b0--77dcbbe0767c4bf1bb1e7f0053374c30 afd859c39a42449c95c0f44c92291eda 77dcbbe0767c4bf1bb1e7f0053374c30--afd859c39a42449c95c0f44c92291eda b1371a7989f9484f848422098a5d458d afd859c39a42449c95c0f44c92291eda--b1371a7989f9484f848422098a5d458d 06dabd1a58114a7fbc1c99398e8204ea b1371a7989f9484f848422098a5d458d--06dabd1a58114a7fbc1c99398e8204ea b651f3fea9aa4adaab8d9e1bc8900472 06dabd1a58114a7fbc1c99398e8204ea--b651f3fea9aa4adaab8d9e1bc8900472 56cd0bbb8bfa42348364663a55b7630b b651f3fea9aa4adaab8d9e1bc8900472--56cd0bbb8bfa42348364663a55b7630b 176fb9a3eabc4fc983585499f27d3d13 56cd0bbb8bfa42348364663a55b7630b--176fb9a3eabc4fc983585499f27d3d13 534606d8fd3a472ab642d0e60babb8db 176fb9a3eabc4fc983585499f27d3d13--534606d8fd3a472ab642d0e60babb8db 552653a1009343f0b79e49877a51927b 534606d8fd3a472ab642d0e60babb8db--552653a1009343f0b79e49877a51927b 43f9490220794076825ec7c439e8faab 552653a1009343f0b79e49877a51927b--43f9490220794076825ec7c439e8faab 4da568909b9c49b3a5e130e36c754886 43f9490220794076825ec7c439e8faab--4da568909b9c49b3a5e130e36c754886 8bbd8e793bbf4d748aa7de5740befc64 4da568909b9c49b3a5e130e36c754886--8bbd8e793bbf4d748aa7de5740befc64 57854dc9a50749babae800f0dfcb1c77 8bbd8e793bbf4d748aa7de5740befc64--57854dc9a50749babae800f0dfcb1c77 9c20fab579254e9d9f9b6cdec2bf0967 X 57854dc9a50749babae800f0dfcb1c77--9c20fab579254e9d9f9b6cdec2bf0967 9c20fab579254e9d9f9b6cdec2bf0967--3365c0bce07741098a2d2a7dd16131c0 93434e44853c4b6e836d0e8039fb81dc RZ(-1.0*g0) 9c20fab579254e9d9f9b6cdec2bf0967--93434e44853c4b6e836d0e8039fb81dc d29c776173294cbfb510a1f766c95ce1 X 93434e44853c4b6e836d0e8039fb81dc--d29c776173294cbfb510a1f766c95ce1 d29c776173294cbfb510a1f766c95ce1--c7ec30d813c6415cb26aa6c61e1b3bf3 3f22dd46a3ff4123bed63884bf5b2e46 d29c776173294cbfb510a1f766c95ce1--3f22dd46a3ff4123bed63884bf5b2e46 3621efd156ee4a94bf91ca430906c1b4 3f22dd46a3ff4123bed63884bf5b2e46--3621efd156ee4a94bf91ca430906c1b4 2c2d1f0140f74a168f8285be591fdc52 3621efd156ee4a94bf91ca430906c1b4--2c2d1f0140f74a168f8285be591fdc52 ea1437fd5acc4d3885d5be7ac41964f8 X 2c2d1f0140f74a168f8285be591fdc52--ea1437fd5acc4d3885d5be7ac41964f8 ea1437fd5acc4d3885d5be7ac41964f8--cf3312d008274bb8b92890bdb1ab6753 9d467550e6fd48559f94220b5ebd6b48 RZ(-1.0*g0) ea1437fd5acc4d3885d5be7ac41964f8--9d467550e6fd48559f94220b5ebd6b48 bf0d0d2964b946739f70c63379ad1271 X 9d467550e6fd48559f94220b5ebd6b48--bf0d0d2964b946739f70c63379ad1271 bf0d0d2964b946739f70c63379ad1271--27c744042dab4ce48b2bd62fbd6dce7c de0f7c7f73ef44c0abfa4d85317fdd46 RX(b07) bf0d0d2964b946739f70c63379ad1271--de0f7c7f73ef44c0abfa4d85317fdd46 420befe8fa7b4b7fad649c782f36f0e7 de0f7c7f73ef44c0abfa4d85317fdd46--420befe8fa7b4b7fad649c782f36f0e7 3785ebeef5bf46b18e52f75a04eec53d 420befe8fa7b4b7fad649c782f36f0e7--3785ebeef5bf46b18e52f75a04eec53d 6772a6129cd74aedb6e6d2d056671bfb 3785ebeef5bf46b18e52f75a04eec53d--6772a6129cd74aedb6e6d2d056671bfb 4672d08c842b47f0924d4057ff272327 6772a6129cd74aedb6e6d2d056671bfb--4672d08c842b47f0924d4057ff272327 b87ceb4f5930458e9a98f5f28eaaf0d0 4672d08c842b47f0924d4057ff272327--b87ceb4f5930458e9a98f5f28eaaf0d0 9f89e5c2f0544d64bf61e88f06b90962 b87ceb4f5930458e9a98f5f28eaaf0d0--9f89e5c2f0544d64bf61e88f06b90962 e3dff3472e904bc89e50dd94f2516d07 X 9f89e5c2f0544d64bf61e88f06b90962--e3dff3472e904bc89e50dd94f2516d07 e3dff3472e904bc89e50dd94f2516d07--6ea2e505b9644db495e8d4be0eeb0c44 b9db3fd1754a4a569a2123febbb73144 RZ(1.0*g1) e3dff3472e904bc89e50dd94f2516d07--b9db3fd1754a4a569a2123febbb73144 676379d464764aed9e72bf9900bff497 X b9db3fd1754a4a569a2123febbb73144--676379d464764aed9e72bf9900bff497 676379d464764aed9e72bf9900bff497--17224f3c49a343f6b34e102663299edc d94f9d3a7f2d40a08c30ed67def706b5 676379d464764aed9e72bf9900bff497--d94f9d3a7f2d40a08c30ed67def706b5 a0f3cc07cb554aa39bbd62253808c43e d94f9d3a7f2d40a08c30ed67def706b5--a0f3cc07cb554aa39bbd62253808c43e b34c6ccc5cfc464fa2a259ab51b257b4 a0f3cc07cb554aa39bbd62253808c43e--b34c6ccc5cfc464fa2a259ab51b257b4 95b8009306f84e5d916df9e4f13b0be1 b34c6ccc5cfc464fa2a259ab51b257b4--95b8009306f84e5d916df9e4f13b0be1 a59762cf02d2484b82831e3cf8a036d1 95b8009306f84e5d916df9e4f13b0be1--a59762cf02d2484b82831e3cf8a036d1 71d3098f36d5423dbab2cec9e4ba99d0 a59762cf02d2484b82831e3cf8a036d1--71d3098f36d5423dbab2cec9e4ba99d0 9046cc20eaea477da35efa2ed2352e88 71d3098f36d5423dbab2cec9e4ba99d0--9046cc20eaea477da35efa2ed2352e88 0c4f111db92946d791a0f0b4d7b1b4d1 9046cc20eaea477da35efa2ed2352e88--0c4f111db92946d791a0f0b4d7b1b4d1 833f1b2cba67489da4331ce209a922c8 0c4f111db92946d791a0f0b4d7b1b4d1--833f1b2cba67489da4331ce209a922c8 c3c7106288c547b0bc26e59180036547 833f1b2cba67489da4331ce209a922c8--c3c7106288c547b0bc26e59180036547 2ca83691ace44ea5950b8c791a36cee8 c3c7106288c547b0bc26e59180036547--2ca83691ace44ea5950b8c791a36cee8 fa1349d8419044c8b7566914d4fb5c5b 2ca83691ace44ea5950b8c791a36cee8--fa1349d8419044c8b7566914d4fb5c5b c8083f87e0454f25b19ed9ce5fe13c68 fa1349d8419044c8b7566914d4fb5c5b--c8083f87e0454f25b19ed9ce5fe13c68 305ac03e75fe43bb83f7c8a8e04217b9 c8083f87e0454f25b19ed9ce5fe13c68--305ac03e75fe43bb83f7c8a8e04217b9 9d6b0969be91482aa9407c1c3723237d 305ac03e75fe43bb83f7c8a8e04217b9--9d6b0969be91482aa9407c1c3723237d 8eb2ce910a5645a9bc178c8beeb0da46 9d6b0969be91482aa9407c1c3723237d--8eb2ce910a5645a9bc178c8beeb0da46 34c05bfeb318497098a5e75fce38f69f 8eb2ce910a5645a9bc178c8beeb0da46--34c05bfeb318497098a5e75fce38f69f e111530aea56438387fa5b5b1df004ff 34c05bfeb318497098a5e75fce38f69f--e111530aea56438387fa5b5b1df004ff ad9aa958e0ec4d8c924a75bc536aa883 e111530aea56438387fa5b5b1df004ff--ad9aa958e0ec4d8c924a75bc536aa883 cdade24905bd4c27897553606e4ae7ad ad9aa958e0ec4d8c924a75bc536aa883--cdade24905bd4c27897553606e4ae7ad 493399a1a51545f8a19bfc78c70ce200 cdade24905bd4c27897553606e4ae7ad--493399a1a51545f8a19bfc78c70ce200 3eecfc3d4f7a4613bc832404d28203cf 493399a1a51545f8a19bfc78c70ce200--3eecfc3d4f7a4613bc832404d28203cf 0fe18efbd1974d6a995b5caf2b8add0e 3eecfc3d4f7a4613bc832404d28203cf--0fe18efbd1974d6a995b5caf2b8add0e 7c547ccc20a2418c98a022a472408e14 0fe18efbd1974d6a995b5caf2b8add0e--7c547ccc20a2418c98a022a472408e14 bd8060f98fc14f469160ed05185ea6dd 7c547ccc20a2418c98a022a472408e14--bd8060f98fc14f469160ed05185ea6dd 94feba01d6a246caa18ca5792ff894b2 bd8060f98fc14f469160ed05185ea6dd--94feba01d6a246caa18ca5792ff894b2 bbb59dfa0a09451ca9a6bb7d8eb758a0 94feba01d6a246caa18ca5792ff894b2--bbb59dfa0a09451ca9a6bb7d8eb758a0 c6ce6141b12c4873892ecddf23139405 bbb59dfa0a09451ca9a6bb7d8eb758a0--c6ce6141b12c4873892ecddf23139405 166523bc70ec4133b7d40dba6c5ee81a c6ce6141b12c4873892ecddf23139405--166523bc70ec4133b7d40dba6c5ee81a 701437f832914ea3b2835bf0fa163064 166523bc70ec4133b7d40dba6c5ee81a--701437f832914ea3b2835bf0fa163064 6b342d0366534cc1addfb3566c33d1ca 701437f832914ea3b2835bf0fa163064--6b342d0366534cc1addfb3566c33d1ca 0228d1016f4c47ccbd9beb57f9ce146c 6b342d0366534cc1addfb3566c33d1ca--0228d1016f4c47ccbd9beb57f9ce146c 291a604dcf2e465ab4ba8b8729fe0a61 0228d1016f4c47ccbd9beb57f9ce146c--291a604dcf2e465ab4ba8b8729fe0a61 417c2e2256694676a1595336dd91dbf0 291a604dcf2e465ab4ba8b8729fe0a61--417c2e2256694676a1595336dd91dbf0 f6dd953ce6ff4c16b754211856a71fc8 417c2e2256694676a1595336dd91dbf0--f6dd953ce6ff4c16b754211856a71fc8 077f0dcf3020427784157c962ac69686 f6dd953ce6ff4c16b754211856a71fc8--077f0dcf3020427784157c962ac69686 48c2f50c5882452d8248c868173d9c90 077f0dcf3020427784157c962ac69686--48c2f50c5882452d8248c868173d9c90 38eeca6041d5444eb80fbd46485b18e9 48c2f50c5882452d8248c868173d9c90--38eeca6041d5444eb80fbd46485b18e9 1e5cf77dcfb44babbe7679a4065e0c26 38eeca6041d5444eb80fbd46485b18e9--1e5cf77dcfb44babbe7679a4065e0c26 6f599c8d95584e9baabd70a023cf454f 1e5cf77dcfb44babbe7679a4065e0c26--6f599c8d95584e9baabd70a023cf454f cb726cc17474425995209a2813b2ee91 6f599c8d95584e9baabd70a023cf454f--cb726cc17474425995209a2813b2ee91 81df87dff3bd4bdc83c551e820ec7b7e cb726cc17474425995209a2813b2ee91--81df87dff3bd4bdc83c551e820ec7b7e 4b305d3254f848d4a934c6ae3b8a9426 81df87dff3bd4bdc83c551e820ec7b7e--4b305d3254f848d4a934c6ae3b8a9426 422b3ba8c33a4f56beb663c47bd9aac0 4b305d3254f848d4a934c6ae3b8a9426--422b3ba8c33a4f56beb663c47bd9aac0 18501c7dcd0a4997bd7baf2806e08763 422b3ba8c33a4f56beb663c47bd9aac0--18501c7dcd0a4997bd7baf2806e08763 e64c41a43f1f43efa515d2b37fdea667 X 18501c7dcd0a4997bd7baf2806e08763--e64c41a43f1f43efa515d2b37fdea667 e64c41a43f1f43efa515d2b37fdea667--b3b387e2c81f43159605fb2b65bee098 e2522cc15dfe4583916302f96b632db9 RZ(-1.0*g1) e64c41a43f1f43efa515d2b37fdea667--e2522cc15dfe4583916302f96b632db9 90ffc1f7b9b74954bc6a96177ff6fbc8 X e2522cc15dfe4583916302f96b632db9--90ffc1f7b9b74954bc6a96177ff6fbc8 90ffc1f7b9b74954bc6a96177ff6fbc8--da84a19d943340bba36b6c44eff423f5 b99e8ca9d5784ab58560402d732b44cb 90ffc1f7b9b74954bc6a96177ff6fbc8--b99e8ca9d5784ab58560402d732b44cb 7ee51a6e2796492c8e987a519a164e78 b99e8ca9d5784ab58560402d732b44cb--7ee51a6e2796492c8e987a519a164e78 166c680e194648019712a51cbbdbe2c1 7ee51a6e2796492c8e987a519a164e78--166c680e194648019712a51cbbdbe2c1 b0eee08cbc2d417c86030d3d2940129d 166c680e194648019712a51cbbdbe2c1--b0eee08cbc2d417c86030d3d2940129d 26179b69b4e94499b992e75460ad2531 b0eee08cbc2d417c86030d3d2940129d--26179b69b4e94499b992e75460ad2531 ff6cd7d75df04667a01fcafa06172f0f 26179b69b4e94499b992e75460ad2531--ff6cd7d75df04667a01fcafa06172f0f 1ed494c84c13498c9ddb8312e1364086 ff6cd7d75df04667a01fcafa06172f0f--1ed494c84c13498c9ddb8312e1364086 582b423308d54122b8635b8f71275f59 1ed494c84c13498c9ddb8312e1364086--582b423308d54122b8635b8f71275f59 3945f717370948bc96644c9d84ecfade 582b423308d54122b8635b8f71275f59--3945f717370948bc96644c9d84ecfade 8ef2a1f233984728bd1cb6b54583db29 3945f717370948bc96644c9d84ecfade--8ef2a1f233984728bd1cb6b54583db29 f30e431ec2734853971c47b92c6a87db 8ef2a1f233984728bd1cb6b54583db29--f30e431ec2734853971c47b92c6a87db fcb921ec69aa4b1a988382288f9fdcca f30e431ec2734853971c47b92c6a87db--fcb921ec69aa4b1a988382288f9fdcca 64c75d6cf65240d391b0eedb41a5d725 fcb921ec69aa4b1a988382288f9fdcca--64c75d6cf65240d391b0eedb41a5d725 d75f3dc4ba7145c6bf3bdaa8c032a6eb 64c75d6cf65240d391b0eedb41a5d725--d75f3dc4ba7145c6bf3bdaa8c032a6eb bb2f5f79babd470b8259903558943215 d75f3dc4ba7145c6bf3bdaa8c032a6eb--bb2f5f79babd470b8259903558943215 578dfd5d7a3b4786b5340e7510909897 bb2f5f79babd470b8259903558943215--578dfd5d7a3b4786b5340e7510909897 b5bdff16bb034587a0319f380475c30f 578dfd5d7a3b4786b5340e7510909897--b5bdff16bb034587a0319f380475c30f 1cd049266c434821a4d1df2f60a7131b b5bdff16bb034587a0319f380475c30f--1cd049266c434821a4d1df2f60a7131b 7ae1c1f2596e4aa09535eb47ddf9b3e4 1cd049266c434821a4d1df2f60a7131b--7ae1c1f2596e4aa09535eb47ddf9b3e4 979d6663b31e4ae7ba5276570e441bb5 7ae1c1f2596e4aa09535eb47ddf9b3e4--979d6663b31e4ae7ba5276570e441bb5 6b86e066430f447eb4926a93b40c6ad3 979d6663b31e4ae7ba5276570e441bb5--6b86e066430f447eb4926a93b40c6ad3 a7a3a2109620424eb3bcbbc686d14a7f 6b86e066430f447eb4926a93b40c6ad3--a7a3a2109620424eb3bcbbc686d14a7f 5c0a26223def4fcba5bc76a621d6c214 a7a3a2109620424eb3bcbbc686d14a7f--5c0a26223def4fcba5bc76a621d6c214 e45c7688e9db4359b91b475ef1dc21b9 5c0a26223def4fcba5bc76a621d6c214--e45c7688e9db4359b91b475ef1dc21b9 bb739d751a8547989ddfafa6be804676 e45c7688e9db4359b91b475ef1dc21b9--bb739d751a8547989ddfafa6be804676 5dbd9dd5baf342ea9c4a04b76eef5bc8 bb739d751a8547989ddfafa6be804676--5dbd9dd5baf342ea9c4a04b76eef5bc8 ccdf36b341e34a04a4f4467a24fbecae 5dbd9dd5baf342ea9c4a04b76eef5bc8--ccdf36b341e34a04a4f4467a24fbecae b8550e9928b142aca2a074efec1b5683 ccdf36b341e34a04a4f4467a24fbecae--b8550e9928b142aca2a074efec1b5683 7fd14317210c499fa7ebde34044863c7 b8550e9928b142aca2a074efec1b5683--7fd14317210c499fa7ebde34044863c7 41838eb76f3046d89d29e111fc607a3d 7fd14317210c499fa7ebde34044863c7--41838eb76f3046d89d29e111fc607a3d 79455453477b4c4ba01e49e0e2224b8c 41838eb76f3046d89d29e111fc607a3d--79455453477b4c4ba01e49e0e2224b8c 06243e71ca85455e813aecdcc6c654e4 79455453477b4c4ba01e49e0e2224b8c--06243e71ca85455e813aecdcc6c654e4 110ba30580c245af89d3c8071cbbf47c 06243e71ca85455e813aecdcc6c654e4--110ba30580c245af89d3c8071cbbf47c b6cd6a95e5f24e06b41a20f31a4d19b7 110ba30580c245af89d3c8071cbbf47c--b6cd6a95e5f24e06b41a20f31a4d19b7 da6f5f47ddce4268913faaf44e1161c5 b6cd6a95e5f24e06b41a20f31a4d19b7--da6f5f47ddce4268913faaf44e1161c5 528311e0502149ce92cae29dca652a4d da6f5f47ddce4268913faaf44e1161c5--528311e0502149ce92cae29dca652a4d 8b8ea32344ea4da6bd1e3e7f99f36257 528311e0502149ce92cae29dca652a4d--8b8ea32344ea4da6bd1e3e7f99f36257 7e35fe0884a84d748054f10bd959fc5b 8b8ea32344ea4da6bd1e3e7f99f36257--7e35fe0884a84d748054f10bd959fc5b 6d6fd1aec0c6409aa17f41ac6f574726 7e35fe0884a84d748054f10bd959fc5b--6d6fd1aec0c6409aa17f41ac6f574726 52e4b85d31d1475289288f621891c577 6d6fd1aec0c6409aa17f41ac6f574726--52e4b85d31d1475289288f621891c577 5658b49549a541acafca15cd96769745 52e4b85d31d1475289288f621891c577--5658b49549a541acafca15cd96769745 5bfc3a2d31d44c19b4d35cff50578ec8 5658b49549a541acafca15cd96769745--5bfc3a2d31d44c19b4d35cff50578ec8 dc458f21c06342038cd1fcf161d51111 5bfc3a2d31d44c19b4d35cff50578ec8--dc458f21c06342038cd1fcf161d51111 f23bc4028f924bd4b04e62c9874de1d4 dc458f21c06342038cd1fcf161d51111--f23bc4028f924bd4b04e62c9874de1d4 2713672326254ee097e7e5f9eb885a29 f23bc4028f924bd4b04e62c9874de1d4--2713672326254ee097e7e5f9eb885a29 335da9831f8b48ff8d5a8c850c46055e 2713672326254ee097e7e5f9eb885a29--335da9831f8b48ff8d5a8c850c46055e ace278d084de4bc2b8e87ffa8721bd11 335da9831f8b48ff8d5a8c850c46055e--ace278d084de4bc2b8e87ffa8721bd11 3ee245da476545ff8ae281785a936f12 ace278d084de4bc2b8e87ffa8721bd11--3ee245da476545ff8ae281785a936f12 a8cf105b8cc844e48d8ed82c22e11268 3ee245da476545ff8ae281785a936f12--a8cf105b8cc844e48d8ed82c22e11268 fafbb7c75f5947dabebbaf377c4e5e94 a8cf105b8cc844e48d8ed82c22e11268--fafbb7c75f5947dabebbaf377c4e5e94 c8231bb0ddab4cd7a680a869b8072ecd fafbb7c75f5947dabebbaf377c4e5e94--c8231bb0ddab4cd7a680a869b8072ecd a0af16f0629f4d1996d59e702c225af6 c8231bb0ddab4cd7a680a869b8072ecd--a0af16f0629f4d1996d59e702c225af6 9707ec156bae4b31b135c74640da12ea a0af16f0629f4d1996d59e702c225af6--9707ec156bae4b31b135c74640da12ea b8c7ae8c896e4802a2a0b1f4e5b625e7 9707ec156bae4b31b135c74640da12ea--b8c7ae8c896e4802a2a0b1f4e5b625e7 0e7e4d16040847a99b2600a2c3d641af b8c7ae8c896e4802a2a0b1f4e5b625e7--0e7e4d16040847a99b2600a2c3d641af 5adab41c827240938801c5a88bed245e 0e7e4d16040847a99b2600a2c3d641af--5adab41c827240938801c5a88bed245e 47944e51622d45de9cf97e2eb2f65e1b 5adab41c827240938801c5a88bed245e--47944e51622d45de9cf97e2eb2f65e1b 88d20c4d13994cb69286deb4b0d80910 47944e51622d45de9cf97e2eb2f65e1b--88d20c4d13994cb69286deb4b0d80910 140fdaf6a6414d02bfba78b620848e08 88d20c4d13994cb69286deb4b0d80910--140fdaf6a6414d02bfba78b620848e08 f91a77b67e334fe691e8e153d8908a24 140fdaf6a6414d02bfba78b620848e08--f91a77b67e334fe691e8e153d8908a24 f87858abb39344fca83cbd74940cb150 f91a77b67e334fe691e8e153d8908a24--f87858abb39344fca83cbd74940cb150 bd67888e08444912bef7082a944a20c8 f87858abb39344fca83cbd74940cb150--bd67888e08444912bef7082a944a20c8 377e2884f39343f6a2ab28f46156b66b bd67888e08444912bef7082a944a20c8--377e2884f39343f6a2ab28f46156b66b 5366a96680174689b014b83c26f72c0a 377e2884f39343f6a2ab28f46156b66b--5366a96680174689b014b83c26f72c0a c4a143b60aac43f58db0fae149bbcc9f 5366a96680174689b014b83c26f72c0a--c4a143b60aac43f58db0fae149bbcc9f cfac705e4ed2404a9638989a39f8b4b5 X c4a143b60aac43f58db0fae149bbcc9f--cfac705e4ed2404a9638989a39f8b4b5 cfac705e4ed2404a9638989a39f8b4b5--e46c0f9f15a04644949b1b4f851c6b17 6ce116db2ed44017bef3c373d03e412c RZ(-1.0*g1) cfac705e4ed2404a9638989a39f8b4b5--6ce116db2ed44017bef3c373d03e412c 0e641019cce14ae7850cb21793adf77b X 6ce116db2ed44017bef3c373d03e412c--0e641019cce14ae7850cb21793adf77b 0e641019cce14ae7850cb21793adf77b--410dd6eae6a14dada868cf8e194bf15c b038e42770d049a59553980aa2cf0748 0e641019cce14ae7850cb21793adf77b--b038e42770d049a59553980aa2cf0748 e19f1b8ab97d43ee99bb03eeed9a53b4 b038e42770d049a59553980aa2cf0748--e19f1b8ab97d43ee99bb03eeed9a53b4 2ad992c36f084a98b7c42852f88d9826 e19f1b8ab97d43ee99bb03eeed9a53b4--2ad992c36f084a98b7c42852f88d9826 c8ec4795026b48a3b60e98e7ac4e46fa X 2ad992c36f084a98b7c42852f88d9826--c8ec4795026b48a3b60e98e7ac4e46fa c8ec4795026b48a3b60e98e7ac4e46fa--bfdedc92658349ecb7ed6a12b6e737e7 a55a3e4e99264487bcf9c2d72f1c6661 RZ(-1.0*g1) c8ec4795026b48a3b60e98e7ac4e46fa--a55a3e4e99264487bcf9c2d72f1c6661 8cdc0e028c124cf7b0ff7e789f4fc34f X a55a3e4e99264487bcf9c2d72f1c6661--8cdc0e028c124cf7b0ff7e789f4fc34f 8cdc0e028c124cf7b0ff7e789f4fc34f--7430aed30eb544e4b1470026d4816b66 9339fc6fe55a4d26ba7aba378c0e9264 RX(b17) 8cdc0e028c124cf7b0ff7e789f4fc34f--9339fc6fe55a4d26ba7aba378c0e9264 9339fc6fe55a4d26ba7aba378c0e9264--45c3535a0895459cbad9aa2a1fee5552"},{"location":"qml/qaoa/#train-the-qaoa-circuit-to-solve-maxcut","title":"Train the QAOA circuit to solve MaxCut","text":"<p>Given the QAOA circuit above, one can construct the associated Qadence <code>QuantumModel</code> and train it using standard gradient based optimization.</p> <p>The loss function to be minimized reads:</p> \\[\\mathcal{L} = \\sum_{i,j}^{N_{\\mathcal{E}}} \\frac{1}{2} \\left(1 - \\langle \\psi | \\sigma_i^z \\sigma_j^z | \\psi \\rangle \\right)\\] <p>where \\(\\psi(\\beta, \\gamma)\\) is the wavefunction obtained by propagating the QAQA quantum circuit and the sum runs over the edges of the graph \\(N_{\\mathcal{E}}\\).</p> <pre><code>import torch\nfrom qadence import QuantumModel\ntorch.manual_seed(seed)\ndef loss_function(_model: QuantumModel):\nexpval_ops = _model.expectation().squeeze()\n# this corresponds to the MaxCut cost by definition\n# with negative sign in front to perform maximization\nexpval = 0.0\nfor val in expval_ops:\nexpval += 0.5 * (1 - val)\nreturn -1.0 * expval\n# initialize the parameters to random values\nmodel = QuantumModel(circuit, observable=zz_ops)\nmodel.reset_vparams(torch.rand(model.num_vparams))\ninitial_loss = loss_function(model)\nprint(f\"Initial loss: {initial_loss}\")\n# train the model\nn_epochs = 100\nlr = 1.0\noptimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\nfor i in range(n_epochs):\noptimizer.zero_grad()\nloss = loss_function(model)\nloss.backward()\noptimizer.step()\nif (i+1) % (n_epochs // 10) == 0:\nprint(f\"MaxCut cost at iteration {i+1}: {-loss.item()}\")\n</code></pre> <pre><code>Initial loss: -3.9083080238804184\nMaxCut cost at iteration 10: 9.213496147926481\nMaxCut cost at iteration 20: 10.977326673754586\nMaxCut cost at iteration 30: 10.982568896988312\nMaxCut cost at iteration 40: 10.999062777814745\nMaxCut cost at iteration 50: 10.999637969555074\nMaxCut cost at iteration 60: 10.999841553266368\nMaxCut cost at iteration 70: 10.999928348749943\nMaxCut cost at iteration 80: 10.999967119179326\nMaxCut cost at iteration 90: 10.999984806735625\nMaxCut cost at iteration 100: 10.999992956166363\n</code></pre> <p>Qadence offers some convenience functions to implement this training loop with advanced logging and metrics track features. You can refer to this tutorial for more details.</p>"},{"location":"qml/qaoa/#results","title":"Results","text":"<p>Given the trained quantum model, one needs to sample the resulting quantum state to recover the bitstring with the highest probability which corresponds to the maximum cut of the graph.</p> <pre><code>samples = model.sample(n_shots=100)[0]\nmost_frequent = max(samples, key=samples.get)\nprint(f\"Most frequently sampled bitstring corresponding to the maximum cut: {most_frequent}\")\n# let's now draw the cut obtained with the QAOA procedure\ncolors = []\nlabels = {}\nfor node, b in zip(graph.nodes(), most_frequent):\ncolors.append(\"green\") if int(b) == 0 else colors.append(\"red\")\nlabels[node] = \"A\" if int(b) == 0 else \"B\"\nnx.draw_networkx(graph, node_color=colors, with_labels=True, labels=labels)\n</code></pre>   Most frequently sampled bitstring corresponding to the maximum cut: 11100001  2023-10-25T16:45:19.704081 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"qml/qaoa/#references","title":"References","text":"<ol> <li> <p>Farhi et al. - A Quantum Approximate Optimization Algorithm\u00a0\u21a9</p> </li> </ol>"},{"location":"qml/qcl/","title":"Quantum circuit learning","text":"<p>This tutorial shows how to apply <code>qadence</code> for solving a basic quantum machine learning application: fitting a simple function with the quantum circuit learning<sup>1</sup> (QCL) algorithm.</p> <p>QCL is a supervised quantum machine learning algorithm that uses a parametrized quantum neural network to learn the behavior of an arbitrary mathematical function using a set of function values as training data. This tutorial shows how to fit the \\(\\sin(x)\\) function in the \\([-1, 1]\\) domain.</p> <p>In the following, train and test data are defined.</p> <pre><code>import torch\nfrom torch.utils.data import random_split\n# make sure all tensors are kept on the same device\n# only available from PyTorch 2.0\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.set_default_device(device)\ndef qcl_training_data(\ndomain: tuple = (0, 2*torch.pi), n_points: int = 200\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\nstart, end = domain\nx_rand, _ = torch.sort(torch.DoubleTensor(n_points).uniform_(start, end))\ny_rand = torch.sin(x_rand)\nreturn x_rand, y_rand\nx, y = qcl_training_data()\n# random train/test split of the dataset\ntrain_subset, test_subset = random_split(x, [0.75, 0.25])\ntrain_ind = sorted(train_subset.indices)\ntest_ind = sorted(test_subset.indices)\nx_train, y_train = x[train_ind], y[train_ind]\nx_test, y_test = x[test_ind], y[test_ind]\n</code></pre>"},{"location":"qml/qcl/#train-the-qcl-model","title":"Train the QCL model","text":"<p>Qadence provides the <code>QNN</code> convenience constructor to build a quantum neural network. The <code>QNN</code> class needs a circuit and a list of observables; the number of feature parameters in the input circuit determines the number of input features (i.e. the dimensionality of the classical data given as input) whereas the number of observables determines the number of outputs of the quantum neural network.</p> <p>Total qubit magnetization is used as observable:</p> \\[ \\hat{O} = \\sum_i^N \\hat{\\sigma}_i^z \\] <p>In the following the observable, quantum circuit and corresponding QNN model are constructed.</p> <pre><code>import qadence as qd\nn_qubits = 4\n# create a simple feature map to encode the input data\nfeature_param = qd.FeatureParameter(\"phi\")\nfeature_map = qd.kron(qd.RX(i, feature_param) for i in range(n_qubits))\nfeature_map = qd.tag(feature_map, \"feature_map\")\n# create a digital-analog variational ansatz using Qadence convenience constructors\nansatz = qd.hea(n_qubits, depth=n_qubits)\nansatz = qd.tag(ansatz, \"ansatz\")\n# total qubit magnetization observable\nobservable = qd.hamiltonian_factory(n_qubits, detuning=qd.Z)\ncircuit = qd.QuantumCircuit(n_qubits, feature_map, ansatz)\nmodel = qd.QNN(circuit, [observable])\nexpval = model(values=torch.rand(10))\n</code></pre> <pre><code>tensor([[0.2025],\n[0.1315],\n[0.2424],\n[0.1552],\n[0.1592],\n[0.2063],\n[0.1899],\n[0.2208],\n[0.2472],\n[0.1580]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> <p>The QCL algorithm uses the output of the quantum neural network as a tunable universal function approximator. Standard PyTorch code is used for training the QNN using a mean-square error loss, Adam optimizer. Training is performend on the GPU if available:</p> <pre><code>n_epochs = 100\nlr = 0.25\ninput_values = {\"phi\": x_train}\nmse_loss = torch.nn.MSELoss()  # standard PyTorch loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)  # standard PyTorch Adam optimizer\nprint(f\"Initial loss: {mse_loss(model(values=x_train), y_train)}\")\ny_pred_initial = model(values=x_test)\nfor i in range(n_epochs):\noptimizer.zero_grad()\n# given a `n_batch` number of input points and a `n_observables`\n# number of input observables to measure, the QNN returns\n# an output of the following shape: [n_batch x n_observables]\n# given that there is only one observable, a squeeze is applied to get\n# a 1-dimensional tensor\nloss = mse_loss(model(values=x_train).squeeze(), y_train)\nloss.backward()\noptimizer.step()\nif (i+1) % 20 == 0:\nprint(f\"Epoch {i+1} - Loss: {loss.item()}\")\nassert loss.item() &lt; 1e-3\n</code></pre> <pre><code>Initial loss: 0.6533070454755132\nEpoch 20 - Loss: 0.006756732932883128\nEpoch 40 - Loss: 0.0013178262682414356\nEpoch 60 - Loss: 0.00024411275385789364\nEpoch 80 - Loss: 1.810927009147257e-05\nEpoch 100 - Loss: 3.344354751233859e-06\n</code></pre> <p>Qadence offers some convenience functions to implement this training loop with advanced logging and metrics track features. You can refer to this tutorial for more details.</p> <p>The quantum model is now trained on the training data points. To determine the quality of the results, one can check to see how well it fits the function on the test set.</p> <pre><code>import matplotlib.pyplot as plt\ny_pred = model({\"phi\": x_test})\n# convert all the results to numpy arrays for plotting\nx_train_np = x_train.cpu().detach().numpy().flatten()\ny_train_np = y_train.cpu().detach().numpy().flatten()\nx_test_np = x_test.cpu().detach().numpy().flatten()\ny_test_np = y_test.cpu().detach().numpy().flatten()\ny_pred_initial_np = y_pred_initial.cpu().detach().numpy().flatten()\ny_pred_np = y_pred.cpu().detach().numpy().flatten()\nfig, _ = plt.subplots()\nplt.scatter(x_test_np, y_test_np, label=\"Test points\", marker=\"o\", color=\"orange\")\nplt.plot(x_test_np, y_pred_initial_np, label=\"Initial prediction\", color=\"green\", alpha=0.5)\nplt.plot(x_test_np, y_pred_np, label=\"Final prediction\")\nplt.legend()\n</code></pre> 2023-10-25T16:45:28.002401 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"qml/qcl/#references","title":"References","text":"<ol> <li> <p>Mitarai et al., Quantum Circuit Learning \u21a9</p> </li> </ol>"},{"location":"qml/qml_constructors/","title":"Quantum machine learning constructors","text":"<p>Besides the arbitrary Hamiltonian constructors, Qadence also provides a complete set of program constructors useful for digital-analog quantum machine learning programs.</p>"},{"location":"qml/qml_constructors/#feature-maps","title":"Feature maps","text":"<p>The <code>feature_map</code> function can easily create several types of data-encoding blocks. The two main types of feature maps use a Fourier basis or a Chebyshev basis.</p> <pre><code>from qadence import feature_map, BasisSet, chain\nfrom qadence.draw import display\nn_qubits = 3\nfourier_fm = feature_map(n_qubits, fm_type=BasisSet.FOURIER)\nchebyshev_fm = feature_map(n_qubits, fm_type=BasisSet.CHEBYSHEV)\nblock = chain(fourier_fm, chebyshev_fm)\n</code></pre> %3 cluster_aec5c12b3799470abd16ce0b1c3dd534 Constant Chebyshev FM cluster_8de9e7d910ef4474bab5d5c62834f11b Constant Fourier FM b9b3bc67bf324a969c0bfb9115d14e59 0 f1a687be553245769a7a706bc91acfaf RX(phi) b9b3bc67bf324a969c0bfb9115d14e59--f1a687be553245769a7a706bc91acfaf 71e243c4299c4633a4850928804dc0d2 1 eb2a47b4acc84b97bd753933d8e0aa46 RX(acos(phi)) f1a687be553245769a7a706bc91acfaf--eb2a47b4acc84b97bd753933d8e0aa46 90f74b6062c248e88a3b6ea4e4817389 eb2a47b4acc84b97bd753933d8e0aa46--90f74b6062c248e88a3b6ea4e4817389 b16675d3cf4340ef8051fdafbda78809 98f5f6e904554d37842a1747a80a004c RX(phi) 71e243c4299c4633a4850928804dc0d2--98f5f6e904554d37842a1747a80a004c 584b6153a58d4788bee2fd288029d32d 2 b64234a70a844286bb3fc7f9978d828c RX(acos(phi)) 98f5f6e904554d37842a1747a80a004c--b64234a70a844286bb3fc7f9978d828c b64234a70a844286bb3fc7f9978d828c--b16675d3cf4340ef8051fdafbda78809 1731bdec6f914096aa8964f0e0b29a8b 8a6fef03f12649c0bc37b16df59a9cb0 RX(phi) 584b6153a58d4788bee2fd288029d32d--8a6fef03f12649c0bc37b16df59a9cb0 90bf0b1294394679aa520692e72f9616 RX(acos(phi)) 8a6fef03f12649c0bc37b16df59a9cb0--90bf0b1294394679aa520692e72f9616 90bf0b1294394679aa520692e72f9616--1731bdec6f914096aa8964f0e0b29a8b <p>A custom encoding function can also be passed with <code>sympy</code></p> <pre><code>from sympy import asin, Function\nn_qubits = 3\n# Using a pre-defined sympy Function\ncustom_fm_0 = feature_map(n_qubits, fm_type=asin)\n# Creating a custom sub-class of Function\nclass custom_func(Function):\n@classmethod\ndef eval(cls, x):\nreturn asin(x) + x**2\ncustom_fm_1 = feature_map(n_qubits, fm_type=custom_func)\nblock = chain(custom_fm_0, custom_fm_1)\n</code></pre> %3 cluster_15c02a53d02648f7a391e43598f3b2d8 Constant custom_func FM cluster_9eef0852ad4f4ef29be41c460d0534f2 Constant asin FM 4edf81e552e3474789c5cc0b751ab167 0 e02844bf783e44f3b8d17f0aa23ad9f0 RX(asin(phi)) 4edf81e552e3474789c5cc0b751ab167--e02844bf783e44f3b8d17f0aa23ad9f0 1ead6ded447b423eaa160c47aa47d4d0 1 ba7eea60f81c48c995e0189a2f76c242 RX(phi**2 + asin(phi)) e02844bf783e44f3b8d17f0aa23ad9f0--ba7eea60f81c48c995e0189a2f76c242 44905099ea7e49959820084923e3bf16 ba7eea60f81c48c995e0189a2f76c242--44905099ea7e49959820084923e3bf16 ce267ce4483d4c41bc602edea0276661 4fb1dd6d540642079403f4ba1074a0a9 RX(asin(phi)) 1ead6ded447b423eaa160c47aa47d4d0--4fb1dd6d540642079403f4ba1074a0a9 01156d97bca04974b1678d8314bba390 2 453bca5351614cc08d333937ee707485 RX(phi**2 + asin(phi)) 4fb1dd6d540642079403f4ba1074a0a9--453bca5351614cc08d333937ee707485 453bca5351614cc08d333937ee707485--ce267ce4483d4c41bc602edea0276661 73eafa907b394c569ef1edab11a1b9f0 e06e74e1a2614034bc6d8bee508c82a9 RX(asin(phi)) 01156d97bca04974b1678d8314bba390--e06e74e1a2614034bc6d8bee508c82a9 ba9ce08aa221413cbf55c9d9984e3c87 RX(phi**2 + asin(phi)) e06e74e1a2614034bc6d8bee508c82a9--ba9ce08aa221413cbf55c9d9984e3c87 ba9ce08aa221413cbf55c9d9984e3c87--73eafa907b394c569ef1edab11a1b9f0 <p>Furthermore, the <code>reupload_scaling</code> argument can be used to change the scaling applied to each qubit in the support of the feature map. The default scalings can be chosen from the <code>ReuploadScaling</code> enumeration.</p> <pre><code>from qadence import ReuploadScaling\nfrom qadence.draw import display\nn_qubits = 5\n# Default constant value\nfm_constant = feature_map(n_qubits, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.CONSTANT)\n# Linearly increasing scaling\nfm_tower = feature_map(n_qubits, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.TOWER)\n# Exponentially increasing scaling\nfm_exp = feature_map(n_qubits, fm_type=BasisSet.FOURIER, reupload_scaling=ReuploadScaling.EXP)\nblock = chain(fm_constant, fm_tower, fm_exp)\n</code></pre> %3 cluster_e29099181a6f46d886c23cda4f6edc05 Exponential Fourier FM cluster_21ada88a093c4a0f8e3bc62f0a2a410f Constant Fourier FM cluster_cf720a8429474e2293314b3344798127 Tower Fourier FM 6975a865d65649648b3683d03d674c36 0 a0e0c2d33ef2410ab696480c6586b00e RX(phi) 6975a865d65649648b3683d03d674c36--a0e0c2d33ef2410ab696480c6586b00e 3f56081350df42858f33a27ed13df635 1 5537387ea20b4b428651ca7c82ac795c RX(1.0*phi) a0e0c2d33ef2410ab696480c6586b00e--5537387ea20b4b428651ca7c82ac795c ce314d0a9d55414887fc8776935b69fc RX(1.0*phi) 5537387ea20b4b428651ca7c82ac795c--ce314d0a9d55414887fc8776935b69fc 95185f7d6f4f4ef889410c4809b807ee ce314d0a9d55414887fc8776935b69fc--95185f7d6f4f4ef889410c4809b807ee 1b7530a816644bef825140bccab974a1 008e1964c6b74dce82c8ee2d39f282e6 RX(phi) 3f56081350df42858f33a27ed13df635--008e1964c6b74dce82c8ee2d39f282e6 37abdac71e7d4be4971d7ec99ccea013 2 d42ec10af87e4d8d9b15d1f1bf4e96d3 RX(2.0*phi) 008e1964c6b74dce82c8ee2d39f282e6--d42ec10af87e4d8d9b15d1f1bf4e96d3 6c0cd10011a8408cb4b894efbc4c26db RX(2.0*phi) d42ec10af87e4d8d9b15d1f1bf4e96d3--6c0cd10011a8408cb4b894efbc4c26db 6c0cd10011a8408cb4b894efbc4c26db--1b7530a816644bef825140bccab974a1 ebdab465215c48228352e9133b7b87b4 32cfe668faff45a7b181b37d8296eaea RX(phi) 37abdac71e7d4be4971d7ec99ccea013--32cfe668faff45a7b181b37d8296eaea 291029ead8f743e1a87fee8a8fc3322a 3 7cd0dfccf2204dd09a4186f2ae3e0158 RX(3.0*phi) 32cfe668faff45a7b181b37d8296eaea--7cd0dfccf2204dd09a4186f2ae3e0158 1e4014a754604f38844398f77dd7ffde RX(4.0*phi) 7cd0dfccf2204dd09a4186f2ae3e0158--1e4014a754604f38844398f77dd7ffde 1e4014a754604f38844398f77dd7ffde--ebdab465215c48228352e9133b7b87b4 673f58966da94452901b4aa7931c86bc 35b1aedd586f4b85bff3f13293b801aa RX(phi) 291029ead8f743e1a87fee8a8fc3322a--35b1aedd586f4b85bff3f13293b801aa a0c799bf82584b979c884ed6497b0e90 4 3a91709092ac4ab1a407b01fd7646efa RX(4.0*phi) 35b1aedd586f4b85bff3f13293b801aa--3a91709092ac4ab1a407b01fd7646efa 78b9063f5977456d8aa35298b80d6757 RX(8.0*phi) 3a91709092ac4ab1a407b01fd7646efa--78b9063f5977456d8aa35298b80d6757 78b9063f5977456d8aa35298b80d6757--673f58966da94452901b4aa7931c86bc 95a46aa97a874004acc726d911348c86 656e9e784d3a40dc860483a022eed30e RX(phi) a0c799bf82584b979c884ed6497b0e90--656e9e784d3a40dc860483a022eed30e 11647f89de884124be361c782705dea4 RX(5.0*phi) 656e9e784d3a40dc860483a022eed30e--11647f89de884124be361c782705dea4 f464cb3515b344dfb46cb00c2215ac77 RX(16.0*phi) 11647f89de884124be361c782705dea4--f464cb3515b344dfb46cb00c2215ac77 f464cb3515b344dfb46cb00c2215ac77--95a46aa97a874004acc726d911348c86 <p>A custom scaling can also be defined with a function with an <code>int</code> input and <code>int</code> or <code>float</code> output.</p> <pre><code>n_qubits = 5\ndef custom_scaling(i: int) -&gt; int | float:\n\"\"\"Sqrt(i+1)\"\"\"\nreturn (i+1) ** (0.5)\n# Custom scaling function\nfm_custom = feature_map(n_qubits, fm_type=BasisSet.CHEBYSHEV, reupload_scaling=custom_scaling)\n</code></pre> %3 a3783f9424444331a2c24131f9edf4c7 0 653c530fb8cd4f3d80fe0755ca0a6ddd RX(1.0*acos(phi)) a3783f9424444331a2c24131f9edf4c7--653c530fb8cd4f3d80fe0755ca0a6ddd 2f6d75a89daf4fb1aaeef0ddf4a53d79 1 49b5a61801bf46bcabeea4868742c2c8 653c530fb8cd4f3d80fe0755ca0a6ddd--49b5a61801bf46bcabeea4868742c2c8 3537ed643b86411aa3ffb6ddfb52d3f0 657345fd96fd4e4fbbe04e75fa629d08 RX(1.414*acos(phi)) 2f6d75a89daf4fb1aaeef0ddf4a53d79--657345fd96fd4e4fbbe04e75fa629d08 4e2e67feb1e74171a953adc10649ca0e 2 657345fd96fd4e4fbbe04e75fa629d08--3537ed643b86411aa3ffb6ddfb52d3f0 a8d5a529e8f44550b36b1935daeebb19 556f0d2c2fa343ff87d0bfaf9e5b3a2a RX(1.732*acos(phi)) 4e2e67feb1e74171a953adc10649ca0e--556f0d2c2fa343ff87d0bfaf9e5b3a2a cfaf67f3eb6647d2bf4bd98049216920 3 556f0d2c2fa343ff87d0bfaf9e5b3a2a--a8d5a529e8f44550b36b1935daeebb19 24140e16613f43c5bdf17d407ee47d42 26f24a68a38149c69e29b510b768adcf RX(2.0*acos(phi)) cfaf67f3eb6647d2bf4bd98049216920--26f24a68a38149c69e29b510b768adcf 72792c06ae5f4b5086254715afb1f4e0 4 26f24a68a38149c69e29b510b768adcf--24140e16613f43c5bdf17d407ee47d42 02a120d5d4764b03b7fd09b69065a0d5 43c6031572c6420ba2a1f69446b27e3b RX(2.236*acos(phi)) 72792c06ae5f4b5086254715afb1f4e0--43c6031572c6420ba2a1f69446b27e3b 43c6031572c6420ba2a1f69446b27e3b--02a120d5d4764b03b7fd09b69065a0d5 <p>A full description of the remaining arguments can be found in the <code>feature_map</code> API reference. We provide an example below.</p> <pre><code>from qadence import RY\nn_qubits = 5\n# Custom scaling function\nfm_full = feature_map(\nn_qubits = n_qubits,\nsupport = tuple(reversed(range(n_qubits))), # Reverse the qubit support to run the scaling from bottom to top\nparam = \"x\", # Change the name of the parameter\nop = RY, # Change the rotation gate between RX, RY, RZ or PHASE\nfm_type = BasisSet.CHEBYSHEV,\nreupload_scaling = ReuploadScaling.EXP,\nfeature_range = (-1.0, 2.0), # Range from which the input data comes from\ntarget_range = (1.0, 3.0), # Range the encoder assumes as the natural range\nmultiplier = 5.0 # Extra multiplier, which can also be a Parameter\n)\n</code></pre> %3 717e11c3d3234312894ed7a38f48ad2d 0 4f686a0b49e346c49c04636c8b44c6a6 RY(80.0*acos(0.667*x + 1.667)) 717e11c3d3234312894ed7a38f48ad2d--4f686a0b49e346c49c04636c8b44c6a6 b9d67656e89c4bada2e2fc6774aeaa25 1 9da75a535d19432387c90a9f2601f741 4f686a0b49e346c49c04636c8b44c6a6--9da75a535d19432387c90a9f2601f741 9989724e823a4b6f9f1a8d4c6da7a042 f8f88ca0a66a4962acae2fa53b4aa833 RY(40.0*acos(0.667*x + 1.667)) b9d67656e89c4bada2e2fc6774aeaa25--f8f88ca0a66a4962acae2fa53b4aa833 ee88407e95f74eaf94a89d6f3490ceed 2 f8f88ca0a66a4962acae2fa53b4aa833--9989724e823a4b6f9f1a8d4c6da7a042 04850a653a2249668faac8cd4f47c2be ea8884ee8a464048807c86b2326d21d2 RY(20.0*acos(0.667*x + 1.667)) ee88407e95f74eaf94a89d6f3490ceed--ea8884ee8a464048807c86b2326d21d2 4b822cf1381d47539e073f77e95fb129 3 ea8884ee8a464048807c86b2326d21d2--04850a653a2249668faac8cd4f47c2be c30bd9c4a6684530b8dd65d3fe4fce6f af447607c49e4ca2bae94fe4984932bf RY(10.0*acos(0.667*x + 1.667)) 4b822cf1381d47539e073f77e95fb129--af447607c49e4ca2bae94fe4984932bf 51d9f05a4d554781967e8c41c132641e 4 af447607c49e4ca2bae94fe4984932bf--c30bd9c4a6684530b8dd65d3fe4fce6f 0529cfedb3364420b916e6539d0af6ad 6cef6645b34a4758a2614dc7cb294819 RY(5.0*acos(0.667*x + 1.667)) 51d9f05a4d554781967e8c41c132641e--6cef6645b34a4758a2614dc7cb294819 6cef6645b34a4758a2614dc7cb294819--0529cfedb3364420b916e6539d0af6ad"},{"location":"qml/qml_constructors/#hardware-efficient-ansatz","title":"Hardware-efficient ansatz","text":"<p>Ansatze blocks for quantum machine-learning are typically built following the Hardware-Efficient Ansatz formalism (HEA). Both fully digital and digital-analog HEAs can easily be built with the <code>hea</code> function. By default, the digital version is returned:</p> <pre><code>from qadence import hea\nfrom qadence.draw import display\nn_qubits = 3\ndepth = 2\nansatz = hea(n_qubits, depth)\n</code></pre> %3 f38a32c351444ea2bf35611ed447dd8a 0 f4e000a253ec4fa5a916c073620e01e6 RX(theta\u2080) f38a32c351444ea2bf35611ed447dd8a--f4e000a253ec4fa5a916c073620e01e6 c57bf005a8474b489ef676f0ab9deabb 1 fce6b77f710c4780b565c8f8fab91d1d RY(theta\u2083) f4e000a253ec4fa5a916c073620e01e6--fce6b77f710c4780b565c8f8fab91d1d 2581bdb4e301498aabe624cce01d462e RX(theta\u2086) fce6b77f710c4780b565c8f8fab91d1d--2581bdb4e301498aabe624cce01d462e d5be16e826ee424e82818767de59e34a 2581bdb4e301498aabe624cce01d462e--d5be16e826ee424e82818767de59e34a fd3cf653cc294d96b2d0430d162d734e d5be16e826ee424e82818767de59e34a--fd3cf653cc294d96b2d0430d162d734e 21fd01c9a1844295a229259206dc6259 RX(theta\u2089) fd3cf653cc294d96b2d0430d162d734e--21fd01c9a1844295a229259206dc6259 6cf8943e7f77409b8ef0c86fdb5fc60a RY(theta\u2081\u2082) 21fd01c9a1844295a229259206dc6259--6cf8943e7f77409b8ef0c86fdb5fc60a 0d57b0e01b70447f855b1f76a24966dd RX(theta\u2081\u2085) 6cf8943e7f77409b8ef0c86fdb5fc60a--0d57b0e01b70447f855b1f76a24966dd ee37e4fa4bc24589ba4424585a773bac 0d57b0e01b70447f855b1f76a24966dd--ee37e4fa4bc24589ba4424585a773bac b320be2870ed41b0a92fc36950066189 ee37e4fa4bc24589ba4424585a773bac--b320be2870ed41b0a92fc36950066189 67c272e05b4f4657bd7e98edf43c259d b320be2870ed41b0a92fc36950066189--67c272e05b4f4657bd7e98edf43c259d 5e2a1bb5479843f5917f1a382876b95b fa71c91f7f254c628c00ea4634bd898b RX(theta\u2081) c57bf005a8474b489ef676f0ab9deabb--fa71c91f7f254c628c00ea4634bd898b c6d6fdea289e4f918e8352db234b1227 2 9c6aa0d304fd486e83bec4b87b7bc22c RY(theta\u2084) fa71c91f7f254c628c00ea4634bd898b--9c6aa0d304fd486e83bec4b87b7bc22c 23ad1d1a0f024eef8e840333220bc82f RX(theta\u2087) 9c6aa0d304fd486e83bec4b87b7bc22c--23ad1d1a0f024eef8e840333220bc82f a6d37c9e695f4d9d8bb7da2b056ad6df X 23ad1d1a0f024eef8e840333220bc82f--a6d37c9e695f4d9d8bb7da2b056ad6df a6d37c9e695f4d9d8bb7da2b056ad6df--d5be16e826ee424e82818767de59e34a ae934c7fa69e484f8e6b25008642e375 a6d37c9e695f4d9d8bb7da2b056ad6df--ae934c7fa69e484f8e6b25008642e375 537962aa93e24a5ea3bb0a1267656099 RX(theta\u2081\u2080) ae934c7fa69e484f8e6b25008642e375--537962aa93e24a5ea3bb0a1267656099 8a4dc4dc125f4a7fa31bb36c8eab91ea RY(theta\u2081\u2083) 537962aa93e24a5ea3bb0a1267656099--8a4dc4dc125f4a7fa31bb36c8eab91ea f1a14f1aa16b42b0b6f42fdee08b8679 RX(theta\u2081\u2086) 8a4dc4dc125f4a7fa31bb36c8eab91ea--f1a14f1aa16b42b0b6f42fdee08b8679 bd7d63099040419e9525b228d013e30a X f1a14f1aa16b42b0b6f42fdee08b8679--bd7d63099040419e9525b228d013e30a bd7d63099040419e9525b228d013e30a--ee37e4fa4bc24589ba4424585a773bac 039481558afb44d99543eb7fe58aa6c0 bd7d63099040419e9525b228d013e30a--039481558afb44d99543eb7fe58aa6c0 039481558afb44d99543eb7fe58aa6c0--5e2a1bb5479843f5917f1a382876b95b c8d925fef10d4e47a51d1a56fb615366 620c5bb340dd45b1baaf8aded847a6da RX(theta\u2082) c6d6fdea289e4f918e8352db234b1227--620c5bb340dd45b1baaf8aded847a6da b20fe1d80db34cc68956466a88a96fac RY(theta\u2085) 620c5bb340dd45b1baaf8aded847a6da--b20fe1d80db34cc68956466a88a96fac b0b9930dd1254fc4af70b6eefa5d0082 RX(theta\u2088) b20fe1d80db34cc68956466a88a96fac--b0b9930dd1254fc4af70b6eefa5d0082 df0d9b36d9b84268a58e58d69708f96a b0b9930dd1254fc4af70b6eefa5d0082--df0d9b36d9b84268a58e58d69708f96a 3915810bb54b49efa834e7934f8ec409 X df0d9b36d9b84268a58e58d69708f96a--3915810bb54b49efa834e7934f8ec409 3915810bb54b49efa834e7934f8ec409--ae934c7fa69e484f8e6b25008642e375 dbc4cd5e54aa408e8181c22adf05d311 RX(theta\u2081\u2081) 3915810bb54b49efa834e7934f8ec409--dbc4cd5e54aa408e8181c22adf05d311 ba122da4dc084e63b86fa27971bc495e RY(theta\u2081\u2084) dbc4cd5e54aa408e8181c22adf05d311--ba122da4dc084e63b86fa27971bc495e 1496ab7f3c8b46f5bc5f319683573f7b RX(theta\u2081\u2087) ba122da4dc084e63b86fa27971bc495e--1496ab7f3c8b46f5bc5f319683573f7b 94857ec612ce488b9cc95c7c16bdf1d7 1496ab7f3c8b46f5bc5f319683573f7b--94857ec612ce488b9cc95c7c16bdf1d7 cfff9adb60fe442d88cb81f419b6f45e X 94857ec612ce488b9cc95c7c16bdf1d7--cfff9adb60fe442d88cb81f419b6f45e cfff9adb60fe442d88cb81f419b6f45e--039481558afb44d99543eb7fe58aa6c0 cfff9adb60fe442d88cb81f419b6f45e--c8d925fef10d4e47a51d1a56fb615366 <p>As seen above, the rotation layers are automatically parameterized, and the prefix <code>\"theta\"</code> can be changed with the <code>param_prefix</code> argument.</p> <p>Furthermore, both the single-qubit rotations and the two-qubit entangler can be customized with the <code>operations</code> and <code>entangler</code> argument. The operations can be passed as a list of single-qubit rotations, while the entangler should be either <code>CNOT</code>, <code>CZ</code>, <code>CRX</code>, <code>CRY</code>, <code>CRZ</code> or <code>CPHASE</code>.</p> <pre><code>from qadence import RX, RY, CPHASE\nansatz = hea(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=\"phi\",\noperations=[RX, RY, RX],\nentangler=CPHASE\n)\n</code></pre> %3 09c2495bf0eb484eb2d8de185446dbf1 0 3c903317dffd46dba3697e92622948f8 RX(phi\u2080) 09c2495bf0eb484eb2d8de185446dbf1--3c903317dffd46dba3697e92622948f8 784c0fb8d6fe4817aac8be789aadf666 1 4c3fffbb2e6e46db8bcf89da8875c5a7 RY(phi\u2083) 3c903317dffd46dba3697e92622948f8--4c3fffbb2e6e46db8bcf89da8875c5a7 785c01acaa5846069b237539e06570ae RX(phi\u2086) 4c3fffbb2e6e46db8bcf89da8875c5a7--785c01acaa5846069b237539e06570ae 44f918ee88034ad0bff8922a191beb6e 785c01acaa5846069b237539e06570ae--44f918ee88034ad0bff8922a191beb6e 198d44b6fc194c64bdf5135002d9406e 44f918ee88034ad0bff8922a191beb6e--198d44b6fc194c64bdf5135002d9406e 7dabff5313a041049c018b7b99d975dc RX(phi\u2089) 198d44b6fc194c64bdf5135002d9406e--7dabff5313a041049c018b7b99d975dc 71810893e9cc420baf8925f3da98c6af RY(phi\u2081\u2082) 7dabff5313a041049c018b7b99d975dc--71810893e9cc420baf8925f3da98c6af 2c8da7d9dcff4d81b70f28ac1aed58b2 RX(phi\u2081\u2085) 71810893e9cc420baf8925f3da98c6af--2c8da7d9dcff4d81b70f28ac1aed58b2 aedb1f0aa6814db4bc26dba21ae054b8 2c8da7d9dcff4d81b70f28ac1aed58b2--aedb1f0aa6814db4bc26dba21ae054b8 62d87373b68f4ae09377087d7dbcee81 aedb1f0aa6814db4bc26dba21ae054b8--62d87373b68f4ae09377087d7dbcee81 ed74d87a5dc648ba88876be653fe1d0c 62d87373b68f4ae09377087d7dbcee81--ed74d87a5dc648ba88876be653fe1d0c 6c4a9516964b492aab1da14613ae15c9 3f7d4fa209cc40efb27f09ffd72990d3 RX(phi\u2081) 784c0fb8d6fe4817aac8be789aadf666--3f7d4fa209cc40efb27f09ffd72990d3 adb0ccef0f5641f4a50d65598c9ed622 2 1a1cffb0115e46be9012dd1e34451003 RY(phi\u2084) 3f7d4fa209cc40efb27f09ffd72990d3--1a1cffb0115e46be9012dd1e34451003 daadca9761a746a6816313d80494a14e RX(phi\u2087) 1a1cffb0115e46be9012dd1e34451003--daadca9761a746a6816313d80494a14e 85ccdf4e591f415e8af4ee0225072668 PHASE(phi_ent\u2080) daadca9761a746a6816313d80494a14e--85ccdf4e591f415e8af4ee0225072668 85ccdf4e591f415e8af4ee0225072668--44f918ee88034ad0bff8922a191beb6e 486cb660afb24203b7a887ad4f4c988a 85ccdf4e591f415e8af4ee0225072668--486cb660afb24203b7a887ad4f4c988a 2d1317028f974e4a898be54e5a063fc6 RX(phi\u2081\u2080) 486cb660afb24203b7a887ad4f4c988a--2d1317028f974e4a898be54e5a063fc6 43d2dfca0d004d098a7ea6506ea17fc4 RY(phi\u2081\u2083) 2d1317028f974e4a898be54e5a063fc6--43d2dfca0d004d098a7ea6506ea17fc4 63da273fa5fa47a7a8adaeaba02bbbe1 RX(phi\u2081\u2086) 43d2dfca0d004d098a7ea6506ea17fc4--63da273fa5fa47a7a8adaeaba02bbbe1 e07ef94cae73400ba18ab47d488debe3 PHASE(phi_ent\u2082) 63da273fa5fa47a7a8adaeaba02bbbe1--e07ef94cae73400ba18ab47d488debe3 e07ef94cae73400ba18ab47d488debe3--aedb1f0aa6814db4bc26dba21ae054b8 83e474019f20435ca0cd428556f39583 e07ef94cae73400ba18ab47d488debe3--83e474019f20435ca0cd428556f39583 83e474019f20435ca0cd428556f39583--6c4a9516964b492aab1da14613ae15c9 589aff6a87aa47cabcf3b265faa369ab 425f2a1b31064537aecc2c75883980a0 RX(phi\u2082) adb0ccef0f5641f4a50d65598c9ed622--425f2a1b31064537aecc2c75883980a0 bb8255ddcde840a587df56b8a865b0f3 RY(phi\u2085) 425f2a1b31064537aecc2c75883980a0--bb8255ddcde840a587df56b8a865b0f3 62669053ebbe4c1c88ca4f1bae145554 RX(phi\u2088) bb8255ddcde840a587df56b8a865b0f3--62669053ebbe4c1c88ca4f1bae145554 ac9c00266c0d4d17b51f23aeb6b7c675 62669053ebbe4c1c88ca4f1bae145554--ac9c00266c0d4d17b51f23aeb6b7c675 b21de24d0ed74c0c856c65ad6df1e65d PHASE(phi_ent\u2081) ac9c00266c0d4d17b51f23aeb6b7c675--b21de24d0ed74c0c856c65ad6df1e65d b21de24d0ed74c0c856c65ad6df1e65d--486cb660afb24203b7a887ad4f4c988a 19945e7f2d5d491b942f324680141988 RX(phi\u2081\u2081) b21de24d0ed74c0c856c65ad6df1e65d--19945e7f2d5d491b942f324680141988 294bb1e6eb08429a959b31973bc85a04 RY(phi\u2081\u2084) 19945e7f2d5d491b942f324680141988--294bb1e6eb08429a959b31973bc85a04 c1198d5baa6d4506be0425de2aded73d RX(phi\u2081\u2087) 294bb1e6eb08429a959b31973bc85a04--c1198d5baa6d4506be0425de2aded73d 4d667fbb9dd3419bbc289757e7f993aa c1198d5baa6d4506be0425de2aded73d--4d667fbb9dd3419bbc289757e7f993aa 2fe329bc3bb24e9784369a25f16b3a81 PHASE(phi_ent\u2083) 4d667fbb9dd3419bbc289757e7f993aa--2fe329bc3bb24e9784369a25f16b3a81 2fe329bc3bb24e9784369a25f16b3a81--83e474019f20435ca0cd428556f39583 2fe329bc3bb24e9784369a25f16b3a81--589aff6a87aa47cabcf3b265faa369ab <p>Having a truly hardware-efficient ansatz means that the entangling operation can be chosen according to each device's native interactions. Besides digital operations, in Qadence it is also possible to build digital-analog HEAs with the entanglement produced by the natural evolution of a set of interacting qubits, as natively implemented in neutral atom devices. As with other digital-analog functions, this can be controlled with the <code>strategy</code> argument which can be chosen from the <code>Strategy</code> enum type. Currently, only <code>Strategy.DIGITAL</code> and <code>Strategy.SDAQC</code> are available. By default, calling <code>strategy = Strategy.SDAQC</code> will use a global entangling Hamiltonian with Ising-like \\(NN\\) interactions and constant interaction strength,</p> <pre><code>from qadence import Strategy\nansatz = hea(\nn_qubits,\ndepth=depth,\nstrategy=Strategy.SDAQC\n)\n</code></pre> %3 cluster_f9e663ea98bc4919b35d42502461dd53 cluster_43baff3d5fbf4d708cb83c8c89301aa6 1406789865b549edbedc34b73ec1de46 0 bdf0e4b3bae34bbc805e5a7e0375db21 RX(theta\u2080) 1406789865b549edbedc34b73ec1de46--bdf0e4b3bae34bbc805e5a7e0375db21 befde7d0ae064090aaf96e6055a8c7ed 1 0eb12edb6e2f4df2a3fa1686e5ba6b1e RY(theta\u2083) bdf0e4b3bae34bbc805e5a7e0375db21--0eb12edb6e2f4df2a3fa1686e5ba6b1e d609c624c6e342b8be8c46190de1df3b RX(theta\u2086) 0eb12edb6e2f4df2a3fa1686e5ba6b1e--d609c624c6e342b8be8c46190de1df3b ab76da85b7944444a2b449b22477686c HamEvo d609c624c6e342b8be8c46190de1df3b--ab76da85b7944444a2b449b22477686c f75b82ee91f540b89d137d1c03f4d9ba RX(theta\u2089) ab76da85b7944444a2b449b22477686c--f75b82ee91f540b89d137d1c03f4d9ba 5bdad9d2575b4c1eac3d280964bf218b RY(theta\u2081\u2082) f75b82ee91f540b89d137d1c03f4d9ba--5bdad9d2575b4c1eac3d280964bf218b 1e9f164d062b42e29b0cba1ce6c3ce99 RX(theta\u2081\u2085) 5bdad9d2575b4c1eac3d280964bf218b--1e9f164d062b42e29b0cba1ce6c3ce99 4d60f477d84d41a48926d5e85226e33c HamEvo 1e9f164d062b42e29b0cba1ce6c3ce99--4d60f477d84d41a48926d5e85226e33c b4d60ee8aba04c48bc2370e574a81153 4d60f477d84d41a48926d5e85226e33c--b4d60ee8aba04c48bc2370e574a81153 5635d33e31694795905c84b8df233fc9 a82bf97f4e8d40018b10ddb505ac9356 RX(theta\u2081) befde7d0ae064090aaf96e6055a8c7ed--a82bf97f4e8d40018b10ddb505ac9356 fd885be1ef5545b2b3e6bd2c3c03587c 2 c8ef8cdbec614b968241669c847b7d47 RY(theta\u2084) a82bf97f4e8d40018b10ddb505ac9356--c8ef8cdbec614b968241669c847b7d47 d9966dfe265b402ba4c3e1f4026ddf2c RX(theta\u2087) c8ef8cdbec614b968241669c847b7d47--d9966dfe265b402ba4c3e1f4026ddf2c 4593f64a04c0474b98db677098864f97 t = theta_t\u2080 d9966dfe265b402ba4c3e1f4026ddf2c--4593f64a04c0474b98db677098864f97 b04b648e666d4f38a5846ed015ad8c64 RX(theta\u2081\u2080) 4593f64a04c0474b98db677098864f97--b04b648e666d4f38a5846ed015ad8c64 280039e70b6e4dcdb439e444fd4470eb RY(theta\u2081\u2083) b04b648e666d4f38a5846ed015ad8c64--280039e70b6e4dcdb439e444fd4470eb 9ef908e8aaa14eaa83186e427f18d73c RX(theta\u2081\u2086) 280039e70b6e4dcdb439e444fd4470eb--9ef908e8aaa14eaa83186e427f18d73c 7a95c929a45a435a90954c58b199c162 t = theta_t\u2081 9ef908e8aaa14eaa83186e427f18d73c--7a95c929a45a435a90954c58b199c162 7a95c929a45a435a90954c58b199c162--5635d33e31694795905c84b8df233fc9 45b7804123c84295bf381cec62050fe2 ab02d232877c42b2be4ac4b95cc4eadb RX(theta\u2082) fd885be1ef5545b2b3e6bd2c3c03587c--ab02d232877c42b2be4ac4b95cc4eadb f8cdf7e8e1b641bf8e3666240280383c RY(theta\u2085) ab02d232877c42b2be4ac4b95cc4eadb--f8cdf7e8e1b641bf8e3666240280383c b6531b0a723c4766bb136be8aa50cfdf RX(theta\u2088) f8cdf7e8e1b641bf8e3666240280383c--b6531b0a723c4766bb136be8aa50cfdf 8f49f8ff53aa484d891067a272b162e2 b6531b0a723c4766bb136be8aa50cfdf--8f49f8ff53aa484d891067a272b162e2 fd57047361b94fdaa2c31e16c21495d3 RX(theta\u2081\u2081) 8f49f8ff53aa484d891067a272b162e2--fd57047361b94fdaa2c31e16c21495d3 d46498c828484abc9270bca071617aab RY(theta\u2081\u2084) fd57047361b94fdaa2c31e16c21495d3--d46498c828484abc9270bca071617aab d50e212df4744a33bafe2d19aecac689 RX(theta\u2081\u2087) d46498c828484abc9270bca071617aab--d50e212df4744a33bafe2d19aecac689 0f9ea5cb03f349b0b2b52f041909d1b9 d50e212df4744a33bafe2d19aecac689--0f9ea5cb03f349b0b2b52f041909d1b9 0f9ea5cb03f349b0b2b52f041909d1b9--45b7804123c84295bf381cec62050fe2 <p>Note that, by default, only the time-parameter is automatically parameterized when building a digital-analog HEA. However, as described in the Hamiltonians tutorial, arbitrary interaction Hamiltonians can be easily built with the <code>hamiltonian_factory</code> function, with both customized or fully parameterized interactions, and these can be directly passed as the <code>entangler</code> for a customizable digital-analog HEA.</p> <pre><code>from qadence import hamiltonian_factory, Interaction, N, Register, hea\n# Build a parameterized neutral-atom Hamiltonian following a honeycomb_lattice:\nregister = Register.honeycomb_lattice(1, 1)\nentangler = hamiltonian_factory(\nregister,\ninteraction=Interaction.NN,\ndetuning=N,\ninteraction_strength=\"e\",\ndetuning_strength=\"n\"\n)\n# Build a fully parameterized Digital-Analog HEA:\nn_qubits = register.n_qubits\ndepth = 2\nansatz = hea(\nn_qubits=register.n_qubits,\ndepth=depth,\noperations=[RX, RY, RX],\nentangler=entangler,\nstrategy=Strategy.SDAQC\n)\n</code></pre> %3 cluster_763cb86d5f6e4efcaf5c6fba8e1fe445 cluster_742d5c3b46e449d4a5ff7f4c01c4d85b fb04283798d14876b0faa0b1bf50763a 0 9f9a86906f254b2eb8f1a9ca0df5368f RX(theta\u2080) fb04283798d14876b0faa0b1bf50763a--9f9a86906f254b2eb8f1a9ca0df5368f a6e415f1f1324ee78547b819ec44f51c 1 8abbda71bbf74cfaa3be1dcab378e2c0 RY(theta\u2086) 9f9a86906f254b2eb8f1a9ca0df5368f--8abbda71bbf74cfaa3be1dcab378e2c0 a37a63c0035e45919432102daecd8bcd RX(theta\u2081\u2082) 8abbda71bbf74cfaa3be1dcab378e2c0--a37a63c0035e45919432102daecd8bcd adbc223800d74c8e88c207f5f2cbbb2f a37a63c0035e45919432102daecd8bcd--adbc223800d74c8e88c207f5f2cbbb2f 83a937a773a2450aa87e97223dea14d7 RX(theta\u2081\u2088) adbc223800d74c8e88c207f5f2cbbb2f--83a937a773a2450aa87e97223dea14d7 1c240306844c46e0aa3ff69e0641ffb2 RY(theta\u2082\u2084) 83a937a773a2450aa87e97223dea14d7--1c240306844c46e0aa3ff69e0641ffb2 7bacefe468eb45c6b62ea8bca93b0ffb RX(theta\u2083\u2080) 1c240306844c46e0aa3ff69e0641ffb2--7bacefe468eb45c6b62ea8bca93b0ffb 53262323435e4b32b0bfce9f61b9cb0e 7bacefe468eb45c6b62ea8bca93b0ffb--53262323435e4b32b0bfce9f61b9cb0e ab2e3b1fd653486ca3edd4e1ed4a5a05 53262323435e4b32b0bfce9f61b9cb0e--ab2e3b1fd653486ca3edd4e1ed4a5a05 a4c8234cf90443c9a98dfa50f82293f8 daf81e08a4b9424598ddd5e38ed90d90 RX(theta\u2081) a6e415f1f1324ee78547b819ec44f51c--daf81e08a4b9424598ddd5e38ed90d90 a0ec78eb65324b228bb9ae29d22d3c5e 2 83307a2402de45bb85cd6495529039bb RY(theta\u2087) daf81e08a4b9424598ddd5e38ed90d90--83307a2402de45bb85cd6495529039bb d2d4a8ebd9d24567911bf4d345b2a90e RX(theta\u2081\u2083) 83307a2402de45bb85cd6495529039bb--d2d4a8ebd9d24567911bf4d345b2a90e cec11cdc15fc4418b8a40e875b883642 d2d4a8ebd9d24567911bf4d345b2a90e--cec11cdc15fc4418b8a40e875b883642 fe3ae893f1ec478a9fd2c9e209edfeb5 RX(theta\u2081\u2089) cec11cdc15fc4418b8a40e875b883642--fe3ae893f1ec478a9fd2c9e209edfeb5 293dabe58c9c40dba6846219bad2eff6 RY(theta\u2082\u2085) fe3ae893f1ec478a9fd2c9e209edfeb5--293dabe58c9c40dba6846219bad2eff6 c743419b6cee45a5be6082a2254f2e9a RX(theta\u2083\u2081) 293dabe58c9c40dba6846219bad2eff6--c743419b6cee45a5be6082a2254f2e9a 6306fc4a4ab24e56acebfccbe588348d c743419b6cee45a5be6082a2254f2e9a--6306fc4a4ab24e56acebfccbe588348d 6306fc4a4ab24e56acebfccbe588348d--a4c8234cf90443c9a98dfa50f82293f8 2acbd51ca28c4f3ab4c5adba5aff2bdc 0763e07733c24b729e24b3b6f0632b84 RX(theta\u2082) a0ec78eb65324b228bb9ae29d22d3c5e--0763e07733c24b729e24b3b6f0632b84 a0c11dd3151a4bc3b95a3217fd313075 3 0399514bc43840e490a5c1edd64fa88a RY(theta\u2088) 0763e07733c24b729e24b3b6f0632b84--0399514bc43840e490a5c1edd64fa88a 8a041e47382b4ef4802acc8041b49c9b RX(theta\u2081\u2084) 0399514bc43840e490a5c1edd64fa88a--8a041e47382b4ef4802acc8041b49c9b 2ee24809fde04fc5ae9cfda38e8db980 HamEvo 8a041e47382b4ef4802acc8041b49c9b--2ee24809fde04fc5ae9cfda38e8db980 5f1f54cd005f4029a71d9785fb76befe RX(theta\u2082\u2080) 2ee24809fde04fc5ae9cfda38e8db980--5f1f54cd005f4029a71d9785fb76befe 55c28158a34a46178eb9c3c39109d4b5 RY(theta\u2082\u2086) 5f1f54cd005f4029a71d9785fb76befe--55c28158a34a46178eb9c3c39109d4b5 89bc708823ba4a5fafeb84180bd28c79 RX(theta\u2083\u2082) 55c28158a34a46178eb9c3c39109d4b5--89bc708823ba4a5fafeb84180bd28c79 bcab43e86f394836ae6000fb6cd83eef HamEvo 89bc708823ba4a5fafeb84180bd28c79--bcab43e86f394836ae6000fb6cd83eef bcab43e86f394836ae6000fb6cd83eef--2acbd51ca28c4f3ab4c5adba5aff2bdc daab52117ef244cbb2d0875e9629e71d 79bba395f966425db3a2db5f91067b4f RX(theta\u2083) a0c11dd3151a4bc3b95a3217fd313075--79bba395f966425db3a2db5f91067b4f 06cda9c91137464fbca905dbdd291594 4 89e55785750444a79fb7ead4214fde37 RY(theta\u2089) 79bba395f966425db3a2db5f91067b4f--89e55785750444a79fb7ead4214fde37 ba0cbdc13a4c429fb592f3d7002c0150 RX(theta\u2081\u2085) 89e55785750444a79fb7ead4214fde37--ba0cbdc13a4c429fb592f3d7002c0150 31330a4504064e33b0c77ce09e8c1d3d t = theta_t\u2080 ba0cbdc13a4c429fb592f3d7002c0150--31330a4504064e33b0c77ce09e8c1d3d 4cf262f88b8b4306ad6aac3d5ddb5285 RX(theta\u2082\u2081) 31330a4504064e33b0c77ce09e8c1d3d--4cf262f88b8b4306ad6aac3d5ddb5285 ce6281bdd1d54010b1b5ba8d18193fbe RY(theta\u2082\u2087) 4cf262f88b8b4306ad6aac3d5ddb5285--ce6281bdd1d54010b1b5ba8d18193fbe 35189b3a6ef246f5b216879f5b99bbc7 RX(theta\u2083\u2083) ce6281bdd1d54010b1b5ba8d18193fbe--35189b3a6ef246f5b216879f5b99bbc7 d375075e9df44936822f8f51e815b2bd t = theta_t\u2081 35189b3a6ef246f5b216879f5b99bbc7--d375075e9df44936822f8f51e815b2bd d375075e9df44936822f8f51e815b2bd--daab52117ef244cbb2d0875e9629e71d 7c60ef1813ea41f9bff33559d404ac57 18615b1c20764341be0327aa81fa6b6d RX(theta\u2084) 06cda9c91137464fbca905dbdd291594--18615b1c20764341be0327aa81fa6b6d d206b9d0ee154de18ea69e9442db13d1 5 446bb09425ea4b5a87bab369312c0f0c RY(theta\u2081\u2080) 18615b1c20764341be0327aa81fa6b6d--446bb09425ea4b5a87bab369312c0f0c 5989f71a75914b54b1c098d922ef38f9 RX(theta\u2081\u2086) 446bb09425ea4b5a87bab369312c0f0c--5989f71a75914b54b1c098d922ef38f9 bbf1376c0877403cae1c1399c3991be5 5989f71a75914b54b1c098d922ef38f9--bbf1376c0877403cae1c1399c3991be5 4724630182164d279cdbbd8f36f895d9 RX(theta\u2082\u2082) bbf1376c0877403cae1c1399c3991be5--4724630182164d279cdbbd8f36f895d9 f4f9536832c74196b7add07dff26d130 RY(theta\u2082\u2088) 4724630182164d279cdbbd8f36f895d9--f4f9536832c74196b7add07dff26d130 dd2a74c56f6a4df980526569a2465527 RX(theta\u2083\u2084) f4f9536832c74196b7add07dff26d130--dd2a74c56f6a4df980526569a2465527 d737ed190b824c6eb02204fd5d614652 dd2a74c56f6a4df980526569a2465527--d737ed190b824c6eb02204fd5d614652 d737ed190b824c6eb02204fd5d614652--7c60ef1813ea41f9bff33559d404ac57 f6c4d9f1db314fcc88748b01956a6b58 30d1cace05d34396b4d75b969e4033ff RX(theta\u2085) d206b9d0ee154de18ea69e9442db13d1--30d1cace05d34396b4d75b969e4033ff c09f6a10b4ec4ca986e43f8a73cf4c2d RY(theta\u2081\u2081) 30d1cace05d34396b4d75b969e4033ff--c09f6a10b4ec4ca986e43f8a73cf4c2d 1ffe69e1ce3c450ca2e9b39694cf9b0e RX(theta\u2081\u2087) c09f6a10b4ec4ca986e43f8a73cf4c2d--1ffe69e1ce3c450ca2e9b39694cf9b0e f2655f648263467ca77e2cce625fa390 1ffe69e1ce3c450ca2e9b39694cf9b0e--f2655f648263467ca77e2cce625fa390 e2bade4cc3454c7bb0547b8301b4e06c RX(theta\u2082\u2083) f2655f648263467ca77e2cce625fa390--e2bade4cc3454c7bb0547b8301b4e06c 3f31abd21d72490186b0948d44212058 RY(theta\u2082\u2089) e2bade4cc3454c7bb0547b8301b4e06c--3f31abd21d72490186b0948d44212058 731ad78a1e8b49d98568a775a5244d99 RX(theta\u2083\u2085) 3f31abd21d72490186b0948d44212058--731ad78a1e8b49d98568a775a5244d99 d62c0b1f6d0545019887a2944bbda2ea 731ad78a1e8b49d98568a775a5244d99--d62c0b1f6d0545019887a2944bbda2ea d62c0b1f6d0545019887a2944bbda2ea--f6c4d9f1db314fcc88748b01956a6b58"},{"location":"tutorials/backends/","title":"Backends","text":"<p>Backends allow execution of Qadence abstract quantum circuits. They could be chosen from a variety of simulators, emulators and hardware and can enable circuit differentiability. The primary way to interact and configure a backend is via the high-level API <code>QuantumModel</code>.</p> <p>Not all backends are equivalent</p> <p>Not all backends support the same set of operations, especially while executing analog blocks. Qadence will throw descriptive errors in such cases.</p>"},{"location":"tutorials/backends/#execution-backends","title":"Execution backends","text":"<p>PyQTorch: An efficient, large-scale simulator designed for quantum machine learning, seamlessly integrated with the popular PyTorch deep learning framework for automatic differentiability. It also offers analog computing for time-independent pulses. See <code>PyQTorchBackend</code>.</p> <p>Pulser: A Python library for pulse-level/analog control of neutral atom devices. Execution via QuTiP. See <code>PulserBackend</code>.</p> <p>Braket: A Python SDK for interacting with quantum devices on Amazon Braket. Currently, only the devices with the digital interface of Amazon Braket are supported and execution is performed using the local simulator. Execution on remote simulators and quantum processing units will be available soon. See <code>BraketBackend</code></p> <p>More: Proprietary Qadence extensions provide more high-performance backends based on tensor networks or differentiation engines. For more enquiries, please contact: <code>info@pasqal.com</code>.</p>"},{"location":"tutorials/backends/#differentiation-backend","title":"Differentiation backend","text":"<p>The <code>DifferentiableBackend</code> class enables different differentiation modes for the given backend. This can be chosen from two types:</p> <ul> <li>Automatic differentiation (AD): available for PyTorch based backends (PyQTorch).</li> <li>Parameter Shift Rules (PSR): available for all backends. See this section for more information on differentiability and PSR.</li> </ul> <p>In practice, only a <code>diff_mode</code> should be provided in the <code>QuantumModel</code>. Please note that <code>diff_mode</code> defaults to <code>None</code>:</p> <pre><code>import sympy\nimport torch\nfrom qadence import Parameter, RX, RZ, Z, CNOT, QuantumCircuit, QuantumModel, chain, BackendName, DiffMode\nx = Parameter(\"x\", trainable=False)\ny = Parameter(\"y\", trainable=False)\nfm = chain(\nRX(0, 3 * x),\nRX(0, x),\nRZ(1, sympy.exp(y)),\nRX(0, 3.14),\nRZ(1, \"theta\")\n)\nansatz = CNOT(0, 1)\nblock = chain(fm, ansatz)\ncircuit = QuantumCircuit(2, block)\nobservable = Z(0)\n# DiffMode.GPSR is available for any backend.\n# DiffMode.AD is only available for natively differentiable backends.\nmodel = QuantumModel(circuit, observable, backend=BackendName.PYQTORCH, diff_mode=DiffMode.GPSR)\n# Get some values for the feature parameters.\nvalues = {\"x\": (x := torch.tensor([0.5], requires_grad=True)), \"y\": torch.tensor([0.1])}\n# Compute expectation.\nexp = model.expectation(values)\n# Differentiate the expectation wrt x.\ndexp_dx = torch.autograd.grad(exp, x, torch.ones_like(exp))\n</code></pre> <pre><code>dexp_dx = (tensor([3.6398]),)\n</code></pre>"},{"location":"tutorials/backends/#low-level-backend_factory-interface","title":"Low-level <code>backend_factory</code> interface","text":"<p>Every backend in Qadence inherits from the abstract <code>Backend</code> class: <code>Backend</code> and implement the following methods:</p> <ul> <li><code>run</code>: propagate the initial state according to the quantum circuit and return the final wavefunction object.</li> <li><code>sample</code>: sample from a circuit.</li> <li><code>expectation</code>: computes the expectation of a circuit given an observable.</li> <li><code>convert</code>: convert the abstract <code>QuantumCircuit</code> object to its backend-native representation including a backend specific parameter embedding function.</li> </ul> <p>Backends are purely functional objects which take as input the values for the circuit parameters and return the desired output from a call to a method. In order to use a backend directly, embedded parameters must be supplied as they are returned by the backend specific embedding function.</p> <p>Here is a simple demonstration of the use of the Braket backend to execute a circuit in non-differentiable mode:</p> <pre><code>from qadence import QuantumCircuit, FeatureParameter, RX, RZ, CNOT, hea, chain\n# Construct a feature map.\nx = FeatureParameter(\"x\")\nz = FeatureParameter(\"y\")\nfm = chain(RX(0, 3 * x), RZ(1, z), CNOT(0, 1))\n# Construct a circuit with an hardware-efficient ansatz.\ncircuit = QuantumCircuit(3, fm, hea(3,1))\n</code></pre> <p>The abstract <code>QuantumCircuit</code> can now be converted to its native representation via the Braket backend.</p> <pre><code>from qadence import backend_factory\n# Use only Braket in non-differentiable mode:\nbackend = backend_factory(\"braket\")\n# The `Converted` object\n# (contains a `ConvertedCircuit` with the original and native representation)\nconv = backend.convert(circuit)\n</code></pre> <pre><code>conv.circuit.original = ChainBlock(0,1,2)\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 RX(0) [params: ['3*x']]\n\u2502   \u251c\u2500\u2500 RZ(1) [params: ['y']]\n\u2502   \u2514\u2500\u2500 CNOT(0,1)\n\u2514\u2500\u2500 ChainBlock(0,1,2) [tag: HEA]\n\u251c\u2500\u2500 ChainBlock(0,1,2)\n\u2502   \u251c\u2500\u2500 KronBlock(0,1,2)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u251c\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(2) [params: ['theta_2']]\n\u2502   \u251c\u2500\u2500 KronBlock(0,1,2)\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_3']]\n\u2502   \u2502   \u251c\u2500\u2500 RY(1) [params: ['theta_4']]\n\u2502   \u2502   \u2514\u2500\u2500 RY(2) [params: ['theta_5']]\n\u2502   \u2514\u2500\u2500 KronBlock(0,1,2)\n\u2502       \u251c\u2500\u2500 RX(0) [params: ['theta_6']]\n\u2502       \u251c\u2500\u2500 RX(1) [params: ['theta_7']]\n\u2502       \u2514\u2500\u2500 RX(2) [params: ['theta_8']]\n\u2514\u2500\u2500 ChainBlock(0,1,2)\n\u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2514\u2500\u2500 CNOT(0,1)\n\u2514\u2500\u2500 KronBlock(1,2)\n\u2514\u2500\u2500 CNOT(1,2)\nconv.circuit.native = Circuit('instructions': [Instruction('operator': Rx('angle': 7106b8d0-5f16-42d5-afe8-236c61ac8e45, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rz('angle': eab6c08d-87d4-4d1d-b0a9-28d711719517, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(0), Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 7fd8e082-1e52-4e14-aa57-ae12700bc652, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 98392ede-ad8d-417f-bc6a-fe89ebf9994a, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 505b9684-509a-41b4-a107-d439b8d7dcf0, 'qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Ry('angle': 0ba7283e-cf71-43b7-adb6-48e0f4660fe9, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Ry('angle': 22ba5254-09a4-466f-b04e-3dc4180a1337, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Ry('angle': 98e79e9c-040c-419c-a48c-3e6d96d3cb74, 'qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 0760d5b2-6fdf-4493-a98f-b7707ca7ddef, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 5467abb1-5ec1-4434-9dd3-bd0ba9d9f7cb, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 5daef11d-1bb0-485d-8209-20cfd96d7a98, 'qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(0), Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(1), Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1)])\n</code></pre> <p>Additionally, <code>Converted</code> contains all fixed and variational parameters, as well as an embedding function which accepts feature parameters to construct a dictionary of circuit native parameters. These are needed as each backend uses a different representation of the circuit parameters:</p> <pre><code>import torch\n# Contains fixed parameters and variational (from the HEA)\nconv.params\ninputs = {\"x\": torch.tensor([1., 1.]), \"y\":torch.tensor([2., 2.])}\n# get all circuit parameters (including feature params)\nembedded = conv.embedding_fn(conv.params, inputs)\n</code></pre> <pre><code>conv.params = {\ntheta_5: tensor([0.3965], requires_grad=True)\ntheta_6: tensor([0.7306], requires_grad=True)\ntheta_7: tensor([0.6091], requires_grad=True)\ntheta_8: tensor([0.2952], requires_grad=True)\ntheta_1: tensor([0.2035], requires_grad=True)\ntheta_3: tensor([0.0577], requires_grad=True)\ntheta_4: tensor([0.9744], requires_grad=True)\ntheta_0: tensor([0.8941], requires_grad=True)\ntheta_2: tensor([0.0558], requires_grad=True)\n}\nembedded = {\n7106b8d0-5f16-42d5-afe8-236c61ac8e45: tensor([3., 3.], grad_fn=&lt;ViewBackward0&gt;)\neab6c08d-87d4-4d1d-b0a9-28d711719517: tensor([2., 2.])\n7fd8e082-1e52-4e14-aa57-ae12700bc652: tensor([0.8941], grad_fn=&lt;ViewBackward0&gt;)\n98392ede-ad8d-417f-bc6a-fe89ebf9994a: tensor([0.2035], grad_fn=&lt;ViewBackward0&gt;)\n505b9684-509a-41b4-a107-d439b8d7dcf0: tensor([0.0558], grad_fn=&lt;ViewBackward0&gt;)\n0ba7283e-cf71-43b7-adb6-48e0f4660fe9: tensor([0.0577], grad_fn=&lt;ViewBackward0&gt;)\n22ba5254-09a4-466f-b04e-3dc4180a1337: tensor([0.9744], grad_fn=&lt;ViewBackward0&gt;)\n98e79e9c-040c-419c-a48c-3e6d96d3cb74: tensor([0.3965], grad_fn=&lt;ViewBackward0&gt;)\n0760d5b2-6fdf-4493-a98f-b7707ca7ddef: tensor([0.7306], grad_fn=&lt;ViewBackward0&gt;)\n5467abb1-5ec1-4434-9dd3-bd0ba9d9f7cb: tensor([0.6091], grad_fn=&lt;ViewBackward0&gt;)\n5daef11d-1bb0-485d-8209-20cfd96d7a98: tensor([0.2952], grad_fn=&lt;ViewBackward0&gt;)\n}\n</code></pre> <p>Note that above the parameters keys have changed as they now address the keys on the Braket device. A more readable embedding is provided by the PyQTorch backend:</p> <pre><code>from qadence import BackendName, DiffMode\npyq_backend = backend_factory(backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD)\n# the `Converted` object\n# (contains a `ConvertedCircuit` wiht the original and native representation)\npyq_conv = pyq_backend.convert(circuit)\nembedded = pyq_conv.embedding_fn(pyq_conv.params, inputs)\n</code></pre> <pre><code>embedded = {\ntheta_8: tensor([0.2952], grad_fn=&lt;ViewBackward0&gt;)\ntheta_5: tensor([0.3965], grad_fn=&lt;ViewBackward0&gt;)\ny: tensor([2., 2.])\ntheta_6: tensor([0.7306], grad_fn=&lt;ViewBackward0&gt;)\ntheta_7: tensor([0.6091], grad_fn=&lt;ViewBackward0&gt;)\n3*x: tensor([3., 3.], grad_fn=&lt;ViewBackward0&gt;)\ntheta_1: tensor([0.2035], grad_fn=&lt;ViewBackward0&gt;)\ntheta_3: tensor([0.0577], grad_fn=&lt;ViewBackward0&gt;)\ntheta_4: tensor([0.9744], grad_fn=&lt;ViewBackward0&gt;)\ntheta_0: tensor([0.8941], grad_fn=&lt;ViewBackward0&gt;)\ntheta_2: tensor([0.0558], grad_fn=&lt;ViewBackward0&gt;)\n}\n</code></pre> <p>With the embedded parameters, <code>QuantumModel</code> methods are accessible:</p> <pre><code>embedded = conv.embedding_fn(conv.params, inputs)\nsamples = backend.run(conv.circuit, embedded)\nprint(f\"{samples = }\")\n</code></pre> <pre><code>samples = tensor([[ 0.3854-0.1967j,  0.0458-0.1071j,  0.0059+0.1483j, -0.3360+0.4374j,\n-0.4565-0.3294j, -0.1511+0.0105j,  0.0796+0.0516j,  0.1044+0.3365j],\n[ 0.3854-0.1967j,  0.0458-0.1071j,  0.0059+0.1483j, -0.3360+0.4374j,\n-0.4565-0.3294j, -0.1511+0.0105j,  0.0796+0.0516j,  0.1044+0.3365j]])\n</code></pre>"},{"location":"tutorials/backends/#lower-level-the-backend-representation","title":"Lower-level: the <code>Backend</code> representation","text":"<p>If there is a requirement to work with a specific backend, it is possible to access directly the native circuit. For example, Braket noise features can be imported which are not exposed directly by Qadence.</p> <pre><code>from braket.circuits import Noise\n# Get the native Braket circuit with the given parameters\ninputs = {\"x\": torch.rand(1), \"y\":torch.rand(1)}\nembedded = conv.embedding_fn(conv.params, inputs)\nnative = backend.assign_parameters(conv.circuit, embedded)\n# Define a noise channel\nnoise = Noise.Depolarizing(probability=0.1)\n# Add noise to every gate in the circuit\nnative.apply_gate_noise(noise)\n</code></pre> <p>In order to run this noisy circuit, the density matrix simulator is needed in Braket:</p> <p><pre><code>from braket.devices import LocalSimulator\ndevice = LocalSimulator(\"braket_dm\")\nresult = device.run(native, shots=1000).result().measurement_counts\nprint(result)\n</code></pre> <pre><code>Counter({'100': 184, '000': 183, '011': 182, '111': 136, '010': 85, '110': 80, '101': 77, '001': 73})\n</code></pre> <pre><code>print(conv.circuit.native.diagram())\n</code></pre> <pre><code>T  : |                   0                    |                   1                    |                   2                    |                   3                    |                   4                    |5|6|\nq0 : -Rx(7106b8d0-5f16-42d5-afe8-236c61ac8e45)-C----------------------------------------Rx(7fd8e082-1e52-4e14-aa57-ae12700bc652)-Ry(0ba7283e-cf71-43b7-adb6-48e0f4660fe9)-Rx(0760d5b2-6fdf-4493-a98f-b7707ca7ddef)-C---\n|                                                                                                                                                                   |   q1 : -Rz(eab6c08d-87d4-4d1d-b0a9-28d711719517)-X----------------------------------------Rx(98392ede-ad8d-417f-bc6a-fe89ebf9994a)-Ry(22ba5254-09a4-466f-b04e-3dc4180a1337)-Rx(5467abb1-5ec1-4434-9dd3-bd0ba9d9f7cb)-X-C-\n| q2 : -Rx(505b9684-509a-41b4-a107-d439b8d7dcf0)-Ry(98e79e9c-040c-419c-a48c-3e6d96d3cb74)-Rx(5daef11d-1bb0-485d-8209-20cfd96d7a98)-------------------------------------------------------------------------------------X-\nT  : |                   0                    |                   1                    |                   2                    |                   3                    |                   4                    |5|6|\nUnassigned parameters: [0760d5b2-6fdf-4493-a98f-b7707ca7ddef, 0ba7283e-cf71-43b7-adb6-48e0f4660fe9, 22ba5254-09a4-466f-b04e-3dc4180a1337, 505b9684-509a-41b4-a107-d439b8d7dcf0, 5467abb1-5ec1-4434-9dd3-bd0ba9d9f7cb, 5daef11d-1bb0-485d-8209-20cfd96d7a98, 7106b8d0-5f16-42d5-afe8-236c61ac8e45, 7fd8e082-1e52-4e14-aa57-ae12700bc652, 98392ede-ad8d-417f-bc6a-fe89ebf9994a, 98e79e9c-040c-419c-a48c-3e6d96d3cb74, eab6c08d-87d4-4d1d-b0a9-28d711719517].\n</code></pre> <pre><code>print(native.diagram())\n</code></pre> <pre><code>T  : |        0         |        1         |        2         |        3         |        4         |     5     |     6     |\nq0 : -Rx(2.81)-DEPO(0.1)-C--------DEPO(0.1)-Rx(0.89)-DEPO(0.1)-Ry(0.06)-DEPO(0.1)-Rx(0.73)-DEPO(0.1)-C-DEPO(0.1)-------------\n|                                                                           |                       q1 : -Rz(0.45)-DEPO(0.1)-X--------DEPO(0.1)-Rx(0.20)-DEPO(0.1)-Ry(0.97)-DEPO(0.1)-Rx(0.61)-DEPO(0.1)-X-DEPO(0.1)-C-DEPO(0.1)-\n|           q2 : -Rx(0.06)-DEPO(0.1)-Ry(0.40)-DEPO(0.1)-Rx(0.30)-DEPO(0.1)---------------------------------------------------X-DEPO(0.1)-\nT  : |        0         |        1         |        2         |        3         |        4         |     5     |     6     |\n</code></pre> </p>"},{"location":"tutorials/getting_started/","title":"Getting started","text":"<p>Quantum programs in Qadence are constructed via a block-system, with an emphasis on composability of primitive blocks to obtain larger, composite blocks. This functional approach is different from other frameworks which follow a more object-oriented way to construct circuits and express programs.</p> How to visualize blocks <p>There are two ways to display blocks in a Python interpreter: either as a tree in ASCII format using <code>print</code>:</p> <p><pre><code>from qadence import X, Y, kron\nkron_block = kron(X(0), Y(1))\nprint(kron_block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 Y(1)\n</code></pre> </p> <p>Or using the visualization package:</p> <p><pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\nkron_block = kron(X(0), Y(1))\n# display(kron_block)  # un-comment this line\n</code></pre> %3 73efbcb250c241ec81b6b13aacfd5026 0 49a0d0f61d87483f899e49e518aaa240 X 73efbcb250c241ec81b6b13aacfd5026--49a0d0f61d87483f899e49e518aaa240 ae3fb3ab089c4384abfe0e9f957149d2 1 e93c320de676421681fc3fbef4fafea5 49a0d0f61d87483f899e49e518aaa240--e93c320de676421681fc3fbef4fafea5 242b389da08342998e266583c680b5bf 2a6c48ba942e4b198096f9f930f31edc Y ae3fb3ab089c4384abfe0e9f957149d2--2a6c48ba942e4b198096f9f930f31edc 2a6c48ba942e4b198096f9f930f31edc--242b389da08342998e266583c680b5bf </p>"},{"location":"tutorials/getting_started/#primitive-blocks","title":"Primitive blocks","text":"<p>A <code>PrimitiveBlock</code> represents a digital or an analog time-evolution quantum operation applied to a qubit support. Programs can always be decomposed down into a sequence of <code>PrimitiveBlock</code> elements.</p> <p>Two canonical examples of digital primitive blocks are the parametrized <code>RX</code> and the <code>CNOT</code> gates:</p> <pre><code>from qadence import RX\n# A rotation gate on qubit 0 with a fixed numerical parameter.\nrx_gate = RX(0, 0.5)\n</code></pre> %3 4727bfe993ad48928a8eaeeb2f17f70f 0 b414f58382c943c6a09695d149d81a3b RX(0.5) 4727bfe993ad48928a8eaeeb2f17f70f--b414f58382c943c6a09695d149d81a3b b39e8144b32c4f4ba88ce44a9f71a28e b414f58382c943c6a09695d149d81a3b--b39e8144b32c4f4ba88ce44a9f71a28e <pre><code>from qadence import CNOT\n# A CNOT gate with control on qubit 0 and target on qubit 1.\ncnot_gate = CNOT(0, 1)\n</code></pre> %3 8d53e9769a9e41cf8f1340f7a52e24c1 0 5293f805ce8c478b9780720af6d86c18 8d53e9769a9e41cf8f1340f7a52e24c1--5293f805ce8c478b9780720af6d86c18 245aae1a2b6942da81d1969029794fe9 1 28c14d76a62c4cabad38ce1198f2a8b7 5293f805ce8c478b9780720af6d86c18--28c14d76a62c4cabad38ce1198f2a8b7 041b770c26ff4a07aa51d20d96fae961 cda4fe40246248358aecb3bfa3a57aac X 245aae1a2b6942da81d1969029794fe9--cda4fe40246248358aecb3bfa3a57aac cda4fe40246248358aecb3bfa3a57aac--5293f805ce8c478b9780720af6d86c18 cda4fe40246248358aecb3bfa3a57aac--041b770c26ff4a07aa51d20d96fae961 <p>A list of all instances of primitive blocks (also referred to as operations) can be found here.</p>"},{"location":"tutorials/getting_started/#composite-blocks","title":"Composite Blocks","text":"<p>Programs can be expressed by composing blocks to result in a larger <code>CompositeBlock</code> using three fundamental operations: chain, kron, and add.</p> <ul> <li>chain applies a set of blocks in sequence on the same or overlapping qubit supports and results in a <code>ChainBlock</code> type. It is akin to applying a matrix product of the sub-blocks with the <code>*</code> operator.</li> </ul> <p><pre><code>from qadence import X, chain\n# Chaining on the same qubit using a call to the function.\nchain_x = chain(X(0), X(0))\n</code></pre> %3 1ddf573d9d2f48d8adfa8659bfc7116f 0 cc99e35c174e495c84f49bbea64ddaaa X 1ddf573d9d2f48d8adfa8659bfc7116f--cc99e35c174e495c84f49bbea64ddaaa 2c370563ff9a4ebd915e4ccc35f9c655 X cc99e35c174e495c84f49bbea64ddaaa--2c370563ff9a4ebd915e4ccc35f9c655 0108e6357b694cd9a09a2dd221c9bb62 2c370563ff9a4ebd915e4ccc35f9c655--0108e6357b694cd9a09a2dd221c9bb62 <pre><code># Chaining on different qubits using the operator overload.\n# Identical to the kron operation.\nchain_xx = X(0) * X(1)\n</code></pre> %3 f83767b5b99f4764a55fca34847e7e4c 0 64f8237e4cda4b308566915f7befdb9d X f83767b5b99f4764a55fca34847e7e4c--64f8237e4cda4b308566915f7befdb9d c35636db3e67407fb9e355f50e4f5cdc 1 d6a580738a4c4f3d92c31f2276b8a1d8 64f8237e4cda4b308566915f7befdb9d--d6a580738a4c4f3d92c31f2276b8a1d8 745d189745f14668924a82f9b2e25bb7 d6a580738a4c4f3d92c31f2276b8a1d8--745d189745f14668924a82f9b2e25bb7 d74353ea03c347a784b95b8c5ff49fb1 8a4cf6f024f2417d9396eca53484ff57 c35636db3e67407fb9e355f50e4f5cdc--8a4cf6f024f2417d9396eca53484ff57 9119aae4d95e4030b6e037c59726983f X 8a4cf6f024f2417d9396eca53484ff57--9119aae4d95e4030b6e037c59726983f 9119aae4d95e4030b6e037c59726983f--d74353ea03c347a784b95b8c5ff49fb1 </p> <ul> <li>kron applies a set of blocks in parallel (simultaneously) on disjoint qubit support and results in a <code>KronBlock</code> type. This is akin to applying a tensor product of the sub-blocks with the <code>@</code> operator.</li> </ul> <pre><code>from qadence import X, kron\nkron_xx = kron(X(0), X(1))  # Equivalent to X(0) @ X(1)\n</code></pre> %3 e16bd90eee02433d9f18ce3be1260f47 0 5f96cbcdd44c4fbb9a0cda83ccd6c1fd X e16bd90eee02433d9f18ce3be1260f47--5f96cbcdd44c4fbb9a0cda83ccd6c1fd 4ac2db0c4ae442dda62642312c69a906 1 ebc8fb1f38dc499c961af57516724e04 5f96cbcdd44c4fbb9a0cda83ccd6c1fd--ebc8fb1f38dc499c961af57516724e04 ab97ec8af12e4d29b97df1fffdfd5108 674b16f05ea847b8b47d6faac90cc90a X 4ac2db0c4ae442dda62642312c69a906--674b16f05ea847b8b47d6faac90cc90a 674b16f05ea847b8b47d6faac90cc90a--ab97ec8af12e4d29b97df1fffdfd5108 <p>For the digital case, it should be noted that <code>kron</code> and <code>chain</code> are semantically equivalent up to the diagrammatic representation as <code>chain</code> implicitly fills blank wires with identities. However, Qadence also supports analog blocks, for which composing sequentially or in parallel becomes non-equivalent. More about analog blocks can be found in the digital-analog section.</p> <ul> <li>add sums the corresponding matrix of each sub-block and results in a <code>AddBlock</code> type which can be used to construct Pauli operators. Please note that <code>AddBlock</code> can give rise to non-unitary computations that might not be supported by all backends.</li> </ul> Get the matrix of a block <p>It is always possible to retrieve the matrix representation of a block by calling the <code>block.tensor()</code> method. Please note that the returned tensor contains a batch dimension for the purposes of block parametrization.</p> <p><pre><code>\n</code></pre> <pre><code>X(0) * X(0) tensor = tensor([[[1.+0.j, 0.+0.j],\n[0.+0.j, 1.+0.j]]])\nX(0) @ X(1) tensor = tensor([[[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]]])\n</code></pre> </p> <pre><code>from qadence import X, Z\nxz = X(0) + Z(0)\nprint(xz.tensor())\n</code></pre> <pre><code>tensor([[[ 1.+0.j,  1.+0.j],\n[ 1.+0.j, -1.+0.j]]])\n</code></pre> <p>Finally, it is possible to tag blocks with human-readable names:</p> <pre><code>from qadence import X, Y, CNOT, kron, chain, tag\nxy = kron(X(0), Y(1))\ntag(xy, \"subblock\")\ncomposite_block = kron(xy, CNOT(3,4))\nfinal_block = chain(composite_block, composite_block)\n</code></pre> %3 cluster_c23ef849b8cc4a9a8b2e8807e6c3f508 subblock cluster_660a714a073e4dd0a7ce3240cda20e4a subblock 60a9ecd7fa5446ec93ef7098b6fa5ac8 0 a471c39a49f94ac2848bc899b029a64a X 60a9ecd7fa5446ec93ef7098b6fa5ac8--a471c39a49f94ac2848bc899b029a64a 8335265ca36e4924bb6a2a399c3efda3 1 3ebff76d60c9422889b794914f6c80e3 X a471c39a49f94ac2848bc899b029a64a--3ebff76d60c9422889b794914f6c80e3 e3f2c58345dd4709903062f89c58773a 3ebff76d60c9422889b794914f6c80e3--e3f2c58345dd4709903062f89c58773a b30b7cc7f0654f2385b614185bf221a0 cb471e16a34744eeafa202e3b7159c62 Y 8335265ca36e4924bb6a2a399c3efda3--cb471e16a34744eeafa202e3b7159c62 9e97ab002b1f41cbb88a679f0333dac7 2 974e7fd419854e1093fc460b31d84964 Y cb471e16a34744eeafa202e3b7159c62--974e7fd419854e1093fc460b31d84964 974e7fd419854e1093fc460b31d84964--b30b7cc7f0654f2385b614185bf221a0 2486f22eb31a4710b36a32ccd241bab6 d71e4a6ca80e405ab1ae021ae4e5e8ce 9e97ab002b1f41cbb88a679f0333dac7--d71e4a6ca80e405ab1ae021ae4e5e8ce 81909f7b80be4dc9a243c69cd64b96e5 3 7669bc9b6212493e9811dd233e718b81 d71e4a6ca80e405ab1ae021ae4e5e8ce--7669bc9b6212493e9811dd233e718b81 7669bc9b6212493e9811dd233e718b81--2486f22eb31a4710b36a32ccd241bab6 a911e7fc6a4e48c6aa7a55471ff7b195 7f80cd968be3478abd7ebde162408b35 81909f7b80be4dc9a243c69cd64b96e5--7f80cd968be3478abd7ebde162408b35 afbd9bbffd444793b70d192e5bbbfe96 4 7fbee7bd63ee49ba8845359adb61dc2a 7f80cd968be3478abd7ebde162408b35--7fbee7bd63ee49ba8845359adb61dc2a 7fbee7bd63ee49ba8845359adb61dc2a--a911e7fc6a4e48c6aa7a55471ff7b195 116a5d794a44494eb51ead0342dafaf9 4ecbbf180f114d869f93b5f1e1ec410d X afbd9bbffd444793b70d192e5bbbfe96--4ecbbf180f114d869f93b5f1e1ec410d 4ecbbf180f114d869f93b5f1e1ec410d--7f80cd968be3478abd7ebde162408b35 580d0229e3d44623973164813644ba7b X 4ecbbf180f114d869f93b5f1e1ec410d--580d0229e3d44623973164813644ba7b 580d0229e3d44623973164813644ba7b--7fbee7bd63ee49ba8845359adb61dc2a 580d0229e3d44623973164813644ba7b--116a5d794a44494eb51ead0342dafaf9"},{"location":"tutorials/getting_started/#block-execution","title":"Block execution","text":"<p>To quickly run quantum operations and access wavefunctions, samples or expectation values of observables, one can use the convenience functions <code>run</code>, <code>sample</code> and <code>expectation</code>. The following example shows an execution workflow with the natively available <code>PyQTorch</code> backend:</p> <pre><code>from qadence import chain, add, H, Z, run, sample, expectation\nn_qubits = 2\nblock = chain(H(0), H(1))\n# Compute the wavefunction.\n# Please check the documentation for other available backends.\nwf = run(block)\n# Sample the resulting wavefunction with a given number of shots.\nxs = sample(block, n_shots=1000)\n# Compute an expectation based on an observable of Pauli-Z operators.\nobs = add(Z(i) for i in range(n_qubits))\nex = expectation(block, obs)\n</code></pre> <pre><code>wf = tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\nxs = [Counter({'00': 271, '10': 252, '01': 244, '11': 233})]\nex = tensor([[0.]])\n</code></pre> <p>More fine-grained control and better performance is provided via the high-level <code>QuantumModel</code> abstraction.</p>"},{"location":"tutorials/getting_started/#execution-via-quantumcircuit-and-quantummodel","title":"Execution via <code>QuantumCircuit</code> and <code>QuantumModel</code>","text":"<p>Quantum programs in Qadence are constructed in two steps:</p> <ol> <li>Build a <code>QuantumCircuit</code> which ties together a composite block and a register.</li> <li>Define a <code>QuantumModel</code> which differentiates, compiles and executes the circuit.</li> </ol> <p><code>QuantumCircuit</code> is a central class in Qadence and circuits are abstract objects from the actual hardware/simulator that they are expected to be executed on. They require to specify the <code>Register</code> of resources to execute your program on. Previous examples were already using <code>QuantumCircuit</code> with a <code>Register</code> that fits the qubit support for the given block.</p> <pre><code>from qadence import QuantumCircuit, Register, H, chain\n# NOTE: Run a block which supports two qubits\n# on a register of three qubits.\nregister = Register(3)\ncircuit = QuantumCircuit(register, chain(H(0), H(1)))\n</code></pre> <pre><code>circuit = ChainBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 H(1)\n</code></pre> <p>Registers and qubit supports</p> <p>Registers can also be constructed from qubit coordinates to create arbitrary register topologies. See details in the digital-analog section. Qubit supports are subsets of the circuit register tied to blocks.</p> <p><code>QuantumModel</code> is another central class in Qadence. It specifies a Backend for the differentiation, compilation and execution of the abstract circuit.</p> <pre><code>from qadence import BackendName, DiffMode, QuantumCircuit, QuantumModel, Register, H, chain\nreg = Register(3)\ncirc = QuantumCircuit(reg, chain(H(0), H(1)))\nmodel = QuantumModel(circ, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD)\nxs = model.sample(n_shots=100)\n</code></pre> <pre><code>xs = [Counter({'100': 30, '110': 25, '000': 24, '010': 21})]\n</code></pre> <p>For more details on <code>QuantumModel</code>, see here.</p>"},{"location":"tutorials/hamiltonians/","title":"Constructing arbitrary Hamiltonians","text":"<p>At the heart of digital-analog quantum computing is the description and execution of analog blocks, which represent a set of interacting qubits under some interaction Hamiltonian. For this purpose, Qadence relies on the <code>hamiltonian_factory</code> function to create arbitrary Hamiltonian blocks to be used as generators of <code>HamEvo</code> or as observables to be measured.</p>"},{"location":"tutorials/hamiltonians/#arbitrary-all-to-all-hamiltonians","title":"Arbitrary all-to-all Hamiltonians","text":"<p>Arbitrary all-to-all interaction Hamiltonians can be easily created by passing the number of qubits in the first argument. The type of <code>interaction</code> can be chosen from the available ones in the <code>Interaction</code> enum type.</p> <pre><code>from qadence import hamiltonian_factory\nfrom qadence import N, X, Y, Z\nfrom qadence import Interaction\nn_qubits = 3\nhamilt = hamiltonian_factory(n_qubits, interaction=Interaction.ZZ)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(2)\n\u2514\u2500\u2500 [mul: 1.00000000000000] \u2514\u2500\u2500 KronBlock(1,2)\n\u251c\u2500\u2500 Z(1)\n\u2514\u2500\u2500 Z(2)\n</code></pre> <p>Single-qubit terms can also be added by passing the respective operator directly to the <code>detuning</code> argument. For example, the total magnetization is commonly used as an observable to be measured:</p> <pre><code>total_mag = hamiltonian_factory(n_qubits, detuning = Z)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 Z(0)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 Z(1)\n\u2514\u2500\u2500 [mul: 1.00000000000000] \u2514\u2500\u2500 Z(2)\n</code></pre> <p>For further customization, arbitrary coefficients can be passed as arrays to the <code>interaction_strength</code> and <code>detuning_strength</code> arguments for the two-qubits and single-qubit terms respectively.</p> <pre><code>n_qubits = 3\nhamilt = hamiltonian_factory(\nn_qubits,\ninteraction=Interaction.ZZ,\ndetuning=Z,\ninteraction_strength=[0.5, 0.2, 0.1],\ndetuning_strength=[0.1, 0.5, -0.3]\n)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 0.100] \u2502   \u2514\u2500\u2500 Z(0)\n\u251c\u2500\u2500 [mul: 0.500] \u2502   \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: -0.300] \u2502   \u2514\u2500\u2500 Z(2)\n\u251c\u2500\u2500 [mul: 0.500] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: 0.200] \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(2)\n\u2514\u2500\u2500 [mul: 0.100] \u2514\u2500\u2500 KronBlock(1,2)\n\u251c\u2500\u2500 Z(1)\n\u2514\u2500\u2500 Z(2)\n</code></pre> <p>Ordering interaction strengths matters</p> <p>When passing interaction strengths as an array, the ordering must be identical to the one obtained from the <code>edge</code> property of a Qadence <code>Register</code>:</p> <p><pre><code>from qadence import Register\nprint(Register(n_qubits).edges)\n</code></pre> <pre><code>[(0, 1), (0, 2), (1, 2)]\n</code></pre> </p> <p>For one more example, let's create a transverse-field Ising model,</p> <pre><code>n_qubits = 4\nn_edges = int(0.5 * n_qubits * (n_qubits - 1))\nz_terms = [1.0] * n_qubits\nzz_terms = [2.0] * n_edges\nzz_ham = hamiltonian_factory(\nn_qubits,\ninteraction=Interaction.ZZ,\ndetuning=Z,\ninteraction_strength=zz_terms,\ndetuning_strength=z_terms\n)\nx_terms = [-1.0] * n_qubits\nx_ham = hamiltonian_factory(n_qubits, detuning = X, detuning_strength = x_terms)\ntransverse_ising = zz_ham + x_ham\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 AddBlock(0,1,2,3)\n\u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 Z(0)\n\u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 Z(1)\n\u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 Z(3)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(1)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(3)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502   \u2502       \u251c\u2500\u2500 Z(1)\n\u2502   \u2502       \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(1,3)\n\u2502   \u2502       \u251c\u2500\u2500 Z(1)\n\u2502   \u2502       \u2514\u2500\u2500 Z(3)\n\u2502   \u2514\u2500\u2500 [mul: 2.00000000000000] \u2502       \u2514\u2500\u2500 KronBlock(2,3)\n\u2502           \u251c\u2500\u2500 Z(2)\n\u2502           \u2514\u2500\u2500 Z(3)\n\u2514\u2500\u2500 AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: -1.00000000000000] \u2502   \u2514\u2500\u2500 X(0)\n\u251c\u2500\u2500 [mul: -1.00000000000000] \u2502   \u2514\u2500\u2500 X(1)\n\u251c\u2500\u2500 [mul: -1.00000000000000] \u2502   \u2514\u2500\u2500 X(2)\n\u2514\u2500\u2500 [mul: -1.00000000000000] \u2514\u2500\u2500 X(3)\n</code></pre> <p>Random interaction coefficients</p> <p>Random interaction coefficients can be chosen between -1 and 1 by simply passing <code>random_strength = True</code> instead of <code>detuning_strength</code> and <code>interaction_strength</code>.</p>"},{"location":"tutorials/hamiltonians/#arbitrary-hamiltonian-topologies","title":"Arbitrary Hamiltonian topologies","text":"<p>Arbitrary interaction topologies can be created using the Qadence <code>Register</code>. Simply pass the register with the desired topology as the first argument to the <code>hamiltonian_factory</code>:</p> <pre><code>from qadence import Register\nreg = Register.square(qubits_side=2)\nsquare_hamilt = hamiltonian_factory(reg, interaction=Interaction.NN)\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(3)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: 1.00000000000000] \u2514\u2500\u2500 KronBlock(2,3)\n\u251c\u2500\u2500 N(2)\n\u2514\u2500\u2500 N(3)\n</code></pre> <p>Custom Hamiltonian coefficients can also be added to the register beforehand using the <code>\"strength\"</code> key.</p> <pre><code>reg = Register.square(qubits_side = 2)\nfor i, edge in enumerate(reg.edges):\nreg.edges[edge][\"strength\"] = (0.5 * i) ** 2\nsquare_hamilt = hamiltonian_factory(reg, interaction=Interaction.NN)\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: 0.0] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: 0.250] \u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(3)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: 2.250] \u2514\u2500\u2500 KronBlock(2,3)\n\u251c\u2500\u2500 N(2)\n\u2514\u2500\u2500 N(3)\n</code></pre> <p>Alternatively, if the register already stores interaction or detuning strengths, it is possible to override them in the Hamiltonian creation by using <code>force_update = True</code>.</p>"},{"location":"tutorials/hamiltonians/#adding-variational-parameters","title":"Adding variational parameters","text":"<p>Finally, fully parameterized Hamiltonians can be created by passing a string to the strength arguments:</p> <pre><code>n_qubits = 3\nnn_ham = hamiltonian_factory(\nn_qubits,\ninteraction=Interaction.NN,\ndetuning=N,\ninteraction_strength=\"c\",\ndetuning_strength=\"d\"\n)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: d_0] \u2502   \u2514\u2500\u2500 N(0)\n\u251c\u2500\u2500 [mul: d_1] \u2502   \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: d_2] \u2502   \u2514\u2500\u2500 N(2)\n\u251c\u2500\u2500 [mul: c_01] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: c_02] \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: c_12] \u2514\u2500\u2500 KronBlock(1,2)\n\u251c\u2500\u2500 N(1)\n\u2514\u2500\u2500 N(2)\n</code></pre>"},{"location":"tutorials/overlap/","title":"Wavefunction overlaps","text":"<p>Qadence offers convenience functions for computing the overlap between the wavefunctions generated by two quantum circuits \\(U\\) and \\(W\\) as:</p> \\[ S = |\\langle \\psi_U | \\psi_W \\rangle|^2 \\quad \\textrm{where} \\quad \\psi_U = U|\\psi_0\\rangle \\] <p>Here is an example on how to compute the overlap between two very simple parametric circuits consisting of a single <code>RX</code> rotation on different qubits. The overlap is expected to be non-zero only when the rotation angle is different from \\(\\pi \\; \\textrm{mod}\\; 2\\pi\\) for both rotations:</p> <pre><code>import torch\nimport numpy as np\nfrom qadence import Overlap, OverlapMethod, QuantumCircuit, H, RX, X, FeatureParameter, hea\n# Create two quantum circuits\n# with a single qubit rotation on two random qubits\nn_qubits = 4\nqubits = np.random.choice(n_qubits, n_qubits, replace=False)\nphi = FeatureParameter(\"phi\")\ncircuit_bra = QuantumCircuit(n_qubits, RX(qubits[0], phi))\npsi = FeatureParameter(\"psi\")\ncircuit_ket = QuantumCircuit(n_qubits, RX(qubits[1], psi))\n# Values for the feature parameters\nvalues_bra = {\"phi\": torch.Tensor([torch.pi / 2, torch.pi])}\nvalues_ket = {\"psi\": torch.Tensor([torch.pi / 2, torch.pi])}\n# Calculate overlap by assigning values to the given bra and ket circuits\novrlp = Overlap(circuit_bra, circuit_ket)\novrlp = ovrlp(bra_param_values=values_bra, ket_param_values=values_ket)\n</code></pre> <pre><code>Overlap with exact method:\ntensor([[2.5000e-01, 1.8747e-33],\n[1.8747e-33, 1.4058e-65]])\n</code></pre> <p>The <code>Overlap</code> class above inherits from <code>QuantumModel</code> and is executed through its inherited forward method for the given input parameter values. By default, the overlap is computed exactly by performing the dot product of the wavefunction propagated from bra and ket circuits.</p> <p>However, it is possible to choose a different method from the <code>OverlapMethod</code> enumeration to be passed via the <code>overlap_method</code> argument in the <code>Overlap</code> initializer. Currently, one can choose from:</p> <ul> <li><code>EXACT</code>: exact computation using the wavefunction matrix representation. Does not work with real devices since it assumes access to the complete qubit system wavefunction.</li> <li><code>COMPUTE_UNCOMPUTE</code>: exact or sampling-based computation using bra \\(U\\) and ket \\(W^{\\dagger}\\) unitaries.</li> <li><code>SWAP_TEST</code>: exact or sampling-based computation using the SWAP test method.</li> <li><code>HADAMARD_TEST</code>: exact or sampling-based computation using the Hadamard test method.</li> <li><code>JENSEN_SHANNON</code>: compute the overlap using the Jensen-Shannon divergence of the two probability distributions obtained by sampling the propagated circuits. This will yield a different result than the other methods.</li> </ul> <p>All methods (except for the <code>EXACT</code> method) take an optional <code>n_shots</code> argument which can be used to perform shot-based calculations.</p> <p>Warning</p> <p>If you select a finite number of shots, the overlap is not differentiable. Therefore, it cannot be used as output of a quantum model if gradients are required.</p> <pre><code># Calculate overlap with SWAP test\novrlp = Overlap(circuit_bra, circuit_ket, method=OverlapMethod.SWAP_TEST)\novrlp_ha = ovrlp(values_bra, values_ket)\n# Calculate overlap with SWAP test\n# using a finite number of shots\novrlp = Overlap(circuit_bra, circuit_ket, method=OverlapMethod.SWAP_TEST)\novrlp_ha = ovrlp(values_bra, values_ket, n_shots=10_000)\n</code></pre> <pre><code>Overlap with SWAP test:\ntensor([[2.5000e-01, 4.4409e-16],\n[4.4409e-16, 4.4409e-16]])\nOverlap with SWAP test with finite number of shots:\ntensor([[ 0.2524, -0.0104],\n[ 0.0020,  0.0012]])\n</code></pre>"},{"location":"tutorials/parameters/","title":"Parametric programs","text":"<p>Qadence base <code>Parameter</code> type is a subtype of <code>sympy.Symbol</code>. There are three kinds of parameter subtypes used:</p> <ul> <li>Fixed Parameter: A constant with a fixed, non-trainable value (e.g. \\(\\dfrac{\\pi}{2}\\)).</li> <li>Variational Parameter: A trainable parameter which can be optimized.</li> <li>Feature Parameter: A non-trainable parameter which can be used to encode classical data into a quantum state.</li> </ul>"},{"location":"tutorials/parameters/#fixed-parameters","title":"Fixed Parameters","text":"<p>To pass a fixed parameter to a gate (or any parametrizable block), one can simply use either Python numeric types or wrapped in a <code>torch.Tensor</code>.</p> <pre><code>from torch import pi\nfrom qadence import RX, run\n# Let's use a torch type.\nblock = RX(0, pi)\nwf = run(block)\n# Let's pass a simple float.\nblock = RX(0, 1.)\nwf = run(block)\n</code></pre> <pre><code>wf = tensor([[6.1232e-17+0.j, 0.0000e+00-1.j]])\nwf = tensor([[0.8776+0.0000j, 0.0000-0.4794j]])\n</code></pre>"},{"location":"tutorials/parameters/#variational-parameters","title":"Variational Parameters","text":"<p>To parametrize a block by an angle <code>theta</code>, either a Python <code>string</code> or an instance of  <code>VariationalParameter</code> can be passed instead of a numeric type to the gate constructor:</p> <pre><code>from qadence import RX, run, VariationalParameter\nblock = RX(0, \"theta\")\n# This is equivalent to:\nblock = RX(0, VariationalParameter(\"theta\"))\nwf = run(block)\n</code></pre> <pre><code>wf = tensor([[0.9903+0.0000j, 0.0000-0.1388j]])\n</code></pre> <p>In the first case in the above example, <code>theta</code> is automatically inferred as a <code>VariationalParameter</code> (i.e. trainable). It is initialized to a random value for the purposes of execution. In the context of a <code>QuantumModel</code>, there is no need to pass a value for <code>theta</code> to the <code>run</code> method since it is stored within the underlying model parameter dictionary.</p>"},{"location":"tutorials/parameters/#feature-parameters","title":"Feature Parameters","text":"<p><code>FeatureParameter</code> types (i.e. inputs), always need to be provided with a value or a batch of values as a dictionary:</p> <pre><code>from torch import tensor\nfrom qadence import RX, run, FeatureParameter\nblock = RX(0, FeatureParameter(\"phi\"))\nwf = run(block, values={\"phi\": tensor([1., 2.])})\n</code></pre> <pre><code>wf = tensor([[0.8776+0.0000j, 0.0000-0.4794j],\n[0.5403+0.0000j, 0.0000-0.8415j]])\n</code></pre> <p>Now, <code>run</code> returns a batch of states, one for every provided angle which coincides with the value of the particular <code>FeatureParameter</code>.</p>"},{"location":"tutorials/parameters/#multiparameter-expressions","title":"Multiparameter Expressions","text":"<p>However, an angle can itself be an expression <code>Parameter</code> types of any kind. As such, any sympy expression <code>expr: sympy.Basic</code> consisting of a combination of free symbols (i.e. <code>sympy</code> types) and Qadence <code>Parameter</code> can be passed to a block, including trigonometric functions.</p> <pre><code>from torch import tensor\nfrom qadence import RX, Parameter, run, FeatureParameter\nfrom sympy import sin\ntheta, phi = Parameter(\"theta\"), FeatureParameter(\"phi\")\nblock = RX(0, sin(theta+phi))\n# Remember, to run the block, only FeatureParameter values have to be provided:\nvalues = {\"phi\": tensor([1.0, 2.0])}\nwf = run(block, values=values)\n</code></pre> <pre><code>wf = tensor([[0.8950+0.0000j, 0.0000-0.4460j],\n[0.9960+0.0000j, 0.0000-0.0893j]])\n</code></pre>"},{"location":"tutorials/parameters/#parameters-redundancy","title":"Parameters Redundancy","text":"<p>Parameters are uniquely defined by their name and redundancy is allowed in composite blocks to assign the same value to different blocks.</p> <pre><code>import torch\nfrom qadence import RX, RY, run, chain, kron\nblock = chain(\nkron(RX(0, \"phi\"), RY(1, \"theta\")),\nkron(RX(0, \"phi\"), RY(1, \"theta\")),\n)\nwf = run(block)  # Same random initialization for all instances of phi and theta.\n</code></pre> <pre><code>wf = tensor([[0.7308+0.0000j, 0.6788+0.0000j, 0.0000-0.0523j, 0.0000-0.0486j]])\n</code></pre>"},{"location":"tutorials/parameters/#parametrized-circuits","title":"Parametrized Circuits","text":"<p>Now, let's have a look at the construction of a variational ansatz which composes <code>FeatureParameter</code> and <code>VariationalParameter</code> types:</p> <pre><code>import sympy\nfrom qadence import RX, RY, RZ, CNOT, Z, run, chain, kron, FeatureParameter, VariationalParameter\nphi = FeatureParameter(\"phi\")\ntheta = VariationalParameter(\"theta\")\nblock = chain(\nkron(\nRX(0, phi/theta),\nRY(1, theta*2),\nRZ(2, sympy.cos(phi)),\n),\nkron(\nRX(0, phi),\nRY(1, theta),\nRZ(2, phi),\n),\nkron(\nRX(0, phi),\nRY(1, theta),\nRZ(2, phi),\n),\nkron(\nRX(0, phi + theta),\nRY(1, theta**2),\nRZ(2, sympy.cos(phi)),\n),\nchain(CNOT(0,1), CNOT(1,2))\n)\nblock.tag = \"Rotations\"\nobs = 2*kron(*map(Z, range(3)))\nblock = chain(block, obs)\n</code></pre> %3 cluster_6d7d116101f344b3abe1688dffb68cd8 [* 2] cluster_56f78e1a29804bb2b6ba63ebaee7ae3e Rotations 8a696d08e96345269c1cd66dd00b97c2 0 c229fac778154677a406c108fcb3ca39 RX(phi/theta) 8a696d08e96345269c1cd66dd00b97c2--c229fac778154677a406c108fcb3ca39 d6435d8d1f4447d0ae6d6b9ad7c4a47c 1 4b45157c750b4875bb90f0fd847ba2fb RX(phi) c229fac778154677a406c108fcb3ca39--4b45157c750b4875bb90f0fd847ba2fb 10d3d3af55694bc1b3ea1a82de94659f RX(phi) 4b45157c750b4875bb90f0fd847ba2fb--10d3d3af55694bc1b3ea1a82de94659f f5cca5a61f6940798772bb6d0d4247e2 RX(phi + theta) 10d3d3af55694bc1b3ea1a82de94659f--f5cca5a61f6940798772bb6d0d4247e2 f80bd838da194b7d83b7aa29a491e092 f5cca5a61f6940798772bb6d0d4247e2--f80bd838da194b7d83b7aa29a491e092 f954636407fa41f2bf320da76187d680 f80bd838da194b7d83b7aa29a491e092--f954636407fa41f2bf320da76187d680 8be06a8eb1c74cd39d3e9230eccbbf1d Z f954636407fa41f2bf320da76187d680--8be06a8eb1c74cd39d3e9230eccbbf1d e48edac2320048f3866a16cccd4a16f8 8be06a8eb1c74cd39d3e9230eccbbf1d--e48edac2320048f3866a16cccd4a16f8 37d4a0cbfef147e9bff5c1357e19b02f b9fce6c0d6b2472191db04f0670cc04b RY(2*theta) d6435d8d1f4447d0ae6d6b9ad7c4a47c--b9fce6c0d6b2472191db04f0670cc04b a0476b86c67e40ff9ef2554f75c53f34 2 830b7e3f7a4b445eae7df9f85199e909 RY(theta) b9fce6c0d6b2472191db04f0670cc04b--830b7e3f7a4b445eae7df9f85199e909 a4f88c02007a4555b18936a5d2e2ee77 RY(theta) 830b7e3f7a4b445eae7df9f85199e909--a4f88c02007a4555b18936a5d2e2ee77 2a81c3f0c2ac49a1bb2f1d95c74338fc RY(theta**2) a4f88c02007a4555b18936a5d2e2ee77--2a81c3f0c2ac49a1bb2f1d95c74338fc 06e0ebb3eadd48a998d7bb929a1632c5 X 2a81c3f0c2ac49a1bb2f1d95c74338fc--06e0ebb3eadd48a998d7bb929a1632c5 06e0ebb3eadd48a998d7bb929a1632c5--f80bd838da194b7d83b7aa29a491e092 0807a95d9be7498c87b523717d4e3381 06e0ebb3eadd48a998d7bb929a1632c5--0807a95d9be7498c87b523717d4e3381 13ce3eb1a1204408972c7b886713dddb Z 0807a95d9be7498c87b523717d4e3381--13ce3eb1a1204408972c7b886713dddb 13ce3eb1a1204408972c7b886713dddb--37d4a0cbfef147e9bff5c1357e19b02f 1d7df57453914d589989d76aef7edd1f 8a11a41831e14e97ab828c7235b212fe RZ(cos(phi)) a0476b86c67e40ff9ef2554f75c53f34--8a11a41831e14e97ab828c7235b212fe d75814d3ca6c47ddab8c0851cf6f1ee4 RZ(phi) 8a11a41831e14e97ab828c7235b212fe--d75814d3ca6c47ddab8c0851cf6f1ee4 8a1f7875fcdf43739cbd08763ba58a37 RZ(phi) d75814d3ca6c47ddab8c0851cf6f1ee4--8a1f7875fcdf43739cbd08763ba58a37 6ce235a29ab044a890d30cb029641dad RZ(cos(phi)) 8a1f7875fcdf43739cbd08763ba58a37--6ce235a29ab044a890d30cb029641dad 4c8d0e816124448699a12a27c7699c9f 6ce235a29ab044a890d30cb029641dad--4c8d0e816124448699a12a27c7699c9f bbc8db87edcd4a3b8c566d023d1a4f92 X 4c8d0e816124448699a12a27c7699c9f--bbc8db87edcd4a3b8c566d023d1a4f92 bbc8db87edcd4a3b8c566d023d1a4f92--0807a95d9be7498c87b523717d4e3381 5ed91794300247cda33e5c27b6d9775c Z bbc8db87edcd4a3b8c566d023d1a4f92--5ed91794300247cda33e5c27b6d9775c 5ed91794300247cda33e5c27b6d9775c--1d7df57453914d589989d76aef7edd1f <p>Please note the different colors for the parametrization with different types. The default palette assigns light blue for <code>VariationalParameter</code>, light green for <code>FeatureParameter</code> and shaded red for observables.</p>"},{"location":"tutorials/parameters/#parametrized-quantummodels","title":"Parametrized QuantumModels","text":"<p>As a quick reminder: <code>FeatureParameter</code> are used for data input and data encoding into a quantum state. <code>VariationalParameter</code> are trainable parameters in a variational ansatz. When used within a <code>QuantumModel</code>, an abstract quantum circuit is made differentiable with respect to both variational and feature parameters which are uniquely identified by their name.</p> <pre><code>from qadence import FeatureParameter, Parameter, VariationalParameter\n# Feature parameters are non-trainable parameters.\n# Their primary use is input data encoding.\nfp = FeatureParameter(\"x\")\nassert fp == Parameter(\"x\", trainable=False)\n# Variational parameters are trainable parameters.\n# Their primary use is for optimization.\nvp = VariationalParameter(\"y\")\nassert vp == Parameter(\"y\", trainable=True)\n</code></pre> <p>Let's construct a parametric quantum circuit.</p> <pre><code>from qadence import QuantumCircuit, RX, RY, chain, kron\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\nblock = chain(\nkron(RX(0, theta), RY(1, theta)),\nkron(RX(0, phi), RY(1, phi)),\n)\ncircuit = QuantumCircuit(2, block)\nunique_params = circuit.unique_parameters\n</code></pre> <pre><code>unique_params = [theta, phi]\n</code></pre> <p>In the circuit above, four parameters are defined but only two unique names. Therefore, there will be only one variational parameter to be optimized.</p> <p>The <code>QuantumModel</code> class also provides convenience methods to manipulate parameters.</p> <pre><code>from qadence import QuantumModel, BackendName, DiffMode\nmodel = QuantumModel(circuit, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD)\nnum_vparams = model.num_vparams # get the number of variational parameters\nvparams_values = model.vparams\n</code></pre> <pre><code>num_vparams = 1\nvparams_values = OrderedDict([('theta', tensor([0.1479]))])\n</code></pre> <p>Only provide feature parameter values to the quantum model</p> <p>In order to <code>run</code> the variational circuit only feature parameter values have to be provided. Variational parameters are stored in the model itself. If multiple feature parameters are present, values must be provided in batches of same length.</p> <p><pre><code>import torch\nvalues = {\"phi\": torch.rand(3)} # theta does not appear here\nwf = model.run(values)\n</code></pre> <pre><code>wf = tensor([[0.9868+0.0000j, 0.1142+0.0000j, 0.0000-0.1142j, 0.0000-0.0132j],\n[0.9047+0.0000j, 0.2937+0.0000j, 0.0000-0.2937j, 0.0000-0.0953j],\n[0.8202+0.0000j, 0.3840+0.0000j, 0.0000-0.3840j, 0.0000-0.1798j]],\ngrad_fn=&lt;TBackward0&gt;)\n</code></pre> </p>"},{"location":"tutorials/parameters/#standard-constructors","title":"Standard constructors","text":"<p>The unique parameter identification is relevant when using built-in Qadence block constructors in the <code>qadence.constructors</code> module such as feature maps and hardware efficient ansatze (HEA).</p> <p><pre><code>from qadence import QuantumCircuit, hea\nn_qubits = 4\ndepth = 2\nhea1 = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, hea1)\nnum_unique_parameters = circuit.num_unique_parameters\n</code></pre> <pre><code>Unique parameters with a single HEA: 24\n</code></pre> %3 0c66b21616704b0c805616fcc9acd0d3 0 e6c6beadd6fa456690959fb48e0a63ac RX(theta\u2080) 0c66b21616704b0c805616fcc9acd0d3--e6c6beadd6fa456690959fb48e0a63ac f6ffa6a2554949df96c7daad5b3e0a40 1 9f3e53d7cbc74ca18a0a51d9be809173 RY(theta\u2084) e6c6beadd6fa456690959fb48e0a63ac--9f3e53d7cbc74ca18a0a51d9be809173 6e41c2adefd54c33a3a3663e0541d34e RX(theta\u2088) 9f3e53d7cbc74ca18a0a51d9be809173--6e41c2adefd54c33a3a3663e0541d34e ba35dd84ce2e40d386526e1282a86182 6e41c2adefd54c33a3a3663e0541d34e--ba35dd84ce2e40d386526e1282a86182 a20dd91112cc488f994283cb1a40fe32 ba35dd84ce2e40d386526e1282a86182--a20dd91112cc488f994283cb1a40fe32 2dd59f6ac07f48c182e90480dc193d56 RX(theta\u2081\u2082) a20dd91112cc488f994283cb1a40fe32--2dd59f6ac07f48c182e90480dc193d56 8c7869e6c0bb4529b623177ca9950718 RY(theta\u2081\u2086) 2dd59f6ac07f48c182e90480dc193d56--8c7869e6c0bb4529b623177ca9950718 7e863a1fbed0412b9510b53621db1d0e RX(theta\u2082\u2080) 8c7869e6c0bb4529b623177ca9950718--7e863a1fbed0412b9510b53621db1d0e 9eeacce2620845219f6ebaa68f6c5246 7e863a1fbed0412b9510b53621db1d0e--9eeacce2620845219f6ebaa68f6c5246 05b7b3e1bf5e46bda7a92e65e291e6d5 9eeacce2620845219f6ebaa68f6c5246--05b7b3e1bf5e46bda7a92e65e291e6d5 6f87b725699940aeb2f8beb07b1f0bc3 05b7b3e1bf5e46bda7a92e65e291e6d5--6f87b725699940aeb2f8beb07b1f0bc3 97114e0773e94aae88a6cdf6ecbfd858 87f6c9131e2a491eb0645b82ea89b0b0 RX(theta\u2081) f6ffa6a2554949df96c7daad5b3e0a40--87f6c9131e2a491eb0645b82ea89b0b0 987a43d56c8d4b71b0391bdc56a8dde7 2 90dfcc4640e44dfe83b2f7776ae495a1 RY(theta\u2085) 87f6c9131e2a491eb0645b82ea89b0b0--90dfcc4640e44dfe83b2f7776ae495a1 f0e3ab95db794dc98da6deb8dcce6fcb RX(theta\u2089) 90dfcc4640e44dfe83b2f7776ae495a1--f0e3ab95db794dc98da6deb8dcce6fcb c123cdcbad394b1e9305b688d4606d58 X f0e3ab95db794dc98da6deb8dcce6fcb--c123cdcbad394b1e9305b688d4606d58 c123cdcbad394b1e9305b688d4606d58--ba35dd84ce2e40d386526e1282a86182 f393de322c2b4f86a3c89581e1826190 c123cdcbad394b1e9305b688d4606d58--f393de322c2b4f86a3c89581e1826190 ce1506f6c0124826a989bf23b9132b02 RX(theta\u2081\u2083) f393de322c2b4f86a3c89581e1826190--ce1506f6c0124826a989bf23b9132b02 5a256523f74b45c6b55c34996ededd55 RY(theta\u2081\u2087) ce1506f6c0124826a989bf23b9132b02--5a256523f74b45c6b55c34996ededd55 3d0956e70c4746509eb9c125fb02beea RX(theta\u2082\u2081) 5a256523f74b45c6b55c34996ededd55--3d0956e70c4746509eb9c125fb02beea 623c2069145d4cb1b5668486196b0f60 X 3d0956e70c4746509eb9c125fb02beea--623c2069145d4cb1b5668486196b0f60 623c2069145d4cb1b5668486196b0f60--9eeacce2620845219f6ebaa68f6c5246 7abe6e0c2bab44e7b0ec893868c9944e 623c2069145d4cb1b5668486196b0f60--7abe6e0c2bab44e7b0ec893868c9944e 7abe6e0c2bab44e7b0ec893868c9944e--97114e0773e94aae88a6cdf6ecbfd858 6948ec7ce5484026935ce0123f7a79e7 db7d65d427fa43d5ab26e228c7eda278 RX(theta\u2082) 987a43d56c8d4b71b0391bdc56a8dde7--db7d65d427fa43d5ab26e228c7eda278 a7afa03c50a944d8b237a6911323ea0b 3 d71f210849584edc9c9a6b21dfe81045 RY(theta\u2086) db7d65d427fa43d5ab26e228c7eda278--d71f210849584edc9c9a6b21dfe81045 fb88cf0a2eff4103b156be9fd6c2c617 RX(theta\u2081\u2080) d71f210849584edc9c9a6b21dfe81045--fb88cf0a2eff4103b156be9fd6c2c617 18489cae08c0483bb8956ba7f1a1a33c fb88cf0a2eff4103b156be9fd6c2c617--18489cae08c0483bb8956ba7f1a1a33c 7235acfa34de4dea9c5c6e8524c34fc4 X 18489cae08c0483bb8956ba7f1a1a33c--7235acfa34de4dea9c5c6e8524c34fc4 7235acfa34de4dea9c5c6e8524c34fc4--f393de322c2b4f86a3c89581e1826190 7b2e2972554948ccbe9defe5c0317946 RX(theta\u2081\u2084) 7235acfa34de4dea9c5c6e8524c34fc4--7b2e2972554948ccbe9defe5c0317946 cb3ba2fbbb7f4273a879ae2c56e47da1 RY(theta\u2081\u2088) 7b2e2972554948ccbe9defe5c0317946--cb3ba2fbbb7f4273a879ae2c56e47da1 cfadd91759094a358fbba053e549ef3e RX(theta\u2082\u2082) cb3ba2fbbb7f4273a879ae2c56e47da1--cfadd91759094a358fbba053e549ef3e 7d69e37bdb38444ba73164b1c7396f6b cfadd91759094a358fbba053e549ef3e--7d69e37bdb38444ba73164b1c7396f6b fdb82c1132b14854aca4d41f52d30c90 X 7d69e37bdb38444ba73164b1c7396f6b--fdb82c1132b14854aca4d41f52d30c90 fdb82c1132b14854aca4d41f52d30c90--7abe6e0c2bab44e7b0ec893868c9944e fdb82c1132b14854aca4d41f52d30c90--6948ec7ce5484026935ce0123f7a79e7 e7e323846df346ab974f1ea3731cc77f 07f56cb98fcc4b73933d8390c422ee6e RX(theta\u2083) a7afa03c50a944d8b237a6911323ea0b--07f56cb98fcc4b73933d8390c422ee6e 4b90cb86fc59451a884feb4b69f76052 RY(theta\u2087) 07f56cb98fcc4b73933d8390c422ee6e--4b90cb86fc59451a884feb4b69f76052 c2bbbda6cdcc442c97684200bc8c8c06 RX(theta\u2081\u2081) 4b90cb86fc59451a884feb4b69f76052--c2bbbda6cdcc442c97684200bc8c8c06 b882350181b4450cafdcc1529ff61fe1 X c2bbbda6cdcc442c97684200bc8c8c06--b882350181b4450cafdcc1529ff61fe1 b882350181b4450cafdcc1529ff61fe1--18489cae08c0483bb8956ba7f1a1a33c 5f6c651074b247ecbbfe38c1eaa6b952 b882350181b4450cafdcc1529ff61fe1--5f6c651074b247ecbbfe38c1eaa6b952 54f6b0e2065f4557811734abba0fee9d RX(theta\u2081\u2085) 5f6c651074b247ecbbfe38c1eaa6b952--54f6b0e2065f4557811734abba0fee9d caead0abfd5a4d6bb732cea2bfb208eb RY(theta\u2081\u2089) 54f6b0e2065f4557811734abba0fee9d--caead0abfd5a4d6bb732cea2bfb208eb 7f2b1af05ea14e029a7c9d0e3d967d63 RX(theta\u2082\u2083) caead0abfd5a4d6bb732cea2bfb208eb--7f2b1af05ea14e029a7c9d0e3d967d63 b780b7ce6ab0478ebc36e83bd4d8e4fb X 7f2b1af05ea14e029a7c9d0e3d967d63--b780b7ce6ab0478ebc36e83bd4d8e4fb b780b7ce6ab0478ebc36e83bd4d8e4fb--7d69e37bdb38444ba73164b1c7396f6b 05c16c51c50449148963718ea0bf8328 b780b7ce6ab0478ebc36e83bd4d8e4fb--05c16c51c50449148963718ea0bf8328 05c16c51c50449148963718ea0bf8328--e7e323846df346ab974f1ea3731cc77f </p> <p>A new circuit can be created by adding another identical HEA. As expected, the number of unique parameters is the same.</p> <p><pre><code>hea2 = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, hea1, hea2)\nnum_unique_params_two_heas = circuit.num_unique_parameters\n</code></pre> <pre><code>Unique parameters with two stacked HEAs: 24\n</code></pre> %3 cluster_46c80d1ac81d43ae9be646e456e5cba5 HEA cluster_71acd74fa4f145019fef3bcb186371b7 HEA 1adb912f44b84230ae0604bb20475c80 0 8c46b614e9774a10acd7b227afcecea9 RX(theta\u2080) 1adb912f44b84230ae0604bb20475c80--8c46b614e9774a10acd7b227afcecea9 6d38c26a64484a0185273b8ce80fc595 1 d95e5eaba2c84a0b94f66cf9f09b1ad2 RY(theta\u2084) 8c46b614e9774a10acd7b227afcecea9--d95e5eaba2c84a0b94f66cf9f09b1ad2 af71c679b7b74254b03c7e7629ba4dcd RX(theta\u2088) d95e5eaba2c84a0b94f66cf9f09b1ad2--af71c679b7b74254b03c7e7629ba4dcd 18cbe6429fde4096a746c38c721b7d0a af71c679b7b74254b03c7e7629ba4dcd--18cbe6429fde4096a746c38c721b7d0a a0213f83a50e4010b627ad96d08e20fa 18cbe6429fde4096a746c38c721b7d0a--a0213f83a50e4010b627ad96d08e20fa 498b5393bc7b4f758d0296a756fa8fe1 RX(theta\u2081\u2082) a0213f83a50e4010b627ad96d08e20fa--498b5393bc7b4f758d0296a756fa8fe1 7dc3c78d085f4409b8889c5765ea8f8d RY(theta\u2081\u2086) 498b5393bc7b4f758d0296a756fa8fe1--7dc3c78d085f4409b8889c5765ea8f8d 708377b2d6134f538f2b9a7a81c21133 RX(theta\u2082\u2080) 7dc3c78d085f4409b8889c5765ea8f8d--708377b2d6134f538f2b9a7a81c21133 2f07fc1429c144f3911e6d12b08b8cab 708377b2d6134f538f2b9a7a81c21133--2f07fc1429c144f3911e6d12b08b8cab 8ae0c0eeee024f46a70d9cabea63ba78 2f07fc1429c144f3911e6d12b08b8cab--8ae0c0eeee024f46a70d9cabea63ba78 caa97758a98649aa941a06651ab0c024 RX(theta\u2080) 8ae0c0eeee024f46a70d9cabea63ba78--caa97758a98649aa941a06651ab0c024 0b273292a6464102b0b22340c9c04ee4 RY(theta\u2084) caa97758a98649aa941a06651ab0c024--0b273292a6464102b0b22340c9c04ee4 024d8d4a25dc4228911d8504283dc92f RX(theta\u2088) 0b273292a6464102b0b22340c9c04ee4--024d8d4a25dc4228911d8504283dc92f c71c050ab091410cb992b993eaafe098 024d8d4a25dc4228911d8504283dc92f--c71c050ab091410cb992b993eaafe098 db5475c3947e456281ee79909d212f5c c71c050ab091410cb992b993eaafe098--db5475c3947e456281ee79909d212f5c 9a9a79c9c6034bc9bfc38e620940e1e4 RX(theta\u2081\u2082) db5475c3947e456281ee79909d212f5c--9a9a79c9c6034bc9bfc38e620940e1e4 7c51a949f5614582924393f3e0bfccb7 RY(theta\u2081\u2086) 9a9a79c9c6034bc9bfc38e620940e1e4--7c51a949f5614582924393f3e0bfccb7 fa292b89625d4052a9ad2a5b98aac0df RX(theta\u2082\u2080) 7c51a949f5614582924393f3e0bfccb7--fa292b89625d4052a9ad2a5b98aac0df b3cac5f2459c490f8418d389e4340f76 fa292b89625d4052a9ad2a5b98aac0df--b3cac5f2459c490f8418d389e4340f76 09c81a95742743d29eff946e52335bfe b3cac5f2459c490f8418d389e4340f76--09c81a95742743d29eff946e52335bfe fadf126e4122464eb4c7637bfa89d96c 09c81a95742743d29eff946e52335bfe--fadf126e4122464eb4c7637bfa89d96c 5d1ee5f1dac7419683c6658196c93a7a 3c2d008bbb0b4992ae1e7a1c7c9223b5 RX(theta\u2081) 6d38c26a64484a0185273b8ce80fc595--3c2d008bbb0b4992ae1e7a1c7c9223b5 7cd84bdcbe1344949792ef93a6cb1af2 2 05f87efd35094e5890fa0deffeaf4512 RY(theta\u2085) 3c2d008bbb0b4992ae1e7a1c7c9223b5--05f87efd35094e5890fa0deffeaf4512 86628fef28954896b02bc63495558f0e RX(theta\u2089) 05f87efd35094e5890fa0deffeaf4512--86628fef28954896b02bc63495558f0e 9e697d2dcb0f40ed9b65aa18a2a65cbc X 86628fef28954896b02bc63495558f0e--9e697d2dcb0f40ed9b65aa18a2a65cbc 9e697d2dcb0f40ed9b65aa18a2a65cbc--18cbe6429fde4096a746c38c721b7d0a a91e3ca1625d43dcb188d9dc704d3a84 9e697d2dcb0f40ed9b65aa18a2a65cbc--a91e3ca1625d43dcb188d9dc704d3a84 7d45815aba504263bd3e708eddaef546 RX(theta\u2081\u2083) a91e3ca1625d43dcb188d9dc704d3a84--7d45815aba504263bd3e708eddaef546 08a98fa23dcb40f68d5afea8b2a172bc RY(theta\u2081\u2087) 7d45815aba504263bd3e708eddaef546--08a98fa23dcb40f68d5afea8b2a172bc 947e8b894690415392f006c69826b460 RX(theta\u2082\u2081) 08a98fa23dcb40f68d5afea8b2a172bc--947e8b894690415392f006c69826b460 23ab4df27689467e9ae801e223930b58 X 947e8b894690415392f006c69826b460--23ab4df27689467e9ae801e223930b58 23ab4df27689467e9ae801e223930b58--2f07fc1429c144f3911e6d12b08b8cab eda92bdacedf47da8ef9de54fe56c0fd 23ab4df27689467e9ae801e223930b58--eda92bdacedf47da8ef9de54fe56c0fd 3c834054c2ea4ce297e796f88ebcc148 RX(theta\u2081) eda92bdacedf47da8ef9de54fe56c0fd--3c834054c2ea4ce297e796f88ebcc148 0053eeed143041bbb1d2de4307cf2025 RY(theta\u2085) 3c834054c2ea4ce297e796f88ebcc148--0053eeed143041bbb1d2de4307cf2025 477f4e883cfc4839951e5a39a12a4d78 RX(theta\u2089) 0053eeed143041bbb1d2de4307cf2025--477f4e883cfc4839951e5a39a12a4d78 f7725c56c50b47a7a5ed31f23fb17f2e X 477f4e883cfc4839951e5a39a12a4d78--f7725c56c50b47a7a5ed31f23fb17f2e f7725c56c50b47a7a5ed31f23fb17f2e--c71c050ab091410cb992b993eaafe098 efe8d8dddccf4a6c8a6a82850e7c8f5c f7725c56c50b47a7a5ed31f23fb17f2e--efe8d8dddccf4a6c8a6a82850e7c8f5c e4dd15e5cc494540b8a9dc7b1ddf4c77 RX(theta\u2081\u2083) efe8d8dddccf4a6c8a6a82850e7c8f5c--e4dd15e5cc494540b8a9dc7b1ddf4c77 601391c479c947269234e4971cc940c9 RY(theta\u2081\u2087) e4dd15e5cc494540b8a9dc7b1ddf4c77--601391c479c947269234e4971cc940c9 2b28ea61c8c8481c84915d54c65e27c7 RX(theta\u2082\u2081) 601391c479c947269234e4971cc940c9--2b28ea61c8c8481c84915d54c65e27c7 9f84d514bd454830ab7e939c91219881 X 2b28ea61c8c8481c84915d54c65e27c7--9f84d514bd454830ab7e939c91219881 9f84d514bd454830ab7e939c91219881--b3cac5f2459c490f8418d389e4340f76 0fa0222bf7294aa096aca1ce4edd18a1 9f84d514bd454830ab7e939c91219881--0fa0222bf7294aa096aca1ce4edd18a1 0fa0222bf7294aa096aca1ce4edd18a1--5d1ee5f1dac7419683c6658196c93a7a 87f365e90dea47fcbaabcf9048de5e1f dc8e9f867b3840fe85afa10e64a4764e RX(theta\u2082) 7cd84bdcbe1344949792ef93a6cb1af2--dc8e9f867b3840fe85afa10e64a4764e c908c77792d44ae89a3a1538732f59e1 3 5cb6f99c1b704448b30a225620ad5169 RY(theta\u2086) dc8e9f867b3840fe85afa10e64a4764e--5cb6f99c1b704448b30a225620ad5169 74bad092b4b9416baa45fb84929a4205 RX(theta\u2081\u2080) 5cb6f99c1b704448b30a225620ad5169--74bad092b4b9416baa45fb84929a4205 5f78a8e5ac81492d9968026cdeac941e 74bad092b4b9416baa45fb84929a4205--5f78a8e5ac81492d9968026cdeac941e c2afd60fac094a24a1fd8347f57812a1 X 5f78a8e5ac81492d9968026cdeac941e--c2afd60fac094a24a1fd8347f57812a1 c2afd60fac094a24a1fd8347f57812a1--a91e3ca1625d43dcb188d9dc704d3a84 7d30e30733194013b3b20e36f75a194f RX(theta\u2081\u2084) c2afd60fac094a24a1fd8347f57812a1--7d30e30733194013b3b20e36f75a194f 3a5ae51e8c2c4230ad4328d4966c7d3f RY(theta\u2081\u2088) 7d30e30733194013b3b20e36f75a194f--3a5ae51e8c2c4230ad4328d4966c7d3f cee833d06d5a493686f47534f684ff6e RX(theta\u2082\u2082) 3a5ae51e8c2c4230ad4328d4966c7d3f--cee833d06d5a493686f47534f684ff6e a0583b14946542a3bc6873857ce21edf cee833d06d5a493686f47534f684ff6e--a0583b14946542a3bc6873857ce21edf f0fd99d982e2499ebf807947b54d6e6b X a0583b14946542a3bc6873857ce21edf--f0fd99d982e2499ebf807947b54d6e6b f0fd99d982e2499ebf807947b54d6e6b--eda92bdacedf47da8ef9de54fe56c0fd 3b5c13a6b5a34c92afe948fcd8a30d2a RX(theta\u2082) f0fd99d982e2499ebf807947b54d6e6b--3b5c13a6b5a34c92afe948fcd8a30d2a 9a95f82e7ec74704aa4706e5814c5b0a RY(theta\u2086) 3b5c13a6b5a34c92afe948fcd8a30d2a--9a95f82e7ec74704aa4706e5814c5b0a 225b0aa590cc48d08859f84e081b3969 RX(theta\u2081\u2080) 9a95f82e7ec74704aa4706e5814c5b0a--225b0aa590cc48d08859f84e081b3969 7325a02cba3e44af90cb3ed744e80c05 225b0aa590cc48d08859f84e081b3969--7325a02cba3e44af90cb3ed744e80c05 05a41d2e0605469e950f359c19a772d8 X 7325a02cba3e44af90cb3ed744e80c05--05a41d2e0605469e950f359c19a772d8 05a41d2e0605469e950f359c19a772d8--efe8d8dddccf4a6c8a6a82850e7c8f5c 696ed80bf4f248c3b9776a12f646b129 RX(theta\u2081\u2084) 05a41d2e0605469e950f359c19a772d8--696ed80bf4f248c3b9776a12f646b129 27540e743acd4ad8b054f7c06f0c93d2 RY(theta\u2081\u2088) 696ed80bf4f248c3b9776a12f646b129--27540e743acd4ad8b054f7c06f0c93d2 9eca397203a14ce0aeaed44b9d1b0c0f RX(theta\u2082\u2082) 27540e743acd4ad8b054f7c06f0c93d2--9eca397203a14ce0aeaed44b9d1b0c0f 17363516dc9546ccabff326efc509e77 9eca397203a14ce0aeaed44b9d1b0c0f--17363516dc9546ccabff326efc509e77 d1ae230a60e14818aa0b0646389efe9e X 17363516dc9546ccabff326efc509e77--d1ae230a60e14818aa0b0646389efe9e d1ae230a60e14818aa0b0646389efe9e--0fa0222bf7294aa096aca1ce4edd18a1 d1ae230a60e14818aa0b0646389efe9e--87f365e90dea47fcbaabcf9048de5e1f c77f96550d14459ab359bf6be800e48d 48e7c94786e74f26b0a25968f8523edf RX(theta\u2083) c908c77792d44ae89a3a1538732f59e1--48e7c94786e74f26b0a25968f8523edf 8542c805a3354104a99e80118de5fb04 RY(theta\u2087) 48e7c94786e74f26b0a25968f8523edf--8542c805a3354104a99e80118de5fb04 af50769160ce40bea848ff59b42d4161 RX(theta\u2081\u2081) 8542c805a3354104a99e80118de5fb04--af50769160ce40bea848ff59b42d4161 a0c18a50d44f44fab50f729349f41b21 X af50769160ce40bea848ff59b42d4161--a0c18a50d44f44fab50f729349f41b21 a0c18a50d44f44fab50f729349f41b21--5f78a8e5ac81492d9968026cdeac941e 1506a7c30cb94eab83cb3f2ee9157e74 a0c18a50d44f44fab50f729349f41b21--1506a7c30cb94eab83cb3f2ee9157e74 21816fe3587544828fb0312426f5d69e RX(theta\u2081\u2085) 1506a7c30cb94eab83cb3f2ee9157e74--21816fe3587544828fb0312426f5d69e 4d808870169e4c35a00b2a51b10bd3a2 RY(theta\u2081\u2089) 21816fe3587544828fb0312426f5d69e--4d808870169e4c35a00b2a51b10bd3a2 ef35b4bc269440a097b181f39e5e8bd1 RX(theta\u2082\u2083) 4d808870169e4c35a00b2a51b10bd3a2--ef35b4bc269440a097b181f39e5e8bd1 eb16bd0345ed42148453920f39e30450 X ef35b4bc269440a097b181f39e5e8bd1--eb16bd0345ed42148453920f39e30450 eb16bd0345ed42148453920f39e30450--a0583b14946542a3bc6873857ce21edf 2ae5bf42c09d4207ad505775394ae584 eb16bd0345ed42148453920f39e30450--2ae5bf42c09d4207ad505775394ae584 26dc427d94c94804b0e432074e6085ab RX(theta\u2083) 2ae5bf42c09d4207ad505775394ae584--26dc427d94c94804b0e432074e6085ab 6c7231f4315c405890c1f2a9293f0280 RY(theta\u2087) 26dc427d94c94804b0e432074e6085ab--6c7231f4315c405890c1f2a9293f0280 aeabadccee8142e7968f300e4ffadec7 RX(theta\u2081\u2081) 6c7231f4315c405890c1f2a9293f0280--aeabadccee8142e7968f300e4ffadec7 5c794ba905c7490db99489c8a78b0bbf X aeabadccee8142e7968f300e4ffadec7--5c794ba905c7490db99489c8a78b0bbf 5c794ba905c7490db99489c8a78b0bbf--7325a02cba3e44af90cb3ed744e80c05 e4f91a5649144159a37a63d2b9953745 5c794ba905c7490db99489c8a78b0bbf--e4f91a5649144159a37a63d2b9953745 b0c53639896b47cdb684c23fd0ab7bec RX(theta\u2081\u2085) e4f91a5649144159a37a63d2b9953745--b0c53639896b47cdb684c23fd0ab7bec e6506a46311b4e0a94176bb5e433821a RY(theta\u2081\u2089) b0c53639896b47cdb684c23fd0ab7bec--e6506a46311b4e0a94176bb5e433821a 8e44ae7a49b146a9883399b7d6a46092 RX(theta\u2082\u2083) e6506a46311b4e0a94176bb5e433821a--8e44ae7a49b146a9883399b7d6a46092 6414ed563e2b426f8a083438966b4041 X 8e44ae7a49b146a9883399b7d6a46092--6414ed563e2b426f8a083438966b4041 6414ed563e2b426f8a083438966b4041--17363516dc9546ccabff326efc509e77 54b0c89599a8430eaec17986514a4e28 6414ed563e2b426f8a083438966b4041--54b0c89599a8430eaec17986514a4e28 54b0c89599a8430eaec17986514a4e28--c77f96550d14459ab359bf6be800e48d </p> <p>Avoid non-unique names by prefixing</p> <p>A parameter prefix for each HEA can be passed as follows:</p> <p><pre><code>hea1 = hea(n_qubits=n_qubits, depth=depth, param_prefix=\"p1\")\nhea2 = hea(n_qubits=n_qubits, depth=depth, param_prefix=\"p2\")\ncircuit = QuantumCircuit(n_qubits, hea1, hea2)\nn_params_two_heas = circuit.num_unique_parameters\n</code></pre> <pre><code>Unique parameters with two stacked HEAs: 48\n</code></pre> %3 cluster_b3e162d0bce44d04ae5b95c8fe142e88 HEA cluster_015269ab6e294b2e8a1aa7645c22b116 HEA d9b2ca04f7184858878c4d83a476e487 0 0763f3fe400441d582ea717af16a94df RX(p1\u2080) d9b2ca04f7184858878c4d83a476e487--0763f3fe400441d582ea717af16a94df 2518d00d6c2945f18a9c960de7a5db67 1 11a43eba394343e9a2bf68a87ddb9f45 RY(p1\u2084) 0763f3fe400441d582ea717af16a94df--11a43eba394343e9a2bf68a87ddb9f45 920ae4a7538a43c3b47797b6bb9636b5 RX(p1\u2088) 11a43eba394343e9a2bf68a87ddb9f45--920ae4a7538a43c3b47797b6bb9636b5 fced09e37e1b4ded931888d667dd9124 920ae4a7538a43c3b47797b6bb9636b5--fced09e37e1b4ded931888d667dd9124 005fd516745a4baea68ead6b03e44196 fced09e37e1b4ded931888d667dd9124--005fd516745a4baea68ead6b03e44196 c21035a759f8462ea2cef092d708f57e RX(p1\u2081\u2082) 005fd516745a4baea68ead6b03e44196--c21035a759f8462ea2cef092d708f57e 3ed624e729fd44a59a5809b43da6f0ed RY(p1\u2081\u2086) c21035a759f8462ea2cef092d708f57e--3ed624e729fd44a59a5809b43da6f0ed 5bf0d48316074a47bbad6b7f7cba058c RX(p1\u2082\u2080) 3ed624e729fd44a59a5809b43da6f0ed--5bf0d48316074a47bbad6b7f7cba058c a0c5c9779b984ddfabf732a0791b010a 5bf0d48316074a47bbad6b7f7cba058c--a0c5c9779b984ddfabf732a0791b010a f650d11a376549bdb9061eafbd7b43f6 a0c5c9779b984ddfabf732a0791b010a--f650d11a376549bdb9061eafbd7b43f6 f3670b9e55cb48388a484bc83bba17ed RX(p2\u2080) f650d11a376549bdb9061eafbd7b43f6--f3670b9e55cb48388a484bc83bba17ed c4dcdbb839af43e98dad746a3b459f67 RY(p2\u2084) f3670b9e55cb48388a484bc83bba17ed--c4dcdbb839af43e98dad746a3b459f67 cf4e7f51183c47e5902f2121a08103be RX(p2\u2088) c4dcdbb839af43e98dad746a3b459f67--cf4e7f51183c47e5902f2121a08103be 31a97e16224645918d23fd0463a3c085 cf4e7f51183c47e5902f2121a08103be--31a97e16224645918d23fd0463a3c085 157c49aed7114248beb071a203968e71 31a97e16224645918d23fd0463a3c085--157c49aed7114248beb071a203968e71 f795031282d74f70bf463b91f5dad534 RX(p2\u2081\u2082) 157c49aed7114248beb071a203968e71--f795031282d74f70bf463b91f5dad534 478c11d8d8c8424db3a80a259272513d RY(p2\u2081\u2086) f795031282d74f70bf463b91f5dad534--478c11d8d8c8424db3a80a259272513d 6581bc499c284f8da0224be6bd199777 RX(p2\u2082\u2080) 478c11d8d8c8424db3a80a259272513d--6581bc499c284f8da0224be6bd199777 80afceef6e6b43cca4afe0b46f4db9f8 6581bc499c284f8da0224be6bd199777--80afceef6e6b43cca4afe0b46f4db9f8 1ee7535d69c848a497d0d8906172a16b 80afceef6e6b43cca4afe0b46f4db9f8--1ee7535d69c848a497d0d8906172a16b d6f4cf01afb24ba188d18bab92c509c1 1ee7535d69c848a497d0d8906172a16b--d6f4cf01afb24ba188d18bab92c509c1 aa5dbbbf1e084bcba7468f26425e872c 06034d67b6184e9ca0626e3b35817583 RX(p1\u2081) 2518d00d6c2945f18a9c960de7a5db67--06034d67b6184e9ca0626e3b35817583 fd4fcf6a3cd24e9a81b1b152ee3572fb 2 18d44a526887437aaf7a2ab534b2842a RY(p1\u2085) 06034d67b6184e9ca0626e3b35817583--18d44a526887437aaf7a2ab534b2842a ed92451da9e442929ac7f615a940afa9 RX(p1\u2089) 18d44a526887437aaf7a2ab534b2842a--ed92451da9e442929ac7f615a940afa9 d70a9e84d3754a1299e3c3373b21967c X ed92451da9e442929ac7f615a940afa9--d70a9e84d3754a1299e3c3373b21967c d70a9e84d3754a1299e3c3373b21967c--fced09e37e1b4ded931888d667dd9124 fdb6f92e435b4903b15130722a55f448 d70a9e84d3754a1299e3c3373b21967c--fdb6f92e435b4903b15130722a55f448 13f4cc5cac9b47618b3a2b82a12dd6a3 RX(p1\u2081\u2083) fdb6f92e435b4903b15130722a55f448--13f4cc5cac9b47618b3a2b82a12dd6a3 b45711dfa2d846fa84818499d0e27c01 RY(p1\u2081\u2087) 13f4cc5cac9b47618b3a2b82a12dd6a3--b45711dfa2d846fa84818499d0e27c01 7b95aa556e6f46bfa2d4fdf1682777d5 RX(p1\u2082\u2081) b45711dfa2d846fa84818499d0e27c01--7b95aa556e6f46bfa2d4fdf1682777d5 939e3a858bbf41e3ab00c08c6ae19b6a X 7b95aa556e6f46bfa2d4fdf1682777d5--939e3a858bbf41e3ab00c08c6ae19b6a 939e3a858bbf41e3ab00c08c6ae19b6a--a0c5c9779b984ddfabf732a0791b010a ab3d50eb234f4d40b99f2d41429e97fc 939e3a858bbf41e3ab00c08c6ae19b6a--ab3d50eb234f4d40b99f2d41429e97fc de243f72369f4bd1aed5e83755ad3246 RX(p2\u2081) ab3d50eb234f4d40b99f2d41429e97fc--de243f72369f4bd1aed5e83755ad3246 8466c40928824514818188266749c1d6 RY(p2\u2085) de243f72369f4bd1aed5e83755ad3246--8466c40928824514818188266749c1d6 31d86527d09d45b8bc007424cae8fd27 RX(p2\u2089) 8466c40928824514818188266749c1d6--31d86527d09d45b8bc007424cae8fd27 1ae3522e2299468e9dcce6076954928c X 31d86527d09d45b8bc007424cae8fd27--1ae3522e2299468e9dcce6076954928c 1ae3522e2299468e9dcce6076954928c--31a97e16224645918d23fd0463a3c085 161e54f49fc449e3a81c7e09edf8d87f 1ae3522e2299468e9dcce6076954928c--161e54f49fc449e3a81c7e09edf8d87f b30b9c53849c4404bff5499b1113aca7 RX(p2\u2081\u2083) 161e54f49fc449e3a81c7e09edf8d87f--b30b9c53849c4404bff5499b1113aca7 ab1fbe08880b4e5e94738e775739aba0 RY(p2\u2081\u2087) b30b9c53849c4404bff5499b1113aca7--ab1fbe08880b4e5e94738e775739aba0 292d6c883308429ba1f9a321e7563914 RX(p2\u2082\u2081) ab1fbe08880b4e5e94738e775739aba0--292d6c883308429ba1f9a321e7563914 f214339a9e974145863e64ffa666cf02 X 292d6c883308429ba1f9a321e7563914--f214339a9e974145863e64ffa666cf02 f214339a9e974145863e64ffa666cf02--80afceef6e6b43cca4afe0b46f4db9f8 092900477d3d431a82734e616c4c761c f214339a9e974145863e64ffa666cf02--092900477d3d431a82734e616c4c761c 092900477d3d431a82734e616c4c761c--aa5dbbbf1e084bcba7468f26425e872c b7067f7003e14bbea86e89f0cb8afa81 13cfa4904de44de99af711392b5f42f2 RX(p1\u2082) fd4fcf6a3cd24e9a81b1b152ee3572fb--13cfa4904de44de99af711392b5f42f2 00aa95522afa44e3b423b3818cea5d4e 3 95291082264b4312b979f0dc158493c4 RY(p1\u2086) 13cfa4904de44de99af711392b5f42f2--95291082264b4312b979f0dc158493c4 1cc00d29675b4a338b32fc500237a9b0 RX(p1\u2081\u2080) 95291082264b4312b979f0dc158493c4--1cc00d29675b4a338b32fc500237a9b0 6f1c5df81f5d4c058241ff77ef5ff858 1cc00d29675b4a338b32fc500237a9b0--6f1c5df81f5d4c058241ff77ef5ff858 21bb176ae3a04312aa4a3e15a0cfabfb X 6f1c5df81f5d4c058241ff77ef5ff858--21bb176ae3a04312aa4a3e15a0cfabfb 21bb176ae3a04312aa4a3e15a0cfabfb--fdb6f92e435b4903b15130722a55f448 357ae40f2e964f5188dc9fe20a793913 RX(p1\u2081\u2084) 21bb176ae3a04312aa4a3e15a0cfabfb--357ae40f2e964f5188dc9fe20a793913 4317d2cf3a9f43f293fd89dc5be447a5 RY(p1\u2081\u2088) 357ae40f2e964f5188dc9fe20a793913--4317d2cf3a9f43f293fd89dc5be447a5 b77f48d285434ac6b363434e316f271b RX(p1\u2082\u2082) 4317d2cf3a9f43f293fd89dc5be447a5--b77f48d285434ac6b363434e316f271b 22b77ba32ffd45679738edc7fc000505 b77f48d285434ac6b363434e316f271b--22b77ba32ffd45679738edc7fc000505 0be659634d004fe78df54a7382f29826 X 22b77ba32ffd45679738edc7fc000505--0be659634d004fe78df54a7382f29826 0be659634d004fe78df54a7382f29826--ab3d50eb234f4d40b99f2d41429e97fc b3772d2713524b66bfab5b10d763fc3f RX(p2\u2082) 0be659634d004fe78df54a7382f29826--b3772d2713524b66bfab5b10d763fc3f a357aae091e848c8998b0e6be9d7928c RY(p2\u2086) b3772d2713524b66bfab5b10d763fc3f--a357aae091e848c8998b0e6be9d7928c 8036f2359a2044e18a0ba7424d737cf1 RX(p2\u2081\u2080) a357aae091e848c8998b0e6be9d7928c--8036f2359a2044e18a0ba7424d737cf1 99543b1bbf3b4e998760ecca02396bf8 8036f2359a2044e18a0ba7424d737cf1--99543b1bbf3b4e998760ecca02396bf8 73ae78120c68469eacf56eb2ec929260 X 99543b1bbf3b4e998760ecca02396bf8--73ae78120c68469eacf56eb2ec929260 73ae78120c68469eacf56eb2ec929260--161e54f49fc449e3a81c7e09edf8d87f d303b36385ea40e98d6775e95ba2f136 RX(p2\u2081\u2084) 73ae78120c68469eacf56eb2ec929260--d303b36385ea40e98d6775e95ba2f136 82beb9c0c6f74ae3b08af620ec550ed9 RY(p2\u2081\u2088) d303b36385ea40e98d6775e95ba2f136--82beb9c0c6f74ae3b08af620ec550ed9 bf4c36a6ec5149feaf1b9709087b8b08 RX(p2\u2082\u2082) 82beb9c0c6f74ae3b08af620ec550ed9--bf4c36a6ec5149feaf1b9709087b8b08 f2ade50a7d734deeb61c536abcb7234b bf4c36a6ec5149feaf1b9709087b8b08--f2ade50a7d734deeb61c536abcb7234b 55c6a2e389ab4ae2bfd57fe9815030f5 X f2ade50a7d734deeb61c536abcb7234b--55c6a2e389ab4ae2bfd57fe9815030f5 55c6a2e389ab4ae2bfd57fe9815030f5--092900477d3d431a82734e616c4c761c 55c6a2e389ab4ae2bfd57fe9815030f5--b7067f7003e14bbea86e89f0cb8afa81 b4a6b90c32774378b2ec0e3549377294 f45b7c3888c44cf493c16c2f9a3ed149 RX(p1\u2083) 00aa95522afa44e3b423b3818cea5d4e--f45b7c3888c44cf493c16c2f9a3ed149 d14a4066ffac404b98830d92afca7954 RY(p1\u2087) f45b7c3888c44cf493c16c2f9a3ed149--d14a4066ffac404b98830d92afca7954 35f747ac84304f78bb541e3844f7e9f3 RX(p1\u2081\u2081) d14a4066ffac404b98830d92afca7954--35f747ac84304f78bb541e3844f7e9f3 d320be68e29344d59d732e99d0b77191 X 35f747ac84304f78bb541e3844f7e9f3--d320be68e29344d59d732e99d0b77191 d320be68e29344d59d732e99d0b77191--6f1c5df81f5d4c058241ff77ef5ff858 c88434f5dc934cac9787b90b90586961 d320be68e29344d59d732e99d0b77191--c88434f5dc934cac9787b90b90586961 e01f6752276543c5b6abfc52b5e5a6ce RX(p1\u2081\u2085) c88434f5dc934cac9787b90b90586961--e01f6752276543c5b6abfc52b5e5a6ce 9f609863704342c4bdd9f852a463bb90 RY(p1\u2081\u2089) e01f6752276543c5b6abfc52b5e5a6ce--9f609863704342c4bdd9f852a463bb90 abca9971a4a1448abfc39e8ede83c070 RX(p1\u2082\u2083) 9f609863704342c4bdd9f852a463bb90--abca9971a4a1448abfc39e8ede83c070 f53ff139b9d842a9af32fdff7eaec63a X abca9971a4a1448abfc39e8ede83c070--f53ff139b9d842a9af32fdff7eaec63a f53ff139b9d842a9af32fdff7eaec63a--22b77ba32ffd45679738edc7fc000505 f8b307a4f7244e2ea10d205f7bc300db f53ff139b9d842a9af32fdff7eaec63a--f8b307a4f7244e2ea10d205f7bc300db e9f14b14ad6346f98f721e5c8d3f6c14 RX(p2\u2083) f8b307a4f7244e2ea10d205f7bc300db--e9f14b14ad6346f98f721e5c8d3f6c14 8bde671c191a41169895fd3e52acec46 RY(p2\u2087) e9f14b14ad6346f98f721e5c8d3f6c14--8bde671c191a41169895fd3e52acec46 ceaf442f753243e59d4a200efe390ceb RX(p2\u2081\u2081) 8bde671c191a41169895fd3e52acec46--ceaf442f753243e59d4a200efe390ceb 1afb55701e1d4efbb0ed2609e5b322f7 X ceaf442f753243e59d4a200efe390ceb--1afb55701e1d4efbb0ed2609e5b322f7 1afb55701e1d4efbb0ed2609e5b322f7--99543b1bbf3b4e998760ecca02396bf8 4f3b03429726485c942326215e01b23a 1afb55701e1d4efbb0ed2609e5b322f7--4f3b03429726485c942326215e01b23a 61821cc445944b3ea2600bd61731ea41 RX(p2\u2081\u2085) 4f3b03429726485c942326215e01b23a--61821cc445944b3ea2600bd61731ea41 f8f8dd4dcb6c415d8844a92a7b15009e RY(p2\u2081\u2089) 61821cc445944b3ea2600bd61731ea41--f8f8dd4dcb6c415d8844a92a7b15009e 371e778df18e459f8862223cfb6c607d RX(p2\u2082\u2083) f8f8dd4dcb6c415d8844a92a7b15009e--371e778df18e459f8862223cfb6c607d ffd5ea8b6ab144dfa2570788ffd5441b X 371e778df18e459f8862223cfb6c607d--ffd5ea8b6ab144dfa2570788ffd5441b ffd5ea8b6ab144dfa2570788ffd5441b--f2ade50a7d734deeb61c536abcb7234b 8d8511a116bd4c6ab9eeb1559a922d82 ffd5ea8b6ab144dfa2570788ffd5441b--8d8511a116bd4c6ab9eeb1559a922d82 8d8511a116bd4c6ab9eeb1559a922d82--b4a6b90c32774378b2ec0e3549377294 </p> <p>The <code>hea</code> function will be further explored in the QML Constructors tutorial.</p>"},{"location":"tutorials/parameters/#parametric-observables","title":"Parametric observables","text":"<p>In Qadence, one can define quantum observables with classical optimizable parameters to improve the convergence of QML calculations. This is particularly useful for differentiable quantum circuits.</p> <pre><code>from qadence import VariationalParameter, Z, add, tag\ns = VariationalParameter(\"s\")\nobservable = add(s * Z(i) for i in range(n_qubits))\n</code></pre> <p>Now, a quantum model can be created with the parametric observable. The observable variational parameters are included among the model ones.</p> <pre><code>from qadence import QuantumModel, QuantumCircuit\ncircuit = QuantumCircuit(n_qubits, hea(n_qubits, depth))\nmodel = QuantumModel(circuit, observable=observable)\n</code></pre> <pre><code>Variational parameters = OrderedDict([('s', tensor([0.6032])), ('theta_0', tensor([0.7060])), ('theta_1', tensor([0.8729])), ('theta_10', tensor([0.5824])), ('theta_11', tensor([0.7651])), ('theta_12', tensor([0.7259])), ('theta_13', tensor([0.8999])), ('theta_14', tensor([0.5249])), ('theta_15', tensor([0.8056])), ('theta_16', tensor([0.8753])), ('theta_17', tensor([0.9508])), ('theta_18', tensor([0.5994])), ('theta_19', tensor([0.5960])), ('theta_2', tensor([0.3586])), ('theta_20', tensor([0.0068])), ('theta_21', tensor([0.4744])), ('theta_22', tensor([0.3152])), ('theta_23', tensor([0.4480])), ('theta_3', tensor([0.7231])), ('theta_4', tensor([0.2878])), ('theta_5', tensor([0.8199])), ('theta_6', tensor([0.4943])), ('theta_7', tensor([0.6892])), ('theta_8', tensor([0.0667])), ('theta_9', tensor([0.9967]))])\n</code></pre> <p>One optimization step (forward and backward pass) can be performed using built-in <code>torch</code> functionalities. Variational parameters can be checked to have been updated accordingly:</p> <pre><code>import torch\nmse_loss = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters())\n# Compute forward &amp; backward pass\noptimizer.zero_grad()\nloss = mse_loss(model.expectation({}), torch.zeros(1))\nloss.backward()\n# Update the parameters and check the parameters.\noptimizer.step()\n</code></pre> <pre><code>Variational parameters = OrderedDict([('s', tensor([0.6022])), ('theta_0', tensor([0.7070])), ('theta_1', tensor([0.8719])), ('theta_10', tensor([0.5834])), ('theta_11', tensor([0.7661])), ('theta_12', tensor([0.7269])), ('theta_13', tensor([0.9009])), ('theta_14', tensor([0.5259])), ('theta_15', tensor([0.8066])), ('theta_16', tensor([0.8763])), ('theta_17', tensor([0.9518])), ('theta_18', tensor([0.5984])), ('theta_19', tensor([0.5970])), ('theta_2', tensor([0.3596])), ('theta_20', tensor([0.0078])), ('theta_21', tensor([0.4754])), ('theta_22', tensor([0.3162])), ('theta_23', tensor([0.4490])), ('theta_3', tensor([0.7241])), ('theta_4', tensor([0.2888])), ('theta_5', tensor([0.8209])), ('theta_6', tensor([0.4953])), ('theta_7', tensor([0.6902])), ('theta_8', tensor([0.0677])), ('theta_9', tensor([0.9957]))])\n</code></pre>"},{"location":"tutorials/parameters/#non-unitary-circuits","title":"Non-unitary circuits","text":"<p>Qadence allows composing with non-unitary blocks. Here is an example of a non-unitary block as a sum of Pauli operators with complex coefficients.</p> <p>Currently, only the <code>PyQTorch</code> backend fully supports execution of non-unitary circuits.</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, Z, X\nc1 = 2.0\nc2 = 2.0 + 2.0j\nblock = c1 * Z(0) + c2 * X(1) + c1 * c2 * (Z(2) + X(3))\ncircuit = QuantumCircuit(4, block)\nmodel = QuantumModel(circuit)  # BackendName.PYQTORCH and DiffMode.AD by default.\n</code></pre> <pre><code>wf = tensor([[6.+4.j, 4.+4.j, 0.+0.j, 0.+0.j, 2.+2.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre>"},{"location":"tutorials/quantummodels/","title":"Quantum models","text":"<p>A quantum program can be expressed and executed using the <code>QuantumModel</code> type. It serves three primary purposes:</p> <p>Parameter handling: by conveniently handling and embedding the two parameter types that Qadence supports: feature and variational (see more details in the next section).</p> <p>Differentiability: by enabling a differentiable backend that supports two differentiable modes: automated differentiation (AD) and parameter shift rule (PSR). The former is used to differentiate non-gate parameters and enabled for PyTorch-based simulators only. The latter is used to differentiate gate parameters and is enabled for all backends.</p> <p>Execution: by defining which backend the program is expected to be executed on. Qadence supports circuit compilation to the native backend representation.</p> <p>Backends</p> <p>Quantum models can execute on a number of different purpose backends: simulators, emulators or real hardware. By default, Qadence executes on the PyQTorch backend which implements a state vector simulator. Other choices include the Pulser backend (pulse sequences on programmable neutral atom arrays).  For more information see the backend section.</p> <p>The base <code>QuantumModel</code> exposes the following methods:</p> <ul> <li><code>QuantumModel.run()</code>: To extract the wavefunction after circuit execution. Not supported by all backends.</li> <li><code>QuantumModel.sample()</code>: Sample a bitstring from the resulting quantum state after circuit execution. Supported by all backends.</li> <li><code>QuantumModel.expectation()</code>: Compute the expectation value of an observable.</li> </ul> <p>Every <code>QuantumModel</code> is an instance of a <code>torch.nn.Module</code> that enables differentiability for its <code>expectation</code> method.</p> <p>Upon construction of the model, a compiled version of the abstract <code>QuantumCircuit</code> is created:</p> <pre><code>from qadence import QuantumCircuit, QuantumModel, RX, Z, chain, BackendName, Parameter\n# Construct a parametrized abstract circuit.\n# At this point we cannot run anything yet.\nx = Parameter(\"x\")\nn_qubits = 2\nblock = chain(RX(0, x), RX(1, x))\ncircuit = QuantumCircuit(n_qubits, block)\nobservable = Z(0)\n# Construct a QuantumModel which will compile\n# the abstract circuit to targetted backend.\n# By default, diff_mode=DiffMode.AD.\nmodel = QuantumModel(circuit, observable, backend=BackendName.PYQTORCH)\n# The converted circuit is a private attribute and should not\n# manually be tampered with, but we can at least verify its there\n# by printing it.\n</code></pre> <pre><code>model._circuit.native = QuantumCircuit(\n(operations): ModuleList(\n(0): QuantumCircuit(\n(operations): ModuleList(\n(0): ParametricPyQOperation(\n(operation): RX(qubits=(0,), n_qubits=2)\n)\n(1): ParametricPyQOperation(\n(operation): RX(qubits=(1,), n_qubits=2)\n)\n)\n)\n)\n)\n</code></pre> <p>Now, the wavefunction, sample, or expectation value are computable by passing a batch of values :</p> <pre><code>import torch\n# Set a batch of random parameter values.\nvalues = {\"x\": torch.rand(3)}\nwf = model.run(values)\nxs = model.sample(values, n_shots=100)\nex = model.expectation(values)\n</code></pre> <pre><code>wf = tensor([[ 0.9968+0.0000j,  0.0000-0.0567j,  0.0000-0.0567j, -0.0032+0.0000j],\n[ 0.9533+0.0000j,  0.0000-0.2109j,  0.0000-0.2109j, -0.0467+0.0000j],\n[ 0.9707+0.0000j,  0.0000-0.1686j,  0.0000-0.1686j, -0.0293+0.0000j]])\nxs = [Counter({'00': 100}), Counter({'00': 92, '10': 5, '11': 2, '01': 1}), Counter({'00': 95, '01': 4, '10': 1})]\nex = tensor([[0.9936],\n[0.9067],\n[0.9414]], requires_grad=True)\n</code></pre> <p>You can also measure multiple observables by passing a list of blocks.</p> <pre><code># By default, backend=BackendName.PYQTORCH.\nmodel = QuantumModel(circuit, [Z(0), Z(1)])\nex = model.expectation(values)\n</code></pre> <pre><code>ex = tensor([[0.9936, 0.9936],\n[0.9067, 0.9067],\n[0.9414, 0.9414]], requires_grad=True)\n</code></pre>"},{"location":"tutorials/quantummodels/#quantum-neural-network-qnn","title":"Quantum Neural Network (QNN)","text":"<p>The <code>QNN</code> is a subclass of the <code>QuantumModel</code> geared towards quantum machine learning and parameter optimisation. See the quantum machine learning section section or the <code>QNN</code> API reference for more detailed information, and the parametric program tutorial for parameterization.</p>"},{"location":"tutorials/register/","title":"Quantum registers","text":"<p>In Qadence, quantum programs can be executed by specifying the layout of a register of resources as a lattice. Built-in <code>Register</code> types can be used or constructed for arbitrary topologies. Common register topologies are available and illustrated in the plot below.</p> 2023-10-25T16:45:30.263497 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"tutorials/register/#building-and-drawing-registers","title":"Building and drawing registers","text":"<p>Built-in topologies are directly accessible in the <code>Register</code>:</p> <pre><code>from qadence import Register\nreg = Register.honeycomb_lattice(2, 3)\nreg.draw(show=False)\n</code></pre> 2023-10-25T16:45:31.045616 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ <p>Arbitrarily shaped registers can be constructed by providing coordinates.</p> <p>Registers defined from coordinates</p> <p><code>Register</code> constructed via the <code>from_coordinates</code> method do not define edges in the connectivity graph.</p> <pre><code>import numpy as np\nfrom qadence import Register\nreg = Register.from_coordinates(\n[(x, np.sin(x)) for x in np.linspace(0, 2*np.pi, 10)]\n)\nreg.draw(show=False)\n</code></pre> 2023-10-25T16:45:31.162106 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ <p>Units for qubit coordinates</p> <p>Qubits coordinates in Qadence are dimensionless but converted to the required unit when executed on a backend. For instance, Pulser uses \\(\\mu \\textrm{m}\\).</p>"},{"location":"tutorials/register/#connectivity-graphs","title":"Connectivity graphs","text":"<p>Register topology is often assumed in simulations to be an all-to-all qubit connectivity. When running on real devices that enable the digital-analog computing paradigm, qubit interaction must be specified either by specifying distances between qubits, or by defining edges in the register connectivity graph.</p> <p>It is possible to access the abstract graph nodes and edges to work with if needed as in the perfect state transfer example.</p> <pre><code>from qadence import Register\nreg = Register.rectangular_lattice(2,3)\n</code></pre> <pre><code>reg.nodes = NodeView((0, 1, 2, 3, 4, 5))\nreg.edges = EdgeView([(0, 2), (0, 1), (1, 3), (2, 4), (2, 3), (3, 5), (4, 5)])\n</code></pre> <p>It is possible to customize qubit interaction through the <code>add_interaction</code> method. In that case, <code>Register.coords</code> are accessible from the concrete graph:</p> <pre><code>print(f\"{reg.coords = }\")\n</code></pre> <pre><code>reg.coords = {0: (0.0, 0.0), 1: (0.0, 1.0), 2: (1.0, 0.0), 3: (1.0, 1.0), 4: (2.0, 0.0), 5: (2.0, 1.0)}\n</code></pre> <p>More details about their usage in the digital-analog paradigm can be found in the digital-analog basics section.</p>"},{"location":"tutorials/serializ_and_prep/","title":"Serialization","text":"<p>Qadence offers convenience functions for serializing and deserializing any quantum program. This is useful for storing quantum programs and sending them for execution over the network via an API.</p> <p>Note</p> <p>Qadence currently uses a custom JSON serialization as interchange format. Support for QASM format for digital quantum programs is currently under consideration.</p> <ul> <li><code>serialize/deserialize</code>: serialize and deserialize a Qadence object into a dictionary</li> <li><code>save/load</code>: save and load a Qadence object to a file with one of the supported   formats. Currently, these are <code>.json</code> and the PyTorch-compatible <code>.pt</code> format.</li> </ul> <p>Let's start with serialization into a dictionary.</p> <pre><code>import torch\nfrom qadence import QuantumCircuit, QuantumModel, DiffMode\nfrom qadence import chain, hamiltonian_factory, feature_map, hea, Z\nfrom qadence.serialization import serialize, deserialize\nn_qubits = 4\nmy_block = chain(feature_map(n_qubits, param=\"x\"), hea(n_qubits, depth=2))\nobs = hamiltonian_factory(n_qubits, detuning=Z)\n# Use the block defined above to create a quantum circuit\n# serialize/deserialize it\nqc = QuantumCircuit(n_qubits, my_block)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n# Let's wrap it in a QuantumModel\n# and serialize it\nqm = QuantumModel(qc, obs, diff_mode=DiffMode.AD)\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Check if the loaded QuantumModel returns the same expectation\nvalues = {\"x\": torch.rand(10)}\nassert torch.allclose(qm.expectation(values=values), qm_deserialized.expectation(values=values))\n</code></pre> <p>Finally, we can save the quantum circuit and the model with the two supported formats.</p> <pre><code>from qadence.serialization import serialize, deserialize, save, load, SerializationFormat\nqc_fname = \"circuit\"\nsave(qc, folder=\".\", file_name=qc_fname, format=SerializationFormat.PT)\nloaded_qc = load(f\"{qc_fname}.pt\")\nassert qc == loaded_qc\nqm_fname = \"model\"\nsave(qm, folder=\".\", file_name=qm_fname, format=SerializationFormat.JSON)\nmodel = load(f\"{qm_fname}.json\")\nassert isinstance(model, QuantumModel)\n</code></pre>"},{"location":"tutorials/state_conventions/","title":"State Conventions","text":"<p>Here is an overview of the state conventions used in Qadence together with practical examples.</p>"},{"location":"tutorials/state_conventions/#qubit-register-order","title":"Qubit register order","text":"<p>Qubit registers in quantum computing are often indexed in increasing or decreasing order from left to right. In Qadence, the convention is qubit indexation in increasing order. For example, a register of four qubits in bra-ket notation reads:</p> \\[|q_0, q_1, q_2, q_3\\rangle\\] <p>Furthermore, when displaying a quantum circuit, qubits are ordered from top to bottom.</p>"},{"location":"tutorials/state_conventions/#basis-state-order","title":"Basis state order","text":"<p>Basis state ordering refers to how basis states are ordered when considering the conversion from bra-ket notation to the standard linear algebra basis. In Qadence, basis states are ordered in the following manner:</p> \\[ \\begin{align} |00\\rangle = [1, 0, 0, 0]^T\\\\ |01\\rangle = [0, 1, 0, 0]^T\\\\ |10\\rangle = [0, 0, 1, 0]^T\\\\ |11\\rangle = [0, 0, 0, 1]^T \\end{align} \\]"},{"location":"tutorials/state_conventions/#endianness","title":"Endianness","text":"<p>Endianness refers to the storage convention for binary information (in bytes) in a classical memory register. In quantum computing, information is either stored in bits or in qubits. The most commonly used conventions are:</p> <ul> <li>A big-endian system stores the most significant bit of a binary word at the smallest memory address.</li> <li>A little-endian system stores the least significant bit of a binary word at the smallest memory address.</li> </ul> <p>Given the register convention in Qadence, the integer \\(2\\) written in binary big-endian as \\(10\\) can be encoded in a qubit register in both big-endian as \\(|10\\rangle\\) or little-endian as \\(|01\\rangle\\).</p> <p>The convention for Qadence is big-endian.</p>"},{"location":"tutorials/state_conventions/#quantum-states","title":"Quantum states","text":"<p>In practical scenarios, conventions regarding register order, basis state order and endianness are very much intertwined, and identical results can be obtained by fixing or varying any of them. In Qadence, we assume that qubit ordering and basis state ordering is fixed, and allow an <code>endianness</code> argument that can be passed to control the expected result. Here are a few examples:</p> <p>A simple and direct way to exemplify the endianness convention is using convenience functions for state preparation.</p> <p>Bitstring convention as inputs</p> <p>When a bitstring is passed as input to a function for state preparation, it has to be understood in big-endian convention.</p> <pre><code>from qadence import Endianness, product_state\n# The state |10&gt;, the 3rd basis state.\nstate_big = product_state(\"10\", endianness=Endianness.BIG) # or just \"Big\"\n# The state |01&gt;, the 2nd basis state.\nstate_little = product_state(\"10\", endianness=Endianness.LITTLE) # or just \"Little\"\n</code></pre> <pre><code>State in big endian = tensor([[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]])\nState in little endian = tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> <p>Here, a bitword expressed as a Python string to encode the integer 2 in big-endian is used to create the respective basis state in both conventions. However, note that the same results can be obtained by fixing the endianness convention as big-endian (thus creating the state \\(|10\\rangle\\) in both cases), and changing the basis state ordering. A similar argument holds for fixing both endianness and basis state ordering and simply changing the qubit index order.</p> <p>Another example where endianness directly comes into play is when measuring a register. A big- or little-endian measurement will choose the first or the last qubit, respectively, as the most significant bit. Let's see this in an example:</p> <pre><code>from qadence import I, H, sample\n# Create superposition state: |00&gt; + |01&gt; (normalized)\nblock = I(0) @ H(1)  # Identity on qubit 0, Hadamard on qubit 1\n# Generate bitword samples following both conventions\n# Samples \"00\" and \"01\"\nresult_big = sample(block, endianness=Endianness.BIG)\n# Samples \"00\" and \"10\"\nresult_little = sample(block, endianness=Endianness.LITTLE)\n</code></pre> <pre><code>Sample in big endian = [Counter({'00': 53, '01': 47})]\nSample in little endian = [Counter({'10': 60, '00': 40})]\n</code></pre> <p>In Qadence, endianness can be flipped for many relevant objects:</p> <pre><code>from qadence import invert_endianness\n# Equivalent to sampling in little-endian.\nflip_big_sample = invert_endianness(result_big)\n# Equivalent to a state created in little-endian.\nflip_big_state = invert_endianness(state_big)\n</code></pre> <pre><code>Flipped sample = [Counter({'00': 53, '10': 47})]\nFlipped state = tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre>"},{"location":"tutorials/state_conventions/#quantum-operations","title":"Quantum operations","text":"<p>When looking at the matricial form of quantum operations, the usage of the term endianness becomes slightly abusive. To exemplify, we may consider the <code>CNOT</code> operation with <code>control = 0</code> and <code>target = 1</code>. This operation is often described with two different matrices:</p> \\[ \\text{CNOT(0, 1)} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ \\end{bmatrix} \\qquad \\text{or} \\qquad \\text{CNOT(0, 1)} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} \\] <p>The difference can be easily explained either by considering a different ordering of the qubit indices, or a different ordering of the basis states. In Qadence, both can be retrieved through the <code>endianness</code> argument:</p> <pre><code>from qadence import block_to_tensor, CNOT\nmatrix_big = block_to_tensor(CNOT(0, 1), endianness=Endianness.BIG)\nmatrix_little = block_to_tensor(CNOT(0, 1), endianness=Endianness.LITTLE)\n</code></pre> <pre><code>CNOT matrix in big endian =\ntensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]]])\nCNOT matrix in little endian =\ntensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]]])\n</code></pre>"},{"location":"tutorials/state_conventions/#backends","title":"Backends","text":"<p>An important part of having clear state conventions is that we need to make sure our results are consistent accross different computational backends, which may have their own conventions. In Qadence, this is taken care of automatically: by calling operations for different backends, the result is expected to be equivalent up to qubit ordering.</p> <pre><code>from qadence import BackendName, RX, run, sample\nimport torch\n# RX(pi/4) on qubit 1\nn_qubits = 2\nop = RX(1, torch.pi/4)\n</code></pre> <pre><code>Same sampling order in big endian:\nOn PyQTorch = [Counter({'00': 89, '01': 11})]\nOn Braket = [Counter({'00': 87, '01': 13})]\nOn Pulser = [Counter({'00': 88, '01': 12})]\nSame wavefunction order:\nOn PyQTorch = tensor([[0.9239+0.0000j, 0.0000-0.3827j, 0.0000+0.0000j, 0.0000+0.0000j]])\nOn Braket = tensor([[0.9239+0.0000j, 0.0000-0.3827j, 0.0000+0.0000j, 0.0000+0.0000j]])\nOn Pulser = tensor([[0.9223+0.0000j, 0.0000-0.3865j, 0.0000+0.0000j, 0.0000+0.0000j]])\n</code></pre>"},{"location":"tutorials/state_init/","title":"State initialization","text":"<p>Qadence offers convenience routines for preparing initial quantum states. These routines are divided into two approaches:</p> <ul> <li>As a dense matrix.</li> <li>From a suitable quantum circuit. This is available for every backend and it should be added in front of the desired quantum circuit to simulate.</li> </ul> <p>Let's illustrate the usage of the state preparation routine.</p> <pre><code>from qadence import random_state, product_state, is_normalized, StateGeneratorType\n# Random initial state.\n# the default `type` is StateGeneratorType.HaarMeasureFast\nstate = random_state(n_qubits=2, type=StateGeneratorType.RANDOM_ROTATIONS)\n# Check the normalization.\nassert is_normalized(state)\n# Product state from a given bitstring.\n# NB: Qadence follows the big endian convention.\nstate = product_state(\"01\")\n</code></pre> <pre><code>Random initial state generated with rotations:\nstate = [ 0.58118498+0.j          0.        -0.81374446j  0.        -0.0038541j\n-0.0053963 +0.j        ]\nProduct state corresponding to bitstring '01':\nstate = [0.+0.j 1.+0.j 0.+0.j 0.+0.j]\n</code></pre> <p>Now we see how to generate the product state corresponding to the one above with a suitable quantum circuit.</p> <p><pre><code>from qadence import product_block, tag, hea, QuantumCircuit\nfrom qadence.draw import display\nstate_prep_block = product_block(\"01\")\n# display(state_prep_block)\n# Let's now prepare a circuit.\nn_qubits = 4\nstate_prep_block = product_block(\"0001\")\ntag(state_prep_block, \"Prep block\")\ncircuit_block = tag(hea(n_qubits, depth = 2), \"Circuit block\")\nqc_with_state_prep = QuantumCircuit(n_qubits, state_prep_block, circuit_block)\n</code></pre> %3 cluster_816cb842ffae43f3990255449ce8f50d Circuit block cluster_7a3d965a37454a81b27c93400f5b85a4 Prep block 89e28c26b1114782adcfc19b77609f4b 0 851751bb566f491b96bf33013526a77f 89e28c26b1114782adcfc19b77609f4b--851751bb566f491b96bf33013526a77f 03fba14459054177a2810b1a5f43cc7b 1 fa8a4c99bf2b415cb072f1888c92af7a RX(theta\u2080) 851751bb566f491b96bf33013526a77f--fa8a4c99bf2b415cb072f1888c92af7a 2c05a345e99946d19df69439138ee532 RY(theta\u2084) fa8a4c99bf2b415cb072f1888c92af7a--2c05a345e99946d19df69439138ee532 e64875f7912c4fb39fe3e6c431df4bd4 RX(theta\u2088) 2c05a345e99946d19df69439138ee532--e64875f7912c4fb39fe3e6c431df4bd4 94f1b868eb944469aeb7a3173dd1eaee e64875f7912c4fb39fe3e6c431df4bd4--94f1b868eb944469aeb7a3173dd1eaee ee9bfa48433a467a8b8039d1fde62265 94f1b868eb944469aeb7a3173dd1eaee--ee9bfa48433a467a8b8039d1fde62265 5a334550d3e5498fa101650e6c903a13 RX(theta\u2081\u2082) ee9bfa48433a467a8b8039d1fde62265--5a334550d3e5498fa101650e6c903a13 b58d9fc4186c48a1b14fb1e538ba8039 RY(theta\u2081\u2086) 5a334550d3e5498fa101650e6c903a13--b58d9fc4186c48a1b14fb1e538ba8039 712165eba6c542c68efcfaf4ddce7697 RX(theta\u2082\u2080) b58d9fc4186c48a1b14fb1e538ba8039--712165eba6c542c68efcfaf4ddce7697 978495cfbc954a188d85ecdaac9757d5 712165eba6c542c68efcfaf4ddce7697--978495cfbc954a188d85ecdaac9757d5 528c14ec6eb94d7ea8c9b5eceeeeddd8 978495cfbc954a188d85ecdaac9757d5--528c14ec6eb94d7ea8c9b5eceeeeddd8 44aae52292854a288b77e9e717c169d1 528c14ec6eb94d7ea8c9b5eceeeeddd8--44aae52292854a288b77e9e717c169d1 108aea92da344a09994143b51bf1539c f321dfbee0fb4b0f97f20de53b40139f 03fba14459054177a2810b1a5f43cc7b--f321dfbee0fb4b0f97f20de53b40139f 10a72475655f467faeafaf1c4787d24b 2 a4cb14169187477692dee8e857be17ae RX(theta\u2081) f321dfbee0fb4b0f97f20de53b40139f--a4cb14169187477692dee8e857be17ae b99261790c7b4bb99679934ba9a7424f RY(theta\u2085) a4cb14169187477692dee8e857be17ae--b99261790c7b4bb99679934ba9a7424f c6e0f96ad233487ca7e14fda944dff1c RX(theta\u2089) b99261790c7b4bb99679934ba9a7424f--c6e0f96ad233487ca7e14fda944dff1c ed863512fdc542d09e92d66593f7b936 X c6e0f96ad233487ca7e14fda944dff1c--ed863512fdc542d09e92d66593f7b936 ed863512fdc542d09e92d66593f7b936--94f1b868eb944469aeb7a3173dd1eaee 74b5066066c849f78e0645f06dc21825 ed863512fdc542d09e92d66593f7b936--74b5066066c849f78e0645f06dc21825 503feabc785d4f37b2144113d151bba4 RX(theta\u2081\u2083) 74b5066066c849f78e0645f06dc21825--503feabc785d4f37b2144113d151bba4 5cc71377c36e484ba1443d278dbdc3d7 RY(theta\u2081\u2087) 503feabc785d4f37b2144113d151bba4--5cc71377c36e484ba1443d278dbdc3d7 713193e16bf84264b2dfc9945028f45b RX(theta\u2082\u2081) 5cc71377c36e484ba1443d278dbdc3d7--713193e16bf84264b2dfc9945028f45b aaa3870e12594031a99f985813b5ec38 X 713193e16bf84264b2dfc9945028f45b--aaa3870e12594031a99f985813b5ec38 aaa3870e12594031a99f985813b5ec38--978495cfbc954a188d85ecdaac9757d5 3e674b7edeb041fbbd9408b52e1cca58 aaa3870e12594031a99f985813b5ec38--3e674b7edeb041fbbd9408b52e1cca58 3e674b7edeb041fbbd9408b52e1cca58--108aea92da344a09994143b51bf1539c 7dcc7674d3164adf907f3023a086608a 62ea3a6001074106809d90cba7a1e955 10a72475655f467faeafaf1c4787d24b--62ea3a6001074106809d90cba7a1e955 a029c968d9d44d87bde7680d1ce3a360 3 c1fd52ae4be247b28a47f9f6edc718cb RX(theta\u2082) 62ea3a6001074106809d90cba7a1e955--c1fd52ae4be247b28a47f9f6edc718cb 9b6f0f61867143ba87d1a15e4669cbff RY(theta\u2086) c1fd52ae4be247b28a47f9f6edc718cb--9b6f0f61867143ba87d1a15e4669cbff f482f7f2793f4f259ac75f6bdc765029 RX(theta\u2081\u2080) 9b6f0f61867143ba87d1a15e4669cbff--f482f7f2793f4f259ac75f6bdc765029 97bb660f3ca2428f973e627f61709d23 f482f7f2793f4f259ac75f6bdc765029--97bb660f3ca2428f973e627f61709d23 fb6da9d8e5ed4f688435db9cb57d5f4a X 97bb660f3ca2428f973e627f61709d23--fb6da9d8e5ed4f688435db9cb57d5f4a fb6da9d8e5ed4f688435db9cb57d5f4a--74b5066066c849f78e0645f06dc21825 762def0c97c646a2ad0d21bc6ce22421 RX(theta\u2081\u2084) fb6da9d8e5ed4f688435db9cb57d5f4a--762def0c97c646a2ad0d21bc6ce22421 697ff0354789444c807dcafd17cb31c6 RY(theta\u2081\u2088) 762def0c97c646a2ad0d21bc6ce22421--697ff0354789444c807dcafd17cb31c6 687ce6eef7b94c088d4af623600a44a1 RX(theta\u2082\u2082) 697ff0354789444c807dcafd17cb31c6--687ce6eef7b94c088d4af623600a44a1 87c9b19c883e42fc941e1672bc82eede 687ce6eef7b94c088d4af623600a44a1--87c9b19c883e42fc941e1672bc82eede 8fd2617e620d4a87bf3ea8643664cc0a X 87c9b19c883e42fc941e1672bc82eede--8fd2617e620d4a87bf3ea8643664cc0a 8fd2617e620d4a87bf3ea8643664cc0a--3e674b7edeb041fbbd9408b52e1cca58 8fd2617e620d4a87bf3ea8643664cc0a--7dcc7674d3164adf907f3023a086608a 33bff10b04c24da4b1facbb7a1f5d17f 08bec690ce7045249cf1c82284ab416d X a029c968d9d44d87bde7680d1ce3a360--08bec690ce7045249cf1c82284ab416d e7e6ab72dcbc4c7aa6cdae053792ad21 RX(theta\u2083) 08bec690ce7045249cf1c82284ab416d--e7e6ab72dcbc4c7aa6cdae053792ad21 7dc18f8b115b469cad1475979cf16ec1 RY(theta\u2087) e7e6ab72dcbc4c7aa6cdae053792ad21--7dc18f8b115b469cad1475979cf16ec1 99f7061bac334d56b48a544a896ed65b RX(theta\u2081\u2081) 7dc18f8b115b469cad1475979cf16ec1--99f7061bac334d56b48a544a896ed65b 9242f81729d847609ac17d4c5ed7e7bc X 99f7061bac334d56b48a544a896ed65b--9242f81729d847609ac17d4c5ed7e7bc 9242f81729d847609ac17d4c5ed7e7bc--97bb660f3ca2428f973e627f61709d23 655a34c061d64bddbcba2a3aa4b76ccf 9242f81729d847609ac17d4c5ed7e7bc--655a34c061d64bddbcba2a3aa4b76ccf 6c8c500277bc468c8fbbaae893ac4503 RX(theta\u2081\u2085) 655a34c061d64bddbcba2a3aa4b76ccf--6c8c500277bc468c8fbbaae893ac4503 226641a169884f598c8f2d268b8715e8 RY(theta\u2081\u2089) 6c8c500277bc468c8fbbaae893ac4503--226641a169884f598c8f2d268b8715e8 c846995a8cd54069944c0b623e34c64c RX(theta\u2082\u2083) 226641a169884f598c8f2d268b8715e8--c846995a8cd54069944c0b623e34c64c 6272c2e2458e4ea2a3d76c08deafe3c0 X c846995a8cd54069944c0b623e34c64c--6272c2e2458e4ea2a3d76c08deafe3c0 6272c2e2458e4ea2a3d76c08deafe3c0--87c9b19c883e42fc941e1672bc82eede d570b6db92fa4709a1adfff66fb3e422 6272c2e2458e4ea2a3d76c08deafe3c0--d570b6db92fa4709a1adfff66fb3e422 d570b6db92fa4709a1adfff66fb3e422--33bff10b04c24da4b1facbb7a1f5d17f  Several standard quantum states can be conveniently initialized in Qadence, both in statevector form as well as in block form as shown in following.</p>"},{"location":"tutorials/state_init/#state-vector-initialization","title":"State vector initialization","text":"<p>Qadence offers a number of constructor functions for state vector preparation.</p> <pre><code>from qadence import uniform_state, zero_state, one_state\nn_qubits = 3\nbatch_size = 2\nuniform_state = uniform_state(n_qubits, batch_size)\nzero_state = zero_state(n_qubits, batch_size)\none_state = one_state(n_qubits, batch_size)\n</code></pre> <pre><code>Uniform state = tensor([[0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j,\n0.3536+0.j],\n[0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j,\n0.3536+0.j]])\nZero state = tensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\nOne state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre> <p>As already seen, product states can be easily created, even in batches:</p> <pre><code>from qadence import product_state, rand_product_state\n# From a bitsring \"100\"\nprod_state = product_state(\"100\", batch_size)\n# Or a random product state\nrand_state = rand_product_state(n_qubits, batch_size)\n</code></pre> <pre><code>Product state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\nRandom state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> <p>Creating a GHZ state:</p> <pre><code>from qadence import ghz_state\nghz = ghz_state(n_qubits, batch_size)\n</code></pre> <pre><code>GHZ state = tensor([[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n0.7071+0.j],\n[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n0.7071+0.j]])\n</code></pre> <p>Creating a random state uniformly sampled from a Haar measure:</p> <pre><code>from qadence import random_state\nrand_haar_state = random_state(n_qubits, batch_size)\n</code></pre> <pre><code>Random state from Haar = tensor([[-0.1938-0.0520j, -0.2004+0.3661j, -0.0483-0.0577j, -0.2657-0.3253j,\n0.4508+0.0664j,  0.2878+0.0577j, -0.2979+0.1222j, -0.0662+0.4491j],\n[ 0.2315-0.2451j,  0.2807+0.1053j, -0.3644+0.4587j, -0.0791+0.0530j,\n-0.0125-0.1685j,  0.2731-0.3878j, -0.3455-0.2506j, -0.0893-0.0241j]])\n</code></pre> <p>Custom initial states can then be passed to either <code>run</code>, <code>sample</code> and <code>expectation</code> through the <code>state</code> argument</p> <pre><code>from qadence import random_state, product_state, CNOT, run\ninit_state = product_state(\"10\")\nfinal_state = run(CNOT(0, 1), state=init_state)\n</code></pre> <pre><code>Final state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre>"},{"location":"tutorials/state_init/#block-initialization","title":"Block initialization","text":"<p>Not all backends support custom statevector initialization, however previous utility functions have their counterparts to initialize the respective blocks:</p> <pre><code>from qadence import uniform_block, one_block\nn_qubits = 3\nuniform_block = uniform_block(n_qubits)\none_block = one_block(n_qubits)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 H(0)\n\u251c\u2500\u2500 H(1)\n\u2514\u2500\u2500 H(2)\nKronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> <p>Similarly, for product states:</p> <pre><code>from qadence import product_block, rand_product_block\nproduct_block = product_block(\"100\")\nrand_product_block = rand_product_block(n_qubits)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 I(1)\n\u2514\u2500\u2500 I(2)\nKronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> <p>And GHZ states:</p> <pre><code>from qadence import ghz_block\nghz_block = ghz_block(n_qubits)\n</code></pre> <pre><code>ChainBlock(0,1,2)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 ChainBlock(0,1,2)\n\u251c\u2500\u2500 CNOT(0,1)\n\u2514\u2500\u2500 CNOT(1,2)\n</code></pre> <p>Initial state blocks can simply be chained at the start of a given circuit.</p>"},{"location":"tutorials/state_init/#utility-functions","title":"Utility functions","text":"<p>Some state vector utility functions are also available. We can easily create the probability mass function of a given statevector using <code>torch.distributions.Categorical</code></p> <pre><code>from qadence import random_state, pmf\nn_qubits = 3\nstate = random_state(n_qubits)\ndistribution = pmf(state)\n</code></pre> <pre><code>Categorical(probs: torch.Size([1, 8]))\n</code></pre> <p>We can also check if a state is normalized:</p> <pre><code>from qadence import random_state, is_normalized\nstate = random_state(n_qubits)\nprint(is_normalized(state))\n</code></pre> <pre><code>True\n</code></pre> <p>Or normalize a state:</p> <pre><code>import torch\nfrom qadence import normalize, is_normalized\nstate = torch.tensor([[1, 1, 1, 1]], dtype = torch.cdouble)\nprint(normalize(state))\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre>"}]}