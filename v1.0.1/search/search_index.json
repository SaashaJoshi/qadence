{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Qadence","text":"<p>Qadence is a Python package that provides a simple interface to build digital-analog quantum programs with tunable qubit interaction defined on arbitrary register topologies realizable on neutral atom devices.</p>"},{"location":"#feature-highlights","title":"Feature highlights","text":"<ul> <li> <p>A block-based system for composing complex digital-analog   programs in a flexible and scalable manner, inspired by the Julia quantum SDK   Yao.jl and functional programming concepts.</p> </li> <li> <p>A simple interface to work with interacting neutral-atom qubit systems   using arbitrary registers topologies.</p> </li> <li> <p>An intuitive expression-based system developed on top of the symbolic library Sympy to construct parametric quantum programs easily.</p> </li> <li> <p>High-order generalized parameter shift rules for differentiating parametrized quantum operations.</p> </li> <li> <p>Out-of-the-box automatic differentiability of quantum programs with PyTorch integration.</p> </li> <li> <p>Efficient execution on a variety of different purpose backends: from state vector simulators to tensor network emulators and real devices.</p> </li> </ul> <p>In following are some examples of Qadence possibilites in the analog, digital-analog and digital paradigms.</p>"},{"location":"#analog-emulation-of-a-perfect-state-transfer","title":"Analog emulation of a perfect state transfer","text":"<p>This next example showcases the construction and sampling of a system that admits a perfect state transfer between the two edge qubits of a three qubit register laid out in a line. This relies on time-evolving a Hamiltonian for a custom defined qubit interation until \\(t=\\frac{\\pi}{\\sqrt 2}\\).</p> <pre><code>from torch import pi\nfrom qadence import X, Y, HamEvo, Register, product_state, sample, add\n# Define the qubit-qubit interaction term.\ndef interaction(i, j):\nreturn 0.5 * (X(i) @ X(j) + Y(i) @ Y(j))  # Compose gates in parallel and sum their contribution.\n# Initial state with left-most qubit in the 1 state.\ninit_state = product_state(\"100\")\n# Define a register of 3 qubits laid out in a line.\nregister = Register.line(n_qubits=3)\n# Define an interaction Hamiltonian by summing interactions on indexed qubits.\n# hamiltonian = interaction(0, 1) + interaction(1, 2)\nhamiltonian = add(interaction(*edge) for edge in register.edges)\n# Define and time-evolve the Hamiltonian until t=pi/sqrt(2).\nt = pi/(2**0.5)  # Dimensionless.\nevolution = HamEvo(hamiltonian, t)\n# Sample with 100 shots.\nsamples = sample(register, evolution, state=init_state, n_shots=100)\n</code></pre> <pre><code>samples = [Counter({'001': 100})]\n</code></pre>"},{"location":"#digital-analog-example","title":"Digital-analog example","text":"<p>This final example deals with the construction and sampling of an Ising Hamiltonian that includes a distance-based interaction between qubits and a global analog block of rotations around the \\(X\\)-axis. Here, global has to be understood as applied to the whole register for qubits.</p> <pre><code>from torch import pi\nfrom qadence import Register, AnalogRX, sample\n# Global analog RX block.\nblock = AnalogRX(pi)\n# Almost non-interacting qubits as too far apart.\nregister = Register.from_coordinates([(0,0), (0,15)])  # Dimensionless.\nsamples = sample(register, block)\n# Interacting qubits as close together.\nregister = Register.from_coordinates([(0,0), (0,5)])\nsamples = sample(register, AnalogRX(pi))\n</code></pre> <pre><code>distance = 15: samples = [Counter({'11': 100})]\ndistance =  5: samples = [Counter({'00': 36, '01': 35, '10': 29})]\n</code></pre>"},{"location":"#sampling-the-canonical-bell-state","title":"Sampling the canonical Bell state","text":"<p>This example illustrates how to prepare a Bell state using digital gates and sampling from the outcome bitstring distribution:</p> <pre><code>from qadence import CNOT, H, chain, sample\n# Preparing a Bell state by composing a Hadamard and CNOT gates in sequence.\nbell_state = chain(H(0), CNOT(0,1))\n# Sample with 100 shots.\nsamples = sample(bell_state, n_shots=100)\n</code></pre> <pre><code>samples = [Counter({'00': 53, '11': 47})]\n</code></pre>"},{"location":"#further-resources","title":"Further resources","text":"<p>For a more comprehensive introduction and advanced topics, please have a look at the following tutorials:</p> <ul> <li>Quantum state conventions used throughout Qadence.</li> <li>Basic tutorials for first hands-on.</li> <li>Digital-analog basics to build quantum programs in the digital-analog paradigm.</li> <li>Parametric quantum circuits for the generation and manipulation of parametric programs.</li> <li>Advanced features about low-level backend interface and differentiablity.</li> <li><code>QuantumModel</code> for defining custom models.</li> </ul>"},{"location":"#installation-guide","title":"Installation guide","text":"<p>Qadence can be installed from PyPI with <code>pip</code> as follows:</p> <pre><code>pip install qadence\n</code></pre> <p>The default backend for Qadence is PyQTorch, a differentiable state vector simulator for digital-analog simulation. It is possible to install additional backends and the circuit visualization library using the following extras:</p> <ul> <li><code>braket</code>: the Braket backend.</li> <li><code>pulser</code>: the Pulser backend for composing, simulating and executing pulse sequences for neutral-atom quantum devices.</li> <li><code>visualization</code>: to display diagrammatically quantum circuits.</li> </ul> <p>To just get qadence with the <code>pyqtorch</code> backend, simply run:</p> <pre><code>pip install qadence\n</code></pre> <p>To install other backends or the visualization tool, please use:</p> <pre><code>pip install \"qadence[braket, pulser, visualization]\"\n</code></pre> <p>Warning</p> <p>In order to correctly install the <code>visualization</code> extra, the <code>graphviz</code> package needs to be installed in your system:</p> <pre><code># on Ubuntu\nsudo apt install graphviz\n\n# on MacOS\nbrew install graphviz\n\n# via conda\nconda install python-graphviz\n</code></pre>"},{"location":"#citation","title":"Citation","text":"<p>If you use Qadence for a publication, we kindly ask you to cite our work using the following BibTex entry:</p> <pre><code>@misc{qadence2023pasqal,\n  url = {https://github.com/pasqal-io/qadence},\n  title = {Qadence: {A} {D}igital-analog quantum programming interface.},\n  year = {2023}\n}\n</code></pre>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CONTRIBUTING/","title":"How to contribute","text":"<p>We're grateful for your interest in participating in Qadence. Please follow our guidelines to ensure a smooth contribution process.</p>"},{"location":"CONTRIBUTING/#reporting-an-issue-or-proposing-a-feature","title":"Reporting an issue or proposing a feature","text":"<p>Your course of action will depend on your objective, but generally, you should start by creating an issue. If you've discovered a bug or have a feature you'd like to see added to qadence, feel free to create an issue on qadence's GitHub issue tracker. Here are some steps to take:</p> <ol> <li>Quickly search the existing issues using relevant keywords to ensure your issue hasn't been addressed already.</li> <li> <p>If your issue is not listed, create a new one. Try to be as detailed and clear as possible in your description.</p> </li> <li> <p>If you're merely suggesting an improvement or reporting a bug, that's already excellent! We thank you for it. Your issue will be listed and, hopefully, addressed at some point.</p> </li> <li>However, if you're willing to be the one solving the issue, that would be even better! In such instances, you would proceed by preparing a Pull Request.</li> </ol>"},{"location":"CONTRIBUTING/#submitting-a-pull-request","title":"Submitting a pull request","text":"<p>We're excited that you're eager to contribute to Qadence. To contribute, fork the <code>main</code> branch of qadence repository and once you are satisfied with your feature and all the tests pass create a Pull Request.</p> <p>Here's the process for making a contribution:</p> <p>Click the \"Fork\" button at the upper right corner of the repo page to create a new GitHub repo at <code>https://github.com/USERNAME/qadence</code>, where <code>USERNAME</code> is your GitHub ID. Then, <code>cd</code> into the directory where you want to place your new fork and clone it:</p> <pre><code>git clone https://github.com/USERNAME/qadence.git\n</code></pre> <p>Next, navigate to your new qadence fork directory and mark the main qadence repository as the <code>upstream</code>:</p> <pre><code>git remote add upstream https://github.com/pasqal-io/qadence.git\n</code></pre>"},{"location":"CONTRIBUTING/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>We recommended to use <code>hatch</code> for managing environments:</p> <p>To develop within qadence, use: <pre><code>pip install hatch\nhatch -v shell\n</code></pre></p> <p>To run qadence tests, use:</p> <pre><code>hatch -e tests run test\n</code></pre> <p>If you don't want to use <code>hatch</code>, you can use the environment manager of your choice (e.g. Conda) and execute the following:</p> <pre><code>pip install pytest\npip install -e .\npytest\n</code></pre>"},{"location":"CONTRIBUTING/#useful-things-for-your-workflow-linting-and-testing","title":"Useful things for your workflow: linting and testing","text":"<p>Use <code>pre-commit</code> to lint your code and run the unit tests before pushing a new commit.</p> <p>Using <code>hatch</code>, it's simply:</p> <pre><code>hatch -e tests run pre-commit run --all-files\nhatch -e tests run test\n</code></pre> <p>Our CI/CD pipeline will also test if the documentation can be built correctly. To test it locally, please run:</p> <pre><code>hatch -e docs run mkdocs build --clean --strict\n</code></pre> <p>Without <code>hatch</code>, <code>pip</code> install those libraries first: \"mkdocs\", \"mkdocs-material\", \"mkdocstrings\", \"mkdocstrings-python\", \"mkdocs-section-index\", \"mkdocs-jupyter\", \"mkdocs-exclude\", \"markdown-exec\"</p> <p>And then:</p> <pre><code> mkdocs build --clean --strict\n</code></pre>"},{"location":"models/","title":"Quantum models","text":""},{"location":"models/#qadence.models.quantum_model.QuantumModel","title":"<code>QuantumModel(circuit, observable=None, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, protocol=None, configuration=None)</code>","text":"<p>             Bases: <code>Module</code></p> <p>The central class of qadence that executes <code>QuantumCircuit</code>s and make them differentiable.</p> <p>This class should be used as base class for any new quantum model supported in the qadence framework for information on the implementation of custom models see here.</p> <p>Initialize a generic QuantumModel instance.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>The circuit that is executed.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>observable</code> <p>Optional observable(s) that are used only in the <code>expectation</code> method. You can also provide observables on the fly to the expectation call directly.</p> <p> TYPE: <code>list[AbstractBlock] | AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>A backend for circuit execution.</p> <p> TYPE: <code>BackendName | str</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>A differentiability mode. Parameter shift based modes work on all backends. AD based modes only on PyTorch based backends.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>protocol</code> <p>Optional measurement protocol. If None, use exact expectation value with a statevector simulator.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>Configuration for the backend.</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>if the <code>diff_mode</code> argument is set to None</p> Source code in <code>qadence/models/quantum_model.py</code> <pre><code>def __init__(\nself,\ncircuit: QuantumCircuit,\nobservable: list[AbstractBlock] | AbstractBlock | None = None,\nbackend: BackendName | str = BackendName.PYQTORCH,\ndiff_mode: DiffMode = DiffMode.AD,\nprotocol: Measurements | None = None,\nconfiguration: BackendConfiguration | dict | None = None,\n):\n\"\"\"Initialize a generic QuantumModel instance.\n    Arguments:\n        circuit: The circuit that is executed.\n        observable: Optional observable(s) that are used only in the `expectation` method. You\n            can also provide observables on the fly to the expectation call directly.\n        backend: A backend for circuit execution.\n        diff_mode: A differentiability mode. Parameter shift based modes work on all backends.\n            AD based modes only on PyTorch based backends.\n        protocol: Optional measurement protocol. If None, use\n            exact expectation value with a statevector simulator.\n        configuration: Configuration for the backend.\n    Raises:\n        ValueError: if the `diff_mode` argument is set to None\n    \"\"\"\nsuper().__init__()\nif not isinstance(circuit, QuantumCircuit):\nTypeError(\nf\"The circuit should be of type '&lt;class QuantumCircuit&gt;'. Got {type(circuit)}.\"\n)\nself.inputs = [p for p in circuit.unique_parameters if not p.trainable and not p.is_number]\nif diff_mode is None:\nraise ValueError(\"`diff_mode` cannot be `None` in a `QuantumModel`.\")\nself.backend = backend_factory(\nbackend=backend, diff_mode=diff_mode, configuration=configuration\n)\nif isinstance(observable, list) or observable is None:\nobservable = observable\nelse:\nobservable = [observable]\nconv = self.backend.convert(circuit, observable)\nself.embedding_fn = conv.embedding_fn\nself._circuit = conv.circuit\nself._observable = conv.observable\nself._backend_name = backend\nself._diff_mode = diff_mode\nself._protocol = protocol\nself._params = nn.ParameterDict(\n{\nstr(key): nn.Parameter(val, requires_grad=val.requires_grad)\nfor key, val in conv.params.items()\n}\n)\n</code></pre>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.in_features","title":"<code>in_features: int</code>  <code>property</code>","text":"<p>Number of inputs.</p>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.num_vparams","title":"<code>num_vparams: int</code>  <code>property</code>","text":"<p>The number of variational parameters</p>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.out_features","title":"<code>out_features: int | None</code>  <code>property</code>","text":"<p>Number of outputs</p>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.vals_vparams","title":"<code>vals_vparams: Tensor</code>  <code>property</code>","text":"<p>Dictionary with parameters which are actually updated during optimization</p>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.assign_parameters","title":"<code>assign_parameters(values)</code>","text":"<p>Return the final, assigned circuit that is used in e.g. <code>backend.run</code></p> Source code in <code>qadence/models/quantum_model.py</code> <pre><code>def assign_parameters(self, values: dict[str, Tensor]) -&gt; Any:\n\"\"\"Return the final, assigned circuit that is used in e.g. `backend.run`\"\"\"\nparams = self.embedding_fn(self._params, values)\nreturn self.backend.assign_parameters(self._circuit, params)\n</code></pre>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.expectation","title":"<code>expectation(values={}, observable=None, state=None, protocol=None, endianness=Endianness.BIG)</code>","text":"<p>Compute expectation using the given backend.</p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor of shape n_batches x n_obs</p> Source code in <code>qadence/models/quantum_model.py</code> <pre><code>def expectation(\nself,\nvalues: dict[str, Tensor] = {},\nobservable: list[ConvertedObservable] | ConvertedObservable | None = None,\nstate: Optional[Tensor] = None,\nprotocol: Measurements | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Compute expectation using the given backend.\n    Returns:\n        A torch.Tensor of shape n_batches x n_obs\n    \"\"\"\nif observable is None:\nif self._observable is None:\nraise ValueError(\n\"Provide an AbstractBlock as the observable to compute expectation.\"\n\"Either pass a 'native_observable' directly to 'QuantumModel.expectation'\"\n\"or pass a (non-native) '&lt;class AbstractBlock&gt;' to the 'QuantumModel.__init__'.\"\n)\nobservable = self._observable\nparams = self.embedding_fn(self._params, values)\nif protocol is None:\nprotocol = self._protocol\nreturn self.backend.expectation(\ncircuit=self._circuit,\nobservable=observable,\nparam_values=params,\nstate=state,\nprotocol=protocol,\nendianness=endianness,\n)\n</code></pre>"},{"location":"models/#qadence.models.quantum_model.QuantumModel.reset_vparams","title":"<code>reset_vparams(values)</code>","text":"<p>Reset all the variational parameters with a given list of values</p> Source code in <code>qadence/models/quantum_model.py</code> <pre><code>def reset_vparams(self, values: Sequence) -&gt; None:\n\"\"\"Reset all the variational parameters with a given list of values\"\"\"\ncurrent_vparams = OrderedDict({k: v for k, v in self._params.items() if v.requires_grad})\nassert (\nlen(values) == self.num_vparams\n), \"Pass an iterable with the values of all variational parameters\"\nfor i, k in enumerate(current_vparams.keys()):\ncurrent_vparams[k].data = torch.tensor([values[i]])\n</code></pre>"},{"location":"models/#qadence.models.qnn.QNN","title":"<code>QNN(circuit, observable, transform=None, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD, protocol=None, configuration=None)</code>","text":"<p>             Bases: <code>QuantumModel</code></p> <p>Quantum neural network model for n-dimensional inputs</p> <p>Examples: <pre><code>import torch\nfrom qadence import QuantumCircuit, QNN\nfrom qadence import hea, feature_map, hamiltonian_factory, Z\n# create the circuit\nn_qubits, depth = 2, 4\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nobs_base = hamiltonian_factory(n_qubits, detuning = Z)\n# the QNN will yield two outputs\nobs = [2.0 * obs_base, 4.0 * obs_base]\n# initialize and use the model\nqnn = QNN(circuit, obs, diff_mode=\"ad\", backend=\"pyqtorch\")\ny = qnn.expectation({\"phi\": torch.rand(3)})\n</code></pre> <pre><code>tensor([[0.7110, 1.4221],\n[1.6172, 3.2344],\n[1.1616, 2.3231]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> </p> <p>Initialize the QNN</p> <p>The number of inputs is determined by the feature parameters in the input quantum circuit while the number of outputs is determined by how many observables are provided as input</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>The quantum circuit to use for the QNN.</p> <p> TYPE: <code>QuantumCircuit</code> </p> <code>transform</code> <p>A transformation applied to the output of the QNN.</p> <p> TYPE: <code>Callable[[Tensor], Tensor]</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>The chosen quantum backend.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>The differentiation engine to use. Choices 'gpsr' or 'ad'.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>protocol</code> <p>optional measurement protocol. If None, use exact expectation value with a statevector simulator</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>configuration</code> <p>optional configuration for the backend</p> <p> TYPE: <code>BackendConfiguration | dict | None</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/models/qnn.py</code> <pre><code>def __init__(\nself,\ncircuit: QuantumCircuit,\nobservable: list[AbstractBlock] | AbstractBlock,\ntransform: Callable[[Tensor], Tensor] = None,  # transform output of the QNN\nbackend: BackendName = BackendName.PYQTORCH,\ndiff_mode: DiffMode = DiffMode.AD,\nprotocol: Measurements | None = None,\nconfiguration: BackendConfiguration | dict | None = None,\n):\n\"\"\"Initialize the QNN\n    The number of inputs is determined by the feature parameters in the input\n    quantum circuit while the number of outputs is determined by how many\n    observables are provided as input\n    Args:\n        circuit: The quantum circuit to use for the QNN.\n        transform: A transformation applied to the output of the QNN.\n        backend: The chosen quantum backend.\n        diff_mode: The differentiation engine to use. Choices 'gpsr' or 'ad'.\n        protocol: optional measurement protocol. If None,\n            use exact expectation value with a statevector simulator\n        configuration: optional configuration for the backend\n    \"\"\"\nsuper().__init__(\ncircuit=circuit,\nobservable=observable,\nbackend=backend,\ndiff_mode=diff_mode,\nprotocol=protocol,\nconfiguration=configuration,\n)\nif self.out_features is None:\nraise ValueError(\"You need to provide at least one observable in the QNN constructor\")\nself.transform = transform if transform else lambda x: x\n</code></pre>"},{"location":"models/#qadence.models.qnn.QNN.forward","title":"<code>forward(values=None, state=None, protocol=None, endianness=Endianness.BIG)</code>","text":"<p>Forward pass of the model</p> <p>This returns the (differentiable) expectation value of the given observable operator defined in the constructor. Differently from the base QuantumModel class, the QNN accepts also a tensor as input for the forward pass. The tensor is expected to have shape: <code>n_batches x in_features</code> where <code>n_batches</code> is the number of data points and <code>in_features</code> is the dimensionality of the problem</p> <p>The output of the forward pass is the expectation value of the input observable(s). If a single observable is given, the output shape is <code>n_batches</code> while if multiple observables are given the output shape is instead <code>n_batches x n_observables</code></p> PARAMETER  DESCRIPTION <code>values</code> <p>the values of the feature parameters</p> <p> TYPE: <code>dict[str, Tensor] | Tensor</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a tensor with the expectation value of the observables passed in the constructor of the model</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/models/qnn.py</code> <pre><code>def forward(\nself,\nvalues: dict[str, Tensor] | Tensor = None,\nstate: Tensor | None = None,\nprotocol: Measurements | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Forward pass of the model\n    This returns the (differentiable) expectation value of the given observable\n    operator defined in the constructor. Differently from the base QuantumModel\n    class, the QNN accepts also a tensor as input for the forward pass. The\n    tensor is expected to have shape: `n_batches x in_features` where `n_batches`\n    is the number of data points and `in_features` is the dimensionality of the problem\n    The output of the forward pass is the expectation value of the input\n    observable(s). If a single observable is given, the output shape is\n    `n_batches` while if multiple observables are given the output shape\n    is instead `n_batches x n_observables`\n    Args:\n        values (dict[str, Tensor] | Tensor): the values of the feature parameters\n    Returns:\n        Tensor: a tensor with the expectation value of the observables passed\n            in the constructor of the model\n    \"\"\"\nif values is None:\nvalues = {}\nif not isinstance(values, dict):\nvalues = self._format_to_dict(values)\nif protocol is None:\nprotocol = self._protocol\nreturn self.transform(\nself.expectation(values=values, state=state, protocol=protocol, endianness=endianness)\n)\n</code></pre>"},{"location":"advanced_tutorials/custom-models/","title":"Custom quantum models","text":"<p>In <code>qadence</code>, the <code>QuantumModel</code> is the central class point for executing <code>QuantumCircuit</code>s.  The idea of a <code>QuantumModel</code> is to decouple the backend execution from the management of circuit parameters and desired quantum computation output.</p> <p>In the following, we create a custom <code>QuantumModel</code> instance which introduces some additional optimizable parameters: *  an adjustable scaling factor in front of the observable to measured *  adjustable scale and shift factors to be applied to the model output before returning the result</p> <p>This can be easily done using PyTorch flexible model definition, and it will automatically work with the rest of <code>qadence</code> infrastructure.</p> <pre><code>import torch\nfrom qadence import QuantumModel, QuantumCircuit\nclass CustomQuantumModel(QuantumModel):\ndef __init__(self, circuit: QuantumCircuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\"):\nsuper().__init__(circuit, observable=observable, backend=backend, diff_mode=diff_mode)\nself.n_qubits = circuit.n_qubits\n# define some additional parameters which will scale and shift (variationally) the\n# output of the QuantumModel\n# you can use all torch machinery for building those\nself.scale_out = torch.nn.Parameter(torch.ones(1))\nself.shift_out = torch.nn.Parameter(torch.ones(1))\n# override the forward pass of the model\n# the forward pass is the output of your QuantumModel and in this case\n# it's the (scaled) expectation value of the total magnetization with\n# a variable coefficient in front\ndef forward(self, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\n# scale the observable\nres = self.expectation(values)\n# scale and shift the result before returning\nreturn self.shift_out + res * self.scale_out\n</code></pre> <p>The custom model can be used like any other <code>QuantumModel</code>: <pre><code>from qadence import Parameter, RX, CNOT, QuantumCircuit\nfrom qadence import chain, kron, hamiltonian_factory, Z\nfrom sympy import acos\ndef quantum_circuit(n_qubits):\nx = Parameter(\"x\", trainable=False)\nfm = kron(RX(i, acos(x) * (i+1)) for i in range(n_qubits))\nansatz = kron(RX(i, f\"theta{i}\") for i in range(n_qubits))\nansatz = chain(ansatz, CNOT(0, n_qubits-1))\nblock = chain(fm, ansatz)\nblock.tag = \"circuit\"\nreturn QuantumCircuit(n_qubits, block)\nn_qubits = 4\nbatch_size = 10\ncircuit = quantum_circuit(n_qubits)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)  # Total magnetization\nmodel = CustomQuantumModel(circuit, observable, backend=\"pyqtorch\")\nvalues = {\"x\": torch.rand(batch_size)}\nres = model(values)\nprint(\"Model output: \", res)\nassert len(res) == batch_size\n</code></pre> <pre><code>Model output:  tensor([[ 1.0910],\n[-0.3106],\n[-0.0326],\n[-0.2145],\n[-0.1543],\n[-0.5374],\n[-0.5529],\n[-0.0691],\n[-0.0888],\n[-0.4947]], grad_fn=&lt;AddBackward0&gt;)\n</code></pre> </p>"},{"location":"advanced_tutorials/custom-models/#quantum-model-with-wavefunction-overlaps","title":"Quantum model with wavefunction overlaps","text":"<p><code>QuantumModel</code>'s can also use different quantum operations in their forward pass, such as wavefunction overlaps described here. Beware that the resulting overlap tensor has to be differentiable to apply gradient-based optimization. This is only applicable to the <code>\"EXACT\"</code> overlap method.</p> <p>Here we show how to use overlap calculation when fitting a parameterized quantum circuit to act as a standard Hadamard gate.</p> <pre><code>from qadence import RY, RX, H, Overlap\n# create a quantum model which acts as an Hadamard gate after training\nclass LearnHadamard(QuantumModel):\ndef __init__(\nself,\ntrain_circuit: QuantumCircuit,\ntarget_circuit: QuantumCircuit,\nbackend=\"pyqtorch\",\n):\nsuper().__init__(circuit=train_circuit, backend=backend)\nself.overlap_fn = Overlap(train_circuit, target_circuit, backend=backend, method=\"exact\", diff_mode='ad')\ndef forward(self):\nreturn self.overlap_fn()\n# compute the wavefunction of the associated train circuit\ndef wavefunction(self):\nreturn model.overlap_fn.run({})\ntrain_circuit = QuantumCircuit(1, chain(RX(0, \"phi\"), RY(0, \"theta\")))\ntarget_circuit = QuantumCircuit(1, H(0))\nmodel = LearnHadamard(train_circuit, target_circuit)\n# get the overlap between model and target circuit wavefunctions\nprint(model())\n</code></pre> <pre><code>tensor([[0.5337]], grad_fn=&lt;UnsqueezeBackward0&gt;)\n</code></pre> <p>This model can then be trained with the standard Qadence helper functions.</p> <pre><code>from qadence import run\nfrom qadence.ml_tools import train_with_grad, TrainConfig\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\ndef loss_fn(model: LearnHadamard, _unused) -&gt; tuple[torch.Tensor, dict]:\nloss = criterion(torch.tensor([[1.0]]), model())\nreturn loss, {}\nconfig = TrainConfig(max_iter=2500)\nmodel, optimizer = train_with_grad(\nmodel, None, optimizer, config, loss_fn=loss_fn\n)\nwf_target = run(target_circuit)\nassert torch.allclose(wf_target, model.wavefunction(), atol=1e-2)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"advanced_tutorials/differentiability/","title":"Differentiability","text":"<p>Many application in quantum computing and quantum machine learning more specifically requires the differentiation of a quantum circuit with respect to its parameters.</p> <p>In Qadence, we perform quantum computations via the <code>QuantumModel</code> interface. The derivative of the outputs of quantum models with respect to feature and variational parameters in the quantum circuit can be implemented in Qadence with two different modes:</p> <ul> <li>Automatic differentiation (AD) mode <sup>1</sup>. This mode allows to differentiation both <code>run()</code> and <code>expectation()</code> methods of the <code>QuantumModel</code> and it is the fastest available differentiation method. Under the hood, it is based on the PyTorch autograd engine wrapped by the <code>DifferentiableBackend</code> class. This mode is not working on quantum devices.</li> <li>Generalized parameter shift rule (GPSR) mode. This is general implementation of the well known parameter  shift rule algorithm <sup>2</sup> which works for arbitrary quantum operations <sup>3</sup>. This mode is only applicable to  the <code>expectation()</code> method of <code>QuantumModel</code> but it is compatible with execution or quantum devices.</li> </ul>"},{"location":"advanced_tutorials/differentiability/#automatic-differentiation","title":"Automatic differentiation","text":"<p>Automatic differentiation <sup>1</sup> is a procedure to derive a complex function defined as a sequence of elementary mathematical operations in the form of a computer program. Automatic differentiation is a cornerstone of modern machine learning and a crucial ingredient of its recent successes. In its so-called reverse mode, it follows this sequence of operations in reverse order by systematically applying the chain rule to recover the exact value of derivative. Reverse mode automatic differentiation is implemented in Qadence leveraging the PyTorch <code>autograd</code> engine.</p> <p>Only available with PyQTorch backend</p> <p>Currently, automatic differentiation mode is only available when the <code>pyqtorch</code> backend is selected.</p>"},{"location":"advanced_tutorials/differentiability/#generalized-parameter-shift-rule","title":"Generalized parameter shift rule","text":"<p>The generalized parameter shift rule implementation in Qadence was introduced in <sup>3</sup>. Here the standard parameter shift rules, which only works for quantum operations whose generator has a single gap in its eigenvalue spectrum, was generalized to work with arbitrary generators of quantum operations.</p> <p>For this, we define the differentiable function as quantum expectation value</p> \\[ f(x) = \\left\\langle 0\\right|\\hat{U}^{\\dagger}(x)\\hat{C}\\hat{U}(x)\\left|0\\right\\rangle \\] <p>where \\(\\hat{U}(x)={\\rm exp}{\\left( -i\\frac{x}{2}\\hat{G}\\right)}\\) is the quantum evolution operator with generator \\(\\hat{G}\\) representing the structure of the underlying quantum circuit and \\(\\hat{C}\\) is the cost operator. Then using the eigenvalue spectrum \\(\\left\\{ \\lambda_n\\right\\}\\) of the generator \\(\\hat{G}\\) we calculate the full set of corresponding unique non-zero spectral gaps \\(\\left\\{ \\Delta_s\\right\\}\\) (differences between eigenvalues). It can be shown that the final expression of derivative of \\(f(x)\\) is then given by the following expression:</p> <p>\\(\\begin{equation} \\frac{{\\rm d}f\\left(x\\right)}{{\\rm d}x}=\\overset{S}{\\underset{s=1}{\\sum}}\\Delta_{s}R_{s}, \\end{equation}\\)</p> <p>where \\(S\\) is the number of unique non-zero spectral gaps and \\(R_s\\) are real quantities that are solutions of a system of linear equations</p> <p>\\(\\begin{equation} \\begin{cases} F_{1} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{1}\\Delta_{s}}{2}\\right)R_{s},\\\\ F_{2} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{2}\\Delta_{s}}{2}\\right)R_{s},\\\\  &amp; ...\\\\ F_{S} &amp; =4\\overset{S}{\\underset{s=1}{\\sum}}{\\rm sin}\\left(\\frac{\\delta_{M}\\Delta_{s}}{2}\\right)R_{s}. \\end{cases} \\end{equation}\\)</p> <p>Here \\(F_s=f(x+\\delta_s)-f(x-\\delta_s)\\) denotes the difference between values of functions evaluated at shifted arguments \\(x\\pm\\delta_s\\).</p>"},{"location":"advanced_tutorials/differentiability/#usage","title":"Usage","text":""},{"location":"advanced_tutorials/differentiability/#basics","title":"Basics","text":"<p>In Qadence, the GPSR differentiation engine can be selected by passing <code>diff_mode=\"gpsr\"</code> or, equivalently, <code>diff_mode=DiffMode.GPSR</code> to a <code>QuantumModel</code> instance. The code in the box below shows how to create <code>QuantumModel</code> instances with both AD and GPSR engines.</p> <pre><code>from qadence import (FeatureParameter, HamEvo, X, I, Z,\nhamiltonian_factory, QuantumCircuit,\nQuantumModel, BackendName, DiffMode)\nimport torch\nn_qubits = 2\n# define differentiation parameter\nx = FeatureParameter(\"x\")\n# define generator and HamEvo block\ngenerator = X(0) + X(1) + 0.2 * (Z(0) + I(1)) * (I(0) + Z(1))\nblock = HamEvo(generator, x)\n# create quantum circuit\ncircuit = QuantumCircuit(n_qubits, block)\n# create total magnetization cost operator\nobs = hamiltonian_factory(n_qubits, detuning=Z)\n# create models with AD and GPSR differentiation engines\nmodel_ad = QuantumModel(circuit, obs,\nbackend=BackendName.PYQTORCH,\ndiff_mode=DiffMode.AD)\nmodel_gpsr = QuantumModel(circuit, obs,\nbackend=BackendName.PYQTORCH,\ndiff_mode=DiffMode.GPSR)\n# generate value for circuit's parameter\nxs = torch.linspace(0, 2*torch.pi, 100, requires_grad=True)\nvalues = {\"x\": xs}\n# calculate function f(x)\nexp_val_ad = model_ad.expectation(values)\nexp_val_gpsr = model_gpsr.expectation(values)\n# calculate derivative df/dx using the PyTorch\n# autograd engine\ndexpval_x_ad = torch.autograd.grad(\nexp_val_ad, values[\"x\"], torch.ones_like(exp_val_ad), create_graph=True\n)[0]\ndexpval_x_gpsr = torch.autograd.grad(\nexp_val_gpsr, values[\"x\"], torch.ones_like(exp_val_gpsr), create_graph=True\n)[0]\n</code></pre> <p>We can plot the resulting derivatives and see that in both cases they coincide.</p> <pre><code>import matplotlib.pyplot as plt\n# plot f(x) and df/dx derivatives calculated using AD and GPSR\n# differentiation engines\nfig, ax = plt.subplots()\nax.scatter(xs.detach().numpy(),\nexp_val_ad.detach().numpy(),\nlabel=\"f(x)\")\nax.scatter(xs.detach().numpy(),\ndexpval_x_ad.detach().numpy(),\nlabel=\"df/dx AD\")\nax.scatter(xs.detach().numpy(),\ndexpval_x_gpsr.detach().numpy(),\ns=5,\nlabel=\"df/dx GPSR\")\nplt.legend()\n</code></pre> 2023-10-12T16:59:35.006041 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"advanced_tutorials/differentiability/#low-level-control-on-the-shift-values","title":"Low-level control on the shift values","text":"<p>In order to get a finer control over the GPSR differentiation engine we can use the low-level Qadence API to define a <code>DifferentiableBackend</code>.</p> <pre><code>from qadence import DifferentiableBackend\nfrom qadence.backends.pyqtorch import Backend as PyQBackend\n# define differentiable quantum backend\nquantum_backend = PyQBackend()\nconv = quantum_backend.convert(circuit, obs)\npyq_circ, pyq_obs, embedding_fn, params = conv\ndiff_backend = DifferentiableBackend(quantum_backend, diff_mode=DiffMode.GPSR, shift_prefac=0.2)\n# calculate function f(x)\nexpval = diff_backend.expectation(pyq_circ, pyq_obs, embedding_fn(params, values))\n</code></pre> <p>Here we passed an additional argument <code>shift_prefac</code> to the <code>DifferentiableBackend</code> instance that governs the magnitude of shifts \\(\\delta\\equiv\\alpha\\delta^\\prime\\) shown in equation (2) above. In this relation \\(\\delta^\\prime\\) is set internally and \\(\\alpha\\) is the value passed by <code>shift_prefac</code> and the resulting shift value \\(\\delta\\) is then used in all the following GPSR calculations.</p> <p>Tuning parameter \\(\\alpha\\) is useful to improve results when the generator \\(\\hat{G}\\) or the quantum operation is a dense matrix, for example a complex <code>HamEvo</code> operation; if many entries of this matrix are sufficiently larger than 0 the operation is equivalent to a strongly interacting system. In such case parameter \\(\\alpha\\) should be gradually lowered in order to achieve exact derivative values.</p>"},{"location":"advanced_tutorials/differentiability/#references","title":"References","text":"<ol> <li> <p>A. G. Baydin et al., Automatic Differentiation in Machine Learning: a Survey \u21a9\u21a9</p> </li> <li> <p>Schuld et al., Evaluating analytic gradients on quantum hardware (2018). \u21a9</p> </li> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9\u21a9</p> </li> </ol>"},{"location":"backends/backend/","title":"Abstract backend","text":""},{"location":"backends/backend/#qadence.backend.Backend","title":"<code>Backend</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ABC</code></p> <p>The abstract class that defines the interface for the backends</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>backend unique string identifier</p> <p> TYPE: <code>BackendName</code> </p> <code>supports_ad</code> <p>whether or not the backend has a native autograd</p> <p> TYPE: <code>bool</code> </p> <code>supports_bp</code> <p>whether or not the backend has a native backprop</p> <p> TYPE: <code>bool</code> </p> <code>is_remote</code> <p>whether computations are executed locally or remotely on this backend, useful when using cloud platforms where credentials are needed for example.</p> <p> TYPE: <code>bool</code> </p> <code>with_measurements</code> <p>whether it supports counts or not</p> <p> TYPE: <code>bool</code> </p> <code>with_noise</code> <p>whether to add realistic noise or not</p> <p> TYPE: <code>bool</code> </p>"},{"location":"backends/backend/#qadence.backend.Backend.circuit","title":"<code>circuit(circuit)</code>  <code>abstractmethod</code>","text":"<p>Converts an abstract <code>QuantumCircuit</code> to the native backend representation.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A circuit, for example: <code>QuantumCircuit(2, X(0))</code></p> <p> TYPE: <code>QuantumCircuit</code> </p> RETURNS DESCRIPTION <code>ConvertedCircuit</code> <p>A converted circuit <code>c</code>. You can access the original, arbstract circuit via <code>c.abstract</code></p> <code>ConvertedCircuit</code> <p>and the converted (or backend native) circuit via <code>c.native</code>.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef circuit(self, circuit: QuantumCircuit) -&gt; ConvertedCircuit:\n\"\"\"Converts an abstract `QuantumCircuit` to the native backend representation.\n    Arguments:\n        circuit: A circuit, for example: `QuantumCircuit(2, X(0))`\n    Returns:\n        A converted circuit `c`. You can access the original, arbstract circuit via `c.abstract`\n        and the converted (or backend *native*) circuit via `c.native`.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.convert","title":"<code>convert(circuit, observable=None)</code>","text":"<p>Convert an abstract circuit (and optionally and observable) to their native representation. Additionally this function constructs an embedding function which maps from user-facing parameters to device parameters (read more on parameter embedding here).</p> Source code in <code>qadence/backend.py</code> <pre><code>def convert(\nself, circuit: QuantumCircuit, observable: list[AbstractBlock] | AbstractBlock | None = None\n) -&gt; Converted:\n\"\"\"Convert an abstract circuit (and optionally and observable) to their native\n    representation. Additionally this function constructs an embedding function which maps from\n    user-facing parameters to device parameters (read more on parameter embedding\n    [here][qadence.blocks.embedding.embedding]).\n    \"\"\"\ndef check_observable(obs_obj: Any) -&gt; AbstractBlock:\nif isinstance(obs_obj, QubitOperator):\nfrom qadence.blocks.manipulate import from_openfermion\nassert len(obs_obj.terms) &gt; 0, \"Make sure to give a non-empty qubit hamiltonian\"\nreturn from_openfermion(obs_obj)\nelif isinstance(obs_obj, (CompositeBlock, PrimitiveBlock, ScaleBlock)):\nfrom qadence.blocks.utils import block_is_qubit_hamiltonian\nassert block_is_qubit_hamiltonian(\nobs_obj\n), \"Make sure the QubitHamiltonian consists only of Pauli operators X, Y, Z, I\"\nreturn obs_obj\nraise TypeError(\n\"qubit_hamiltonian should be a Pauli-like AbstractBlock or a QubitOperator\"\n)\nconv_circ = self.circuit(circuit)\ncirc_params, circ_embedding_fn = embedding(\nconv_circ.abstract.block, self.config._use_gate_params\n)\nparams = circ_params\nif observable is not None:\nobservable = observable if isinstance(observable, list) else [observable]\nconv_obs = []\nobs_embedding_fn_list = []\nfor obs in observable:\nobs = check_observable(obs)\nc_obs = self.observable(obs, max(circuit.n_qubits, obs.n_qubits))\nobs_params, obs_embedding_fn = embedding(\nc_obs.abstract, self.config._use_gate_params\n)\nparams.update(obs_params)\nobs_embedding_fn_list.append(obs_embedding_fn)\nconv_obs.append(c_obs)\ndef embedding_fn_dict(a: dict, b: dict) -&gt; dict:\nembedding_dict = circ_embedding_fn(a, b)\nfor o in obs_embedding_fn_list:\nembedding_dict.update(o(a, b))\nreturn embedding_dict\nreturn Converted(conv_circ, conv_obs, embedding_fn_dict, params)\ndef embedding_fn(a: dict, b: dict) -&gt; dict:\nreturn circ_embedding_fn(a, b)\nreturn Converted(conv_circ, None, embedding_fn, params)\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, protocol=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Compute the expectation value of the <code>circuit</code> with the given <code>observable</code>.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bitstrings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef expectation(\nself,\ncircuit: ConvertedCircuit,\nobservable: list[ConvertedObservable] | ConvertedObservable,\nparam_values: dict[str, Tensor] = {},\nstate: Tensor | None = None,\nprotocol: Measurements | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Compute the expectation value of the `circuit` with the given `observable`.\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        endianness: Endianness of the resulting bitstrings.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.observable","title":"<code>observable(observable, n_qubits)</code>  <code>abstractmethod</code>","text":"<p>Converts an abstract observable (which is just an <code>AbstractBlock</code>) to the native backend representation.</p> PARAMETER  DESCRIPTION <code>observable</code> <p>An observable.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>n_qubits</code> <p>Number of qubits the observable covers. This is typically <code>circuit.n_qubits</code>.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ConvertedObservable</code> <p>A converted observable <code>o</code>. You can access the original, arbstract observable via</p> <code>ConvertedObservable</code> <p><code>o.abstract</code> and the converted (or backend native) observable via <code>o.native</code>.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef observable(self, observable: AbstractBlock, n_qubits: int) -&gt; ConvertedObservable:\n\"\"\"Converts an abstract observable (which is just an `AbstractBlock`) to the native backend\n    representation.\n    Arguments:\n        observable: An observable.\n        n_qubits: Number of qubits the observable covers. This is typically `circuit.n_qubits`.\n    Returns:\n        A converted observable `o`. You can access the original, arbstract observable via\n        `o.abstract` and the converted (or backend *native*) observable via `o.native`.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.run","title":"<code>run(circuit, param_values={}, state=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Run a circuit and return the resulting wave function.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting samples.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A list of Counter objects where each key represents a bitstring</p> <code>Tensor</code> <p>and its value the number of times it has been sampled from the given wave function.</p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef run(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor] = {},\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Run a circuit and return the resulting wave function.\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        state: Initial state.\n        endianness: Endianness of the resulting samples.\n    Returns:\n        A list of Counter objects where each key represents a bitstring\n        and its value the number of times it has been sampled from the given wave function.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.Backend.sample","title":"<code>sample(circuit, param_values={}, n_shots=1000, state=None, endianness=Endianness.BIG)</code>  <code>abstractmethod</code>","text":"<p>Sample bit strings.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A converted circuit as returned by <code>backend.circuit</code>.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Already embedded parameters of the circuit. See <code>embedding</code> for more info.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>n_shots</code> <p>Number of shots to sample.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1000</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the resulting bitstrings.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>@abstractmethod\ndef sample(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor] = {},\nn_shots: int = 1000,\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n\"\"\"Sample bit strings.\n    Arguments:\n        circuit: A converted circuit as returned by `backend.circuit`.\n        param_values: _**Already embedded**_ parameters of the circuit. See\n            [`embedding`][qadence.blocks.embedding.embedding] for more info.\n        n_shots: Number of shots to sample.\n        state: Initial state.\n        endianness: Endianness of the resulting bitstrings.\n    \"\"\"\nraise NotImplementedError\n</code></pre>"},{"location":"backends/backend/#qadence.backend.BackendConfiguration","title":"<code>BackendConfiguration</code>  <code>dataclass</code>","text":""},{"location":"backends/backend/#qadence.backend.BackendConfiguration.available_options","title":"<code>available_options()</code>","text":"<p>Return as a string the available fields with types of the configuration</p> RETURNS DESCRIPTION <code>str</code> <p>a string with all the available fields, one per line</p> <p> TYPE: <code>str</code> </p> Source code in <code>qadence/backend.py</code> <pre><code>def available_options(self) -&gt; str:\n\"\"\"Return as a string the available fields with types of the configuration\n    Returns:\n        str: a string with all the available fields, one per line\n    \"\"\"\nconf_msg = \"\"\nfor field in fields(self):\nif not field.name.startswith(\"_\"):\nconf_msg += (\nf\"Name: {field.name} - Type: {field.type} - Default value: {field.default}\\n\"\n)\nreturn conf_msg\n</code></pre>"},{"location":"backends/backend/#qadence.backend.BackendConfiguration.get_param_name","title":"<code>get_param_name(blk)</code>","text":"<p>Return parameter names for the current backend. Depending on which backend is in use this function returns either UUIDs or expressions of parameters.</p> Source code in <code>qadence/backend.py</code> <pre><code>def get_param_name(self, blk: AbstractBlock) -&gt; Tuple[str, ...]:\n\"\"\"Return parameter names for the current backend. Depending on which backend is in use this\n    function returns either UUIDs or expressions of parameters.\"\"\"\nparam_ids: Tuple\n# FIXME: better type hiearchy?\ntypes = (TimeEvolutionBlock, ParametricBlock, ConstantAnalogRotation, WaitBlock)\nif not isinstance(blk, types):\nraise TypeError(f\"Can not infer param name from {type(blk)}\")\nelse:\nif self._use_gate_params:\nparam_ids = tuple(blk.parameters.uuids())\nelse:\nparam_ids = tuple(map(stringify, blk.parameters.expressions()))\nreturn param_ids\n</code></pre>"},{"location":"backends/braket/","title":"Amazon Braket","text":""},{"location":"backends/braket/#braket-digital-backend","title":"Braket Digital backend","text":""},{"location":"backends/braket/#qadence.backends.braket.backend.Backend","title":"<code>Backend</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Backend</code></p>"},{"location":"backends/braket/#qadence.backends.braket.backend.Backend.assign_parameters","title":"<code>assign_parameters(circuit, param_values)</code>","text":"<p>Assign numerical values to the circuit parameters</p> Source code in <code>qadence/backends/braket/backend.py</code> <pre><code>def assign_parameters(\nself, circuit: ConvertedCircuit, param_values: dict[str, Tensor | float]\n) -&gt; BraketCircuit:\n\"\"\"Assign numerical values to the circuit parameters\"\"\"\nif param_values is None:\nreturn circuit.native()\nparams_copy = param_values.copy()\npnames = [p.name for p in circuit.native.parameters]\n# account for fixed parameters\nfor name in param_values.keys():\nif name not in pnames:\nparams_copy.pop(name)\n# make sure that all the parameters are single floats\n# otherwise it won't be accepted by Braket\nnative_params = promote_parameters(params_copy)\n# assign the parameters to the circuit\nassigned_circuit = circuit.native(**native_params)\nreturn assigned_circuit\n</code></pre>"},{"location":"backends/braket/#qadence.backends.braket.backend.Backend.run","title":"<code>run(circuit, param_values={}, state=None, endianness=Endianness.BIG)</code>","text":"<p>Execute the circuit and return a wavefunction in form of a statevector.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>The circuit that is executed.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>Parameters of the circuit (after calling the embedding function on the user-facing parameters).</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>The endianness of the wave function.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> Source code in <code>qadence/backends/braket/backend.py</code> <pre><code>def run(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor] = {},\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"\n    Execute the circuit and return a wavefunction in form of a statevector.\n    Arguments:\n        circuit: The circuit that is executed.\n        param_values: Parameters of the circuit (after calling the embedding\n            function on the user-facing parameters).\n        state: Initial state.\n        endianness: The endianness of the wave function.\n    \"\"\"\nif state is not None:\nraise NotImplementedError\nif self.is_remote:\n# handle here, or different backends?\nraise NotImplementedError\n# loop over all values in the batch\nresults = []\nfor vals in to_list_of_dicts(param_values):\nfinal_circuit = self.assign_parameters(circuit, vals)\nfinal_circuit.state_vector()  # set simulation type\ntask = self._device.run(final_circuit, 0)\nresults.append(task.result().values[0])\nstates = torch.tensor(np.array(results))\nn_qubits = circuit.abstract.n_qubits\nif endianness != self.native_endianness and n_qubits &gt; 1:\nfrom qadence.transpile import invert_endianness\nstates = invert_endianness(states)\nreturn states\n</code></pre>"},{"location":"backends/braket/#qadence.backends.braket.backend.Backend.sample","title":"<code>sample(circuit, param_values={}, n_shots=1, state=None, endianness=Endianness.BIG)</code>","text":"<p>Execute the circuit and return samples of the resulting wavefunction.</p> Source code in <code>qadence/backends/braket/backend.py</code> <pre><code>def sample(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor] = {},\nn_shots: int = 1,\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n\"\"\"Execute the circuit and return samples of the resulting wavefunction.\"\"\"\nif state is not None:\nraise NotImplementedError(\"Braket cannot handle a custom initial state.\")\nif n_shots &lt; 1:\nraise ValueError(\"You can only call sample with n_shots&gt;0.\")\nif self.is_remote:\n# handle here, or different backends?\nraise NotImplementedError\n# loop over all values in the batch\nsamples = []\nfor vals in to_list_of_dicts(param_values):\nfinal_circuit = self.assign_parameters(circuit, vals)\ntask = self._device.run(final_circuit, n_shots)\nsamples.append(task.result().measurement_counts)\nif endianness != self.native_endianness:\nfrom qadence.transpile import invert_endianness\nsamples = invert_endianness(samples)\nreturn samples\n</code></pre>"},{"location":"backends/differentiable/","title":"DifferentiableBackend","text":""},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableBackend","title":"<code>DifferentiableBackend(backend, diff_mode=DiffMode.AD, **psr_args)</code>","text":"<p>             Bases: <code>Module</code></p> <p>A class to abstract the operations done by the autodiff engine</p> PARAMETER  DESCRIPTION <code>backend</code> <p>An instance of the QuantumBackend type perform execution.</p> <p> TYPE: <code>Backend</code> </p> <code>diff_mode</code> <p>A differentiable mode supported by the differentiation engine.</p> <p> TYPE: <code>DiffMode</code> DEFAULT: <code>AD</code> </p> <code>**psr_args</code> <p>Arguments that will be passed on to <code>DifferentiableExpectation</code>.</p> <p> TYPE: <code>int | float | None</code> DEFAULT: <code>{}</code> </p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>def __init__(\nself,\nbackend: QuantumBackend,\ndiff_mode: DiffMode = DiffMode.AD,\n**psr_args: int | float | None,\n) -&gt; None:\nsuper().__init__()\nself.backend = backend\nself.diff_mode = diff_mode\nself.psr_args = psr_args\n# TODO: Add differentiable overlap calculation\nself._overlap: Callable = None  # type: ignore [assignment]\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableBackend.expectation","title":"<code>expectation(circuit, observable, param_values={}, state=None, protocol=None, endianness=Endianness.BIG)</code>","text":"<p>Compute the expectation value of a given observable.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A backend native quantum circuit to be executed.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>observable</code> <p>A backend native observable to compute the expectation value from.</p> <p> TYPE: <code>list[ConvertedObservable] | ConvertedObservable</code> </p> <code>param_values</code> <p>A dict of values for symbolic substitution.</p> <p> TYPE: <code>dict[str, Tensor]</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>An initial state.</p> <p> TYPE: <code>Tensor | None</code> DEFAULT: <code>None</code> </p> <code>protocol</code> <p>A shot-based measurement protocol.</p> <p> TYPE: <code>Measurements | None</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>Endianness of the state.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A tensor of expectation values.</p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>def expectation(\nself,\ncircuit: ConvertedCircuit,\nobservable: list[ConvertedObservable] | ConvertedObservable,\nparam_values: dict[str, Tensor] = {},\nstate: Tensor | None = None,\nprotocol: Measurements | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Compute the expectation value of a given observable.\n    Arguments:\n        circuit: A backend native quantum circuit to be executed.\n        observable: A backend native observable to compute the expectation value from.\n        param_values: A dict of values for symbolic substitution.\n        state: An initial state.\n        protocol: A shot-based measurement protocol.\n        endianness: Endianness of the state.\n    Returns:\n        A tensor of expectation values.\n    \"\"\"\nobservable = observable if isinstance(observable, list) else [observable]\ndifferentiable_expectation = DifferentiableExpectation(\nbackend=self.backend,\ncircuit=circuit,\nobservable=observable,\nparam_values=param_values,\nstate=state,\nprotocol=protocol,\nendianness=endianness,\n)\nif self.diff_mode == DiffMode.AD:\nexpectation = differentiable_expectation.ad\nelse:\ntry:\nfns = get_gpsr_fns()\npsr_fn = fns[self.diff_mode]\nexcept KeyError:\nraise ValueError(f\"{self.diff_mode} differentiation mode is not supported\")\nexpectation = partial(differentiable_expectation.psr, psr_fn=psr_fn, **self.psr_args)\nreturn expectation()\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableBackend.run","title":"<code>run(circuit, param_values={}, state=None, endianness=Endianness.BIG)</code>","text":"<p>Run on the underlying backend.</p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>def run(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict = {},\nstate: Tensor | None = None,\nendianness: Endianness = Endianness.BIG,\n) -&gt; Tensor:\n\"\"\"Run on the underlying backend.\"\"\"\nreturn self.backend.run(\ncircuit=circuit, param_values=param_values, state=state, endianness=endianness\n)\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableBackend.sample","title":"<code>sample(circuit, param_values, state=None, n_shots=1, endianness=Endianness.BIG)</code>","text":"<p>Sample bitstring from the registered circuit.</p> PARAMETER  DESCRIPTION <code>circuit</code> <p>A backend native quantum circuit to be executed.</p> <p> TYPE: <code>ConvertedCircuit</code> </p> <code>param_values</code> <p>The values of the parameters after embedding</p> <p> TYPE: <code>dict[str, Tensor]</code> </p> <code>n_shots</code> <p>The number of shots. Defaults to 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>list[Counter]</code> <p>An iterable with all the sampled bitstrings</p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>def sample(\nself,\ncircuit: ConvertedCircuit,\nparam_values: dict[str, Tensor],\nstate: Tensor | None = None,\nn_shots: int = 1,\nendianness: Endianness = Endianness.BIG,\n) -&gt; list[Counter]:\n\"\"\"Sample bitstring from the registered circuit.\n    Arguments:\n        circuit: A backend native quantum circuit to be executed.\n        param_values: The values of the parameters after embedding\n        n_shots: The number of shots. Defaults to 1.\n    Returns:\n        An iterable with all the sampled bitstrings\n    \"\"\"\nwith torch.no_grad():\nreturn self.backend.sample(\ncircuit=circuit,\nparam_values=param_values,\nstate=state,\nn_shots=n_shots,\nendianness=endianness,\n)\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableExpectation","title":"<code>DifferentiableExpectation</code>  <code>dataclass</code>","text":"<p>A handler for differentiating expectation estimation using various engines.</p>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.DifferentiableExpectation.construct_rules","title":"<code>construct_rules(circuit, observable, psr_fn, **psr_args)</code>  <code>staticmethod</code>","text":"<p>Create a mapping between parameters and PSR functions.</p> Source code in <code>qadence/backends/pytorch_wrapper.py</code> <pre><code>@staticmethod\ndef construct_rules(\ncircuit: QuantumCircuit,\nobservable: list[AbstractBlock],\npsr_fn: Callable,\n**psr_args: int | float | None,\n) -&gt; dict[str, Callable]:\n\"\"\"Create a mapping between parameters and PSR functions.\"\"\"\nuuid_to_eigs = uuid_to_eigen(circuit.block)\n# We currently rely on implicit ordering to match the PSR to the parameter,\n# because we want to cache PSRs.\nparam_to_psr = OrderedDict()\nfor param_id, eigenvalues in uuid_to_eigs.items():\nif eigenvalues is None:\nraise ValueError(\nf\"Eigenvalues are not defined for param_id {param_id}\\n\"\n# f\"of type {type(block)}.\\n\"\n\"PSR cannot be defined in that case.\"\n)\nparam_to_psr[param_id] = psr_fn(eigenvalues, **psr_args)\nfor obs in observable:\nfor param_id, _ in uuid_to_eigen(obs).items():\n# We need the embedded fixed params of the observable in the param_values dict\n# to be able to call expectation. Since torch backward requires\n# a list of param_ids and values of equal length, we need to pass them to PSR too.\n# Since they are constants their gradients are 0.\nparam_to_psr[param_id] = lambda x: torch.tensor([0.0], requires_grad=False)\nreturn param_to_psr\n</code></pre>"},{"location":"backends/differentiable/#qadence.backends.pytorch_wrapper.PSRExpectation","title":"<code>PSRExpectation</code>","text":"<p>             Bases: <code>Function</code></p> <p>Overloads the PyTorch AD system to perform parameter shift rule on quantum circuits.</p>"},{"location":"backends/pulser/","title":"Pulser","text":"<p>The Pulser backend features a basic integration with the pulse-level programming interface Pulser. This backend offers for now few simple operations which are translated into a valid, non time-dependent pulse sequence. In particular, one has access to:</p> <ul> <li>analog rotations: <code>AnalogRx</code> and <code>AnalogRy</code> blocks</li> <li>free evolution blocks (basically no pulse, just interaction): <code>AnalogWait</code> block</li> <li>a block for creating entangled states: <code>AnalogEntanglement</code></li> <li>digital rotation <code>Rx</code> and <code>Ry</code></li> </ul>"},{"location":"backends/pulser/#qadence.backends.pulser.backend.Backend","title":"<code>Backend</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Backend</code></p> <p>The Pulser backend</p>"},{"location":"backends/pulser/#qadence.backends.pulser.backend.create_register","title":"<code>create_register(register, spacing=DEFAULT_SPACING)</code>","text":"<p>Create Pulser register instance.</p> PARAMETER  DESCRIPTION <code>register</code> <p>graph representing a register with accompanying coordinate data</p> <p> TYPE: <code>Register</code> </p> <code>spacing</code> <p>distance between qubits in micrometers</p> <p> TYPE: <code>float</code> DEFAULT: <code>DEFAULT_SPACING</code> </p> RETURNS DESCRIPTION <code>Register</code> <p>Pulser register</p> <p> TYPE: <code>Register</code> </p> Source code in <code>qadence/backends/pulser/backend.py</code> <pre><code>def create_register(register: Register, spacing: float = DEFAULT_SPACING) -&gt; PulserRegister:\n\"\"\"Create Pulser register instance.\n    Args:\n        register (Register): graph representing a register with accompanying coordinate data\n        spacing (float): distance between qubits in micrometers\n    Returns:\n        Register: Pulser register\n    \"\"\"\n# create register from coordinates\ncoords = np.array(list(register.coords.values()))\nreturn PulserRegister.from_coordinates(coords * spacing)\n</code></pre>"},{"location":"backends/pulser/#qadence.backends.pulser.devices.Device","title":"<code>Device</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Supported types of devices for Pulser backend</p>"},{"location":"backends/pulser/#qadence.backends.pulser.devices.Device.IDEALIZED","title":"<code>IDEALIZED = IdealDevice</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>idealized device, least realistic</p>"},{"location":"backends/pulser/#qadence.backends.pulser.devices.Device.REALISTIC","title":"<code>REALISTIC = RealisticDevice</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>device with realistic specs</p>"},{"location":"backends/pyqtorch/","title":"PyQTorch","text":"<p>Fast differentiable statevector emulator based on PyTorch. The code is open source, hosted on Github and maintained by Pasqal.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend","title":"<code>Backend</code>  <code>dataclass</code>","text":"<p>             Bases: <code>Backend</code></p> <p>PyQTorch backend.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.backend.Backend.convert","title":"<code>convert(circuit, observable=None)</code>","text":"<p>Convert an abstract circuit (and optionally and observable) to their native representation. Additionally this function constructs an embedding function which maps from user-facing parameters to device parameters (read more on parameter embedding here).</p> Source code in <code>qadence/backend.py</code> <pre><code>def convert(\nself, circuit: QuantumCircuit, observable: list[AbstractBlock] | AbstractBlock | None = None\n) -&gt; Converted:\n\"\"\"Convert an abstract circuit (and optionally and observable) to their native\n    representation. Additionally this function constructs an embedding function which maps from\n    user-facing parameters to device parameters (read more on parameter embedding\n    [here][qadence.blocks.embedding.embedding]).\n    \"\"\"\ndef check_observable(obs_obj: Any) -&gt; AbstractBlock:\nif isinstance(obs_obj, QubitOperator):\nfrom qadence.blocks.manipulate import from_openfermion\nassert len(obs_obj.terms) &gt; 0, \"Make sure to give a non-empty qubit hamiltonian\"\nreturn from_openfermion(obs_obj)\nelif isinstance(obs_obj, (CompositeBlock, PrimitiveBlock, ScaleBlock)):\nfrom qadence.blocks.utils import block_is_qubit_hamiltonian\nassert block_is_qubit_hamiltonian(\nobs_obj\n), \"Make sure the QubitHamiltonian consists only of Pauli operators X, Y, Z, I\"\nreturn obs_obj\nraise TypeError(\n\"qubit_hamiltonian should be a Pauli-like AbstractBlock or a QubitOperator\"\n)\nconv_circ = self.circuit(circuit)\ncirc_params, circ_embedding_fn = embedding(\nconv_circ.abstract.block, self.config._use_gate_params\n)\nparams = circ_params\nif observable is not None:\nobservable = observable if isinstance(observable, list) else [observable]\nconv_obs = []\nobs_embedding_fn_list = []\nfor obs in observable:\nobs = check_observable(obs)\nc_obs = self.observable(obs, max(circuit.n_qubits, obs.n_qubits))\nobs_params, obs_embedding_fn = embedding(\nc_obs.abstract, self.config._use_gate_params\n)\nparams.update(obs_params)\nobs_embedding_fn_list.append(obs_embedding_fn)\nconv_obs.append(c_obs)\ndef embedding_fn_dict(a: dict, b: dict) -&gt; dict:\nembedding_dict = circ_embedding_fn(a, b)\nfor o in obs_embedding_fn_list:\nembedding_dict.update(o(a, b))\nreturn embedding_dict\nreturn Converted(conv_circ, conv_obs, embedding_fn_dict, params)\ndef embedding_fn(a: dict, b: dict) -&gt; dict:\nreturn circ_embedding_fn(a, b)\nreturn Converted(conv_circ, None, embedding_fn, params)\n</code></pre>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration","title":"<code>Configuration</code>  <code>dataclass</code>","text":"<p>             Bases: <code>BackendConfiguration</code></p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.interaction","title":"<code>interaction: Callable | Interaction | str = Interaction.NN</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Digital-analog emulation interaction that is used for <code>AnalogBlock</code>s.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.loop_expectation","title":"<code>loop_expectation: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>When computing batches of expectation values, only allocate one wavefunction and loop over the batch of parameters to only allocate a single wavefunction at any given time.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.use_gradient_checkpointing","title":"<code>use_gradient_checkpointing: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use gradient checkpointing. Recommended for higher-order optimization tasks.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.config.Configuration.use_single_qubit_composition","title":"<code>use_single_qubit_composition: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Composes chains of single qubit gates into a single matmul if possible.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.supported_gates","title":"<code>supported_gates = list(set(OpName.list()) - set([OpName.TDAGGER]))</code>  <code>module-attribute</code>","text":"<p>The set of supported gates. Tdagger is currently not supported.</p>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.PyQComposedBlock","title":"<code>PyQComposedBlock(ops, qubits, n_qubits, config=None)</code>","text":"<p>             Bases: <code>Module</code></p> <p>Compose a chain of single qubit operations on the same qubit into a single call to _apply_batch_gate.</p> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def __init__(\nself,\nops: list[Module],\nqubits: list[int] | tuple,\nn_qubits: int,\nconfig: Configuration = None,\n):\n\"\"\"Compose a chain of single qubit operations on the same qubit into a single\n    call to _apply_batch_gate.\"\"\"\nsuper().__init__()\nself.operations = ops\nself.qubits = qubits\nself.n_qubits = n_qubits\n</code></pre>"},{"location":"backends/pyqtorch/#qadence.backends.pyqtorch.convert_ops.ScalePyQOperation","title":"<code>ScalePyQOperation(n_qubits, block, config)</code>","text":"<p>             Bases: <code>Module</code></p> <p>Computes:</p> <pre><code>M = matrix(op, theta)\nscale * matmul(M, state)\n</code></pre> Source code in <code>qadence/backends/pyqtorch/convert_ops.py</code> <pre><code>def __init__(self, n_qubits: int, block: ScaleBlock, config: Configuration):\nsuper().__init__()\n(self.param_name,) = config.get_param_name(block)\nif not isinstance(block.block, PrimitiveBlock):\nraise NotImplementedError(\n\"The pyqtorch backend can currently only scale `PrimitiveBlock` types.\\\n            Please use the following transpile function on your circuit first:\\\n            from qadence.transpile import scale_primitive_blocks_only\"\n)\nself.operation = convert_block(block.block, n_qubits, config)[0]\ndef _fwd(state: torch.Tensor, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\nreturn values[self.param_name] * self.operation(state, values)\nif config.use_gradient_checkpointing:\ndef _forward(state: torch.Tensor, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\nreturn checkpoint(_fwd, state, values, use_reentrant=False)\nelse:\ndef _forward(state: torch.Tensor, values: dict[str, torch.Tensor]) -&gt; torch.Tensor:\nreturn _fwd(state, values)\nself._forward = _forward\n</code></pre>"},{"location":"development/architecture/","title":"Architecture and sharp bits","text":"<p>Qadence as a software library mixes functional and object-oriented programming. We do that by maintaining core objects and operating on them with functions.</p> <p>Furthermore, Qadence strives at keeping the lower level abstraction layers for automatic differentiation and quantum computation fully stateless while only the frontend layer which is the main user-facing interface is stateful.</p> <p>Code design philosopy</p> <p>Functional, stateless core with object-oriented, stateful user interface.</p>"},{"location":"development/architecture/#abstraction-layers","title":"Abstraction layers","text":"<p>In Qadence there are 4 main objects spread across 3 different levels of abstraction:</p> <ul> <li> <p>Frontend layer: The user facing layer and encompasses two objects:</p> <ul> <li><code>QuantumCircuit</code>: A class representing an abstract quantum   circuit not tight not any particular framework. Parameters are represented symbolically using   <code>sympy</code> expressions.</li> <li><code>QuantumModel</code>: The models are higher-level abstraction   providing an interface for executing different kinds of common quantum computing models such   quantum neural networks (QNNs), quantum kernels etc.</li> </ul> </li> <li> <p>Differentiation layer: Intermediate layer has the purpose of integrating quantum   computation with a given automatic differentiation engine. It is meant to be purely stateless and   contains one object:</p> <ul> <li><code>DifferentiableBackend</code>:   An abstract class whose concrete implementation wraps a quantum backend and make it   automatically differentiable using different engines (e.g. PyTorch or Jax).   Note, that today only PyTorch is supported but there is plan to add also a Jax   differentiable backend which will require some changes in the base class implementation.</li> </ul> </li> <li> <p>Quantum layer: The lower-level layer which directly interfaces with quantum emulators   and processing units. It is meant to be purely stateless and it contains one base object which is   specialized for each supported backend:</p> <ul> <li><code>Backend</code>: An abstract class whose concrete implementation   enables the execution of quantum circuit with a variety of quantum backends (normally non   automatically differentiable by default) such as PyQTorch, Pulser or Braket.</li> </ul> </li> </ul>"},{"location":"development/architecture/#main-components","title":"Main components","text":""},{"location":"development/architecture/#quantumcircuit","title":"<code>QuantumCircuit</code>","text":"<p>We consider <code>QuantumCircuit</code> to be an abstract object, i.e. it is not tied to any backend. However, it blocks are even more abstract. This is because we consider <code>QuantumCircuit</code>s \"real\", whereas the blocks are largely considered just syntax.</p> <p>Unitary <code>QuantumCircuits</code> (this encompasses digital, or gate-based, circuits as well as analog circuits) are constructed by [<code>PrimitiveBlocks</code>] using a syntax that allows you to execute them in sequence, dubbed <code>ChainBlock</code> in the code, or in parallel (i.e. at the same time) where applicable, dubbed <code>KronBlock</code> in the code. Notice that this differs from other packages by providing more control of the layout of the circuit than conventional packages like Qiskit, and from Yao where the blocks are the primary type.</p>"},{"location":"development/architecture/#quantummodel","title":"<code>QuantumModel</code>","text":"<p><code>QuantumModel</code>s are meant to be the main entry point for quantum computations in <code>qadence</code>. In general, they take one or more quantum circuit as input and they wrap all the necessary boiler plate code to make the circuit executable and differentiable on the chosen backend.</p> <p>Models are meant to be specific for a certain kind of quantum problem or algorithm and you can easily create new ones starting from the base class <code>QuantumModel</code>, as explained in the custom model tutorial. Currently, Qadence offers a <code>QNN</code> model class which provides convenient methods to work with quantum neural networks with multi-dimensional inputs and outputs.</p>"},{"location":"development/architecture/#differentiablebackend","title":"<code>DifferentiableBackend</code>","text":"<p>The differentiable backend is a thin wrapper which takes as input a <code>QuantumCircuit</code> instance and a chosen quantum backend and make the circuit execution routines (expectation value, overalap, etc.) differentiable. Currently, the only implemented differentiation engine is PyTorch but it is easy to add support to another one like Jax.</p>"},{"location":"development/architecture/#quantum-backend","title":"Quantum <code>Backend</code>","text":"<p>For execution the primary object is the <code>Backend</code>. Backends maintain the same user-facing interface, and internally connects to other libraries to execute circuits. Those other libraries can execute the code on QPUs and local or cloud-based emulators. The <code>Backends</code> use PyTorch tensors to represent data and leverages PyTorchs autograd to help compute derivatives of circuits.</p>"},{"location":"development/architecture/#symbolic-parameters","title":"Symbolic parameters","text":"<p>To illustrate how parameters work in Qadence, let's consider the following simple block composed of just two rotations:</p> <pre><code>import sympy\nfrom qadence import Parameter, RX\nparam = Parameter(\"phi\", trainable=False)\nblock = RX(0, param) * RX(1, sympy.acos(param))\n</code></pre> <p>The rotation angles assigned to <code>RX</code> (and to any Qadence quantum operation) are defined as arbitrary expressions of <code>Parameter</code>'s. <code>Parameter</code> is a subclass of <code>sympy.Symbol</code>, thus fully interoperable with it.</p> <p>To assign values of the parameter <code>phi</code> in a quantum model, one should use a dictionary containing the a key with parameter name and the corresponding values values:</p> <pre><code>import torch\nfrom qadence import run\nvalues = {\"phi\": torch.rand(10)}\nwf = run(block, values=values)\n</code></pre> <p>This is the only interface for parameter assignment exposed to the user. Under the hood, parameters applied to every quantum operation are identified in different ways:</p> <ul> <li> <p>By default, with a stringified version of the <code>sympy</code> expression supplied to the quantum operation. Notice that multiple operations can have the same expression.</p> </li> <li> <p>In certain case, e.g. for constructing parameter shift rules, one must access a unique identifier of the parameter for each quantum operation. Therefore, Qadence also creates unique identifiers for each parametrized operation (see the <code>ParamMap</code> class).</p> </li> </ul> <p>By default, when one constructs a new backend, the parameter identifiers are the <code>sympy</code> expressions which are used when converting an abstract block into a native circuit for the chosen backend. However, one can use the unique identifiers as parameter names by setting the private flag <code>_use_gate_params</code> to <code>True</code> in the backend configuration <code>BackendConfiguration</code>. This is automatically set when PSR differentiation is selected (see next section for more details).</p> <p>You can see the logic for choosing the parameter identifier in <code>get_param_name</code>.</p>"},{"location":"development/architecture/#differentiation-with-parameter-shift-rules-psr","title":"Differentiation with parameter shift rules (PSR)","text":"<p>In Qadence, parameter shift rules are implemented by extending the PyTorch autograd engine using custom <code>Function</code> objects. The implementation is based on this PyTorch guide.</p> <p>A custom PyTorch <code>Function</code> looks like this:</p> <pre><code>import torch\nfrom torch.autograd import Function\nclass CustomFunction(Function):\n# forward pass implementation giving the output of the module\n@staticmethod\ndef forward(ctx, inputs: torch.Tensor, params: torch.Tensor):\nctx.save_for_backward(inputs, params)\n...\n# backward pass implementation giving the derivative of the module\n# with respect to the parameters. This must return the whole vector-jacobian\n# product to integrate within the autograd engine\n@staticmethod\ndef backward(ctx, grad_output: torch.Tensor):\ninputs, params = ctx.saved_tensors\n...\n</code></pre> <p>The class <code>PSRExpectation</code> implements parameter shift rules for all parameters using a custom function as the one above. There are a few implementation details to keep in mind if you want to modify the PSR code:</p> <ul> <li> <p>PyTorch <code>Function</code> only works with tensor arguments. Parameters in Qadence are passed around as   dictionaries with parameter names as keys and current parameter values (tensors)   as values. This works for both variational and feature parameters. However, the <code>Function</code> class   only work with PyTorch tensors as input, not dictionaries. Therefore, the forward pass of   <code>PSRExpectation</code> accepts one argument <code>param_keys</code> with the   parameter keys and a variadic positional argument <code>param_values</code> with the parameter values one by   one. The dictionary is reconstructed within the <code>forward()</code> pass body.</p> </li> <li> <p>Higher-order derivatives with PSR. Higher-order PSR derivatives can be tricky. Parameter shift   rules calls, under the hood, the <code>QuantumBackend</code> expectation value routine that usually yield a   non-differentiable output. Therefore, a second call to the backward pass would not work. However,   Qadence employs a very simple trick to make higher-order derivatives work: instead of using   directly the expectation value of the quantum backend, the PSR backward pass uses the PSR forward   pass itself as expectation value function (see the code below). In this way, multiple calls to the   backward pass are allowed since the <code>expectation_fn</code> routine is always differentiable by   definition. Notice that this implementation is simple but suboptimal since, in some corner cases,   higher-order derivates might include some repeated terms that, with this implementation, are   always recomputed.</p> </li> </ul> <pre><code># expectation value used in the PSR backward pass\ndef expectation_fn(params: dict[str, Tensor]) -&gt; Tensor:\nreturn PSRExpectation.apply(\nctx.expectation_fn,\nctx.param_psrs,\nparams.keys(),\n*params.values(),\n)\n</code></pre> <ul> <li> <p>Operation parameters must be uniquely identified for PSR to work. Parameter shift rules work at the level of individual quantum operations. This means that, given a parameter <code>x</code>, one needs to sum the contributions from shifting the parameter values of all the operation where the parameter <code>x</code> appears. When constructing the PSR rules, one must access a unique parameter identifier for each operation even if the corresponding user-facing parameter is the same. Therefore, when PSR differentiation is selected, the flag <code>_use_gate_params</code> is automatically set to <code>True</code> in the backend configuration <code>BackendConfiguration</code> (see previous section).</p> </li> <li> <p>PSR must not be applied to observable parameters. In Qadence, Pauli observables can also be parametrized. However, the tunable parameters of observables are purely classical and should not be included in the differentiation with PSRs. However, the quantum expectation value depends on them, thus they still need to enter into the PSR evaluation. To solve this issue, the code sets the <code>requires_grad</code> attribute of all observable parameters to <code>False</code> when constructing the PSRs for the circuit as in the snippet below:</p> </li> </ul> <pre><code>for obs in observable:\nfor param_id, _ in uuid_to_eigen(obs).items():\nparam_to_psr[param_id] = lambda x: torch.tensor([0.0], requires_grad=False)\n</code></pre>"},{"location":"development/draw/","title":"<code>qadence.draw</code> example plots","text":"<p>Mostly for quick, manual checking of correct plotting output.</p> <pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\nb = kron(X(0), Y(1))\n</code></pre> d41a107175b74eab8dbae1298c9bc2d8 0 09d45f67c8f74c0b91ffb4c17d503a45 X d41a107175b74eab8dbae1298c9bc2d8--09d45f67c8f74c0b91ffb4c17d503a45 a67c9da601d14122b6c1e8db9bc01e20 1 b8ba9c63167d4e2582ae224001206b51 09d45f67c8f74c0b91ffb4c17d503a45--b8ba9c63167d4e2582ae224001206b51 81c6237a24e240ec9dbc4b2a8edc103f b2231b24a1444d5db57ffa3c607ca4a2 Y a67c9da601d14122b6c1e8db9bc01e20--b2231b24a1444d5db57ffa3c607ca4a2 b2231b24a1444d5db57ffa3c607ca4a2--81c6237a24e240ec9dbc4b2a8edc103f <pre><code>from qadence import X, Y, chain\nfrom qadence.draw import display\nb = chain(X(0), Y(0))\n</code></pre> ac470f6b92054a4f81057dc046a87a48 0 1e00eabafdad4c4b83458af55d151574 X ac470f6b92054a4f81057dc046a87a48--1e00eabafdad4c4b83458af55d151574 83ae49aac61040d59902616752d15e57 Y 1e00eabafdad4c4b83458af55d151574--83ae49aac61040d59902616752d15e57 84896d2869394a0780c833ee868c4cd6 83ae49aac61040d59902616752d15e57--84896d2869394a0780c833ee868c4cd6 <pre><code>from qadence import X, Y, chain\nfrom qadence.draw import display\nb = chain(X(0), Y(1))\n</code></pre> 65353964226a4b57ae6652dc7a494f3b 0 5971eee5488f405b8d382da2d70e9bbd X 65353964226a4b57ae6652dc7a494f3b--5971eee5488f405b8d382da2d70e9bbd 432f485e6c2941f9a532bef022759f17 1 adae78c7a3804972970e16fc1078f530 5971eee5488f405b8d382da2d70e9bbd--adae78c7a3804972970e16fc1078f530 7adec86d94734c0197bdeaf820790058 adae78c7a3804972970e16fc1078f530--7adec86d94734c0197bdeaf820790058 844263d4d35e414a8995f750fc5efe79 0c6355a9c35e466b8b8b508aec01edad 432f485e6c2941f9a532bef022759f17--0c6355a9c35e466b8b8b508aec01edad b00d736b5fae4d81a3e750d81041b835 Y 0c6355a9c35e466b8b8b508aec01edad--b00d736b5fae4d81a3e750d81041b835 b00d736b5fae4d81a3e750d81041b835--844263d4d35e414a8995f750fc5efe79 <pre><code>from qadence import X, Y, add\nfrom qadence.draw import display\nb = add(X(0), Y(1), X(2))\n</code></pre> cluster_fda4871b82274d48bccff0141fe226f3 c4076a07d4d84838bec4ddbc825acfcf 0 b196cd619fcb481488d9db80a88a6b2b c4076a07d4d84838bec4ddbc825acfcf--b196cd619fcb481488d9db80a88a6b2b 08dcb05c841248699e206bbbb5163cc0 1 021a6fe9c4a947f9b22ac649e0f812ed b196cd619fcb481488d9db80a88a6b2b--021a6fe9c4a947f9b22ac649e0f812ed 23c74d1bf5cc4172945e0649dba3ff02 02719f8ddff34de5a6cb34029e1862d1 AddBlock 08dcb05c841248699e206bbbb5163cc0--02719f8ddff34de5a6cb34029e1862d1 4767808647fa4524830e8993d440c1e5 2 02719f8ddff34de5a6cb34029e1862d1--23c74d1bf5cc4172945e0649dba3ff02 b96b950c98e44b609c4803221851aa4c 6f821ad366234840bca1bbbf893b90b6 4767808647fa4524830e8993d440c1e5--6f821ad366234840bca1bbbf893b90b6 6f821ad366234840bca1bbbf893b90b6--b96b950c98e44b609c4803221851aa4c <pre><code>from qadence import CNOT, RX, HamEvo, X, Y, Z, chain, kron\nrx = kron(RX(3,0.5), RX(2, \"x\"))\nrx.tag = \"rx\"\ngen = chain(Z(i) for i in range(4))\n# `chain` puts things in sequence\nblock = chain(\nkron(X(0), Y(1), rx),\nCNOT(2,3),\nHamEvo(gen, 10)\n)\n</code></pre> cluster_da33d291eddc47129bfa0082a519ee75 cluster_cd1b4f30b44244c1ba5d26d9179fea69 rx 294d8a76ce9740b688f056c9be7b8154 0 f1068831fd8a4311b601c47f4c1c5cef X 294d8a76ce9740b688f056c9be7b8154--f1068831fd8a4311b601c47f4c1c5cef 607f90fd20834c9992462022d694c470 1 4aef82b949e3495ea99abc6979c4ebc6 f1068831fd8a4311b601c47f4c1c5cef--4aef82b949e3495ea99abc6979c4ebc6 a0ddcf00a55347f686f1ecf178b607af 4aef82b949e3495ea99abc6979c4ebc6--a0ddcf00a55347f686f1ecf178b607af 5dcbc0265962468493fb874678217a7e a0ddcf00a55347f686f1ecf178b607af--5dcbc0265962468493fb874678217a7e 7b039ee5f1f44b9c93fa396e7aa94cb4 c214de49b21341feaece8aee68a9fab3 Y 607f90fd20834c9992462022d694c470--c214de49b21341feaece8aee68a9fab3 38f17f0751724810bbfd69c275e15968 2 7377daf1ba0e437896a802dc837e5f3c c214de49b21341feaece8aee68a9fab3--7377daf1ba0e437896a802dc837e5f3c ca134024e74443c39a23e5ef2224d711 HamEvo 7377daf1ba0e437896a802dc837e5f3c--ca134024e74443c39a23e5ef2224d711 ca134024e74443c39a23e5ef2224d711--7b039ee5f1f44b9c93fa396e7aa94cb4 561d6f9f6ae749b9aa54dfc0f44732af 1bf5d3cbecb046898e6ff95421d8f2cc RX(x) 38f17f0751724810bbfd69c275e15968--1bf5d3cbecb046898e6ff95421d8f2cc 03393c8f42f046a1959fe44b7c0fc880 3 7d4005218e1447f0bedd33b14759af6e 1bf5d3cbecb046898e6ff95421d8f2cc--7d4005218e1447f0bedd33b14759af6e ae2e42a9c67e4fc3a25717d961859543 t = 10 7d4005218e1447f0bedd33b14759af6e--ae2e42a9c67e4fc3a25717d961859543 ae2e42a9c67e4fc3a25717d961859543--561d6f9f6ae749b9aa54dfc0f44732af 176249e647cb413e88be1444632e321a 5f4ffd4948c74d949013044e15a61fd2 RX(0.5) 03393c8f42f046a1959fe44b7c0fc880--5f4ffd4948c74d949013044e15a61fd2 b2fa3d8a9ed24737806e9967df210d5a X 5f4ffd4948c74d949013044e15a61fd2--b2fa3d8a9ed24737806e9967df210d5a b2fa3d8a9ed24737806e9967df210d5a--7d4005218e1447f0bedd33b14759af6e 5e59cc7da43c4132a32c6327d52c6935 b2fa3d8a9ed24737806e9967df210d5a--5e59cc7da43c4132a32c6327d52c6935 5e59cc7da43c4132a32c6327d52c6935--176249e647cb413e88be1444632e321a <pre><code>from qadence import feature_map, hea, chain\nblock = chain(feature_map(4, fm_type=\"tower\"), hea(4,2))\n</code></pre> cluster_4b66bc0b3fb2443bb13b6c8f87fd5d7c HEA cluster_b985231551e84b7cb16018ac7207ebff FM 20d0181c83b64866952d4c8d8d189769 0 b973b433170e41ec9000e5984c21c7a5 RX(2*acos(phi)) 20d0181c83b64866952d4c8d8d189769--b973b433170e41ec9000e5984c21c7a5 b29f5eb96bbe46eea3551815131ca0c2 1 9a6af5e7ed44475a94797e389de2594f RX(theta\u2080) b973b433170e41ec9000e5984c21c7a5--9a6af5e7ed44475a94797e389de2594f a1d8723884ec41bbb3d6127c578a1c88 RY(theta\u2084) 9a6af5e7ed44475a94797e389de2594f--a1d8723884ec41bbb3d6127c578a1c88 290c917acd77451b82c910b6c57c268b RX(theta\u2088) a1d8723884ec41bbb3d6127c578a1c88--290c917acd77451b82c910b6c57c268b b7584e017dbb4534b334b6b83adbbd3e 290c917acd77451b82c910b6c57c268b--b7584e017dbb4534b334b6b83adbbd3e 60dc40115e104d46a54f4c917fa1a88e b7584e017dbb4534b334b6b83adbbd3e--60dc40115e104d46a54f4c917fa1a88e 728055c840c848ac9e59429f4d51455f RX(theta\u2081\u2082) 60dc40115e104d46a54f4c917fa1a88e--728055c840c848ac9e59429f4d51455f d0da1a0fdec84e6fab40db9a4fdb6ae5 RY(theta\u2081\u2086) 728055c840c848ac9e59429f4d51455f--d0da1a0fdec84e6fab40db9a4fdb6ae5 e52e8fb0aa0f4776bf1246f6fae8732b RX(theta\u2082\u2080) d0da1a0fdec84e6fab40db9a4fdb6ae5--e52e8fb0aa0f4776bf1246f6fae8732b 91646c899861434280e2e8a22e9bbe37 e52e8fb0aa0f4776bf1246f6fae8732b--91646c899861434280e2e8a22e9bbe37 a339dc3aaa6b4fdf84b8b6ecc7c2d832 91646c899861434280e2e8a22e9bbe37--a339dc3aaa6b4fdf84b8b6ecc7c2d832 57295a53a5c4404498cb3044765c4f52 a339dc3aaa6b4fdf84b8b6ecc7c2d832--57295a53a5c4404498cb3044765c4f52 a44be21a884b478da4a3b614ce6f8659 e20ddb79a784426e9edea956ee6560c4 RX(4*acos(phi)) b29f5eb96bbe46eea3551815131ca0c2--e20ddb79a784426e9edea956ee6560c4 5691ee1839a34fa382f1caf02d266e26 2 8910e993b0ba469585e88e63b66454fd RX(theta\u2081) e20ddb79a784426e9edea956ee6560c4--8910e993b0ba469585e88e63b66454fd 01a24e692d3c49baa96abc463ca9307e RY(theta\u2085) 8910e993b0ba469585e88e63b66454fd--01a24e692d3c49baa96abc463ca9307e ad94b3c18c7d433dbd648cc1f614cfe0 RX(theta\u2089) 01a24e692d3c49baa96abc463ca9307e--ad94b3c18c7d433dbd648cc1f614cfe0 36237e77fb824318b988f9cae37d4b2e X ad94b3c18c7d433dbd648cc1f614cfe0--36237e77fb824318b988f9cae37d4b2e 36237e77fb824318b988f9cae37d4b2e--b7584e017dbb4534b334b6b83adbbd3e f5341672207c49448febce3b3b131e30 36237e77fb824318b988f9cae37d4b2e--f5341672207c49448febce3b3b131e30 b9789779117b426abb8d1a81f5111cbd RX(theta\u2081\u2083) f5341672207c49448febce3b3b131e30--b9789779117b426abb8d1a81f5111cbd 435cf515ef684771b696f66b06d832ff RY(theta\u2081\u2087) b9789779117b426abb8d1a81f5111cbd--435cf515ef684771b696f66b06d832ff aa51e55d4f02400da558d0bd7c801895 RX(theta\u2082\u2081) 435cf515ef684771b696f66b06d832ff--aa51e55d4f02400da558d0bd7c801895 3a1c851f30e243bab0a5484e48d63de1 X aa51e55d4f02400da558d0bd7c801895--3a1c851f30e243bab0a5484e48d63de1 3a1c851f30e243bab0a5484e48d63de1--91646c899861434280e2e8a22e9bbe37 38b6b1b6af95446181c38455d2f17bcd 3a1c851f30e243bab0a5484e48d63de1--38b6b1b6af95446181c38455d2f17bcd 38b6b1b6af95446181c38455d2f17bcd--a44be21a884b478da4a3b614ce6f8659 e4f7146fb14543d48107eeca7f6e3ab5 c1f58c8c6a6847c2ad7d2415b3ab670d RX(6*acos(phi)) 5691ee1839a34fa382f1caf02d266e26--c1f58c8c6a6847c2ad7d2415b3ab670d 5d028680fa964d84b809ff3bfe46402d 3 139642c361c446b299c75ea3700d728c RX(theta\u2082) c1f58c8c6a6847c2ad7d2415b3ab670d--139642c361c446b299c75ea3700d728c 57bad990c4964209a9c4f69965f91551 RY(theta\u2086) 139642c361c446b299c75ea3700d728c--57bad990c4964209a9c4f69965f91551 d897210a27fa4c5e8c46900b6c054b16 RX(theta\u2081\u2080) 57bad990c4964209a9c4f69965f91551--d897210a27fa4c5e8c46900b6c054b16 744ed71146744c6f8e353fb692e4936f d897210a27fa4c5e8c46900b6c054b16--744ed71146744c6f8e353fb692e4936f 7611ca946b0e47aca84b172ab4dd21dd X 744ed71146744c6f8e353fb692e4936f--7611ca946b0e47aca84b172ab4dd21dd 7611ca946b0e47aca84b172ab4dd21dd--f5341672207c49448febce3b3b131e30 109abec5a8ed406c9091706495bc410c RX(theta\u2081\u2084) 7611ca946b0e47aca84b172ab4dd21dd--109abec5a8ed406c9091706495bc410c 09e87150aec444fdbfab507a616e23d1 RY(theta\u2081\u2088) 109abec5a8ed406c9091706495bc410c--09e87150aec444fdbfab507a616e23d1 ffa5eea1108e40c6bcf20f85effb8637 RX(theta\u2082\u2082) 09e87150aec444fdbfab507a616e23d1--ffa5eea1108e40c6bcf20f85effb8637 836c88999d774b3e8d7010b29af1dfdc ffa5eea1108e40c6bcf20f85effb8637--836c88999d774b3e8d7010b29af1dfdc ce0bb8061715488a8445d41a32881863 X 836c88999d774b3e8d7010b29af1dfdc--ce0bb8061715488a8445d41a32881863 ce0bb8061715488a8445d41a32881863--38b6b1b6af95446181c38455d2f17bcd ce0bb8061715488a8445d41a32881863--e4f7146fb14543d48107eeca7f6e3ab5 14070986debb424da0689ceedfb474a3 c41737d332604d57a3d9379a1d2df501 RX(8*acos(phi)) 5d028680fa964d84b809ff3bfe46402d--c41737d332604d57a3d9379a1d2df501 1b57aac5bdd54e5ea4f611ee3ff8d8b1 RX(theta\u2083) c41737d332604d57a3d9379a1d2df501--1b57aac5bdd54e5ea4f611ee3ff8d8b1 800baf73078b425b8a8b0a50d0fc4235 RY(theta\u2087) 1b57aac5bdd54e5ea4f611ee3ff8d8b1--800baf73078b425b8a8b0a50d0fc4235 2f6f63e162bc4a73b2a37d2adb6ed82e RX(theta\u2081\u2081) 800baf73078b425b8a8b0a50d0fc4235--2f6f63e162bc4a73b2a37d2adb6ed82e b0d7f7caee9448c7aea305dc5cc90fbc X 2f6f63e162bc4a73b2a37d2adb6ed82e--b0d7f7caee9448c7aea305dc5cc90fbc b0d7f7caee9448c7aea305dc5cc90fbc--744ed71146744c6f8e353fb692e4936f 3824a34da166430f88d23e0a7d364fa3 b0d7f7caee9448c7aea305dc5cc90fbc--3824a34da166430f88d23e0a7d364fa3 6be23c21dfd44cf0911123941718c48a RX(theta\u2081\u2085) 3824a34da166430f88d23e0a7d364fa3--6be23c21dfd44cf0911123941718c48a d3814f5b9b8f46178ac3c2323438c4ff RY(theta\u2081\u2089) 6be23c21dfd44cf0911123941718c48a--d3814f5b9b8f46178ac3c2323438c4ff 66dccdb941a3403b90955725deef67ed RX(theta\u2082\u2083) d3814f5b9b8f46178ac3c2323438c4ff--66dccdb941a3403b90955725deef67ed 6e5e115836024eca8470e6bfa8a1fe73 X 66dccdb941a3403b90955725deef67ed--6e5e115836024eca8470e6bfa8a1fe73 6e5e115836024eca8470e6bfa8a1fe73--836c88999d774b3e8d7010b29af1dfdc c0320605ca904476a1b70cfdb887f5a7 6e5e115836024eca8470e6bfa8a1fe73--c0320605ca904476a1b70cfdb887f5a7 c0320605ca904476a1b70cfdb887f5a7--14070986debb424da0689ceedfb474a3"},{"location":"development/draw/#developer-documentation","title":"Developer documentation","text":"<p>This section contains examples in pure graphviz that can be used to understand roughly what is done in the actual drawing backend.</p> <pre><code>import graphviz\nfont_name = \"Sans-Serif\"\nfont_size = \"8\"\ngraph_attr = {\n\"rankdir\": \"LR\",  # LR = left to right, TB = top to bottom\n\"nodesep\": \"0.1\",  # In inches, tells distance between nodes without edges\n\"compound\": \"true\",  # Needed to draw properly edges in hamevo when content is hidden\n\"splines\": \"false\",  # Needed to draw control gates vertical lines one over the other\n}  # These are the default values for graphs\nnode_attr = {\n\"shape\": \"box\",  # 'box' for normal nodes, 'point' for control gates or 'plaintext' for starting nodes (the qubit label).\n\"style\": \"rounded\",  # Unfortunately we can't specify the radius of the rounded, at least for this version\n\"fontname\": font_name,\n\"fontsize\": font_size,\n\"width\": \"0.1\",  # In inches, it doesn't get tinier than the label font.\n\"height\": \"0.1\"  # In inches, it doesn't get tinier than the label font.\n}  # These are the defaults values that can be overridden at node declaration.\ndefault_cluster_attr = {\n\"fontname\": font_name,\n\"fontsize\": font_size,\n\"labelloc\": \"b\",  # location of cluster label. b as bottom, t as top\n\"style\": \"rounded\"\n} # These are the defaults values that can be overridden at sub graph declaration\nhamevo_cluster_attr = {\n\"label\": \"HamEvo(t=10)\"\n}\nhamevo_cluster_attr.update(default_cluster_attr)\nh = graphviz.Graph(graph_attr=graph_attr, node_attr=node_attr)\nh.node(\"Hello World!\")\nh\n</code></pre> <pre><code>\n</code></pre> <pre><code># Define graph\nh = graphviz.Graph(node_attr=node_attr, graph_attr=graph_attr)\n# Add start and end nodes\nfor i in range(4):\nh.node(f's{i}', shape=\"plaintext\", label=f'{i}', group=f\"{i}\")\nh.node(f'e{i}', style='invis', group=f\"{i}\")\n# Add nodes\nh.node('X', group=\"0\")\nh.node('Y', group=\"1\")\n# Add hamevo and its nodes\nhamevo = graphviz.Graph(name='cluster_hamevo', graph_attr=hamevo_cluster_attr)\nfor i in range(4):\nhamevo.node(f'z{i}', shape=\"box\", style=\"invis\", label=f'{i}', group=f\"{i}\")\nh.subgraph(hamevo)\n# Add rx gates cluster and its nodes\ncluster_attr = {\"label\": \"RX gates\"}\ncluster_attr.update(default_cluster_attr)\ncluster = graphviz.Graph(name=\"cluster_0\", graph_attr=cluster_attr)\ncluster.node('RX(x)', group=\"2\")\ncluster.node('RX(0.5)', group=\"3\")\nh.subgraph(cluster)\nh.node('cnot0', label='', shape='point', width='0.1', group='0')\nh.node('cnot1', label='X', group='1')\nh.node('cnot2', label='', shape='point', width='0.1', group='2')\nh.node('cnot3', label='', shape='point', width='0.1', group='3')\n# Add edges\nh.edge('s0', 'X')\nh.edge('X', 'cnot0')\nh.edge('cnot0', 'z0', lhead='cluster_hamevo')\nh.edge('z0', 'e0', ltail='cluster_hamevo')\nh.edge('s1', 'Y')\nh.edge('Y', 'cnot1')\nh.edge('cnot1', 'z1', lhead='cluster_hamevo')\nh.edge('z1', 'e1', ltail='cluster_hamevo')\nh.edge('s2', 'RX(x)')\nh.edge('RX(x)', 'cnot2')\nh.edge('cnot2', 'z2', lhead='cluster_hamevo')\nh.edge('z2', 'e2', ltail='cluster_hamevo')\nh.edge('s3', 'RX(0.5)')\nh.edge('RX(0.5)', 'cnot3')\nh.edge('cnot3', 'z3', lhead='cluster_hamevo')\nh.edge('z3', 'e3', ltail='cluster_hamevo')\nh.edge('cnot1', 'cnot0', constraint='false')  # constraint: false is needed to draw vertical edges\nh.edge('cnot1', 'cnot2', constraint='false')  # constraint: false is needed to draw vertical edges\nh.edge('cnot1', 'cnot3', constraint='false')  # constraint: false is needed to draw vertical edges\nh\n</code></pre> <pre><code>\n</code></pre>"},{"location":"development/draw/#example-of-cluster-of-clusters","title":"Example of cluster of clusters","text":"<pre><code># Define graph\nh = graphviz.Graph(node_attr=node_attr, graph_attr=graph_attr)\n# Define start and end nodes\nfor i in range(4):\nh.node(f's{i}', shape=\"plaintext\", label=f'{i}', group=f\"{i}\")\nh.node(f'e{i}', style='invis', group=f\"{i}\")\n# Define outer cluster\ncluster_attr = {\"label\": \"Outer cluster\"}\ncluster_attr.update(default_cluster_attr)\nouter_cluster = graphviz.Graph(name=\"cluster_outer\", graph_attr=cluster_attr)\n# Define inner cluster 1 and its nodes\ncluster_attr = {\"label\": \"Inner cluster 1\"}\ncluster_attr.update(default_cluster_attr)\ninner1_cluster = graphviz.Graph(name=\"cluster_inner1\", graph_attr=cluster_attr)\ninner1_cluster.node(\"a0\", group=\"0\")\ninner1_cluster.node(\"a1\", group=\"1\")\nouter_cluster.subgraph(inner1_cluster)\n# Define inner cluster 2 and its nodes\ncluster_attr = {\"label\": \"Inner cluster 2\"}\ncluster_attr.update(default_cluster_attr)\ninner2_cluster = graphviz.Graph(name=\"cluster_inner2\", graph_attr=cluster_attr)\ninner2_cluster.node(\"a2\", group=\"2\")\ninner2_cluster.node(\"a3\", group=\"3\")\nouter_cluster.subgraph(inner2_cluster)\n# This has to be done here, after inner clusters definitions\nh.subgraph(outer_cluster)\n# Define more nodes\nfor i in range(4):\nh.node(f\"b{i}\", group=f\"{i}\")\nfor i in range(4):\nh.edge(f's{i}', f'a{i}')\nh.edge(f'a{i}', f'b{i}')\nh.edge(f'b{i}', f'e{i}')\nh\n</code></pre> <pre><code>\n</code></pre>"},{"location":"digital_analog_qc/analog-basics/","title":"Digital-Analog Emulation","text":""},{"location":"digital_analog_qc/analog-basics/#from-theory-to-implementation","title":"From theory to implementation","text":"<p>Qadence includes primitives for the construction of Ising-like Hamiltonians to account for custom qubit interaction. This allows to simulate systems close to real quantum computing platforms such as neutral atoms. The general form for time-independent Ising Hamiltonians is</p> \\[ \\mathcal{H} = \\sum_{i} \\frac{\\hbar\\Omega}{2} \\hat\\sigma^x_i - \\sum_{i} \\hbar\\delta \\hat n_i  + \\mathcal{H}_{\\textrm{int}}, \\] <p>where \\(\\Omega\\) is the Rabi frequency, \\(\\delta\\) is the detuning, \\(\\hat n = \\frac{1-\\hat\\sigma_z}{2}\\) is the number operator, and \\(\\mathcal{H}_{\\textrm{int}}\\) a pair-wise interaction term. Two central operations implement this Hamiltonian as blocks:</p> <ul> <li><code>WaitBlock</code> by free-evolving \\(\\mathcal{H}_{\\textrm{int}}\\)</li> <li><code>ConstantAnalogRotation</code> by free-evolving \\(\\mathcal{H}\\)</li> </ul> <p>The <code>wait</code> operation can be emulated with an \\(ZZ\\)- (Ising) or an \\(XY\\)-interaction:</p> <pre><code>from qadence import Register, wait, add_interaction, run, Interaction\nblock = wait(duration=3000)\nreg = Register.from_coordinates([(0,0), (0,5)])  # Dimensionless.\nemulated = add_interaction(reg, block, interaction=Interaction.XY)  # or Interaction.ZZ for Ising.\n</code></pre> <pre><code>block = WaitBlock(t=3000.0, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,)) emulated.generator = AddBlock(0,1)\n\u2514\u2500\u2500 [mul: 29.600] \u2514\u2500\u2500 AddBlock(0,1)\n\u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u251c\u2500\u2500 X(0)\n\u2502   \u2514\u2500\u2500 X(1)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u251c\u2500\u2500 Y(0)\n\u2514\u2500\u2500 Y(1)\n</code></pre> <p>The <code>AnalogRot</code> constructor can be used to create a fully customizable <code>ConstantAnalogRotation</code> instances:</p> <pre><code>import torch\nfrom qadence import AnalogRot, AnalogRX\n# Implement a global RX rotation by setting all parameters.\nblock = AnalogRot(\nduration=1000., # [ns]\nomega=torch.pi, # [rad/\u03bcs]\ndelta=0,        # [rad/\u03bcs]\nphase=0,        # [rad]\n)\n# Or use the shortcut.\nblock = AnalogRX(torch.pi)\n</code></pre> <pre><code>AnalogRot = ConstantAnalogRotation(\u03b1=3.14159265358979, t=1000.00000000000, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,), \u03a9=3.14159265358979, \u03b4=0, \u03c6=0)\nAnalogRX = ConstantAnalogRotation(\u03b1=3.14159265358979, t=1000.00000000000, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,), \u03a9=3.14159265358979, \u03b4=0, \u03c6=0)\n</code></pre> <p>Automatic emulation in the PyQTorch backend</p> <p>All analog blocks are automatically translated to their emulated version when running them with the PyQTorch backend:</p> <p><pre><code>import torch\nfrom qadence import Register, AnalogRX, sample\nreg = Register.from_coordinates([(0,0), (0,5)])\nsample = sample(reg, AnalogRX(torch.pi))\n</code></pre> <pre><code>sample = [Counter({'00': 40, '10': 32, '01': 28})]\n</code></pre> </p> <p>To compose analog blocks, the regular <code>chain</code> and <code>kron</code> operations can be used under the following restrictions:</p> <ul> <li>The resulting <code>AnalogChain</code> type can only be constructed from <code>AnalogKron</code> blocks   or globally supported primitive analog blocks.</li> <li>The resulting <code>AnalogKron</code> type can only be constructed from non-global   analog blocks with the same duration.</li> </ul> <pre><code>import torch\nfrom qadence import AnalogRot, kron, chain, wait\n# Only analog blocks with a global qubit support can be composed\n# using chain.\nanalog_chain = chain(wait(duration=200), AnalogRot(duration=300, omega=2.0))\n# Only blocks with the same `duration` can be composed using kron.\nanalog_kron = kron(\nwait(duration=1000, qubit_support=(0,1)),\nAnalogRot(duration=1000, omega=2.0, qubit_support=(2,3))\n)\n</code></pre> <pre><code>Analog Chain block = AnalogChain(t=500.000000000000, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,))\n\u251c\u2500\u2500 WaitBlock(t=200.0, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,))\n\u2514\u2500\u2500 ConstantAnalogRotation(\u03b1=0.600000000000000, t=300, support=(&lt;QubitSupportType.GLOBAL: 'global'&gt;,), \u03a9=2.00000000000000, \u03b4=0, \u03c6=0)\nAnalog Kron block = AnalogKron(t=1000, support=(0, 1, 2, 3))\n\u251c\u2500\u2500 WaitBlock(t=1000.0, support=(0, 1))\n\u2514\u2500\u2500 ConstantAnalogRotation(\u03b1=2.00000000000000, t=1000, support=(2, 3), \u03a9=2.00000000000000, \u03b4=0, \u03c6=0)\n</code></pre> <p>Composing digital &amp; analog blocks</p> <p>It is possible to compose digital and analog blocks where the additional restrictions for <code>chain</code> and <code>kron</code> only apply to composite blocks which contain analog blocks only. For further details, see <code>AnalogChain</code> and <code>AnalogKron</code>.</p>"},{"location":"digital_analog_qc/analog-basics/#fitting-a-simple-function","title":"Fitting a simple function","text":"<p>Analog blocks can indeed be parametrized to, for instance, create small ansatze to fit a sine function. When using the <code>pyqtorch</code> backend the <code>add_interaction</code> function is called automatically. As usual, we can choose which differentiation backend we want to use: autodiff or parameter shift rule (PSR).</p> <p>First we define an ansatz block and an observable <pre><code>import torch\nfrom qadence import Register, FeatureParameter, VariationalParameter\nfrom qadence import AnalogRX, AnalogRZ, Z\nfrom qadence import wait, chain, add\npi = torch.pi\n# two qubit register\nreg = Register.from_coordinates([(0, 0), (0, 12)])\n# analog ansatz with input parameter\nt = FeatureParameter(\"t\")\nblock = chain(\nAnalogRX(pi / 2),\nAnalogRZ(t),\nwait(1000 * VariationalParameter(\"theta\", value=0.5)),\nAnalogRX(pi / 2),\n)\n# observable\nobs = add(Z(i) for i in range(reg.n_qubits))\n</code></pre> </p> Plotting functions <code>plot</code> and <code>scatter</code> <p><pre><code>def plot(ax, x, y, **kwargs):\nxnp = x.detach().cpu().numpy().flatten()\nynp = y.detach().cpu().numpy().flatten()\nax.plot(xnp, ynp, **kwargs)\ndef scatter(ax, x, y, **kwargs):\nxnp = x.detach().cpu().numpy().flatten()\nynp = y.detach().cpu().numpy().flatten()\nax.scatter(xnp, ynp, **kwargs)\n</code></pre> </p> <p>Then we define the dataset we want to train on and plot the initial prediction. <pre><code>import matplotlib.pyplot as plt\nfrom qadence import QuantumCircuit, QuantumModel\n# define quantum model; including digital-analog emulation\ncirc = QuantumCircuit(reg, block)\nmodel = QuantumModel(circ, obs, diff_mode=\"gpsr\")\nx_train = torch.linspace(0, 6, steps=30)\ny_train = -0.64 * torch.sin(x_train + 0.33) + 0.1\ny_pred_initial = model.expectation({\"t\": x_train})\nfig, ax = plt.subplots()\nscatter(ax, x_train, y_train, label=\"Training points\", marker=\"o\", color=\"green\")\nplot(ax, x_train, y_pred_initial, label=\"Initial prediction\")\nplt.legend()\n</code></pre> 2023-10-12T16:59:36.810319 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ </p> <p>The rest is the usual PyTorch training routine. <pre><code>mse_loss = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-2)\ndef loss_fn(x_train, y_train):\nreturn mse_loss(model.expectation({\"t\": x_train}).squeeze(), y_train)\n# train\nn_epochs = 200\nfor i in range(n_epochs):\noptimizer.zero_grad()\nloss = loss_fn(x_train, y_train)\nloss.backward()\noptimizer.step()\n# if (i + 1) % 10 == 0:\n#     print(f\"Epoch {i+1:0&gt;3} - Loss: {loss.item()}\\n\")\n# visualize\ny_pred = model.expectation({\"t\": x_train})\nfig, ax = plt.subplots()\nscatter(ax, x_train, y_train, label=\"Training points\", marker=\"o\", color=\"green\")\nplot(ax, x_train, y_pred_initial, label=\"Initial prediction\")\nplot(ax, x_train, y_pred, label=\"Final prediction\")\nplt.legend()\n</code></pre> 2023-10-12T16:59:39.763762 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ </p>"},{"location":"digital_analog_qc/analog-qubo/","title":"Solve a QUBO oroblem","text":"<p>In this notebook we solve a quadratic unconstrained optimization problem with <code>qadence</code> emulated analog interface using the QAOA variational algorithm. The problem is detailed in the Pulser documentation here.</p> Construct QUBO register (defines <code>qubo_register_coords</code> function) <p>Before we start we have to define a register that fits into our device. <pre><code>import torch\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.spatial.distance import pdist, squareform\nfrom pulser.devices import Chadoq2\nseed = 0\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ndef qubo_register_coords(Q):\n\"\"\"Compute coordinates for register.\"\"\"\nbitstrings = [np.binary_repr(i, len(Q)) for i in range(len(Q) ** 2)]\ncosts = []\n# this takes exponential time with the dimension of the QUBO\nfor b in bitstrings:\nz = np.array(list(b), dtype=int)\ncost = z.T @ Q @ z\ncosts.append(cost)\nzipped = zip(bitstrings, costs)\nsort_zipped = sorted(zipped, key=lambda x: x[1])\ndef evaluate_mapping(new_coords, *args):\n\"\"\"Cost function to minimize. Ideally, the pairwise\n        distances are conserved\"\"\"\nQ, shape = args\nnew_coords = np.reshape(new_coords, shape)\nnew_Q = squareform(Chadoq2.interaction_coeff / pdist(new_coords) ** 6)\nreturn np.linalg.norm(new_Q - Q)\nshape = (len(Q), 2)\ncosts = []\nnp.random.seed(0)\nx0 = np.random.random(shape).flatten()\nres = minimize(\nevaluate_mapping,\nx0,\nargs=(Q, shape),\nmethod=\"Nelder-Mead\",\ntol=1e-6,\noptions={\"maxiter\": 200000, \"maxfev\": None},\n)\nreturn [(x, y) for (x, y) in np.reshape(res.x, (len(Q), 2))]\n</code></pre> </p>"},{"location":"digital_analog_qc/analog-qubo/#define-and-solve-qubo","title":"Define and solve QUBO","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom qadence import add_interaction, chain\nfrom qadence import QuantumModel, QuantumCircuit, AnalogRZ, AnalogRX, Register\nseed = 0\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n</code></pre> <p>The QUBO is defined by weighted connections <code>Q</code> and a cost function.</p> <pre><code>def cost_colouring(bitstring, Q):\nz = np.array(list(bitstring), dtype=int)\ncost = z.T @ Q @ z\nreturn cost\ndef cost_fn(counter, Q):\ncost = sum(counter[key] * cost_colouring(key, Q) for key in counter)\nreturn cost / sum(counter.values())  # Divide by total samples\nQ = np.array(\n[\n[-10.0, 19.7365809, 19.7365809, 5.42015853, 5.42015853],\n[19.7365809, -10.0, 20.67626392, 0.17675796, 0.85604541],\n[19.7365809, 20.67626392, -10.0, 0.85604541, 0.17675796],\n[5.42015853, 0.17675796, 0.85604541, -10.0, 0.32306662],\n[5.42015853, 0.85604541, 0.17675796, 0.32306662, -10.0],\n]\n)\n</code></pre> <p>Build a register from graph extracted from the QUBO exactly as you would do with Pulser. <pre><code>reg = Register.from_coordinates(qubo_register_coords(Q))\n</code></pre> </p> <p>The analog circuit is composed of two global rotations per layer.  The first rotation corresponds to the mixing Hamiltonian and the second one to the embedding Hamiltonian.  Subsequently we add the Ising interaction term to emulate the analog circuit.  This uses a principal quantum number n=70 for the Rydberg level under the hood. <pre><code>from qadence.transpile.emulate import ising_interaction\nLAYERS = 2\nblock = chain(*[AnalogRX(f\"t{i}\") * AnalogRZ(f\"s{i}\") for i in range(LAYERS)])\nemulated = add_interaction(\nreg, block, interaction=lambda r, ps: ising_interaction(r, ps, rydberg_level=70)\n)\nprint(emulated)\n</code></pre> <pre><code>ChainBlock(0,1,2,3,4)\n\u251c\u2500\u2500 ChainBlock(0,1,2,3,4)\n\u2502   \u251c\u2500\u2500 HamEvo(0,1,2,3,4) [params: ['51_1430082484387*t0']]\n\u2502   \u2514\u2500\u2500 HamEvo(0,1,2,3,4) [params: ['38_8279677658339*s0']]\n\u2514\u2500\u2500 ChainBlock(0,1,2,3,4)\n\u251c\u2500\u2500 HamEvo(0,1,2,3,4) [params: ['51_1430082484387*t1']]\n\u2514\u2500\u2500 HamEvo(0,1,2,3,4) [params: ['38_8279677658339*s1']]\n</code></pre> </p> <p>Sample the model to get the initial solution. <pre><code>model = QuantumModel(QuantumCircuit(reg, emulated), backend=\"pyqtorch\", diff_mode='gpsr')\ninitial_counts = model.sample({}, n_shots=1000)[0]\n</code></pre> </p> <p>The loss function is defined by averaging over the evaluated bitstrings. <pre><code>def loss(param, *args):\nQ = args[0]\nparam = torch.tensor(param)\nmodel.reset_vparams(param)\nC = model.sample({}, n_shots=1000)[0]\nreturn cost_fn(C, Q)\n</code></pre>  Here we use a gradient-free optimization loop for reaching the optimal solution. <pre><code>#\nfor i in range(20):\ntry:\nres = minimize(\nloss,\nargs=Q,\nx0=np.random.uniform(1, 10, size=2 * LAYERS),\nmethod=\"COBYLA\",\ntol=1e-8,\noptions={\"maxiter\": 20},\n)\nexcept Exception:\npass\n# sample the optimal solution\nmodel.reset_vparams(res.x)\noptimal_count_dict = model.sample({}, n_shots=1000)[0]\nprint(optimal_count_dict)\n</code></pre> <pre><code>Counter({'00111': 243, '01011': 200, '00100': 103, '01000': 97, '01001': 82, '00110': 72, '00000': 61, '00001': 33, '00010': 25, '10000': 23, '01010': 16, '00101': 14, '10001': 7, '10011': 7, '01111': 5, '10010': 5, '01101': 4, '00011': 2, '01100': 1})\n</code></pre> </p> <pre><code>fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n# known solutions to the QUBO\nsolution_bitstrings=[\"01011\", \"00111\"]\nn_to_show = 20\nxs, ys = zip(*sorted(\ninitial_counts.items(),\nkey=lambda item: item[1],\nreverse=True\n))\ncolors = [\"r\" if x in solution_bitstrings else \"g\" for x in xs]\naxs[0].set_xlabel(\"bitstrings\")\naxs[0].set_ylabel(\"counts\")\naxs[0].bar(xs[:n_to_show], ys[:n_to_show], width=0.5, color=colors)\naxs[0].tick_params(axis=\"x\", labelrotation=90)\naxs[0].set_title(\"Initial solution\")\nxs, ys = zip(*sorted(optimal_count_dict.items(),\nkey=lambda item: item[1],\nreverse=True\n))\ncolors = [\"r\" if x in solution_bitstrings else \"g\" for x in xs]\naxs[1].set_xlabel(\"bitstrings\")\naxs[1].set_ylabel(\"counts\")\naxs[1].bar(xs[:n_to_show], ys[:n_to_show], width=0.5, color=colors)\naxs[1].tick_params(axis=\"x\", labelrotation=90)\naxs[1].set_title(\"Optimal solution\")\nplt.tight_layout()\n</code></pre> 2023-10-12T16:59:40.815727 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"digital_analog_qc/daqc-basics/","title":"Digital-Analog Quantum Computation","text":"<p>Digital-analog quantum computation (DAQC) is a universal quantum computing paradigm<sup>1</sup>, based on two primary computations:</p> <ul> <li>Fast single-qubit operations (digital).</li> <li>Multi-partite entangling operations acting on all qubits (analog).</li> </ul> <p>The DAQC paradigm is typically implemented on quantum computing hardware based on neutral-atoms where both these computations are realizable.</p>"},{"location":"digital_analog_qc/daqc-basics/#digital-analog-emulation","title":"Digital-analog emulation","text":"<p>Qadence simplifies the execution of DAQC programs on either emulated or real neutral-atom devices by providing a simplified interface for customizing interactions and interfacing with pulse-level programming in <code>Pulser</code><sup>3</sup>.</p>"},{"location":"digital_analog_qc/daqc-basics/#digital-analog-transformation","title":"Digital-analog transformation","text":"<p>Furthermore, the essence of digital-analog computation is the ability to represent any analog operation, i.e. any arbitrary Hamiltonian, using an auxiliary device-amenable Hamiltonian, such as the ubiquitous Ising model<sup>2</sup>. This is at the core of the DAQC implementation in Qadence.</p>"},{"location":"digital_analog_qc/daqc-basics/#references","title":"References","text":"<ol> <li> <p>Dodd et al., Universal quantum computation and simulation using any entangling Hamiltonian and local unitaries, PRA 65, 040301 (2002). \u21a9</p> </li> <li> <p>Pulser: An open-source package for the design of pulse sequences in programmable neutral-atom arrays \u21a9</p> </li> <li> <p>Parra-Rodriguez et al., Digital-Analog Quantum Computation, PRA 101, 022305 (2020). \u21a9</p> </li> </ol>"},{"location":"digital_analog_qc/daqc-cnot/","title":"DAQC Transform","text":"<p>Digital-analog quantum computing focuses on using simple digital gates combined with more complex and device-dependent analog interactions to represent quantum programs. Such techniques have been shown to be universal for quantum computation <sup>1</sup>. However, while this approach may have advantages when adapting quantum programs to real devices, known quantum algorithms are very often expressed in a fully digital paradigm. As such, it is also important to have concrete ways to transform from one paradigm to another.</p> <p>In this tutorial we will exemplify this transformation starting with the representation of a simple digital CNOT using the universality of the Ising Hamiltonian <sup>2</sup>.</p>"},{"location":"digital_analog_qc/daqc-cnot/#cnot-with-cphase","title":"CNOT with CPHASE","text":"<p>Let's look at a single example of how the digital-analog transformation can be used to perform a CNOT on two qubits inside a register of globally interacting qubits.</p> <p>First, note that the CNOT can be decomposed with two Hadamard and a CPHASE gate with \\(\\phi=\\pi\\):</p> <pre><code>import torch\nimport qadence as qd\nfrom qadence.draw import display\nfrom qadence import X, I, Z, H, N, CPHASE, CNOT, HamEvo\nn_qubits = 2\n# CNOT gate\ncnot_gate = CNOT(0, 1)\n# CNOT decomposed\nphi = torch.pi\ncnot_decomp = qd.chain(H(1), CPHASE(0, 1, phi), H(1))\ninit_state = qd.product_state(\"10\")\nprint(qd.sample(n_qubits, block = cnot_gate, state = init_state, n_shots = 100))\nprint(qd.sample(n_qubits, block = cnot_decomp, state = init_state, n_shots = 100))\n</code></pre> <pre><code>[Counter({'11': 100})]\n[Counter({'11': 100})]\n</code></pre> <p>The CPHASE gate is fully diagonal, and can be implemented by exponentiating an Ising-like Hamiltonian, or generator,</p> \\[\\text{CPHASE}(i,j,\\phi)=\\text{exp}\\left(-i\\phi \\mathcal{H}_\\text{CP}(i, j)\\right)\\] \\[\\begin{aligned} \\mathcal{H}_\\text{CP}&amp;=-\\frac{1}{4}(I_i-Z_i)(I_j-Z_j)\\\\ &amp;=-N_iN_j \\end{aligned}\\] <p>where we used the number operator \\(N_i = \\frac{1}{2}(I_i-Z_i)\\), leading to an Ising-like interaction \\(N_iN_j\\) that is common in neutral-atom systems. Let's rebuild the CNOT using this evolution.</p> <pre><code># Hamiltonian for the CPHASE gate\nh_cphase = (-1.0) * qd.kron(N(0), N(1))\n# Exponentiating the Hamiltonian\ncphase_evo = HamEvo(h_cphase, phi)\n# Check that we have the CPHASE gate:\ncphase_matrix = qd.block_to_tensor(CPHASE(0, 1, phi))\ncphase_evo_matrix = qd.block_to_tensor(cphase_evo)\nassert torch.allclose(cphase_matrix, cphase_evo_matrix)\n</code></pre> <p>Now that we have checked the generator of the CPHASE gate, we can use it to apply the CNOT:</p> <pre><code># CNOT with Hamiltonian Evolution\ncnot_evo = qd.chain(\nH(1),\ncphase_evo,\nH(1)\n)\ninit_state = qd.product_state(\"10\")\nprint(qd.sample(n_qubits, block = cnot_gate, state = init_state, n_shots = 100))\nprint(qd.sample(n_qubits, block = cnot_evo, state = init_state, n_shots = 100))\n</code></pre> <pre><code>[Counter({'11': 100})]\n[Counter({'11': 100})]\n</code></pre> <p>Thus, a CNOT gate can be applied by combining a few single-qubit gates together with a 2-qubit Ising interaction between the control and the target qubit. This is important because it now allows us to exemplify the usage of the Ising transform proposed in the DAQC paper <sup>2</sup>. In the paper, the transform is described for \\(ZZ\\) interactions. In <code>qadence</code> it works both with \\(ZZ\\) and \\(NN\\) interactions.</p>"},{"location":"digital_analog_qc/daqc-cnot/#cnot-in-an-interacting-system-of-3-qubits","title":"CNOT in an interacting system of 3 qubits","text":"<p>Consider a simple experimental setup with \\(n=3\\) interacting qubits in a triangular grid. For simplicity let's consider that all qubits interact with each other with an Ising (\\(NN\\)) interaction of constant strength \\(g_\\text{int}\\). The Hamiltonian for the system can be written by summing this interaction over all pairs:</p> \\[\\mathcal{H}_\\text{sys}=\\sum_{i=0}^{n}\\sum_{j=0}^{i-1}g_\\text{int}N_iN_j,\\] <p>which in this case leads to only three interaction terms,</p> \\[\\mathcal{H}_\\text{sys}=g_\\text{int}(N_0N_1+N_1N_2+N_0N_2)\\] <p>This generator can be easily built:</p> <pre><code>n_qubits = 3\ng_int = 1.0\ninteraction_list = []\nfor i in range(n_qubits):\nfor j in range(i):\ninteraction_list.append(g_int * qd.kron(N(i), N(j)))\nh_sys = qd.add(*interaction_list)\nprint(h_sys)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(0)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(2)\n\u2502       \u2514\u2500\u2500 N(0)\n\u2514\u2500\u2500 [mul: 1.00000000000000] \u2514\u2500\u2500 KronBlock(1,2)\n\u251c\u2500\u2500 N(2)\n\u2514\u2500\u2500 N(1)\n</code></pre> <p>Now let's consider that the experimental system is fixed, and we cannot isolate the qubits from each other. All we can do is the following:</p> <ul> <li>Turn on or off the global system Hamiltonian.</li> <li>Perform single-qubit rotations on individual qubits.</li> </ul> <p>How can we perform a CNOT on two specific qubits of our choice?</p> <p>To perform a fully digital CNOT we would need to isolate the control and target qubit from the third one and have those interact to implement the gate directly. While this may be relatively simple for a 3-qubit system, the experimental burden becomes much greater when we start going into the dozens of qubits.</p> <p>However, with the digital-analog paradigm that is not the case! In fact, we can represent the two qubit Ising interaction required for the CNOT by combining the global system Hamiltonian with a specific set of single-qubit rotations. The full details of this transformation are described in the DAQC paper <sup>2</sup>, and it is available in <code>qadence</code> by calling the <code>daqc_transform</code> function.</p> <p>The <code>daqc_transform</code> function will essentially return a program that represents the evolution of an Hamiltonian \\(H_\\text{target}\\) (target Hamiltonian) for a specified time \\(t_f\\) by using only the evolution of an Hamiltonian \\(H_\\text{build}\\) (build Hamiltonian) for specific intervals of time together with specific single-qubit \\(X\\) rotations. Currently, in <code>qadence</code> it is available for resource and target Hamiltonians composed only of \\(ZZ\\) or \\(NN\\) interactions. The generators are parsed by the <code>daqc_transform</code> function, the appropriate type is automatically determined, and the appropriate single-qubit detunings and global phases are applied.</p> <p>Let's exemplify it for our CNOT problem:</p> <pre><code># The target operation\ni = 0  # Control\nj = 1  # Target\nk = 2  # The extra qubit\n# CNOT on control and target, Identity on the extra qubit\ncnot_target = qd.kron(CNOT(i, j), I(k))\n# The two-qubit Ising (NN) interaction for the CPHASE\nh_int = (-1.0) * qd.kron(N(i), N(j))\n# Transforming the two-qubit Ising interaction using only our system Hamiltonian\ntransformed_ising = qd.daqc_transform(\nn_qubits = 3,        # Total number of qubits in the transformation\ngen_target = h_int,  # The target Ising generator\nt_f = torch.pi,      # The target evolution time\ngen_build = h_sys,   # The building block Ising generator to be used\nstrategy = \"sDAQC\",   # Currently only sDAQC is implemented\nignore_global_phases = False  # Global phases from mapping between Z and N\n)\n# display(transformed_ising)\n</code></pre> cluster_580037716f394af3a7d739a0cf2daa6f cluster_e7073d3804394262984925fe289074f3 cluster_64aa43ea979c43ff9669c103b38043ed cluster_298698094cdb42959832c24b16e4e953 cluster_c0d5dbfae03045649559a161738cd345 cluster_06a1456cc3f548f9a5784bef380229cb cluster_adc84be016414f6eabc83cc52f0a7a81 c50b7457a48a4c2cb56cabbee446f77c 0 3061584cbac64c8eb521db478657297e HamEvo c50b7457a48a4c2cb56cabbee446f77c--3061584cbac64c8eb521db478657297e 3b72ead40ce341939788d489693cbc88 1 4c72700d0dd94ec3bfa366ca1cb98eb1 HamEvo 3061584cbac64c8eb521db478657297e--4c72700d0dd94ec3bfa366ca1cb98eb1 74dff8bf6f074eb0824dc782be45cc24 HamEvo 4c72700d0dd94ec3bfa366ca1cb98eb1--74dff8bf6f074eb0824dc782be45cc24 d78358e7d11f4ed688593037b6ff0ae9 X 74dff8bf6f074eb0824dc782be45cc24--d78358e7d11f4ed688593037b6ff0ae9 87eb6ddea3414a71a83b251bc2d13663 HamEvo d78358e7d11f4ed688593037b6ff0ae9--87eb6ddea3414a71a83b251bc2d13663 e687344f86fb4835979e3f9381c0eb56 HamEvo 87eb6ddea3414a71a83b251bc2d13663--e687344f86fb4835979e3f9381c0eb56 626f5eff4b6b4a70ac0f40eb2ede9a2d X e687344f86fb4835979e3f9381c0eb56--626f5eff4b6b4a70ac0f40eb2ede9a2d 832440d873a849fcb038adb0b689e51e 626f5eff4b6b4a70ac0f40eb2ede9a2d--832440d873a849fcb038adb0b689e51e ca4c27783f3c4e51abd8822c356ab447 HamEvo 832440d873a849fcb038adb0b689e51e--ca4c27783f3c4e51abd8822c356ab447 ac7f1b47098d49ca8d62a5db3a89e91f HamEvo ca4c27783f3c4e51abd8822c356ab447--ac7f1b47098d49ca8d62a5db3a89e91f c6b3fcdd608843fe99c9c494d8546d2c ac7f1b47098d49ca8d62a5db3a89e91f--c6b3fcdd608843fe99c9c494d8546d2c 27e48227a14140cdad30eaae38d215b6 c6b3fcdd608843fe99c9c494d8546d2c--27e48227a14140cdad30eaae38d215b6 1906c141bd0647a989bda0d415b36c5b a06e993d9fb147f4ac6130f12c331f2e t = -3.142 3b72ead40ce341939788d489693cbc88--a06e993d9fb147f4ac6130f12c331f2e 68b1ff608a674e719122dcaad7d031f1 2 4fffb29a4df24d0f8ba21973352ed0aa t = 3.142 a06e993d9fb147f4ac6130f12c331f2e--4fffb29a4df24d0f8ba21973352ed0aa ef34416120dc4fb3ad3f502f94904f17 t = -3.142 4fffb29a4df24d0f8ba21973352ed0aa--ef34416120dc4fb3ad3f502f94904f17 9d00dfdca4c347e498716349908d70f6 ef34416120dc4fb3ad3f502f94904f17--9d00dfdca4c347e498716349908d70f6 1321161c43cf452da1419c7f3631219d t = 1.571 9d00dfdca4c347e498716349908d70f6--1321161c43cf452da1419c7f3631219d cd4762647ff546e19f8155d54bcc8937 t = 1.571 1321161c43cf452da1419c7f3631219d--cd4762647ff546e19f8155d54bcc8937 daf916dbeaf64c36a0efbbaa2684b4e2 cd4762647ff546e19f8155d54bcc8937--daf916dbeaf64c36a0efbbaa2684b4e2 1352d8d97a934dddb3b3773299082ac4 X daf916dbeaf64c36a0efbbaa2684b4e2--1352d8d97a934dddb3b3773299082ac4 324a3d710d404dbbba9ac8e8957c25b4 t = 1.571 1352d8d97a934dddb3b3773299082ac4--324a3d710d404dbbba9ac8e8957c25b4 0be305cc8d5b464081c77a3d7a98dfb5 t = 1.571 324a3d710d404dbbba9ac8e8957c25b4--0be305cc8d5b464081c77a3d7a98dfb5 d98306ff3d4348738501efeb9c5b7013 X 0be305cc8d5b464081c77a3d7a98dfb5--d98306ff3d4348738501efeb9c5b7013 d98306ff3d4348738501efeb9c5b7013--1906c141bd0647a989bda0d415b36c5b c4f5aecc3f33446a9c9edb6281b9cac6 9afb808c0d3f491b92025ba3f01af9b2 68b1ff608a674e719122dcaad7d031f1--9afb808c0d3f491b92025ba3f01af9b2 fbc772fd25d148b6b6566bbe6d2738c7 9afb808c0d3f491b92025ba3f01af9b2--fbc772fd25d148b6b6566bbe6d2738c7 e7200063c32d45b8a294e054c5a11e34 fbc772fd25d148b6b6566bbe6d2738c7--e7200063c32d45b8a294e054c5a11e34 30ff5879ac7f434880aa2c830ca18842 X e7200063c32d45b8a294e054c5a11e34--30ff5879ac7f434880aa2c830ca18842 e658cb2ac9234da4913e67104cf026ad 30ff5879ac7f434880aa2c830ca18842--e658cb2ac9234da4913e67104cf026ad fc34aed414174e359a82bc11de5c08f7 e658cb2ac9234da4913e67104cf026ad--fc34aed414174e359a82bc11de5c08f7 fc974b1cc9bb4190a63e02d93b2e7287 X fc34aed414174e359a82bc11de5c08f7--fc974b1cc9bb4190a63e02d93b2e7287 aafbe62d662a49e499f1c2d4b86f7688 X fc974b1cc9bb4190a63e02d93b2e7287--aafbe62d662a49e499f1c2d4b86f7688 752744456ba44978a0cca9ebf9459b06 aafbe62d662a49e499f1c2d4b86f7688--752744456ba44978a0cca9ebf9459b06 fbc9fe9199a7463ba7657f203afed2a1 752744456ba44978a0cca9ebf9459b06--fbc9fe9199a7463ba7657f203afed2a1 7cb579734722405095574b39220751f8 X fbc9fe9199a7463ba7657f203afed2a1--7cb579734722405095574b39220751f8 7cb579734722405095574b39220751f8--c4f5aecc3f33446a9c9edb6281b9cac6 <p>The circuit above actually only uses two evolutions of the global Hamiltonian. In the displayed circuit also see other instances of <code>HamEvo</code> which account for global-phases and single-qubit detunings related to the mapping between the \\(Z\\) and \\(N\\) operator. Optionally, the application of the global phases can also be ignored, as shown in the input of <code>daqc_transform</code>. This will not create exactly the same state or operator matrix in tensor form, but in practice they will be equivalent.</p> <p>In general, the mapping of a \\(n\\)-qubit Ising Hamiltonian will require at most \\(n(n-1)\\) evolutions. The transformed circuit performs these evolutions for specific times that are computed from the solution of a linear system of equations involving the set of interactions in the target and build Hamiltonians.</p> <p>In this case the mapping is exact, since we used the step-wise DAQC technique (sDAQC). In banged DAQC (bDAQC) the mapping is not exact, but is easier to implement on a physical device with always-on interactions such as neutral-atom systems. Currently, only the sDAQC technique is available in <code>qadence</code>.</p> <p>Just as before, we can check that using the transformed Ising circuit we exactly recover the CPHASE gate:</p> <pre><code># CPHASE on (i, j), Identity on third qubit:\ncphase_matrix = qd.block_to_tensor(qd.kron(CPHASE(i, j, phi), I(k)))\n# CPHASE using the transformed circuit:\ncphase_evo_matrix = qd.block_to_tensor(transformed_ising)\n# Will fail if global phases are ignored:\nassert torch.allclose(cphase_matrix, cphase_evo_matrix)\n</code></pre> <p>And we can now build the CNOT gate:</p> <pre><code>cnot_daqc = qd.chain(\nH(j),\ntransformed_ising,\nH(j)\n)\n# And finally run the CNOT on a specific 3-qubit initial state:\ninit_state = qd.product_state(\"101\")\n# Check we get an equivalent wavefunction (will still pass if global phases are ignored)\nwf_cnot = qd.run(n_qubits, block = cnot_target, state = init_state)\nwf_daqc = qd.run(n_qubits, block = cnot_daqc, state = init_state)\nassert qd.equivalent_state(wf_cnot, wf_daqc)\n# Visualize the CNOT bit-flip:\nprint(qd.sample(n_qubits, block = cnot_target, state = init_state, n_shots = 100))\nprint(qd.sample(n_qubits, block = cnot_daqc, state = init_state, n_shots = 100))\n</code></pre> <pre><code>[Counter({'111': 100})]\n[Counter({'111': 100})]\n</code></pre> <p>And we are done! We have effectively performed a CNOT operation on our desired target qubits by using only the global interaction of the system as the building block Hamiltonian, together with single-qubit rotations. Going through the trouble of decomposing a single digital gate into its Ising Hamiltonian is certainly not very practical, but it serves as a proof of principle for the potential of this technique to represent universal quantum computation. In the next example, we will see it applied to the digital-analog Quantum Fourier Transform.</p>"},{"location":"digital_analog_qc/daqc-cnot/#technical-details-on-the-daqc-transformation","title":"Technical details on the DAQC transformation","text":"<ul> <li>The mapping between target generator and final circuit is performed by solving a linear system of size \\(n(n-1)\\) where \\(n\\) is the number of qubits, so it can be computed efficiently (i.e., with a polynomial cost in the number of qubits).</li> <li>The linear system to be solved is actually not invertible for \\(n=4\\) qubits. This is very specific edge case requiring a workaround, that is currently not yet implemented.</li> <li>As mentioned, the final circuit has at most \\(n(n-1)\\) slices, so there is at most a polynomial overhead in circuit depth.</li> </ul> <p>Finally, and most important to its usage:</p> <ul> <li>The target Hamiltonian should be sufficiently represented in the building block Hamiltonian.</li> </ul> <p>To illustrate this point, consider the following target and build Hamiltonians:</p> <pre><code># Interaction between qubits 0 and 1\ngen_target = 1.0 * (Z(0) @ Z(1))\n# Fixed interaction between qubits 1 and 2, and customizable between 0 and 1\ndef gen_build(g_int):\nreturn g_int * (Z(0) @ Z(1)) + 1.0 * (Z(1) @ Z(2))\n</code></pre> <p>And now we perform the DAQC transform by setting <code>g_int = 1.0</code>, matching the target Hamiltonian:</p> <pre><code>transformed_ising = qd.daqc_transform(\nn_qubits = 3,\ngen_target = gen_target,\nt_f = 1.0,\ngen_build = gen_build(g_int = 1.0),\n)\n# display(transformed_ising)\n</code></pre> cluster_647710bcb3184f858df550143244d29b cluster_a27702f57e424be0a89d81fca60318e8 fb2988f29cf74da9ae4f80d0d0210f10 0 d12eb87aebd647bab2ef433d0699e97d X fb2988f29cf74da9ae4f80d0d0210f10--d12eb87aebd647bab2ef433d0699e97d 9d5fcf55f1334626b13a0bf1ed041128 1 a79401f006c94f9fa827fa0c583d6290 HamEvo d12eb87aebd647bab2ef433d0699e97d--a79401f006c94f9fa827fa0c583d6290 ef2f844ad7464d9bab1d8d461ba154a1 X a79401f006c94f9fa827fa0c583d6290--ef2f844ad7464d9bab1d8d461ba154a1 531254b3b76047b1a705c8c51a53ce42 ef2f844ad7464d9bab1d8d461ba154a1--531254b3b76047b1a705c8c51a53ce42 8e54a8088a2b48cb8633baa3564f1b8e HamEvo 531254b3b76047b1a705c8c51a53ce42--8e54a8088a2b48cb8633baa3564f1b8e ae204d52008c4fee942b68d6f6bbcd0a 8e54a8088a2b48cb8633baa3564f1b8e--ae204d52008c4fee942b68d6f6bbcd0a 7051141c3eac428988743c172e35f535 ae204d52008c4fee942b68d6f6bbcd0a--7051141c3eac428988743c172e35f535 075d78d0d0be42c28eed757cb0464df2 23fcc4aafb924698b7490b531a93ed2d 9d5fcf55f1334626b13a0bf1ed041128--23fcc4aafb924698b7490b531a93ed2d 66d070e1e1624edda397f09035375279 2 5f9447625fde4dda8f32c66d5810cc1b t = -0.500 23fcc4aafb924698b7490b531a93ed2d--5f9447625fde4dda8f32c66d5810cc1b 16ab46059f6546dcbecaa12299f9a6d5 5f9447625fde4dda8f32c66d5810cc1b--16ab46059f6546dcbecaa12299f9a6d5 ec21e31d01ef48c694e370161957771d X 16ab46059f6546dcbecaa12299f9a6d5--ec21e31d01ef48c694e370161957771d be2e5d37bab74489bf2293305d073a81 t = -0.500 ec21e31d01ef48c694e370161957771d--be2e5d37bab74489bf2293305d073a81 c4cfbd4544814d3a8b535e83e4978579 X be2e5d37bab74489bf2293305d073a81--c4cfbd4544814d3a8b535e83e4978579 c4cfbd4544814d3a8b535e83e4978579--075d78d0d0be42c28eed757cb0464df2 6fe81ea5a853462ca74fc792b8a4c2e1 307955cd854e4f59b67571616e63594b X 66d070e1e1624edda397f09035375279--307955cd854e4f59b67571616e63594b 150386cdabab4074978b3f78ac6dd106 307955cd854e4f59b67571616e63594b--150386cdabab4074978b3f78ac6dd106 d60271e325a049be94122e405dc19b48 X 150386cdabab4074978b3f78ac6dd106--d60271e325a049be94122e405dc19b48 9a20c34068f941518cd86dceecc25ad5 X d60271e325a049be94122e405dc19b48--9a20c34068f941518cd86dceecc25ad5 9c8866916a0f420ca7c07387600ae7c5 9a20c34068f941518cd86dceecc25ad5--9c8866916a0f420ca7c07387600ae7c5 0d410e3fc6be416e932cdf06eb9932b6 X 9c8866916a0f420ca7c07387600ae7c5--0d410e3fc6be416e932cdf06eb9932b6 0d410e3fc6be416e932cdf06eb9932b6--6fe81ea5a853462ca74fc792b8a4c2e1 <p>And we get the transformed circuit. What if our build Hamiltonian has a very weak interaction between qubits 0 and 1?</p> <pre><code>transformed_ising = qd.daqc_transform(\nn_qubits = 3,\ngen_target = gen_target,\nt_f = 1.0,\ngen_build = gen_build(g_int = 0.001),\n)\n# display(transformed_ising)\n</code></pre> cluster_582dc107016e4eb98f6e081ae62328cc cluster_548d58af6c0342cfb6a00c794a12b000 b8749f854ae24952855cd8c17e54e880 0 c9c57a4e78aa4da3a3e1886b517ba7bc X b8749f854ae24952855cd8c17e54e880--c9c57a4e78aa4da3a3e1886b517ba7bc f38c0d4639b14929885fb3d8836af047 1 8971a39fba594442abb4a1cabb7a38f5 HamEvo c9c57a4e78aa4da3a3e1886b517ba7bc--8971a39fba594442abb4a1cabb7a38f5 3bc07c4db4414a74b8e3de3d39f960b7 X 8971a39fba594442abb4a1cabb7a38f5--3bc07c4db4414a74b8e3de3d39f960b7 48e8a8ad47e84e3f9a4c544486fe430a 3bc07c4db4414a74b8e3de3d39f960b7--48e8a8ad47e84e3f9a4c544486fe430a 91c76490baef4a2aa763cda389adecc9 HamEvo 48e8a8ad47e84e3f9a4c544486fe430a--91c76490baef4a2aa763cda389adecc9 971c7489734b45d7a36dea3a8e855241 91c76490baef4a2aa763cda389adecc9--971c7489734b45d7a36dea3a8e855241 bd358c50010b45bb887dff1ba4f0e6f4 971c7489734b45d7a36dea3a8e855241--bd358c50010b45bb887dff1ba4f0e6f4 8dd51837a52d4a0a9749e5f218d6798d 68967e2f245d4384b7614a1efcee044c f38c0d4639b14929885fb3d8836af047--68967e2f245d4384b7614a1efcee044c b382c3adf57348838a8c20f2d2903aa6 2 58c7222a11f941c69a0e3b59b8b6dcef t = -500.000000000000 68967e2f245d4384b7614a1efcee044c--58c7222a11f941c69a0e3b59b8b6dcef 38b5eda61b894183acd0dfdcc85061dc 58c7222a11f941c69a0e3b59b8b6dcef--38b5eda61b894183acd0dfdcc85061dc 68a60e61944f4ae9b5b63de5737dd675 X 38b5eda61b894183acd0dfdcc85061dc--68a60e61944f4ae9b5b63de5737dd675 5874420a5c2142df904ce60db0670151 t = -500.000000000000 68a60e61944f4ae9b5b63de5737dd675--5874420a5c2142df904ce60db0670151 9ae56d62f0544282a0b28e4d7c99b95d X 5874420a5c2142df904ce60db0670151--9ae56d62f0544282a0b28e4d7c99b95d 9ae56d62f0544282a0b28e4d7c99b95d--8dd51837a52d4a0a9749e5f218d6798d 4231964201ff4ae8babf6c77198f48ae 876de106aa334586bbf5c5f4157bea23 X b382c3adf57348838a8c20f2d2903aa6--876de106aa334586bbf5c5f4157bea23 f05e975ae00c492fb97f38acb572a73b 876de106aa334586bbf5c5f4157bea23--f05e975ae00c492fb97f38acb572a73b f132f46497b94e3ea941c6a87e36493a X f05e975ae00c492fb97f38acb572a73b--f132f46497b94e3ea941c6a87e36493a 913164d3ecc34861a2ac5027905e9c75 X f132f46497b94e3ea941c6a87e36493a--913164d3ecc34861a2ac5027905e9c75 48a2c5788f06467997ee36050d869b93 913164d3ecc34861a2ac5027905e9c75--48a2c5788f06467997ee36050d869b93 284c6d5fdc3c48ada52dfac45591e26b X 48a2c5788f06467997ee36050d869b93--284c6d5fdc3c48ada52dfac45591e26b 284c6d5fdc3c48ada52dfac45591e26b--4231964201ff4ae8babf6c77198f48ae <p>As we can see, to represent the same interaction between 0 and 1, the slices using the build Hamiltonian need to evolve for much longer, since the target interaction is not sufficiently represented in the building block Hamiltonian.</p> <p>In the limit where that interaction is not present at all, the transform will not work:</p> <pre><code>try:\ntransformed_ising = qd.daqc_transform(\nn_qubits = 3,\ngen_target = gen_target,\nt_f = 1.0,\ngen_build = gen_build(g_int = 0.0),\n)\nexcept ValueError as error:\nprint(\"Error:\", error)\n</code></pre> <pre><code>Error: Incompatible interactions between target and build Hamiltonians.\n</code></pre>"},{"location":"digital_analog_qc/daqc-cnot/#references","title":"References","text":"<ol> <li> <p>Dodd et al., Universal quantum computation and simulation using any entangling Hamiltonian and local unitaries, PRA 65, 040301 (2002). \u21a9</p> </li> <li> <p>Parra-Rodriguez et al., Digital-Analog Quantum Computation, PRA 101, 022305 (2020). \u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"digital_analog_qc/pulser-basic/","title":"Pulse-level programming with Pulser","text":"<p>Qadence offers a direct interface with Pulser<sup>1</sup>, an open-source pulse-level interface written in Python and specifically designed for programming neutral atom quantum computers.</p> <p>Using directly Pulser requires deep knowledge on pulse-level programming and on how neutral atom devices work. Qadence abstracts this complexity out by using the familiar block-based interface for building pulse sequences in Pulser while leaving the possibility to directly manipulate them if required by, for instance, optimal pulse shaping.</p> <p>Note</p> <p>The Pulser backend is still experimental and the interface might change in the future.</p> <p>Let's see it in action.</p>"},{"location":"digital_analog_qc/pulser-basic/#default-qubit-interaction","title":"Default qubit interaction","text":"<p>When simulating pulse sequences written using Pulser, the underlying Hamiltonian it constructs is equivalent to a digital-analog quantum computing program with the following interaction Hamiltonian (see digital-analog emulation for more details):</p> \\[ \\mathcal{H}_{int} = \\sum_{i&lt;j} \\frac{C_6}{|R_i - R_j|^6} \\hat{n}_i \\hat{n}_j \\] <p>where \\(C_6\\) is an interaction coefficient which depends on the principal quantum number of chosen the neutral atom system, \\(R_i\\) are the atomic positions in Cartesian coordinates and \\(\\hat{n} = \\frac{1-\\sigma^z_i}{2}\\) is the number operator.</p> <p>Note</p> <p>The Ising interaction is always-on for all computations performed with the Pulser backend. It cannot be switched off.</p>"},{"location":"digital_analog_qc/pulser-basic/#available-quantum-operations","title":"Available quantum operations","text":"<p>Currently, the Pulser backend supports the following operations:</p> gate description trainable parameter <code>RX</code>, <code>RY</code> Single qubit rotations. Notice that the interaction is on and this affects the resulting gate fidelity. rotation angle <code>AnalogRX</code>, <code>AnalogRY</code>, <code>AnalogRZ</code> Span a single qubit rotation among the entire register. rotation angle <code>entangle</code> Fully entangle the register. interaction time <code>wait</code> An idle block to wait for the system to evolve for a specific time according to the interaction. free evolution time"},{"location":"digital_analog_qc/pulser-basic/#two-qubits-register-bell-state","title":"Two qubits register: Bell state","text":"<p>Using the <code>chain</code> block makes it easy to create a gate sequence. Here is an example of how to create a Bell state. The <code>entangle</code> operation uses <code>CZ</code> interactions (according to the interaction Hamiltonian introduced in the first paragraph of this section) to entangle states on the <code>X</code> basis. We move the qubits back to the <code>Z</code> basis for the readout using a <code>Y</code> rotation.</p> <pre><code>from qadence import chain, entangle, RY\nbell_state = chain(\nentangle(\"t\", qubit_support=(0,1)),\nRY(0, \"y\"),\n)\n</code></pre> <p>To convert the chain block into a pulse sequence, we define a <code>Register</code> with two qubits and combine it to create a circuit as usual. Then we construct a <code>QuantumModel</code> with a Pulser backend to convert it into a proper parametrized pulse sequence. Supplying the parameter values allows to sample from the pulse sequence result like any other Qadence backend.</p> <pre><code>import torch\nimport matplotlib.pyplot as plt\nfrom qadence import Register, QuantumCircuit, QuantumModel\nregister = Register(2)\ncircuit = QuantumCircuit(register, bell_state)\nmodel = QuantumModel(circuit, backend=\"pulser\", diff_mode=\"gpsr\")\nparams = {\n\"t\": torch.tensor([383]),  # ns\n\"y\": torch.tensor([3*torch.pi/2]),\n}\n# return the final state vector\nfinal_vector = model.run(params)\nprint(final_vector)\n# sample from the result state vector and plot the distribution\nsample = model.sample(params, n_shots=50)[0]\nprint(sample)\nfig, ax = plt.subplots()\nax.bar(sample.keys(), sample.values())\n</code></pre>   tensor([[-0.7080-0.0207j,  0.0395+0.3061j,  0.0039-0.0540j,  0.6220-0.1151j]]) Counter({'00': 27, '11': 18, '01': 5})  2023-10-12T16:59:41.698921 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ <p>One can visualise the pulse sequence with different parameters using the <code>assign_paramters</code> method.</p> <pre><code>model.assign_parameters(params).draw(show=False)\n</code></pre> 2023-10-12T16:59:41.755448 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"digital_analog_qc/pulser-basic/#change-device-specifications","title":"Change device specifications","text":"<p>At variance with other backends, the Pulser one provides the concept of <code>Device</code>, inherited from the Pulser. Check this tutorial for more information.</p> <p>A <code>Device</code> instance encapsulates all the properties for the definition of a real neutral atoms processor, including but not limited to the maximum laser amplitude for the pulses, the maximum distance between two qubits and the maximum duration of the pulse.</p> <p>Qadence offers a simplified interface with only two devices which are detailed here:</p> <ul> <li><code>IDEALIZED</code> (default): ideal device which should be used only for testing purposes. It does not have any limitation in what pulse sequences can run with it.</li> <li><code>REALISTIC</code>: device specification very similar to a real neutral atom quantum processor.</li> </ul> <p>Note</p> <p>If you want to perform simulations closer to the specifications of real neutral atom machines, always select the <code>REALISTIC</code> device.</p> <p>One can use the <code>Configuration</code> of the Pulser backend to select the appropriate device:</p> <pre><code>from qadence.backends.pulser.devices import Device\nregister = Register(2)\ncircuit = QuantumCircuit(register, bell_state)\n# choose a realistic device\nmodel = QuantumModel(\ncircuit,\nbackend=\"pulser\",\ndiff_mode=\"gpsr\",\nconfiguration={\"device_type\": Device.REALISTIC}\n)\nparams = {\n\"t\": torch.tensor([383]),  # ns\n\"y\": torch.tensor([3*torch.pi/2]),\n}\n# sample from the result state vector and plot the distribution\nsample = model.sample(params, n_shots=50)[0]\nprint(sample)\n</code></pre>   Counter({'00': 26, '01': 18, '11': 6})"},{"location":"digital_analog_qc/pulser-basic/#create-your-own-gate","title":"Create your own gate","text":"<p>A big advantage of using the block-based interface if  Qadence is that it makes it easy to create complex operations from simple ones as a block composition. In the following, we use the entanglement operation as an example.</p> <p>The operation consists of moving all the qubits to the <code>X</code> basis having the atoms' interaction perform a controlled-Z operation during the free evolution. And we can easily recreate this pattern using the <code>wait</code> (corresponding to free evolution) and <code>AnalogRY</code> blocks with appropriate parameters.</p> <pre><code>from qadence import AnalogRY, chain, wait\ndef my_entanglement(duration):\nreturn chain(\nAnalogRY(-torch.pi / 2),\nwait(duration)\n)\nprotocol = chain(\nmy_entanglement(\"t\"),\nRY(0, \"y\"),\n)\nregister = Register(2)\ncircuit = QuantumCircuit(register, protocol)\nmodel = QuantumModel(circuit, backend=\"pulser\", diff_mode='gpsr')\nparams = {\n\"t\": torch.tensor([383]),  # ns\n\"y\": torch.tensor([torch.pi / 2]),\n}\nsample = model.sample(params, n_shots=50)[0]\nfig, ax = plt.subplots()\nplt.bar(sample.keys(), sample.values())\n</code></pre> 2023-10-12T16:59:41.999030 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"digital_analog_qc/pulser-basic/#digital-analog-qnn-circuit","title":"Digital-analog QNN circuit","text":"<p>Finally, let's put all together by constructing a digital-analog version of a quantum neural network circuit with feature map and variational ansatz.</p> <pre><code>from qadence import kron, fourier_feature_map\nfrom qadence.operations import RX, RY, AnalogRX\nhea_one_layer = chain(\nkron(RY(0, \"th00\"), RY(1, \"th01\")),\nkron(RX(0, \"th10\"), RX(1, \"th11\")),\nkron(RY(0, \"th20\"), RY(1, \"th21\")),\nentangle(\"t\", qubit_support=(0,1)),\n)\nprotocol = chain(\nfourier_feature_map(1, param=\"x\"),\nhea_one_layer,\nAnalogRX(torch.pi/4)\n)\nregister = Register(2)\ncircuit = QuantumCircuit(register, protocol)\nmodel = QuantumModel(circuit, backend=\"pulser\", diff_mode=\"gpsr\")\nparams = {\n\"x\": torch.tensor([0.8]), # rad\n\"t\": torch.tensor([900]), # ns\n\"th00\":  torch.rand(1), # rad\n\"th01\":  torch.rand(1), # rad\n\"th10\":  torch.rand(1), # rad\n\"th11\":  torch.rand(1), # rad\n\"th20\":  torch.rand(1), # rad\n\"th21\":  torch.rand(1), # rad\n}\nmodel.assign_parameters(params).draw(draw_phase_area=True, show=False)\n</code></pre> 2023-10-12T16:59:42.069145 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"digital_analog_qc/pulser-basic/#references","title":"References","text":"<ol> <li> <p>Pulser: An open-source package for the design of pulse sequences in programmable neutral-atom arrays \u21a9</p> </li> </ol>"},{"location":"qadence/blocks/","title":"Block system","text":"<p><code>qadence</code> offers a block-based system to construct quantum circuits in a flexible manner.</p>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock","title":"<code>AbstractBlock</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Base class for both primitive and composite blocks</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>A human-readable name attached to the block type. Notice, this is the same for all the class instances so it cannot be used for identifying different blocks</p> <p> TYPE: <code>str</code> </p> <code>qubit_support</code> <p>The qubit support of the block expressed as a tuple of integers</p> <p> TYPE: <code>tuple[int, ...]</code> </p> <code>tag</code> <p>A tag identifying a particular instance of the block which can be used for identification and pretty printing</p> <p> TYPE: <code>str | None</code> </p> <code>eigenvalues</code> <p>The eigenvalues of the matrix representing the block. This is used mainly for primitive blocks and it's needed for generalized parameter shift rule computations. Currently unused.</p> <p> TYPE: <code>list[float] | None</code> </p>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock.is_identity","title":"<code>is_identity: bool</code>  <code>property</code>","text":"<p>Identity predicate for blocks.</p>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock.n_qubits","title":"<code>n_qubits()</code>","text":"<p>The number of qubits in the whole system. A block acting on qubit N would has at least n_qubits &gt;= N + 1.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef n_qubits(self) -&gt; int:\n\"\"\"The number of qubits in the whole system.\n    A block acting on qubit N would has at least n_qubits &gt;= N + 1.\"\"\"\npass\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock.n_supports","title":"<code>n_supports()</code>","text":"<p>The number of qubits the block is acting on.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef n_supports(self) -&gt; int:\n\"\"\"The number of qubits the block is acting on.\"\"\"\npass\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.abstract.AbstractBlock.qubit_support","title":"<code>qubit_support()</code>","text":"<p>The indices of the qubit(s) the block is acting on. Qadence uses the ordering [0..,N-1] for qubits.</p> Source code in <code>qadence/blocks/abstract.py</code> <pre><code>@abstractproperty\ndef qubit_support(self) -&gt; Tuple[int, ...]:\n\"\"\"The indices of the qubit(s) the block is acting on.\n    Qadence uses the ordering [0..,N-1] for qubits.\"\"\"\npass\n</code></pre>"},{"location":"qadence/blocks/#primitive-blocks","title":"Primitive blocks","text":""},{"location":"qadence/blocks/#qadence.blocks.primitive.ControlBlock","title":"<code>ControlBlock(control, target_block)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The abstract ControlBlock</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, control: tuple[int, ...], target_block: PrimitiveBlock) -&gt; None:\nself.blocks = (target_block,)\n# using tuple expansion because some control operations could\n# have multiple targets, e.g. CSWAP\nsuper().__init__((*control, *target_block.qubit_support))  # target_block.qubit_support[0]))\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.ParametricBlock","title":"<code>ParametricBlock(qubit_support)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>Parameterized primitive blocks</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, qubit_support: tuple[int, ...]):\nself._qubit_support = qubit_support\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.ParametricBlock.num_parameters","title":"<code>num_parameters()</code>  <code>abstractmethod</code>","text":"<p>The number of parameters required by the block</p> <p>This is a class property since the number of parameters is defined automatically before instantiating the operation. Also, this could correspond to a larger number of actual user-facing parameters since any parameter expression is allowed</p> <p>Examples: - RX operation has 1 parameter - U operation has 3 parameters - HamEvo has 2 parameters (generator and time evolution)</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>@abstractmethod\ndef num_parameters(cls) -&gt; int:\n\"\"\"The number of parameters required by the block\n    This is a class property since the number of parameters is defined\n    automatically before instantiating the operation. Also, this could\n    correspond to a larger number of actual user-facing parameters\n    since any parameter expression is allowed\n    Examples:\n    - RX operation has 1 parameter\n    - U operation has 3 parameters\n    - HamEvo has 2 parameters (generator and time evolution)\n    \"\"\"\npass\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.ParametricControlBlock","title":"<code>ParametricControlBlock(control, target_block)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The abstract parametrized ControlBlock</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, control: tuple[int, ...], target_block: ParametricBlock) -&gt; None:\nself.blocks = (target_block,)\nself.parameters = target_block.parameters\nsuper().__init__((*control, target_block.qubit_support[0]))\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.PrimitiveBlock","title":"<code>PrimitiveBlock(qubit_support)</code>","text":"<p>             Bases: <code>AbstractBlock</code></p> <p>Primitive blocks represent elementary unitary operations such as single/multi-qubit gates or Hamiltonian evolution. See <code>qadence.operations</code> for a full list of primitive blocks.</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, qubit_support: tuple[int, ...]):\nself._qubit_support = qubit_support\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.PrimitiveBlock.digital_decomposition","title":"<code>digital_decomposition()</code>","text":"<p>Decomposition into purely digital gates</p> <p>This method returns a decomposition of the Block in a combination of purely digital single-qubit and two-qubit 'gates', by manual/custom knowledge of how this can be done efficiently. :return:</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def digital_decomposition(self) -&gt; AbstractBlock:\n\"\"\"Decomposition into purely digital gates\n    This method returns a decomposition of the Block in a\n    combination of purely digital single-qubit and two-qubit\n    'gates', by manual/custom knowledge of how this can be done efficiently.\n    :return:\n    \"\"\"\nreturn self\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.ScaleBlock","title":"<code>ScaleBlock(block, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>Scale blocks are created when multiplying a block by a number or parameter.</p> <p>Example: <pre><code>from qadence import X\nprint(X(0) * 2)\n</code></pre> <pre><code>[mul: 2] \u2514\u2500\u2500 X(0)\n</code></pre> </p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, block: AbstractBlock, parameter: Any):\nself.block = block\n# TODO: more meaningful name like `scale`?\nself.parameters = (\nparameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n)\nsuper().__init__(block.qubit_support)\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.primitive.TimeEvolutionBlock","title":"<code>TimeEvolutionBlock(qubit_support)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>Simple time evolution block with time-independent Hamiltonian</p> <p>This class is just a convenience class which is used to label blocks which contains simple time evolution with time-independent Hamiltonian operators</p> Source code in <code>qadence/blocks/primitive.py</code> <pre><code>def __init__(self, qubit_support: tuple[int, ...]):\nself._qubit_support = qubit_support\n</code></pre>"},{"location":"qadence/blocks/#analog-blocks","title":"Analog blocks","text":"<p>To learn how to use analog blocks and how to mix digital &amp; analog blocks, check out the digital-analog section of the documentation.</p> <p>Examples on how to use digital-analog blocks can be found in the *examples folder of the qadence repo:</p> <ul> <li>Fit a simple sinus: <code>examples/digital-analog/fit-sin.py</code></li> <li>Solve a QUBO: <code>examples/digital-analog/qubo.py</code></li> </ul>"},{"location":"qadence/blocks/#qadence.blocks.analog.AnalogChain","title":"<code>AnalogChain(blocks)</code>  <code>dataclass</code>","text":"<p>             Bases: <code>AnalogComposite</code></p> <p>A chain of analog blocks. Needed because analog blocks require stricter validation than the general <code>ChainBlock</code>.</p> <p><code>AnalogChain</code>s can only be constructed from <code>AnalogKron</code> blocks or globally supported, primitive, analog blocks (like <code>WaitBlock</code>s and <code>ConstantAnalogRotation</code>s).</p> <p>Automatically constructed by the <code>chain</code> function if only analog blocks are given.</p> <p>Example: <pre><code>from qadence import X, chain, wait\nb = chain(wait(200), wait(200))\nprint(type(b))  # this is an `AnalogChain`\nb = chain(X(0), wait(200))\nprint(type(b))  # this is a general `ChainBlock`\n</code></pre> <pre><code>&lt;class 'qadence.blocks.analog.AnalogChain'&gt;\n&lt;class 'qadence.blocks.composite.ChainBlock'&gt;\n</code></pre> </p> Source code in <code>qadence/blocks/analog.py</code> <pre><code>def __init__(self, blocks: Tuple[AnalogBlock, ...]):\n\"\"\"A chain of analog blocks. Needed because analog blocks require\n    stricter validation than the general `ChainBlock`.\n    `AnalogChain`s can only be constructed from `AnalogKron` blocks or\n    _**globally supported**_, primitive, analog blocks (like `WaitBlock`s and\n    `ConstantAnalogRotation`s).\n    Automatically constructed by the [`chain`][qadence.blocks.utils.chain]\n    function if only analog blocks are given.\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, chain, wait\n    b = chain(wait(200), wait(200))\n    print(type(b))  # this is an `AnalogChain`\n    b = chain(X(0), wait(200))\n    print(type(b))  # this is a general `ChainBlock`\n    ```\n    \"\"\"\nfor b in blocks:\nif not (isinstance(b, AnalogKron) or b.qubit_support.is_global):\nraise ValueError(\"Only KronBlocks or global blocks can be chain'ed.\")\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.analog.AnalogKron","title":"<code>AnalogKron(blocks, interaction=Interaction.NN)</code>  <code>dataclass</code>","text":"<p>             Bases: <code>AnalogComposite</code></p> <p>Stack analog blocks vertically (i.e. in time). Needed because analog require stricter validation than the general <code>KronBlock</code>.</p> <p><code>AnalogKron</code>s can only be constructed from non-global, analog blocks with the same duration.</p> Source code in <code>qadence/blocks/analog.py</code> <pre><code>def __init__(self, blocks: Tuple[AnalogBlock, ...], interaction: Interaction = Interaction.NN):\n\"\"\"Stack analog blocks vertically (i.e. in time). Needed because analog require\n    stricter validation than the general `KronBlock`.\n    `AnalogKron`s can only be constructed from _**non-global**_, analog blocks\n    with the _**same duration**_.\n    \"\"\"\nif len(blocks) == 0:\nraise NotImplementedError(\"Empty KronBlocks not supported\")\nself.blocks = blocks\nself.interaction = interaction\nqubit_support = QubitSupport()\nduration = blocks[0].duration\nfor b in blocks:\nif not isinstance(b, AnalogBlock):\nraise ValueError(\"Can only kron `AnalgoBlock`s with other `AnalgoBlock`s.\")\nif b.qubit_support == QubitSupport(\"global\"):\nraise ValueError(\"Blocks with global support cannot be kron'ed.\")\nif not qubit_support.is_disjoint(b.qubit_support):\nraise ValueError(\"Make sure blocks act on distinct qubits!\")\nif not np.isclose(evaluate(duration), evaluate(b.duration)):\nraise ValueError(\"Kron'ed blocks have to have same duration.\")\nqubit_support += b.qubit_support\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.analog.ConstantAnalogRotation","title":"<code>ConstantAnalogRotation</code>  <code>dataclass</code>","text":"<p>             Bases: <code>AnalogBlock</code></p> <p>Implements a constant analog rotation with interaction dictated by the chosen Hamiltonian</p> <pre><code>H = \u2211\u1d62(h\u03a9/2 sin(\u03c6)*X\u1d62 - cos(\u03c6)*Y\u1d62 - h\u03b4n\u1d62) + H\u1d62\u2099\u209c.\n</code></pre> <p>To construct this block you can use of the following convenience wrappers: - The general rotation operation <code>AnalogRot</code> - Shorthands for rotatins around an axis:   <code>AnalogRX</code>,   <code>AnalogRY</code>,   <code>AnalogRZ</code></p> <p>Can be used with <code>add_interaction</code>. WARNING: do not use <code>ConstantAnalogRotation</code> with <code>alpha</code> as differentiable parameter - use the convenience wrappers mentioned above.</p>"},{"location":"qadence/blocks/#qadence.blocks.analog.WaitBlock","title":"<code>WaitBlock</code>  <code>dataclass</code>","text":"<p>             Bases: <code>AnalogBlock</code></p> <p>Waits. In real interacting quantum devices, it means letting the system evolve freely according to the time-dependent Schrodinger equation. With emulators, this block is translated to an appropriate interaction Hamiltonian, for example, an Ising interation</p> <pre><code>H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2086/r\u1d62\u2c7c\u2076 n\u1d62n\u2c7c\n</code></pre> <p>or an XY-interaction</p> <pre><code>H\u1d62\u2099\u209c = \u2211\u1d62\u2c7c C\u2083/r\u2c7c\u2c7c\u00b3 (X\u1d62X\u2c7c + Z\u1d62Z\u2c7c)\n</code></pre> <p>with <code>n\u1d62 = (1-Z\u1d62)/2</code>.</p> <p>To construct this block, use the <code>wait</code> function.</p> <p>Can be used with <code>add_interaction</code>.</p>"},{"location":"qadence/blocks/#composite-blocks","title":"Composite blocks","text":""},{"location":"qadence/blocks/#qadence.blocks.utils.chain","title":"<code>chain(*args)</code>","text":"<p>Chain blocks sequentially. On digital backends this can be interpreted loosely as a matrix mutliplication of blocks. In the analog case it chains blocks in time.</p> PARAMETER  DESCRIPTION <code>*args</code> <p>Blocks to chain. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator, List[AbstractBlock]]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>ChainBlock</p> <p>Example: <pre><code>from qadence import X, Y, chain\nb = chain(X(0), Y(0))\n# or use a generator\nb = chain(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>ChainBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def chain(*args: Union[AbstractBlock, Generator, List[AbstractBlock]]) -&gt; ChainBlock:\n\"\"\"Chain blocks sequentially. On digital backends this can be interpreted\n    loosely as a matrix mutliplication of blocks. In the analog case it chains\n    blocks in time.\n    Arguments:\n        *args: Blocks to chain. Can also be a generator.\n    Returns:\n        ChainBlock\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, chain\n    b = chain(X(0), Y(0))\n    # or use a generator\n    b = chain(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n# ugly hack to use `AnalogChain` if we are dealing only with analog blocks\nif len(args) and all(\nisinstance(a, AnalogBlock) or isinstance(a, AnalogComposite) for a in args\n):\nreturn analog_chain(*args)  # type: ignore[return-value,arg-type]\nreturn _construct(ChainBlock, args)\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.utils.kron","title":"<code>kron(*args)</code>","text":"<p>Stack blocks vertically. On digital backends this can be intepreted loosely as a kronecker product of blocks. In the analog case it executes blocks parallel in time.</p> PARAMETER  DESCRIPTION <code>*args</code> <p>Blocks to kron. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>KronBlock</p> <p>Example: <pre><code>from qadence import X, Y, kron\nb = kron(X(0), Y(1))\n# or use a generator\nb = kron(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def kron(*args: Union[AbstractBlock, Generator]) -&gt; KronBlock:\n\"\"\"Stack blocks vertically. On digital backends this can be intepreted\n    loosely as a kronecker product of blocks. In the analog case it executes\n    blocks parallel in time.\n    Arguments:\n        *args: Blocks to kron. Can also be a generator.\n    Returns:\n        KronBlock\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, kron\n    b = kron(X(0), Y(1))\n    # or use a generator\n    b = kron(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\n# ugly hack to use `AnalogKron` if we are dealing only with analog blocks\nif len(args) and all(\nisinstance(a, AnalogBlock) or isinstance(a, AnalogComposite) for a in args\n):\nreturn analog_kron(*args)  # type: ignore[return-value,arg-type]\nreturn _construct(KronBlock, args)\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.utils.add","title":"<code>add(*args)</code>","text":"<p>Sums blocks.</p> PARAMETER  DESCRIPTION <code>*args</code> <p>Blocks to add. Can also be a generator.</p> <p> TYPE: <code>Union[AbstractBlock, Generator]</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>AddBlock</code> <p>AddBlock</p> <p>Example: <pre><code>from qadence import X, Y, add\nb = add(X(0), Y(0))\n# or use a generator\nb = add(X(i) for i in range(3))\nprint(b)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> </p> Source code in <code>qadence/blocks/utils.py</code> <pre><code>def add(*args: Union[AbstractBlock, Generator]) -&gt; AddBlock:\n\"\"\"Sums blocks.\n    Arguments:\n        *args: Blocks to add. Can also be a generator.\n    Returns:\n        AddBlock\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import X, Y, add\n    b = add(X(0), Y(0))\n    # or use a generator\n    b = add(X(i) for i in range(3))\n    print(b)\n    ```\n    \"\"\"\nreturn _construct(AddBlock, args)\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.composite.AddBlock","title":"<code>AddBlock(blocks)</code>","text":"<p>             Bases: <code>CompositeBlock</code></p> <p>Adds blocks. Constructed via <code>add</code>.</p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.composite.ChainBlock","title":"<code>ChainBlock(blocks)</code>","text":"<p>             Bases: <code>CompositeBlock</code></p> <p>Chains blocks sequentially. Constructed via <code>chain</code></p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#qadence.blocks.composite.CompositeBlock","title":"<code>CompositeBlock</code>","text":"<p>             Bases: <code>AbstractBlock</code></p> <p>Block which composes multiple blocks into one larger block (which can again be composed). Composite blocks are constructed via <code>chain</code>, <code>kron</code>, and <code>add</code>.</p>"},{"location":"qadence/blocks/#qadence.blocks.composite.KronBlock","title":"<code>KronBlock(blocks)</code>","text":"<p>             Bases: <code>CompositeBlock</code></p> <p>Stacks blocks horizontally. Constructed via <code>kron</code>.</p> Source code in <code>qadence/blocks/composite.py</code> <pre><code>def __init__(self, blocks: Tuple[AbstractBlock, ...]):\nif len(blocks) == 0:\nraise NotImplementedError(\"Empty KronBlocks not supported\")\nqubit_support = QubitSupport()\nfor b in blocks:\nassert (\nQubitSupportType.GLOBAL,\n) != b.qubit_support, \"Blocks with global support cannot be kron'ed.\"\nassert qubit_support.is_disjoint(\nb.qubit_support\n), \"Make sure blocks act on distinct qubits!\"\nqubit_support += b.qubit_support\nself.blocks = blocks\n</code></pre>"},{"location":"qadence/blocks/#converting-blocks-to-matrices","title":"Converting blocks to matrices","text":""},{"location":"qadence/blocks/#qadence.blocks.block_to_tensor.block_to_tensor","title":"<code>block_to_tensor(block, values={}, qubit_support=None, use_full_support=True, tensor_type=TensorType.DENSE, endianness=Endianness.BIG)</code>","text":"<p>Convert a block into a torch tensor.</p> PARAMETER  DESCRIPTION <code>block</code> <p>The block to convert.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>values</code> <p>A optional dict with values for parameters.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>qubit_support</code> <p>The qubit_support of the block.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>use_full_support</code> <p>True infers the total number of qubits.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>tensor_type</code> <p>the target tensor type.</p> <p> TYPE: <code>TensorType</code> DEFAULT: <code>DENSE</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence import hea, hamiltonian_factory, Z, block_to_tensor\nblock = hea(2,2)\nprint(block_to_tensor(block))\n# In case you have a diagonal observable, you can use\nobs = hamiltonian_factory(2, detuning = Z)\nprint(block_to_tensor(obs, tensor_type=\"SparseDiagonal\"))\n</code></pre> <pre><code>tensor([[[ 0.5034+0.1645j, -0.2575-0.4773j, -0.1863-0.2398j, -0.5771+0.0125j],\n[ 0.0301-0.4791j,  0.5561+0.0912j, -0.5891-0.2234j, -0.1547-0.1766j],\n[-0.1238-0.5348j, -0.3862-0.0394j,  0.2656+0.1068j, -0.1997-0.6528j],\n[-0.3733-0.2200j, -0.1777-0.4539j,  0.0268-0.6544j,  0.3337+0.1853j]]],\ngrad_fn=&lt;UnsafeViewBackward0&gt;)\ntensor(indices=tensor([[0, 3],\n[0, 3]]),\nvalues=tensor([ 2.+0.j, -2.+0.j]),\nsize=(4, 4), nnz=2, layout=torch.sparse_coo)\n</code></pre> </p> Source code in <code>qadence/blocks/block_to_tensor.py</code> <pre><code>def block_to_tensor(\nblock: AbstractBlock,\nvalues: dict[str, TNumber | torch.Tensor] = {},\nqubit_support: tuple | None = None,\nuse_full_support: bool = True,\ntensor_type: TensorType = TensorType.DENSE,\nendianness: Endianness = Endianness.BIG,\n) -&gt; torch.Tensor:\n\"\"\"\n    Convert a block into a torch tensor.\n    Arguments:\n        block (AbstractBlock): The block to convert.\n        values (dict): A optional dict with values for parameters.\n        qubit_support (tuple): The qubit_support of the block.\n        use_full_support (bool): True infers the total number of qubits.\n        tensor_type (TensorType): the target tensor type.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import hea, hamiltonian_factory, Z, block_to_tensor\n    block = hea(2,2)\n    print(block_to_tensor(block))\n    # In case you have a diagonal observable, you can use\n    obs = hamiltonian_factory(2, detuning = Z)\n    print(block_to_tensor(obs, tensor_type=\"SparseDiagonal\"))\n    ```\n    \"\"\"\n# FIXME: default use_full_support to False. In general, it would\n# be more efficient to do that, and make sure that computations such\n# as observables only do the matmul of the size of the qubit support.\nif tensor_type == TensorType.DENSE:\nfrom qadence.blocks import embedding\n(ps, embed) = embedding(block)\nreturn _block_to_tensor_embedded(\nblock, embed(ps, values), qubit_support, use_full_support, endianness=endianness\n)\nelif tensor_type == TensorType.SPARSEDIAGONAL:\nt = block_to_diagonal(block, endianness=endianness)\nindices, values, size = torch.nonzero(t), t[t != 0], len(t)\nindices = torch.stack((indices.flatten(), indices.flatten()))\nreturn torch.sparse_coo_tensor(indices, values, (size, size))\n</code></pre>"},{"location":"qadence/constructors/","title":"Constructors for common quantum circuits","text":""},{"location":"qadence/constructors/#qadence.constructors.feature_maps.chebyshev_feature_map","title":"<code>chebyshev_feature_map(n_qubits, support=None, param='phi', op=RX)</code>","text":"<p>Construct a Chebyshev feature map</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits across which the FM is created</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>The qubit support</p> <p> TYPE: <code>Iterable[int]</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>The base name for the feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'phi'</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def chebyshev_feature_map(\nn_qubits: int, support: tuple[int, ...] = None, param: str = \"phi\", op: Type[Rotation] = RX\n) -&gt; AbstractBlock:\n\"\"\"Construct a Chebyshev feature map\n    Args:\n        n_qubits: number of qubits across which the FM is created\n        support (Iterable[int]): The qubit support\n        param: The base name for the feature `Parameter`\n    \"\"\"\nfm = feature_map(n_qubits, support=support, param=param, op=op, fm_type=\"chebyshev\")\nreturn tag(fm, tag=\"ChebyshevFM\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.feature_maps.exp_fourier_feature_map","title":"<code>exp_fourier_feature_map(n_qubits, support=None, param='x', feature_range=None)</code>","text":"<p>Exponential fourier feature map.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the feature</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>qubit support</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>name of feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'x'</code> </p> <code>feature_range</code> <p>min and max value of the feature, as floats in a Tuple</p> <p> TYPE: <code>tuple[float, float]</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def exp_fourier_feature_map(\nn_qubits: int,\nsupport: tuple[int, ...] = None,\nparam: str = \"x\",\nfeature_range: tuple[float, float] = None,\n) -&gt; AbstractBlock:\n\"\"\"\n    Exponential fourier feature map.\n    Args:\n        n_qubits: number of qubits in the feature\n        support: qubit support\n        param: name of feature `Parameter`\n        feature_range: min and max value of the feature, as floats in a Tuple\n    \"\"\"\nif feature_range is None:\nfeature_range = (0.0, 2.0**n_qubits)\nif support is None:\nsupport = tuple(range(n_qubits))\nxmax = max(feature_range)\nxmin = min(feature_range)\nx = Parameter(param, trainable=False)\n# The feature map works on the range of 0 to 2**n\nx_rescaled = 2 * np.pi * (x - xmin) / (xmax - xmin)\nhlayer = kron(H(qubit) for qubit in support)\nrlayer = kron(RZ(support[i], x_rescaled * (2**i)) for i in range(n_qubits))\nreturn tag(chain(hlayer, rlayer), f\"ExpFourierFM({param})\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.feature_maps.feature_map","title":"<code>feature_map(n_qubits, support=None, param='phi', op=RX, fm_type='fourier')</code>","text":"<p>Construct a feature map of a given type.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>Number of qubits the feature map covers. Results in <code>support=range(n_qubits)</code>.</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>Overrides <code>n_qubits</code>. Puts one rotation gate on every qubit in <code>support</code>.</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>param</code> <p>Parameter of the feature map.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'phi'</code> </p> <code>op</code> <p>Rotation operation of the feature map.</p> <p> TYPE: <code>Type[Rotation]</code> DEFAULT: <code>RX</code> </p> <code>fm_type</code> <p>Determines the additional expression the final feature parameter (the addtional term in front of <code>param</code>). <code>\"fourier\": param</code> (nothing is done to <code>param</code>) <code>\"chebyshev\": 2*acos(param)</code>, <code>\"tower\": (i+1)*2*acos(param)</code> (where <code>i</code> is the qubit index).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'fourier'</code> </p> <p>Example: <pre><code>from qadence import feature_map\nfm = feature_map(3, fm_type=\"fourier\")\nprint(f\"{fm = }\")\nfm = feature_map(3, fm_type=\"chebyshev\")\nprint(f\"{fm = }\")\nfm = feature_map(3, fm_type=\"tower\")\nprint(f\"{fm = }\")\n</code></pre> <pre><code>fm = KronBlock(0,1,2) [tag: FM]\n\u251c\u2500\u2500 RX(0) [params: ['phi']]\n\u251c\u2500\u2500 RX(1) [params: ['phi']]\n\u2514\u2500\u2500 RX(2) [params: ['phi']]\nfm = KronBlock(0,1,2) [tag: FM]\n\u251c\u2500\u2500 RX(0) [params: ['2*acos(phi)']]\n\u251c\u2500\u2500 RX(1) [params: ['2*acos(phi)']]\n\u2514\u2500\u2500 RX(2) [params: ['2*acos(phi)']]\nfm = KronBlock(0,1,2) [tag: FM]\n\u251c\u2500\u2500 RX(0) [params: ['2*acos(phi)']]\n\u251c\u2500\u2500 RX(1) [params: ['4*acos(phi)']]\n\u2514\u2500\u2500 RX(2) [params: ['6*acos(phi)']]\n</code></pre> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def feature_map(\nn_qubits: int,\nsupport: tuple[int, ...] = None,\nparam: str = \"phi\",\nop: Type[Rotation] = RX,\nfm_type: str = \"fourier\",\n) -&gt; KronBlock:\n\"\"\"Construct a feature map of a given type.\n    Arguments:\n        n_qubits: Number of qubits the feature map covers. Results in `support=range(n_qubits)`.\n        support: Overrides `n_qubits`. Puts one rotation gate on every qubit in `support`.\n        param: Parameter of the feature map.\n        op: Rotation operation of the feature map.\n        fm_type: Determines the additional expression the final feature parameter (the addtional\n            term in front of `param`). `\"fourier\": param` (nothing is done to `param`)\n            `\"chebyshev\": 2*acos(param)`, `\"tower\": (i+1)*2*acos(param)` (where `i` is the qubit\n            index).\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import feature_map\n    fm = feature_map(3, fm_type=\"fourier\")\n    print(f\"{fm = }\")\n    fm = feature_map(3, fm_type=\"chebyshev\")\n    print(f\"{fm = }\")\n    fm = feature_map(3, fm_type=\"tower\")\n    print(f\"{fm = }\")\n    ```\n    \"\"\"\nfparam = FeatureParameter(param)\nif support is None:\nsupport = tuple(range(n_qubits))\nassert len(support) &lt;= n_qubits, \"Wrong qubit support supplied\"\nif fm_type == \"fourier\":\nfm = kron(*[op(qubit, fparam) for qubit in support])\nelif fm_type == \"chebyshev\":\nfm = kron(*[op(qubit, 2 * sympy.acos(fparam)) for qubit in support])\nelif fm_type == \"tower\":\nfm = kron(*[op(qubit, (i + 1) * 2 * sympy.acos(fparam)) for i, qubit in enumerate(support)])\nelse:\nraise NotImplementedError(f\"Feature map {fm_type} not implemented\")\nfm.tag = \"FM\"\nreturn fm\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.feature_maps.fourier_feature_map","title":"<code>fourier_feature_map(n_qubits, support=None, param='phi', op=RX)</code>","text":"<p>Construct a Fourier feature map</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits across which the FM is created</p> <p> TYPE: <code>int</code> </p> <code>param</code> <p>The base name for the feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'phi'</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def fourier_feature_map(\nn_qubits: int, support: tuple[int, ...] = None, param: str = \"phi\", op: Type[Rotation] = RX\n) -&gt; AbstractBlock:\n\"\"\"Construct a Fourier feature map\n    Args:\n        n_qubits: number of qubits across which the FM is created\n        param: The base name for the feature `Parameter`\n    \"\"\"\nfm = feature_map(n_qubits, support=support, param=param, op=op, fm_type=\"fourier\")\nreturn tag(fm, tag=\"FourierFM\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.feature_maps.tower_feature_map","title":"<code>tower_feature_map(n_qubits, support=None, param='phi', op=RX)</code>","text":"<p>Construct a Chebyshev tower feature map</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits across which the FM is created</p> <p> TYPE: <code>int</code> </p> <code>param</code> <p>The base name for the feature <code>Parameter</code></p> <p> TYPE: <code>str</code> DEFAULT: <code>'phi'</code> </p> Source code in <code>qadence/constructors/feature_maps.py</code> <pre><code>def tower_feature_map(\nn_qubits: int, support: tuple[int, ...] = None, param: str = \"phi\", op: Type[Rotation] = RX\n) -&gt; AbstractBlock:\n\"\"\"Construct a Chebyshev tower feature map\n    Args:\n        n_qubits: number of qubits across which the FM is created\n        param: The base name for the feature `Parameter`\n    \"\"\"\nfm = feature_map(n_qubits, support=support, param=param, op=op, fm_type=\"tower\")\nreturn tag(fm, tag=\"TowerFM\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.ansatze.build_qnn","title":"<code>build_qnn(n_qubits, n_features, depth=None, ansatz=None, fm_pauli=RY, spectrum='simple', basis='fourier', fm_strategy='parallel')</code>","text":"<p>Helper function to build a qadence QNN quantum circuit</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>n_features</code> <p>The number of input dimensions.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>The depth of the ansatz.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>ansatz</code> <p>An optional argument to pass a custom qadence ansatz.</p> <p> TYPE: <code>Optional[AbstractBlock]</code> DEFAULT: <code>None</code> </p> <code>fm_pauli</code> <p>The type of Pauli gate for the feature map. Must be one of 'RX', 'RY', or 'RZ'.</p> <p> TYPE: <code>str</code> DEFAULT: <code>RY</code> </p> <code>spectrum</code> <p>The desired spectrum of the feature map generator. The options simple, tower and exponential produce a spectrum with linear, quadratic and exponential eigenvalues with respect to the number of qubits.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'simple'</code> </p> <code>basis</code> <p>The encoding function. The options fourier and chebyshev correspond to \u03a6(x)=x and arcos(x) respectively.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'fourier'</code> </p> <code>fm_strategy</code> <p>The feature map encoding strategy. If \"parallel\", the features are encoded in one block of rotation gates, with each feature given an equal number of qubits. If \"serial\", the features are encoded sequentially, with a HEA block between.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'parallel'</code> </p> RETURNS DESCRIPTION <code>list[AbstractBlock]</code> <p>A list of Abstract blocks to be used for constructing a quantum circuit</p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def build_qnn(\nn_qubits: int,\nn_features: int,\ndepth: int = None,\nansatz: Optional[AbstractBlock] = None,\nfm_pauli: Type[RY] = RY,\nspectrum: str = \"simple\",\nbasis: str = \"fourier\",\nfm_strategy: str = \"parallel\",\n) -&gt; list[AbstractBlock]:\n\"\"\"Helper function to build a qadence QNN quantum circuit\n    Args:\n        n_qubits (int): The number of qubits.\n        n_features (int): The number of input dimensions.\n        depth (int): The depth of the ansatz.\n        ansatz (Optional[AbstractBlock]):  An optional argument to pass a custom qadence ansatz.\n        fm_pauli (str): The type of Pauli gate for the feature map. Must be one of 'RX',\n            'RY', or 'RZ'.\n        spectrum (str): The desired spectrum of the feature map generator. The options simple,\n            tower and exponential produce a spectrum with linear, quadratic and exponential\n            eigenvalues with respect to the number of qubits.\n        basis (str): The encoding function. The options fourier and chebyshev correspond to \u03a6(x)=x\n            and arcos(x) respectively.\n        fm_strategy (str): The feature map encoding strategy. If \"parallel\", the features\n            are encoded in one block of rotation gates, with each feature given\n            an equal number of qubits. If \"serial\", the features are encoded\n            sequentially, with a HEA block between.\n    Returns:\n        A list of Abstract blocks to be used for constructing a quantum circuit\n    \"\"\"\ndepth = n_qubits if depth is None else depth\nidx_fms = build_idx_fms(basis, fm_pauli, fm_strategy, n_features, n_qubits, spectrum)\nif fm_strategy == \"parallel\":\n_fm = kron(*idx_fms)\nfm = tag(_fm, tag=\"FM\")\nelif fm_strategy == \"serial\":\nfm_components: list[AbstractBlock] = []\nfor j, fm_idx in enumerate(idx_fms[:-1]):\nfm_idx = tag(fm_idx, tag=f\"FM{j}\")  # type: ignore[assignment]\nfm_component = (fm_idx, hea(n_qubits, 1, f\"theta_{j}\"))\nfm_components.extend(fm_component)\nfm_components.append(tag(idx_fms[-1], tag=f\"FM{len(idx_fms) - 1}\"))\nfm = chain(*fm_components)  # type: ignore[assignment]\nansatz = hea(n_qubits, depth=depth) if ansatz is None else ansatz\nreturn [fm, ansatz]\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.ansatze.hea","title":"<code>hea(n_qubits, depth=1, param_prefix='theta', support=None, strategy=Strategy.DIGITAL, **strategy_args)</code>","text":"<p>Factory function for the Hardware Efficient Ansatz (HEA).</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>support</code> <p>qubit indexes where the HEA is applied</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>strategy</code> <p>Strategy.Digital or Strategy.DigitalAnalog</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>**strategy_args</code> <p>see below</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> PARAMETER DESCRIPTION <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer. Valid for Digital and DigitalAnalog HEA.</p> <p> TYPE: <code>list</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. periodic=False is not supported in emu-c. Valid for only for Digital HEA.</p> <p> TYPE: <code>bool</code> </p> <code>entangler</code> <ul> <li>Digital: 2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational parameters on the rotation angles.</li> <li>DigitaAnalog | Analog: Hamiltonian generator for the analog entangling layer. Defaults to global ZZ Hamiltonian. Time parameter is considered variational.</li> </ul> <p> TYPE: <code>AbstractBlock</code> </p> <p>Examples: <pre><code>from qadence import RZ, RX\nfrom qadence import hea\n# create the circuit\nn_qubits, depth = 2, 4\nansatz = hea(\nn_qubits=n_qubits,\ndepth=depth,\nstrategy=\"sDAQC\",\noperations=[RZ,RX,RZ]\n)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def hea(\nn_qubits: int,\ndepth: int = 1,\nparam_prefix: str = \"theta\",\nsupport: tuple[int, ...] = None,\nstrategy: Strategy = Strategy.DIGITAL,\n**strategy_args: Any,\n) -&gt; AbstractBlock:\n\"\"\"\n    Factory function for the Hardware Efficient Ansatz (HEA).\n    Args:\n        n_qubits: number of qubits in the block\n        depth: number of layers of the HEA\n        param_prefix: the base name of the variational parameters\n        support: qubit indexes where the HEA is applied\n        strategy: Strategy.Digital or Strategy.DigitalAnalog\n        **strategy_args: see below\n    Keyword Arguments:\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer. Valid for\n            Digital and DigitalAnalog HEA.\n        periodic (bool): if the qubits should be linked periodically.\n            periodic=False is not supported in emu-c. Valid for only\n            for Digital HEA.\n        entangler (AbstractBlock):\n            - Digital: 2-qubit entangling operation. Supports CNOT, CZ,\n            CRX, CRY, CRZ, CPHASE. Controlled rotations will have variational\n            parameters on the rotation angles.\n            - DigitaAnalog | Analog: Hamiltonian generator for the\n            analog entangling layer. Defaults to global ZZ Hamiltonian.\n            Time parameter is considered variational.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import RZ, RX\n    from qadence import hea\n    # create the circuit\n    n_qubits, depth = 2, 4\n    ansatz = hea(\n        n_qubits=n_qubits,\n        depth=depth,\n        strategy=\"sDAQC\",\n        operations=[RZ,RX,RZ]\n    )\n    ```\n    \"\"\"\nif support is None:\nsupport = tuple(range(n_qubits))\nhea_func_dict = {\nStrategy.DIGITAL: hea_digital,\nStrategy.SDAQC: hea_sDAQC,\nStrategy.BDAQC: hea_bDAQC,\nStrategy.ANALOG: hea_analog,\n}\ntry:\nhea_func = hea_func_dict[strategy]\nexcept KeyError:\nraise KeyError(f\"Strategy {strategy} not recognized.\")\nhea_block: AbstractBlock = hea_func(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=param_prefix,\nsupport=support,\n**strategy_args,\n)  # type: ignore\nreturn hea_block\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.ansatze.hea_digital","title":"<code>hea_digital(n_qubits, depth=1, param_prefix='theta', periodic=False, operations=[RX, RY, RX], support=None, entangler=CNOT)</code>","text":"<p>Construct the Digital Hardware Efficient Ansatz (HEA).</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>periodic</code> <p>if the qubits should be linked periodically. periodic=False is not supported in emu-c.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY, RX]</code> </p> <code>support</code> <p>qubit indexes where the HEA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>entangler</code> <p>2-qubit entangling operation. Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations will have variational parameters on the rotation angles.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>CNOT</code> </p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def hea_digital(\nn_qubits: int,\ndepth: int = 1,\nparam_prefix: str = \"theta\",\nperiodic: bool = False,\noperations: list[type[AbstractBlock]] = [RX, RY, RX],\nsupport: tuple[int, ...] = None,\nentangler: Type[DigitalEntanglers] = CNOT,\n) -&gt; AbstractBlock:\n\"\"\"\n    Construct the Digital Hardware Efficient Ansatz (HEA).\n    Args:\n        n_qubits (int): number of qubits in the block.\n        depth (int): number of layers of the HEA.\n        param_prefix (str): the base name of the variational parameters\n        periodic (bool): if the qubits should be linked periodically.\n            periodic=False is not supported in emu-c.\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        support (tuple): qubit indexes where the HEA is applied.\n        entangler (AbstractBlock): 2-qubit entangling operation.\n            Supports CNOT, CZ, CRX, CRY, CRZ. Controlld rotations\n            will have variational parameters on the rotation angles.\n    \"\"\"\ntry:\nif entangler not in [CNOT, CZ, CRX, CRY, CRZ, CPHASE]:\nraise ValueError(\n\"Please provide a valid two-qubit entangler operation for digital HEA.\"\n)\nexcept TypeError:\nraise ValueError(\"Please provide a valid two-qubit entangler operation for digital HEA.\")\nrot_list = _rotations_digital(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=param_prefix,\nsupport=support,\noperations=operations,\n)\nent_list = _entanglers_digital(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=param_prefix,\nsupport=support,\nperiodic=periodic,\nentangler=entangler,\n)\nlayers = []\nfor d in range(depth):\nlayers.append(rot_list[d])\nlayers.append(ent_list[d])\nreturn tag(chain(*layers), \"HEA\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.ansatze.hea_sDAQC","title":"<code>hea_sDAQC(n_qubits, depth=1, param_prefix='theta', operations=[RX, RY, RX], support=None, entangler=None)</code>","text":"<p>Construct the Hardware Efficient Ansatz (HEA) with analog entangling layers using step-wise digital-analog computation.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the block.</p> <p> TYPE: <code>int</code> </p> <code>depth</code> <p>number of layers of the HEA.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>param_prefix</code> <p>the base name of the variational parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>'theta'</code> </p> <code>operations</code> <p>list of operations to cycle through in the digital single-qubit rotations of each layer.</p> <p> TYPE: <code>list</code> DEFAULT: <code>[RX, RY, RX]</code> </p> <code>support</code> <p>qubit indexes where the HEA is applied.</p> <p> TYPE: <code>tuple</code> DEFAULT: <code>None</code> </p> <code>entangler</code> <p>Hamiltonian generator for the analog entangling layer. Defaults to global ZZ Hamiltonian. Time parameter is considered variational.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>None</code> </p> Source code in <code>qadence/constructors/ansatze.py</code> <pre><code>def hea_sDAQC(\nn_qubits: int,\ndepth: int = 1,\nparam_prefix: str = \"theta\",\noperations: list[type[AbstractBlock]] = [RX, RY, RX],\nsupport: tuple[int, ...] = None,\nentangler: AbstractBlock | None = None,\n) -&gt; AbstractBlock:\n\"\"\"\n    Construct the Hardware Efficient Ansatz (HEA) with analog entangling layers\n    using step-wise digital-analog computation.\n    Args:\n        n_qubits (int): number of qubits in the block.\n        depth (int): number of layers of the HEA.\n        param_prefix (str): the base name of the variational parameters\n        operations (list): list of operations to cycle through in the\n            digital single-qubit rotations of each layer.\n        support (tuple): qubit indexes where the HEA is applied.\n        entangler (AbstractBlock): Hamiltonian generator for the\n            analog entangling layer. Defaults to global ZZ Hamiltonian.\n            Time parameter is considered variational.\n    \"\"\"\n# TODO: Add qubit support\nif entangler is None:\nentangler = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\ntry:\nif not block_is_qubit_hamiltonian(entangler):\nraise ValueError(\n\"Please provide a valid Pauli Hamiltonian generator for digital-analog HEA.\"\n)\nexcept NotImplementedError:\nraise ValueError(\n\"Please provide a valid Pauli Hamiltonian generator for digital-analog HEA.\"\n)\nrot_list = _rotations_digital(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=param_prefix,\nsupport=support,\noperations=operations,\n)\nent_list = _entanglers_analog(\ndepth=depth,\nparam_prefix=param_prefix,\nentangler=entangler,\n)\nlayers = []\nfor d in range(depth):\nlayers.append(rot_list[d])\nlayers.append(ent_list[d])\nreturn tag(chain(*layers), \"HEA-sDA\")\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.hamiltonian_factory","title":"<code>hamiltonian_factory(register, interaction=None, detuning=None, interaction_strength=None, detuning_strength=None, random_strength=False, force_update=False)</code>","text":"<p>General Hamiltonian creation function. Can be used to create Hamiltonians with 2-qubit interactions and single-qubit detunings, both with arbitrary strength or parameterized.</p> PARAMETER  DESCRIPTION <code>register</code> <p>register of qubits with a specific graph topology, or number of qubits. When passing a number of qubits a register with all-to-all connectivity is created.</p> <p> TYPE: <code>Register | int</code> </p> <code>interaction</code> <p>Interaction.ZZ, Interaction.NN, Interaction.XY, or Interacton.XYZ.</p> <p> TYPE: <code>Interaction | None</code> DEFAULT: <code>None</code> </p> <code>detuning</code> <p>single-qubit operator N, X, Y, or Z.</p> <p> TYPE: <code>TDetuning | None</code> DEFAULT: <code>None</code> </p> <code>interaction_strength</code> <p>list of values to be used as the interaction strength for each pair of qubits. Should be ordered following the order of <code>Register(n_qubits).edges</code>. Alternatively, some string \"x\" can be passed, which will create a parameterized interactions for each pair of qubits, each labelled as <code>\"x_ij\"</code>.</p> <p> TYPE: <code>TArray | str | None</code> DEFAULT: <code>None</code> </p> <code>detuning_strength</code> <p>list of values to be used as the detuning strength for each qubit. Alternatively, some string \"x\" can be passed, which will create a parameterized detuning for each qubit, each labelled as <code>\"x_i\"</code>.</p> <p> TYPE: <code>TArray | str | None</code> DEFAULT: <code>None</code> </p> <code>random_strength</code> <p>set random interaction and detuning strengths between -1 and 1.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>force_update</code> <p>force override register detuning and interaction strengths.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Examples:</p> <pre><code>from qadence import hamiltonian_factory, Interaction, Register, Z\nn_qubits = 3\n# Constant total magnetization observable:\nobservable = hamiltonian_factory(n_qubits, detuning = Z)\n# Parameterized total magnetization observable:\nobservable = hamiltonian_factory(n_qubits, detuning = Z, detuning_strength = \"z\")\n# Random all-to-all XY Hamiltonian generator:\ngenerator = hamiltonian_factory(\nn_qubits,\ninteraction = Interaction.XY,\nrandom_strength = True,\n)\n# Parameterized NN Hamiltonian generator with a square grid interaction topology:\nregister = Register.square(qubits_side = n_qubits)\ngenerator = hamiltonian_factory(\nregister,\ninteraction = Interaction.NN,\ninteraction_strength = \"theta\"\n)\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def hamiltonian_factory(\nregister: Register | int,\ninteraction: Interaction | None = None,\ndetuning: TDetuning | None = None,\ninteraction_strength: TArray | str | None = None,\ndetuning_strength: TArray | str | None = None,\nrandom_strength: bool = False,\nforce_update: bool = False,\n) -&gt; AbstractBlock:\n\"\"\"\n    General Hamiltonian creation function. Can be used to create Hamiltonians with 2-qubit\n    interactions and single-qubit detunings, both with arbitrary strength or parameterized.\n    Arguments:\n        register: register of qubits with a specific graph topology, or number of qubits.\n            When passing a number of qubits a register with all-to-all connectivity\n            is created.\n        interaction: Interaction.ZZ, Interaction.NN, Interaction.XY, or Interacton.XYZ.\n        detuning: single-qubit operator N, X, Y, or Z.\n        interaction_strength: list of values to be used as the interaction strength for each\n            pair of qubits. Should be ordered following the order of `Register(n_qubits).edges`.\n            Alternatively, some string \"x\" can be passed, which will create a parameterized\n            interactions for each pair of qubits, each labelled as `\"x_ij\"`.\n        detuning_strength: list of values to be used as the detuning strength for each qubit.\n            Alternatively, some string \"x\" can be passed, which will create a parameterized\n            detuning for each qubit, each labelled as `\"x_i\"`.\n        random_strength: set random interaction and detuning strengths between -1 and 1.\n        force_update: force override register detuning and interaction strengths.\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import hamiltonian_factory, Interaction, Register, Z\n        n_qubits = 3\n        # Constant total magnetization observable:\n        observable = hamiltonian_factory(n_qubits, detuning = Z)\n        # Parameterized total magnetization observable:\n        observable = hamiltonian_factory(n_qubits, detuning = Z, detuning_strength = \"z\")\n        # Random all-to-all XY Hamiltonian generator:\n        generator = hamiltonian_factory(\n            n_qubits,\n            interaction = Interaction.XY,\n            random_strength = True,\n            )\n        # Parameterized NN Hamiltonian generator with a square grid interaction topology:\n        register = Register.square(qubits_side = n_qubits)\n        generator = hamiltonian_factory(\n            register,\n            interaction = Interaction.NN,\n            interaction_strength = \"theta\"\n            )\n        ```\n    \"\"\"\nif interaction is None and detuning is None:\nraise ValueError(\"Please provide an interaction and/or detuning for the Hamiltonian.\")\n# If number of qubits is given, creates all-to-all register\nregister = Register(register) if isinstance(register, int) else register\n# Get interaction function\ntry:\nint_fn = INTERACTION_DICT[interaction]  # type: ignore [index]\nexcept (KeyError, ValueError) as error:\nif interaction is None:\npass\nelse:\nraise KeyError(f\"Interaction {interaction} not supported.\")\n# Check single-qubit detuning\nif (detuning is not None) and (detuning not in DETUNINGS):\nraise TypeError(f\"Detuning of type {type(detuning)} not supported.\")\n# Pre-process detuning and interaction strengths and update register\nhas_detuning_strength, detuning_strength = _preprocess_strengths(\nregister, detuning_strength, \"nodes\", force_update, random_strength\n)\nhas_interaction_strength, interaction_strength = _preprocess_strengths(\nregister, interaction_strength, \"edges\", force_update, random_strength\n)\nif (not has_detuning_strength) or force_update:\nregister = _update_detuning_strength(register, detuning_strength)\nif (not has_interaction_strength) or force_update:\nregister = _update_interaction_strength(register, interaction_strength)\n# Create single-qubit detunings:\nsingle_qubit_terms: List[AbstractBlock] = []\nif detuning is not None:\nfor node in register.nodes:\nblock_sq = detuning(node)  # type: ignore [operator]\nstrength_sq = register.nodes[node][\"strength\"]\nsingle_qubit_terms.append(strength_sq * block_sq)\n# Create two-qubit interactions:\ntwo_qubit_terms: List[AbstractBlock] = []\nif interaction is not None:\nfor edge in register.edges:\nblock_tq = int_fn(*edge)  # type: ignore [operator]\nstrength_tq = register.edges[edge][\"strength\"]\ntwo_qubit_terms.append(strength_tq * block_tq)\nreturn add(*single_qubit_terms, *two_qubit_terms)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.interaction_nn","title":"<code>interaction_nn(i, j)</code>","text":"<p>Ising NN interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_nn(i: int, j: int) -&gt; AbstractBlock:\n\"\"\"Ising NN interaction.\"\"\"\nreturn N(i) @ N(j)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.interaction_xy","title":"<code>interaction_xy(i, j)</code>","text":"<p>XY interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_xy(i: int, j: int) -&gt; AbstractBlock:\n\"\"\"XY interaction.\"\"\"\nreturn X(i) @ X(j) + Y(i) @ Y(j)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.interaction_xyz","title":"<code>interaction_xyz(i, j)</code>","text":"<p>Heisenberg XYZ interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_xyz(i: int, j: int) -&gt; AbstractBlock:\n\"\"\"Heisenberg XYZ interaction.\"\"\"\nreturn X(i) @ X(j) + Y(i) @ Y(j) + Z(i) @ Z(j)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.hamiltonians.interaction_zz","title":"<code>interaction_zz(i, j)</code>","text":"<p>Ising ZZ interaction.</p> Source code in <code>qadence/constructors/hamiltonians.py</code> <pre><code>def interaction_zz(i: int, j: int) -&gt; AbstractBlock:\n\"\"\"Ising ZZ interaction.\"\"\"\nreturn Z(i) @ Z(j)\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.qft.qft","title":"<code>qft(n_qubits, support=None, inverse=False, reverse_in=False, swaps_out=False, strategy=Strategy.DIGITAL, gen_build=None)</code>","text":"<p>The Quantum Fourier Transform</p> <p>Depending on the application, user should be careful with qubit ordering in the input and output. This can be controlled with reverse_in and swaps_out arguments.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of qubits in the QFT</p> <p> TYPE: <code>int</code> </p> <code>support</code> <p>qubit support to use</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <code>inverse</code> <p>True performs the inverse QFT</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>reverse_in</code> <p>Reverses the input qubits to account for endianness</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>swaps_out</code> <p>Performs swaps on the output qubits to match the \"textbook\" QFT.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>strategy</code> <p>Strategy.Digital or Strategy.sDAQC</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>DIGITAL</code> </p> <code>gen_build</code> <p>building block Ising Hamiltonian for the DAQC transform. Defaults to constant all-to-all Ising.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>from qadence import qft\nn_qubits = 3\nqft_circuit = qft(n_qubits, strategy = \"sDAQC\")\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/qft.py</code> <pre><code>def qft(\nn_qubits: int,\nsupport: tuple[int, ...] = None,\ninverse: bool = False,\nreverse_in: bool = False,\nswaps_out: bool = False,\nstrategy: Strategy = Strategy.DIGITAL,\ngen_build: AbstractBlock | None = None,\n) -&gt; AbstractBlock:\n\"\"\"\n    The Quantum Fourier Transform\n    Depending on the application, user should be careful with qubit ordering\n    in the input and output. This can be controlled with reverse_in and swaps_out\n    arguments.\n    Args:\n        n_qubits: number of qubits in the QFT\n        support: qubit support to use\n        inverse: True performs the inverse QFT\n        reverse_in: Reverses the input qubits to account for endianness\n        swaps_out: Performs swaps on the output qubits to match the \"textbook\" QFT.\n        strategy: Strategy.Digital or Strategy.sDAQC\n        gen_build: building block Ising Hamiltonian for the DAQC transform.\n            Defaults to constant all-to-all Ising.\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import qft\n        n_qubits = 3\n        qft_circuit = qft(n_qubits, strategy = \"sDAQC\")\n        ```\n    \"\"\"\nif support is None:\nsupport = tuple(range(n_qubits))\nassert len(support) &lt;= n_qubits, \"Wrong qubit support supplied\"\nif reverse_in:\nsupport = support[::-1]\nqft_layer_dict = {\nStrategy.DIGITAL: _qft_layer_digital,\nStrategy.SDAQC: _qft_layer_sDAQC,\nStrategy.BDAQC: _qft_layer_bDAQC,\nStrategy.ANALOG: _qft_layer_analog,\n}\ntry:\nlayer_func = qft_layer_dict[strategy]\nexcept KeyError:\nraise KeyError(f\"Strategy {strategy} not recognized.\")\nqft_layers = reversed(range(n_qubits)) if inverse else range(n_qubits)\nqft_circ = chain(\nlayer_func(\nn_qubits=n_qubits, support=support, layer=layer, inverse=inverse, gen_build=gen_build\n)  # type: ignore\nfor layer in qft_layers\n)\nif swaps_out:\nswap_ops = [SWAP(support[i], support[n_qubits - i - 1]) for i in range(n_qubits // 2)]\nqft_circ = chain(*swap_ops, qft_circ) if inverse else chain(qft_circ, *swap_ops)\nreturn tag(qft_circ, tag=\"iQFT\") if inverse else tag(qft_circ, tag=\"QFT\")\n</code></pre>"},{"location":"qadence/constructors/#the-daqc-transform","title":"The DAQC Transform","text":""},{"location":"qadence/constructors/#qadence.constructors.daqc.daqc.daqc_transform","title":"<code>daqc_transform(n_qubits, gen_target, t_f, gen_build=None, zero_tol=1e-08, strategy=Strategy.SDAQC, ignore_global_phases=False)</code>","text":"<p>Implements the DAQC transform for representing an arbitrary 2-body Hamiltonian with another fixed 2-body Hamiltonian.</p> <p>Reference for universality of 2-body Hamiltonians:</p> <p>-- https://arxiv.org/abs/quant-ph/0106064</p> <p>Based on the transformation for Ising (ZZ) interactions, as described in the paper</p> <p>-- https://arxiv.org/abs/1812.03637</p> <p>The transform translates a target weighted generator of the type:</p> <pre><code>`gen_target = add(g_jk * kron(op(j), op(k)) for j &lt; k)`\n</code></pre> <p>To a circuit using analog evolutions with a fixed building block generator:</p> <pre><code>`gen_build = add(f_jk * kron(op(j), op(k)) for j &lt; k)`\n</code></pre> <p>where <code>op = Z</code> or <code>op = N</code>.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>total number of qubits to use.</p> <p> TYPE: <code>int</code> </p> <code>gen_target</code> <p>target generator built with the structure above. The type of the generator will be automatically evaluated when parsing.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>t_f</code> <p>total time for the gen_target evolution.</p> <p> TYPE: <code>float</code> </p> <code>gen_build</code> <p>fixed generator to act as a building block. Defaults to constant NN: add(1.0 * kron(N(j), N(k)) for j &lt; k). The type of the generator will be automatically evaluated when parsing.</p> <p> TYPE: <code>AbstractBlock | None</code> DEFAULT: <code>None</code> </p> <code>zero_tol</code> <p>default \"zero\" for a missing interaction. Included for numerical reasons, see notes below.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-08</code> </p> <code>strategy</code> <p>sDAQC or bDAQC, following definitions in the reference paper.</p> <p> TYPE: <code>Strategy</code> DEFAULT: <code>SDAQC</code> </p> <code>ignore_global_phases</code> <p>if <code>True</code> the transform does not correct the global phases coming from the mapping between ZZ and NN interactions.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Notes:</p> <pre><code>The paper follows an index convention of running from 1 to N. A few functions\nhere also use that convention to be consistent with the paper. However, for qadence\nrelated things the indices are converted to [0, N-1].\n\nThe case for `n_qubits = 4` is an edge case where the sign matrix is not invertible.\nThere is a workaround for this described in the paper, but it is currently not implemented.\n\nThe current implementation may result in evolution times that are both positive or\nnegative. In practice, both can be represented by simply changing the signs of the\ninteractions. However, for a real implementation where the interactions should remain\nfixed, the paper discusses a workaround that is not currently implemented.\n\nThe transformation works by representing each interaction in the target hamiltonian by\na set of evolutions using the build hamiltonian. As a consequence, some care must be\ntaken when choosing the build hamiltonian. Some cases:\n\n- The target hamiltonian can have any interaction, as long as it is sufficiently\nrepresented in the build hamiltonian. E.g., if the interaction `g_01 * kron(Z(0), Z(1))`\nis in the target hamiltonian, the corresponding interaction `f_01 * kron(Z(0), Z(1))`\nneeds to be in the build hamiltonian. This is checked when the generators are parsed.\n\n- The build hamiltonian can have any interaction, irrespectively of it being needed\nfor the target hamiltonian. This is especially useful for designing local operations\nthrough the repeated evolution of a \"global\" hamiltonian.\n\n- The parameter `zero_tol` controls what it means for an interaction to be \"missing\".\nAny interaction strength smaller than `zero_tol` in the build hamiltonian will not be\nconsidered, and thus that interaction is missing.\n\n- The various ratios `g_jk / f_jk` will influence the time parameter for the various\nevolution slices, meaning that if there is a big discrepancy in the interaction strength\nfor a given qubit pair (j, k), the output circuit may require the usage of hamiltonian\nevolutions with very large times.\n\n- A warning will be issued for evolution times larger than `1/sqrt(zero_tol)`. Evolution\ntimes smaller than `zero_tol` will not be represented.\n</code></pre> <p>Examples:</p> <pre><code>from qadence import Z, N, daqc_transform\nn_qubits = 3\ngen_build = 0.5 * (N(0)@N(1)) + 0.7 * (N(1)@N(2)) + 0.2 * (N(0)@N(2))\ngen_target = 0.1 * (Z(1)@Z(2))\nt_f = 2.0\ntransformed_circuit = daqc_transform(\nn_qubits = n_qubits,\ngen_target = gen_target,\nt_f = t_f,\ngen_build = gen_build,\n)\n</code></pre> <pre><code>\n</code></pre> Source code in <code>qadence/constructors/daqc/daqc.py</code> <pre><code>def daqc_transform(\nn_qubits: int,\ngen_target: AbstractBlock,\nt_f: float,\ngen_build: AbstractBlock | None = None,\nzero_tol: float = 1e-08,\nstrategy: Strategy = Strategy.SDAQC,\nignore_global_phases: bool = False,\n) -&gt; AbstractBlock:\n\"\"\"\n    Implements the DAQC transform for representing an arbitrary 2-body Hamiltonian\n    with another fixed 2-body Hamiltonian.\n    Reference for universality of 2-body Hamiltonians:\n    -- https://arxiv.org/abs/quant-ph/0106064\n    Based on the transformation for Ising (ZZ) interactions, as described in the paper\n    -- https://arxiv.org/abs/1812.03637\n    The transform translates a target weighted generator of the type:\n        `gen_target = add(g_jk * kron(op(j), op(k)) for j &lt; k)`\n    To a circuit using analog evolutions with a fixed building block generator:\n        `gen_build = add(f_jk * kron(op(j), op(k)) for j &lt; k)`\n    where `op = Z` or `op = N`.\n    Args:\n        n_qubits: total number of qubits to use.\n        gen_target: target generator built with the structure above. The type\n            of the generator will be automatically evaluated when parsing.\n        t_f (float): total time for the gen_target evolution.\n        gen_build: fixed generator to act as a building block. Defaults to\n            constant NN: add(1.0 * kron(N(j), N(k)) for j &lt; k). The type\n            of the generator will be automatically evaluated when parsing.\n        zero_tol: default \"zero\" for a missing interaction. Included for\n            numerical reasons, see notes below.\n        strategy: sDAQC or bDAQC, following definitions in the reference paper.\n        ignore_global_phases: if `True` the transform does not correct the global\n            phases coming from the mapping between ZZ and NN interactions.\n    Notes:\n        The paper follows an index convention of running from 1 to N. A few functions\n        here also use that convention to be consistent with the paper. However, for qadence\n        related things the indices are converted to [0, N-1].\n        The case for `n_qubits = 4` is an edge case where the sign matrix is not invertible.\n        There is a workaround for this described in the paper, but it is currently not implemented.\n        The current implementation may result in evolution times that are both positive or\n        negative. In practice, both can be represented by simply changing the signs of the\n        interactions. However, for a real implementation where the interactions should remain\n        fixed, the paper discusses a workaround that is not currently implemented.\n        The transformation works by representing each interaction in the target hamiltonian by\n        a set of evolutions using the build hamiltonian. As a consequence, some care must be\n        taken when choosing the build hamiltonian. Some cases:\n        - The target hamiltonian can have any interaction, as long as it is sufficiently\n        represented in the build hamiltonian. E.g., if the interaction `g_01 * kron(Z(0), Z(1))`\n        is in the target hamiltonian, the corresponding interaction `f_01 * kron(Z(0), Z(1))`\n        needs to be in the build hamiltonian. This is checked when the generators are parsed.\n        - The build hamiltonian can have any interaction, irrespectively of it being needed\n        for the target hamiltonian. This is especially useful for designing local operations\n        through the repeated evolution of a \"global\" hamiltonian.\n        - The parameter `zero_tol` controls what it means for an interaction to be \"missing\".\n        Any interaction strength smaller than `zero_tol` in the build hamiltonian will not be\n        considered, and thus that interaction is missing.\n        - The various ratios `g_jk / f_jk` will influence the time parameter for the various\n        evolution slices, meaning that if there is a big discrepancy in the interaction strength\n        for a given qubit pair (j, k), the output circuit may require the usage of hamiltonian\n        evolutions with very large times.\n        - A warning will be issued for evolution times larger than `1/sqrt(zero_tol)`. Evolution\n        times smaller than `zero_tol` will not be represented.\n    Examples:\n        ```python exec=\"on\" source=\"material-block\" result=\"json\"\n        from qadence import Z, N, daqc_transform\n        n_qubits = 3\n        gen_build = 0.5 * (N(0)@N(1)) + 0.7 * (N(1)@N(2)) + 0.2 * (N(0)@N(2))\n        gen_target = 0.1 * (Z(1)@Z(2))\n        t_f = 2.0\n        transformed_circuit = daqc_transform(\n            n_qubits = n_qubits,\n            gen_target = gen_target,\n            t_f = t_f,\n            gen_build = gen_build,\n        )\n        ```\n    \"\"\"\n##################\n# Input controls #\n##################\nif strategy != Strategy.SDAQC:\nraise NotImplementedError(\"Currently only the sDAQC transform is implemented.\")\nif n_qubits == 4:\nraise NotImplementedError(\"DAQC transform 4-qubit edge case not implemented.\")\nif gen_build is None:\ngen_build = hamiltonian_factory(n_qubits, interaction=Interaction.NN)\ntry:\nif (not block_is_qubit_hamiltonian(gen_target)) or (\nnot block_is_qubit_hamiltonian(gen_build)\n):\nraise ValueError(\n\"Generator block is not a qubit Hamiltonian. Only ZZ or NN interactions allowed.\"\n)\nexcept NotImplementedError:\n# Happens when block_is_qubit_hamiltonian is called on something that is not a block.\nraise TypeError(\n\"Generator block is not a qubit Hamiltonian. Only ZZ or NN interactions allowed.\"\n)\n#####################\n# Generator parsing #\n#####################\ng_jk_target, mat_jk_target, target_type = _parse_generator(n_qubits, gen_target, 0.0)\ng_jk_build, mat_jk_build, build_type = _parse_generator(n_qubits, gen_build, zero_tol)\n# Get the global phase hamiltonian and single-qubit detuning hamiltonian\nif build_type == GenDAQC.NN:\nh_phase_build, h_sq_build = _nn_phase_and_detunings(n_qubits, mat_jk_build)\nif target_type == GenDAQC.NN:\nh_phase_target, h_sq_target = _nn_phase_and_detunings(n_qubits, mat_jk_target)\n# Time re-scalings\nif build_type == GenDAQC.ZZ and target_type == GenDAQC.NN:\nt_star = t_f / 4.0\nelif build_type == GenDAQC.NN and target_type == GenDAQC.ZZ:\nt_star = 4.0 * t_f\nelse:\nt_star = t_f\n# Check if target Hamiltonian can be mapped with the build Hamiltonian\nassert _check_compatibility(g_jk_target, g_jk_build, zero_tol)\n##################\n# DAQC Transform #\n##################\n# Section III A of https://arxiv.org/abs/1812.03637:\n# Matrix M for the linear system, exemplified in Table I:\nmatrix_M = _build_matrix_M(n_qubits)\n# Linear system mapping interaction ratios -&gt; evolution times.\nt_slices = torch.linalg.solve(matrix_M, g_jk_target / g_jk_build) * t_star\n# ZZ-DAQC with ZZ or NN build Hamiltonian\ndaqc_slices = []\nfor m in range(2, n_qubits + 1):\nfor n in range(1, m):\nalpha = _ix_map(n_qubits, n, m)\nt = t_slices[alpha - 1]\nif abs(t) &gt; zero_tol:\nif abs(t) &gt; (1 / (zero_tol**0.5)):\nlogger.warning(\n\"\"\"\nTransformed circuit with very long evolution time.\nMake sure your target interactions are sufficiently\nrepresented in the build Hamiltonian.\"\"\"\n)\nx_gates = kron(X(n - 1), X(m - 1))\nanalog_evo = HamEvo(gen_build, t)\n# TODO: Fix repeated X-gates\nif build_type == GenDAQC.NN:\n# Local detuning at each DAQC layer for NN build Hamiltonian\nsq_detuning_build = HamEvo(h_sq_build, t)\ndaqc_slices.append(chain(x_gates, sq_detuning_build, analog_evo, x_gates))\nelif build_type == GenDAQC.ZZ:\ndaqc_slices.append(chain(x_gates, analog_evo, x_gates))\ndaqc_circuit = chain(*daqc_slices)\n########################\n# Phases and Detunings #\n########################\nif target_type == GenDAQC.NN:\n# Local detuning given a NN target Hamiltonian\nsq_detuning_target = HamEvo(h_sq_target, t_f).dagger()\ndaqc_circuit = chain(sq_detuning_target, daqc_circuit)\nif not ignore_global_phases:\nif build_type == GenDAQC.NN:\n# Constant global phase given a NN build Hamiltonian\nglobal_phase_build = HamEvo(h_phase_build, t_slices.sum())\ndaqc_circuit = chain(global_phase_build, daqc_circuit)\nif target_type == GenDAQC.NN:\n# Constant global phase and given a NN target Hamiltonian\nglobal_phase_target = HamEvo(h_phase_target, t_f).dagger()\ndaqc_circuit = chain(global_phase_target, daqc_circuit)\nreturn daqc_circuit\n</code></pre>"},{"location":"qadence/constructors/#some-utility-functions","title":"Some utility functions","text":""},{"location":"qadence/constructors/#qadence.constructors.utils.build_idx_fms","title":"<code>build_idx_fms(basis, fm_pauli, fm_strategy, n_features, n_qubits, spectrum)</code>","text":"<p>Builds the index feature maps based on the given parameters.</p> PARAMETER  DESCRIPTION <code>basis</code> <p>Type of basis chosen for the feature map.</p> <p> TYPE: <code>str</code> </p> <code>fm_pauli</code> <p>The chosen Pauli rotation type.</p> <p> TYPE: <code>PrimitiveBlock type</code> </p> <code>fm_strategy</code> <p>The feature map strategy to be used. Possible values are 'parallel' or 'serial'.</p> <p> TYPE: <code>str</code> </p> <code>n_features</code> <p>The number of features.</p> <p> TYPE: <code>int</code> </p> <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>spectrum</code> <p>The chosen spectrum.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>list[KronBlock]</code> <p>List[KronBlock]: The list of index feature maps.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def build_idx_fms(\nbasis: str,\nfm_pauli: Type[RY],\nfm_strategy: str,\nn_features: int,\nn_qubits: int,\nspectrum: str,\n) -&gt; list[KronBlock]:\n\"\"\"Builds the index feature maps based on the given parameters.\n    Args:\n        basis (str): Type of basis chosen for the feature map.\n        fm_pauli (PrimitiveBlock type): The chosen Pauli rotation type.\n        fm_strategy (str): The feature map strategy to be used. Possible values are\n            'parallel' or 'serial'.\n        n_features (int): The number of features.\n        n_qubits (int): The number of qubits.\n        spectrum (str): The chosen spectrum.\n    Returns:\n        List[KronBlock]: The list of index feature maps.\n    \"\"\"\nidx_fms = []\nfor i in range(n_features):\ntarget_qubits = get_fm_qubits(fm_strategy, i, n_qubits, n_features)\nparam = FeatureParameter(f\"x{i}\")\nblock = kron(\n*[\nfm_pauli(qubit, generator_prefactor(spectrum, j) * basis_func(basis, param))\nfor j, qubit in enumerate(target_qubits)\n]\n)\nidx_fm = block\nidx_fms.append(idx_fm)\nreturn idx_fms\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.utils.generator_prefactor","title":"<code>generator_prefactor(spectrum, qubit_index)</code>","text":"<p>Converts a spectrum string (e.g., tower or exponential) to the correct generator prefactor.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def generator_prefactor(spectrum: str, qubit_index: int) -&gt; float | int:\n\"\"\"\n    Converts a spectrum string (e.g., tower or exponential) to the correct generator prefactor.\n    \"\"\"\nspectrum = spectrum.lower()\nconversion_dict: dict[str, float | int] = {\n\"simple\": 1,\n\"tower\": qubit_index + 1,\n\"exponential\": 2 * np.pi / (2 ** (qubit_index + 1)),\n}\nreturn conversion_dict[spectrum]\n</code></pre>"},{"location":"qadence/constructors/#qadence.constructors.utils.get_fm_qubits","title":"<code>get_fm_qubits(fm_strategy, i, n_qubits, n_features)</code>","text":"<p>Returns the list of target qubits for the given feature map strategy and feature index</p> PARAMETER  DESCRIPTION <code>fm_strategy</code> <p>The feature map strategy to be used. Possible values are 'parallel' or 'serial'.</p> <p> TYPE: <code>str</code> </p> <code>i</code> <p>The feature index.</p> <p> TYPE: <code>int</code> </p> <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>n_features</code> <p>The number of features.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Iterable</code> <p>List[int]: The list of target qubits.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the feature map strategy is not implemented.</p> Source code in <code>qadence/constructors/utils.py</code> <pre><code>def get_fm_qubits(fm_strategy: str, i: int, n_qubits: int, n_features: int) -&gt; Iterable:\n\"\"\"Returns the list of target qubits for the given feature map strategy and feature index\n    Args:\n        fm_strategy (str): The feature map strategy to be used. Possible values\n            are 'parallel' or 'serial'.\n        i (int): The feature index.\n        n_qubits (int): The number of qubits.\n        n_features (int): The number of features.\n    Returns:\n        List[int]: The list of target qubits.\n    Raises:\n        ValueError: If the feature map strategy is not implemented.\n    \"\"\"\nif fm_strategy == \"parallel\":\nn_qubits_per_feature = int(n_qubits / n_features)\ntarget_qubits = range(i * n_qubits_per_feature, (i + 1) * n_qubits_per_feature)\nelif fm_strategy == \"serial\":\ntarget_qubits = range(0, n_qubits)\nelse:\nraise ValueError(f\"Feature map strategy {fm_strategy} not implemented.\")\nreturn target_qubits\n</code></pre>"},{"location":"qadence/execution/","title":"Execution","text":""},{"location":"qadence/execution/#qadence.execution.expectation","title":"<code>expectation(x, observable, values={}, state=None, backend=BackendName.PYQTORCH, diff_mode=None, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.expectation</code> method.  This is a <code>functools.singledispatch</code>ed function so it can be called with a number of different arguments (see in the examples).</p> PARAMETER  DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>observable</code> <p>Observable(s) w.r.t. which the expectation is computed.</p> <p> TYPE: <code>Union[list[AbstractBlock], AbstractBlock]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>diff_mode</code> <p>Which differentiation mode to use.</p> <p> TYPE: <code>Union[DiffMode, str, None]</code> DEFAULT: <code>None</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A wavefunction</p> <pre><code>from qadence import RX, Z, Register, QuantumCircuit, expectation\nreg = Register(1)\nblock = RX(0, 0.5)\nobservable = Z(0)\ncirc = QuantumCircuit(reg, block)\n# You can compute the expectation for a\n# QuantumCircuit with a given observable.\nexpectation(circ, observable)\n# You can also use only a block.\n# In this case the register is constructed automatically to\n# Register.line(block.n_qubits)\nexpectation(block, observable)\n# Or a register and block\nexpectation(reg, block, observable)\n</code></pre> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef expectation(\nx: Union[QuantumCircuit, AbstractBlock, Register, int],\nobservable: Union[list[AbstractBlock], AbstractBlock],\nvalues: dict = {},\nstate: Tensor = None,\nbackend: BackendName = BackendName.PYQTORCH,\ndiff_mode: Union[DiffMode, str, None] = None,\nendianness: Endianness = Endianness.BIG,\nconfiguration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; Tensor:\n\"\"\"Convenience wrapper for the `QuantumModel.expectation` method.  This is a\n    `functools.singledispatch`ed function so it can be called with a number of different arguments\n    (see in the examples).\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        observable: Observable(s) w.r.t. which the expectation is computed.\n        values: User-facing parameter dict.\n        state: Initial state.\n        backend: Name of the backend to run on.\n        diff_mode: Which differentiation mode to use.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n    Returns:\n        A wavefunction\n    ```python exec=\"on\" source=\"material-block\"\n    from qadence import RX, Z, Register, QuantumCircuit, expectation\n    reg = Register(1)\n    block = RX(0, 0.5)\n    observable = Z(0)\n    circ = QuantumCircuit(reg, block)\n    # You can compute the expectation for a\n    # QuantumCircuit with a given observable.\n    expectation(circ, observable)\n    # You can also use only a block.\n    # In this case the register is constructed automatically to\n    # Register.line(block.n_qubits)\n    expectation(block, observable)\n    # Or a register and block\n    expectation(reg, block, observable)\n    ```\"\"\"\nraise ValueError(f\"Cannot execute {type(x)}\")\n</code></pre>"},{"location":"qadence/execution/#qadence.execution.run","title":"<code>run(x, *args, values={}, state=None, backend=BackendName.PYQTORCH, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.run</code> method.  This is a <code>functools.singledispatch</code>ed function so it can be called with a number of different arguments. See the examples of the <code>expectation</code> function. This function works exactly the same.</p> PARAMETER  DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Tensor</code> DEFAULT: <code>None</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A wavefunction</p> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef run(\nx: Union[QuantumCircuit, AbstractBlock, Register, int],\n*args: Any,\nvalues: dict = {},\nstate: Tensor = None,\nbackend: BackendName = BackendName.PYQTORCH,\nendianness: Endianness = Endianness.BIG,\nconfiguration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; Tensor:\n\"\"\"Convenience wrapper for the `QuantumModel.run` method.  This is a\n    `functools.singledispatch`ed function so it can be called with a number of different arguments.\n    See the examples of the [`expectation`][qadence.execution.expectation] function. This function\n    works exactly the same.\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        values: User-facing parameter dict.\n        state: Initial state.\n        backend: Name of the backend to run on.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n    Returns:\n        A wavefunction\n    \"\"\"\nraise ValueError(f\"Cannot run {type(x)}\")\n</code></pre>"},{"location":"qadence/execution/#qadence.execution.sample","title":"<code>sample(x, *args, values={}, state=None, n_shots=100, backend=BackendName.PYQTORCH, endianness=Endianness.BIG, configuration=None)</code>","text":"<p>Convenience wrapper for the <code>QuantumModel.sample</code> method.  This is a <code>functools.singledispatch</code>ed function so it can be called with a number of different arguments. See the examples of the <code>expectation</code> function. This function works exactly the same.</p> PARAMETER  DESCRIPTION <code>x</code> <p>Circuit, block, or (register+block) to run.</p> <p> TYPE: <code>Union[QuantumCircuit, AbstractBlock, Register, int]</code> </p> <code>values</code> <p>User-facing parameter dict.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>state</code> <p>Initial state.</p> <p> TYPE: <code>Union[Tensor, None]</code> DEFAULT: <code>None</code> </p> <code>n_shots</code> <p>Number of shots per element in the batch.</p> <p> TYPE: <code>int</code> DEFAULT: <code>100</code> </p> <code>backend</code> <p>Name of the backend to run on.</p> <p> TYPE: <code>BackendName</code> DEFAULT: <code>PYQTORCH</code> </p> <code>endianness</code> <p>The target device endianness.</p> <p> TYPE: <code>Endianness</code> DEFAULT: <code>BIG</code> </p> <code>configuration</code> <p>The backend configuration.</p> <p> TYPE: <code>Union[BackendConfiguration, dict, None]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[Counter]</code> <p>A list of Counter instances with the sample results</p> Source code in <code>qadence/execution.py</code> <pre><code>@singledispatch\ndef sample(\nx: Union[QuantumCircuit, AbstractBlock, Register, int],\n*args: Any,\nvalues: dict = {},\nstate: Union[Tensor, None] = None,\nn_shots: int = 100,\nbackend: BackendName = BackendName.PYQTORCH,\nendianness: Endianness = Endianness.BIG,\nconfiguration: Union[BackendConfiguration, dict, None] = None,\n) -&gt; list[Counter]:\n\"\"\"Convenience wrapper for the `QuantumModel.sample` method.  This is a\n    `functools.singledispatch`ed function so it can be called with a number of different arguments.\n    See the examples of the [`expectation`][qadence.execution.expectation] function. This function\n    works exactly the same.\n    Arguments:\n        x: Circuit, block, or (register+block) to run.\n        values: User-facing parameter dict.\n        state: Initial state.\n        n_shots: Number of shots per element in the batch.\n        backend: Name of the backend to run on.\n        endianness: The target device endianness.\n        configuration: The backend configuration.\n    Returns:\n        A list of Counter instances with the sample results\n    \"\"\"\nraise ValueError(f\"Cannot sample from {type(x)}\")\n</code></pre>"},{"location":"qadence/ml_tools/","title":"QML tools","text":""},{"location":"qadence/ml_tools/#ml-tools","title":"ML Tools","text":"<p>This module implements gradient-free and gradient-based training loops for torch Modules and QuantumModel.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig","title":"<code>TrainConfig</code>  <code>dataclass</code>","text":"<p>Default config for the train function. The default value of each field can be customize with the constructor:</p> <pre><code>from qadence.ml_tools import TrainConfig\nc = TrainConfig(folder=\"/tmp/train\")\n</code></pre> <pre><code>TrainConfig(max_iter=10000, print_every=1000, write_every=50, checkpoint_every=5000, folder=PosixPath('/tmp/train'), create_subfolder_per_run=False, checkpoint_best_only=False, validation_criterion=&lt;function TrainConfig.__post_init__.&lt;locals&gt;.&lt;lambda&gt; at 0x2920708b0&gt;, trainstop_criterion=&lt;function TrainConfig.__post_init__.&lt;locals&gt;.&lt;lambda&gt; at 0x2920704c0&gt;, batch_size=1)\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.batch_size","title":"<code>batch_size: int = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The batch_size to use when passing a list/tuple of torch.Tensors.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.checkpoint_best_only","title":"<code>checkpoint_best_only: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Write model/optimizer checkpoint only if a metric has improved</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.checkpoint_every","title":"<code>checkpoint_every: int = 5000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Write model/optimizer checkpoint</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.create_subfolder_per_run","title":"<code>create_subfolder_per_run: bool = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Checkpoint/tensorboard logs stored in subfolder with name <code>&lt;timestamp&gt;_&lt;PID&gt;</code>. Prevents continuing from previous checkpoint, useful for fast prototyping.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.folder","title":"<code>folder: Optional[Path] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Checkpoint/tensorboard logs folder</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.max_iter","title":"<code>max_iter: int = 10000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of training iterations.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.print_every","title":"<code>print_every: int = 1000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Print loss/metrics.</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.trainstop_criterion","title":"<code>trainstop_criterion: Optional[Callable] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A boolean function which evaluates a given training stopping metric is satisfied</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.validation_criterion","title":"<code>validation_criterion: Optional[Callable] = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A boolean function which evaluates a given validation metric is satisfied</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.config.TrainConfig.write_every","title":"<code>write_every: int = 50</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Write tensorboard logs</p>"},{"location":"qadence/ml_tools/#qadence.ml_tools.parameters.get_parameters","title":"<code>get_parameters(model)</code>","text":"<p>Retrieve all trainable model parameters in a single vector</p> PARAMETER  DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>a 1-dimensional tensor with the parameters</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def get_parameters(model: Module) -&gt; Tensor:\n\"\"\"Retrieve all trainable model parameters in a single vector\n    Args:\n        model (Module): the input PyTorch model\n    Returns:\n        Tensor: a 1-dimensional tensor with the parameters\n    \"\"\"\nps = [p.reshape(-1) for p in model.parameters() if p.requires_grad]\nreturn torch.concat(ps)\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.parameters.num_parameters","title":"<code>num_parameters(model)</code>","text":"<p>Return the total number of parameters of the given model</p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def num_parameters(model: Module) -&gt; int:\n\"\"\"Return the total number of parameters of the given model\"\"\"\nreturn len(get_parameters(model))\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.parameters.set_parameters","title":"<code>set_parameters(model, theta)</code>","text":"<p>Set all trainable parameters of a model from a single vector</p> <p>Notice that this function assumes prior knowledge of right number of parameters in the model</p> PARAMETER  DESCRIPTION <code>model</code> <p>the input PyTorch model</p> <p> TYPE: <code>Module</code> </p> <code>theta</code> <p>the parameters to assign</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>qadence/ml_tools/parameters.py</code> <pre><code>def set_parameters(model: Module, theta: Tensor) -&gt; None:\n\"\"\"Set all trainable parameters of a model from a single vector\n    Notice that this function assumes prior knowledge of right number\n    of parameters in the model\n    Args:\n        model (Module): the input PyTorch model\n        theta (Tensor): the parameters to assign\n    \"\"\"\nwith torch.no_grad():\nidx = 0\nfor ps in model.parameters():\nif ps.requires_grad:\nn = torch.numel(ps)\nif ps.ndim == 0:\nps[()] = theta[idx : idx + n]\nelse:\nps[:] = theta[idx : idx + n].reshape(ps.size())\nidx += n\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.optimize_step.data_to_model","title":"<code>data_to_model(xs, device='cpu')</code>","text":"<p>Default behavior for single-dispatched function</p> <p>Just return the given data independently on the type</p> PARAMETER  DESCRIPTION <code>xs</code> <p>the input data</p> <p> TYPE: <code>Any</code> </p> <code>device</code> <p>The torch device. Not used in this implementation.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>the <code>xs</code> argument untouched</p> <p> TYPE: <code>Any</code> </p> Source code in <code>qadence/ml_tools/optimize_step.py</code> <pre><code>@singledispatch\ndef data_to_model(xs: Any, device: str = \"cpu\") -&gt; Any:\n\"\"\"Default behavior for single-dispatched function\n    Just return the given data independently on the type\n    Args:\n        xs (Any): the input data\n        device (str, optional): The torch device. Not used in this implementation.\n    Returns:\n        Any: the `xs` argument untouched\n    \"\"\"\nreturn xs\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.optimize_step.optimize_step","title":"<code>optimize_step(model, optimizer, loss_fn, xs, device='cpu')</code>","text":"<p>Default Torch optimize step with closure</p> <p>This is the default optimization step which should work for most of the standard use cases of optimization of Torch models</p> PARAMETER  DESCRIPTION <code>model</code> <p>The input model</p> <p> TYPE: <code>Module</code> </p> <code>optimizer</code> <p>The chosen Torch optimizer</p> <p> TYPE: <code>Optimizer</code> </p> <code>loss_fn</code> <p>A custom loss function</p> <p> TYPE: <code>Callable</code> </p> <code>xs</code> <p>the input data. If None it means that the given model does not require any input data</p> <p> TYPE: <code>dict | list | Tensor | None</code> </p> <code>device</code> <p>The device were computations are executed. Defaults to \"cpu\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> RETURNS DESCRIPTION <code>tuple</code> <p>tuple containing the model, the optimizer, a dictionary with the collected metrics and the compute value loss</p> <p> TYPE: <code>tuple[Tensor | float, dict | None]</code> </p> Source code in <code>qadence/ml_tools/optimize_step.py</code> <pre><code>def optimize_step(\nmodel: Module,\noptimizer: Optimizer,\nloss_fn: Callable,\nxs: dict | list | torch.Tensor | None,\ndevice: str = \"cpu\",\n) -&gt; tuple[torch.Tensor | float, dict | None]:\n\"\"\"Default Torch optimize step with closure\n    This is the default optimization step which should work for most\n    of the standard use cases of optimization of Torch models\n    Args:\n        model (Module): The input model\n        optimizer (Optimizer): The chosen Torch optimizer\n        loss_fn (Callable): A custom loss function\n        xs (dict | list | torch.Tensor | None): the input data. If None it means\n            that the given model does not require any input data\n        device (str, optional): The device were computations are executed.\n            Defaults to \"cpu\".\n    Returns:\n        tuple: tuple containing the model, the optimizer, a dictionary with\n            the collected metrics and the compute value loss\n    \"\"\"\nloss, metrics = None, {}\ndef closure() -&gt; Any:\n# NOTE: We need the nonlocal as we can't return a metric dict and\n# because e.g. LBFGS calls this closure multiple times but for some\n# reason the returned loss is always the first one...\nnonlocal metrics, loss\noptimizer.zero_grad()\nloss, metrics = loss_fn(model, xs)\nloss.backward(retain_graph=True)\nreturn loss.item()\noptimizer.step(closure)\n# return the loss/metrics that are being mutated inside the closure...\nreturn loss, metrics\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.train_grad.train","title":"<code>train(model, dataloader, optimizer, config, loss_fn, device='cpu', optimize_step=optimize_step, write_tensorboard=write_tensorboard)</code>","text":"<p>Runs the training loop with gradient-based optimizer</p> <p>Assumes that <code>loss_fn</code> returns a tuple of (loss, metrics: dict), where <code>metrics</code> is a dict of scalars. Loss and metrics are written to tensorboard. Checkpoints are written every <code>config.checkpoint_every</code> steps (and after the last training step).  If a checkpoint is found at <code>config.folder</code> we resume training from there.  The tensorboard logs can be viewed via <code>tensorboard --logdir /path/to/folder</code>.</p> PARAMETER  DESCRIPTION <code>model</code> <p>The model to train.</p> <p> TYPE: <code>Module</code> </p> <code>dataloader</code> <p>dataloader of different types. If None, no data is required by the model</p> <p> TYPE: <code>DictDataLoader | DataLoader | list[Tensor] | tuple[Tensor, Tensor] | None</code> </p> <code>optimizer</code> <p>The optimizer to use.</p> <p> TYPE: <code>Optimizer</code> </p> <code>config</code> <p><code>TrainConfig</code> with additional training options.</p> <p> TYPE: <code>TrainConfig</code> </p> <code>loss_fn</code> <p>Loss function returning (loss: float, metrics: dict[str, float])</p> <p> TYPE: <code>Callable</code> </p> <code>device</code> <p>String defining device to train on, pass 'cuda' for GPU.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> <code>optimize_step</code> <p>Customizable optimization callback which is called at every iteration.= The function must have the signature <code>optimize_step(model, optimizer, loss_fn, xs, device=\"cpu\")</code> (see the example below). Apart from the default we already supply three other optimization functions <code>optimize_step_evo</code>, <code>optimize_step_grad_norm</code>, and <code>optimize_step_inv_dirichlet</code>. Learn more about how to use this in the Advancded features tutorial of the documentation.</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>optimize_step</code> </p> <code>write_tensorboard</code> <p>Customizable tensorboard logging callback which is called every <code>config.write_every</code> iterations. The function must have the signature <code>write_tensorboard(writer, loss, metrics, iteration)</code> (see the example below).</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>write_tensorboard</code> </p> <p>Example: <pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence.models import QNN\nfrom qadence.ml_tools import train_with_grad, TrainConfig\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning = Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\n## lets prepare the train routine\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\nnext(cnt)\nx, y = data[0], data[1]\nout = model(x)\nloss = criterion(out, y)\nreturn loss, {}\ntmp_path = Path(\"/tmp\")\nn_epochs = 5\nconfig = TrainConfig(\nfolder=tmp_path,\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\nbatch_size = 25\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\ntrain_with_grad(model, (x, y), optimizer, config, loss_fn=loss_fn)\n</code></pre> </p> Source code in <code>qadence/ml_tools/train_grad.py</code> <pre><code>def train(\nmodel: Module,\ndataloader: DictDataLoader | DataLoader | list[Tensor] | tuple[Tensor, Tensor] | None,\noptimizer: Optimizer,\nconfig: TrainConfig,\nloss_fn: Callable,\ndevice: str = \"cpu\",\noptimize_step: Callable = optimize_step,\nwrite_tensorboard: Callable = write_tensorboard,\n) -&gt; tuple[Module, Optimizer]:\n\"\"\"Runs the training loop with gradient-based optimizer\n    Assumes that `loss_fn` returns a tuple of (loss,\n    metrics: dict), where `metrics` is a dict of scalars. Loss and metrics are\n    written to tensorboard. Checkpoints are written every\n    `config.checkpoint_every` steps (and after the last training step).  If a\n    checkpoint is found at `config.folder` we resume training from there.  The\n    tensorboard logs can be viewed via `tensorboard --logdir /path/to/folder`.\n    Args:\n        model: The model to train.\n        dataloader: dataloader of different types. If None, no data is required by\n            the model\n        optimizer: The optimizer to use.\n        config: `TrainConfig` with additional training options.\n        loss_fn: Loss function returning (loss: float, metrics: dict[str, float])\n        device: String defining device to train on, pass 'cuda' for GPU.\n        optimize_step: Customizable optimization callback which is called at every iteration.=\n            The function must have the signature `optimize_step(model,\n            optimizer, loss_fn, xs, device=\"cpu\")` (see the example below).\n            Apart from the default we already supply three other optimization\n            functions `optimize_step_evo`, `optimize_step_grad_norm`, and\n            `optimize_step_inv_dirichlet`. Learn more about how to use this in\n            the [Advancded features](../../tutorials/advanced) tutorial of the\n            documentation.\n        write_tensorboard: Customizable tensorboard logging callback which is\n            called every `config.write_every` iterations. The function must have\n            the signature `write_tensorboard(writer, loss, metrics, iteration)`\n            (see the example below).\n    Example:\n    ```python exec=\"on\" source=\"material-block\"\n    from pathlib import Path\n    import torch\n    from itertools import count\n    from qadence.constructors import hamiltonian_factory, hea, feature_map\n    from qadence import chain, Parameter, QuantumCircuit, Z\n    from qadence.models import QNN\n    from qadence.ml_tools import train_with_grad, TrainConfig\n    n_qubits = 2\n    fm = feature_map(n_qubits)\n    ansatz = hea(n_qubits=n_qubits, depth=3)\n    observable = hamiltonian_factory(n_qubits, detuning = Z)\n    circuit = QuantumCircuit(n_qubits, fm, ansatz)\n    model = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\n    batch_size = 1\n    input_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\n    pred = model(input_values)\n    ## lets prepare the train routine\n    cnt = count()\n    criterion = torch.nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n    def loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\n        next(cnt)\n        x, y = data[0], data[1]\n        out = model(x)\n        loss = criterion(out, y)\n        return loss, {}\n    tmp_path = Path(\"/tmp\")\n    n_epochs = 5\n    config = TrainConfig(\n        folder=tmp_path,\n        max_iter=n_epochs,\n        checkpoint_every=100,\n        write_every=100,\n        batch_size=batch_size,\n    )\n    batch_size = 25\n    x = torch.linspace(0, 1, batch_size).reshape(-1, 1)\n    y = torch.sin(x)\n    train_with_grad(model, (x, y), optimizer, config, loss_fn=loss_fn)\n    ```\n    \"\"\"\nassert loss_fn is not None, \"Provide a valid loss function\"\n# Move model to device before optimizer is loaded\nmodel = model.to(device)\n# load available checkpoint\ninit_iter = 0\nif config.folder:\nmodel, optimizer, init_iter = load_checkpoint(config.folder, model, optimizer)\nlogger.debug(f\"Loaded model and optimizer from {config.folder}\")\n# initialize tensorboard\nwriter = SummaryWriter(config.folder, purge_step=init_iter)\n## Training\nprogress = Progress(\nTextColumn(\"[progress.description]{task.description}\"),\nBarColumn(),\nTaskProgressColumn(),\nTimeRemainingColumn(elapsed_when_finished=True),\n)\nif isinstance(dataloader, (list, tuple)):\nfrom qadence.ml_tools.data import to_dataloader\nassert len(dataloader) == 2, \"Please provide exactly two torch tensors.\"\nx, y = dataloader\ndataloader = to_dataloader(x=x, y=y, batch_size=config.batch_size)\nwith progress:\ndl_iter = iter(dataloader) if isinstance(dataloader, DictDataLoader) else None\n# outer epoch loop\nfor iteration in progress.track(range(init_iter, init_iter + config.max_iter)):\ntry:\n# in case there is not data needed by the model\n# this is the case, for example, of quantum models\n# which do not have classical input data (e.g. chemistry)\nif dataloader is None:\nloss, metrics = optimize_step(\nmodel, optimizer, loss_fn, dataloader, device=device\n)\nloss = loss.item()\n# single epoch with DictDataloader using a single iteration method\n# DictDataloader returns a single sample of the data\n# with a given batch size decided when the dataloader is defined\nelif isinstance(dataloader, DictDataLoader):\n# resample all the time from the dataloader\n# by creating a fresh iterator if the dataloader\n# does not support automatically iterating datasets\nif not dataloader.has_automatic_iter:\ndl_iter = iter(dataloader)\ndata = next(dl_iter)  # type: ignore[arg-type]\nloss, metrics = optimize_step(model, optimizer, loss_fn, data, device=device)\nelif isinstance(dataloader, DataLoader):\n# single-epoch with standard DataLoader\n# otherwise a standard PyTorch DataLoader behavior\n# is assumed with optional mini-batches\nrunning_loss = 0.0\nfor i, data in enumerate(dataloader):\n# TODO: make sure to average metrics as well\nloss, metrics = optimize_step(\nmodel, optimizer, loss_fn, data, device=device\n)\nrunning_loss += loss.item()\nloss = running_loss / (i + 1)\nelse:\nraise NotImplementedError(\"Unsupported dataloader type!\")\nif iteration % config.print_every == 0:\nprint_metrics(loss, metrics, iteration)\nif iteration % config.write_every == 0:\nwrite_tensorboard(writer, loss, metrics, iteration)\nif config.folder:\nif iteration % config.checkpoint_every == 0:\nwrite_checkpoint(config.folder, model, optimizer, iteration)\nexcept KeyboardInterrupt:\nprint(\"Terminating training gracefully after the current iteration.\")\nbreak\n# Final writing and checkpointing\nif config.folder:\nwrite_checkpoint(config.folder, model, optimizer, iteration)\nwrite_tensorboard(writer, loss, metrics, iteration)\nwriter.close()\nreturn model, optimizer\n</code></pre>"},{"location":"qadence/ml_tools/#qadence.ml_tools.train_no_grad.train","title":"<code>train(model, dataloader, optimizer, config, loss_fn)</code>","text":"<p>Runs the training loop with a gradient-free optimizer</p> <p>Assumes that <code>loss_fn</code> returns a tuple of (loss, metrics: dict), where <code>metrics</code> is a dict of scalars. Loss and metrics are written to tensorboard. Checkpoints are written every <code>config.checkpoint_every</code> steps (and after the last training step).  If a checkpoint is found at <code>config.folder</code> we resume training from there.  The tensorboard logs can be viewed via <code>tensorboard --logdir /path/to/folder</code>.</p> PARAMETER  DESCRIPTION <code>model</code> <p>The model to train</p> <p> TYPE: <code>Module</code> </p> <code>dataloader</code> <p>Dataloader constructed via <code>dictdataloader</code></p> <p> TYPE: <code>DictDataLoader | DataLoader | None</code> </p> <code>optimizer</code> <p>The optimizer to use taken from the Nevergrad library. If this is not the case the function will raise an AssertionError</p> <p> TYPE: <code>Optimizer</code> </p> <code>loss_fn</code> <p>Loss function returning (loss: float, metrics: dict[str, float])</p> <p> TYPE: <code>Callable</code> </p> Source code in <code>qadence/ml_tools/train_no_grad.py</code> <pre><code>def train(\nmodel: Module,\ndataloader: DictDataLoader | DataLoader | None,\noptimizer: NGOptimizer,\nconfig: TrainConfig,\nloss_fn: Callable,\n) -&gt; tuple[Module, NGOptimizer]:\n\"\"\"Runs the training loop with a gradient-free optimizer\n    Assumes that `loss_fn` returns a tuple of (loss, metrics: dict), where\n    `metrics` is a dict of scalars. Loss and metrics are written to\n    tensorboard. Checkpoints are written every `config.checkpoint_every` steps\n    (and after the last training step).  If a checkpoint is found at `config.folder`\n    we resume training from there.  The tensorboard logs can be viewed via\n    `tensorboard --logdir /path/to/folder`.\n    Args:\n        model: The model to train\n        dataloader: Dataloader constructed via `dictdataloader`\n        optimizer: The optimizer to use taken from the Nevergrad library. If this is not\n            the case the function will raise an AssertionError\n        loss_fn: Loss function returning (loss: float, metrics: dict[str, float])\n    \"\"\"\ninit_iter = 0\nif config.folder:\nmodel, optimizer, init_iter = load_checkpoint(config.folder, model, optimizer)\nlogger.debug(f\"Loaded model and optimizer from {config.folder}\")\ndef _update_parameters(\ndata: Tensor | None, ng_params: ng.p.Array\n) -&gt; tuple[float, dict, ng.p.Array]:\nloss, metrics = loss_fn(model, data)  # type: ignore[misc]\noptimizer.tell(ng_params, float(loss))\nng_params = optimizer.ask()  # type: ignore [assignment]\nparams = promote_to_tensor(ng_params.value, requires_grad=False)\nset_parameters(model, params)\nreturn loss, metrics, ng_params\nassert loss_fn is not None, \"Provide a valid loss function\"\n# TODO: support also Scipy optimizers\nassert isinstance(optimizer, NGOptimizer), \"Use only optimizers from the Nevergrad library\"\n# initialize tensorboard\nwriter = SummaryWriter(config.folder, purge_step=init_iter)\n# set optimizer configuration and initial parameters\noptimizer.budget = config.max_iter\noptimizer.enable_pickling()\n# TODO: Make it GPU compatible if possible\nparams = get_parameters(model).detach().numpy()\nng_params = ng.p.Array(init=params)\n# serial training\n# TODO: Add a parallelization using the num_workers argument in Nevergrad\nprogress = Progress(\nTextColumn(\"[progress.description]{task.description}\"),\nBarColumn(),\nTaskProgressColumn(),\nTimeRemainingColumn(elapsed_when_finished=True),\n)\nwith progress:\ndl_iter = iter(dataloader) if isinstance(dataloader, DictDataLoader) else None\nfor iteration in progress.track(range(init_iter, init_iter + config.max_iter)):\nif dataloader is None:\nloss, metrics, ng_params = _update_parameters(None, ng_params)\nelif isinstance(dataloader, DictDataLoader):\n# resample all the time from the dataloader\n# by creating a fresh iterator if the dataloader\n# does not support automatically iterating datasets\nif not dataloader.has_automatic_iter:\ndl_iter = iter(dataloader)\ndata = next(dl_iter)  # type: ignore[arg-type]\nloss, metrics, ng_params = _update_parameters(data, ng_params)\nelif isinstance(dataloader, DataLoader):\n# single-epoch with standard DataLoader\n# otherwise a standard PyTorch DataLoader behavior\n# is assumed with optional mini-batches\nrunning_loss = 0.0\nfor i, data in enumerate(dataloader):\nloss, metrics, ng_params = _update_parameters(data, ng_params)\nrunning_loss += loss\nloss = running_loss / (i + 1)\nelse:\nraise NotImplementedError(\"Unsupported dataloader type!\")\nif iteration % config.print_every == 0:\nprint_metrics(loss, metrics, iteration)\nif iteration % config.write_every == 0:\nwrite_tensorboard(writer, loss, metrics, iteration)\nif config.folder:\nif iteration % config.checkpoint_every == 0:\nwrite_checkpoint(config.folder, model, optimizer, iteration)\nif iteration &gt;= init_iter + config.max_iter:\nbreak\n## Final writing and stuff\nif config.folder:\nwrite_checkpoint(config.folder, model, optimizer, iteration)\nwrite_tensorboard(writer, loss, metrics, iteration)\nwriter.close()\nreturn model, optimizer\n</code></pre>"},{"location":"qadence/operations/","title":"Operations","text":"<p>Operations are common <code>PrimitiveBlocks</code>, these are often called gates elsewhere.</p>"},{"location":"qadence/operations/#constant-blocks","title":"Constant blocks","text":"<p>CY gate not implemented</p>"},{"location":"qadence/operations/#qadence.operations.X","title":"<code>X(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The X gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.Y","title":"<code>Y(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Y gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.Z","title":"<code>Z(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Z gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.I","title":"<code>I(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The identity gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.H","title":"<code>H(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Hadamard or H gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = (1 / np.sqrt(2)) * (X(target) + Z(target) - np.sqrt(2) * I(target))\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.S","title":"<code>S(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The S / Phase gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.SDagger","title":"<code>SDagger(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Hermitian adjoint/conjugate transpose of the S / Phase gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.SWAP","title":"<code>SWAP(control, target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The SWAP gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, control: int, target: int) -&gt; None:\na11 = 0.5 * (Z(control) - I(control))\na22 = -0.5 * (Z(target) + I(target))\na12 = 0.5 * (chain(X(control), Z(control)) + X(control))\na21 = 0.5 * (chain(Z(target), X(target)) + X(target))\nself.generator = (\nkron(-1.0 * a22, a11) + kron(-1.0 * a11, a22) + kron(a12, a21) + kron(a21, a12)\n)\nsuper().__init__((control, target))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.T","title":"<code>T(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The T gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.TDagger","title":"<code>TDagger(target)</code>","text":"<p>             Bases: <code>PrimitiveBlock</code></p> <p>The Hermitian adjoint/conjugate transpose of the T gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int):\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CNOT","title":"<code>CNOT(control, target)</code>","text":"<p>             Bases: <code>ControlBlock</code></p> <p>The CNot, or CX, gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, control: int, target: int) -&gt; None:\nself.generator = kron((I(control) - Z(control)) * 0.5, X(target) - I(target))\nsuper().__init__((control,), X(target))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CZ","title":"<code>CZ(control, target)</code>","text":"<p>             Bases: <code>MCZ</code></p> <p>The CZ gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, control: int, target: int) -&gt; None:\nsuper().__init__((control,), target)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CPHASE","title":"<code>CPHASE(control, target, parameter)</code>","text":"<p>             Bases: <code>MCPHASE</code></p> <p>The CPHASE gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ncontrol: int,\ntarget: int,\nparameter: Parameter | TNumber | sympy.Expr | str,\n):\nsuper().__init__((control,), target, parameter)\n</code></pre>"},{"location":"qadence/operations/#parametrized-blocks","title":"Parametrized blocks","text":""},{"location":"qadence/operations/#qadence.operations.RX","title":"<code>RX(target, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The Rx gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TParameter | ParamMap):\n# TODO: should we give them more meaningful names? like 'angle'?\nself.parameters = (\nparameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n)\nself.generator = X(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.RY","title":"<code>RY(target, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The Ry gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TParameter | ParamMap):\nself.parameters = (\nparameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n)\nself.generator = Y(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.RZ","title":"<code>RZ(target, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The Rz gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TParameter | ParamMap):\nself.parameters = (\nparameter if isinstance(parameter, ParamMap) else ParamMap(parameter=parameter)\n)\nself.generator = Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CRX","title":"<code>CRX(control, target, parameter)</code>","text":"<p>             Bases: <code>MCRX</code></p> <p>The CRX gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ncontrol: int,\ntarget: int,\nparameter: Parameter | TNumber | sympy.Expr | str,\n):\nsuper().__init__((control,), target, parameter)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CRY","title":"<code>CRY(control, target, parameter)</code>","text":"<p>             Bases: <code>MCRY</code></p> <p>The CRY gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ncontrol: int,\ntarget: int,\nparameter: Parameter | TNumber | sympy.Expr | str,\n):\nsuper().__init__((control,), target, parameter)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.CRZ","title":"<code>CRZ(control, target, parameter)</code>","text":"<p>             Bases: <code>MCRZ</code></p> <p>The CRZ gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ncontrol: int,\ntarget: int,\nparameter: Parameter | TNumber | sympy.Expr | str,\n):\nsuper().__init__((control,), target, parameter)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.PHASE","title":"<code>PHASE(target, parameter)</code>","text":"<p>             Bases: <code>ParametricBlock</code></p> <p>The Parametric Phase / S gate</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, target: int, parameter: Parameter | TNumber | sympy.Expr | str):\nself.parameters = ParamMap(parameter=parameter)\nself.generator = I(target) - Z(target)\nsuper().__init__((target,))\n</code></pre>"},{"location":"qadence/operations/#hamiltonian-evolution","title":"Hamiltonian Evolution","text":"<p>AnalogSWAP should be turned into a proper analog block</p>"},{"location":"qadence/operations/#qadence.operations.HamEvo","title":"<code>HamEvo(generator, parameter, qubit_support=None)</code>","text":"<p>             Bases: <code>TimeEvolutionBlock</code></p> A block implementing the Hamiltonian evolution operation H where <p>H = exp(-iG, t)</p> <p>where G represents a square generator and t represents the time parameter which can be parametrized.</p> PARAMETER  DESCRIPTION <code>generator</code> <p>Either a AbstractBlock, torch.Tensor or numpy.ndarray.</p> <p> TYPE: <code>Union[TGenerator, AbstractBlock]</code> </p> <code>parameter</code> <p>A scalar or vector of numeric or torch.Tensor type.</p> <p> TYPE: <code>TParameter</code> </p> <code>qubit_support</code> <p>The qubits on which the evolution will be performed on.</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>None</code> </p> <p>Examples:</p> <pre><code>from qadence import RX, HamEvo, run\nimport torch\nhevo = HamEvo(generator=RX(0, torch.pi), parameter=torch.rand(2))\nprint(run(hevo))\n# Now lets use a torch.Tensor as a generator, Now we have to pass the support\ngen = torch.rand(2,2, dtype=torch.complex128)\nhevo = HamEvo(generator=gen, parameter=torch.rand(2), qubit_support=(0,))\nprint(run(hevo))\n</code></pre> <pre><code>tensor([[ 1.2374-5.1225e-17j, -0.7288+3.0170e-17j],\n[ 1.1660-4.0583e-17j, -0.5995+2.0868e-17j]])\ntensor([[1.7414-1.2075j, 0.7742-1.1094j],\n[1.3634-0.3266j, 0.4083-0.2874j]])\n</code></pre> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(\nself,\ngenerator: Union[TGenerator, AbstractBlock],\nparameter: TParameter,\nqubit_support: tuple[int, ...] = None,\n):\ngen_exprs = {}\nif qubit_support is None and not isinstance(generator, AbstractBlock):\nraise ValueError(\"You have to supply a qubit support for non-block generators.\")\nsuper().__init__(qubit_support if qubit_support else generator.qubit_support)\nif isinstance(generator, AbstractBlock):\nqubit_support = generator.qubit_support\nif generator.is_parametric:\ngen_exprs = {str(e): e for e in expressions(generator)}\nelif isinstance(generator, torch.Tensor):\nmsg = \"Please provide a square generator.\"\nif len(generator.shape) == 2:\nassert generator.shape[0] == generator.shape[1], msg\nelif len(generator.shape) == 3:\nassert generator.shape[1] == generator.shape[2], msg\nassert generator.shape[0] == 1, \"Qadence doesnt support batched generators.\"\nelse:\nraise TypeError(\n\"Only 2D or 3D generators are supported.\\\n                            In case of a 3D generator, the batch dim\\\n                            is expected to be at dim 0.\"\n)\ngen_exprs = {str(generator.__hash__()): generator}\nelif isinstance(generator, (sympy.Basic, sympy.Array)):\ngen_exprs = {str(generator): generator}\nelse:\nraise TypeError(\nf\"Generator of type {type(generator)} not supported.\\\n                        If you're using a numpy.ndarray, please cast it to a torch tensor.\"\n)\nps = {\"parameter\": Parameter(parameter), **gen_exprs}\nself.parameters = ParamMap(**ps)\nself.generator = generator\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.HamEvo.digital_decomposition","title":"<code>digital_decomposition(approximation=LTSOrder.ST4)</code>","text":"<p>Decompose the Hamiltonian evolution into digital gates</p> PARAMETER  DESCRIPTION <code>approximation</code> <p>Choose the type of decomposition. Defaults to \"st4\". Available types are: * 'basic' = apply first-order Trotter formula and decompose each term of     the exponential into digital gates. It is exact only if applied to an     operator whose terms are mutually commuting. * 'st2' = Trotter-Suzuki 2nd order formula for approximating non-commuting     Hamiltonians. * 'st4' = Trotter-Suzuki 4th order formula for approximating non-commuting     Hamiltonians.</p> <p> TYPE: <code>str</code> DEFAULT: <code>ST4</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>a block with the digital decomposition</p> <p> TYPE: <code>AbstractBlock</code> </p> Source code in <code>qadence/operations.py</code> <pre><code>def digital_decomposition(self, approximation: LTSOrder = LTSOrder.ST4) -&gt; AbstractBlock:\n\"\"\"Decompose the Hamiltonian evolution into digital gates\n    Args:\n        approximation (str, optional): Choose the type of decomposition. Defaults to \"st4\".\n            Available types are:\n            * 'basic' = apply first-order Trotter formula and decompose each term of\n                the exponential into digital gates. It is exact only if applied to an\n                operator whose terms are mutually commuting.\n            * 'st2' = Trotter-Suzuki 2nd order formula for approximating non-commuting\n                Hamiltonians.\n            * 'st4' = Trotter-Suzuki 4th order formula for approximating non-commuting\n                Hamiltonians.\n    Returns:\n        AbstractBlock: a block with the digital decomposition\n    \"\"\"\n# psi(t) = exp(-i * H * t * psi0)\n# psi(t) = exp(-i * lambda * t * psi0)\n# H = sum(Paulin) + sum(Pauli1*Pauli2)\nlogger.info(\"Quantum simulation of the time-independent Schr\u00f6dinger equation.\")\nblocks = []\n# how to change the type/dict to enum effectively\n# when there is a term including non-commuting matrices use st2 or st4\n# 1) should check that the given generator respects the constraints\n# single-qubit gates\nassert isinstance(\nself.generator, AbstractBlock\n), \"Only a generator represented as a block can be decomposed\"\nif block_is_qubit_hamiltonian(self.generator):\ntry:\nblock_is_commuting_hamiltonian(self.generator)\napproximation = LTSOrder.BASIC  # use the simpler approach if the H is commuting\nexcept TypeError:\nlogger.warning(\n\"\"\"Non-commuting terms in the Pauli operator.\n                The Suzuki-Trotter approximation is applied.\"\"\"\n)\nblocks.extend(\nlie_trotter_suzuki(\nblock=self.generator,\nparameter=self.parameters.parameter,\norder=LTSOrder[approximation],\n)\n)\n# 2) return an AbstractBlock instance with the set of gates\n# resulting from the decomposition\nreturn chain(*blocks)\nelse:\nraise NotImplementedError(\n\"The current digital decomposition can be applied only to Pauli Hamiltonians.\"\n)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.AnalogSWAP","title":"<code>AnalogSWAP(control, target, parameter=3 * np.pi / 4)</code>","text":"<p>             Bases: <code>HamEvo</code></p> <p>Single time-independent Hamiltonian evolution over a Rydberg Ising hamiltonian yielding a SWAP (up to global phase).</p> <p>Derived from Bapat et al. where it is applied to XX-type Hamiltonian</p> Source code in <code>qadence/operations.py</code> <pre><code>def __init__(self, control: int, target: int, parameter: TParameter = 3 * np.pi / 4):\nrydberg_ising_hamiltonian_generator = (\n4.0 * kron((I(control) - Z(control)) / 2.0, (I(target) - Z(target)) / 2.0)\n+ (2.0 / 3.0) * np.sqrt(2.0) * X(control)\n+ (2.0 / 3.0) * np.sqrt(2.0) * X(target)\n+ (1.0 + np.sqrt(5.0) / 3) * Z(control)\n+ (1.0 + np.sqrt(5.0) / 3) * Z(target)\n)\nsuper().__init__(rydberg_ising_hamiltonian_generator, parameter, (control, target))\n</code></pre>"},{"location":"qadence/operations/#analog-blocks","title":"Analog blocks","text":""},{"location":"qadence/operations/#qadence.operations.AnalogRX","title":"<code>AnalogRX(angle, qubit_support='global')</code>","text":"<p>Analog X rotation. Shorthand for <code>AnalogRot</code>:</p> <pre><code>\u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\nAnalogRot(duration=t, omega=\u03a9)\n</code></pre> PARAMETER  DESCRIPTION <code>angle</code> <p>Rotation angle [rad]</p> <p> TYPE: <code>float | str | Parameter</code> </p> <code>qubit_support</code> <p>Defines the (local/global) qubit support</p> <p> TYPE: <code>str | QubitSupport | Tuple</code> DEFAULT: <code>'global'</code> </p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations.py</code> <pre><code>def AnalogRX(\nangle: float | str | Parameter,\nqubit_support: str | QubitSupport | Tuple = \"global\",\n) -&gt; ConstantAnalogRotation:\n\"\"\"Analog X rotation. Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n    ```python\n    \u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\n    AnalogRot(duration=t, omega=\u03a9)\n    ```\n    Arguments:\n        angle: Rotation angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\nreturn _analog_rot(angle, qubit_support, phase=0)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.AnalogRY","title":"<code>AnalogRY(angle, qubit_support='global')</code>","text":"<p>Analog Y rotation. Shorthand for <code>AnalogRot</code>:</p> <p><pre><code>\u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\nAnalogRot(duration=t, omega=\u03a9, phase=-\u03c0/2)\n</code></pre> Arguments:     angle: Rotation angle [rad]     qubit_support: Defines the (local/global) qubit support</p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations.py</code> <pre><code>def AnalogRY(\nangle: float | str | Parameter,\nqubit_support: str | QubitSupport | Tuple = \"global\",\n) -&gt; ConstantAnalogRotation:\n\"\"\"Analog Y rotation. Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n    ```python\n    \u03c6=2.4; \u03a9=\u03c0; t = \u03c6/\u03a9 * 1000\n    AnalogRot(duration=t, omega=\u03a9, phase=-\u03c0/2)\n    ```\n    Arguments:\n        angle: Rotation angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\nreturn _analog_rot(angle, qubit_support, phase=-np.pi / 2)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.AnalogRZ","title":"<code>AnalogRZ(angle, qubit_support='global')</code>","text":"<p>Analog Z rotation. Shorthand for <code>AnalogRot</code>: <pre><code>\u03c6=2.4; \u03b4=\u03c0; t = \u03c6/\u03b4 * 100)\nAnalogRot(duration=t, delta=\u03b4, phase=\u03c0/2)\n</code></pre></p> Source code in <code>qadence/operations.py</code> <pre><code>def AnalogRZ(\nangle: float | str | Parameter,\nqubit_support: str | QubitSupport | Tuple = \"global\",\n) -&gt; ConstantAnalogRotation:\n\"\"\"Analog Z rotation. Shorthand for [`AnalogRot`][qadence.operations.AnalogRot]:\n    ```\n    \u03c6=2.4; \u03b4=\u03c0; t = \u03c6/\u03b4 * 100)\n    AnalogRot(duration=t, delta=\u03b4, phase=\u03c0/2)\n    ```\n    \"\"\"\nq = _cast(QubitSupport, qubit_support)\nalpha = _cast(Parameter, angle)\ndelta = np.pi\nduration = alpha / delta * 1000\nps = ParamMap(alpha=alpha, duration=duration, omega=0, delta=delta, phase=np.pi / 2)\nreturn ConstantAnalogRotation(qubit_support=q, parameters=ps)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.AnalogRot","title":"<code>AnalogRot(duration=1000.0, omega=0, delta=0, phase=0, qubit_support='global')</code>","text":"<p>General analog rotation operation.</p> PARAMETER  DESCRIPTION <code>duration</code> <p>Duration of the rotation [ns].</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>1000.0</code> </p> <code>omega</code> <p>Rotation frequency [rad/\u03bcs]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>delta</code> <p>Rotation frequency [rad/\u03bcs]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>phase</code> <p>Phase angle [rad]</p> <p> TYPE: <code>float | str | Parameter</code> DEFAULT: <code>0</code> </p> <code>qubit_support</code> <p>Defines the (local/global) qubit support</p> <p> TYPE: <code>str | QubitSupport | Tuple</code> DEFAULT: <code>'global'</code> </p> RETURNS DESCRIPTION <code>ConstantAnalogRotation</code> <p>ConstantAnalogRotation</p> Source code in <code>qadence/operations.py</code> <pre><code>def AnalogRot(\nduration: float | str | Parameter = 1000.0,\nomega: float | str | Parameter = 0,\ndelta: float | str | Parameter = 0,\nphase: float | str | Parameter = 0,\nqubit_support: str | QubitSupport | Tuple = \"global\",\n) -&gt; ConstantAnalogRotation:\n\"\"\"General analog rotation operation.\n    Arguments:\n        duration: Duration of the rotation [ns].\n        omega: Rotation frequency [rad/\u03bcs]\n        delta: Rotation frequency [rad/\u03bcs]\n        phase: Phase angle [rad]\n        qubit_support: Defines the (local/global) qubit support\n    Returns:\n        ConstantAnalogRotation\n    \"\"\"\nq = _cast(QubitSupport, qubit_support)\nif isinstance(duration, str):\nduration = Parameter(duration)\nalpha = duration * sympy.sqrt(omega**2 + delta**2) / 1000  # type: ignore [operator]\nps = ParamMap(alpha=alpha, duration=duration, omega=omega, delta=delta, phase=phase)\nreturn ConstantAnalogRotation(parameters=ps, qubit_support=q)\n</code></pre>"},{"location":"qadence/operations/#qadence.operations.wait","title":"<code>wait(duration, qubit_support='global')</code>","text":"<p>Constructs a <code>WaitBlock</code>.</p> PARAMETER  DESCRIPTION <code>duration</code> <p>Time to wait in nanoseconds.</p> <p> TYPE: <code>TNumber | Basic</code> </p> <code>qubit_support</code> <p>Qubits the <code>WaitBlock</code> is applied to. Can be either <code>\"global\"</code> to apply the wait block to all qubits or a tuple of integers.</p> <p> TYPE: <code>str | QubitSupport | tuple</code> DEFAULT: <code>'global'</code> </p> RETURNS DESCRIPTION <code>WaitBlock</code> <p>a <code>WaitBlock</code></p> Source code in <code>qadence/operations.py</code> <pre><code>def wait(\nduration: TNumber | sympy.Basic,\nqubit_support: str | QubitSupport | tuple = \"global\",\n) -&gt; WaitBlock:\n\"\"\"Constructs a [`WaitBlock`][qadence.blocks.analog.WaitBlock].\n    Arguments:\n        duration: Time to wait in nanoseconds.\n        qubit_support: Qubits the `WaitBlock` is applied to. Can be either\n            `\"global\"` to apply the wait block to all qubits or a tuple of integers.\n    Returns:\n        a `WaitBlock`\n    \"\"\"\nq = _cast(QubitSupport, qubit_support)\nps = ParamMap(duration=duration)\nreturn WaitBlock(parameters=ps, qubit_support=q)\n</code></pre>"},{"location":"qadence/parameters/","title":"Parameters","text":""},{"location":"qadence/parameters/#parameters","title":"Parameters","text":""},{"location":"qadence/parameters/#qadence.parameters.ParamMap","title":"<code>ParamMap(**kwargs)</code>","text":"<p>Connects UUIDs of parameters to their expressions and names. This class is not user-facing and only needed for more complex block definitions. It provides convenient access to expressions/UUIDs/names needed in different backends.</p> PARAMETER  DESCRIPTION <code>kwargs</code> <p>Parameters.</p> <p> TYPE: <code>str | TNumber | Tensor | Basic | Parameter</code> DEFAULT: <code>{}</code> </p> <p>Example: <pre><code>import sympy\nfrom qadence.parameters import ParamMap\n(x,y) = sympy.symbols(\"x y\")\nps = ParamMap(omega=2.0, duration=x+y)\nprint(f\"{ps.names() = }\")\nprint(f\"{ps.expressions() = }\")\nprint(f\"{ps.uuids() = }\")\n</code></pre> <pre><code>ps.names() = dict_keys(['omega', 'duration'])\nps.expressions() = dict_values([2.00000000000000, x + y])\nps.uuids() = dict_keys(['ac0fb7a8-4a7c-467f-909a-805a45881f85', 'e44d1e44-dc3e-47c4-8a67-6f9ec6d24568'])\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def __init__(self, **kwargs: str | TNumber | Tensor | Basic | Parameter):\nself._name_dict: dict[str, tuple[str, Basic]] = {}\nself._uuid_dict: dict[str, str] = {}\nfor name, v in kwargs.items():\nparam = v if isinstance(v, sympy.Basic) else Parameter(v)\nuuid = str(uuid4())\nself._name_dict[name] = (uuid, param)\nself._uuid_dict[uuid] = param\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.Parameter","title":"<code>Parameter</code>","text":"<p>             Bases: <code>Symbol</code></p> <p>A wrapper on top of <code>sympy.Symbol</code> to include two additional keywords: <code>trainable</code> and <code>value</code>. This class is to define both feature parameter and variational parameters.</p>"},{"location":"qadence/parameters/#qadence.parameters.Parameter.trainable","title":"<code>trainable: bool</code>  <code>instance-attribute</code>","text":"<p>Trainable parameters are variational parameters. Non-trainable parameters are feature parameters.</p>"},{"location":"qadence/parameters/#qadence.parameters.Parameter.value","title":"<code>value: TNumber</code>  <code>instance-attribute</code>","text":"<p>(Initial) value of the parameter.</p>"},{"location":"qadence/parameters/#qadence.parameters.Parameter.__new__","title":"<code>__new__(name, **assumptions)</code>","text":"PARAMETER  DESCRIPTION <code>name</code> <p>When given a string only, the class constructs a trainable Parameter with a a randomly initialized value.</p> <p> TYPE: <code>str | TNumber | Tensor | Basic | Parameter</code> </p> <code>**assumptions</code> <p>are passed on to the parent class <code>sympy.Symbol</code>. Two new assumption kwargs are supported by this constructor: <code>trainable: bool</code>, and <code>value: TNumber</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> <p>Example: <pre><code>from qadence import Parameter, VariationalParameter\ntheta = Parameter(\"theta\")\nprint(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\nassert not theta.is_number\n# you can specify both trainable/value in the constructor\ntheta = Parameter(\"theta\", trainable=True, value=2.0)\nprint(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n# VariationalParameter/FeatureParameter are constructing\n# trainable/untrainable Parameters\ntheta = VariationalParameter(\"theta\", value=2.0)\nassert theta == Parameter(\"theta\", trainable=True, value=2.0)\n# When provided with a numeric type, Parameter constructs a sympy numeric type\":\nconstant_zero = Parameter(0)\nassert constant_zero.is_number\n# When passed a Parameter or a sympy expression, it just returns it.\nexpr = Parameter(\"x\") * Parameter(\"y\")\nprint(f\"{expr=} : {expr.free_symbols}\")\n</code></pre> <pre><code>theta: trainable=True value=0.854665659675864\ntheta: trainable=True value=2.0\nexpr=x*y : {x, y}\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def __new__(\ncls, name: str | TNumber | Tensor | Basic | Parameter, **assumptions: Any\n) -&gt; Parameter | Basic | Expr | Array:\n\"\"\"\n    Arguments:\n        name: When given a string only, the class\n            constructs a trainable Parameter with a a randomly initialized value.\n        **assumptions: are passed on to the parent class `sympy.Symbol`. Two new assumption\n            kwargs are supported by this constructor: `trainable: bool`, and `value: TNumber`.\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import Parameter, VariationalParameter\n    theta = Parameter(\"theta\")\n    print(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n    assert not theta.is_number\n    # you can specify both trainable/value in the constructor\n    theta = Parameter(\"theta\", trainable=True, value=2.0)\n    print(f\"{theta}: trainable={theta.trainable} value={theta.value}\")\n    # VariationalParameter/FeatureParameter are constructing\n    # trainable/untrainable Parameters\n    theta = VariationalParameter(\"theta\", value=2.0)\n    assert theta == Parameter(\"theta\", trainable=True, value=2.0)\n    # When provided with a numeric type, Parameter constructs a sympy numeric type\":\n    constant_zero = Parameter(0)\n    assert constant_zero.is_number\n    # When passed a Parameter or a sympy expression, it just returns it.\n    expr = Parameter(\"x\") * Parameter(\"y\")\n    print(f\"{expr=} : {expr.free_symbols}\")\n    ```\n    \"\"\"\np: Parameter\nif isinstance(name, get_args(TNumber)):\nreturn sympify(name)\nelif isinstance(name, Tensor):\nif name.numel() == 1:\nreturn sympify(name)\nelse:\nreturn Array(name.detach().numpy())\nelif isinstance(name, Parameter):\np = super().__new__(cls, name.name, **assumptions)\np.name = name.name\np.trainable = name.trainable\np.value = name.value\nreturn p\nelif isinstance(name, (Basic, Expr)):\nif name.is_number:\nreturn sympify(evaluate(name))\nreturn name\nelif isinstance(name, str):\np = super().__new__(cls, name, **assumptions)\np.trainable = assumptions.get(\"trainable\", True)\np.value = assumptions.get(\"value\", None)\nif p.value is None:\np.value = torch.rand(1).item()\nreturn p\nelse:\nraise TypeError(f\"Parameter does not support type {type(name)}\")\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.FeatureParameter","title":"<code>FeatureParameter(name, **kwargs)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=False)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def FeatureParameter(name: str, **kwargs: Any) -&gt; Parameter:\n\"\"\"Shorthand for `Parameter(..., trainable=False)`.\"\"\"\nreturn Parameter(name, trainable=False, **kwargs)\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.VariationalParameter","title":"<code>VariationalParameter(name, **kwargs)</code>","text":"<p>Shorthand for <code>Parameter(..., trainable=True)</code>.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def VariationalParameter(name: str, **kwargs: Any) -&gt; Parameter:\n\"\"\"Shorthand for `Parameter(..., trainable=True)`.\"\"\"\nreturn Parameter(name, trainable=True, **kwargs)\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.evaluate","title":"<code>evaluate(expr, values={}, as_torch=False)</code>","text":"PARAMETER  DESCRIPTION <code>expr</code> <p>An expression consisting of Parameters.</p> <p> TYPE: <code>Expr</code> </p> <code>values</code> <p>values dict which contains values for the Parameters, if empty, Parameter.value will be used.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>{}</code> </p> <code>as_torch</code> <p>Whether to retrieve a torch-differentiable expression result.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <p>Example: <pre><code>from qadence.parameters import Parameter, evaluate\nexpr = Parameter(\"x\") * Parameter(\"y\")\n# Unless specified, Parameter initialized random values\n# Lets evaluate this expression and see what the result is\nres = evaluate(expr)\nprint(res)\n# We can also evaluate the expr using a custom dict\nd = {\"x\": 1, \"y\":2}\nres = evaluate(expr, d)\nprint(res)\n# Lastly, if we want a differentiable result, lets put the as_torch flag\nres = evaluate(expr, d, as_torch=True)\nprint(res)\n</code></pre> <pre><code>0.013496193764961003\n2.0\ntensor([2])\n</code></pre> </p> Source code in <code>qadence/parameters.py</code> <pre><code>def evaluate(expr: Expr, values: dict = {}, as_torch: bool = False) -&gt; TNumber | Tensor:\n\"\"\"\n    Arguments:\n        expr: An expression consisting of Parameters.\n        values: values dict which contains values for the Parameters,\n            if empty, Parameter.value will be used.\n        as_torch: Whether to retrieve a torch-differentiable expression result.\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.parameters import Parameter, evaluate\n    expr = Parameter(\"x\") * Parameter(\"y\")\n    # Unless specified, Parameter initialized random values\n    # Lets evaluate this expression and see what the result is\n    res = evaluate(expr)\n    print(res)\n    # We can also evaluate the expr using a custom dict\n    d = {\"x\": 1, \"y\":2}\n    res = evaluate(expr, d)\n    print(res)\n    # Lastly, if we want a differentiable result, lets put the as_torch flag\n    res = evaluate(expr, d, as_torch=True)\n    print(res)\n    ```\n    \"\"\"\nres: Basic\nres_value: TNumber | Tensor\nquery: dict[Parameter, TNumber | Tensor] = {}\nif isinstance(expr, Array):\nreturn torch.Tensor(expr.tolist())\nelse:\nif not expr.is_number:\nfor s in expr.free_symbols:\nif s.name in values.keys():\nquery[s] = values[s.name]\nelif hasattr(s, \"value\"):\nquery[s] = s.value\nelse:\nraise ValueError(f\"No value provided for symbol {s.name}\")\nif as_torch:\nres_value = torchify(expr)(**{s.name: torch.tensor(v) for s, v in query.items()})\nelse:\nres = expr.subs(query)\nres_value = sympy_to_numeric(res)\nreturn res_value\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.extract_original_param_entry","title":"<code>extract_original_param_entry(param)</code>","text":"<p>Given an Expression, what was the original \"param\" given by the user? It is either going to be a numeric value, or a sympy Expression (in case a string was given, it was converted via Parameter(\"string\").</p> Source code in <code>qadence/parameters.py</code> <pre><code>def extract_original_param_entry(\nparam: Expr,\n) -&gt; TNumber | Tensor | Expr:\n\"\"\"\n    Given an Expression, what was the original \"param\" given by the user? It is either\n    going to be a numeric value, or a sympy Expression (in case a string was given,\n    it was converted via Parameter(\"string\").\n    \"\"\"\nreturn param if not param.is_number else evaluate(param)\n</code></pre>"},{"location":"qadence/parameters/#qadence.parameters.torchify","title":"<code>torchify(expr)</code>","text":"PARAMETER  DESCRIPTION <code>expr</code> <p>An expression consisting of Parameters.</p> <p> TYPE: <code>Expr</code> </p> RETURNS DESCRIPTION <code>SymPyModule</code> <p>A torchified, differentiable Expression.</p> Source code in <code>qadence/parameters.py</code> <pre><code>def torchify(expr: Expr) -&gt; SymPyModule:\n\"\"\"\n    Arguments:\n        expr: An expression consisting of Parameters.\n    Returns:\n        A torchified, differentiable Expression.\n    \"\"\"\nextra_funcs = {sympy.core.numbers.ImaginaryUnit: 1.0j}\nreturn SymPyModule(expressions=[expr], extra_funcs=extra_funcs)\n</code></pre>"},{"location":"qadence/parameters/#parameter-embedding","title":"Parameter embedding","text":""},{"location":"qadence/parameters/#qadence.blocks.embedding.embedding","title":"<code>embedding(block, to_gate_params=False)</code>","text":"<p>Construct embedding function which maps user-facing parameters to either expression-level parameters or gate-level parameters. The construced embedding function has the signature:</p> <pre><code> embedding_fn(params: StrTensorDict, inputs: StrTensorDict) -&gt; StrTensorDict:\n</code></pre> <p>which means that it maps the variational parameter dict <code>params</code> and the feature parameter dict <code>inputs</code> to one new parameter dict <code>embedded_dict</code> which holds all parameters that are needed to execute a circuit on a given backend. There are two different modes for this mapping:</p> <ul> <li>Expression-level parameters: For AD-based optimization. For every unique expression we end   up with one entry in the embedded dict:   <code>len(embedded_dict) == len(unique_parameter_expressions)</code>.</li> <li>Gate-level parameters: For PSR-based optimization or real devices. One parameter for each   gate parameter, regardless if they are based on the same expression. <code>len(embedded_dict) ==   len(parametric_gates)</code>. This is needed because PSR requires to shift the angles of every   gate where the same parameter appears.</li> </ul> PARAMETER  DESCRIPTION <code>block</code> <p>parametrized block into which we want to embed parameters.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>to_gate_params</code> <p>A boolean flag whether to generate gate-level parameters or expression-level parameters.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>tuple[StrTensorDict, Callable[[StrTensorDict, StrTensorDict], StrTensorDict]]</code> <p>A tuple with variational parameter dict and the embedding function.</p> Source code in <code>qadence/blocks/embedding.py</code> <pre><code>def embedding(\nblock: AbstractBlock, to_gate_params: bool = False\n) -&gt; tuple[StrTensorDict, Callable[[StrTensorDict, StrTensorDict], StrTensorDict],]:\n\"\"\"Construct embedding function which maps user-facing parameters to either *expression-level*\n    parameters or *gate-level* parameters. The construced embedding function has the signature:\n         embedding_fn(params: StrTensorDict, inputs: StrTensorDict) -&gt; StrTensorDict:\n    which means that it maps the *variational* parameter dict `params` and the *feature* parameter\n    dict `inputs` to one new parameter dict `embedded_dict` which holds all parameters that are\n    needed to execute a circuit on a given backend. There are two different *modes* for this\n    mapping:\n    - *Expression-level* parameters: For AD-based optimization. For every unique expression we end\n      up with one entry in the embedded dict:\n      `len(embedded_dict) == len(unique_parameter_expressions)`.\n    - *Gate-level* parameters: For PSR-based optimization or real devices. One parameter for each\n      gate parameter, regardless if they are based on the same expression. `len(embedded_dict) ==\n      len(parametric_gates)`. This is needed because PSR requires to shift the angles of **every**\n      gate where the same parameter appears.\n    Arguments:\n        block: parametrized block into which we want to embed parameters.\n        to_gate_params: A boolean flag whether to generate gate-level parameters or\n            expression-level parameters.\n    Returns:\n        A tuple with variational parameter dict and the embedding function.\n    \"\"\"\nunique_expressions = unique(expressions(block))\nunique_symbols = [p for p in unique(parameters(block)) if not isinstance(p, sympy.Array)]\nunique_const_matrices = [e for e in unique_expressions if isinstance(e, sympy.Array)]\nunique_expressions = [e for e in unique_expressions if not isinstance(e, sympy.Array)]\n# NOTE\n# there are 3 kinds of parameters in qadence\n# - non-trainable which are considered as inputs for classical data\n# - trainable which are the variational parameters to be optimized\n# - fixed: which are non-trainable parameters with fixed value (e.g. pi/2)\n#\n# both non-trainable and trainable parameters can have the same element applied\n# to different operations in the quantum circuit, e.g. assigning the same parameter\n# to multiple gates.\nnon_numeric_symbols = [p for p in unique_symbols if not p.is_number]\ntrainable_symbols = [p for p in non_numeric_symbols if p.trainable]\nconstant_expressions = [expr for expr in unique_expressions if expr.is_number]\n# we dont need to care about constant symbols if they are contained in an symbolic expression\n# we only care about gate params which are ONLY a constant\nembeddings: dict[sympy.Expr, sympytorch.SymPyModule] = {\nexpr: torchify(expr) for expr in unique_expressions if not expr.is_number\n}\nuuid_to_expr = uuid_to_expression(block)\ndef embedding_fn(params: StrTensorDict, inputs: StrTensorDict) -&gt; StrTensorDict:\nembedded_params: dict[sympy.Expr, Tensor] = {}\nfor expr, fn in embeddings.items():\nangle: Tensor\nvalues = {}\nfor symbol in expr.free_symbols:\nif symbol.name in inputs:\nvalue = inputs[symbol.name]\nelif symbol.name in params:\nvalue = params[symbol.name]\nelse:\nmsg_trainable = \"Trainable\" if symbol.trainable else \"Non-trainable\"\nraise KeyError(\nf\"{msg_trainable} parameter '{symbol.name}' not found in the \"\nf\"inputs list: {list(inputs.keys())} nor the \"\nf\"params list: {list(params.keys())}.\"\n)\nvalues[symbol.name] = value\nangle = fn(**values)\n# do not reshape parameters which are multi-dimensional\n# tensors, such as for example generator matrices\nif not len(angle.squeeze().shape) &gt; 1:\nangle = angle.reshape(-1)\nembedded_params[expr] = angle\nfor e in constant_expressions + unique_const_matrices:\nembedded_params[e] = params[stringify(e)]\nif to_gate_params:\ngate_lvl_params: StrTensorDict = {}\nfor uuid, e in uuid_to_expr.items():\ngate_lvl_params[uuid] = embedded_params[e]\nreturn gate_lvl_params\nelse:\nreturn {stringify(k): v for k, v in embedded_params.items()}\nparams: StrTensorDict\nparams = {p.name: torch.tensor([p.value], requires_grad=True) for p in trainable_symbols}\nparams.update(\n{\nstringify(expr): torch.tensor([evaluate(expr)], requires_grad=False)\nfor expr in constant_expressions\n}\n)\nparams.update(\n{\nstringify(expr): torch.tensor(\nnp.array(expr.tolist(), dtype=np.cdouble), requires_grad=False\n)\nfor expr in unique_const_matrices\n}\n)\nreturn params, embedding_fn\n</code></pre>"},{"location":"qadence/quantumcircuit/","title":"QuantumCircuit","text":""},{"location":"qadence/quantumcircuit/#quantumcircuit","title":"QuantumCircuit","text":"<p>The abstract <code>QuantumCircuit</code> is the key object in Qadence, as it is what can be executed.</p>"},{"location":"qadence/quantumcircuit/#qadence.circuit.QuantumCircuit","title":"<code>QuantumCircuit(support, *blocks)</code>  <code>dataclass</code>","text":"<p>A QuantumCircuit instance is completely abstract and it needs to be passed to a quantum backend in order to be executed.</p> PARAMETER  DESCRIPTION <code>support</code> <p><code>Register</code> or number of qubits. If an integer is provided, a register is constructed with <code>Register.all_to_all(x)</code></p> <p> TYPE: <code>int | Register</code> </p> <code>*blocks</code> <p>(Possibly multiple) blocks to construct the circuit from.</p> <p> TYPE: <code>AbstractBlock</code> DEFAULT: <code>()</code> </p> Source code in <code>qadence/circuit.py</code> <pre><code>def __init__(self, support: int | Register, *blocks: AbstractBlock):\n\"\"\"\n    Arguments:\n        support: `Register` or number of qubits. If an integer is provided, a register is\n            constructed with `Register.all_to_all(x)`\n        *blocks: (Possibly multiple) blocks to construct the circuit from.\n    \"\"\"\nself.block = chain(*blocks) if len(blocks) != 1 else blocks[0]\nself.register = Register(support) if isinstance(support, int) else support\nglobal_block = isinstance(self.block, AnalogBlock) and self.block.qubit_support.is_global\nif not global_block and len(self.block) and self.block.n_qubits &gt; self.register.n_qubits:\nraise ValueError(\nf\"Register with {self.register.n_qubits} qubits is too small for the \"\nf\"given block with {self.block.n_qubits} qubits\"\n)\n</code></pre>"},{"location":"qadence/quantumcircuit/#qadence.circuit.QuantumCircuit.unique_parameters","title":"<code>unique_parameters: list[Parameter]</code>  <code>property</code>","text":"<p>Return the unique parameters in the circuit</p> <p>These parameters are the actual user-facing parameters which can be assigned by the user. Multiple gates can contain the same unique parameter</p> RETURNS DESCRIPTION <code>list[Parameter]</code> <p>list[Parameter]: List of unique parameters in the circuit</p>"},{"location":"qadence/quantumcircuit/#qadence.circuit.QuantumCircuit.get_blocks_by_tag","title":"<code>get_blocks_by_tag(tag)</code>","text":"<p>Extract one or more blocks using the human-readable tag</p> <p>This function recurservily explores all composite blocks to find all the occurrences of a certain tag in the blocks</p> PARAMETER  DESCRIPTION <code>tag</code> <p>the tag to look for</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>list[AbstractBlock]</code> <p>list[AbstractBlock]: The block(s) corresponding to the given tag</p> Source code in <code>qadence/circuit.py</code> <pre><code>def get_blocks_by_tag(self, tag: str) -&gt; list[AbstractBlock]:\n\"\"\"Extract one or more blocks using the human-readable tag\n    This function recurservily explores all composite blocks to find\n    all the occurrences of a certain tag in the blocks\n    Args:\n        tag (str): the tag to look for\n    Returns:\n        list[AbstractBlock]: The block(s) corresponding to the given tag\n    \"\"\"\ndef _get_block(block: AbstractBlock) -&gt; list[AbstractBlock]:\nblocks = []\nif block.tag == tag:\nblocks += [block]\nif isinstance(block, CompositeBlock):\nblocks += flatten(*[_get_block(b) for b in block.blocks])\nreturn blocks\nreturn _get_block(self.block)\n</code></pre>"},{"location":"qadence/quantumcircuit/#qadence.circuit.QuantumCircuit.parameters","title":"<code>parameters()</code>","text":"<p>Extract all parameters for primitive blocks in the circuit</p> <p>Notice that this function returns all the unique Parameters used in the quantum circuit. These can correspond to constants too.</p> RETURNS DESCRIPTION <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>List[tuple[Parameter]]: A list of tuples containing the Parameter</p> <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>instance of each of the primitive blocks in the circuit or, if the <code>flatten</code></p> <code>list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]</code> <p>flag is set to True, a flattened list of all circuit parameters</p> Source code in <code>qadence/circuit.py</code> <pre><code>def parameters(self) -&gt; list[Parameter | Basic] | list[tuple[Parameter | Basic, ...]]:\n\"\"\"Extract all parameters for primitive blocks in the circuit\n    Notice that this function returns all the unique Parameters used\n    in the quantum circuit. These can correspond to constants too.\n    Returns:\n        List[tuple[Parameter]]: A list of tuples containing the Parameter\n        instance of each of the primitive blocks in the circuit or, if the `flatten`\n        flag is set to True, a flattened list of all circuit parameters\n    \"\"\"\nreturn parameters(self.block)\n</code></pre>"},{"location":"qadence/register/","title":"Register","text":""},{"location":"qadence/register/#quantum-registers","title":"Quantum Registers","text":""},{"location":"qadence/register/#qadence.register.Register","title":"<code>Register(support)</code>","text":"<p>A 2D register of qubits which includes their coordinates (needed for e.g. analog computing). The coordinates are ignored in backends that don't need them. The easiest way to construct a register is via its classmethods like <code>Register.triangular_lattice</code>.</p> PARAMETER  DESCRIPTION <code>support</code> <p>A graph or number of qubits. Nodes can include a <code>\"pos\"</code> attribute such that e.g.: <code>graph.nodes = {0: {\"pos\": (2,3)}, 1: {\"pos\": (0,0)}, ...}</code> which will be used in backends that need qubit coordinates. See the classmethods for simple construction of some predefined lattices if you don't want to build a graph manually. If you pass an integer the resulting register is the same as <code>Register.all_to_all(n_qubits)</code>.</p> <p> TYPE: <code>Graph | int</code> </p> <p>Examples: <pre><code>from qadence import Register\nreg = Register.honeycomb_lattice(2,3)\nreg.draw()\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/register.py</code> <pre><code>def __init__(self, support: nx.Graph | int):\n\"\"\"A 2D register of qubits which includes their coordinates (needed for e.g. analog\n    computing). The coordinates are ignored in backends that don't need them. The easiest\n    way to construct a register is via its classmethods like `Register.triangular_lattice`.\n    Arguments:\n        support: A graph or number of qubits. Nodes can include a `\"pos\"` attribute\n            such that e.g.: `graph.nodes = {0: {\"pos\": (2,3)}, 1: {\"pos\": (0,0)}, ...}` which\n            will be used in backends that need qubit coordinates.\n            See the classmethods for simple construction of some predefined lattices if you\n            don't want to build a graph manually.\n            If you pass an integer the resulting register is the same as\n            `Register.all_to_all(n_qubits)`.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import Register\n    reg = Register.honeycomb_lattice(2,3)\n    reg.draw()\n    ```\n    \"\"\"\nself.graph = support if isinstance(support, nx.Graph) else alltoall_graph(support)\n</code></pre>"},{"location":"qadence/register/#qadence.register.line_graph","title":"<code>line_graph(n_qubits, spacing=1.0)</code>","text":"<p>Create graph representing linear lattice.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>number of nodes in the graph</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Graph</code> <p>graph instance</p> Source code in <code>qadence/register.py</code> <pre><code>def line_graph(n_qubits: int, spacing: float = 1.0) -&gt; nx.Graph:\n\"\"\"Create graph representing linear lattice.\n    Args:\n        n_qubits (int): number of nodes in the graph\n    Returns:\n        graph instance\n    \"\"\"\ngraph = nx.Graph()\nfor i in range(n_qubits):\ngraph.add_node(i, pos=(i * spacing, 0.0))\nfor i, j in zip(range(n_qubits - 1), range(1, n_qubits)):\ngraph.add_edge(i, j)\nreturn graph\n</code></pre>"},{"location":"qadence/serialization/","title":"Serialization","text":""},{"location":"qadence/serialization/#serialization","title":"Serialization","text":""},{"location":"qadence/serialization/#qadence.serialization.deserialize","title":"<code>deserialize(d, as_torch=False)</code>","text":"<p>Supported Types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | Module Deserializes a dict to one of the supported types.</p> PARAMETER  DESCRIPTION <code>d</code> <p>A dict containing a serialized object.</p> <p> TYPE: <code>dict</code> </p> <p>Returns:     AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register, Module.</p> <p>Examples: <pre><code>import torch\nfrom qadence import serialize, deserialize, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nblock_dict = serialize(myblock)\nprint(block_dict)\n## Lets use myblock in a QuantumCircuit and serialize it.\nqc = QuantumCircuit(n_qubits, myblock)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n## Finally, let's wrap it in a QuantumModel\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Lets check if the loaded QuantumModel returns the same expectation\nassert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n</code></pre> <pre><code>{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': 'HEA', 'blocks': [{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('c56d9d8a-8518-4f19-8636-605c01bba3bd', {'name': 'theta_0', 'expression': \"Parameter('theta_0')\", 'symbols': {'theta_0': {'name': 'theta_0', 'trainable': 'True', 'value': '0.9649102256983412'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('d9ee52bb-fc89-4ec3-96cc-f01afed1815c', {'name': 'theta_1', 'expression': \"Parameter('theta_1')\", 'symbols': {'theta_1': {'name': 'theta_1', 'trainable': 'True', 'value': '0.855299175233669'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RY', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('e768186a-1697-4d14-8792-fe07a0e4cd82', {'name': 'theta_2', 'expression': \"Parameter('theta_2')\", 'symbols': {'theta_2': {'name': 'theta_2', 'trainable': 'True', 'value': '0.4821242625372467'}}})}}}, {'type': 'RY', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('1c3700a8-af19-42bc-805d-88ee9725484a', {'name': 'theta_3', 'expression': \"Parameter('theta_3')\", 'symbols': {'theta_3': {'name': 'theta_3', 'trainable': 'True', 'value': '0.7216139771883192'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('db5d62a3-5b5c-4459-b57a-a47430768082', {'name': 'theta_4', 'expression': \"Parameter('theta_4')\", 'symbols': {'theta_4': {'name': 'theta_4', 'trainable': 'True', 'value': '0.5520005343296959'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('93e4239b-1dec-4381-bdb3-151154ac1dc0', {'name': 'theta_5', 'expression': \"Parameter('theta_5')\", 'symbols': {'theta_5': {'name': 'theta_5', 'trainable': 'True', 'value': '0.5128236248712018'}}})}}}]}]}, {'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'CNOT', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'X', 'qubit_support': (1,), 'tag': None}]}]}]}]}\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def deserialize(d: dict, as_torch: bool = False) -&gt; SUPPORTED_TYPES:\n\"\"\"\n    Supported Types:\n    AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | Module\n    Deserializes a dict to one of the supported types.\n    Arguments:\n        d (dict): A dict containing a serialized object.\n    Returns:\n        AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register, Module.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence import serialize, deserialize, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    block_dict = serialize(myblock)\n    print(block_dict)\n    ## Lets use myblock in a QuantumCircuit and serialize it.\n    qc = QuantumCircuit(n_qubits, myblock)\n    qc_dict = serialize(qc)\n    qc_deserialized = deserialize(qc_dict)\n    assert qc == qc_deserialized\n    ## Finally, let's wrap it in a QuantumModel\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    qm_dict = serialize(qm)\n    qm_deserialized = deserialize(qm_dict)\n    # Lets check if the loaded QuantumModel returns the same expectation\n    assert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n    ```\n    \"\"\"\nobj: Any\nif d.get(\"expression\"):\nexpr = eval(d[\"expression\"])\nif hasattr(expr, \"free_symbols\"):\nfor symb in expr.free_symbols:\nsymb.value = float(d[\"symbols\"][symb.name][\"value\"])\nobj = expr\nelif d.get(\"QuantumModel\"):\nobj = QuantumModel._from_dict(d, as_torch)\nelif d.get(\"QNN\"):\nobj = QNN._from_dict(d, as_torch)\nelif d.get(\"TransformedModule\"):\nobj = TransformedModule._from_dict(d, as_torch)\nelif d.get(\"block\") and d.get(\"register\"):\nobj = QuantumCircuit._from_dict(d)\nelif d.get(\"graph\"):\nobj = Register._from_dict(d)\nelif d.get(\"type\"):\nif d[\"type\"] in ALL_BLOCK_NAMES:\nblock: AbstractBlock = (\ngetattr(operations, d[\"type\"])._from_dict(d)\nif hasattr(operations, d[\"type\"])\nelse getattr(qadenceblocks, d[\"type\"])._from_dict(d)\n)\nif d[\"tag\"] is not None:\nblock = tag(block, d[\"tag\"])\nobj = block\nelse:\nimport warnings\nmsg = warnings.warn(\n\"In order to load a custom torch.nn.Module, make sure its imported in the namespace.\"\n)\ntry:\nmodule_name = list(d.keys())[0]\nobj = getattr(globals(), module_name)\nobj.load_state_dict(d[module_name])\nexcept Exception as e:\nlogger.error(\nTypeError(\nf\"{msg}. Unable to deserialize object due to {e}.\\\n                    Supported objects are: {SUPPORTED_OBJECTS}\"\n)\n)\nreturn obj\n</code></pre>"},{"location":"qadence/serialization/#qadence.serialization.load","title":"<code>load(file_path, map_location='cpu')</code>","text":"<p>Same as serialize/deserialize but for storing/loading files. Supported types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register Loads a .json or .pt file to one of the supported types.</p> PARAMETER  DESCRIPTION <code>file_path</code> <p>The name of the file.</p> <p> TYPE: <code>str</code> </p> <code>map_location</code> <p>In case of a .pt file, on which device to load the object (cpu,cuda).</p> <p> TYPE: <code>str</code> DEFAULT: <code>'cpu'</code> </p> <p>Returns:     A object of type AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register.</p> <p>Examples: <pre><code>import torch\nfrom pathlib import Path\nimport os\nfrom qadence import save, load, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nqc = QuantumCircuit(n_qubits, myblock)\n# Lets store the circuit in a json file\nsave(qc, '.', 'circ')\nloaded_qc = load(Path('circ.json'))\nqc == loaded_qc\nos.remove('circ.json')\n## Let's wrap it in a QuantumModel and store that\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nsave(qm, folder= '.',file_name= 'quantum_model')\nqm_loaded = load('quantum_model.json')\nos.remove('quantum_model.json')\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def load(file_path: str | Path, map_location: str = \"cpu\") -&gt; SUPPORTED_TYPES:\n\"\"\"\n    Same as serialize/deserialize but for storing/loading files.\n    Supported types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register\n    Loads a .json or .pt file to one of the supported types.\n    Arguments:\n        file_path (str): The name of the file.\n        map_location (str): In case of a .pt file, on which device to load the object (cpu,cuda).\n    Returns:\n        A object of type AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from pathlib import Path\n    import os\n    from qadence import save, load, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    qc = QuantumCircuit(n_qubits, myblock)\n    # Lets store the circuit in a json file\n    save(qc, '.', 'circ')\n    loaded_qc = load(Path('circ.json'))\n    qc == loaded_qc\n    os.remove('circ.json')\n    ## Let's wrap it in a QuantumModel and store that\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    save(qm, folder= '.',file_name= 'quantum_model')\n    qm_loaded = load('quantum_model.json')\n    os.remove('quantum_model.json')\n    ```\n    \"\"\"\nd = {}\nif isinstance(file_path, str):\nfile_path = Path(file_path)\nif not os.path.exists(file_path):\nlogger.error(f\"File {file_path} not found.\")\nraise FileNotFoundError\nFORMAT = file_extension(file_path)\n_, _, load_fn, _ = FORMAT_DICT[FORMAT]  # type: ignore[index]\ntry:\nd = load_fn(file_path, map_location)\nlogger.debug(f\"Successfully loaded {d} from {file_path}.\")\nexcept Exception as e:\nlogger.error(f\"Unable to load Object from {file_path} due to {e}\")\nreturn deserialize(d)\n</code></pre>"},{"location":"qadence/serialization/#qadence.serialization.save","title":"<code>save(obj, folder, file_name='', format=SerializationFormat.JSON)</code>","text":"<p>Same as serialize/deserialize but for storing/loading files. Supported types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | torch.nn.Module Saves a qadence object to a json/.pt.</p> PARAMETER  DESCRIPTION <code>obj</code> <pre><code>Either AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register.\n</code></pre> <p> TYPE: <code>AbstractBlock | QuantumCircuit | QuantumModel | Register</code> </p> <code>file_name</code> <p>The name of the file.</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>format</code> <p>The type of file to save.</p> <p> TYPE: <code>str</code> DEFAULT: <code>JSON</code> </p> <p>Returns:     None.</p> <p>Examples: <pre><code>import torch\nfrom pathlib import Path\nimport os\nfrom qadence import save, load, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nqc = QuantumCircuit(n_qubits, myblock)\n# Lets store the circuit in a json file\nsave(qc, '.', 'circ')\nloaded_qc = load(Path('circ.json'))\nqc == loaded_qc\nos.remove('circ.json')\n## Let's wrap it in a QuantumModel and store that\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nsave(qm, folder= '.',file_name= 'quantum_model')\nqm_loaded = load('quantum_model.json')\nos.remove('quantum_model.json')\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def save(\nobj: SUPPORTED_TYPES,\nfolder: str | Path,\nfile_name: str = \"\",\nformat: SerializationFormat = SerializationFormat.JSON,\n) -&gt; None:\n\"\"\"\n    Same as serialize/deserialize but for storing/loading files.\n    Supported types:\n    AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | torch.nn.Module\n    Saves a qadence object to a json/.pt.\n    Arguments:\n        obj (AbstractBlock | QuantumCircuit | QuantumModel | Register):\n                Either AbstractBlock, QuantumCircuit, QuantumModel, TransformedModule, Register.\n        file_name (str): The name of the file.\n        format (str): The type of file to save.\n    Returns:\n        None.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from pathlib import Path\n    import os\n    from qadence import save, load, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    qc = QuantumCircuit(n_qubits, myblock)\n    # Lets store the circuit in a json file\n    save(qc, '.', 'circ')\n    loaded_qc = load(Path('circ.json'))\n    qc == loaded_qc\n    os.remove('circ.json')\n    ## Let's wrap it in a QuantumModel and store that\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    save(qm, folder= '.',file_name= 'quantum_model')\n    qm_loaded = load('quantum_model.json')\n    os.remove('quantum_model.json')\n    ```\n    \"\"\"\nif not isinstance(obj, get_args(SUPPORTED_TYPES)):\nlogger.error(f\"Serialization of object type {type(obj)} not supported.\")\nfolder = Path(folder)\nif not folder.is_dir():\nlogger.error(NotADirectoryError)\nif file_name == \"\":\nfile_name = type(obj).__name__\ntry:\nsuffix, save_fn, _, save_params = FORMAT_DICT[format]\nd = serialize(obj, save_params)\nfile_path = folder / Path(file_name + suffix)\nsave_fn(d, file_path)\nlogger.debug(f\"Successfully saved {obj} from to {folder}.\")\nexcept Exception as e:\nlogger.error(f\"Unable to write {type(obj)} to disk due to {e}\")\n</code></pre>"},{"location":"qadence/serialization/#qadence.serialization.serialize","title":"<code>serialize(obj, save_params=False)</code>","text":"<p>Supported Types: AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | Module Serializes a qadence object to a dictionary.</p> PARAMETER  DESCRIPTION <code>obj</code> <p> TYPE: <code>AbstractBlock | QuantumCircuit | QuantumModel | Register | Module</code> </p> <p>Returns:     A dict.</p> <p>Examples: <pre><code>import torch\nfrom qadence import serialize, deserialize, hea, hamiltonian_factory, Z\nfrom qadence import QuantumCircuit, QuantumModel\nn_qubits = 2\nmyblock = hea(n_qubits=n_qubits, depth=1)\nblock_dict = serialize(myblock)\nprint(block_dict)\n## Lets use myblock in a QuantumCircuit and serialize it.\nqc = QuantumCircuit(n_qubits, myblock)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n## Finally, let's wrap it in a QuantumModel\nobs = hamiltonian_factory(n_qubits, detuning = Z)\nqm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Lets check if the loaded QuantumModel returns the same expectation\nassert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n</code></pre> <pre><code>{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': 'HEA', 'blocks': [{'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('a41d1844-cddd-4763-b417-a33246d161c7', {'name': 'theta_0', 'expression': \"Parameter('theta_0')\", 'symbols': {'theta_0': {'name': 'theta_0', 'trainable': 'True', 'value': '0.7262773469971591'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('494bedcb-ade3-4c45-8e10-beb9cd3838e8', {'name': 'theta_1', 'expression': \"Parameter('theta_1')\", 'symbols': {'theta_1': {'name': 'theta_1', 'trainable': 'True', 'value': '0.9592730319839947'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RY', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('50278fa2-02f4-49c4-8221-fbd3e3fe880b', {'name': 'theta_2', 'expression': \"Parameter('theta_2')\", 'symbols': {'theta_2': {'name': 'theta_2', 'trainable': 'True', 'value': '0.29853362350562773'}}})}}}, {'type': 'RY', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('afe9175c-ca22-4a18-8630-eb6927b746b6', {'name': 'theta_3', 'expression': \"Parameter('theta_3')\", 'symbols': {'theta_3': {'name': 'theta_3', 'trainable': 'True', 'value': '0.8358036266838368'}}})}}}]}, {'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'RX', 'qubit_support': (0,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('05eb907a-e56c-44c8-989c-ebfc9295c5df', {'name': 'theta_4', 'expression': \"Parameter('theta_4')\", 'symbols': {'theta_4': {'name': 'theta_4', 'trainable': 'True', 'value': '0.5395678859265043'}}})}}}, {'type': 'RX', 'qubit_support': (1,), 'tag': None, 'parameters': {'_name_dict': {'parameter': ('f1400dd6-0e5b-47cf-96d1-78adcdc7ee85', {'name': 'theta_5', 'expression': \"Parameter('theta_5')\", 'symbols': {'theta_5': {'name': 'theta_5', 'trainable': 'True', 'value': '0.3978401946895035'}}})}}}]}]}, {'type': 'ChainBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'KronBlock', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'CNOT', 'qubit_support': (0, 1), 'tag': None, 'blocks': [{'type': 'X', 'qubit_support': (1,), 'tag': None}]}]}]}]}\n</code></pre> </p> Source code in <code>qadence/serialization.py</code> <pre><code>def serialize(obj: SUPPORTED_TYPES, save_params: bool = False) -&gt; dict:\n\"\"\"\n    Supported Types:\n    AbstractBlock | QuantumCircuit | QuantumModel | TransformedModule | Register | Module\n    Serializes a qadence object to a dictionary.\n    Arguments:\n        obj (AbstractBlock | QuantumCircuit | QuantumModel | Register | Module):\n    Returns:\n        A dict.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    import torch\n    from qadence import serialize, deserialize, hea, hamiltonian_factory, Z\n    from qadence import QuantumCircuit, QuantumModel\n    n_qubits = 2\n    myblock = hea(n_qubits=n_qubits, depth=1)\n    block_dict = serialize(myblock)\n    print(block_dict)\n    ## Lets use myblock in a QuantumCircuit and serialize it.\n    qc = QuantumCircuit(n_qubits, myblock)\n    qc_dict = serialize(qc)\n    qc_deserialized = deserialize(qc_dict)\n    assert qc == qc_deserialized\n    ## Finally, let's wrap it in a QuantumModel\n    obs = hamiltonian_factory(n_qubits, detuning = Z)\n    qm = QuantumModel(qc, obs, backend='pyqtorch', diff_mode='ad')\n    qm_dict = serialize(qm)\n    qm_deserialized = deserialize(qm_dict)\n    # Lets check if the loaded QuantumModel returns the same expectation\n    assert torch.isclose(qm.expectation({}), qm_deserialized.expectation({}))\n    ```\n    \"\"\"\nif not isinstance(obj, get_args(SUPPORTED_TYPES)):\nlogger.error(TypeError(f\"Serialization of object type {type(obj)} not supported.\"))\nd: dict = {}\ntry:\nif isinstance(obj, Expr):\nsymb_dict = {}\nexpr_dict = {\"name\": str(obj), \"expression\": srepr(obj)}\nsymbs: set[Parameter | Basic] = obj.free_symbols\nif symbs:\nsymb_dict = {\"symbols\": {str(s): s._to_dict() for s in symbs}}\nd = {**expr_dict, **symb_dict}\nelif isinstance(obj, (QuantumModel, QNN, TransformedModule)):\nd = obj._to_dict(save_params)\nelif isinstance(obj, torch.nn.Module):\nd = {type(obj).__name__: obj.state_dict()}\nelse:\nd = obj._to_dict()\nexcept Exception as e:\nlogger.error(f\"Serialization of object {obj} failed due to {e}\")\nreturn d\n</code></pre>"},{"location":"qadence/states/","title":"State preparation","text":""},{"location":"qadence/states/#state-preparation-routines","title":"State Preparation Routines","text":""},{"location":"qadence/states/#qadence.states.ghz_block","title":"<code>ghz_block(n_qubits)</code>","text":"<p>Generates the abstract ghz state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ChainBlock</code> <p>A ChainBlock representing the GHZ state.</p> <p>Examples: <pre><code>from qadence.states import ghz_block\nblock = ghz_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 ChainBlock(0,1)\n\u2514\u2500\u2500 CNOT(0,1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def ghz_block(n_qubits: int) -&gt; ChainBlock:\n\"\"\"\n    Generates the abstract ghz state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A ChainBlock representing the GHZ state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import ghz_block\n    block = ghz_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\ncnots = chain(CNOT(i - 1, i) for i in range(1, n_qubits))\nreturn chain(H(0), cnots)\n</code></pre>"},{"location":"qadence/states/#qadence.states.ghz_state","title":"<code>ghz_state(n_qubits, batch_size=1)</code>","text":"<p>Creates a GHZ state.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>How many bitstrings to use.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import ghz_state\nprint(ghz_state(n_qubits=2, batch_size=2))\n</code></pre> <pre><code>tensor([[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j],\n[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.7071+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def ghz_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Creates a GHZ state.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): How many bitstrings to use.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import ghz_state\n    print(ghz_state(n_qubits=2, batch_size=2))\n    ```\n    \"\"\"\nnorm = 1 / torch.sqrt(torch.tensor(2))\nreturn norm * (zero_state(n_qubits, batch_size) + one_state(n_qubits, batch_size))\n</code></pre>"},{"location":"qadence/states/#qadence.states.is_normalized","title":"<code>is_normalized(wf, atol=NORMALIZATION_ATOL)</code>","text":"<p>Checks if a wave function is normalized.</p> PARAMETER  DESCRIPTION <code>wf</code> <p>The wave function as a torch tensor.</p> <p> TYPE: <code>Tensor</code> </p> <code>atol</code> <p>The tolerance.</p> <p> TYPE: <code>float) </code> DEFAULT: <code>NORMALIZATION_ATOL</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>A bool.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, is_normalized\nprint(is_normalized(uniform_state(2)))\n</code></pre> <pre><code>True\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def is_normalized(wf: Tensor, atol: float = NORMALIZATION_ATOL) -&gt; bool:\n\"\"\"\n    Checks if a wave function is normalized.\n    Arguments:\n        wf (torch.Tensor): The wave function as a torch tensor.\n        atol (float) : The tolerance.\n    Returns:\n        A bool.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, is_normalized\n    print(is_normalized(uniform_state(2)))\n    ```\n    \"\"\"\nif wf.dim() == 1:\nwf = wf.unsqueeze(0)\nsum_probs: Tensor = (wf.abs() ** 2).sum(dim=1)\nones = torch.ones_like(sum_probs)\nreturn torch.allclose(sum_probs, ones, rtol=0.0, atol=atol)  # type: ignore[no-any-return]\n</code></pre>"},{"location":"qadence/states/#qadence.states.normalize","title":"<code>normalize(wf)</code>","text":"<p>Normalizes a wavefunction or batch of wave functions.</p> PARAMETER  DESCRIPTION <code>wf</code> <p>Normalized wavefunctions.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, normalize\nprint(normalize(uniform_state(2, 2)))\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j],\n[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def normalize(wf: Tensor) -&gt; Tensor:\n\"\"\"\n    Normalizes a wavefunction or batch of wave functions.\n    Arguments:\n        wf (torch.Tensor): Normalized wavefunctions.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, normalize\n    print(normalize(uniform_state(2, 2)))\n    ```\n    \"\"\"\nif wf.dim() == 1:\nreturn wf / torch.sqrt((wf.abs() ** 2).sum())\nelse:\nreturn wf / torch.sqrt((wf.abs() ** 2).sum(1)).unsqueeze(1)\n</code></pre>"},{"location":"qadence/states/#qadence.states.one_block","title":"<code>one_block(n_qubits)</code>","text":"<p>Generates the abstract one state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the one state.</p> <p>Examples: <pre><code>from qadence.states import one_block\nblock = one_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def one_block(n_qubits: int) -&gt; KronBlock:\n\"\"\"\n    Generates the abstract one state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A KronBlock representing the one state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import one_block\n    block = one_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\nreturn _from_op(X, n_qubits=n_qubits)\n</code></pre>"},{"location":"qadence/states/#qadence.states.one_state","title":"<code>one_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the one state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import one_state\nstate = one_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def one_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Generates the one state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): The batch size.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import one_state\n    state = one_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\nbitstring = \"1\" * n_qubits\nreturn _state_from_bitstring(bitstring, batch_size)\n</code></pre>"},{"location":"qadence/states/#qadence.states.pmf","title":"<code>pmf(wf)</code>","text":"<p>Converts a wave function into a torch Distribution.</p> PARAMETER  DESCRIPTION <code>wf</code> <p>The wave function as a torch tensor.</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>Distribution</code> <p>A torch.distributions.Distribution.</p> <p>Examples: <pre><code>from qadence.states import uniform_state, pmf\nprint(pmf(uniform_state(2)).probs)\n</code></pre> <pre><code>tensor([[0.2500, 0.2500, 0.2500, 0.2500]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def pmf(wf: Tensor) -&gt; Distribution:\n\"\"\"\n    Converts a wave function into a torch Distribution.\n    Arguments:\n        wf (torch.Tensor): The wave function as a torch tensor.\n    Returns:\n        A torch.distributions.Distribution.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state, pmf\n    print(pmf(uniform_state(2)).probs)\n    ```\n    \"\"\"\nreturn Categorical(torch.abs(torch.pow(wf, 2)))\n</code></pre>"},{"location":"qadence/states/#qadence.states.product_block","title":"<code>product_block(bitstring)</code>","text":"<p>Creates an abstract product state from a bitstring.</p> PARAMETER  DESCRIPTION <code>bitstring</code> <p>A bitstring.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the product state.</p> <p>Examples: <pre><code>from qadence.states import product_block\nprint(product_block(\"1100\"))\n</code></pre> <pre><code>KronBlock(0,1,2,3)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u251c\u2500\u2500 I(2)\n\u2514\u2500\u2500 I(3)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def product_block(bitstring: str) -&gt; KronBlock:\n\"\"\"\n    Creates an abstract product state from a bitstring.\n    Arguments:\n        bitstring (str): A bitstring.\n    Returns:\n        A KronBlock representing the product state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import product_block\n    print(product_block(\"1100\"))\n    ```\n    \"\"\"\nreturn _block_from_bitstring(bitstring)\n</code></pre>"},{"location":"qadence/states/#qadence.states.product_state","title":"<code>product_state(bitstring, batch_size=1, endianness=Endianness.BIG)</code>","text":"<p>Creates a product state from a bitstring.</p> PARAMETER  DESCRIPTION <code>bitstring</code> <p>A bitstring.</p> <p> TYPE: <code>str</code> </p> <code>batch_size</code> <p>Batch size.</p> <p> TYPE: <code>int) </code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import product_state\nprint(product_state(\"1100\"))\n</code></pre> <pre><code>tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>@singledispatch\ndef product_state(\nbitstring: str, batch_size: int = 1, endianness: Endianness = Endianness.BIG\n) -&gt; Tensor:\n\"\"\"\n    Creates a product state from a bitstring.\n    Arguments:\n        bitstring (str): A bitstring.\n        batch_size (int) : Batch size.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import product_state\n    print(product_state(\"1100\"))\n    ```\n    \"\"\"\nreturn _state_from_bitstring(bitstring, batch_size, endianness=endianness)\n</code></pre>"},{"location":"qadence/states/#qadence.states.rand_bitstring","title":"<code>rand_bitstring(N)</code>","text":"<p>Creates a random bistring.</p> PARAMETER  DESCRIPTION <code>N</code> <p>The length of the bitstring.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>str</code> <p>A string.</p> <p>Examples: <pre><code>from qadence.states import rand_bitstring\nprint(rand_bitstring(N=8))\n</code></pre> <pre><code>01111111\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_bitstring(N: int) -&gt; str:\n\"\"\"\n    Creates a random bistring.\n    Arguments:\n        N (int): The length of the bitstring.\n    Returns:\n        A string.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_bitstring\n    print(rand_bitstring(N=8))\n    ```\n    \"\"\"\nreturn \"\".join(str(random.randint(0, 1)) for _ in range(N))\n</code></pre>"},{"location":"qadence/states/#qadence.states.rand_product_block","title":"<code>rand_product_block(n_qubits)</code>","text":"<p>Creates a block representing a random abstract product state.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the product state.</p> <p>Examples: <pre><code>from qadence.states import rand_product_block\nprint(rand_product_block(n_qubits=2))\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 I(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_product_block(n_qubits: int) -&gt; KronBlock:\n\"\"\"\n    Creates a block representing a random abstract product state.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A KronBlock representing the product state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_product_block\n    print(rand_product_block(n_qubits=2))\n    ```\n    \"\"\"\nreturn product_block(rand_bitstring(n_qubits))\n</code></pre>"},{"location":"qadence/states/#qadence.states.rand_product_state","title":"<code>rand_product_state(n_qubits, batch_size=1)</code>","text":"<p>Creates a random product state.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>How many bitstrings to use.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import rand_product_state\nprint(rand_product_state(n_qubits=2, batch_size=2))\n</code></pre> <pre><code>tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def rand_product_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Creates a random product state.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): How many bitstrings to use.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import rand_product_state\n    print(rand_product_state(n_qubits=2, batch_size=2))\n    ```\n    \"\"\"\nwf_batch = torch.zeros(batch_size, 2**n_qubits, dtype=DTYPE)\nrand_pos = torch.randint(0, 2**n_qubits, (batch_size,))\nwf_batch[torch.arange(batch_size), rand_pos] = torch.tensor(1.0 + 0j, dtype=DTYPE)\nreturn wf_batch\n</code></pre>"},{"location":"qadence/states/#qadence.states.random_state","title":"<code>random_state(n_qubits, batch_size=1, backend=BackendName.PYQTORCH, type=StateGeneratorType.HAAR_MEASURE_FAST)</code>","text":"<p>Generates a random state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>backend</code> <p>The backend to use.</p> <p> TYPE: <code>str</code> DEFAULT: <code>PYQTORCH</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>type</code> <p>StateGeneratorType.</p> <p> DEFAULT: <code>HAAR_MEASURE_FAST</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import random_state, StateGeneratorType\nfrom qadence.states import random_state, is_normalized, pmf\nfrom qadence.backend import BackendName\nfrom torch.distributions import Distribution\n### We have the following options:\nprint([g.value for g in StateGeneratorType])\nn_qubits = 2\n# The default is StateGeneratorType.HAAR_MEASURE_FAST\nstate = random_state(n_qubits=n_qubits)\nprint(state)\n### Lets initialize a state using random rotations, i.e., StateGeneratorType.RANDOM_ROTATIONS.\nrandom = random_state(n_qubits=n_qubits, type=StateGeneratorType.RANDOM_ROTATIONS)\nprint(random)\n</code></pre> <pre><code>['RandomRotations', 'HaarMeasureFast', 'HaarMeasureSlow']\ntensor([[0.3686-0.0605j, 0.2386+0.1186j, 0.0478+0.7804j, 0.0436-0.4199j]])\ntensor([[ 0.9923+0.0887j, -0.0077+0.0861j,  0.0000+0.0000j,  0.0000+0.0000j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def random_state(\nn_qubits: int,\nbatch_size: int = 1,\nbackend: str = BackendName.PYQTORCH,\ntype: StateGeneratorType = StateGeneratorType.HAAR_MEASURE_FAST,\n) -&gt; Tensor:\n\"\"\"\n    Generates a random state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        backend (str): The backend to use.\n        batch_size (int): The batch size.\n        type : StateGeneratorType.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import random_state, StateGeneratorType\n    from qadence.states import random_state, is_normalized, pmf\n    from qadence.backend import BackendName\n    from torch.distributions import Distribution\n    ### We have the following options:\n    print([g.value for g in StateGeneratorType])\n    n_qubits = 2\n    # The default is StateGeneratorType.HAAR_MEASURE_FAST\n    state = random_state(n_qubits=n_qubits)\n    print(state)\n    ### Lets initialize a state using random rotations, i.e., StateGeneratorType.RANDOM_ROTATIONS.\n    random = random_state(n_qubits=n_qubits, type=StateGeneratorType.RANDOM_ROTATIONS)\n    print(random)\n    ```\n    \"\"\"\nif type == StateGeneratorType.HAAR_MEASURE_FAST:\nstate = concat(tuple(_rand_haar_fast(n_qubits) for _ in range(batch_size)), dim=0)\nelif type == StateGeneratorType.HAAR_MEASURE_SLOW:\nstate = concat(tuple(_rand_haar_slow(n_qubits) for _ in range(batch_size)), dim=0)\nelif type == StateGeneratorType.RANDOM_ROTATIONS:\nstate = _run_state(_abstract_random_state(n_qubits, batch_size), backend)  # type: ignore\nassert all(list(map(is_normalized, state)))\nreturn state\n</code></pre>"},{"location":"qadence/states/#qadence.states.uniform_block","title":"<code>uniform_block(n_qubits)</code>","text":"<p>Generates the abstract uniform state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the uniform state.</p> <p>Examples: <pre><code>from qadence.states import uniform_block\nblock = uniform_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 H(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def uniform_block(n_qubits: int) -&gt; KronBlock:\n\"\"\"\n    Generates the abstract uniform state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A KronBlock representing the uniform state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_block\n    block = uniform_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\nreturn _from_op(H, n_qubits=n_qubits)\n</code></pre>"},{"location":"qadence/states/#qadence.states.uniform_state","title":"<code>uniform_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the uniform state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import uniform_state\nstate = uniform_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def uniform_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Generates the uniform state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n        batch_size (int): The batch size.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import uniform_state\n    state = uniform_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\nnorm = 1 / torch.sqrt(torch.tensor(2**n_qubits))\nreturn norm * torch.ones(batch_size, 2**n_qubits, dtype=DTYPE)\n</code></pre>"},{"location":"qadence/states/#qadence.states.zero_block","title":"<code>zero_block(n_qubits)</code>","text":"<p>Generates the abstract zero state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>KronBlock</code> <p>A KronBlock representing the zero state.</p> <p>Examples: <pre><code>from qadence.states import zero_block\nblock = zero_block(n_qubits=2)\nprint(block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 I(0)\n\u2514\u2500\u2500 I(1)\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def zero_block(n_qubits: int) -&gt; KronBlock:\n\"\"\"\n    Generates the abstract zero state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits.\n    Returns:\n        A KronBlock representing the zero state.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import zero_block\n    block = zero_block(n_qubits=2)\n    print(block)\n    ```\n    \"\"\"\nreturn _from_op(I, n_qubits=n_qubits)\n</code></pre>"},{"location":"qadence/states/#qadence.states.zero_state","title":"<code>zero_state(n_qubits, batch_size=1)</code>","text":"<p>Generates the zero state for a specified number of qubits.</p> PARAMETER  DESCRIPTION <code>n_qubits</code> <p>The number of qubits for which the zero state is to be generated.</p> <p> TYPE: <code>int</code> </p> <code>batch_size</code> <p>The batch size for the zero state.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>A torch.Tensor.</p> <p>Examples: <pre><code>from qadence.states import zero_state\nstate = zero_state(n_qubits=2)\nprint(state)\n</code></pre> <pre><code>tensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> </p> Source code in <code>qadence/states.py</code> <pre><code>def zero_state(n_qubits: int, batch_size: int = 1) -&gt; Tensor:\n\"\"\"\n    Generates the zero state for a specified number of qubits.\n    Arguments:\n        n_qubits (int): The number of qubits for which the zero state is to be generated.\n        batch_size (int): The batch size for the zero state.\n    Returns:\n        A torch.Tensor.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence.states import zero_state\n    state = zero_state(n_qubits=2)\n    print(state)\n    ```\n    \"\"\"\nbitstring = \"0\" * n_qubits\nreturn _state_from_bitstring(bitstring, batch_size)\n</code></pre>"},{"location":"qadence/transpile/","title":"Transpilation","text":"<p>Contains functions that operate on blocks and circuits to <code>transpile</code> them to new blocks/circuits.</p>"},{"location":"qadence/transpile/#qadence.transpile.transpile.transpile","title":"<code>transpile(*fs)</code>","text":"<p><code>AbstractBlock</code> or <code>QuantumCircuit</code> transpilation. Compose functions that accept a circuit/block and returns a circuit/block.</p> PARAMETER  DESCRIPTION <code>*fs</code> <p>composable functions that either map blocks to blocks (<code>Callable[[AbstractBlock], AbstractBlock]</code>) or circuits to circuits (<code>Callable[[QuantumCircuit], QuantumCircuit]</code>).</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>()</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>Composed function.</p> <p>Examples:</p> <p>Flatten a block of nested chains and krons: <pre><code>from qadence import *\nfrom qadence.transpile import transpile, flatten, scale_primitive_blocks_only\nb = chain(2 * chain(chain(X(0), Y(0))), kron(kron(X(0), X(1))))\nprint(b)\n# both flatten and scale_primitive_blocks_only are functions that accept and\n# return a block\nt = transpile(flatten, scale_primitive_blocks_only)(b)\nprint(t)\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 [mul: 2] \u2502   \u2514\u2500\u2500 ChainBlock(0)\n\u2502       \u2514\u2500\u2500 ChainBlock(0)\n\u2502           \u251c\u2500\u2500 X(0)\n\u2502           \u2514\u2500\u2500 Y(0)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\nChainBlock(0,1)\n\u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2514\u2500\u2500 X(0)\n\u251c\u2500\u2500 Y(0)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> <p>We also proved a decorator to easily turn a function <code>Callable[[AbstractBlock], AbstractBlock]</code> into a <code>Callable[[QuantumCircuit], QuantumCircuit]</code> to be used in circuit transpilation. <pre><code>from qadence import *\nfrom qadence.transpile import transpile, blockfn_to_circfn, flatten\n# We want to pass this circuit to `transpile` instead of a block,\n# so we need functions that map from a circuit to a circuit.\ncirc = QuantumCircuit(2, chain(chain(X(0), chain(X(1)))))\n@blockfn_to_circfn\ndef fn(block):\n# un-decorated function accepts a block and returns a block\nreturn block * block\ntransp = transpile(\n# the decorated function accepts a circuit and returns a circuit\nfn,\n# already existing functions can also be decorated\nblockfn_to_circfn(flatten)\n)\nprint(transp(circ))\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 X(0)\n\u2502   \u2514\u2500\u2500 X(1)\n\u2514\u2500\u2500 ChainBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 X(1)\n</code></pre> </p> Source code in <code>qadence/transpile/transpile.py</code> <pre><code>def transpile(*fs: Callable) -&gt; Callable:\n\"\"\"`AbstractBlock` or `QuantumCircuit` transpilation. Compose functions that\n    accept a circuit/block and returns a circuit/block.\n    Arguments:\n        *fs: composable functions that either map blocks to blocks\n            (`Callable[[AbstractBlock], AbstractBlock]`)\n            or circuits to circuits (`Callable[[QuantumCircuit], QuantumCircuit]`).\n    Returns:\n        Composed function.\n    Examples:\n    Flatten a block of nested chains and krons:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import *\n    from qadence.transpile import transpile, flatten, scale_primitive_blocks_only\n    b = chain(2 * chain(chain(X(0), Y(0))), kron(kron(X(0), X(1))))\n    print(b)\n    print() # markdown-exec: hide\n    # both flatten and scale_primitive_blocks_only are functions that accept and\n    # return a block\n    t = transpile(flatten, scale_primitive_blocks_only)(b)\n    print(t)\n    ```\n    We also proved a decorator to easily turn a function `Callable[[AbstractBlock], AbstractBlock]`\n    into a `Callable[[QuantumCircuit], QuantumCircuit]` to be used in circuit transpilation.\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import *\n    from qadence.transpile import transpile, blockfn_to_circfn, flatten\n    # We want to pass this circuit to `transpile` instead of a block,\n    # so we need functions that map from a circuit to a circuit.\n    circ = QuantumCircuit(2, chain(chain(X(0), chain(X(1)))))\n    @blockfn_to_circfn\n    def fn(block):\n        # un-decorated function accepts a block and returns a block\n        return block * block\n    transp = transpile(\n        # the decorated function accepts a circuit and returns a circuit\n        fn,\n        # already existing functions can also be decorated\n        blockfn_to_circfn(flatten)\n    )\n    print(transp(circ))\n    ```\n    \"\"\"\nreturn lambda x: reduce(lambda acc, f: f(acc), reversed(fs), x)\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.chain_single_qubit_ops","title":"<code>chain_single_qubit_ops(block)</code>","text":"<p>Transpile a chain of krons into a kron of chains of single qubit operations.</p> <p>Examples: <pre><code>from qadence import hea\nfrom qadence.transpile.block import chain_single_qubit_ops\n# Consider a single HEA layer\nblock = hea(2,1)\nprint(block)\n# After applying chain_single_qubit_ops, we get:\nprint(chain_single_qubit_ops(block))\n</code></pre> <pre><code>ChainBlock(0,1) [tag: HEA]\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502   \u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_2']]\n\u2502   \u2502   \u2514\u2500\u2500 RY(1) [params: ['theta_3']]\n\u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 RX(0) [params: ['theta_4']]\n\u2502       \u2514\u2500\u2500 RX(1) [params: ['theta_5']]\n\u2514\u2500\u2500 ChainBlock(0,1)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u2514\u2500\u2500 CNOT(0,1)\nChainBlock(0,1)\n\u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u251c\u2500\u2500 ChainBlock(0)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_2']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(0) [params: ['theta_4']]\n\u2502   \u2514\u2500\u2500 ChainBlock(1)\n\u2502       \u251c\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502       \u251c\u2500\u2500 RY(1) [params: ['theta_3']]\n\u2502       \u2514\u2500\u2500 RX(1) [params: ['theta_5']]\n\u2514\u2500\u2500 ChainBlock(0,1)\n\u2514\u2500\u2500 KronBlock(0,1)\n\u2514\u2500\u2500 CNOT(0,1)\n</code></pre></p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def chain_single_qubit_ops(block: AbstractBlock) -&gt; AbstractBlock:\n\"\"\"Transpile a chain of krons into a kron of chains of single qubit operations.\n    Examples:\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import hea\n    from qadence.transpile.block import chain_single_qubit_ops\n    # Consider a single HEA layer\n    block = hea(2,1)\n    print(block)\n    # After applying chain_single_qubit_ops, we get:\n    print(chain_single_qubit_ops(block))\n    ```\n    \"\"\"\nif is_chain_of_primitivekrons(block):\nkronblocks = block.blocks  # type: ignore[attr-defined]\nn_blocks = len(kronblocks)\nchains = []\nfor qb_idx in range(block.n_qubits):\nprim_gates = []\nfor kron_idx in range(n_blocks):\nprim_gates.append(kronblocks[kron_idx][qb_idx])  # type: ignore[index]\nchains.append(chain(*prim_gates))\ntry:\nreturn kron(*chains)\nexcept Exception as e:\nlogger.debug(\nf\"Unable to transpile {block} using chain_single_qubit_ops\\\n                         due to {e}. Returning original circuit.\"\n)\nreturn block\nelif isinstance(block, CompositeBlock):\nreturn _construct(type(block), tuple(chain_single_qubit_ops(b) for b in block.blocks))\nelse:\nreturn block\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.flatten","title":"<code>flatten(block, types=[ChainBlock, KronBlock, AddBlock])</code>","text":"<p>Flattens the given types of <code>CompositeBlock</code>s if possible.</p> <p>Example: <pre><code>from qadence import chain, kron, X\nfrom qadence.transpile import flatten\nfrom qadence.blocks import ChainBlock, KronBlock, AddBlock\nx = chain(chain(chain(X(0))), kron(kron(X(0))))\n# flatten only `ChainBlock`s\nassert flatten(x, [ChainBlock]) == chain(X(0), kron(kron(X(0))))\n# flatten `ChainBlock`s and `KronBlock`s\nassert flatten(x, [ChainBlock, KronBlock]) == chain(X(0), kron(X(0)))\n# flatten `AddBlock`s (does nothing in this case)\nassert flatten(x, [AddBlock]) == x\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def flatten(block: AbstractBlock, types: list = [ChainBlock, KronBlock, AddBlock]) -&gt; AbstractBlock:\n\"\"\"Flattens the given types of `CompositeBlock`s if possible.\n    Example:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import chain, kron, X\n    from qadence.transpile import flatten\n    from qadence.blocks import ChainBlock, KronBlock, AddBlock\n    x = chain(chain(chain(X(0))), kron(kron(X(0))))\n    # flatten only `ChainBlock`s\n    assert flatten(x, [ChainBlock]) == chain(X(0), kron(kron(X(0))))\n    # flatten `ChainBlock`s and `KronBlock`s\n    assert flatten(x, [ChainBlock, KronBlock]) == chain(X(0), kron(X(0)))\n    # flatten `AddBlock`s (does nothing in this case)\n    assert flatten(x, [AddBlock]) == x\n    ```\n    \"\"\"\nif isinstance(block, CompositeBlock):\ndef fn(b: AbstractBlock, T: Type) -&gt; AbstractBlock:\nreturn _construct(type(block), tuple(_flat_blocks(b, T)))\nreturn reduce(fn, types, block)  # type: ignore[arg-type]\nelif isinstance(block, ScaleBlock):\nblk = deepcopy(block)\nblk.block = flatten(block.block, types=types)\nreturn blk\nelse:\nreturn block\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.scale_primitive_blocks_only","title":"<code>scale_primitive_blocks_only(block, scale=None)</code>","text":"<p>When given a scaled CompositeBlock consisting of several PrimitiveBlocks, move the scale all the way down into the leaves of the block tree.</p> PARAMETER  DESCRIPTION <code>block</code> <p>The block to be transpiled.</p> <p> TYPE: <code>AbstractBlock</code> </p> <code>scale</code> <p>An optional scale parameter. Only to be used for recursive calls internally.</p> <p> TYPE: <code>Basic</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>AbstractBlock</code> <p>A block of the same type where the scales have been moved into the subblocks.</p> <p> TYPE: <code>AbstractBlock</code> </p> <p>Examples:</p> <p>There are two different cases: <code>ChainBlock</code>s/<code>KronBlock</code>s: Only the first subblock needs to be scaled because chains/krons represent multiplications. <pre><code>from qadence import chain, X, RX\nfrom qadence.transpile import scale_primitive_blocks_only\nb = 2 * chain(X(0), RX(0, \"theta\"))\nprint(b)\n# After applying scale_primitive_blocks_only\nprint(scale_primitive_blocks_only(b))\n</code></pre> <pre><code>[mul: 2] \u2514\u2500\u2500 ChainBlock(0)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 RX(0) [params: ['theta']]\nChainBlock(0)\n\u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 RX(0) [params: ['theta']]\n</code></pre></p> <p><code>AddBlock</code>s: Consider 2 * add(X(0), RX(0, \"theta\")).  The scale needs to be added to all subblocks.  We get add(2 * X(0), 2 * RX(0, \"theta\")). <pre><code>from qadence import add, X, RX\nfrom qadence.transpile import scale_primitive_blocks_only\nb = 2 * add(X(0), RX(0, \"theta\"))\nprint(b)\n# After applying scale_primitive_blocks_only\nprint(scale_primitive_blocks_only(b))\n</code></pre> <pre><code>[mul: 2] \u2514\u2500\u2500 AddBlock(0)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 RX(0) [params: ['theta']]\nAddBlock(0)\n\u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 [mul: 2.00000000000000] \u2514\u2500\u2500 RX(0) [params: ['theta']]\n</code></pre></p> Source code in <code>qadence/transpile/block.py</code> <pre><code>@singledispatch\ndef scale_primitive_blocks_only(block: AbstractBlock, scale: sympy.Basic = None) -&gt; AbstractBlock:\n\"\"\"When given a scaled CompositeBlock consisting of several PrimitiveBlocks,\n    move the scale all the way down into the leaves of the block tree.\n    Arguments:\n        block: The block to be transpiled.\n        scale: An optional scale parameter. Only to be used for recursive calls internally.\n    Returns:\n        AbstractBlock: A block of the same type where the scales have been moved into the subblocks.\n    Examples:\n    There are two different cases:\n    `ChainBlock`s/`KronBlock`s: Only the first subblock needs to be scaled because chains/krons\n    represent multiplications.\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import chain, X, RX\n    from qadence.transpile import scale_primitive_blocks_only\n    b = 2 * chain(X(0), RX(0, \"theta\"))\n    print(b)\n    # After applying scale_primitive_blocks_only\n    print(scale_primitive_blocks_only(b))\n    ```\n    `AddBlock`s: Consider 2 * add(X(0), RX(0, \"theta\")).  The scale needs to be added to all\n    subblocks.  We get add(2 * X(0), 2 * RX(0, \"theta\")).\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence import add, X, RX\n    from qadence.transpile import scale_primitive_blocks_only\n    b = 2 * add(X(0), RX(0, \"theta\"))\n    print(b)\n    # After applying scale_primitive_blocks_only\n    print(scale_primitive_blocks_only(b))\n    ```\n    \"\"\"\nraise NotImplementedError(f\"scale_primitive_blocks_only is not implemented for {type(block)}\")\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.set_trainable","title":"<code>set_trainable(blocks, value=True, inplace=True)</code>","text":"<p>Set the trainability of all parameters in a block to a given value</p> PARAMETER  DESCRIPTION <code>blocks</code> <p>Block or list of blocks for which to set the trainable attribute</p> <p> TYPE: <code>AbstractBlock | list[AbstractBlock]</code> </p> <code>value</code> <p>The value of the trainable attribute to assign to the input blocks</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>inplace</code> <p>Whether to modify the block(s) in place or not. Currently, only</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>NotImplementedError</code> <p>if the <code>inplace</code> argument is set to False, the function will raise  this exception</p> RETURNS DESCRIPTION <code>AbstractBlock | list[AbstractBlock]</code> <p>AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable attribute set to the given value</p> Source code in <code>qadence/transpile/block.py</code> <pre><code>def set_trainable(\nblocks: AbstractBlock | list[AbstractBlock], value: bool = True, inplace: bool = True\n) -&gt; AbstractBlock | list[AbstractBlock]:\n\"\"\"Set the trainability of all parameters in a block to a given value\n    Args:\n        blocks (AbstractBlock | list[AbstractBlock]): Block or list of blocks for which\n            to set the trainable attribute\n        value (bool, optional): The value of the trainable attribute to assign to the input blocks\n        inplace (bool, optional): Whether to modify the block(s) in place or not. Currently, only\n    Raises:\n        NotImplementedError: if the `inplace` argument is set to False, the function will\n            raise  this exception\n    Returns:\n        AbstractBlock | list[AbstractBlock]: the input block or list of blocks with the trainable\n            attribute set to the given value\n    \"\"\"\nif isinstance(blocks, AbstractBlock):\nblocks = [blocks]\nif inplace:\nfor block in blocks:\nparams: list[sympy.Basic] = parameters(block)\nfor p in params:\nif not p.is_number:\np.trainable = value\nelse:\nraise NotImplementedError(\"Not inplace set_trainable is not yet available\")\nreturn blocks if len(blocks) &gt; 1 else blocks[0]\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.block.validate","title":"<code>validate(block)</code>","text":"<p>Moves a block from global to local qubit numbers by adding PutBlocks and reassigning qubit locations approriately.</p>"},{"location":"qadence/transpile/#qadence.transpile.block.validate--example","title":"Example","text":"<pre><code>from qadence.blocks import chain\nfrom qadence.operations import X\nfrom qadence.transpile import validate\nx = chain(chain(X(0)), chain(X(1)))\nprint(x)\nprint(validate(x))\n</code></pre> <pre><code>ChainBlock(0,1)\n\u251c\u2500\u2500 ChainBlock(0)\n\u2502   \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 ChainBlock(1)\n\u2514\u2500\u2500 X(1)\nChainBlock(0,1)\n\u251c\u2500\u2500 put on (0)\n\u2502   \u2514\u2500\u2500 ChainBlock(0)\n\u2502       \u2514\u2500\u2500 put on (0)\n\u2502           \u2514\u2500\u2500 X(0)\n\u2514\u2500\u2500 put on (1)\n\u2514\u2500\u2500 ChainBlock(0)\n\u2514\u2500\u2500 put on (0)\n\u2514\u2500\u2500 X(0)\n</code></pre> Source code in <code>qadence/transpile/block.py</code> <pre><code>def validate(block: AbstractBlock) -&gt; AbstractBlock:\n\"\"\"Moves a block from global to local qubit numbers by adding PutBlocks and reassigning\n    qubit locations approriately.\n    # Example\n    ```python exec=\"on\" source=\"above\" result=\"json\"\n    from qadence.blocks import chain\n    from qadence.operations import X\n    from qadence.transpile import validate\n    x = chain(chain(X(0)), chain(X(1)))\n    print(x)\n    print(validate(x))\n    ```\n    \"\"\"\nvblock: AbstractBlock\nfrom qadence.transpile import reassign\nif isinstance(block, ControlBlock):\nvblock = deepcopy(block)\nb: AbstractBlock\n(b,) = block.blocks\nb = reassign(b, {i: i - min(b.qubit_support) for i in b.qubit_support})\nb = validate(b)\nvblock.blocks = (b,)  # type: ignore[assignment]\nelif isinstance(block, CompositeBlock):\nblocks = []\nfor b in block.blocks:\nmi, ma = min(b.qubit_support), max(b.qubit_support)\nnb = reassign(b, {i: i - min(b.qubit_support) for i in b.qubit_support})\nnb = validate(nb)\nnb = PutBlock(nb, tuple(range(mi, ma + 1)))\nblocks.append(nb)\ntry:\nvblock = _construct(type(block), tuple(blocks))\nexcept AssertionError as e:\nif str(e) == \"Make sure blocks act on distinct qubits!\":\nvblock = chain(*blocks)\nelse:\nraise e\nelif isinstance(block, PrimitiveBlock):\nvblock = deepcopy(block)\nelse:\nraise NotImplementedError\nvblock.tag = block.tag\nreturn vblock\n</code></pre>"},{"location":"qadence/transpile/#qadence.transpile.emulate.add_interaction","title":"<code>add_interaction(x, *args, interaction=Interaction.NN, spacing=1.0)</code>","text":"<p>Turns blocks or circuits into (a chain of) <code>HamEvo</code> blocks including a chosen interaction term.</p> <p>This is a <code>@singledipatch</code>ed function which can be called in three ways:</p> <ul> <li>With a <code>QuantumCircuit</code> which contains all necessary information: <code>add_interaction(circuit)</code></li> <li>With a <code>Register</code> and an <code>AbstractBlock</code>: <code>add_interaction(reg, block)</code></li> <li>With an <code>AbstractBlock</code> only: <code>add_interaction(block)</code></li> </ul> <p>See the section about analog blocks for detailed information about how which types of blocks are translated.</p> PARAMETER  DESCRIPTION <code>x</code> <p>Circuit or block to be emulated. See the examples on which argument combinations are accepted.</p> <p> TYPE: <code>Register | QuantumCircuit | AbstractBlock</code> </p> <code>interaction</code> <p>Type of interaction that is added. Can also be a function that accepts a register and a list of edges that define which qubits interact (see the examples).</p> <p> TYPE: <code>Interaction | Callable</code> DEFAULT: <code>NN</code> </p> <code>spacing</code> <p>All qubit coordinates are multiplied by <code>spacing</code>.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> <p>Examples: <pre><code>from qadence import QuantumCircuit, AnalogRX, add_interaction\nc = QuantumCircuit(2, AnalogRX(2.0))\ne = add_interaction(c)\n</code></pre> <pre><code>[mul: 0.0] \u2514\u2500\u2500 AddBlock(0,1)\n\u251c\u2500\u2500 AddBlock(0,1)\n\u2502   \u2514\u2500\u2500 AddBlock(0,1)\n\u2502       \u251c\u2500\u2500 [mul: 1.571] \u2502       \u2502   \u2514\u2500\u2500 AddBlock(0,1)\n\u2502       \u2502       \u251c\u2500\u2500 AddBlock(0)\n\u2502       \u2502       \u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502       \u2502       \u2502   \u2502   \u2514\u2500\u2500 X(0)\n\u2502       \u2502       \u2502   \u2514\u2500\u2500 [mul: 0.0] \u2502       \u2502       \u2502       \u2514\u2500\u2500 Y(0)\n\u2502       \u2502       \u2514\u2500\u2500 AddBlock(1)\n\u2502       \u2502           \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502       \u2502           \u2502   \u2514\u2500\u2500 X(1)\n\u2502       \u2502           \u2514\u2500\u2500 [mul: 0.0] \u2502       \u2502               \u2514\u2500\u2500 Y(1)\n\u2502       \u2514\u2500\u2500 [mul: 0.0] \u2502           \u2514\u2500\u2500 AddBlock(0,1)\n\u2502               \u251c\u2500\u2500 N(0)\n\u2502               \u2514\u2500\u2500 N(1)\n\u2514\u2500\u2500 AddBlock(0,1)\n\u2514\u2500\u2500 [mul: 865723.020] \u2514\u2500\u2500 KronBlock(0,1)\n\u251c\u2500\u2500 N(0)\n\u2514\u2500\u2500 N(1)\n</code></pre>  You can also use <code>add_interaction</code> directly on a block, but you have to provide either the <code>Register</code> or define a non-global qubit support. <pre><code>from qadence import AnalogRX, Register, add_interaction\nb = AnalogRX(2.0)\nr = Register(1)\ne = add_interaction(r, b)\n# or provide only the block with local qubit support\n# in this case the register is created via `Register(b.n_qubits)`\ne = add_interaction(AnalogRX(2.0, qubit_support=(0,)))\nprint(e.generator)\n</code></pre> <pre><code>[mul: 0.450] \u2514\u2500\u2500 AddBlock(0)\n\u2514\u2500\u2500 AddBlock(0)\n\u251c\u2500\u2500 [mul: 1.571] \u2502   \u2514\u2500\u2500 AddBlock(0)\n\u2502       \u2514\u2500\u2500 AddBlock(0)\n\u2502           \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502           \u2502   \u2514\u2500\u2500 X(0)\n\u2502           \u2514\u2500\u2500 [mul: 0.0] \u2502               \u2514\u2500\u2500 Y(0)\n\u2514\u2500\u2500 [mul: 0.0] \u2514\u2500\u2500 AddBlock(0)\n\u2514\u2500\u2500 N(0)\n[mul: 0.450] \u2514\u2500\u2500 AddBlock(0)\n\u2514\u2500\u2500 AddBlock(0)\n\u251c\u2500\u2500 [mul: 1.571] \u2502   \u2514\u2500\u2500 AddBlock(0)\n\u2502       \u2514\u2500\u2500 AddBlock(0)\n\u2502           \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502           \u2502   \u2514\u2500\u2500 X(0)\n\u2502           \u2514\u2500\u2500 [mul: 0.0] \u2502               \u2514\u2500\u2500 Y(0)\n\u2514\u2500\u2500 [mul: 0.0] \u2514\u2500\u2500 AddBlock(0)\n\u2514\u2500\u2500 N(0)\n</code></pre>  You can specify a custom <code>interaction</code> function which has to accept a <code>Register</code> and a list of <code>edges: list[tuple[int, int]]</code>: <pre><code>from qadence import AnalogRX, Register, add_interaction\nfrom qadence.transpile.emulate import ising_interaction\ndef int_fn(r: Register, pairs: list[tuple[int, int]]) -&gt; AbstractBlock:\n# do either something completely custom\n# ...\n# or e.g. change the default kwargs to `ising_interaction`\nreturn ising_interaction(r, pairs, rydberg_level=70)\nb = AnalogRX(2.0)\nr = Register(1)\ne = add_interaction(r, b, interaction=int_fn)\n</code></pre> <pre><code>\n</code></pre> </p> Source code in <code>qadence/transpile/emulate.py</code> <pre><code>@singledispatch\ndef add_interaction(\nx: Register | QuantumCircuit | AbstractBlock,\n*args: Any,\ninteraction: Interaction | Callable = Interaction.NN,\nspacing: float = 1.0,\n) -&gt; QuantumCircuit | AbstractBlock:\n\"\"\"Turns blocks or circuits into (a chain of) `HamEvo` blocks including a\n    chosen interaction term.\n    This is a `@singledipatch`ed function which can be called in three ways:\n    * With a `QuantumCircuit` which contains all necessary information: `add_interaction(circuit)`\n    * With a `Register` and an `AbstractBlock`: `add_interaction(reg, block)`\n    * With an `AbstractBlock` only: `add_interaction(block)`\n    See the section about [analog blocks](/digital_analog_qc/analog-basics.md) for\n    detailed information about how which types of blocks are translated.\n    Arguments:\n        x: Circuit or block to be emulated. See the examples on which argument\n            combinations are accepted.\n        interaction: Type of interaction that is added. Can also be a function that accepts a\n            register and a list of edges that define which qubits interact (see the examples).\n        spacing: All qubit coordinates are multiplied by `spacing`.\n    Examples:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import QuantumCircuit, AnalogRX, add_interaction\n    c = QuantumCircuit(2, AnalogRX(2.0))\n    e = add_interaction(c)\n    print(str(e.block.generator)) # markdown-exec: hide\n    ```\n    You can also use `add_interaction` directly on a block, but you have to provide either\n    the `Register` or define a non-global qubit support.\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import AnalogRX, Register, add_interaction\n    b = AnalogRX(2.0)\n    r = Register(1)\n    e = add_interaction(r, b)\n    print(e.generator) # markdown-exec: hide\n    # or provide only the block with local qubit support\n    # in this case the register is created via `Register(b.n_qubits)`\n    e = add_interaction(AnalogRX(2.0, qubit_support=(0,)))\n    print(e.generator)\n    ```\n    You can specify a custom `interaction` function which has to accept a `Register` and a list\n    of `edges: list[tuple[int, int]]`:\n    ```python exec=\"on\" source=\"material-block\" result=\"json\"\n    from qadence import AnalogRX, Register, add_interaction\n    from qadence.transpile.emulate import ising_interaction\n    def int_fn(r: Register, pairs: list[tuple[int, int]]) -&gt; AbstractBlock:\n        # do either something completely custom\n        # ...\n        # or e.g. change the default kwargs to `ising_interaction`\n        return ising_interaction(r, pairs, rydberg_level=70)\n    b = AnalogRX(2.0)\n    r = Register(1)\n    e = add_interaction(r, b, interaction=int_fn)\n    ```\n    \"\"\"\nraise ValueError(f\"`add_interaction` is not implemented for {type(x)}\")\n</code></pre>"},{"location":"qadence/types/","title":"Types","text":""},{"location":"qadence/types/#qadence-types","title":"Qadence Types","text":""},{"location":"qadence/types/#qadence.types.TArray","title":"<code>TArray = Union[Iterable, torch.Tensor, np.ndarray]</code>  <code>module-attribute</code>","text":"<p>Union of common array types.</p>"},{"location":"qadence/types/#qadence.types.TGenerator","title":"<code>TGenerator = Union[torch.Tensor, sympy.Array, sympy.Basic]</code>  <code>module-attribute</code>","text":"<p>Union of torch tensors and numpy arrays.</p>"},{"location":"qadence/types/#qadence.types.TNumber","title":"<code>TNumber = Union[int, float, complex]</code>  <code>module-attribute</code>","text":"<p>Union of python number types.</p>"},{"location":"qadence/types/#qadence.types.TParameter","title":"<code>TParameter = Union[TNumber, torch.Tensor, sympy.Basic, str]</code>  <code>module-attribute</code>","text":"<p>Union of numbers, tensors, and parameter types.</p>"},{"location":"qadence/types/#qadence.types.AlgoHEvo","title":"<code>AlgoHEvo</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Hamiltonian Evolution algorithms that can be used by the backend.</p>"},{"location":"qadence/types/#qadence.types.AlgoHEvo.EIG","title":"<code>EIG = 'EIG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using Hamiltonian diagonalization.</p>"},{"location":"qadence/types/#qadence.types.AlgoHEvo.EXP","title":"<code>EXP = 'EXP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Using torch.matrix_exp on the generator matrix.</p>"},{"location":"qadence/types/#qadence.types.AlgoHEvo.RK4","title":"<code>RK4 = 'RK4'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>4th order Runge-Kutta approximation.</p>"},{"location":"qadence/types/#qadence.types.Endianness","title":"<code>Endianness</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>The endianness convention to use.</p>"},{"location":"qadence/types/#qadence.types.Endianness.BIG","title":"<code>BIG = 'Big'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use Big endianness.</p>"},{"location":"qadence/types/#qadence.types.Endianness.LITTLE","title":"<code>LITTLE = 'Little'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use little endianness.</p>"},{"location":"qadence/types/#qadence.types.FigFormat","title":"<code>FigFormat</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Available output formats for exporting visualized circuits to a file.</p>"},{"location":"qadence/types/#qadence.types.FigFormat.PDF","title":"<code>PDF = 'PDF'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>PDF format.</p>"},{"location":"qadence/types/#qadence.types.FigFormat.PNG","title":"<code>PNG = 'PNG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>PNG format.</p>"},{"location":"qadence/types/#qadence.types.FigFormat.SVG","title":"<code>SVG = 'SVG'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>SVG format.</p>"},{"location":"qadence/types/#qadence.types.GenDAQC","title":"<code>GenDAQC</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>The type of interaction for the DAQC transform.</p>"},{"location":"qadence/types/#qadence.types.GenDAQC.NN","title":"<code>NN = 'NN'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NN</p>"},{"location":"qadence/types/#qadence.types.GenDAQC.ZZ","title":"<code>ZZ = 'ZZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZZ</p>"},{"location":"qadence/types/#qadence.types.Interaction","title":"<code>Interaction</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Interaction types used in - <code>add_interaction</code>. - <code>hamiltonian_factory</code>.</p>"},{"location":"qadence/types/#qadence.types.Interaction.NN","title":"<code>NN = 'NN'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>NN-Ising Interaction, N=(I-Z)/2</p>"},{"location":"qadence/types/#qadence.types.Interaction.XY","title":"<code>XY = 'XY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>XY Interaction</p>"},{"location":"qadence/types/#qadence.types.Interaction.XYZ","title":"<code>XYZ = 'XYZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>XYZ Interaction</p>"},{"location":"qadence/types/#qadence.types.Interaction.ZZ","title":"<code>ZZ = 'ZZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ZZ-Ising Interaction</p>"},{"location":"qadence/types/#qadence.types.LTSOrder","title":"<code>LTSOrder</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Lie-Trotter-Suzuki approximation order.</p>"},{"location":"qadence/types/#qadence.types.LTSOrder.BASIC","title":"<code>BASIC = 'BASIC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Basic.</p>"},{"location":"qadence/types/#qadence.types.LTSOrder.ST2","title":"<code>ST2 = 'ST2'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ST2.</p>"},{"location":"qadence/types/#qadence.types.LTSOrder.ST4","title":"<code>ST4 = 'ST4'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>ST4.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology","title":"<code>LatticeTopology</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Lattice topologies to choose from for the register.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.ALL_TO_ALL","title":"<code>ALL_TO_ALL = 'all_to_all'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>All to all- connected lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.ARBITRARY","title":"<code>ARBITRARY = 'arbitrary'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Arbitrarily-shaped lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.CIRCLE","title":"<code>CIRCLE = 'circle'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Circular lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.HONEYCOMB_LATTICE","title":"<code>HONEYCOMB_LATTICE = 'honeycomb_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Honeycomb-shaped lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.LINE","title":"<code>LINE = 'line'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Line-format lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.RECTANGULAR_LATTICE","title":"<code>RECTANGULAR_LATTICE = 'rectangular_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Rectangular-shaped lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.SQUARE","title":"<code>SQUARE = 'square'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Square lattice.</p>"},{"location":"qadence/types/#qadence.types.LatticeTopology.TRIANGULAR_LATTICE","title":"<code>TRIANGULAR_LATTICE = 'triangular_lattice'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Triangular-shaped shape.</p>"},{"location":"qadence/types/#qadence.types.OpName","title":"<code>OpName</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>A list of all available of digital-analog operations.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGENTANG","title":"<code>ANALOGENTANG = 'AnalogEntanglement'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog entanglement operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGRX","title":"<code>ANALOGRX = 'AnalogRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RX operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGRY","title":"<code>ANALOGRY = 'AnalogRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RY operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGRZ","title":"<code>ANALOGRZ = 'AnalogRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog RZ operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.ANALOGSWAP","title":"<code>ANALOGSWAP = 'AnalogSWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The analog SWAP operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.CNOT","title":"<code>CNOT = 'CNOT'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The CNOT gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CPHASE","title":"<code>CPHASE = 'CPHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The controlled PHASE gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CRX","title":"<code>CRX = 'CRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control RX gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CRY","title":"<code>CRY = 'CRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Controlled RY gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CRZ","title":"<code>CRZ = 'CRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control RZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CSWAP","title":"<code>CSWAP = 'CSWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Control SWAP gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.CZ","title":"<code>CZ = 'CZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The CZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.ENTANG","title":"<code>ENTANG = 'entangle'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The entanglement operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.H","title":"<code>H = 'H'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Hadamard gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.HAMEVO","title":"<code>HAMEVO = 'HamEvo'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Hamiltonian Evolution operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.I","title":"<code>I = 'I'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Identity gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCPHASE","title":"<code>MCPHASE = 'MCPHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol PHASE gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCRX","title":"<code>MCRX = 'MCRX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RX gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCRY","title":"<code>MCRY = 'MCRY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RY gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCRZ","title":"<code>MCRZ = 'MCRZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol RZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.MCZ","title":"<code>MCZ = 'MCZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Multicontrol CZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.N","title":"<code>N = 'N'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The N = (1/2)(I-Z) operator</p>"},{"location":"qadence/types/#qadence.types.OpName.PHASE","title":"<code>PHASE = 'PHASE'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The PHASE gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.RX","title":"<code>RX = 'RX'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RX gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.RY","title":"<code>RY = 'RY'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RY gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.RZ","title":"<code>RZ = 'RZ'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The RZ gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.S","title":"<code>S = 'S'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The S gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.SDAGGER","title":"<code>SDAGGER = 'SDagger'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The S dagger gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.SWAP","title":"<code>SWAP = 'SWAP'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The SWAP gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.T","title":"<code>T = 'T'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The T gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.TDAGGER","title":"<code>TDAGGER = 'TDagger'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The T dagger gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.TOFFOLI","title":"<code>TOFFOLI = 'Toffoli'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Toffoli gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.U","title":"<code>U = 'U'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The U gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.WAIT","title":"<code>WAIT = 'wait'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The wait operation.</p>"},{"location":"qadence/types/#qadence.types.OpName.X","title":"<code>X = 'X'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The X gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.Y","title":"<code>Y = 'Y'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Y gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.Z","title":"<code>Z = 'Z'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Z gate.</p>"},{"location":"qadence/types/#qadence.types.OpName.ZERO","title":"<code>ZERO = 'Zero'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The zero gate.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod","title":"<code>OverlapMethod</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Overlap Methods to choose from.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.COMPUTE_UNCOMPUTE","title":"<code>COMPUTE_UNCOMPUTE = 'compute_uncompute'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Compute-uncompute.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.EXACT","title":"<code>EXACT = 'exact'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Exact.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.HADAMARD_TEST","title":"<code>HADAMARD_TEST = 'hadamard_test'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Hadamard-test.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.JENSEN_SHANNON","title":"<code>JENSEN_SHANNON = 'jensen_shannon'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Jensen-shannon.</p>"},{"location":"qadence/types/#qadence.types.OverlapMethod.SWAP_TEST","title":"<code>SWAP_TEST = 'swap_test'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Swap-test.</p>"},{"location":"qadence/types/#qadence.types.ParameterType","title":"<code>ParameterType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Parameter types available in qadence.</p>"},{"location":"qadence/types/#qadence.types.ParameterType.FEATURE","title":"<code>FEATURE = 'Feature'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>FeatureParameters act as input and are not trainable.</p>"},{"location":"qadence/types/#qadence.types.ParameterType.FIXED","title":"<code>FIXED = 'Fixed'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Fixed/ constant parameters are neither trainable nor act as input.</p>"},{"location":"qadence/types/#qadence.types.ParameterType.VARIATIONAL","title":"<code>VARIATIONAL = 'Variational'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>VariationalParameters are trainable.</p>"},{"location":"qadence/types/#qadence.types.QubitSupportType","title":"<code>QubitSupportType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Qubit support types.</p>"},{"location":"qadence/types/#qadence.types.QubitSupportType.GLOBAL","title":"<code>GLOBAL = 'global'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use global qubit support.</p>"},{"location":"qadence/types/#qadence.types.ResultType","title":"<code>ResultType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Available data types for generating certain results.</p>"},{"location":"qadence/types/#qadence.types.ResultType.NUMPY","title":"<code>NUMPY = 'Numpy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Numpy Array Type.</p>"},{"location":"qadence/types/#qadence.types.ResultType.STRING","title":"<code>STRING = 'String'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>String Type.</p>"},{"location":"qadence/types/#qadence.types.ResultType.TORCH","title":"<code>TORCH = 'Torch'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Torch Tensor Type.</p>"},{"location":"qadence/types/#qadence.types.SerializationFormat","title":"<code>SerializationFormat</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Available serialization formats for circuits.</p>"},{"location":"qadence/types/#qadence.types.SerializationFormat.JSON","title":"<code>JSON = 'JSON'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The Json format.</p>"},{"location":"qadence/types/#qadence.types.SerializationFormat.PT","title":"<code>PT = 'PT'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The PT format used by Torch.</p>"},{"location":"qadence/types/#qadence.types.StateGeneratorType","title":"<code>StateGeneratorType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Methods to generate random states.</p>"},{"location":"qadence/types/#qadence.types.StateGeneratorType.HAAR_MEASURE_FAST","title":"<code>HAAR_MEASURE_FAST = 'HaarMeasureFast'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>HaarMeasure.</p>"},{"location":"qadence/types/#qadence.types.StateGeneratorType.HAAR_MEASURE_SLOW","title":"<code>HAAR_MEASURE_SLOW = 'HaarMeasureSlow'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>HaarMeasure non-optimized version.</p>"},{"location":"qadence/types/#qadence.types.StateGeneratorType.RANDOM_ROTATIONS","title":"<code>RANDOM_ROTATIONS = 'RandomRotations'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Random Rotations.</p>"},{"location":"qadence/types/#qadence.types.StrEnum","title":"<code>StrEnum</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"qadence/types/#qadence.types.StrEnum.__str__","title":"<code>__str__()</code>","text":"<p>Used when dumping enum fields in a schema.</p> Source code in <code>qadence/types.py</code> <pre><code>def __str__(self) -&gt; str:\n\"\"\"Used when dumping enum fields in a schema.\"\"\"\nret: str = self.value\nreturn ret\n</code></pre>"},{"location":"qadence/types/#qadence.types.Strategy","title":"<code>Strategy</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Computing paradigm.</p>"},{"location":"qadence/types/#qadence.types.Strategy.ANALOG","title":"<code>ANALOG = 'Analog'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the analog paradigm.</p>"},{"location":"qadence/types/#qadence.types.Strategy.BDAQC","title":"<code>BDAQC = 'bDAQC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the banged digital-analog QC paradigm.</p>"},{"location":"qadence/types/#qadence.types.Strategy.DIGITAL","title":"<code>DIGITAL = 'Digital'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the digital paradigm.</p>"},{"location":"qadence/types/#qadence.types.Strategy.SDAQC","title":"<code>SDAQC = 'sDAQC'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Use the step-wise digital-analog QC paradigm.</p>"},{"location":"qadence/types/#qadence.types.TensorType","title":"<code>TensorType</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Tensor Types for converting blocks to tensors.</p>"},{"location":"qadence/types/#qadence.types.TensorType.DENSE","title":"<code>DENSE = 'Dense'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a block to a dense tensor.</p>"},{"location":"qadence/types/#qadence.types.TensorType.SPARSE","title":"<code>SPARSE = 'Sparse'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a observable block to a sparse tensor.</p>"},{"location":"qadence/types/#qadence.types.TensorType.SPARSEDIAGONAL","title":"<code>SPARSEDIAGONAL = 'SparseDiagonal'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Convert a diagonal observable block to a sparse diagonal if possible.</p>"},{"location":"qml/","title":"Variational quantum algorithms","text":"<p>Variational algorithms on noisy devices and quantum machine learning (QML) [^1] in particular are the target applications for Qadence. For this purpose, the library offers both flexible symbolic expressions for the quantum circuit parameters via <code>sympy</code> (see here for more details) and native automatic differentiation via integration with PyTorch deep learning framework.</p> <p>Qadence symbolic parameter interface allows to create arbitrary feature maps to encode classical data into quantum circuits with an arbitrary non-linear function embedding for the input values:</p> <pre><code>import qadence as qd\nfrom qadence.operations import *\nimport torch\nfrom sympy import acos\nn_qubits = 4\nfp = qd.FeatureParameter(\"phi\")\nfeature_map = qd.kron(RX(i, 2 * acos(fp)) for i in range(n_qubits))\n# the key in the dictionary must correspond to\n# the name of the assigned to the feature parameter\ninputs = {\"phi\": torch.rand(3)}\nsamples = qd.sample(feature_map, values=inputs)\nprint(samples)\n</code></pre>   [Counter({'1111': 75, '1011': 9, '0111': 6, '1101': 4, '1110': 4, '0110': 2}), Counter({'1111': 24, '1110': 16, '1101': 9, '0111': 8, '1001': 7, '0011': 6, '0110': 6, '0100': 5, '1010': 5, '1011': 5, '0101': 3, '0010': 2, '1100': 2, '0000': 1, '0001': 1}), Counter({'0000': 28, '1000': 14, '0001': 12, '0010': 6, '0100': 6, '0101': 6, '1100': 6, '0011': 5, '0110': 4, '1001': 4, '1011': 2, '1101': 2, '1110': 2, '0111': 1, '1010': 1, '1111': 1})]    <p>The <code>constructors.feature_map</code> module provides convenience functions to build commonly used feature maps where the input parameter is encoded in the single-qubit gates rotation angle.</p> <p>Furthermore, Qadence is natively integrated with PyTorch automatic differentiation engine thus Qadence quantum models can be used seamlessly in a PyTorch workflow.</p> <p>Let's create a quantum neural network model using the feature map just defined, a digital-analog variational ansaztz and a simple observable \\(X(0) \\otimes X(1)\\). We use the convenience <code>QNN</code> quantum model abstraction.</p> <pre><code>ansatz = qd.hea(n_qubits, strategy=\"sDAQC\")\ncircuit = qd.QuantumCircuit(n_qubits, feature_map, ansatz)\nobservable = qd.kron(X(0), X(1))\nmodel = qd.QNN(circuit, observable)\n# NOTE: the `QNN` is a torch.nn.Module\nassert isinstance(model, torch.nn.Module)\n</code></pre> <pre><code>\n</code></pre> <p>Differentiation works the same way as any other PyTorch module:</p> <pre><code>values = {\"phi\": torch.rand(10, requires_grad=True)}\n# the forward pass of the quantum model returns the expectation\n# value of the input observable\nout = model(values)\nprint(f\"Quantum model output: {out}\")\n# you can compute the gradient with respect to inputs using\n# PyTorch autograd differentiation engine\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: {dout}\")\n# you can also call directly a backward pass to compute derivatives with respect\n# to the variational parameters and use it for implementing variational\n# optimization\nout.sum().backward()\n</code></pre>   Quantum model output: tensor([[0.1904],         [0.3953],         [0.2193],         [0.0431],         [0.2558],         [0.3160],         [0.0408],         [0.4406],         [0.4627],         [0.4138]], grad_fn=) First-order derivative w.r.t. the feature parameter: tensor([ 0.5730,  0.6237,  0.6140, -1.0375,  0.6560,  0.6914, -0.9687, -0.5948,         -0.1979, -0.8826], grad_fn=)    <p>To run QML on real devices, Qadence offers generalized parameter shift rules (GPSR) <sup>1</sup> for arbitrary quantum operations which can be selected when constructing the <code>QNN</code> model:</p> <pre><code>model = qd.QNN(circuit, observable, diff_mode=\"gpsr\")\nout = model(values)\ndout = torch.autograd.grad(out, values[\"phi\"], torch.ones_like(out), create_graph=True)[0]\nprint(f\"First-order derivative w.r.t. the feature parameter: {dout}\")\n</code></pre>   First-order derivative w.r.t. the feature parameter: tensor([ 0.5730,  0.6237,  0.6140, -1.0375,  0.6560,  0.6914, -0.9687, -0.5948,         -0.1979, -0.8826], grad_fn=)    <p>See here for more details on how the parameter shift rules implementation works in Qadence.</p>"},{"location":"qml/#references","title":"References","text":"<p>[^1] Schuld, Petruccione, Machine learning on Quantum Computers, Springer Nature (2021)</p> <ol> <li> <p>Kyriienko et al., General quantum circuit differentiation rules \u21a9</p> </li> </ol>"},{"location":"qml/qaoa/","title":"Solving MaxCut with QAOA","text":"<p>This tutorial shows how to solve the maximum cut (MaxCut) combinatorial optimization problem on a graph using the Quantum Approximate Optimization Algorithm (QAOA), first introduced by Farhi et al. in 2014 <sup>1</sup>.</p> <p>Given an arbitrary graph, the MaxCut problem consists in finding a graph cut which partitions the nodes into two disjoint sets, such that the number of edges in the cut is maximized. This is a very common combinatorial optimization problem which is computationally hard.</p> <p>The graph used for this tutorial is a randomly generated using the <code>networkx</code> library with a \\(0.5\\) probability of having an edge between two arbitrary nodes.</p> <pre><code>import numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\n# ensure reproducibility\nseed = 10\nnp.random.seed(seed)\nn_nodes = 8\nedge_prob = 0.5\ngraph = nx.gnp_random_graph(n_nodes, edge_prob)\nnx.draw(graph)\n</code></pre> 2023-10-12T16:59:43.555273 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ <p>The goal of the MaxCut algorithm is to maximize the following cost function:</p> \\[\\mathcal{C}(p) = \\sum_{\\alpha}^m \\mathcal{C}_{\\alpha}(p)\\] <p>where \\(p\\) is the given partition of the graph, \\(\\alpha\\) is an index over the edges and \\(\\mathcal{C}_{\\alpha}(p)\\) is written such that if the nodes connected by the \\(\\alpha\\) edge are in the same set, it returns \\(0\\), otherwise it returns \\(1\\).</p>"},{"location":"qml/qaoa/#the-qaoa-quantum-circuit","title":"The QAOA quantum circuit","text":"<p>This problem can be solved by using a parametrized quantum circuit with the QAOA algorithm. This requires a circuit with two main components:</p> <ul> <li>the cost component: a circuit generated by a diagonal Hamiltonian which   encodes the cost function described above into a quantum circuit.</li> <li>the mixing component: a simple set of single-qubit rotations with adjustable   angles which are tuned during the classical optimization loop to minimize the cost</li> </ul> <p>Below, the QAOA quantum circuit with the cost and mixing components is defined using <code>qadence</code> operations. The cost component of each layer of the circuit is decomposed into digital single and two-qubits operations via the <code>.digital_decomposition()</code> method. The decomposition is exact since the Hamiltonian generator is diagonal.</p> <pre><code>from qadence import Zero, I, HamEvo, tag, kron, chain, QuantumCircuit, RX, Z\n# generators associated with the edges of the given graph\nzz_ops = [kron(Z(edge[0]), Z(edge[1])) for edge in graph.edges()]\nn_qubits = graph.number_of_nodes()\nn_layers = 2\ncost_ham = Zero()\nfor op in zz_ops:\ncost_ham += 0.5 * op\ncost_ham = 0.5 * kron(I(i) for i in range(n_qubits)) - cost_ham\nlayers = []\nfor layer in range(n_layers):\n# cost layer with digital decomposition\ncost_layer = HamEvo(cost_ham, f\"g{layer}\").digital_decomposition()\ncost_layer = tag(cost_layer, \"cost\")\n# mixing layer with single qubit rotations\nmixing_layer = kron(RX(i, f\"b{layer}{i}\") for i in range(n_qubits))\nmixing_layer = tag(mixing_layer, \"mixing\")\n# putting all together in a single ChainBlock\nlayers.append(chain(cost_layer, mixing_layer))\nfinal_b = chain(*layers)\ncircuit = QuantumCircuit(n_qubits, final_b)\n</code></pre> cluster_dbf025402507421b92990537e4c1796d mixing cluster_f5fbb5d96e8349899e1d48abd9fc4898 cost cluster_6b65c207f5d04ce49b1be89572d1a379 mixing cluster_d2ecbe1ef316413f967657f03d26b082 cost 04a9dd3cc21f44b5b0ea4469e0656ace 0 8d969c619e13466caaebf9c212cb138d 04a9dd3cc21f44b5b0ea4469e0656ace--8d969c619e13466caaebf9c212cb138d 99a53e295ed2494fa999a71bf6e53069 1 8e18f4b1dce64322923e175c7bfd7eb8 8d969c619e13466caaebf9c212cb138d--8e18f4b1dce64322923e175c7bfd7eb8 a89a0c1892394e31956d945b6bfd852f 8e18f4b1dce64322923e175c7bfd7eb8--a89a0c1892394e31956d945b6bfd852f 38e9a5d10c4b46f58682a030be7cf7f6 a89a0c1892394e31956d945b6bfd852f--38e9a5d10c4b46f58682a030be7cf7f6 201a85189ca340739101d6d9f3a9e6a0 38e9a5d10c4b46f58682a030be7cf7f6--201a85189ca340739101d6d9f3a9e6a0 8438e53639e2464a8c13329ba205159e 201a85189ca340739101d6d9f3a9e6a0--8438e53639e2464a8c13329ba205159e 09d1f1363fe140ecbf3f71b45785f976 8438e53639e2464a8c13329ba205159e--09d1f1363fe140ecbf3f71b45785f976 78c87ae31b5f48768153eccb28ffa46f 09d1f1363fe140ecbf3f71b45785f976--78c87ae31b5f48768153eccb28ffa46f 70775eb950d041129cc977dbf0a8f0b2 78c87ae31b5f48768153eccb28ffa46f--70775eb950d041129cc977dbf0a8f0b2 ec9ae2b41b404cea9665019ac92ff36d 70775eb950d041129cc977dbf0a8f0b2--ec9ae2b41b404cea9665019ac92ff36d 5674f883aa4643c0a6a2ed5d4071e0b2 ec9ae2b41b404cea9665019ac92ff36d--5674f883aa4643c0a6a2ed5d4071e0b2 580eea3ad79443ab87eb713153ddcce6 5674f883aa4643c0a6a2ed5d4071e0b2--580eea3ad79443ab87eb713153ddcce6 642ccf11eaa748cb878971b6f5058732 580eea3ad79443ab87eb713153ddcce6--642ccf11eaa748cb878971b6f5058732 267408fd3cb64606bdf68d02e3f61f99 642ccf11eaa748cb878971b6f5058732--267408fd3cb64606bdf68d02e3f61f99 848edb94b2ac433ba2873df799c992b4 267408fd3cb64606bdf68d02e3f61f99--848edb94b2ac433ba2873df799c992b4 e1382e133fd643ae9aad529aa6458849 848edb94b2ac433ba2873df799c992b4--e1382e133fd643ae9aad529aa6458849 015fb98dc5e941ffb2d9308d2024e4ea e1382e133fd643ae9aad529aa6458849--015fb98dc5e941ffb2d9308d2024e4ea acddcd90f9224cc69507fac31bda1230 015fb98dc5e941ffb2d9308d2024e4ea--acddcd90f9224cc69507fac31bda1230 589d030eadda4ac8b1c8c09690906cd3 acddcd90f9224cc69507fac31bda1230--589d030eadda4ac8b1c8c09690906cd3 79469456537e4810a1a127bff2fb356a 589d030eadda4ac8b1c8c09690906cd3--79469456537e4810a1a127bff2fb356a 8004c673fe904350a410aa45b968be58 79469456537e4810a1a127bff2fb356a--8004c673fe904350a410aa45b968be58 bdf097d5873b4f1b822e30d262991159 8004c673fe904350a410aa45b968be58--bdf097d5873b4f1b822e30d262991159 0ed3009978c041969fb72163b713e19b bdf097d5873b4f1b822e30d262991159--0ed3009978c041969fb72163b713e19b 789319a6793043ad89ca006aa8f46432 0ed3009978c041969fb72163b713e19b--789319a6793043ad89ca006aa8f46432 6adbeb041008424ca0e2122a4e00f0e9 789319a6793043ad89ca006aa8f46432--6adbeb041008424ca0e2122a4e00f0e9 8d62c86eedb54df8b8662c224f44825a 6adbeb041008424ca0e2122a4e00f0e9--8d62c86eedb54df8b8662c224f44825a e21e6e66d63e4f7f8fb2ed9ed32784b4 8d62c86eedb54df8b8662c224f44825a--e21e6e66d63e4f7f8fb2ed9ed32784b4 5d8e1c3fa8f54655917264a66c083675 e21e6e66d63e4f7f8fb2ed9ed32784b4--5d8e1c3fa8f54655917264a66c083675 2a9cc1f5a65043f787326bc8a23b102a 5d8e1c3fa8f54655917264a66c083675--2a9cc1f5a65043f787326bc8a23b102a 251786a6995e46e995ba8e983a59c0b2 2a9cc1f5a65043f787326bc8a23b102a--251786a6995e46e995ba8e983a59c0b2 8e545ad8d6e745a9900ac5ed8bc523f0 251786a6995e46e995ba8e983a59c0b2--8e545ad8d6e745a9900ac5ed8bc523f0 dc1de928ccab4d3092b9f87cf77c9b3f 8e545ad8d6e745a9900ac5ed8bc523f0--dc1de928ccab4d3092b9f87cf77c9b3f a78fd2f3507a4e8896e752a021acdb39 dc1de928ccab4d3092b9f87cf77c9b3f--a78fd2f3507a4e8896e752a021acdb39 179b1fb37dd9410cb3f164a648a4a995 a78fd2f3507a4e8896e752a021acdb39--179b1fb37dd9410cb3f164a648a4a995 1b74f9148f424d1bbc989964ff791376 179b1fb37dd9410cb3f164a648a4a995--1b74f9148f424d1bbc989964ff791376 da1fa1e5c1c548e5b1d24344786952e9 1b74f9148f424d1bbc989964ff791376--da1fa1e5c1c548e5b1d24344786952e9 9f0eaee5f5424973832aef6cb000b20d da1fa1e5c1c548e5b1d24344786952e9--9f0eaee5f5424973832aef6cb000b20d 25b5b21152d044ed844cb23d77e01ef9 9f0eaee5f5424973832aef6cb000b20d--25b5b21152d044ed844cb23d77e01ef9 89a3962cc1fe4246bebf0913b853a2be 25b5b21152d044ed844cb23d77e01ef9--89a3962cc1fe4246bebf0913b853a2be 57377d5ab0ad4a728c168671ec9b1760 89a3962cc1fe4246bebf0913b853a2be--57377d5ab0ad4a728c168671ec9b1760 a43fbb2898ce4c4b8119eb8f3e7a50ad 57377d5ab0ad4a728c168671ec9b1760--a43fbb2898ce4c4b8119eb8f3e7a50ad 9570ed4f32154c51863204527f0183f2 a43fbb2898ce4c4b8119eb8f3e7a50ad--9570ed4f32154c51863204527f0183f2 c69ff6537b2f4da290bbb247ba0576e6 9570ed4f32154c51863204527f0183f2--c69ff6537b2f4da290bbb247ba0576e6 0e303949eb6547f18e347b10e83a10cd c69ff6537b2f4da290bbb247ba0576e6--0e303949eb6547f18e347b10e83a10cd f4a8df74cd1f40be8fc8ae76f1379547 0e303949eb6547f18e347b10e83a10cd--f4a8df74cd1f40be8fc8ae76f1379547 c57a9c2f99f04aa9b9ce5e620d8da687 f4a8df74cd1f40be8fc8ae76f1379547--c57a9c2f99f04aa9b9ce5e620d8da687 6201d1c2f9104ec5aeb72bdf220637f6 c57a9c2f99f04aa9b9ce5e620d8da687--6201d1c2f9104ec5aeb72bdf220637f6 e075f39b2ca44f54836b45e0e81fc460 6201d1c2f9104ec5aeb72bdf220637f6--e075f39b2ca44f54836b45e0e81fc460 80ecc78dae1c4e58828dadb054c2726a e075f39b2ca44f54836b45e0e81fc460--80ecc78dae1c4e58828dadb054c2726a cb36995311fb440e9dc06642b691928f 80ecc78dae1c4e58828dadb054c2726a--cb36995311fb440e9dc06642b691928f 5b24fab06f6547ad8478fbbef14248a7 cb36995311fb440e9dc06642b691928f--5b24fab06f6547ad8478fbbef14248a7 47f1e95c40b3492c806a7e215d7c080d 5b24fab06f6547ad8478fbbef14248a7--47f1e95c40b3492c806a7e215d7c080d b022a2f185e0472385b71557d11b5e42 47f1e95c40b3492c806a7e215d7c080d--b022a2f185e0472385b71557d11b5e42 2c50434fc567478cb0116516988e97ef b022a2f185e0472385b71557d11b5e42--2c50434fc567478cb0116516988e97ef 95ade0a38d9b42b2b46e0571db35e168 2c50434fc567478cb0116516988e97ef--95ade0a38d9b42b2b46e0571db35e168 7d177576833946a39044855cbf577fa1 95ade0a38d9b42b2b46e0571db35e168--7d177576833946a39044855cbf577fa1 7573dc958b554e728028f82901dd2701 7d177576833946a39044855cbf577fa1--7573dc958b554e728028f82901dd2701 e55371ae11184e598f712f6a49d68316 7573dc958b554e728028f82901dd2701--e55371ae11184e598f712f6a49d68316 30d08b50738b4f2099e14c5221044e1f e55371ae11184e598f712f6a49d68316--30d08b50738b4f2099e14c5221044e1f 99f721e69c44459f8cdee331c5633988 30d08b50738b4f2099e14c5221044e1f--99f721e69c44459f8cdee331c5633988 0d6e37b53aa447caa616a6e9782dbb7e 99f721e69c44459f8cdee331c5633988--0d6e37b53aa447caa616a6e9782dbb7e 4ed2213461754d79988b25c596473ebf 0d6e37b53aa447caa616a6e9782dbb7e--4ed2213461754d79988b25c596473ebf 8e28675bc19a44a5b5a27f37a6f4eb91 4ed2213461754d79988b25c596473ebf--8e28675bc19a44a5b5a27f37a6f4eb91 81f5de968bc24f8db42e47d75ed88d2b 8e28675bc19a44a5b5a27f37a6f4eb91--81f5de968bc24f8db42e47d75ed88d2b b6838dccae95406c923b220095a9d1a9 81f5de968bc24f8db42e47d75ed88d2b--b6838dccae95406c923b220095a9d1a9 6499e34dbdc54438a260d36e0eaf5f31 b6838dccae95406c923b220095a9d1a9--6499e34dbdc54438a260d36e0eaf5f31 4789edf7572543208300d8108cea8051 6499e34dbdc54438a260d36e0eaf5f31--4789edf7572543208300d8108cea8051 22ef23bbaabe458b812b278eb39451a9 4789edf7572543208300d8108cea8051--22ef23bbaabe458b812b278eb39451a9 a4095127ff384faab07d154f8ed9d594 22ef23bbaabe458b812b278eb39451a9--a4095127ff384faab07d154f8ed9d594 ef9dee3f60e84097ac375d0e4088ea1f a4095127ff384faab07d154f8ed9d594--ef9dee3f60e84097ac375d0e4088ea1f 9aaee1236d684dbba37a9317ff4bb6cd ef9dee3f60e84097ac375d0e4088ea1f--9aaee1236d684dbba37a9317ff4bb6cd d48a829c69dc4f6fb2e27ce2d476f3d9 9aaee1236d684dbba37a9317ff4bb6cd--d48a829c69dc4f6fb2e27ce2d476f3d9 73a2bbbad0374935aecb225289dd9cf4 d48a829c69dc4f6fb2e27ce2d476f3d9--73a2bbbad0374935aecb225289dd9cf4 baa67710527b4316a7211c73344838ef 73a2bbbad0374935aecb225289dd9cf4--baa67710527b4316a7211c73344838ef 28ea40ff748449ad867b67676d73a39a baa67710527b4316a7211c73344838ef--28ea40ff748449ad867b67676d73a39a c44491922247456eb889974465dd84bd 28ea40ff748449ad867b67676d73a39a--c44491922247456eb889974465dd84bd 04fa242d1c354541b02d5df4358f090a c44491922247456eb889974465dd84bd--04fa242d1c354541b02d5df4358f090a 4e2e0029113947e99480f9f0b368c298 04fa242d1c354541b02d5df4358f090a--4e2e0029113947e99480f9f0b368c298 9ac127b66b214a8ea6d911cd9c30525d 4e2e0029113947e99480f9f0b368c298--9ac127b66b214a8ea6d911cd9c30525d 79ca35a19e39455e87c31e2cbdcd7da0 9ac127b66b214a8ea6d911cd9c30525d--79ca35a19e39455e87c31e2cbdcd7da0 bf2bf4ca1bf1408e9304f59ad1290888 79ca35a19e39455e87c31e2cbdcd7da0--bf2bf4ca1bf1408e9304f59ad1290888 192c29f8b5b24384af233b5e28d44f8e bf2bf4ca1bf1408e9304f59ad1290888--192c29f8b5b24384af233b5e28d44f8e b0a78e0f7fef438180a5f252f095f95b 192c29f8b5b24384af233b5e28d44f8e--b0a78e0f7fef438180a5f252f095f95b 49374f13988443c8a4078cdb90ef55cf b0a78e0f7fef438180a5f252f095f95b--49374f13988443c8a4078cdb90ef55cf 91f872cd0fcd4ac093c36b2f9eff83b1 49374f13988443c8a4078cdb90ef55cf--91f872cd0fcd4ac093c36b2f9eff83b1 ab3809c1a9e84abfa6c249892f9db0a0 91f872cd0fcd4ac093c36b2f9eff83b1--ab3809c1a9e84abfa6c249892f9db0a0 b741e371cb7e4e29b4f7c81c86e9956a ab3809c1a9e84abfa6c249892f9db0a0--b741e371cb7e4e29b4f7c81c86e9956a 9e683353e3b748c3a36351106c335dbd b741e371cb7e4e29b4f7c81c86e9956a--9e683353e3b748c3a36351106c335dbd e18b12ca4d06403da5d438767a28e0e5 9e683353e3b748c3a36351106c335dbd--e18b12ca4d06403da5d438767a28e0e5 0c69ec51f5da447c90d4bc8a5c10db80 e18b12ca4d06403da5d438767a28e0e5--0c69ec51f5da447c90d4bc8a5c10db80 4156578eea5048fa9cd3c5afd02a2caf 0c69ec51f5da447c90d4bc8a5c10db80--4156578eea5048fa9cd3c5afd02a2caf cfc24c430b8c4610ac53dc581741f605 4156578eea5048fa9cd3c5afd02a2caf--cfc24c430b8c4610ac53dc581741f605 6a856763da584c21bc2e603695de6243 cfc24c430b8c4610ac53dc581741f605--6a856763da584c21bc2e603695de6243 6f909f87a4174204ad6cd31bebcc1cf1 6a856763da584c21bc2e603695de6243--6f909f87a4174204ad6cd31bebcc1cf1 6b6ab3a363014cd3bc24ce5b6149491a 6f909f87a4174204ad6cd31bebcc1cf1--6b6ab3a363014cd3bc24ce5b6149491a b52a2c8a9bf54fe096da29112469d544 6b6ab3a363014cd3bc24ce5b6149491a--b52a2c8a9bf54fe096da29112469d544 a4261925f3b14d96920cf0afdf016782 b52a2c8a9bf54fe096da29112469d544--a4261925f3b14d96920cf0afdf016782 bb00601576a0441f82982ccfcbbdd612 a4261925f3b14d96920cf0afdf016782--bb00601576a0441f82982ccfcbbdd612 cdeacd5746f44673964120e8ba0ee082 bb00601576a0441f82982ccfcbbdd612--cdeacd5746f44673964120e8ba0ee082 1e86d0f7728e49bb937bcbe2eb2c40c8 cdeacd5746f44673964120e8ba0ee082--1e86d0f7728e49bb937bcbe2eb2c40c8 e1685a219011405a93566481d5c038af 1e86d0f7728e49bb937bcbe2eb2c40c8--e1685a219011405a93566481d5c038af 8c6f586261f54b139911278559693d0a e1685a219011405a93566481d5c038af--8c6f586261f54b139911278559693d0a 5c4e7725de06402cae251577cb67cf51 8c6f586261f54b139911278559693d0a--5c4e7725de06402cae251577cb67cf51 a31f0a629fc648248819324a9b7dee58 5c4e7725de06402cae251577cb67cf51--a31f0a629fc648248819324a9b7dee58 3ba5472ab4444f16bdf2b8c3f4c2fdd0 a31f0a629fc648248819324a9b7dee58--3ba5472ab4444f16bdf2b8c3f4c2fdd0 52ce291053bd4a5a81a655de2c315026 3ba5472ab4444f16bdf2b8c3f4c2fdd0--52ce291053bd4a5a81a655de2c315026 d1377b66366645808a696704253c9ad7 52ce291053bd4a5a81a655de2c315026--d1377b66366645808a696704253c9ad7 7c17e29393cb42599cb89fe55fc2a995 d1377b66366645808a696704253c9ad7--7c17e29393cb42599cb89fe55fc2a995 f1c3995b5bd54298aaf07d3d9261c0f3 7c17e29393cb42599cb89fe55fc2a995--f1c3995b5bd54298aaf07d3d9261c0f3 4df3d0308e084992a4c83b0d85fe315a f1c3995b5bd54298aaf07d3d9261c0f3--4df3d0308e084992a4c83b0d85fe315a f3c47e64c57d47d59fd5cf3d98957caf 4df3d0308e084992a4c83b0d85fe315a--f3c47e64c57d47d59fd5cf3d98957caf 6dab749315e3433faafb9ca42ec3cff0 f3c47e64c57d47d59fd5cf3d98957caf--6dab749315e3433faafb9ca42ec3cff0 d625423e5b194e07adfafcc15b46bdff 6dab749315e3433faafb9ca42ec3cff0--d625423e5b194e07adfafcc15b46bdff af93be675a0e4759bde048abc3544420 d625423e5b194e07adfafcc15b46bdff--af93be675a0e4759bde048abc3544420 46e75e014b3b490fb74d3de7e0a9d024 af93be675a0e4759bde048abc3544420--46e75e014b3b490fb74d3de7e0a9d024 1cffbcf3815b4b929fe49254518f8cb9 46e75e014b3b490fb74d3de7e0a9d024--1cffbcf3815b4b929fe49254518f8cb9 ce28e6dab3a043dd81fde63774bcc855 1cffbcf3815b4b929fe49254518f8cb9--ce28e6dab3a043dd81fde63774bcc855 5c82834cbe2e4b11b10977701dbc23e7 ce28e6dab3a043dd81fde63774bcc855--5c82834cbe2e4b11b10977701dbc23e7 30ba96eb815348138613d4b340d442a6 5c82834cbe2e4b11b10977701dbc23e7--30ba96eb815348138613d4b340d442a6 b38db563f4794480ab2e0ac5d40426f3 30ba96eb815348138613d4b340d442a6--b38db563f4794480ab2e0ac5d40426f3 7510ea70b4e34b139002ef87510780b1 b38db563f4794480ab2e0ac5d40426f3--7510ea70b4e34b139002ef87510780b1 621af15174ce49098f084e2a27582dc9 7510ea70b4e34b139002ef87510780b1--621af15174ce49098f084e2a27582dc9 ae8be3c3e8c24e11814fa67229438ff3 621af15174ce49098f084e2a27582dc9--ae8be3c3e8c24e11814fa67229438ff3 acf155f5bf4845eaaebf81cfc653d9a4 ae8be3c3e8c24e11814fa67229438ff3--acf155f5bf4845eaaebf81cfc653d9a4 f6affec925464cd0a75b4187437db6ff acf155f5bf4845eaaebf81cfc653d9a4--f6affec925464cd0a75b4187437db6ff d0b5df2671eb4795b189f36b7885ec0e f6affec925464cd0a75b4187437db6ff--d0b5df2671eb4795b189f36b7885ec0e f6251eae51b54dd29532a4f718dbf018 d0b5df2671eb4795b189f36b7885ec0e--f6251eae51b54dd29532a4f718dbf018 21c0188d23074bfbb4a498c9367d1e25 f6251eae51b54dd29532a4f718dbf018--21c0188d23074bfbb4a498c9367d1e25 cbe37429b1944638a7735475567f61fa 21c0188d23074bfbb4a498c9367d1e25--cbe37429b1944638a7735475567f61fa 6e9a171e3cf745acb3f03fd9144dc770 cbe37429b1944638a7735475567f61fa--6e9a171e3cf745acb3f03fd9144dc770 7ce0f2e1a5844685abae24aae8ee86ec 6e9a171e3cf745acb3f03fd9144dc770--7ce0f2e1a5844685abae24aae8ee86ec f22466d3fb034909a742d42c68c0dee0 7ce0f2e1a5844685abae24aae8ee86ec--f22466d3fb034909a742d42c68c0dee0 53e7156e8ce84171b9b0b18cc340f928 f22466d3fb034909a742d42c68c0dee0--53e7156e8ce84171b9b0b18cc340f928 dde4adc8dff24c70ba6d64790a8c4174 53e7156e8ce84171b9b0b18cc340f928--dde4adc8dff24c70ba6d64790a8c4174 e9dd619838d54631bbf370a1c8ee59e3 dde4adc8dff24c70ba6d64790a8c4174--e9dd619838d54631bbf370a1c8ee59e3 50bf1d80c36742ca959f100b1014835f e9dd619838d54631bbf370a1c8ee59e3--50bf1d80c36742ca959f100b1014835f 72609afe12e845168acba6a6507f4ecb 50bf1d80c36742ca959f100b1014835f--72609afe12e845168acba6a6507f4ecb ad2847e14fdf42ba84f0e299a84b2e5b 72609afe12e845168acba6a6507f4ecb--ad2847e14fdf42ba84f0e299a84b2e5b 67915994f2954fb4b2b1b2c46a90578f RX(b00) ad2847e14fdf42ba84f0e299a84b2e5b--67915994f2954fb4b2b1b2c46a90578f fac090765d514138ba342e0762e41f6c 67915994f2954fb4b2b1b2c46a90578f--fac090765d514138ba342e0762e41f6c 8fbda468b59241b4b582265c675397dd fac090765d514138ba342e0762e41f6c--8fbda468b59241b4b582265c675397dd 7237b946b42a4d6fabf27ced9a66bff4 8fbda468b59241b4b582265c675397dd--7237b946b42a4d6fabf27ced9a66bff4 16f3fb769f424475b6bae21ce40cdc2f 7237b946b42a4d6fabf27ced9a66bff4--16f3fb769f424475b6bae21ce40cdc2f 5f6d8b2e219b48ce94e679bb4217e1a8 16f3fb769f424475b6bae21ce40cdc2f--5f6d8b2e219b48ce94e679bb4217e1a8 3a4f31265c0d4ea489188fcf0e661dfb 5f6d8b2e219b48ce94e679bb4217e1a8--3a4f31265c0d4ea489188fcf0e661dfb 187b3d31a07246709872ece419ae0c0b 3a4f31265c0d4ea489188fcf0e661dfb--187b3d31a07246709872ece419ae0c0b b268de56b9f243339aa55be39528ec6f 187b3d31a07246709872ece419ae0c0b--b268de56b9f243339aa55be39528ec6f 113b64ba71c44deba96d95f38bc55a77 b268de56b9f243339aa55be39528ec6f--113b64ba71c44deba96d95f38bc55a77 bc270921d15344228537ad42d1b9de72 113b64ba71c44deba96d95f38bc55a77--bc270921d15344228537ad42d1b9de72 69bfea8b0cb94d13b756c83234736b2e bc270921d15344228537ad42d1b9de72--69bfea8b0cb94d13b756c83234736b2e 3de4b39e1fd74092afed352b53b1eda4 69bfea8b0cb94d13b756c83234736b2e--3de4b39e1fd74092afed352b53b1eda4 32db3ce7341e49b5973746e77f26a0ae 3de4b39e1fd74092afed352b53b1eda4--32db3ce7341e49b5973746e77f26a0ae 537823d279a6413b8683ec766755f834 32db3ce7341e49b5973746e77f26a0ae--537823d279a6413b8683ec766755f834 99b20adebbe64db69225f64e192215e1 537823d279a6413b8683ec766755f834--99b20adebbe64db69225f64e192215e1 caeb5398b945491086416402644e44a7 99b20adebbe64db69225f64e192215e1--caeb5398b945491086416402644e44a7 e279d0d4295e403382a448bd55ed2a04 caeb5398b945491086416402644e44a7--e279d0d4295e403382a448bd55ed2a04 5a481f39b86146b69eaacdcb96be791f e279d0d4295e403382a448bd55ed2a04--5a481f39b86146b69eaacdcb96be791f 22a99f15eeb4411db825c84185dedb10 5a481f39b86146b69eaacdcb96be791f--22a99f15eeb4411db825c84185dedb10 aae07b046cef4500b7f9d882c6f3250f 22a99f15eeb4411db825c84185dedb10--aae07b046cef4500b7f9d882c6f3250f 8ed67316772f4fd3b94a744173c6c2d1 aae07b046cef4500b7f9d882c6f3250f--8ed67316772f4fd3b94a744173c6c2d1 d79490e49f2b45e69d30936f047ec260 8ed67316772f4fd3b94a744173c6c2d1--d79490e49f2b45e69d30936f047ec260 76a42d57ac924049b2114be1cf2e7d11 d79490e49f2b45e69d30936f047ec260--76a42d57ac924049b2114be1cf2e7d11 daef2a76839a457b80543592c3ca86f7 76a42d57ac924049b2114be1cf2e7d11--daef2a76839a457b80543592c3ca86f7 775faa043f684b60ace1232b55e6b80b daef2a76839a457b80543592c3ca86f7--775faa043f684b60ace1232b55e6b80b 552f2f4b3d73471f8ad3a85e1f64e4f2 775faa043f684b60ace1232b55e6b80b--552f2f4b3d73471f8ad3a85e1f64e4f2 a3ab20f29c8b4f1b9a099d00b5bcd5c0 552f2f4b3d73471f8ad3a85e1f64e4f2--a3ab20f29c8b4f1b9a099d00b5bcd5c0 8d3f8965ca164452aabebcfd20fdb607 a3ab20f29c8b4f1b9a099d00b5bcd5c0--8d3f8965ca164452aabebcfd20fdb607 7f2a62c148f44087855a104af52a6046 8d3f8965ca164452aabebcfd20fdb607--7f2a62c148f44087855a104af52a6046 d84cff37da6b48fabfc320b64dc330aa 7f2a62c148f44087855a104af52a6046--d84cff37da6b48fabfc320b64dc330aa 59f6b7b104fa46beb2a2c06f0d41e9ce d84cff37da6b48fabfc320b64dc330aa--59f6b7b104fa46beb2a2c06f0d41e9ce e6b0c8b49a2c43b090321aa71b691590 59f6b7b104fa46beb2a2c06f0d41e9ce--e6b0c8b49a2c43b090321aa71b691590 77ed0687bfe74092b8e8f7da8bce5890 e6b0c8b49a2c43b090321aa71b691590--77ed0687bfe74092b8e8f7da8bce5890 bc3f4288729645d2a9624ffecdb7df58 77ed0687bfe74092b8e8f7da8bce5890--bc3f4288729645d2a9624ffecdb7df58 661d4b5a28ee4ba6a09dbea983c9f718 bc3f4288729645d2a9624ffecdb7df58--661d4b5a28ee4ba6a09dbea983c9f718 55c636929f8840da910a3fe81a09a4c2 661d4b5a28ee4ba6a09dbea983c9f718--55c636929f8840da910a3fe81a09a4c2 df7f38d25bc2487488d6cbc337444c86 55c636929f8840da910a3fe81a09a4c2--df7f38d25bc2487488d6cbc337444c86 63833b7572954047b0e6fb74b850a771 df7f38d25bc2487488d6cbc337444c86--63833b7572954047b0e6fb74b850a771 314ae5d0e9944a3987a1c9f32648baf3 63833b7572954047b0e6fb74b850a771--314ae5d0e9944a3987a1c9f32648baf3 51e76aac58e047b89a73a5e963b43a44 314ae5d0e9944a3987a1c9f32648baf3--51e76aac58e047b89a73a5e963b43a44 4aa712cee91e4dcc8122711c96c6907b 51e76aac58e047b89a73a5e963b43a44--4aa712cee91e4dcc8122711c96c6907b 71f36bac4df442abb65b24a40ce1fd75 4aa712cee91e4dcc8122711c96c6907b--71f36bac4df442abb65b24a40ce1fd75 76383738de0b4fc4b415471c16877175 71f36bac4df442abb65b24a40ce1fd75--76383738de0b4fc4b415471c16877175 3fcaa32a42ff480092374270dc2d1891 76383738de0b4fc4b415471c16877175--3fcaa32a42ff480092374270dc2d1891 1ddc502820b24a08986493b70a723cb8 3fcaa32a42ff480092374270dc2d1891--1ddc502820b24a08986493b70a723cb8 f9ef32b0d954430ba4b96139cc807802 1ddc502820b24a08986493b70a723cb8--f9ef32b0d954430ba4b96139cc807802 8bcdf9c673f04bdd8d61376095e8a24f f9ef32b0d954430ba4b96139cc807802--8bcdf9c673f04bdd8d61376095e8a24f 390ae70c15244b4c946bc7b16f3d74f7 8bcdf9c673f04bdd8d61376095e8a24f--390ae70c15244b4c946bc7b16f3d74f7 758dd3851555444c9350d5903cd88d5d 390ae70c15244b4c946bc7b16f3d74f7--758dd3851555444c9350d5903cd88d5d 828552a28ba9403ca3a15e0aa60b1501 758dd3851555444c9350d5903cd88d5d--828552a28ba9403ca3a15e0aa60b1501 5901643e665043ceafb5f9f75387d29d 828552a28ba9403ca3a15e0aa60b1501--5901643e665043ceafb5f9f75387d29d 67ac1263e9d44f80be960fb665e210fe 5901643e665043ceafb5f9f75387d29d--67ac1263e9d44f80be960fb665e210fe 42e6eb033e6744feac93f910bed8d6b0 67ac1263e9d44f80be960fb665e210fe--42e6eb033e6744feac93f910bed8d6b0 857c6e9983d94ff8a5d40861bacf932b 42e6eb033e6744feac93f910bed8d6b0--857c6e9983d94ff8a5d40861bacf932b 9a169d01d14148f99e5beedfd6855a2e 857c6e9983d94ff8a5d40861bacf932b--9a169d01d14148f99e5beedfd6855a2e e43709713e28488c8b30766746607365 9a169d01d14148f99e5beedfd6855a2e--e43709713e28488c8b30766746607365 7cf5d070ccad4c51a2413726919b04fe e43709713e28488c8b30766746607365--7cf5d070ccad4c51a2413726919b04fe 9dcd41f8578f4af785711747459643ff 7cf5d070ccad4c51a2413726919b04fe--9dcd41f8578f4af785711747459643ff e5d56287bad345b7a49ab87aef61fa36 9dcd41f8578f4af785711747459643ff--e5d56287bad345b7a49ab87aef61fa36 204ef70f834045adaaa51c667ac5c17d e5d56287bad345b7a49ab87aef61fa36--204ef70f834045adaaa51c667ac5c17d 97b7ec62ecd244b9bc12bc1eb9178316 204ef70f834045adaaa51c667ac5c17d--97b7ec62ecd244b9bc12bc1eb9178316 630e9c7346a741d4917c1f7b6b02ec6b 97b7ec62ecd244b9bc12bc1eb9178316--630e9c7346a741d4917c1f7b6b02ec6b 603252ec531240129aa419fece567e42 630e9c7346a741d4917c1f7b6b02ec6b--603252ec531240129aa419fece567e42 ead36b5a5dca4dc5b488b44868f8f321 603252ec531240129aa419fece567e42--ead36b5a5dca4dc5b488b44868f8f321 c99e981ad36a42ab8076ca11b2f71ea3 ead36b5a5dca4dc5b488b44868f8f321--c99e981ad36a42ab8076ca11b2f71ea3 a17a6c24e4fc4b6dbfa9bdca1d37a74f c99e981ad36a42ab8076ca11b2f71ea3--a17a6c24e4fc4b6dbfa9bdca1d37a74f d072943b579a474d9ec3e0244e5338ba a17a6c24e4fc4b6dbfa9bdca1d37a74f--d072943b579a474d9ec3e0244e5338ba 1dd26c9cd8424809a6c7ca9be6b72eb0 d072943b579a474d9ec3e0244e5338ba--1dd26c9cd8424809a6c7ca9be6b72eb0 69986babd73f49959257e51f9610ed4e 1dd26c9cd8424809a6c7ca9be6b72eb0--69986babd73f49959257e51f9610ed4e db5105a86a8d4abeb061f16cdcd8637d 69986babd73f49959257e51f9610ed4e--db5105a86a8d4abeb061f16cdcd8637d 7cf280cc807f4f07b08f71764ca36521 db5105a86a8d4abeb061f16cdcd8637d--7cf280cc807f4f07b08f71764ca36521 129c1f4e7b0b48c68412c0735f3f7b6d 7cf280cc807f4f07b08f71764ca36521--129c1f4e7b0b48c68412c0735f3f7b6d 4b98dd71e05b4dd683619e181d5bcff2 129c1f4e7b0b48c68412c0735f3f7b6d--4b98dd71e05b4dd683619e181d5bcff2 d9d76aaf55f74ed197d55defd8b6a61e 4b98dd71e05b4dd683619e181d5bcff2--d9d76aaf55f74ed197d55defd8b6a61e 186d4572e5d641a0b6035fa37e610c5a d9d76aaf55f74ed197d55defd8b6a61e--186d4572e5d641a0b6035fa37e610c5a 1af75b86ffd443a194466b4ae4bd45b1 186d4572e5d641a0b6035fa37e610c5a--1af75b86ffd443a194466b4ae4bd45b1 4532e9ede5fe423c96b8177075d75775 1af75b86ffd443a194466b4ae4bd45b1--4532e9ede5fe423c96b8177075d75775 dcbda2d858d449639a3d060de1aaaeb3 4532e9ede5fe423c96b8177075d75775--dcbda2d858d449639a3d060de1aaaeb3 7c638ef080864af9905088988dca4c47 dcbda2d858d449639a3d060de1aaaeb3--7c638ef080864af9905088988dca4c47 339ec99e857c4f5db1b682feff76b610 7c638ef080864af9905088988dca4c47--339ec99e857c4f5db1b682feff76b610 6ff2d85e3472431db4a67512d540330e 339ec99e857c4f5db1b682feff76b610--6ff2d85e3472431db4a67512d540330e 6374544b9eea4283a67dde9838ac8a44 6ff2d85e3472431db4a67512d540330e--6374544b9eea4283a67dde9838ac8a44 451d21a02b9b4579a584499ae04c1025 6374544b9eea4283a67dde9838ac8a44--451d21a02b9b4579a584499ae04c1025 4dc93f325ab644a09c12bc3e894f466a 451d21a02b9b4579a584499ae04c1025--4dc93f325ab644a09c12bc3e894f466a c5da4654ecbf4d3388ddaebc1fe9a8b5 4dc93f325ab644a09c12bc3e894f466a--c5da4654ecbf4d3388ddaebc1fe9a8b5 7352c48cc45e42c9b4bcdfe1f4541055 c5da4654ecbf4d3388ddaebc1fe9a8b5--7352c48cc45e42c9b4bcdfe1f4541055 a42247bce3eb4ab8abdc3a722bbed926 7352c48cc45e42c9b4bcdfe1f4541055--a42247bce3eb4ab8abdc3a722bbed926 d90fd1c77f8941768cf58ecb980da6a6 a42247bce3eb4ab8abdc3a722bbed926--d90fd1c77f8941768cf58ecb980da6a6 fe90576fabaf408caee4b303bcf64cd9 d90fd1c77f8941768cf58ecb980da6a6--fe90576fabaf408caee4b303bcf64cd9 47afa035db3c49b8b21d31a3f78c9b09 fe90576fabaf408caee4b303bcf64cd9--47afa035db3c49b8b21d31a3f78c9b09 95778fe5909847e1b475c5546b0931c8 47afa035db3c49b8b21d31a3f78c9b09--95778fe5909847e1b475c5546b0931c8 d3406600daa74d078c4ca46758133bec 95778fe5909847e1b475c5546b0931c8--d3406600daa74d078c4ca46758133bec 4ed90439e26f47a791eea64b32aa65b9 d3406600daa74d078c4ca46758133bec--4ed90439e26f47a791eea64b32aa65b9 29aa78ade39c4ba4890bb3d8b04b1840 4ed90439e26f47a791eea64b32aa65b9--29aa78ade39c4ba4890bb3d8b04b1840 3922ecc99d8a4d1c936478189b8e9b72 29aa78ade39c4ba4890bb3d8b04b1840--3922ecc99d8a4d1c936478189b8e9b72 ea541473f8ae40089f74aa8eca936753 3922ecc99d8a4d1c936478189b8e9b72--ea541473f8ae40089f74aa8eca936753 23afbc6728a24690b9fe31e6da6064e9 ea541473f8ae40089f74aa8eca936753--23afbc6728a24690b9fe31e6da6064e9 592b3f65c0d245a29ec43ea8b3b2bf15 23afbc6728a24690b9fe31e6da6064e9--592b3f65c0d245a29ec43ea8b3b2bf15 fea10986129849df80acdb2e39d5a551 592b3f65c0d245a29ec43ea8b3b2bf15--fea10986129849df80acdb2e39d5a551 51d67a8a58284b00955dffd17b38cbb6 fea10986129849df80acdb2e39d5a551--51d67a8a58284b00955dffd17b38cbb6 6936bd1bba9645918f3a6701410d3d0b 51d67a8a58284b00955dffd17b38cbb6--6936bd1bba9645918f3a6701410d3d0b 7065fff6eb21464ca9f40a502b60aaed 6936bd1bba9645918f3a6701410d3d0b--7065fff6eb21464ca9f40a502b60aaed d9170e11eb554a4592590695d62a68ff 7065fff6eb21464ca9f40a502b60aaed--d9170e11eb554a4592590695d62a68ff 23e4aefe23cf4b08983638f4e953dd4e d9170e11eb554a4592590695d62a68ff--23e4aefe23cf4b08983638f4e953dd4e 9fdddb98067e46249a77b99d2eaac990 23e4aefe23cf4b08983638f4e953dd4e--9fdddb98067e46249a77b99d2eaac990 18ce99bce9ed4c3eac2100df36a2d44d 9fdddb98067e46249a77b99d2eaac990--18ce99bce9ed4c3eac2100df36a2d44d 0440d664c4f4478c86bbfc0edbd7d8b5 18ce99bce9ed4c3eac2100df36a2d44d--0440d664c4f4478c86bbfc0edbd7d8b5 dbc7504a4b60440184e66f42de0c42de 0440d664c4f4478c86bbfc0edbd7d8b5--dbc7504a4b60440184e66f42de0c42de e4ac6b4209584bb4972792b062f62daa dbc7504a4b60440184e66f42de0c42de--e4ac6b4209584bb4972792b062f62daa 5169da6cd029402d899ea0e1ae94975f e4ac6b4209584bb4972792b062f62daa--5169da6cd029402d899ea0e1ae94975f f8c27cb74f5b4558ae21d6307f74f73d 5169da6cd029402d899ea0e1ae94975f--f8c27cb74f5b4558ae21d6307f74f73d 067cd6a10127409faad2406ebc7229e2 f8c27cb74f5b4558ae21d6307f74f73d--067cd6a10127409faad2406ebc7229e2 869a5c796599407daecf4f43f17cd1d8 067cd6a10127409faad2406ebc7229e2--869a5c796599407daecf4f43f17cd1d8 f399ac8cbf084fc5b6ceb1f369850fed 869a5c796599407daecf4f43f17cd1d8--f399ac8cbf084fc5b6ceb1f369850fed 74f3ae96ec1e41928d9fc2075b7fdc03 f399ac8cbf084fc5b6ceb1f369850fed--74f3ae96ec1e41928d9fc2075b7fdc03 8f875d4da6f14fdb950cf173efec7d57 74f3ae96ec1e41928d9fc2075b7fdc03--8f875d4da6f14fdb950cf173efec7d57 04f45f6b3ab44b17bb2971f479717d87 8f875d4da6f14fdb950cf173efec7d57--04f45f6b3ab44b17bb2971f479717d87 2dfa4afee7984df1879e10a356093bd4 04f45f6b3ab44b17bb2971f479717d87--2dfa4afee7984df1879e10a356093bd4 65f1c40b2727494b81954e4016a512b1 2dfa4afee7984df1879e10a356093bd4--65f1c40b2727494b81954e4016a512b1 7642ffae800b416dba7ae5a0b7580e6a 65f1c40b2727494b81954e4016a512b1--7642ffae800b416dba7ae5a0b7580e6a d9403eb07f6b47698c0775877d88a227 7642ffae800b416dba7ae5a0b7580e6a--d9403eb07f6b47698c0775877d88a227 bd4aea5bc4eb46aaba6c77804066f1ae d9403eb07f6b47698c0775877d88a227--bd4aea5bc4eb46aaba6c77804066f1ae d7a5f19689424197953d048dae721f3f bd4aea5bc4eb46aaba6c77804066f1ae--d7a5f19689424197953d048dae721f3f a27c09c54daf4c4f835af60101c637cd d7a5f19689424197953d048dae721f3f--a27c09c54daf4c4f835af60101c637cd 5e1a918db8ec45deb38435a2b014e6b0 a27c09c54daf4c4f835af60101c637cd--5e1a918db8ec45deb38435a2b014e6b0 c02635a450db48d7b918cd1f0973f936 5e1a918db8ec45deb38435a2b014e6b0--c02635a450db48d7b918cd1f0973f936 6e19a31c26f44808925a46294ba5ca1e c02635a450db48d7b918cd1f0973f936--6e19a31c26f44808925a46294ba5ca1e 1e799ff6034748e4adc5185809ad18e2 6e19a31c26f44808925a46294ba5ca1e--1e799ff6034748e4adc5185809ad18e2 d90efd1590194999a1a39cfe7d9df40e 1e799ff6034748e4adc5185809ad18e2--d90efd1590194999a1a39cfe7d9df40e 8d5e26d6784c4c639c068271fbfc7f20 d90efd1590194999a1a39cfe7d9df40e--8d5e26d6784c4c639c068271fbfc7f20 c0d5a508d7334364a36c5b2ffe143ffe 8d5e26d6784c4c639c068271fbfc7f20--c0d5a508d7334364a36c5b2ffe143ffe a375de9690f04db1a10b6b4c20226848 c0d5a508d7334364a36c5b2ffe143ffe--a375de9690f04db1a10b6b4c20226848 6ba72d1dda70428cb86c6fd53fb23891 a375de9690f04db1a10b6b4c20226848--6ba72d1dda70428cb86c6fd53fb23891 3494725883944a90b7221b90a754a626 6ba72d1dda70428cb86c6fd53fb23891--3494725883944a90b7221b90a754a626 a57a6d087959431ab2b55adc0452cc2c 3494725883944a90b7221b90a754a626--a57a6d087959431ab2b55adc0452cc2c dee788b555cc4bedb83fd1e50f1b2d5e a57a6d087959431ab2b55adc0452cc2c--dee788b555cc4bedb83fd1e50f1b2d5e 99b509ead0ef4adb808ba27294ca1410 dee788b555cc4bedb83fd1e50f1b2d5e--99b509ead0ef4adb808ba27294ca1410 5d8ad794a4404630963fd0b9fb19093e 99b509ead0ef4adb808ba27294ca1410--5d8ad794a4404630963fd0b9fb19093e 0dc7679fafa543dcbb65e51194c5fe26 RX(b10) 5d8ad794a4404630963fd0b9fb19093e--0dc7679fafa543dcbb65e51194c5fe26 1bf3254f06f94131aa1e274402df9733 0dc7679fafa543dcbb65e51194c5fe26--1bf3254f06f94131aa1e274402df9733 39f6963648f34d178118c3aba0324c2a 04b9e8ee66a546b5b9f1a40a58175118 X 99a53e295ed2494fa999a71bf6e53069--04b9e8ee66a546b5b9f1a40a58175118 a2b8da45fe344952b2f373e22db5fe2c 2 04b9e8ee66a546b5b9f1a40a58175118--8d969c619e13466caaebf9c212cb138d 3e64166d24b849b886bdef077b86e1b2 04b9e8ee66a546b5b9f1a40a58175118--3e64166d24b849b886bdef077b86e1b2 a379096372e64fb281456d917613a30f 3e64166d24b849b886bdef077b86e1b2--a379096372e64fb281456d917613a30f 7cdc1a54a2564992bfe8469f89666e47 a379096372e64fb281456d917613a30f--7cdc1a54a2564992bfe8469f89666e47 5925008ce1804457b2d31040155a9205 7cdc1a54a2564992bfe8469f89666e47--5925008ce1804457b2d31040155a9205 992018f429c14a5bae1a371e8c3146f0 5925008ce1804457b2d31040155a9205--992018f429c14a5bae1a371e8c3146f0 22781e9bef174b3abd8cde11f74838c9 992018f429c14a5bae1a371e8c3146f0--22781e9bef174b3abd8cde11f74838c9 fd3f449b73304ead8d7dfad87c1436f8 22781e9bef174b3abd8cde11f74838c9--fd3f449b73304ead8d7dfad87c1436f8 943e2cdc12aa43ab978e2d284d4e8880 fd3f449b73304ead8d7dfad87c1436f8--943e2cdc12aa43ab978e2d284d4e8880 929d61c2b9a94c279b635fd9b72e7c76 943e2cdc12aa43ab978e2d284d4e8880--929d61c2b9a94c279b635fd9b72e7c76 7e9ab8c529904e9ca8d7d58db550a34a 929d61c2b9a94c279b635fd9b72e7c76--7e9ab8c529904e9ca8d7d58db550a34a 76b1acaadcf7438ca6b9472d41c0f80a 7e9ab8c529904e9ca8d7d58db550a34a--76b1acaadcf7438ca6b9472d41c0f80a 05a6bc0660ed44feb8b811baca4f24c9 76b1acaadcf7438ca6b9472d41c0f80a--05a6bc0660ed44feb8b811baca4f24c9 a01a3787b27749639f3f2f1344a66b43 05a6bc0660ed44feb8b811baca4f24c9--a01a3787b27749639f3f2f1344a66b43 f3737e3a47e84d5f88c117772a7218e3 X a01a3787b27749639f3f2f1344a66b43--f3737e3a47e84d5f88c117772a7218e3 f3737e3a47e84d5f88c117772a7218e3--848edb94b2ac433ba2873df799c992b4 88a4d64437524b1c999a7fa4edb63c56 X f3737e3a47e84d5f88c117772a7218e3--88a4d64437524b1c999a7fa4edb63c56 88a4d64437524b1c999a7fa4edb63c56--e1382e133fd643ae9aad529aa6458849 d39663f226344445a6df53a124feaca5 RZ(-1.0*g0) 88a4d64437524b1c999a7fa4edb63c56--d39663f226344445a6df53a124feaca5 c30db05e61274003b7c60b3df1a09a79 X d39663f226344445a6df53a124feaca5--c30db05e61274003b7c60b3df1a09a79 c30db05e61274003b7c60b3df1a09a79--acddcd90f9224cc69507fac31bda1230 750c555c94df406a83700d1b8da09d8e X c30db05e61274003b7c60b3df1a09a79--750c555c94df406a83700d1b8da09d8e 750c555c94df406a83700d1b8da09d8e--589d030eadda4ac8b1c8c09690906cd3 0b964dfccadd4be9b62443606a62dd64 750c555c94df406a83700d1b8da09d8e--0b964dfccadd4be9b62443606a62dd64 74c9136c55e74bea9d2e4f5a99ad63fd 0b964dfccadd4be9b62443606a62dd64--74c9136c55e74bea9d2e4f5a99ad63fd 3b560206c8b542cd8124af248e02b71c 74c9136c55e74bea9d2e4f5a99ad63fd--3b560206c8b542cd8124af248e02b71c 7e39f23d9a1b43b2857d8c84416d4000 X 3b560206c8b542cd8124af248e02b71c--7e39f23d9a1b43b2857d8c84416d4000 7e39f23d9a1b43b2857d8c84416d4000--0ed3009978c041969fb72163b713e19b 6bf0e314a1474a5486e51c0a9ff2cf07 X 7e39f23d9a1b43b2857d8c84416d4000--6bf0e314a1474a5486e51c0a9ff2cf07 6bf0e314a1474a5486e51c0a9ff2cf07--789319a6793043ad89ca006aa8f46432 bb661f2865d849c1b130146c5e740323 6bf0e314a1474a5486e51c0a9ff2cf07--bb661f2865d849c1b130146c5e740323 8090d7d8849348fd823ac23400886eb4 bb661f2865d849c1b130146c5e740323--8090d7d8849348fd823ac23400886eb4 d8cc56586c424d3097887fdc9b2c6e88 8090d7d8849348fd823ac23400886eb4--d8cc56586c424d3097887fdc9b2c6e88 1dfa907385064e2881dc2893d0f3dc67 d8cc56586c424d3097887fdc9b2c6e88--1dfa907385064e2881dc2893d0f3dc67 6ddaa951909043eaaa4b6f88f51869fb 1dfa907385064e2881dc2893d0f3dc67--6ddaa951909043eaaa4b6f88f51869fb 0b47936147c24b589b8b4e470ac4245d 6ddaa951909043eaaa4b6f88f51869fb--0b47936147c24b589b8b4e470ac4245d 13775cd241ba444b85e831cecfbe0101 0b47936147c24b589b8b4e470ac4245d--13775cd241ba444b85e831cecfbe0101 0666ea1745ad4e5885ef2b0acd1f45c3 X 13775cd241ba444b85e831cecfbe0101--0666ea1745ad4e5885ef2b0acd1f45c3 0666ea1745ad4e5885ef2b0acd1f45c3--dc1de928ccab4d3092b9f87cf77c9b3f 2c2bebc5070d4c3cb85d2ec0e9bc57c3 X 0666ea1745ad4e5885ef2b0acd1f45c3--2c2bebc5070d4c3cb85d2ec0e9bc57c3 2c2bebc5070d4c3cb85d2ec0e9bc57c3--a78fd2f3507a4e8896e752a021acdb39 6c6e223e1d6d4ff2b42ca662618d87bd 2c2bebc5070d4c3cb85d2ec0e9bc57c3--6c6e223e1d6d4ff2b42ca662618d87bd c3cb931521024be3bf155022e46e8b6e 6c6e223e1d6d4ff2b42ca662618d87bd--c3cb931521024be3bf155022e46e8b6e 043ebc266bf14702a51760cc5bdbbe66 c3cb931521024be3bf155022e46e8b6e--043ebc266bf14702a51760cc5bdbbe66 44f6c71ea292472d85b2c086e013599f 043ebc266bf14702a51760cc5bdbbe66--44f6c71ea292472d85b2c086e013599f fbf7cc3d30564662868c79765f2d24bb 44f6c71ea292472d85b2c086e013599f--fbf7cc3d30564662868c79765f2d24bb 13b3fccbce7c4035a7fa8d5a53083cb7 fbf7cc3d30564662868c79765f2d24bb--13b3fccbce7c4035a7fa8d5a53083cb7 236429ca5e5a442eaf719247ffd94a19 13b3fccbce7c4035a7fa8d5a53083cb7--236429ca5e5a442eaf719247ffd94a19 a23a2789b17847ceaea267cf7e59bddd 236429ca5e5a442eaf719247ffd94a19--a23a2789b17847ceaea267cf7e59bddd 4e92eb4ec6f3429190f36c3528290b0e a23a2789b17847ceaea267cf7e59bddd--4e92eb4ec6f3429190f36c3528290b0e d60281276dcc40d8987d695dde5a10a0 4e92eb4ec6f3429190f36c3528290b0e--d60281276dcc40d8987d695dde5a10a0 bc5044ef93e0413f8de18f3d93cce775 d60281276dcc40d8987d695dde5a10a0--bc5044ef93e0413f8de18f3d93cce775 a09202dafe3b4bd7988351644f5caaff bc5044ef93e0413f8de18f3d93cce775--a09202dafe3b4bd7988351644f5caaff 61614c628c9842379546e85d0c2e5802 a09202dafe3b4bd7988351644f5caaff--61614c628c9842379546e85d0c2e5802 344306b91d23483799ba6c02ea95ab62 X 61614c628c9842379546e85d0c2e5802--344306b91d23483799ba6c02ea95ab62 344306b91d23483799ba6c02ea95ab62--6201d1c2f9104ec5aeb72bdf220637f6 170c5f690768467f9a071e8661e73f91 344306b91d23483799ba6c02ea95ab62--170c5f690768467f9a071e8661e73f91 589f1efcfbc346a9a2e98c49f3dd1e8a 170c5f690768467f9a071e8661e73f91--589f1efcfbc346a9a2e98c49f3dd1e8a 6572109f63dc42eeafd795b63a462725 589f1efcfbc346a9a2e98c49f3dd1e8a--6572109f63dc42eeafd795b63a462725 120ac8c594aa4b9ca838a0306b138f43 6572109f63dc42eeafd795b63a462725--120ac8c594aa4b9ca838a0306b138f43 00d487e6ad664259b21fe0095ca8e8f5 120ac8c594aa4b9ca838a0306b138f43--00d487e6ad664259b21fe0095ca8e8f5 50f52c33c44f4b2092cc5591ea1d6d4b 00d487e6ad664259b21fe0095ca8e8f5--50f52c33c44f4b2092cc5591ea1d6d4b 39257567c3174bac82ec0927902ace3e 50f52c33c44f4b2092cc5591ea1d6d4b--39257567c3174bac82ec0927902ace3e aa47ce129e1d4a5591e89a714b8ff38c 39257567c3174bac82ec0927902ace3e--aa47ce129e1d4a5591e89a714b8ff38c c1471ad3ad97466ea1bee3e84845c6b6 aa47ce129e1d4a5591e89a714b8ff38c--c1471ad3ad97466ea1bee3e84845c6b6 16ac7b2299384ccf8978d15baaaa4ade c1471ad3ad97466ea1bee3e84845c6b6--16ac7b2299384ccf8978d15baaaa4ade 2727c26b334443bfb1723d23455be37e 16ac7b2299384ccf8978d15baaaa4ade--2727c26b334443bfb1723d23455be37e 6d953219fd244a30a0989cccf3f020a0 2727c26b334443bfb1723d23455be37e--6d953219fd244a30a0989cccf3f020a0 e1dacc08a5dd4c8d982adf30a63f456b 6d953219fd244a30a0989cccf3f020a0--e1dacc08a5dd4c8d982adf30a63f456b 7d02cb801f034fa7a3038945cadb7f94 e1dacc08a5dd4c8d982adf30a63f456b--7d02cb801f034fa7a3038945cadb7f94 4fece24d79044b428aa7e03e7d91cb4c 7d02cb801f034fa7a3038945cadb7f94--4fece24d79044b428aa7e03e7d91cb4c 19f4d94ee95a4e90aa3510680be47182 4fece24d79044b428aa7e03e7d91cb4c--19f4d94ee95a4e90aa3510680be47182 0842e1a4c5064671b545495de768635e 19f4d94ee95a4e90aa3510680be47182--0842e1a4c5064671b545495de768635e 76d2ff6d7f214d1d9d3aca133d564bfd 0842e1a4c5064671b545495de768635e--76d2ff6d7f214d1d9d3aca133d564bfd 07893d694b0349ea89e4146b36dea27c 76d2ff6d7f214d1d9d3aca133d564bfd--07893d694b0349ea89e4146b36dea27c 176d55ff93d143c8a78e08f469730486 07893d694b0349ea89e4146b36dea27c--176d55ff93d143c8a78e08f469730486 7a96eee9936740bf8336e97143a195e4 176d55ff93d143c8a78e08f469730486--7a96eee9936740bf8336e97143a195e4 9f9ccc1f11434f53bcbd812b2ecb9286 7a96eee9936740bf8336e97143a195e4--9f9ccc1f11434f53bcbd812b2ecb9286 d33a0677e2da4d95bd1934939851a34d 9f9ccc1f11434f53bcbd812b2ecb9286--d33a0677e2da4d95bd1934939851a34d 97fab4cfc3e64728892a36866b443273 d33a0677e2da4d95bd1934939851a34d--97fab4cfc3e64728892a36866b443273 673c1841c2524c6792231001ef66762d 97fab4cfc3e64728892a36866b443273--673c1841c2524c6792231001ef66762d 1097e16e309847eda935a3746f905d59 673c1841c2524c6792231001ef66762d--1097e16e309847eda935a3746f905d59 83926ba9c2d84ddb99c6e7618e2414b0 1097e16e309847eda935a3746f905d59--83926ba9c2d84ddb99c6e7618e2414b0 47c89cda1497480dad8f50b35ab4bf7f 83926ba9c2d84ddb99c6e7618e2414b0--47c89cda1497480dad8f50b35ab4bf7f 1bc4a88e8519439792cffd170c90a5b4 47c89cda1497480dad8f50b35ab4bf7f--1bc4a88e8519439792cffd170c90a5b4 2a4f576966624e869d3c6c283bb8f708 1bc4a88e8519439792cffd170c90a5b4--2a4f576966624e869d3c6c283bb8f708 0cb12ead099b42db89e6950123410cde 2a4f576966624e869d3c6c283bb8f708--0cb12ead099b42db89e6950123410cde 3a8cc754a80847d1805ec6a4e7554cf0 0cb12ead099b42db89e6950123410cde--3a8cc754a80847d1805ec6a4e7554cf0 0cfbbf48ad7447bfa26ef5101b4f87ee 3a8cc754a80847d1805ec6a4e7554cf0--0cfbbf48ad7447bfa26ef5101b4f87ee 16b8e82a01bc42ee91e2cbea3f85bf97 0cfbbf48ad7447bfa26ef5101b4f87ee--16b8e82a01bc42ee91e2cbea3f85bf97 49dfe80c8f2a47359b9c39630bd8aa57 16b8e82a01bc42ee91e2cbea3f85bf97--49dfe80c8f2a47359b9c39630bd8aa57 efc4bf7fd4e84b788271dc6898c07310 49dfe80c8f2a47359b9c39630bd8aa57--efc4bf7fd4e84b788271dc6898c07310 9e0e0ab59c8847fe805544b50d6e6054 efc4bf7fd4e84b788271dc6898c07310--9e0e0ab59c8847fe805544b50d6e6054 577b3aa92e6341ba87822b346567c15b 9e0e0ab59c8847fe805544b50d6e6054--577b3aa92e6341ba87822b346567c15b 5ab7f623ae4e4c45bbc7f47c608a83bb 577b3aa92e6341ba87822b346567c15b--5ab7f623ae4e4c45bbc7f47c608a83bb e0a6b047c1c14f5398b2bf387ea0eb36 5ab7f623ae4e4c45bbc7f47c608a83bb--e0a6b047c1c14f5398b2bf387ea0eb36 62d362cfe7944a8ba883e8a73027f34d e0a6b047c1c14f5398b2bf387ea0eb36--62d362cfe7944a8ba883e8a73027f34d 0fef9d13e2584c8b81dead6871968c11 62d362cfe7944a8ba883e8a73027f34d--0fef9d13e2584c8b81dead6871968c11 187f34b6fd3646a9b20e5f34f850d1a6 0fef9d13e2584c8b81dead6871968c11--187f34b6fd3646a9b20e5f34f850d1a6 9d18bafd4ff745f19830f1cced7082da 187f34b6fd3646a9b20e5f34f850d1a6--9d18bafd4ff745f19830f1cced7082da a85dd67dbb0d431ebf051610b6f91296 9d18bafd4ff745f19830f1cced7082da--a85dd67dbb0d431ebf051610b6f91296 adc816115e20450eae367a658b1cccf1 a85dd67dbb0d431ebf051610b6f91296--adc816115e20450eae367a658b1cccf1 76750e7a526f487ca2b15e2d8410d99b adc816115e20450eae367a658b1cccf1--76750e7a526f487ca2b15e2d8410d99b 92ba9630db5b44fb830321ae1a910663 76750e7a526f487ca2b15e2d8410d99b--92ba9630db5b44fb830321ae1a910663 8cd22770ffd242cbb0ec03f311413dc3 92ba9630db5b44fb830321ae1a910663--8cd22770ffd242cbb0ec03f311413dc3 cb5c5c9b89164293bfa9850e876d0fd7 8cd22770ffd242cbb0ec03f311413dc3--cb5c5c9b89164293bfa9850e876d0fd7 c275f17dc02749db8605581f8765ffcf cb5c5c9b89164293bfa9850e876d0fd7--c275f17dc02749db8605581f8765ffcf aa43455ed3984739b4e8d40e7b639ddc c275f17dc02749db8605581f8765ffcf--aa43455ed3984739b4e8d40e7b639ddc 9d83451cbd884ba19a5ee5a214451e83 aa43455ed3984739b4e8d40e7b639ddc--9d83451cbd884ba19a5ee5a214451e83 35ece696c628456b9ce9dc04f276649d 9d83451cbd884ba19a5ee5a214451e83--35ece696c628456b9ce9dc04f276649d 0b69c0a76f064765980a0937ebe6d2d6 35ece696c628456b9ce9dc04f276649d--0b69c0a76f064765980a0937ebe6d2d6 26499ac2cbf24b72988657fc4a8c6abf 0b69c0a76f064765980a0937ebe6d2d6--26499ac2cbf24b72988657fc4a8c6abf 186d0dcb33f540929077b33d7667bfd2 26499ac2cbf24b72988657fc4a8c6abf--186d0dcb33f540929077b33d7667bfd2 9a21cfec6893475a9b152b82e4baf8cc 186d0dcb33f540929077b33d7667bfd2--9a21cfec6893475a9b152b82e4baf8cc b4744270dad149b1897952440d107551 9a21cfec6893475a9b152b82e4baf8cc--b4744270dad149b1897952440d107551 179daa7f5ebd47c09ea574d4c654544d b4744270dad149b1897952440d107551--179daa7f5ebd47c09ea574d4c654544d d6ea26b9132842c49e356412fba50617 179daa7f5ebd47c09ea574d4c654544d--d6ea26b9132842c49e356412fba50617 9301cc87c2464037aa98be9fe8bdcdde d6ea26b9132842c49e356412fba50617--9301cc87c2464037aa98be9fe8bdcdde 5b9cd97fd0884a4d80b3e77235ff0b3c 9301cc87c2464037aa98be9fe8bdcdde--5b9cd97fd0884a4d80b3e77235ff0b3c c64305fa60084868b7f8afba11e8f6d4 5b9cd97fd0884a4d80b3e77235ff0b3c--c64305fa60084868b7f8afba11e8f6d4 eaef5525fa2a4cb69b6de3add522ee06 c64305fa60084868b7f8afba11e8f6d4--eaef5525fa2a4cb69b6de3add522ee06 2e241b39b86c4628be3a7b0afe34a8be eaef5525fa2a4cb69b6de3add522ee06--2e241b39b86c4628be3a7b0afe34a8be 2a27741e77eb4e798328e0bb258e7fe0 2e241b39b86c4628be3a7b0afe34a8be--2a27741e77eb4e798328e0bb258e7fe0 32c5c13e66c64432a99714630ac48565 2a27741e77eb4e798328e0bb258e7fe0--32c5c13e66c64432a99714630ac48565 4e8caa2dd9484fe89e58bfd160014abf 32c5c13e66c64432a99714630ac48565--4e8caa2dd9484fe89e58bfd160014abf 7c42dd362e1741499d59e2478790d2f9 4e8caa2dd9484fe89e58bfd160014abf--7c42dd362e1741499d59e2478790d2f9 0ae2aea5cb4548fb9ba5f0901a1067f1 7c42dd362e1741499d59e2478790d2f9--0ae2aea5cb4548fb9ba5f0901a1067f1 92d6663388c34d449528e8bfcbf5f825 0ae2aea5cb4548fb9ba5f0901a1067f1--92d6663388c34d449528e8bfcbf5f825 2fc33126d677442f87a7c9743c7cd7a3 92d6663388c34d449528e8bfcbf5f825--2fc33126d677442f87a7c9743c7cd7a3 8aea2c1d360d472787d1e0d9aeb6292f 2fc33126d677442f87a7c9743c7cd7a3--8aea2c1d360d472787d1e0d9aeb6292f 1702e3c4111943a280445ace78ded490 8aea2c1d360d472787d1e0d9aeb6292f--1702e3c4111943a280445ace78ded490 978cd958700b4b1dbe6a01d4763c5d1c 1702e3c4111943a280445ace78ded490--978cd958700b4b1dbe6a01d4763c5d1c ced265902d01493d9656f75cc6caaebc 978cd958700b4b1dbe6a01d4763c5d1c--ced265902d01493d9656f75cc6caaebc 6c68a4de1ea6486aa48f94923cb29197 ced265902d01493d9656f75cc6caaebc--6c68a4de1ea6486aa48f94923cb29197 2ae3eb19fcb04506bd91f5112bd40312 6c68a4de1ea6486aa48f94923cb29197--2ae3eb19fcb04506bd91f5112bd40312 caf85b8d5e21409c96ddf663dd57f492 2ae3eb19fcb04506bd91f5112bd40312--caf85b8d5e21409c96ddf663dd57f492 0e7e47fe330c47b78e6c1f2412e2bbb9 caf85b8d5e21409c96ddf663dd57f492--0e7e47fe330c47b78e6c1f2412e2bbb9 e838f9e98311480ea6436bff509a79e2 0e7e47fe330c47b78e6c1f2412e2bbb9--e838f9e98311480ea6436bff509a79e2 9aa4fde1220248b3a21bc7a9c942bc20 e838f9e98311480ea6436bff509a79e2--9aa4fde1220248b3a21bc7a9c942bc20 59b52424e7f04ce5ad5907412f73652f 9aa4fde1220248b3a21bc7a9c942bc20--59b52424e7f04ce5ad5907412f73652f a77da60927f14c54ba9a41301f74d3f1 59b52424e7f04ce5ad5907412f73652f--a77da60927f14c54ba9a41301f74d3f1 ceea6df9a0ad4f758c4d2731b502aa9a a77da60927f14c54ba9a41301f74d3f1--ceea6df9a0ad4f758c4d2731b502aa9a 6018345341f64ace923b68e80a381be7 ceea6df9a0ad4f758c4d2731b502aa9a--6018345341f64ace923b68e80a381be7 b858af68de8e4f96b065e12795c89be8 6018345341f64ace923b68e80a381be7--b858af68de8e4f96b065e12795c89be8 afb728b7e70249c68665a3041a09fe6f b858af68de8e4f96b065e12795c89be8--afb728b7e70249c68665a3041a09fe6f 2d0d14cd31cd4d8da8e3e9a1ad608d78 afb728b7e70249c68665a3041a09fe6f--2d0d14cd31cd4d8da8e3e9a1ad608d78 134bb5dbb9a440639b1637302f4ff28d 2d0d14cd31cd4d8da8e3e9a1ad608d78--134bb5dbb9a440639b1637302f4ff28d 1bf41fd7fe434d558873f7847fa6fda1 RX(b01) 134bb5dbb9a440639b1637302f4ff28d--1bf41fd7fe434d558873f7847fa6fda1 71310b257a764d0eb3a0ae5347d99a61 X 1bf41fd7fe434d558873f7847fa6fda1--71310b257a764d0eb3a0ae5347d99a61 71310b257a764d0eb3a0ae5347d99a61--fac090765d514138ba342e0762e41f6c af2fc430c6e94bd4a2cde48c3a94f10d 71310b257a764d0eb3a0ae5347d99a61--af2fc430c6e94bd4a2cde48c3a94f10d 2ea8f97026b44b44ae8d2ade16638cbf af2fc430c6e94bd4a2cde48c3a94f10d--2ea8f97026b44b44ae8d2ade16638cbf b43fd20648c34178b394e338453b6c63 2ea8f97026b44b44ae8d2ade16638cbf--b43fd20648c34178b394e338453b6c63 81d671750d6f42708194c3040caf5d98 b43fd20648c34178b394e338453b6c63--81d671750d6f42708194c3040caf5d98 b94a8a740e6249ba8481993d65c6ac8f 81d671750d6f42708194c3040caf5d98--b94a8a740e6249ba8481993d65c6ac8f 035c2bcea3da41688d88ce31db44393f b94a8a740e6249ba8481993d65c6ac8f--035c2bcea3da41688d88ce31db44393f c58656c7ec844d1b9235cdc3dfd89191 035c2bcea3da41688d88ce31db44393f--c58656c7ec844d1b9235cdc3dfd89191 77af8b445aa947bb8620a890b19af1eb c58656c7ec844d1b9235cdc3dfd89191--77af8b445aa947bb8620a890b19af1eb 4530752ebdf14827a57b9a269f3965a6 77af8b445aa947bb8620a890b19af1eb--4530752ebdf14827a57b9a269f3965a6 ebd6cb11a4784c6ab19bc4d476e89c75 4530752ebdf14827a57b9a269f3965a6--ebd6cb11a4784c6ab19bc4d476e89c75 5640582a8bd34832ab10e0eef19fd239 ebd6cb11a4784c6ab19bc4d476e89c75--5640582a8bd34832ab10e0eef19fd239 f088256d670e49ed843d94d14d3df6e2 5640582a8bd34832ab10e0eef19fd239--f088256d670e49ed843d94d14d3df6e2 7d46c8d231784e838800ddb501ea9bdd f088256d670e49ed843d94d14d3df6e2--7d46c8d231784e838800ddb501ea9bdd b4cdcc00b68c47d89dbed4466c72d304 X 7d46c8d231784e838800ddb501ea9bdd--b4cdcc00b68c47d89dbed4466c72d304 b4cdcc00b68c47d89dbed4466c72d304--99b20adebbe64db69225f64e192215e1 c3c8e42a8e29423c8347dd61190d2900 X b4cdcc00b68c47d89dbed4466c72d304--c3c8e42a8e29423c8347dd61190d2900 c3c8e42a8e29423c8347dd61190d2900--caeb5398b945491086416402644e44a7 f746af15ea0a498e913ac34f3e1a9a11 RZ(-1.0*g1) c3c8e42a8e29423c8347dd61190d2900--f746af15ea0a498e913ac34f3e1a9a11 ff0d9bbe084d4a45829e0e57a0838204 X f746af15ea0a498e913ac34f3e1a9a11--ff0d9bbe084d4a45829e0e57a0838204 ff0d9bbe084d4a45829e0e57a0838204--5a481f39b86146b69eaacdcb96be791f 237d3462008d418ab51d44900e06438d X ff0d9bbe084d4a45829e0e57a0838204--237d3462008d418ab51d44900e06438d 237d3462008d418ab51d44900e06438d--22a99f15eeb4411db825c84185dedb10 a3af0d2034994e5395c48186b5f29c17 237d3462008d418ab51d44900e06438d--a3af0d2034994e5395c48186b5f29c17 5dc617137c204c41af9c84678196099b a3af0d2034994e5395c48186b5f29c17--5dc617137c204c41af9c84678196099b e8e533d988a34a89900cac2444a39ea8 5dc617137c204c41af9c84678196099b--e8e533d988a34a89900cac2444a39ea8 decedc9c4ec7404cb06c6661467988d0 X e8e533d988a34a89900cac2444a39ea8--decedc9c4ec7404cb06c6661467988d0 decedc9c4ec7404cb06c6661467988d0--76a42d57ac924049b2114be1cf2e7d11 d74d93f51cc1482dacb310916685a0b4 X decedc9c4ec7404cb06c6661467988d0--d74d93f51cc1482dacb310916685a0b4 d74d93f51cc1482dacb310916685a0b4--daef2a76839a457b80543592c3ca86f7 b1403f9db2ea45f9b0eb586068eb3782 d74d93f51cc1482dacb310916685a0b4--b1403f9db2ea45f9b0eb586068eb3782 f04276a3fbdc4a65930fe3187cac290d b1403f9db2ea45f9b0eb586068eb3782--f04276a3fbdc4a65930fe3187cac290d d490c1bf693d44cbb9d0a1b39c067547 f04276a3fbdc4a65930fe3187cac290d--d490c1bf693d44cbb9d0a1b39c067547 6bba227ba2ec446daafce90008a76e0b d490c1bf693d44cbb9d0a1b39c067547--6bba227ba2ec446daafce90008a76e0b 9c9d008663b841e784c8c51009d8c9ea 6bba227ba2ec446daafce90008a76e0b--9c9d008663b841e784c8c51009d8c9ea fcc6e3c12e8740a6bd5bae7e43e03c54 9c9d008663b841e784c8c51009d8c9ea--fcc6e3c12e8740a6bd5bae7e43e03c54 440a866d63de42af8283c4a11af948e4 fcc6e3c12e8740a6bd5bae7e43e03c54--440a866d63de42af8283c4a11af948e4 6b90755c3da841999f1b9dc634b62c1a X 440a866d63de42af8283c4a11af948e4--6b90755c3da841999f1b9dc634b62c1a 6b90755c3da841999f1b9dc634b62c1a--e6b0c8b49a2c43b090321aa71b691590 d54c791a37fd4f2ba37de6fe6f54c9f7 X 6b90755c3da841999f1b9dc634b62c1a--d54c791a37fd4f2ba37de6fe6f54c9f7 d54c791a37fd4f2ba37de6fe6f54c9f7--77ed0687bfe74092b8e8f7da8bce5890 83bd7b4b252446e181f46590992bcee7 d54c791a37fd4f2ba37de6fe6f54c9f7--83bd7b4b252446e181f46590992bcee7 1c31637e5c63475fb43baa1668c2d70f 83bd7b4b252446e181f46590992bcee7--1c31637e5c63475fb43baa1668c2d70f 87123909b8cd4b22b083cc75813ba79c 1c31637e5c63475fb43baa1668c2d70f--87123909b8cd4b22b083cc75813ba79c 0af2932823084f10a94ccc6430b99fd8 87123909b8cd4b22b083cc75813ba79c--0af2932823084f10a94ccc6430b99fd8 8d339cfa53b24a968c5f2a2b3dc19237 0af2932823084f10a94ccc6430b99fd8--8d339cfa53b24a968c5f2a2b3dc19237 6b505f6868924f089083bae74530483d 8d339cfa53b24a968c5f2a2b3dc19237--6b505f6868924f089083bae74530483d 8c156054d2174642ad726765549d19db 6b505f6868924f089083bae74530483d--8c156054d2174642ad726765549d19db c6b38bca17ba4b2fade5952809e56896 8c156054d2174642ad726765549d19db--c6b38bca17ba4b2fade5952809e56896 393cf61c94594e37a7f35f56c25435f8 c6b38bca17ba4b2fade5952809e56896--393cf61c94594e37a7f35f56c25435f8 0e56b0c8dc6041be938c5f8905946c60 393cf61c94594e37a7f35f56c25435f8--0e56b0c8dc6041be938c5f8905946c60 0c8df7728d0644a88ae87b9d58f01550 0e56b0c8dc6041be938c5f8905946c60--0c8df7728d0644a88ae87b9d58f01550 35a8264497d24db5a746d2b6ba9ec2e0 0c8df7728d0644a88ae87b9d58f01550--35a8264497d24db5a746d2b6ba9ec2e0 215dacf5c2554f6e91b851846576c989 35a8264497d24db5a746d2b6ba9ec2e0--215dacf5c2554f6e91b851846576c989 8b0b87a0ca0547a19e6810678c4ce5b2 X 215dacf5c2554f6e91b851846576c989--8b0b87a0ca0547a19e6810678c4ce5b2 8b0b87a0ca0547a19e6810678c4ce5b2--8bcdf9c673f04bdd8d61376095e8a24f 10b6021c4b6a42cebb12b9704cbf87c3 8b0b87a0ca0547a19e6810678c4ce5b2--10b6021c4b6a42cebb12b9704cbf87c3 3e92c7b55451481393753f0661e91192 10b6021c4b6a42cebb12b9704cbf87c3--3e92c7b55451481393753f0661e91192 f6963a6c375242faab0663bf47cce64e 3e92c7b55451481393753f0661e91192--f6963a6c375242faab0663bf47cce64e 6eb1db141ef64dc9b4aca430417b94b9 f6963a6c375242faab0663bf47cce64e--6eb1db141ef64dc9b4aca430417b94b9 3c52def7ccca4ed1add99ffd73d06f08 6eb1db141ef64dc9b4aca430417b94b9--3c52def7ccca4ed1add99ffd73d06f08 043b6cdd66e34ddd8000708257843623 3c52def7ccca4ed1add99ffd73d06f08--043b6cdd66e34ddd8000708257843623 1f1e0c7eac714c2d8e9fe907045b3cd5 043b6cdd66e34ddd8000708257843623--1f1e0c7eac714c2d8e9fe907045b3cd5 4e816a50262c4193a7d8a8bdb70149af 1f1e0c7eac714c2d8e9fe907045b3cd5--4e816a50262c4193a7d8a8bdb70149af e673aebcb22c4161ad2f23d5de35bbaa 4e816a50262c4193a7d8a8bdb70149af--e673aebcb22c4161ad2f23d5de35bbaa aaa72eb420d249a4b9d639fb55bb41b6 e673aebcb22c4161ad2f23d5de35bbaa--aaa72eb420d249a4b9d639fb55bb41b6 ee1bed3f24174939979b008f59f1ed0e aaa72eb420d249a4b9d639fb55bb41b6--ee1bed3f24174939979b008f59f1ed0e bd0ca81664df4b02b80b957c2a85a9dd ee1bed3f24174939979b008f59f1ed0e--bd0ca81664df4b02b80b957c2a85a9dd d10aacf8a0034662a28b9df9c16a9428 bd0ca81664df4b02b80b957c2a85a9dd--d10aacf8a0034662a28b9df9c16a9428 f7cf3c73039d4d179cec0fbbf09fd4e9 d10aacf8a0034662a28b9df9c16a9428--f7cf3c73039d4d179cec0fbbf09fd4e9 7333722f076946d29a4c811435ba6cc7 f7cf3c73039d4d179cec0fbbf09fd4e9--7333722f076946d29a4c811435ba6cc7 f5ef064351c04715b624456491b7dfb0 7333722f076946d29a4c811435ba6cc7--f5ef064351c04715b624456491b7dfb0 3a8387c9053241b186ef6d4874750e49 f5ef064351c04715b624456491b7dfb0--3a8387c9053241b186ef6d4874750e49 de5999b997b442988a7097bf1a7d73ba 3a8387c9053241b186ef6d4874750e49--de5999b997b442988a7097bf1a7d73ba a5c6a32ad2da408297330cd170937d81 de5999b997b442988a7097bf1a7d73ba--a5c6a32ad2da408297330cd170937d81 940dd5a45ede461983fbb256dc0ecb0f a5c6a32ad2da408297330cd170937d81--940dd5a45ede461983fbb256dc0ecb0f c18ffe2a9ec843c78191e175d9e81979 940dd5a45ede461983fbb256dc0ecb0f--c18ffe2a9ec843c78191e175d9e81979 72a4d5fbda414dff909042584c1a534f c18ffe2a9ec843c78191e175d9e81979--72a4d5fbda414dff909042584c1a534f aa70cfb8530b4c4e9a22d5ad1c44a68f 72a4d5fbda414dff909042584c1a534f--aa70cfb8530b4c4e9a22d5ad1c44a68f ab2bb3782f664c6ea6307ee6fe35d576 aa70cfb8530b4c4e9a22d5ad1c44a68f--ab2bb3782f664c6ea6307ee6fe35d576 bc4c7700b4474d0db37e362a869daabe ab2bb3782f664c6ea6307ee6fe35d576--bc4c7700b4474d0db37e362a869daabe 53bc395473ad4be8b76721d0914dd423 bc4c7700b4474d0db37e362a869daabe--53bc395473ad4be8b76721d0914dd423 5153f1fed4c94c6ab0b416e685145aad 53bc395473ad4be8b76721d0914dd423--5153f1fed4c94c6ab0b416e685145aad 75eed0fdba9a4532868fb34e757ae976 5153f1fed4c94c6ab0b416e685145aad--75eed0fdba9a4532868fb34e757ae976 0f7f182f62d447bdaf7dca5c0a2fd4f8 75eed0fdba9a4532868fb34e757ae976--0f7f182f62d447bdaf7dca5c0a2fd4f8 5402b05b5aa443ab95b6e5f063ee14ac 0f7f182f62d447bdaf7dca5c0a2fd4f8--5402b05b5aa443ab95b6e5f063ee14ac 90f56d74f1dd4ce2992552abc8740076 5402b05b5aa443ab95b6e5f063ee14ac--90f56d74f1dd4ce2992552abc8740076 4cb3ac927bba455ba2eda78b3c581ff5 90f56d74f1dd4ce2992552abc8740076--4cb3ac927bba455ba2eda78b3c581ff5 e6dc94bce3854a5583bcb7434e6f6d52 4cb3ac927bba455ba2eda78b3c581ff5--e6dc94bce3854a5583bcb7434e6f6d52 2e648f1885624e4fbbef9a9f91970333 e6dc94bce3854a5583bcb7434e6f6d52--2e648f1885624e4fbbef9a9f91970333 ea2f94e5c9ea4798a8054728946abb79 2e648f1885624e4fbbef9a9f91970333--ea2f94e5c9ea4798a8054728946abb79 c27faf38307c410d9fbc299ff5122634 ea2f94e5c9ea4798a8054728946abb79--c27faf38307c410d9fbc299ff5122634 92f963235bf642229224f6c6338ee973 c27faf38307c410d9fbc299ff5122634--92f963235bf642229224f6c6338ee973 b87ec1c209514e2da808f61ca760d3af 92f963235bf642229224f6c6338ee973--b87ec1c209514e2da808f61ca760d3af 144564eaef4845c9aeeb425776acd55c b87ec1c209514e2da808f61ca760d3af--144564eaef4845c9aeeb425776acd55c a146d4094fad41fa99016e51d75dca08 144564eaef4845c9aeeb425776acd55c--a146d4094fad41fa99016e51d75dca08 75e1b2610e114cc89224e800e07b0bc1 a146d4094fad41fa99016e51d75dca08--75e1b2610e114cc89224e800e07b0bc1 d11b0bfeaf7b42a0a7264dc2851560f1 75e1b2610e114cc89224e800e07b0bc1--d11b0bfeaf7b42a0a7264dc2851560f1 1e39441f6a5449da9fd18ec49b261150 d11b0bfeaf7b42a0a7264dc2851560f1--1e39441f6a5449da9fd18ec49b261150 d3457631ee904ab49dd6bb1c8a79412c 1e39441f6a5449da9fd18ec49b261150--d3457631ee904ab49dd6bb1c8a79412c a7ce25df43b64137a7009862b04044fb d3457631ee904ab49dd6bb1c8a79412c--a7ce25df43b64137a7009862b04044fb 97db24bef56d42c78b16103244690513 a7ce25df43b64137a7009862b04044fb--97db24bef56d42c78b16103244690513 84de2224f54e4e17836b5b6680ccdc77 97db24bef56d42c78b16103244690513--84de2224f54e4e17836b5b6680ccdc77 5404f99a25634fac9fb90e2ae7ad4e9d 84de2224f54e4e17836b5b6680ccdc77--5404f99a25634fac9fb90e2ae7ad4e9d 5ab6334acad54d079a60275798368056 5404f99a25634fac9fb90e2ae7ad4e9d--5ab6334acad54d079a60275798368056 36ac65286e154ca7957f236c0e7ab44d 5ab6334acad54d079a60275798368056--36ac65286e154ca7957f236c0e7ab44d 50247fed59454b9881c4e1c658a1f66f 36ac65286e154ca7957f236c0e7ab44d--50247fed59454b9881c4e1c658a1f66f fdf19578cd994a30b1d891a2032cf44e 50247fed59454b9881c4e1c658a1f66f--fdf19578cd994a30b1d891a2032cf44e df97a8b2f9234e04b02bf112709bfe63 fdf19578cd994a30b1d891a2032cf44e--df97a8b2f9234e04b02bf112709bfe63 049bcc178768438fb5594fa4b0a45fcb df97a8b2f9234e04b02bf112709bfe63--049bcc178768438fb5594fa4b0a45fcb 739168d8e95e45eb892e2aaaa626550e 049bcc178768438fb5594fa4b0a45fcb--739168d8e95e45eb892e2aaaa626550e ce2fec22391242e296337739edaecb7c 739168d8e95e45eb892e2aaaa626550e--ce2fec22391242e296337739edaecb7c 47ba79643d554cf2a411795a660a807f ce2fec22391242e296337739edaecb7c--47ba79643d554cf2a411795a660a807f 84c90a0310594874b48bce06e4943204 47ba79643d554cf2a411795a660a807f--84c90a0310594874b48bce06e4943204 b328ac2d863747a7a3e2a29cf35238a7 84c90a0310594874b48bce06e4943204--b328ac2d863747a7a3e2a29cf35238a7 0d275cd6a9be4475a24111550044aca9 b328ac2d863747a7a3e2a29cf35238a7--0d275cd6a9be4475a24111550044aca9 2ce38a7bb0cf4ca8ae5e6dc8c9c95d94 0d275cd6a9be4475a24111550044aca9--2ce38a7bb0cf4ca8ae5e6dc8c9c95d94 975b5619f5804898931450c13708db44 2ce38a7bb0cf4ca8ae5e6dc8c9c95d94--975b5619f5804898931450c13708db44 5c54770183394d77af0343f77a160018 975b5619f5804898931450c13708db44--5c54770183394d77af0343f77a160018 7eb3f5dff1a040b9b74284a9789a3abe 5c54770183394d77af0343f77a160018--7eb3f5dff1a040b9b74284a9789a3abe b49a1b831a3f44f1b2d3f50299c683e1 7eb3f5dff1a040b9b74284a9789a3abe--b49a1b831a3f44f1b2d3f50299c683e1 c8ac246cf1db4984bf868575869a48e5 b49a1b831a3f44f1b2d3f50299c683e1--c8ac246cf1db4984bf868575869a48e5 40a7b8cf2a89483494caad14d8e9630e c8ac246cf1db4984bf868575869a48e5--40a7b8cf2a89483494caad14d8e9630e 0c4cfa14ce8a431fbea4ab79af2419a0 40a7b8cf2a89483494caad14d8e9630e--0c4cfa14ce8a431fbea4ab79af2419a0 f10f7fb6dfe841d9afe839a7e55440f3 0c4cfa14ce8a431fbea4ab79af2419a0--f10f7fb6dfe841d9afe839a7e55440f3 3c125a2eac524c10a46bf1ccf6805acd f10f7fb6dfe841d9afe839a7e55440f3--3c125a2eac524c10a46bf1ccf6805acd 690cb788560f4756a44035c60026b9dd 3c125a2eac524c10a46bf1ccf6805acd--690cb788560f4756a44035c60026b9dd cf8ca6918dac4da2b29c788d5ba2db2e 690cb788560f4756a44035c60026b9dd--cf8ca6918dac4da2b29c788d5ba2db2e 8983ebf61ee8410aaae08f1300189046 cf8ca6918dac4da2b29c788d5ba2db2e--8983ebf61ee8410aaae08f1300189046 8659a0daf18f45e4a06398a53ac1cd24 8983ebf61ee8410aaae08f1300189046--8659a0daf18f45e4a06398a53ac1cd24 1e9333bcc2eb436dbad83f036bfe15bd 8659a0daf18f45e4a06398a53ac1cd24--1e9333bcc2eb436dbad83f036bfe15bd 55b05e1f265b46efac97d4d9745f254c 1e9333bcc2eb436dbad83f036bfe15bd--55b05e1f265b46efac97d4d9745f254c 1f3459c2a3e547819d888fb0cb665ccc 55b05e1f265b46efac97d4d9745f254c--1f3459c2a3e547819d888fb0cb665ccc b634037df6b1499eb245c1ff08a4914d 1f3459c2a3e547819d888fb0cb665ccc--b634037df6b1499eb245c1ff08a4914d 5b7bb2bd0fca4717badd670fd6da3396 b634037df6b1499eb245c1ff08a4914d--5b7bb2bd0fca4717badd670fd6da3396 c60000502a324cb9bfe024f749e9b1f2 5b7bb2bd0fca4717badd670fd6da3396--c60000502a324cb9bfe024f749e9b1f2 2c8ab08b38b14c2da354851ae2ab42c0 c60000502a324cb9bfe024f749e9b1f2--2c8ab08b38b14c2da354851ae2ab42c0 06e96389174546458c416568df51bdcb 2c8ab08b38b14c2da354851ae2ab42c0--06e96389174546458c416568df51bdcb ce2d20be2fc64d70bbe1f2e391fc2dad 06e96389174546458c416568df51bdcb--ce2d20be2fc64d70bbe1f2e391fc2dad 0ce427b2b8194640a2bae30c0cf9cd0c ce2d20be2fc64d70bbe1f2e391fc2dad--0ce427b2b8194640a2bae30c0cf9cd0c 46dfe24847204af7801d720a28bf2c9b 0ce427b2b8194640a2bae30c0cf9cd0c--46dfe24847204af7801d720a28bf2c9b fe0a46c85b534caeb00708d865a77b1e 46dfe24847204af7801d720a28bf2c9b--fe0a46c85b534caeb00708d865a77b1e e031a145634249d08b945ad01f1dbd20 fe0a46c85b534caeb00708d865a77b1e--e031a145634249d08b945ad01f1dbd20 383c1868bf87402e940fe36fe9b348e5 e031a145634249d08b945ad01f1dbd20--383c1868bf87402e940fe36fe9b348e5 aa7589ed20a34cd481057fe32aeed766 383c1868bf87402e940fe36fe9b348e5--aa7589ed20a34cd481057fe32aeed766 51d325d8741d44ecb51bd452873fc4ce aa7589ed20a34cd481057fe32aeed766--51d325d8741d44ecb51bd452873fc4ce 4e0a90471d854536964a42f8840312a8 51d325d8741d44ecb51bd452873fc4ce--4e0a90471d854536964a42f8840312a8 09161ada3fdb426790a19ee63d6d6a06 RX(b11) 4e0a90471d854536964a42f8840312a8--09161ada3fdb426790a19ee63d6d6a06 09161ada3fdb426790a19ee63d6d6a06--39f6963648f34d178118c3aba0324c2a 402ef3c8843f44a0893f1b7f7ef61f26 3bc59adf783643ba961057d5a580a72e a2b8da45fe344952b2f373e22db5fe2c--3bc59adf783643ba961057d5a580a72e 4de47c75478c4b26940bbd99d8599bae 3 8738784bbaee435bad8ada51ac55e3ca X 3bc59adf783643ba961057d5a580a72e--8738784bbaee435bad8ada51ac55e3ca 8738784bbaee435bad8ada51ac55e3ca--3e64166d24b849b886bdef077b86e1b2 04f4824149f949b6a887a91ea13f84de 8738784bbaee435bad8ada51ac55e3ca--04f4824149f949b6a887a91ea13f84de a18383f220b5484587109a0e551cbc62 04f4824149f949b6a887a91ea13f84de--a18383f220b5484587109a0e551cbc62 1835c01fe6cf47329abedfb3eea1700a a18383f220b5484587109a0e551cbc62--1835c01fe6cf47329abedfb3eea1700a 001b7c1510d84e9aa5e11fcbd3040801 1835c01fe6cf47329abedfb3eea1700a--001b7c1510d84e9aa5e11fcbd3040801 e42337becf60436f9b928e9fa3e813df 001b7c1510d84e9aa5e11fcbd3040801--e42337becf60436f9b928e9fa3e813df da95015f0162498cab8eaa45b15658b4 e42337becf60436f9b928e9fa3e813df--da95015f0162498cab8eaa45b15658b4 cfde42bbd1624aabbee52933417e8f7d da95015f0162498cab8eaa45b15658b4--cfde42bbd1624aabbee52933417e8f7d 4757b8314e354ce8a4eee6c9d60556a0 cfde42bbd1624aabbee52933417e8f7d--4757b8314e354ce8a4eee6c9d60556a0 44392f4c46b24c07b6efaae9341243ce 4757b8314e354ce8a4eee6c9d60556a0--44392f4c46b24c07b6efaae9341243ce 5014b28457994436abbd560b535356df 44392f4c46b24c07b6efaae9341243ce--5014b28457994436abbd560b535356df 7a66796fc1bc4fdb9c2d58037500b734 5014b28457994436abbd560b535356df--7a66796fc1bc4fdb9c2d58037500b734 264a5a072ae646e7852030bd326090fe X 7a66796fc1bc4fdb9c2d58037500b734--264a5a072ae646e7852030bd326090fe 264a5a072ae646e7852030bd326090fe--a01a3787b27749639f3f2f1344a66b43 dba69db7df6542e7bd7c5e0e0092ad1d 264a5a072ae646e7852030bd326090fe--dba69db7df6542e7bd7c5e0e0092ad1d eb68f79747b1486e8192dba0ddebca81 dba69db7df6542e7bd7c5e0e0092ad1d--eb68f79747b1486e8192dba0ddebca81 fd19213698cb4100bfe9523e7bb2c749 eb68f79747b1486e8192dba0ddebca81--fd19213698cb4100bfe9523e7bb2c749 0fd896e43b1e454fadf17f76b86d263a fd19213698cb4100bfe9523e7bb2c749--0fd896e43b1e454fadf17f76b86d263a 186280ddd5f3471e89a74020f299e0fe 0fd896e43b1e454fadf17f76b86d263a--186280ddd5f3471e89a74020f299e0fe 919c4a0e3d7b432ba4fe6be8fe5a4237 X 186280ddd5f3471e89a74020f299e0fe--919c4a0e3d7b432ba4fe6be8fe5a4237 919c4a0e3d7b432ba4fe6be8fe5a4237--0b964dfccadd4be9b62443606a62dd64 669ac346e45445ceb0e78d0ce9d6df27 RZ(-1.0*g0) 919c4a0e3d7b432ba4fe6be8fe5a4237--669ac346e45445ceb0e78d0ce9d6df27 f9352e8877f847828e667effab88d86f X 669ac346e45445ceb0e78d0ce9d6df27--f9352e8877f847828e667effab88d86f f9352e8877f847828e667effab88d86f--3b560206c8b542cd8124af248e02b71c 57b2c1f9349445e58dc12b496ed73ee5 f9352e8877f847828e667effab88d86f--57b2c1f9349445e58dc12b496ed73ee5 cd9b53656aca4ed4a3141177aba5d7ba 57b2c1f9349445e58dc12b496ed73ee5--cd9b53656aca4ed4a3141177aba5d7ba 735a0335046342d08d47af220597cadf X cd9b53656aca4ed4a3141177aba5d7ba--735a0335046342d08d47af220597cadf 735a0335046342d08d47af220597cadf--bb661f2865d849c1b130146c5e740323 87f600d1926645529b561d81f0792315 735a0335046342d08d47af220597cadf--87f600d1926645529b561d81f0792315 6c162da660514793ad4045ec17106c1d 87f600d1926645529b561d81f0792315--6c162da660514793ad4045ec17106c1d 58563a7b39314e40b428fb7d27d80a8c 6c162da660514793ad4045ec17106c1d--58563a7b39314e40b428fb7d27d80a8c 1fd1a52ea5474c678326f4cb7d8198be 58563a7b39314e40b428fb7d27d80a8c--1fd1a52ea5474c678326f4cb7d8198be ec026dc052604f40b4b48f3508fa43a5 1fd1a52ea5474c678326f4cb7d8198be--ec026dc052604f40b4b48f3508fa43a5 5e8722cc96bd4e3ea4fb747c3c40ae14 X ec026dc052604f40b4b48f3508fa43a5--5e8722cc96bd4e3ea4fb747c3c40ae14 5e8722cc96bd4e3ea4fb747c3c40ae14--13775cd241ba444b85e831cecfbe0101 1dab306aa988419faf053ad8d1d3b59a 5e8722cc96bd4e3ea4fb747c3c40ae14--1dab306aa988419faf053ad8d1d3b59a a7c08bf9237b432db1342fb48b518db3 1dab306aa988419faf053ad8d1d3b59a--a7c08bf9237b432db1342fb48b518db3 86e972fae4224d74b9d8214364860511 X a7c08bf9237b432db1342fb48b518db3--86e972fae4224d74b9d8214364860511 86e972fae4224d74b9d8214364860511--6c6e223e1d6d4ff2b42ca662618d87bd a7d90385f6b24eaaaef08539f3435543 86e972fae4224d74b9d8214364860511--a7d90385f6b24eaaaef08539f3435543 5e169cee08c748bf898212777f245262 a7d90385f6b24eaaaef08539f3435543--5e169cee08c748bf898212777f245262 683d84e3b706412f8e58e64b246e3211 5e169cee08c748bf898212777f245262--683d84e3b706412f8e58e64b246e3211 7898f08f480b42a39458f47341d829cb 683d84e3b706412f8e58e64b246e3211--7898f08f480b42a39458f47341d829cb 789f084c07e649ac9272cbf4c72e639e 7898f08f480b42a39458f47341d829cb--789f084c07e649ac9272cbf4c72e639e 9224b75489c64e3a9bb4b6c55b60aec0 789f084c07e649ac9272cbf4c72e639e--9224b75489c64e3a9bb4b6c55b60aec0 b5a28d8dc86147e29df714e168de84a0 9224b75489c64e3a9bb4b6c55b60aec0--b5a28d8dc86147e29df714e168de84a0 538e28298a99459ca843a46987069751 b5a28d8dc86147e29df714e168de84a0--538e28298a99459ca843a46987069751 5aa5b512728f49bfa7e3e104332b28e9 538e28298a99459ca843a46987069751--5aa5b512728f49bfa7e3e104332b28e9 7131ca0c4bd94328b55e15da2bea5ca8 5aa5b512728f49bfa7e3e104332b28e9--7131ca0c4bd94328b55e15da2bea5ca8 173783d82a5c48b7a1edd5813c1e946c 7131ca0c4bd94328b55e15da2bea5ca8--173783d82a5c48b7a1edd5813c1e946c e81077e514f44c97af9f4713e11ca214 X 173783d82a5c48b7a1edd5813c1e946c--e81077e514f44c97af9f4713e11ca214 e81077e514f44c97af9f4713e11ca214--61614c628c9842379546e85d0c2e5802 e47e2bd8a5c541859633d301e86996c4 e81077e514f44c97af9f4713e11ca214--e47e2bd8a5c541859633d301e86996c4 21e38ef2b37a4f208815cffb29105e17 X e47e2bd8a5c541859633d301e86996c4--21e38ef2b37a4f208815cffb29105e17 21e38ef2b37a4f208815cffb29105e17--170c5f690768467f9a071e8661e73f91 772f9bc990f64401825971afa475b91c 21e38ef2b37a4f208815cffb29105e17--772f9bc990f64401825971afa475b91c da600cbd99fe4193b79de4ab2f217c4b 772f9bc990f64401825971afa475b91c--da600cbd99fe4193b79de4ab2f217c4b 36dde06a47b24ee1ae7c7fa670a4036f da600cbd99fe4193b79de4ab2f217c4b--36dde06a47b24ee1ae7c7fa670a4036f a462844faec54f9aabbeb3945112bf9a 36dde06a47b24ee1ae7c7fa670a4036f--a462844faec54f9aabbeb3945112bf9a 417d550af5fa4990b965e0f367952469 a462844faec54f9aabbeb3945112bf9a--417d550af5fa4990b965e0f367952469 c20324fc537446cabf6775ca9e3337be 417d550af5fa4990b965e0f367952469--c20324fc537446cabf6775ca9e3337be 316a3912bb5a4ec4988e27a97a16eb35 c20324fc537446cabf6775ca9e3337be--316a3912bb5a4ec4988e27a97a16eb35 ffface0486e4468fbcd902c9ebab038c X 316a3912bb5a4ec4988e27a97a16eb35--ffface0486e4468fbcd902c9ebab038c ffface0486e4468fbcd902c9ebab038c--c1471ad3ad97466ea1bee3e84845c6b6 a8563fadb7b348e78b85ee90ac8c8c63 X ffface0486e4468fbcd902c9ebab038c--a8563fadb7b348e78b85ee90ac8c8c63 a8563fadb7b348e78b85ee90ac8c8c63--16ac7b2299384ccf8978d15baaaa4ade 3787fbb167bc474da644502072df67fc a8563fadb7b348e78b85ee90ac8c8c63--3787fbb167bc474da644502072df67fc 9a68e980d1404e7e91d042265fc23e2f 3787fbb167bc474da644502072df67fc--9a68e980d1404e7e91d042265fc23e2f 8ebb2afda4464d72bc4165ae74f88fc2 9a68e980d1404e7e91d042265fc23e2f--8ebb2afda4464d72bc4165ae74f88fc2 bcf748c12ec5401ba99366f7bceda24b 8ebb2afda4464d72bc4165ae74f88fc2--bcf748c12ec5401ba99366f7bceda24b 3be9dd8bdc164de4a25472b52c7e8296 bcf748c12ec5401ba99366f7bceda24b--3be9dd8bdc164de4a25472b52c7e8296 1079b5853b384282a15d902009e65911 3be9dd8bdc164de4a25472b52c7e8296--1079b5853b384282a15d902009e65911 7b16b9b3053c40a7baaf37e5eb9e94dc 1079b5853b384282a15d902009e65911--7b16b9b3053c40a7baaf37e5eb9e94dc 8754732b8c8a4145ad42f4f5e3bfa324 7b16b9b3053c40a7baaf37e5eb9e94dc--8754732b8c8a4145ad42f4f5e3bfa324 1a7a6c75a53f465b9524b7965a401e8f 8754732b8c8a4145ad42f4f5e3bfa324--1a7a6c75a53f465b9524b7965a401e8f f962142315ae41bbad4a81c952dbd43a X 1a7a6c75a53f465b9524b7965a401e8f--f962142315ae41bbad4a81c952dbd43a f962142315ae41bbad4a81c952dbd43a--176d55ff93d143c8a78e08f469730486 48ea5b7921fd4a0dbfffccf0d8028d67 X f962142315ae41bbad4a81c952dbd43a--48ea5b7921fd4a0dbfffccf0d8028d67 48ea5b7921fd4a0dbfffccf0d8028d67--7a96eee9936740bf8336e97143a195e4 d158662f226841b7a57196d28da3eced 48ea5b7921fd4a0dbfffccf0d8028d67--d158662f226841b7a57196d28da3eced c38c58c123d64892b976d8cb5da2b4a4 d158662f226841b7a57196d28da3eced--c38c58c123d64892b976d8cb5da2b4a4 b10b81afd82c4a418ea86aa74fb23ecd c38c58c123d64892b976d8cb5da2b4a4--b10b81afd82c4a418ea86aa74fb23ecd 68416ae325fc41098ac4f59a8900e532 b10b81afd82c4a418ea86aa74fb23ecd--68416ae325fc41098ac4f59a8900e532 9389f6e83d3941e086a27650eab33b7c 68416ae325fc41098ac4f59a8900e532--9389f6e83d3941e086a27650eab33b7c 1f95e1e896fd4c92a9015cfb5ac46151 9389f6e83d3941e086a27650eab33b7c--1f95e1e896fd4c92a9015cfb5ac46151 c5460815ca404faab44efbe7615e8b70 1f95e1e896fd4c92a9015cfb5ac46151--c5460815ca404faab44efbe7615e8b70 495186f6193a4ded853deccde1615ec0 c5460815ca404faab44efbe7615e8b70--495186f6193a4ded853deccde1615ec0 96c9ca4db36044c4847ee20ac45a4ccd 495186f6193a4ded853deccde1615ec0--96c9ca4db36044c4847ee20ac45a4ccd 6b7ed0acdc354b7ba74b61d91e21426f 96c9ca4db36044c4847ee20ac45a4ccd--6b7ed0acdc354b7ba74b61d91e21426f 9aa14ac4a3aa4c02a3a9a9aef7e90e33 6b7ed0acdc354b7ba74b61d91e21426f--9aa14ac4a3aa4c02a3a9a9aef7e90e33 f1e334267d8a4c5f8915fd12b5b460f2 X 9aa14ac4a3aa4c02a3a9a9aef7e90e33--f1e334267d8a4c5f8915fd12b5b460f2 f1e334267d8a4c5f8915fd12b5b460f2--0cfbbf48ad7447bfa26ef5101b4f87ee 1822dd2537c94ac18a7d66fc1426cfc8 f1e334267d8a4c5f8915fd12b5b460f2--1822dd2537c94ac18a7d66fc1426cfc8 2ba79c93b84d4c1c8ce562574a1ae39f 1822dd2537c94ac18a7d66fc1426cfc8--2ba79c93b84d4c1c8ce562574a1ae39f de0c1dc3317748359ef045cc3fd84219 2ba79c93b84d4c1c8ce562574a1ae39f--de0c1dc3317748359ef045cc3fd84219 0bc47a11d42e47afa0353d266ee92707 de0c1dc3317748359ef045cc3fd84219--0bc47a11d42e47afa0353d266ee92707 959e277c379a432bb39e1079e6972781 0bc47a11d42e47afa0353d266ee92707--959e277c379a432bb39e1079e6972781 5349c964cb534e8998416d7b8618f06b 959e277c379a432bb39e1079e6972781--5349c964cb534e8998416d7b8618f06b c61f5ff5aeb947dcba9d815e582da206 5349c964cb534e8998416d7b8618f06b--c61f5ff5aeb947dcba9d815e582da206 9385e54f9e0d4a9eaf24f9f36161b74d c61f5ff5aeb947dcba9d815e582da206--9385e54f9e0d4a9eaf24f9f36161b74d 22d24a717db4431598c6fd0a5c8d08cb 9385e54f9e0d4a9eaf24f9f36161b74d--22d24a717db4431598c6fd0a5c8d08cb 518a3dfc91b24ba19d4ab575c5832c18 22d24a717db4431598c6fd0a5c8d08cb--518a3dfc91b24ba19d4ab575c5832c18 bc1d581a130240bb915c5b5ee87dd971 518a3dfc91b24ba19d4ab575c5832c18--bc1d581a130240bb915c5b5ee87dd971 b981a23d74ff409ab1a99fa79743849c bc1d581a130240bb915c5b5ee87dd971--b981a23d74ff409ab1a99fa79743849c ba7c440f401e46ad8eacc79eceec6d8b b981a23d74ff409ab1a99fa79743849c--ba7c440f401e46ad8eacc79eceec6d8b 70fcbe84b6a542ae9e2bc85175789542 ba7c440f401e46ad8eacc79eceec6d8b--70fcbe84b6a542ae9e2bc85175789542 bbd80dc3f1a843ebb36d18c44dc19d3d 70fcbe84b6a542ae9e2bc85175789542--bbd80dc3f1a843ebb36d18c44dc19d3d c2f6f858c0a640f89537cdf1fa298914 bbd80dc3f1a843ebb36d18c44dc19d3d--c2f6f858c0a640f89537cdf1fa298914 e2035911133c46339d0fb1b7acb4df5c c2f6f858c0a640f89537cdf1fa298914--e2035911133c46339d0fb1b7acb4df5c 9a6612ceb8e542f794b9559753e84d50 e2035911133c46339d0fb1b7acb4df5c--9a6612ceb8e542f794b9559753e84d50 8eb112ad236e41678734ce077037be39 9a6612ceb8e542f794b9559753e84d50--8eb112ad236e41678734ce077037be39 62b8d338dc98414581e6f3c525b18aad 8eb112ad236e41678734ce077037be39--62b8d338dc98414581e6f3c525b18aad 93f999fefa4f499ea0f6c4e6257f82b6 62b8d338dc98414581e6f3c525b18aad--93f999fefa4f499ea0f6c4e6257f82b6 580a391beae642c28bd5e631fa500cdd 93f999fefa4f499ea0f6c4e6257f82b6--580a391beae642c28bd5e631fa500cdd 80305629f1c24731bbd59d0569e98105 580a391beae642c28bd5e631fa500cdd--80305629f1c24731bbd59d0569e98105 038496e21cec4e78aa0adac2cee60047 80305629f1c24731bbd59d0569e98105--038496e21cec4e78aa0adac2cee60047 5929855f93594a2b872ad4ed84327f2e 038496e21cec4e78aa0adac2cee60047--5929855f93594a2b872ad4ed84327f2e 0e560c3a1f2a4eeabe2308a2aa2fe243 5929855f93594a2b872ad4ed84327f2e--0e560c3a1f2a4eeabe2308a2aa2fe243 acf04687588e4eb6a41d7e83f4608e02 0e560c3a1f2a4eeabe2308a2aa2fe243--acf04687588e4eb6a41d7e83f4608e02 c1eed954ec4f48709a007795425ab8f2 acf04687588e4eb6a41d7e83f4608e02--c1eed954ec4f48709a007795425ab8f2 7a233ddf944741e996e33987735bbd29 c1eed954ec4f48709a007795425ab8f2--7a233ddf944741e996e33987735bbd29 4b13c2cd54c64776a8b74e0f37bf7df9 7a233ddf944741e996e33987735bbd29--4b13c2cd54c64776a8b74e0f37bf7df9 573f17bce3784c39a0dd140480128b5e 4b13c2cd54c64776a8b74e0f37bf7df9--573f17bce3784c39a0dd140480128b5e 65db0d3512264c4ca54e946cb844ad60 573f17bce3784c39a0dd140480128b5e--65db0d3512264c4ca54e946cb844ad60 a9df17e779f746a990e99ede665c6f08 65db0d3512264c4ca54e946cb844ad60--a9df17e779f746a990e99ede665c6f08 99c976ace5b14fd496fc99f11d9ded39 a9df17e779f746a990e99ede665c6f08--99c976ace5b14fd496fc99f11d9ded39 a58115017fa84a2083a544feae70a12f 99c976ace5b14fd496fc99f11d9ded39--a58115017fa84a2083a544feae70a12f 1eaa7245635746aeafef6c6275668ae3 a58115017fa84a2083a544feae70a12f--1eaa7245635746aeafef6c6275668ae3 e453b82367c045dba640c65d3650f811 1eaa7245635746aeafef6c6275668ae3--e453b82367c045dba640c65d3650f811 7f1f7c942a6c4c33afcafd4995da3e6c e453b82367c045dba640c65d3650f811--7f1f7c942a6c4c33afcafd4995da3e6c 7e7551d6eaaa415397c718d8fc793857 7f1f7c942a6c4c33afcafd4995da3e6c--7e7551d6eaaa415397c718d8fc793857 5de4d6ce21cb41d8a13a9c7ef2655605 7e7551d6eaaa415397c718d8fc793857--5de4d6ce21cb41d8a13a9c7ef2655605 ea54a2d6d8ba405db5953ece82093354 5de4d6ce21cb41d8a13a9c7ef2655605--ea54a2d6d8ba405db5953ece82093354 67fc1dae8e8948328fca4ff814a4c312 ea54a2d6d8ba405db5953ece82093354--67fc1dae8e8948328fca4ff814a4c312 fbccb7c0767e43e28e857cf9ef5cca10 67fc1dae8e8948328fca4ff814a4c312--fbccb7c0767e43e28e857cf9ef5cca10 0cf5120c0dac44d0852eaec6d7029280 fbccb7c0767e43e28e857cf9ef5cca10--0cf5120c0dac44d0852eaec6d7029280 8b3d4ceaef454a199e3e9de330353a25 0cf5120c0dac44d0852eaec6d7029280--8b3d4ceaef454a199e3e9de330353a25 0db22d9ccf434f00b42276a966529137 8b3d4ceaef454a199e3e9de330353a25--0db22d9ccf434f00b42276a966529137 6a21a9359aec411eb9cb12abed1fee09 0db22d9ccf434f00b42276a966529137--6a21a9359aec411eb9cb12abed1fee09 bfcd28c2a1284352bb58b75249d9eb91 6a21a9359aec411eb9cb12abed1fee09--bfcd28c2a1284352bb58b75249d9eb91 54e6d53dba9b4895b0362a84248ffb38 bfcd28c2a1284352bb58b75249d9eb91--54e6d53dba9b4895b0362a84248ffb38 4501b62ebf7a44d6b923dc8a01a6bc3e 54e6d53dba9b4895b0362a84248ffb38--4501b62ebf7a44d6b923dc8a01a6bc3e c2c61db0877644e9adb33cced7731f17 4501b62ebf7a44d6b923dc8a01a6bc3e--c2c61db0877644e9adb33cced7731f17 5a480e4a9d5d49d3b30c3b61aab7206e c2c61db0877644e9adb33cced7731f17--5a480e4a9d5d49d3b30c3b61aab7206e 4ec3ea67150d4182a4f0496740c704e6 5a480e4a9d5d49d3b30c3b61aab7206e--4ec3ea67150d4182a4f0496740c704e6 9a2a2da49bab4fb5b68d3914e9576608 4ec3ea67150d4182a4f0496740c704e6--9a2a2da49bab4fb5b68d3914e9576608 1b1145e194054cd9bc0f4aac6d0aa557 9a2a2da49bab4fb5b68d3914e9576608--1b1145e194054cd9bc0f4aac6d0aa557 7e79390e301948f2af2626384a5e72ed 1b1145e194054cd9bc0f4aac6d0aa557--7e79390e301948f2af2626384a5e72ed 1fcd6eefbf2744bca0eba1c8d926c54c 7e79390e301948f2af2626384a5e72ed--1fcd6eefbf2744bca0eba1c8d926c54c a82bfeb7e0074f3aa8e1035e3a17c0e7 1fcd6eefbf2744bca0eba1c8d926c54c--a82bfeb7e0074f3aa8e1035e3a17c0e7 4552fd23e4d14ed5b318cfa6f396e394 RX(b02) a82bfeb7e0074f3aa8e1035e3a17c0e7--4552fd23e4d14ed5b318cfa6f396e394 e31d6f0ebb5d4b8ca35fd0dd73b78ae1 4552fd23e4d14ed5b318cfa6f396e394--e31d6f0ebb5d4b8ca35fd0dd73b78ae1 f30b5ae3509f40ef8472d3552910ccae X e31d6f0ebb5d4b8ca35fd0dd73b78ae1--f30b5ae3509f40ef8472d3552910ccae f30b5ae3509f40ef8472d3552910ccae--af2fc430c6e94bd4a2cde48c3a94f10d 1e3661c98dcd42db8705e1400e1c94b6 f30b5ae3509f40ef8472d3552910ccae--1e3661c98dcd42db8705e1400e1c94b6 2eaa75dd042d4c0290f7b9d1b36f9826 1e3661c98dcd42db8705e1400e1c94b6--2eaa75dd042d4c0290f7b9d1b36f9826 6daee93a33a64b7bb6d8d685dd182e75 2eaa75dd042d4c0290f7b9d1b36f9826--6daee93a33a64b7bb6d8d685dd182e75 3f6bdf1b5e874fabafae475f6d0f16c7 6daee93a33a64b7bb6d8d685dd182e75--3f6bdf1b5e874fabafae475f6d0f16c7 74bdd2b696284c2cad6ffaa30ee45e9b 3f6bdf1b5e874fabafae475f6d0f16c7--74bdd2b696284c2cad6ffaa30ee45e9b b28eb3cc4c5f4ff98dc84300dcd5b791 74bdd2b696284c2cad6ffaa30ee45e9b--b28eb3cc4c5f4ff98dc84300dcd5b791 9281211492924f86b11de1b6dca3469c b28eb3cc4c5f4ff98dc84300dcd5b791--9281211492924f86b11de1b6dca3469c 16edb3579bb940f78519e603dfbcc025 9281211492924f86b11de1b6dca3469c--16edb3579bb940f78519e603dfbcc025 087fe5963faf419fba9b913ed675d3c5 16edb3579bb940f78519e603dfbcc025--087fe5963faf419fba9b913ed675d3c5 de42f51646e24214a107201ce9faf6d6 087fe5963faf419fba9b913ed675d3c5--de42f51646e24214a107201ce9faf6d6 4e9882b7f3a5478f9fe9d45310960a72 de42f51646e24214a107201ce9faf6d6--4e9882b7f3a5478f9fe9d45310960a72 6c35ce516b2048e2a20f6f41ab2f7aba X 4e9882b7f3a5478f9fe9d45310960a72--6c35ce516b2048e2a20f6f41ab2f7aba 6c35ce516b2048e2a20f6f41ab2f7aba--7d46c8d231784e838800ddb501ea9bdd 9158ab2d82d44b039e27436e365d8e0b 6c35ce516b2048e2a20f6f41ab2f7aba--9158ab2d82d44b039e27436e365d8e0b 53175412b90a4e0b848cf7c7963292f0 9158ab2d82d44b039e27436e365d8e0b--53175412b90a4e0b848cf7c7963292f0 4e0c4223c6b34b8dab048e6a44b3ee01 53175412b90a4e0b848cf7c7963292f0--4e0c4223c6b34b8dab048e6a44b3ee01 4aafabbe1fe84abe87001911524160b8 4e0c4223c6b34b8dab048e6a44b3ee01--4aafabbe1fe84abe87001911524160b8 8cbe3f5478e247c581b38cb6d93da062 4aafabbe1fe84abe87001911524160b8--8cbe3f5478e247c581b38cb6d93da062 17f188aec9db4bea8543700539693071 X 8cbe3f5478e247c581b38cb6d93da062--17f188aec9db4bea8543700539693071 17f188aec9db4bea8543700539693071--a3af0d2034994e5395c48186b5f29c17 522451f2805f4e99b625d3f2eee40322 RZ(-1.0*g1) 17f188aec9db4bea8543700539693071--522451f2805f4e99b625d3f2eee40322 bf2fd7a57db54c74b1a1c5b06de9ab21 X 522451f2805f4e99b625d3f2eee40322--bf2fd7a57db54c74b1a1c5b06de9ab21 bf2fd7a57db54c74b1a1c5b06de9ab21--e8e533d988a34a89900cac2444a39ea8 57dbc5a5a84641ec8a2da9d0586d21fe bf2fd7a57db54c74b1a1c5b06de9ab21--57dbc5a5a84641ec8a2da9d0586d21fe f838ce5e2d6c445d88d2cd22530e2828 57dbc5a5a84641ec8a2da9d0586d21fe--f838ce5e2d6c445d88d2cd22530e2828 2bb6e0ee362f43799e33983cfed7aec7 X f838ce5e2d6c445d88d2cd22530e2828--2bb6e0ee362f43799e33983cfed7aec7 2bb6e0ee362f43799e33983cfed7aec7--b1403f9db2ea45f9b0eb586068eb3782 84ffbaf85e5046bea58ca50e61ef8880 2bb6e0ee362f43799e33983cfed7aec7--84ffbaf85e5046bea58ca50e61ef8880 cce38b57dd1a40848acf9d8fd3398dbd 84ffbaf85e5046bea58ca50e61ef8880--cce38b57dd1a40848acf9d8fd3398dbd 022f5a18e5a14ef7bd0833291838035a cce38b57dd1a40848acf9d8fd3398dbd--022f5a18e5a14ef7bd0833291838035a decaa4baffd942daab33600fb0ade541 022f5a18e5a14ef7bd0833291838035a--decaa4baffd942daab33600fb0ade541 c296768cb0304581bd2ce164ebf1a8c3 decaa4baffd942daab33600fb0ade541--c296768cb0304581bd2ce164ebf1a8c3 a535346b0b9d49058018e162ba7fa503 X c296768cb0304581bd2ce164ebf1a8c3--a535346b0b9d49058018e162ba7fa503 a535346b0b9d49058018e162ba7fa503--440a866d63de42af8283c4a11af948e4 2f7401d6ab2347fe9a8a1266662e286b a535346b0b9d49058018e162ba7fa503--2f7401d6ab2347fe9a8a1266662e286b 0f7588ee255b40e5ad5d2099f412a81b 2f7401d6ab2347fe9a8a1266662e286b--0f7588ee255b40e5ad5d2099f412a81b 4ae2bd64591a49b7be86d67b2df9b827 X 0f7588ee255b40e5ad5d2099f412a81b--4ae2bd64591a49b7be86d67b2df9b827 4ae2bd64591a49b7be86d67b2df9b827--83bd7b4b252446e181f46590992bcee7 815f921455a04b6b845b9398bf32edf9 4ae2bd64591a49b7be86d67b2df9b827--815f921455a04b6b845b9398bf32edf9 fa57320a59b9435fbff9d85d869e4c6e 815f921455a04b6b845b9398bf32edf9--fa57320a59b9435fbff9d85d869e4c6e 6f21c6c562f84949922d0055db5b4c72 fa57320a59b9435fbff9d85d869e4c6e--6f21c6c562f84949922d0055db5b4c72 fcafd9113fe44c1e9f4eea51395b9999 6f21c6c562f84949922d0055db5b4c72--fcafd9113fe44c1e9f4eea51395b9999 5f4b7c979e594a8da02db41ad2624570 fcafd9113fe44c1e9f4eea51395b9999--5f4b7c979e594a8da02db41ad2624570 f45e9070091142149ece4a22758faba4 5f4b7c979e594a8da02db41ad2624570--f45e9070091142149ece4a22758faba4 f63ec7166880472ba1b72b1680732200 f45e9070091142149ece4a22758faba4--f63ec7166880472ba1b72b1680732200 10dd62d63446470ba7ec73efe73ac65b f63ec7166880472ba1b72b1680732200--10dd62d63446470ba7ec73efe73ac65b b1ea41cd7a8b45c88b0a505f76165713 10dd62d63446470ba7ec73efe73ac65b--b1ea41cd7a8b45c88b0a505f76165713 24710e5d5f2a449c855d657346f6b815 b1ea41cd7a8b45c88b0a505f76165713--24710e5d5f2a449c855d657346f6b815 edf8e83079094ae9900aac7adb9a4c5f 24710e5d5f2a449c855d657346f6b815--edf8e83079094ae9900aac7adb9a4c5f c51084ab4f224997b01bd7253322aead X edf8e83079094ae9900aac7adb9a4c5f--c51084ab4f224997b01bd7253322aead c51084ab4f224997b01bd7253322aead--215dacf5c2554f6e91b851846576c989 1406a5a652464454a3b5e7685b493986 c51084ab4f224997b01bd7253322aead--1406a5a652464454a3b5e7685b493986 943a8e2155774f699b20c4342ce98912 X 1406a5a652464454a3b5e7685b493986--943a8e2155774f699b20c4342ce98912 943a8e2155774f699b20c4342ce98912--10b6021c4b6a42cebb12b9704cbf87c3 c0d31440259844a3aabd2a30637f03a1 943a8e2155774f699b20c4342ce98912--c0d31440259844a3aabd2a30637f03a1 aceb9051cf644368ad6735d37f4525c5 c0d31440259844a3aabd2a30637f03a1--aceb9051cf644368ad6735d37f4525c5 fc19c3634d7f422da61bf8c4d212d4f3 aceb9051cf644368ad6735d37f4525c5--fc19c3634d7f422da61bf8c4d212d4f3 572108c637a1457bb4a691cd693abecc fc19c3634d7f422da61bf8c4d212d4f3--572108c637a1457bb4a691cd693abecc b87e59d16d68421697a63802c985c195 572108c637a1457bb4a691cd693abecc--b87e59d16d68421697a63802c985c195 2c25830afdaf43f4b985ddf839e47356 b87e59d16d68421697a63802c985c195--2c25830afdaf43f4b985ddf839e47356 9a96deee2426421d9d2471f7fe1737e8 2c25830afdaf43f4b985ddf839e47356--9a96deee2426421d9d2471f7fe1737e8 b7f139c3bbe543929e4e42a939229f2b X 9a96deee2426421d9d2471f7fe1737e8--b7f139c3bbe543929e4e42a939229f2b b7f139c3bbe543929e4e42a939229f2b--e673aebcb22c4161ad2f23d5de35bbaa ed9be36e156948c9ac11cbdd1e05f02b X b7f139c3bbe543929e4e42a939229f2b--ed9be36e156948c9ac11cbdd1e05f02b ed9be36e156948c9ac11cbdd1e05f02b--aaa72eb420d249a4b9d639fb55bb41b6 4693b12b9625478c83da1555ed8f8176 ed9be36e156948c9ac11cbdd1e05f02b--4693b12b9625478c83da1555ed8f8176 eb846ce8e6a54ebbb1c4d025f24715ef 4693b12b9625478c83da1555ed8f8176--eb846ce8e6a54ebbb1c4d025f24715ef fe64963e959d458588376b1871f7558a eb846ce8e6a54ebbb1c4d025f24715ef--fe64963e959d458588376b1871f7558a 0b4b25c5ab004f759bff1c05f3f5242e fe64963e959d458588376b1871f7558a--0b4b25c5ab004f759bff1c05f3f5242e 172f447ec5684ca9a16b80284071a21f 0b4b25c5ab004f759bff1c05f3f5242e--172f447ec5684ca9a16b80284071a21f f8fb45fa763e461984164caed8d060e3 172f447ec5684ca9a16b80284071a21f--f8fb45fa763e461984164caed8d060e3 8ae165e7e9f841358155e5eaaa8f41ca f8fb45fa763e461984164caed8d060e3--8ae165e7e9f841358155e5eaaa8f41ca 3b63ada9fa2846b4914f4dbe3b952a8b 8ae165e7e9f841358155e5eaaa8f41ca--3b63ada9fa2846b4914f4dbe3b952a8b 58067ef827d8434f95e41bcd7fcf8297 3b63ada9fa2846b4914f4dbe3b952a8b--58067ef827d8434f95e41bcd7fcf8297 5db46a16a96f4557822e7f081983c236 X 58067ef827d8434f95e41bcd7fcf8297--5db46a16a96f4557822e7f081983c236 5db46a16a96f4557822e7f081983c236--940dd5a45ede461983fbb256dc0ecb0f 9482d95653ea4a508e612a12da25c4a6 X 5db46a16a96f4557822e7f081983c236--9482d95653ea4a508e612a12da25c4a6 9482d95653ea4a508e612a12da25c4a6--c18ffe2a9ec843c78191e175d9e81979 8cb76630369d46a4bd1b9ffe708fb650 9482d95653ea4a508e612a12da25c4a6--8cb76630369d46a4bd1b9ffe708fb650 3fcad8dd3e6f4233b0560bec3b2d8add 8cb76630369d46a4bd1b9ffe708fb650--3fcad8dd3e6f4233b0560bec3b2d8add c0bfe0c476034ced9a51631aa1728146 3fcad8dd3e6f4233b0560bec3b2d8add--c0bfe0c476034ced9a51631aa1728146 a246fe6dbf84417f8057b76e24dc586c c0bfe0c476034ced9a51631aa1728146--a246fe6dbf84417f8057b76e24dc586c bb551a9d78f04cd2a816f4fd417fcaef a246fe6dbf84417f8057b76e24dc586c--bb551a9d78f04cd2a816f4fd417fcaef 72a0050ea1134a399a565549c8fc3911 bb551a9d78f04cd2a816f4fd417fcaef--72a0050ea1134a399a565549c8fc3911 9720e456f67b4d24a2e54b3212ff7e13 72a0050ea1134a399a565549c8fc3911--9720e456f67b4d24a2e54b3212ff7e13 73b86aea65a94d33b5ff386f3854e4d3 9720e456f67b4d24a2e54b3212ff7e13--73b86aea65a94d33b5ff386f3854e4d3 1943096c5cd24f18bff01f586ce171c5 73b86aea65a94d33b5ff386f3854e4d3--1943096c5cd24f18bff01f586ce171c5 aafddb5f79fa4f4cba4fe522b94cc93a 1943096c5cd24f18bff01f586ce171c5--aafddb5f79fa4f4cba4fe522b94cc93a 0870a168e6fc4d46860746758e59faae aafddb5f79fa4f4cba4fe522b94cc93a--0870a168e6fc4d46860746758e59faae 245a278787bf489d95982a10aa8b8739 X 0870a168e6fc4d46860746758e59faae--245a278787bf489d95982a10aa8b8739 245a278787bf489d95982a10aa8b8739--e6dc94bce3854a5583bcb7434e6f6d52 a13aca97e543456da9b0b01713728639 245a278787bf489d95982a10aa8b8739--a13aca97e543456da9b0b01713728639 1229a644ef494928b6e97a62e025d664 a13aca97e543456da9b0b01713728639--1229a644ef494928b6e97a62e025d664 a0b5ebda185944ac994e98e0af89c7a7 1229a644ef494928b6e97a62e025d664--a0b5ebda185944ac994e98e0af89c7a7 0714262aea6f40b08020547a7fd29bb3 a0b5ebda185944ac994e98e0af89c7a7--0714262aea6f40b08020547a7fd29bb3 37f9e7b5dcb648febb5479890177b79f 0714262aea6f40b08020547a7fd29bb3--37f9e7b5dcb648febb5479890177b79f cef6e5ba1b8544cf8b2bffb4fab3e683 37f9e7b5dcb648febb5479890177b79f--cef6e5ba1b8544cf8b2bffb4fab3e683 ff56bf39ef464073af76c7371ade3d5a cef6e5ba1b8544cf8b2bffb4fab3e683--ff56bf39ef464073af76c7371ade3d5a c0fdec78c30441518bcb7c68acbe0f10 ff56bf39ef464073af76c7371ade3d5a--c0fdec78c30441518bcb7c68acbe0f10 7b33e6a53d494ec29cd7f9b03c6ff386 c0fdec78c30441518bcb7c68acbe0f10--7b33e6a53d494ec29cd7f9b03c6ff386 f9de1486b2314eaabbd477c6029a2ccc 7b33e6a53d494ec29cd7f9b03c6ff386--f9de1486b2314eaabbd477c6029a2ccc 796061db42b2462485c9e78b519335a5 f9de1486b2314eaabbd477c6029a2ccc--796061db42b2462485c9e78b519335a5 6533a10d52984d7e9aed79086dc1ef46 796061db42b2462485c9e78b519335a5--6533a10d52984d7e9aed79086dc1ef46 05ccb7871fee4b1c8d39534878718afc 6533a10d52984d7e9aed79086dc1ef46--05ccb7871fee4b1c8d39534878718afc 4e82c10e3892451298c84d934032d8c2 05ccb7871fee4b1c8d39534878718afc--4e82c10e3892451298c84d934032d8c2 399edb42222c454d91819ded0f04df00 4e82c10e3892451298c84d934032d8c2--399edb42222c454d91819ded0f04df00 80aaa00c53fc45bea89f055c6d06c635 399edb42222c454d91819ded0f04df00--80aaa00c53fc45bea89f055c6d06c635 ca5c6c85969e40edb4302dc56378dc80 80aaa00c53fc45bea89f055c6d06c635--ca5c6c85969e40edb4302dc56378dc80 dca5f29983af44f28644c80e3dc3f505 ca5c6c85969e40edb4302dc56378dc80--dca5f29983af44f28644c80e3dc3f505 88d578df35454c488aeb7466160bab80 dca5f29983af44f28644c80e3dc3f505--88d578df35454c488aeb7466160bab80 33381c6396bd4517997542a102bfafb0 88d578df35454c488aeb7466160bab80--33381c6396bd4517997542a102bfafb0 aa117374fc794257aeb804c3b504666d 33381c6396bd4517997542a102bfafb0--aa117374fc794257aeb804c3b504666d 8633e13a0e83482bbb08c6800e210828 aa117374fc794257aeb804c3b504666d--8633e13a0e83482bbb08c6800e210828 3c0efd0cacb74128af266869148aa571 8633e13a0e83482bbb08c6800e210828--3c0efd0cacb74128af266869148aa571 f82151ffb6fe4a9f8c5995f60910320d 3c0efd0cacb74128af266869148aa571--f82151ffb6fe4a9f8c5995f60910320d c5df55d213764a94a0b88e8b4a08d8da f82151ffb6fe4a9f8c5995f60910320d--c5df55d213764a94a0b88e8b4a08d8da c2d6856796954d268ab5bbddb3505389 c5df55d213764a94a0b88e8b4a08d8da--c2d6856796954d268ab5bbddb3505389 5e75b81bdf314933b855eec1863c910c c2d6856796954d268ab5bbddb3505389--5e75b81bdf314933b855eec1863c910c 1251fa0d21204ef6bc550b81ff1dbd09 5e75b81bdf314933b855eec1863c910c--1251fa0d21204ef6bc550b81ff1dbd09 fce7d4408fc74a1abd388ea8010b626d 1251fa0d21204ef6bc550b81ff1dbd09--fce7d4408fc74a1abd388ea8010b626d 064cdc55a6d64c079c5a43049dcf7ec1 fce7d4408fc74a1abd388ea8010b626d--064cdc55a6d64c079c5a43049dcf7ec1 08bd22233d23422999b9e23ca4935ffb 064cdc55a6d64c079c5a43049dcf7ec1--08bd22233d23422999b9e23ca4935ffb ddc6273e081c4bfabf150dd4c498d3b5 08bd22233d23422999b9e23ca4935ffb--ddc6273e081c4bfabf150dd4c498d3b5 af6294a58c044f399b41fcd7a8f0e7bf ddc6273e081c4bfabf150dd4c498d3b5--af6294a58c044f399b41fcd7a8f0e7bf 71ae44e2d16f4d7f8299027cf6684e93 af6294a58c044f399b41fcd7a8f0e7bf--71ae44e2d16f4d7f8299027cf6684e93 6a842f594a3b4feeab60ff83bb0cbdee 71ae44e2d16f4d7f8299027cf6684e93--6a842f594a3b4feeab60ff83bb0cbdee 9fbd990f3b9f4815a37f52c6be7a8b4d 6a842f594a3b4feeab60ff83bb0cbdee--9fbd990f3b9f4815a37f52c6be7a8b4d 1233bfeba1e54c97bede0dd671373fcd 9fbd990f3b9f4815a37f52c6be7a8b4d--1233bfeba1e54c97bede0dd671373fcd 75fc34f969514ada89653a5a82d4b77a 1233bfeba1e54c97bede0dd671373fcd--75fc34f969514ada89653a5a82d4b77a d68dfd1a0e264bcca743b973e263224f 75fc34f969514ada89653a5a82d4b77a--d68dfd1a0e264bcca743b973e263224f 6bae273c896e492fb8bfb62977d40f80 d68dfd1a0e264bcca743b973e263224f--6bae273c896e492fb8bfb62977d40f80 acec6892163b42298257b211fe88c4a1 6bae273c896e492fb8bfb62977d40f80--acec6892163b42298257b211fe88c4a1 860c8e844fe24492bde51e94fe5fde5b acec6892163b42298257b211fe88c4a1--860c8e844fe24492bde51e94fe5fde5b 3c35ba551aad410793497de142253950 860c8e844fe24492bde51e94fe5fde5b--3c35ba551aad410793497de142253950 9ebd6883a85e4eae9f4a960e7a3194c8 3c35ba551aad410793497de142253950--9ebd6883a85e4eae9f4a960e7a3194c8 680f57d19e7e472580e0d1ffc20e04d1 9ebd6883a85e4eae9f4a960e7a3194c8--680f57d19e7e472580e0d1ffc20e04d1 8782b83155e449fd8352ed884573a92a 680f57d19e7e472580e0d1ffc20e04d1--8782b83155e449fd8352ed884573a92a 01d0859a23a4430989382d26512a4a56 8782b83155e449fd8352ed884573a92a--01d0859a23a4430989382d26512a4a56 2d14dccda08e4920add9247880cb1659 01d0859a23a4430989382d26512a4a56--2d14dccda08e4920add9247880cb1659 85bdb8f941ef4bd0b360afc27619af15 2d14dccda08e4920add9247880cb1659--85bdb8f941ef4bd0b360afc27619af15 ea80be4514f44f15899c2dd8f3998dab 85bdb8f941ef4bd0b360afc27619af15--ea80be4514f44f15899c2dd8f3998dab 9cf7d684b08e48a4862cb7fd2cccb3bd ea80be4514f44f15899c2dd8f3998dab--9cf7d684b08e48a4862cb7fd2cccb3bd f4966c6f0c914737b7de1a3fdd1246d6 9cf7d684b08e48a4862cb7fd2cccb3bd--f4966c6f0c914737b7de1a3fdd1246d6 6a46732d56d84007b34418b0100c3117 f4966c6f0c914737b7de1a3fdd1246d6--6a46732d56d84007b34418b0100c3117 925292e415b845669eb556fa643a0315 6a46732d56d84007b34418b0100c3117--925292e415b845669eb556fa643a0315 01be9e34e5a845e2a2f01244b00cc1e1 925292e415b845669eb556fa643a0315--01be9e34e5a845e2a2f01244b00cc1e1 c82867b16f494647b9bffba158990825 01be9e34e5a845e2a2f01244b00cc1e1--c82867b16f494647b9bffba158990825 30ec2eb5877a44469eed15f67111facb c82867b16f494647b9bffba158990825--30ec2eb5877a44469eed15f67111facb 150a53d30fb948a4b4923812be641170 30ec2eb5877a44469eed15f67111facb--150a53d30fb948a4b4923812be641170 08d31da3faa948bc8e240c7d08287d20 RX(b12) 150a53d30fb948a4b4923812be641170--08d31da3faa948bc8e240c7d08287d20 08d31da3faa948bc8e240c7d08287d20--402ef3c8843f44a0893f1b7f7ef61f26 00687455797a42d29456f723349cc506 b099adbfdc3849ac86d9009570530b1f 4de47c75478c4b26940bbd99d8599bae--b099adbfdc3849ac86d9009570530b1f c8cacdb0e3d24653866ae349be377fb0 4 9db366ff3aed4ffeb5c2f017ed48ddf2 b099adbfdc3849ac86d9009570530b1f--9db366ff3aed4ffeb5c2f017ed48ddf2 04e65ac578e84ed7ad96973aa4113398 X 9db366ff3aed4ffeb5c2f017ed48ddf2--04e65ac578e84ed7ad96973aa4113398 04e65ac578e84ed7ad96973aa4113398--04f4824149f949b6a887a91ea13f84de 278bbb507723466fb6e6f1a5ad42137a 04e65ac578e84ed7ad96973aa4113398--278bbb507723466fb6e6f1a5ad42137a 7283ec676788437cbdfb53d1f500ab26 278bbb507723466fb6e6f1a5ad42137a--7283ec676788437cbdfb53d1f500ab26 8db5e3243b514068be9c66d7f276f94b 7283ec676788437cbdfb53d1f500ab26--8db5e3243b514068be9c66d7f276f94b 26a7bc8e8fb14e80aceb3b3815db42dd 8db5e3243b514068be9c66d7f276f94b--26a7bc8e8fb14e80aceb3b3815db42dd 970b8f74978f4b6ea8176dbd16ec4775 26a7bc8e8fb14e80aceb3b3815db42dd--970b8f74978f4b6ea8176dbd16ec4775 ccc60776c39d47d6812f116c78c49c59 970b8f74978f4b6ea8176dbd16ec4775--ccc60776c39d47d6812f116c78c49c59 1fb7008b35d648ebb5725c963e267bc4 ccc60776c39d47d6812f116c78c49c59--1fb7008b35d648ebb5725c963e267bc4 efb41319896c4f5895a03b583e014425 1fb7008b35d648ebb5725c963e267bc4--efb41319896c4f5895a03b583e014425 602266fbcd2549a794889ac909fb539c efb41319896c4f5895a03b583e014425--602266fbcd2549a794889ac909fb539c 407fe60c72b444418b20b605d05b25c7 X 602266fbcd2549a794889ac909fb539c--407fe60c72b444418b20b605d05b25c7 407fe60c72b444418b20b605d05b25c7--7a66796fc1bc4fdb9c2d58037500b734 7bb5c8b1c83d4eef8e3bf2f82d081d50 407fe60c72b444418b20b605d05b25c7--7bb5c8b1c83d4eef8e3bf2f82d081d50 99a7082f67bd4a3883676a84f9d08068 7bb5c8b1c83d4eef8e3bf2f82d081d50--99a7082f67bd4a3883676a84f9d08068 49baea7998694e8dad00da2d4f8c1072 99a7082f67bd4a3883676a84f9d08068--49baea7998694e8dad00da2d4f8c1072 a0411a49e6024c938f728f3eff815075 49baea7998694e8dad00da2d4f8c1072--a0411a49e6024c938f728f3eff815075 ebb11f5e44104b7e9a73e4aaf664faf2 a0411a49e6024c938f728f3eff815075--ebb11f5e44104b7e9a73e4aaf664faf2 9e999fd3e76e4dc28102329bcdd96046 ebb11f5e44104b7e9a73e4aaf664faf2--9e999fd3e76e4dc28102329bcdd96046 73b95f81e492489496a1a003a7af56a5 9e999fd3e76e4dc28102329bcdd96046--73b95f81e492489496a1a003a7af56a5 a75e91d5cb2843918ff222667d59b675 73b95f81e492489496a1a003a7af56a5--a75e91d5cb2843918ff222667d59b675 6f56f409e1c342b595e13e4258308fe4 a75e91d5cb2843918ff222667d59b675--6f56f409e1c342b595e13e4258308fe4 530ffc4f73944e408715493ee006988f 6f56f409e1c342b595e13e4258308fe4--530ffc4f73944e408715493ee006988f 8a1791c5730a49f68abff91767012ef6 530ffc4f73944e408715493ee006988f--8a1791c5730a49f68abff91767012ef6 42cfdd5eebe84f53b914ea2c83409e04 8a1791c5730a49f68abff91767012ef6--42cfdd5eebe84f53b914ea2c83409e04 df1af656c0d84c0880cba31f904cf5b1 X 42cfdd5eebe84f53b914ea2c83409e04--df1af656c0d84c0880cba31f904cf5b1 df1af656c0d84c0880cba31f904cf5b1--87f600d1926645529b561d81f0792315 9cc6f6eda53d428696c1e6f07a390128 df1af656c0d84c0880cba31f904cf5b1--9cc6f6eda53d428696c1e6f07a390128 e2f5745ec28549d4b12179b5f886ce19 9cc6f6eda53d428696c1e6f07a390128--e2f5745ec28549d4b12179b5f886ce19 b8af31d69a66430f8cf24ef1b08c5e28 e2f5745ec28549d4b12179b5f886ce19--b8af31d69a66430f8cf24ef1b08c5e28 4f0641687c7140fdadac812a5f1bae7c X b8af31d69a66430f8cf24ef1b08c5e28--4f0641687c7140fdadac812a5f1bae7c 4f0641687c7140fdadac812a5f1bae7c--ec026dc052604f40b4b48f3508fa43a5 0e42652daa7642059c256b7c554a7408 4f0641687c7140fdadac812a5f1bae7c--0e42652daa7642059c256b7c554a7408 7926bfbfd6ad4627a18e96c7dbe62339 0e42652daa7642059c256b7c554a7408--7926bfbfd6ad4627a18e96c7dbe62339 cd76ac37ea2943bf8cd8c1d745481047 7926bfbfd6ad4627a18e96c7dbe62339--cd76ac37ea2943bf8cd8c1d745481047 8c6b49a3d5bc49d885eaba03b4f369d0 cd76ac37ea2943bf8cd8c1d745481047--8c6b49a3d5bc49d885eaba03b4f369d0 4127af3a059a4fbda4c707de4d1c1d90 X 8c6b49a3d5bc49d885eaba03b4f369d0--4127af3a059a4fbda4c707de4d1c1d90 4127af3a059a4fbda4c707de4d1c1d90--a7d90385f6b24eaaaef08539f3435543 ccc95afa65d8402984a66cabf1bf0bec 4127af3a059a4fbda4c707de4d1c1d90--ccc95afa65d8402984a66cabf1bf0bec 1f0fb6f5b7264f28b714736ebfe13cc4 ccc95afa65d8402984a66cabf1bf0bec--1f0fb6f5b7264f28b714736ebfe13cc4 28ce9794bb52446aa7824abea4807678 1f0fb6f5b7264f28b714736ebfe13cc4--28ce9794bb52446aa7824abea4807678 35957db541ae42459cd9ebbd22e5f765 28ce9794bb52446aa7824abea4807678--35957db541ae42459cd9ebbd22e5f765 f56ceb2d6db44b6b81364e999260bd54 35957db541ae42459cd9ebbd22e5f765--f56ceb2d6db44b6b81364e999260bd54 b44f34d2e09d40379c06a5d979ee0cb9 f56ceb2d6db44b6b81364e999260bd54--b44f34d2e09d40379c06a5d979ee0cb9 148b8272789743db893862cf61d87920 b44f34d2e09d40379c06a5d979ee0cb9--148b8272789743db893862cf61d87920 0927761016d14a3b9863e9880dbc187d 148b8272789743db893862cf61d87920--0927761016d14a3b9863e9880dbc187d 0c52994475db49cb96506c23b21625a1 0927761016d14a3b9863e9880dbc187d--0c52994475db49cb96506c23b21625a1 78b630dd54d840b6996bd5e221858c78 X 0c52994475db49cb96506c23b21625a1--78b630dd54d840b6996bd5e221858c78 78b630dd54d840b6996bd5e221858c78--173783d82a5c48b7a1edd5813c1e946c 3ce73916f7624aef9ecc1d25fd02439c 78b630dd54d840b6996bd5e221858c78--3ce73916f7624aef9ecc1d25fd02439c 6b9f9e90dc6c40ecbe07968d1b2e8cbf 3ce73916f7624aef9ecc1d25fd02439c--6b9f9e90dc6c40ecbe07968d1b2e8cbf 91756ec6f6474e09bb0f5bd745e376dd 6b9f9e90dc6c40ecbe07968d1b2e8cbf--91756ec6f6474e09bb0f5bd745e376dd b3a8738311d84392856696dbf57ddcec X 91756ec6f6474e09bb0f5bd745e376dd--b3a8738311d84392856696dbf57ddcec b3a8738311d84392856696dbf57ddcec--772f9bc990f64401825971afa475b91c 5c05c160cd134d9da588cf20d3a1375d b3a8738311d84392856696dbf57ddcec--5c05c160cd134d9da588cf20d3a1375d a7906170a3804220b8d16ed35bef20c9 5c05c160cd134d9da588cf20d3a1375d--a7906170a3804220b8d16ed35bef20c9 ab5df40fab7b480fb635fe8295a8d64f a7906170a3804220b8d16ed35bef20c9--ab5df40fab7b480fb635fe8295a8d64f 6cf3184c286945a28130b4144519a734 ab5df40fab7b480fb635fe8295a8d64f--6cf3184c286945a28130b4144519a734 bdd709ae8a3f422e97642b08e1c53089 6cf3184c286945a28130b4144519a734--bdd709ae8a3f422e97642b08e1c53089 fbf14a74dc484c399d99916a99fc2502 X bdd709ae8a3f422e97642b08e1c53089--fbf14a74dc484c399d99916a99fc2502 fbf14a74dc484c399d99916a99fc2502--316a3912bb5a4ec4988e27a97a16eb35 d6caa57f4c0349349ed74992690f979d fbf14a74dc484c399d99916a99fc2502--d6caa57f4c0349349ed74992690f979d 8d7cdc5cde7441db8d5682fec773951d d6caa57f4c0349349ed74992690f979d--8d7cdc5cde7441db8d5682fec773951d aa4e5a73ae22454cb873e0cfbe30fe05 X 8d7cdc5cde7441db8d5682fec773951d--aa4e5a73ae22454cb873e0cfbe30fe05 aa4e5a73ae22454cb873e0cfbe30fe05--3787fbb167bc474da644502072df67fc 992b07efa4d345aeb7641f531088cb82 aa4e5a73ae22454cb873e0cfbe30fe05--992b07efa4d345aeb7641f531088cb82 0de64858a642466dbb4edfe07cc3e346 992b07efa4d345aeb7641f531088cb82--0de64858a642466dbb4edfe07cc3e346 9d9bc983d2c0449db0809c3f25310371 0de64858a642466dbb4edfe07cc3e346--9d9bc983d2c0449db0809c3f25310371 b179f97590a9472188290fc90c673e70 9d9bc983d2c0449db0809c3f25310371--b179f97590a9472188290fc90c673e70 ca68a4cde8c04053a28b748dbd527624 b179f97590a9472188290fc90c673e70--ca68a4cde8c04053a28b748dbd527624 9693ab528cfc47f5a6026923dad2f38c ca68a4cde8c04053a28b748dbd527624--9693ab528cfc47f5a6026923dad2f38c eea2958374684880be91185d0e559337 9693ab528cfc47f5a6026923dad2f38c--eea2958374684880be91185d0e559337 f11941d8e7d046a489dc7329946de73a X eea2958374684880be91185d0e559337--f11941d8e7d046a489dc7329946de73a f11941d8e7d046a489dc7329946de73a--1a7a6c75a53f465b9524b7965a401e8f d27d673115bb46929e130d4edc011379 f11941d8e7d046a489dc7329946de73a--d27d673115bb46929e130d4edc011379 2cefb5e0f64540e88e313527bedcb314 d27d673115bb46929e130d4edc011379--2cefb5e0f64540e88e313527bedcb314 118d9a0b3fa540ff9e6f3f4bbe58b545 X 2cefb5e0f64540e88e313527bedcb314--118d9a0b3fa540ff9e6f3f4bbe58b545 118d9a0b3fa540ff9e6f3f4bbe58b545--d158662f226841b7a57196d28da3eced 84730bfb42d840f886bba033bf42d11a 118d9a0b3fa540ff9e6f3f4bbe58b545--84730bfb42d840f886bba033bf42d11a ad19826bb25849b0a6e73f9e95d6be34 84730bfb42d840f886bba033bf42d11a--ad19826bb25849b0a6e73f9e95d6be34 25fa24401286407e936db830995c1e83 ad19826bb25849b0a6e73f9e95d6be34--25fa24401286407e936db830995c1e83 246d92e8096a443d8e0caa941027cab3 25fa24401286407e936db830995c1e83--246d92e8096a443d8e0caa941027cab3 acbde7063da1432fad40b2920d067458 246d92e8096a443d8e0caa941027cab3--acbde7063da1432fad40b2920d067458 a5db1cf7e8de4e7581944e0f79fe7019 acbde7063da1432fad40b2920d067458--a5db1cf7e8de4e7581944e0f79fe7019 9ae0c6a0b817421c827b8ddc8bba68bf a5db1cf7e8de4e7581944e0f79fe7019--9ae0c6a0b817421c827b8ddc8bba68bf 2b57f0154bc2488199487b16fbdcfdf2 9ae0c6a0b817421c827b8ddc8bba68bf--2b57f0154bc2488199487b16fbdcfdf2 e59ecf21a9d34015aa1b9935478997ff 2b57f0154bc2488199487b16fbdcfdf2--e59ecf21a9d34015aa1b9935478997ff 14b14fb53eae4c869c6bab9afe05bb5e X e59ecf21a9d34015aa1b9935478997ff--14b14fb53eae4c869c6bab9afe05bb5e 14b14fb53eae4c869c6bab9afe05bb5e--9aa14ac4a3aa4c02a3a9a9aef7e90e33 bd93a5aa95704bbbad53bb8ca26ad4bc 14b14fb53eae4c869c6bab9afe05bb5e--bd93a5aa95704bbbad53bb8ca26ad4bc 84b31dcd0fe54182a3e5a079c4146957 X bd93a5aa95704bbbad53bb8ca26ad4bc--84b31dcd0fe54182a3e5a079c4146957 84b31dcd0fe54182a3e5a079c4146957--1822dd2537c94ac18a7d66fc1426cfc8 5b13ccdb92b547a3a8416a9c75ec0083 84b31dcd0fe54182a3e5a079c4146957--5b13ccdb92b547a3a8416a9c75ec0083 38e9aa3617ed4952904ae9a77dff948a 5b13ccdb92b547a3a8416a9c75ec0083--38e9aa3617ed4952904ae9a77dff948a e391ff73e8284b578ee7bcfe1d75f499 38e9aa3617ed4952904ae9a77dff948a--e391ff73e8284b578ee7bcfe1d75f499 4b487daaaf8749b59dfc4cae909e54ff X e391ff73e8284b578ee7bcfe1d75f499--4b487daaaf8749b59dfc4cae909e54ff 4b487daaaf8749b59dfc4cae909e54ff--959e277c379a432bb39e1079e6972781 8be4a887cbfa4f81b25be5b2e050cde1 X 4b487daaaf8749b59dfc4cae909e54ff--8be4a887cbfa4f81b25be5b2e050cde1 8be4a887cbfa4f81b25be5b2e050cde1--5349c964cb534e8998416d7b8618f06b 21bce9a009514f39aef18130a629767e 8be4a887cbfa4f81b25be5b2e050cde1--21bce9a009514f39aef18130a629767e 3a5ce0f673c9434c9422490b825ee4d4 21bce9a009514f39aef18130a629767e--3a5ce0f673c9434c9422490b825ee4d4 9dd4628ed5d347e09e42f9b3a0eb0618 3a5ce0f673c9434c9422490b825ee4d4--9dd4628ed5d347e09e42f9b3a0eb0618 9d273e967bb744739fe7f84f1ea6b101 9dd4628ed5d347e09e42f9b3a0eb0618--9d273e967bb744739fe7f84f1ea6b101 847cb25d7b0343ba82d410af6d8ec40b 9d273e967bb744739fe7f84f1ea6b101--847cb25d7b0343ba82d410af6d8ec40b e0502d4cba7b42faa1cf4c4ebd385c51 X 847cb25d7b0343ba82d410af6d8ec40b--e0502d4cba7b42faa1cf4c4ebd385c51 e0502d4cba7b42faa1cf4c4ebd385c51--b981a23d74ff409ab1a99fa79743849c 6b264571994e4d8b8ad25912561fc483 X e0502d4cba7b42faa1cf4c4ebd385c51--6b264571994e4d8b8ad25912561fc483 6b264571994e4d8b8ad25912561fc483--ba7c440f401e46ad8eacc79eceec6d8b d37689faff734d4dbed034edf8428764 6b264571994e4d8b8ad25912561fc483--d37689faff734d4dbed034edf8428764 f6995544534d4d4ebe80b05072db8e4c d37689faff734d4dbed034edf8428764--f6995544534d4d4ebe80b05072db8e4c 2655dd0bdfa941d0b6d58b2b1427d977 f6995544534d4d4ebe80b05072db8e4c--2655dd0bdfa941d0b6d58b2b1427d977 85a261de9fff445a91ed253358e2445e 2655dd0bdfa941d0b6d58b2b1427d977--85a261de9fff445a91ed253358e2445e d6f8e9ddba41422ba099152d57414987 85a261de9fff445a91ed253358e2445e--d6f8e9ddba41422ba099152d57414987 ad8c3745fe7c490bb7a9776cfa1eec40 d6f8e9ddba41422ba099152d57414987--ad8c3745fe7c490bb7a9776cfa1eec40 0b5ef6e6ff054526af85a63cbd57f6a9 ad8c3745fe7c490bb7a9776cfa1eec40--0b5ef6e6ff054526af85a63cbd57f6a9 882ec7b4cd2b4ff6944e2929cd568586 0b5ef6e6ff054526af85a63cbd57f6a9--882ec7b4cd2b4ff6944e2929cd568586 56fa3ba43e094d76afe417ff142aec19 882ec7b4cd2b4ff6944e2929cd568586--56fa3ba43e094d76afe417ff142aec19 5434498daed840d485915324381e77bd X 56fa3ba43e094d76afe417ff142aec19--5434498daed840d485915324381e77bd 5434498daed840d485915324381e77bd--80305629f1c24731bbd59d0569e98105 992ba4f45fe74becb0d7ef05a70acd15 5434498daed840d485915324381e77bd--992ba4f45fe74becb0d7ef05a70acd15 bdb1b5ebf8f742908c0efe457dff5612 992ba4f45fe74becb0d7ef05a70acd15--bdb1b5ebf8f742908c0efe457dff5612 f6ea3013e5a64bb3b465f2de0de2d6cb bdb1b5ebf8f742908c0efe457dff5612--f6ea3013e5a64bb3b465f2de0de2d6cb e2d1d1414e0846c98d8f250485e2cee1 f6ea3013e5a64bb3b465f2de0de2d6cb--e2d1d1414e0846c98d8f250485e2cee1 c9ca6461a12e469d89f0a84510e5140f e2d1d1414e0846c98d8f250485e2cee1--c9ca6461a12e469d89f0a84510e5140f d0b46ec25faa4ee181a1cb944b62375e c9ca6461a12e469d89f0a84510e5140f--d0b46ec25faa4ee181a1cb944b62375e bb79d29d60b14150b05c69c61cdfae53 d0b46ec25faa4ee181a1cb944b62375e--bb79d29d60b14150b05c69c61cdfae53 bba0b097197b47a6967189f27ecfd646 bb79d29d60b14150b05c69c61cdfae53--bba0b097197b47a6967189f27ecfd646 ecd519dbc1414b349a6eccfc0e4dc179 bba0b097197b47a6967189f27ecfd646--ecd519dbc1414b349a6eccfc0e4dc179 c3cdfd3693024675b108ca0a60044dc7 ecd519dbc1414b349a6eccfc0e4dc179--c3cdfd3693024675b108ca0a60044dc7 842b9bba963c40bd816093732ca0f748 c3cdfd3693024675b108ca0a60044dc7--842b9bba963c40bd816093732ca0f748 fa0696a969544cc78fc3f2d1c29849c7 842b9bba963c40bd816093732ca0f748--fa0696a969544cc78fc3f2d1c29849c7 d365ca1472244369aa660383266b5826 fa0696a969544cc78fc3f2d1c29849c7--d365ca1472244369aa660383266b5826 11c6b022a91e46349b1103944e3af634 d365ca1472244369aa660383266b5826--11c6b022a91e46349b1103944e3af634 5c1a1ed8a29444408182122695e8ac28 11c6b022a91e46349b1103944e3af634--5c1a1ed8a29444408182122695e8ac28 af19983df59d464daae21d67331277a2 5c1a1ed8a29444408182122695e8ac28--af19983df59d464daae21d67331277a2 a1e467faa9c84e808ce4056b7f4e27f8 af19983df59d464daae21d67331277a2--a1e467faa9c84e808ce4056b7f4e27f8 83afc2abf9e149d19b361c0cebe3c44e a1e467faa9c84e808ce4056b7f4e27f8--83afc2abf9e149d19b361c0cebe3c44e e7dee56e37b44de38e20969c7660bf3e 83afc2abf9e149d19b361c0cebe3c44e--e7dee56e37b44de38e20969c7660bf3e 6a2e6a0ed1a6460cb7140228d78e51ad e7dee56e37b44de38e20969c7660bf3e--6a2e6a0ed1a6460cb7140228d78e51ad 5a76fb89bf774e26a2ed86aeae3d6f80 6a2e6a0ed1a6460cb7140228d78e51ad--5a76fb89bf774e26a2ed86aeae3d6f80 7718e3fd048946aca23b6f40162f700f 5a76fb89bf774e26a2ed86aeae3d6f80--7718e3fd048946aca23b6f40162f700f 96f1b73233d6420a9b76e6f1d5b219a5 7718e3fd048946aca23b6f40162f700f--96f1b73233d6420a9b76e6f1d5b219a5 370515ca75504b1b85dab372222e1a50 96f1b73233d6420a9b76e6f1d5b219a5--370515ca75504b1b85dab372222e1a50 835698d5f59d4bd5aebe6879edf002b1 370515ca75504b1b85dab372222e1a50--835698d5f59d4bd5aebe6879edf002b1 d8b4c7d03c6c42ea8add024960f3a1c4 835698d5f59d4bd5aebe6879edf002b1--d8b4c7d03c6c42ea8add024960f3a1c4 6f10d867908a40db947eada1ae948957 d8b4c7d03c6c42ea8add024960f3a1c4--6f10d867908a40db947eada1ae948957 784695deeee747f89ec5177224cab6f2 6f10d867908a40db947eada1ae948957--784695deeee747f89ec5177224cab6f2 b21f44e93c704946b4b7246e989c5044 784695deeee747f89ec5177224cab6f2--b21f44e93c704946b4b7246e989c5044 265ed1103aa641a2bf46571afca0ed40 b21f44e93c704946b4b7246e989c5044--265ed1103aa641a2bf46571afca0ed40 9ceef59860004f099421f13a45210ff1 265ed1103aa641a2bf46571afca0ed40--9ceef59860004f099421f13a45210ff1 374f6674a40145d095546094a1d43862 9ceef59860004f099421f13a45210ff1--374f6674a40145d095546094a1d43862 ddc4ebfdb72d40729db76a1d23a963ca 374f6674a40145d095546094a1d43862--ddc4ebfdb72d40729db76a1d23a963ca c9a1270fa4e44cc685868d1bfed4170c ddc4ebfdb72d40729db76a1d23a963ca--c9a1270fa4e44cc685868d1bfed4170c 6e6fe972c9cb4bb7ae64dc4f67e9aa90 c9a1270fa4e44cc685868d1bfed4170c--6e6fe972c9cb4bb7ae64dc4f67e9aa90 422bbebf51704aebad6e391b681f0464 RX(b03) 6e6fe972c9cb4bb7ae64dc4f67e9aa90--422bbebf51704aebad6e391b681f0464 5f622eaf434a477e9478d6396676e800 422bbebf51704aebad6e391b681f0464--5f622eaf434a477e9478d6396676e800 a3c9b4004d064ed284342fcb57e877de 5f622eaf434a477e9478d6396676e800--a3c9b4004d064ed284342fcb57e877de 5ddb7fb5c4cf43cbb4cdeecc5cee8854 X a3c9b4004d064ed284342fcb57e877de--5ddb7fb5c4cf43cbb4cdeecc5cee8854 5ddb7fb5c4cf43cbb4cdeecc5cee8854--1e3661c98dcd42db8705e1400e1c94b6 9a586d1320494d1cb32ebcb46ec726e9 5ddb7fb5c4cf43cbb4cdeecc5cee8854--9a586d1320494d1cb32ebcb46ec726e9 843a269df3e74fceb0e924d0b5a79a5e 9a586d1320494d1cb32ebcb46ec726e9--843a269df3e74fceb0e924d0b5a79a5e 519ea03f89db4d0191575edcd57b3ab8 843a269df3e74fceb0e924d0b5a79a5e--519ea03f89db4d0191575edcd57b3ab8 33e989a0ad05423e9578603628d89ec3 519ea03f89db4d0191575edcd57b3ab8--33e989a0ad05423e9578603628d89ec3 e7f9e42c0bc448a18dabff3c2ebeb58e 33e989a0ad05423e9578603628d89ec3--e7f9e42c0bc448a18dabff3c2ebeb58e 4d7977ddc37e4764b0ad268158935a6e e7f9e42c0bc448a18dabff3c2ebeb58e--4d7977ddc37e4764b0ad268158935a6e ac0c3e13c1d748399a96f1576b16bbff 4d7977ddc37e4764b0ad268158935a6e--ac0c3e13c1d748399a96f1576b16bbff 3333323624e24056b3933b7fe03f52c1 ac0c3e13c1d748399a96f1576b16bbff--3333323624e24056b3933b7fe03f52c1 0bc4527884d74e9198210c4e5ca16813 3333323624e24056b3933b7fe03f52c1--0bc4527884d74e9198210c4e5ca16813 ac43a01fe27941ec87d9247aff04cb5f X 0bc4527884d74e9198210c4e5ca16813--ac43a01fe27941ec87d9247aff04cb5f ac43a01fe27941ec87d9247aff04cb5f--4e9882b7f3a5478f9fe9d45310960a72 99232f71694247f4b3d476633629679b ac43a01fe27941ec87d9247aff04cb5f--99232f71694247f4b3d476633629679b 76a4a81cb9c5402d9001af27133fbdf0 99232f71694247f4b3d476633629679b--76a4a81cb9c5402d9001af27133fbdf0 2c498d566f1346a59f5f8e9667bf57ef 76a4a81cb9c5402d9001af27133fbdf0--2c498d566f1346a59f5f8e9667bf57ef 96b275f59e5f4f19a2ae8420fac8e07b 2c498d566f1346a59f5f8e9667bf57ef--96b275f59e5f4f19a2ae8420fac8e07b 547d09e3929945b7ad17bb91c4941840 96b275f59e5f4f19a2ae8420fac8e07b--547d09e3929945b7ad17bb91c4941840 0c666f7c87744363800e4da664a5b182 547d09e3929945b7ad17bb91c4941840--0c666f7c87744363800e4da664a5b182 c582f7320d8d40eaa18d23dd0b0797cb 0c666f7c87744363800e4da664a5b182--c582f7320d8d40eaa18d23dd0b0797cb 3243b7c5b38e40149b04e54be8e6ae92 c582f7320d8d40eaa18d23dd0b0797cb--3243b7c5b38e40149b04e54be8e6ae92 8092f9d0edd64fca88767e8d3551d4e9 3243b7c5b38e40149b04e54be8e6ae92--8092f9d0edd64fca88767e8d3551d4e9 5a341ffd69844211bba111ea165247c7 8092f9d0edd64fca88767e8d3551d4e9--5a341ffd69844211bba111ea165247c7 b091de39400d4c6ca11e054e7be8dc4d 5a341ffd69844211bba111ea165247c7--b091de39400d4c6ca11e054e7be8dc4d 69c4b14434ac44f4991c24545cf7f4d1 b091de39400d4c6ca11e054e7be8dc4d--69c4b14434ac44f4991c24545cf7f4d1 458855ed227f4f6fafe8def96886c3d3 X 69c4b14434ac44f4991c24545cf7f4d1--458855ed227f4f6fafe8def96886c3d3 458855ed227f4f6fafe8def96886c3d3--84ffbaf85e5046bea58ca50e61ef8880 f0b53fa76ea440deb12ca1933222f6da 458855ed227f4f6fafe8def96886c3d3--f0b53fa76ea440deb12ca1933222f6da cb73e758aed648678f9eeb874830205a f0b53fa76ea440deb12ca1933222f6da--cb73e758aed648678f9eeb874830205a 403630e9ee024ec1a6a6ed2aa2e7907b cb73e758aed648678f9eeb874830205a--403630e9ee024ec1a6a6ed2aa2e7907b 45831e1e93714eb88df8f2f56f8a35ea X 403630e9ee024ec1a6a6ed2aa2e7907b--45831e1e93714eb88df8f2f56f8a35ea 45831e1e93714eb88df8f2f56f8a35ea--c296768cb0304581bd2ce164ebf1a8c3 9b0fff672c554a4587cda07c7ef34390 45831e1e93714eb88df8f2f56f8a35ea--9b0fff672c554a4587cda07c7ef34390 4e58c94ed03641f2931641f7bf1e1c54 9b0fff672c554a4587cda07c7ef34390--4e58c94ed03641f2931641f7bf1e1c54 639c5eabf5b347ebb528585d32bc1f2b 4e58c94ed03641f2931641f7bf1e1c54--639c5eabf5b347ebb528585d32bc1f2b c4b4f70db28d48f095e106764857a550 639c5eabf5b347ebb528585d32bc1f2b--c4b4f70db28d48f095e106764857a550 8b11b0003d2d41c1bbf31e1732e2e878 X c4b4f70db28d48f095e106764857a550--8b11b0003d2d41c1bbf31e1732e2e878 8b11b0003d2d41c1bbf31e1732e2e878--815f921455a04b6b845b9398bf32edf9 fac3dc98937344639b3d96f617a6e20f 8b11b0003d2d41c1bbf31e1732e2e878--fac3dc98937344639b3d96f617a6e20f cbf2d90995154fbd9f4095a440a5cfcf fac3dc98937344639b3d96f617a6e20f--cbf2d90995154fbd9f4095a440a5cfcf 9b40bd74f8fa4af6b6faa1cd1923cfbc cbf2d90995154fbd9f4095a440a5cfcf--9b40bd74f8fa4af6b6faa1cd1923cfbc 5d3bd24d9c8d4509a68025e32ec93bca 9b40bd74f8fa4af6b6faa1cd1923cfbc--5d3bd24d9c8d4509a68025e32ec93bca 29f8296a6d90493abe81f723054a9e4a 5d3bd24d9c8d4509a68025e32ec93bca--29f8296a6d90493abe81f723054a9e4a dbe394a0b5614c659919d8e8599effbf 29f8296a6d90493abe81f723054a9e4a--dbe394a0b5614c659919d8e8599effbf 5bc8178592624764b5a7a57d754a4ea0 dbe394a0b5614c659919d8e8599effbf--5bc8178592624764b5a7a57d754a4ea0 d20546cf7cf7475ead53fc56d6e1927b 5bc8178592624764b5a7a57d754a4ea0--d20546cf7cf7475ead53fc56d6e1927b f4b6dc384fe14d4c998a4d1ec710aceb d20546cf7cf7475ead53fc56d6e1927b--f4b6dc384fe14d4c998a4d1ec710aceb 2010421826db4d418b050e8555cea706 X f4b6dc384fe14d4c998a4d1ec710aceb--2010421826db4d418b050e8555cea706 2010421826db4d418b050e8555cea706--edf8e83079094ae9900aac7adb9a4c5f 66d050c053874c12aa754443470f92f9 2010421826db4d418b050e8555cea706--66d050c053874c12aa754443470f92f9 012fee0f1244417dba54128a4aff5784 66d050c053874c12aa754443470f92f9--012fee0f1244417dba54128a4aff5784 88d91faf41524482864dc78b5874ed01 012fee0f1244417dba54128a4aff5784--88d91faf41524482864dc78b5874ed01 df7c2f733e1540778082ce98039b9042 X 88d91faf41524482864dc78b5874ed01--df7c2f733e1540778082ce98039b9042 df7c2f733e1540778082ce98039b9042--c0d31440259844a3aabd2a30637f03a1 3d5e5579bb334e1ba0b7ea123e8da8d3 df7c2f733e1540778082ce98039b9042--3d5e5579bb334e1ba0b7ea123e8da8d3 a4225e357d0f4b5f8cc1af43347b5f7f 3d5e5579bb334e1ba0b7ea123e8da8d3--a4225e357d0f4b5f8cc1af43347b5f7f ed2f73b8311e4a778cfaca1c144ee537 a4225e357d0f4b5f8cc1af43347b5f7f--ed2f73b8311e4a778cfaca1c144ee537 3f629647f0f9439f8eed4aad77eae911 ed2f73b8311e4a778cfaca1c144ee537--3f629647f0f9439f8eed4aad77eae911 51318c5f3b08460e8e5d1e624f94c41d 3f629647f0f9439f8eed4aad77eae911--51318c5f3b08460e8e5d1e624f94c41d 3fa8078523be4bf2a1729fe7c15bb4f3 X 51318c5f3b08460e8e5d1e624f94c41d--3fa8078523be4bf2a1729fe7c15bb4f3 3fa8078523be4bf2a1729fe7c15bb4f3--9a96deee2426421d9d2471f7fe1737e8 5a32067111e24f37a187064ef4135d8f 3fa8078523be4bf2a1729fe7c15bb4f3--5a32067111e24f37a187064ef4135d8f 0d27c18cb2b34f81bd0ccf04930a0102 5a32067111e24f37a187064ef4135d8f--0d27c18cb2b34f81bd0ccf04930a0102 c141c9d14a5b41308f4145f3e854b028 X 0d27c18cb2b34f81bd0ccf04930a0102--c141c9d14a5b41308f4145f3e854b028 c141c9d14a5b41308f4145f3e854b028--4693b12b9625478c83da1555ed8f8176 2de5567e2dac4af1a131bb89dfc589ac c141c9d14a5b41308f4145f3e854b028--2de5567e2dac4af1a131bb89dfc589ac 25023926438d43d68a2f12185058c701 2de5567e2dac4af1a131bb89dfc589ac--25023926438d43d68a2f12185058c701 194901c711324192856a371e8ba7cfc8 25023926438d43d68a2f12185058c701--194901c711324192856a371e8ba7cfc8 b46dfa410cca4775b57b1f9339aa06e3 194901c711324192856a371e8ba7cfc8--b46dfa410cca4775b57b1f9339aa06e3 7982edc7970b4cf6aa5e45a85c2c87c4 b46dfa410cca4775b57b1f9339aa06e3--7982edc7970b4cf6aa5e45a85c2c87c4 3df2e3b5896f45e9bea8ccf918a8566a 7982edc7970b4cf6aa5e45a85c2c87c4--3df2e3b5896f45e9bea8ccf918a8566a c75a1341c56943e2bdf4b04a6be7ea64 3df2e3b5896f45e9bea8ccf918a8566a--c75a1341c56943e2bdf4b04a6be7ea64 18b7767b063c4c96a266d3b4b99d03be X c75a1341c56943e2bdf4b04a6be7ea64--18b7767b063c4c96a266d3b4b99d03be 18b7767b063c4c96a266d3b4b99d03be--58067ef827d8434f95e41bcd7fcf8297 3d6c430c96704d0dadf9dc6efda6e7c1 18b7767b063c4c96a266d3b4b99d03be--3d6c430c96704d0dadf9dc6efda6e7c1 e4d816618f84453198c8a9a32688e77c 3d6c430c96704d0dadf9dc6efda6e7c1--e4d816618f84453198c8a9a32688e77c d87b975461624739b4039d7ae9f5492b X e4d816618f84453198c8a9a32688e77c--d87b975461624739b4039d7ae9f5492b d87b975461624739b4039d7ae9f5492b--8cb76630369d46a4bd1b9ffe708fb650 8baa7325ba8c4703ac372b869ad2e563 d87b975461624739b4039d7ae9f5492b--8baa7325ba8c4703ac372b869ad2e563 24cd8a70bc744b049e2b757f18b71071 8baa7325ba8c4703ac372b869ad2e563--24cd8a70bc744b049e2b757f18b71071 a932dd6dd2e546f785d185d95f63f05a 24cd8a70bc744b049e2b757f18b71071--a932dd6dd2e546f785d185d95f63f05a ae0555875c594dc79827b7f909875ca3 a932dd6dd2e546f785d185d95f63f05a--ae0555875c594dc79827b7f909875ca3 4552dd7e73244e8485945e1d7b05e122 ae0555875c594dc79827b7f909875ca3--4552dd7e73244e8485945e1d7b05e122 ddb4647097dd44f9a9dedb4e4199558f 4552dd7e73244e8485945e1d7b05e122--ddb4647097dd44f9a9dedb4e4199558f b6186bab718d4b2bac4234ca41868efc ddb4647097dd44f9a9dedb4e4199558f--b6186bab718d4b2bac4234ca41868efc eb25c326ff494b92b0b74587dcc5b9da b6186bab718d4b2bac4234ca41868efc--eb25c326ff494b92b0b74587dcc5b9da a8ead24298dd452f8356efebe305c978 eb25c326ff494b92b0b74587dcc5b9da--a8ead24298dd452f8356efebe305c978 db959473fa8443a0852ee4c820dca251 X a8ead24298dd452f8356efebe305c978--db959473fa8443a0852ee4c820dca251 db959473fa8443a0852ee4c820dca251--0870a168e6fc4d46860746758e59faae 1097ba03d99540c7a6dbf45125f000bf db959473fa8443a0852ee4c820dca251--1097ba03d99540c7a6dbf45125f000bf a997839f3c0e48638f3c4701f3ee38a9 X 1097ba03d99540c7a6dbf45125f000bf--a997839f3c0e48638f3c4701f3ee38a9 a997839f3c0e48638f3c4701f3ee38a9--a13aca97e543456da9b0b01713728639 23f59c6f96f34ba9a6460215a79b0e68 a997839f3c0e48638f3c4701f3ee38a9--23f59c6f96f34ba9a6460215a79b0e68 fe32930a0aa344a6a8370cfc7d7f36f0 23f59c6f96f34ba9a6460215a79b0e68--fe32930a0aa344a6a8370cfc7d7f36f0 c5bb463b61a443c7bb26af0c42962358 fe32930a0aa344a6a8370cfc7d7f36f0--c5bb463b61a443c7bb26af0c42962358 f6acf0c374fa4df3a12c6d9d14f9879d X c5bb463b61a443c7bb26af0c42962358--f6acf0c374fa4df3a12c6d9d14f9879d f6acf0c374fa4df3a12c6d9d14f9879d--37f9e7b5dcb648febb5479890177b79f 5b80f5e70ec845178715d86c0db34033 X f6acf0c374fa4df3a12c6d9d14f9879d--5b80f5e70ec845178715d86c0db34033 5b80f5e70ec845178715d86c0db34033--cef6e5ba1b8544cf8b2bffb4fab3e683 6d300eef7440446ca1a575a40a131fa1 5b80f5e70ec845178715d86c0db34033--6d300eef7440446ca1a575a40a131fa1 827629470daa478aaa719867df032010 6d300eef7440446ca1a575a40a131fa1--827629470daa478aaa719867df032010 1207cd812960400cbe165973982440f6 827629470daa478aaa719867df032010--1207cd812960400cbe165973982440f6 b44235f71fe240fb9c8efbbfcd693625 1207cd812960400cbe165973982440f6--b44235f71fe240fb9c8efbbfcd693625 3210d6d90e894389bf1667cad9746f07 b44235f71fe240fb9c8efbbfcd693625--3210d6d90e894389bf1667cad9746f07 1f999327232f4f9c91fdde180195432b X 3210d6d90e894389bf1667cad9746f07--1f999327232f4f9c91fdde180195432b 1f999327232f4f9c91fdde180195432b--6533a10d52984d7e9aed79086dc1ef46 a0dd4c9996464d5c8bf44249e713bd99 X 1f999327232f4f9c91fdde180195432b--a0dd4c9996464d5c8bf44249e713bd99 a0dd4c9996464d5c8bf44249e713bd99--05ccb7871fee4b1c8d39534878718afc 6670837784414f5cb2426f64440a605f a0dd4c9996464d5c8bf44249e713bd99--6670837784414f5cb2426f64440a605f 1a7ee908cfdf49fdaea5a88cf7779f84 6670837784414f5cb2426f64440a605f--1a7ee908cfdf49fdaea5a88cf7779f84 d2d5eab59b93417ab375c9ee38cd016b 1a7ee908cfdf49fdaea5a88cf7779f84--d2d5eab59b93417ab375c9ee38cd016b a645eb2f535440419ab77f2fdc7e8d6f d2d5eab59b93417ab375c9ee38cd016b--a645eb2f535440419ab77f2fdc7e8d6f a293967778204b27932c6654768e28cf a645eb2f535440419ab77f2fdc7e8d6f--a293967778204b27932c6654768e28cf c7b2d61baa5e41b18c68414ec21e736c a293967778204b27932c6654768e28cf--c7b2d61baa5e41b18c68414ec21e736c b4d752fa1e2c4ce1bcef6e963df3ea63 c7b2d61baa5e41b18c68414ec21e736c--b4d752fa1e2c4ce1bcef6e963df3ea63 cda1188499624a1c9e2432921b09f67d b4d752fa1e2c4ce1bcef6e963df3ea63--cda1188499624a1c9e2432921b09f67d 8f555c53d7804f568c713035e107a2c7 cda1188499624a1c9e2432921b09f67d--8f555c53d7804f568c713035e107a2c7 b0311b8daf384ceb8d2a075aa5a70ab0 X 8f555c53d7804f568c713035e107a2c7--b0311b8daf384ceb8d2a075aa5a70ab0 b0311b8daf384ceb8d2a075aa5a70ab0--3c0efd0cacb74128af266869148aa571 1d7a7e4851ab4f9f9267fd35e4a58286 b0311b8daf384ceb8d2a075aa5a70ab0--1d7a7e4851ab4f9f9267fd35e4a58286 4df77ce2105e46aa940d5333f8e4c79d 1d7a7e4851ab4f9f9267fd35e4a58286--4df77ce2105e46aa940d5333f8e4c79d 516f8005c73640158ca22acbd7b226a2 4df77ce2105e46aa940d5333f8e4c79d--516f8005c73640158ca22acbd7b226a2 4b078e90d0844d02a9c4096bfb054d4b 516f8005c73640158ca22acbd7b226a2--4b078e90d0844d02a9c4096bfb054d4b af7814aba2cd47b598e9ce48d1cda85a 4b078e90d0844d02a9c4096bfb054d4b--af7814aba2cd47b598e9ce48d1cda85a 50fb86458b4a4c07bf70ae5739676f03 af7814aba2cd47b598e9ce48d1cda85a--50fb86458b4a4c07bf70ae5739676f03 00f35d14cf5f470686cd5e72633404b8 50fb86458b4a4c07bf70ae5739676f03--00f35d14cf5f470686cd5e72633404b8 f87beb371c6a42c091df554e0c3360ce 00f35d14cf5f470686cd5e72633404b8--f87beb371c6a42c091df554e0c3360ce 4209a414e94d4f3d916a3cc8d1c8713d f87beb371c6a42c091df554e0c3360ce--4209a414e94d4f3d916a3cc8d1c8713d 828f2ceb54b0442a96be4aea68a11a5a 4209a414e94d4f3d916a3cc8d1c8713d--828f2ceb54b0442a96be4aea68a11a5a da1f48b45d8341828b783aee118a4d89 828f2ceb54b0442a96be4aea68a11a5a--da1f48b45d8341828b783aee118a4d89 c11640b9695f40ce95b698645b94193c da1f48b45d8341828b783aee118a4d89--c11640b9695f40ce95b698645b94193c eca33d8302dc457ca2d69db0e89a1c30 c11640b9695f40ce95b698645b94193c--eca33d8302dc457ca2d69db0e89a1c30 deab7e30e1844f4f82c0a15b22ed9906 eca33d8302dc457ca2d69db0e89a1c30--deab7e30e1844f4f82c0a15b22ed9906 2ecfd2c52eea4d6aa2d091429650993b deab7e30e1844f4f82c0a15b22ed9906--2ecfd2c52eea4d6aa2d091429650993b 63a194d0a7d34176a2c93bb7c708984c 2ecfd2c52eea4d6aa2d091429650993b--63a194d0a7d34176a2c93bb7c708984c f4bc60fb1fe841d0bbe5909da6701cd5 63a194d0a7d34176a2c93bb7c708984c--f4bc60fb1fe841d0bbe5909da6701cd5 a8987578162b4f0abe27f0705891cb2c f4bc60fb1fe841d0bbe5909da6701cd5--a8987578162b4f0abe27f0705891cb2c c66279f986ee4787bf3db463f2c9071f a8987578162b4f0abe27f0705891cb2c--c66279f986ee4787bf3db463f2c9071f 7e810cc90f6f4ffa8664ce1bc7828162 c66279f986ee4787bf3db463f2c9071f--7e810cc90f6f4ffa8664ce1bc7828162 16a2c0194dd144a9b83b0474d414527c 7e810cc90f6f4ffa8664ce1bc7828162--16a2c0194dd144a9b83b0474d414527c af2efb489e994c88a47ac31710bdfa9e 16a2c0194dd144a9b83b0474d414527c--af2efb489e994c88a47ac31710bdfa9e 7b23f42cd2134438b54c1b5e97d9e588 af2efb489e994c88a47ac31710bdfa9e--7b23f42cd2134438b54c1b5e97d9e588 9912e36c274848af9492881ac5eecf1f 7b23f42cd2134438b54c1b5e97d9e588--9912e36c274848af9492881ac5eecf1f 39651981598744be99b31c23450f0aed 9912e36c274848af9492881ac5eecf1f--39651981598744be99b31c23450f0aed 38c79efc2882434585d85be9805ee902 39651981598744be99b31c23450f0aed--38c79efc2882434585d85be9805ee902 15e211589dbd4cf39d81b75dee7d68a6 38c79efc2882434585d85be9805ee902--15e211589dbd4cf39d81b75dee7d68a6 9ed1d9339a9141fc9a285f6fdeb5a179 15e211589dbd4cf39d81b75dee7d68a6--9ed1d9339a9141fc9a285f6fdeb5a179 9ed2a4675c434c9b91dad53dc1c6a692 9ed1d9339a9141fc9a285f6fdeb5a179--9ed2a4675c434c9b91dad53dc1c6a692 65773c275def4a04b818ceda9f251464 9ed2a4675c434c9b91dad53dc1c6a692--65773c275def4a04b818ceda9f251464 8c2c17129f4d4873a3720d697ab0f346 65773c275def4a04b818ceda9f251464--8c2c17129f4d4873a3720d697ab0f346 84f6cce8a3e4409e9909e74631bc04d2 8c2c17129f4d4873a3720d697ab0f346--84f6cce8a3e4409e9909e74631bc04d2 8471313314194190a32a45a2eb73e2b2 84f6cce8a3e4409e9909e74631bc04d2--8471313314194190a32a45a2eb73e2b2 187af07a5aa84b2d99b48229de5ac07f 8471313314194190a32a45a2eb73e2b2--187af07a5aa84b2d99b48229de5ac07f a8bd679affce452f9543ec7c143f493b 187af07a5aa84b2d99b48229de5ac07f--a8bd679affce452f9543ec7c143f493b cdf591d558184c99a4dc03a9a7186658 RX(b13) a8bd679affce452f9543ec7c143f493b--cdf591d558184c99a4dc03a9a7186658 cdf591d558184c99a4dc03a9a7186658--00687455797a42d29456f723349cc506 e84e9435dd8a4e3b884364e7c6fdb1c1 9b252d89b9ff4969b0e4bd665c7fa584 c8cacdb0e3d24653866ae349be377fb0--9b252d89b9ff4969b0e4bd665c7fa584 d9a4648933c34c6086534819cd48d1e6 5 25bba2afb19c48d298b2cd6934cb9011 9b252d89b9ff4969b0e4bd665c7fa584--25bba2afb19c48d298b2cd6934cb9011 657dbfcd52574ba69cc90a0f17e8f022 25bba2afb19c48d298b2cd6934cb9011--657dbfcd52574ba69cc90a0f17e8f022 55a6818e3cf24915a2f9d98180cb7e93 X 657dbfcd52574ba69cc90a0f17e8f022--55a6818e3cf24915a2f9d98180cb7e93 55a6818e3cf24915a2f9d98180cb7e93--278bbb507723466fb6e6f1a5ad42137a d45c1b94b6df450c9f81b071efab3478 55a6818e3cf24915a2f9d98180cb7e93--d45c1b94b6df450c9f81b071efab3478 8f71e45173944b5d891077b41e63aca5 d45c1b94b6df450c9f81b071efab3478--8f71e45173944b5d891077b41e63aca5 ebb45b37210f4056bec6a0c9dfbbd934 8f71e45173944b5d891077b41e63aca5--ebb45b37210f4056bec6a0c9dfbbd934 b3615b23e2444b5b9bbdc133b9cdfbf3 ebb45b37210f4056bec6a0c9dfbbd934--b3615b23e2444b5b9bbdc133b9cdfbf3 fa89404e944a4e829e3e5838e91fbb3f b3615b23e2444b5b9bbdc133b9cdfbf3--fa89404e944a4e829e3e5838e91fbb3f ec6f20bde99e485486eca5143329779e fa89404e944a4e829e3e5838e91fbb3f--ec6f20bde99e485486eca5143329779e 2776ca7add3a41f4bbefc0427e251c28 ec6f20bde99e485486eca5143329779e--2776ca7add3a41f4bbefc0427e251c28 c8d75b2f54304dfe9d468351c872be7f X 2776ca7add3a41f4bbefc0427e251c28--c8d75b2f54304dfe9d468351c872be7f c8d75b2f54304dfe9d468351c872be7f--602266fbcd2549a794889ac909fb539c 63b297892b4c48e8bdf53a411fa69ed6 c8d75b2f54304dfe9d468351c872be7f--63b297892b4c48e8bdf53a411fa69ed6 c4ee34282aaf48cdb6bc29241c63cdaf 63b297892b4c48e8bdf53a411fa69ed6--c4ee34282aaf48cdb6bc29241c63cdaf e8ee286b729d4193b672e9b918004e76 c4ee34282aaf48cdb6bc29241c63cdaf--e8ee286b729d4193b672e9b918004e76 a59eb4c0b65d4f94b7f2bc0eaf8a922d e8ee286b729d4193b672e9b918004e76--a59eb4c0b65d4f94b7f2bc0eaf8a922d d465af5502cd4e40bdb11789b9705be8 a59eb4c0b65d4f94b7f2bc0eaf8a922d--d465af5502cd4e40bdb11789b9705be8 b9529aa671b144c18c950355d7cb5f64 d465af5502cd4e40bdb11789b9705be8--b9529aa671b144c18c950355d7cb5f64 aba990bc989f4ef1bc330fa8f7f165e1 b9529aa671b144c18c950355d7cb5f64--aba990bc989f4ef1bc330fa8f7f165e1 433f0f0cf54c4bba8cacf24b37a09174 aba990bc989f4ef1bc330fa8f7f165e1--433f0f0cf54c4bba8cacf24b37a09174 909e4d2150a944fbbc21d979e399d29f 433f0f0cf54c4bba8cacf24b37a09174--909e4d2150a944fbbc21d979e399d29f 9a14ab9180664288aca1b99843609b35 909e4d2150a944fbbc21d979e399d29f--9a14ab9180664288aca1b99843609b35 7536de141fe64cfe81ae48c172ec03ef 9a14ab9180664288aca1b99843609b35--7536de141fe64cfe81ae48c172ec03ef 1dee0a3bf1dd40c483c117b66a9f6b6e 7536de141fe64cfe81ae48c172ec03ef--1dee0a3bf1dd40c483c117b66a9f6b6e 58697c20bbdb4bc982d99ec0b9d2c305 1dee0a3bf1dd40c483c117b66a9f6b6e--58697c20bbdb4bc982d99ec0b9d2c305 8f21f9d7fa30412bb978667f40fad3c6 58697c20bbdb4bc982d99ec0b9d2c305--8f21f9d7fa30412bb978667f40fad3c6 094bff40b56d4346ab78e519f93855a6 X 8f21f9d7fa30412bb978667f40fad3c6--094bff40b56d4346ab78e519f93855a6 094bff40b56d4346ab78e519f93855a6--9cc6f6eda53d428696c1e6f07a390128 2c2a3faf81874c4098ddc98f885b4952 RZ(-1.0*g0) 094bff40b56d4346ab78e519f93855a6--2c2a3faf81874c4098ddc98f885b4952 e1dd8e3d69b644ebb9cbb0498f0538b9 X 2c2a3faf81874c4098ddc98f885b4952--e1dd8e3d69b644ebb9cbb0498f0538b9 e1dd8e3d69b644ebb9cbb0498f0538b9--b8af31d69a66430f8cf24ef1b08c5e28 0fc85d4bd43244b085af296a48641d7b e1dd8e3d69b644ebb9cbb0498f0538b9--0fc85d4bd43244b085af296a48641d7b bf81522d5be44b348d98afd84250ad05 0fc85d4bd43244b085af296a48641d7b--bf81522d5be44b348d98afd84250ad05 92a9f3fd5c1c451ab3cca3cbf25a429a bf81522d5be44b348d98afd84250ad05--92a9f3fd5c1c451ab3cca3cbf25a429a da7b20f1b1634bf98254f4894b40c0bd 92a9f3fd5c1c451ab3cca3cbf25a429a--da7b20f1b1634bf98254f4894b40c0bd 08ade6086c6642f0ab5c2707e8ea1621 da7b20f1b1634bf98254f4894b40c0bd--08ade6086c6642f0ab5c2707e8ea1621 b2e623ec87634835b5f42649e5ba98d1 08ade6086c6642f0ab5c2707e8ea1621--b2e623ec87634835b5f42649e5ba98d1 52277cf0c1b7478889fdc3e3b2e0aaf2 X b2e623ec87634835b5f42649e5ba98d1--52277cf0c1b7478889fdc3e3b2e0aaf2 52277cf0c1b7478889fdc3e3b2e0aaf2--ccc95afa65d8402984a66cabf1bf0bec b35e64ae111740e39a53bd119e1b5d09 52277cf0c1b7478889fdc3e3b2e0aaf2--b35e64ae111740e39a53bd119e1b5d09 32822fa6ee9d4c5eb1f5b78b59f31e20 b35e64ae111740e39a53bd119e1b5d09--32822fa6ee9d4c5eb1f5b78b59f31e20 0e0516d9aee846329866ac82641e3a31 32822fa6ee9d4c5eb1f5b78b59f31e20--0e0516d9aee846329866ac82641e3a31 7845c944c03f443cb8f416a81940fe69 0e0516d9aee846329866ac82641e3a31--7845c944c03f443cb8f416a81940fe69 6f63dc1258c84534afc65893d59b0cb7 7845c944c03f443cb8f416a81940fe69--6f63dc1258c84534afc65893d59b0cb7 3de5404f8bda4e749c2e202f2ed65893 6f63dc1258c84534afc65893d59b0cb7--3de5404f8bda4e749c2e202f2ed65893 b83d97b37c1e41e29d1a84ef33d9a404 3de5404f8bda4e749c2e202f2ed65893--b83d97b37c1e41e29d1a84ef33d9a404 5c277abba76a447eb993ac0651138ccd X b83d97b37c1e41e29d1a84ef33d9a404--5c277abba76a447eb993ac0651138ccd 5c277abba76a447eb993ac0651138ccd--0c52994475db49cb96506c23b21625a1 5f80ed28272546db9c7196a4e983ba8d 5c277abba76a447eb993ac0651138ccd--5f80ed28272546db9c7196a4e983ba8d 5becfb11323146cabfbb3338c65400d0 5f80ed28272546db9c7196a4e983ba8d--5becfb11323146cabfbb3338c65400d0 8265313bc814436f9d30e1e2cbb05afd 5becfb11323146cabfbb3338c65400d0--8265313bc814436f9d30e1e2cbb05afd 0d5e68c756244063be9a2ec2ea5af035 8265313bc814436f9d30e1e2cbb05afd--0d5e68c756244063be9a2ec2ea5af035 65d078f9fdb9405695dfae0860b67704 0d5e68c756244063be9a2ec2ea5af035--65d078f9fdb9405695dfae0860b67704 ccedd671e8a647f6b61afb14428b54d3 X 65d078f9fdb9405695dfae0860b67704--ccedd671e8a647f6b61afb14428b54d3 ccedd671e8a647f6b61afb14428b54d3--5c05c160cd134d9da588cf20d3a1375d c53568013cad46b691e0b1f8ef5c7c2f ccedd671e8a647f6b61afb14428b54d3--c53568013cad46b691e0b1f8ef5c7c2f 9042cdbb4a9f4b94860fbceb219d2d59 c53568013cad46b691e0b1f8ef5c7c2f--9042cdbb4a9f4b94860fbceb219d2d59 add25c5829ce4fca9828a0f1918a0817 9042cdbb4a9f4b94860fbceb219d2d59--add25c5829ce4fca9828a0f1918a0817 ed92a39fbb8d4ecbad6adb2924967147 X add25c5829ce4fca9828a0f1918a0817--ed92a39fbb8d4ecbad6adb2924967147 ed92a39fbb8d4ecbad6adb2924967147--bdd709ae8a3f422e97642b08e1c53089 1bfbe557e014455e9ff837bef7f7bc86 ed92a39fbb8d4ecbad6adb2924967147--1bfbe557e014455e9ff837bef7f7bc86 bee9623eb0d24c9b9f627c78f19a3194 1bfbe557e014455e9ff837bef7f7bc86--bee9623eb0d24c9b9f627c78f19a3194 4c49aa89bc9d47eb81505f0156018953 bee9623eb0d24c9b9f627c78f19a3194--4c49aa89bc9d47eb81505f0156018953 d04d7ccc858142a3bc5b1f6367922f08 4c49aa89bc9d47eb81505f0156018953--d04d7ccc858142a3bc5b1f6367922f08 69011011d34e4236a8c7efc82eeb7968 X d04d7ccc858142a3bc5b1f6367922f08--69011011d34e4236a8c7efc82eeb7968 69011011d34e4236a8c7efc82eeb7968--992b07efa4d345aeb7641f531088cb82 8bfe0783de544399a3fabf9b28d1331d 69011011d34e4236a8c7efc82eeb7968--8bfe0783de544399a3fabf9b28d1331d 89c54b6a1a1c4ede98bd7201e4530149 8bfe0783de544399a3fabf9b28d1331d--89c54b6a1a1c4ede98bd7201e4530149 f26c33224e254c11a3d9dc7af30db132 89c54b6a1a1c4ede98bd7201e4530149--f26c33224e254c11a3d9dc7af30db132 67aa1dcc926f48ef85b7ba5049970917 f26c33224e254c11a3d9dc7af30db132--67aa1dcc926f48ef85b7ba5049970917 0e66496baf944460a28a4c4a90ceb0d7 67aa1dcc926f48ef85b7ba5049970917--0e66496baf944460a28a4c4a90ceb0d7 18bd0127b358469ba81acf8450899a46 X 0e66496baf944460a28a4c4a90ceb0d7--18bd0127b358469ba81acf8450899a46 18bd0127b358469ba81acf8450899a46--eea2958374684880be91185d0e559337 f47f6567e0814a6ea7ff8d61dfd60ecd 18bd0127b358469ba81acf8450899a46--f47f6567e0814a6ea7ff8d61dfd60ecd 540f061b185545089136b18263de9aef f47f6567e0814a6ea7ff8d61dfd60ecd--540f061b185545089136b18263de9aef 6096f2faf4dc4c8bb51094fbb425066b 540f061b185545089136b18263de9aef--6096f2faf4dc4c8bb51094fbb425066b e82dd7b0cc71441e883edcbccea440ef 6096f2faf4dc4c8bb51094fbb425066b--e82dd7b0cc71441e883edcbccea440ef 540dba1001ca4053add760173484a84c X e82dd7b0cc71441e883edcbccea440ef--540dba1001ca4053add760173484a84c 540dba1001ca4053add760173484a84c--84730bfb42d840f886bba033bf42d11a a2378ac82db84747ae99cc2194da153c 540dba1001ca4053add760173484a84c--a2378ac82db84747ae99cc2194da153c 00f80821974e454588a74002570f4ef0 a2378ac82db84747ae99cc2194da153c--00f80821974e454588a74002570f4ef0 832902161e6741a4927414eaaa9950bf 00f80821974e454588a74002570f4ef0--832902161e6741a4927414eaaa9950bf f5e98875ad1f42bba627f3b7362c79f8 832902161e6741a4927414eaaa9950bf--f5e98875ad1f42bba627f3b7362c79f8 0bb7f5e0ff7840c1bb6a685ccf84de2d f5e98875ad1f42bba627f3b7362c79f8--0bb7f5e0ff7840c1bb6a685ccf84de2d 71205b0e3ff248619a61054cc506cd08 0bb7f5e0ff7840c1bb6a685ccf84de2d--71205b0e3ff248619a61054cc506cd08 cb4d97a5c45f4505936ac8b2d50d9866 71205b0e3ff248619a61054cc506cd08--cb4d97a5c45f4505936ac8b2d50d9866 f407202ced8e4bee8521d0df8c3532df X cb4d97a5c45f4505936ac8b2d50d9866--f407202ced8e4bee8521d0df8c3532df f407202ced8e4bee8521d0df8c3532df--e59ecf21a9d34015aa1b9935478997ff 583bbd402f2843b7ba9aae6a643be9b5 f407202ced8e4bee8521d0df8c3532df--583bbd402f2843b7ba9aae6a643be9b5 79f2dbe280cf4ea9af3970f3ce4c54fb 583bbd402f2843b7ba9aae6a643be9b5--79f2dbe280cf4ea9af3970f3ce4c54fb 56955ee37ec14799909cd645cd0647af 79f2dbe280cf4ea9af3970f3ce4c54fb--56955ee37ec14799909cd645cd0647af c0e671af937647dcb12b76af57b92988 X 56955ee37ec14799909cd645cd0647af--c0e671af937647dcb12b76af57b92988 c0e671af937647dcb12b76af57b92988--5b13ccdb92b547a3a8416a9c75ec0083 eca66bd202144de48d0fda2db7fc9048 RZ(-1.0*g0) c0e671af937647dcb12b76af57b92988--eca66bd202144de48d0fda2db7fc9048 84551fb8d42c40bd8dd662f4e27ff91f X eca66bd202144de48d0fda2db7fc9048--84551fb8d42c40bd8dd662f4e27ff91f 84551fb8d42c40bd8dd662f4e27ff91f--e391ff73e8284b578ee7bcfe1d75f499 aa5b4d87cad54f73b98058ca20a5dc95 84551fb8d42c40bd8dd662f4e27ff91f--aa5b4d87cad54f73b98058ca20a5dc95 dd255e56a4474146a6f6f7c1abb66218 aa5b4d87cad54f73b98058ca20a5dc95--dd255e56a4474146a6f6f7c1abb66218 9a479d17e3c143d9a8ec38daa14783e3 X dd255e56a4474146a6f6f7c1abb66218--9a479d17e3c143d9a8ec38daa14783e3 9a479d17e3c143d9a8ec38daa14783e3--21bce9a009514f39aef18130a629767e da20cb20af024017889229ad50db04a1 9a479d17e3c143d9a8ec38daa14783e3--da20cb20af024017889229ad50db04a1 242b4192d54b4e2f803847fca66a7a2e da20cb20af024017889229ad50db04a1--242b4192d54b4e2f803847fca66a7a2e 98ce551d1948498e9105e69ed23aa9ef 242b4192d54b4e2f803847fca66a7a2e--98ce551d1948498e9105e69ed23aa9ef 410fbc4d049840a5a7866816d38f9b48 X 98ce551d1948498e9105e69ed23aa9ef--410fbc4d049840a5a7866816d38f9b48 410fbc4d049840a5a7866816d38f9b48--847cb25d7b0343ba82d410af6d8ec40b 7008a6def85149f58e760177552b2aba 410fbc4d049840a5a7866816d38f9b48--7008a6def85149f58e760177552b2aba 6fd6701d57ae4a93a87f4af7a5b4989d 7008a6def85149f58e760177552b2aba--6fd6701d57ae4a93a87f4af7a5b4989d abefb49afae0445fa25d2594c15fa107 X 6fd6701d57ae4a93a87f4af7a5b4989d--abefb49afae0445fa25d2594c15fa107 abefb49afae0445fa25d2594c15fa107--d37689faff734d4dbed034edf8428764 838dc8d0c46142d99292dba3c8e0cba1 abefb49afae0445fa25d2594c15fa107--838dc8d0c46142d99292dba3c8e0cba1 a32acd2c1e1847948f95ee1a1b5ca741 838dc8d0c46142d99292dba3c8e0cba1--a32acd2c1e1847948f95ee1a1b5ca741 a18c9fbbcc6548b39ef44f5aa8fe1eed a32acd2c1e1847948f95ee1a1b5ca741--a18c9fbbcc6548b39ef44f5aa8fe1eed 3a4a63f7048a49589e5d8deda14dc3b4 a18c9fbbcc6548b39ef44f5aa8fe1eed--3a4a63f7048a49589e5d8deda14dc3b4 23723cf39eee421cbe22934d902ea2b4 3a4a63f7048a49589e5d8deda14dc3b4--23723cf39eee421cbe22934d902ea2b4 9ee1fe32edda4298bc91e93191717a61 23723cf39eee421cbe22934d902ea2b4--9ee1fe32edda4298bc91e93191717a61 e89991410dcb4e0e8ce06fd072879dcd 9ee1fe32edda4298bc91e93191717a61--e89991410dcb4e0e8ce06fd072879dcd 7097199702b2475b8f59d6a3f44b5b62 X e89991410dcb4e0e8ce06fd072879dcd--7097199702b2475b8f59d6a3f44b5b62 7097199702b2475b8f59d6a3f44b5b62--56fa3ba43e094d76afe417ff142aec19 005931064e294ef1b201179a9598e86a 7097199702b2475b8f59d6a3f44b5b62--005931064e294ef1b201179a9598e86a 416276d012ce4b6594aae6f9bb3b5930 X 005931064e294ef1b201179a9598e86a--416276d012ce4b6594aae6f9bb3b5930 416276d012ce4b6594aae6f9bb3b5930--992ba4f45fe74becb0d7ef05a70acd15 6bb931e1e71e438a8252ff719111feb5 RZ(-1.0*g0) 416276d012ce4b6594aae6f9bb3b5930--6bb931e1e71e438a8252ff719111feb5 34725b894cbb459a9b0f8604c7abd35d X 6bb931e1e71e438a8252ff719111feb5--34725b894cbb459a9b0f8604c7abd35d 34725b894cbb459a9b0f8604c7abd35d--f6ea3013e5a64bb3b465f2de0de2d6cb 44e648c0968e45b3b4d53f3671f50461 X 34725b894cbb459a9b0f8604c7abd35d--44e648c0968e45b3b4d53f3671f50461 44e648c0968e45b3b4d53f3671f50461--e2d1d1414e0846c98d8f250485e2cee1 595706937caa4498bf623510cd0b7c73 44e648c0968e45b3b4d53f3671f50461--595706937caa4498bf623510cd0b7c73 d91adede68b34331a4748c4cea69a6f1 595706937caa4498bf623510cd0b7c73--d91adede68b34331a4748c4cea69a6f1 cae7aa2a891e453eaf7fd85967ddd2f5 d91adede68b34331a4748c4cea69a6f1--cae7aa2a891e453eaf7fd85967ddd2f5 dd3854be1e6548d988dc223d44326e89 cae7aa2a891e453eaf7fd85967ddd2f5--dd3854be1e6548d988dc223d44326e89 7e38ec2884db4690826bca98f85f0517 dd3854be1e6548d988dc223d44326e89--7e38ec2884db4690826bca98f85f0517 7674c538e3874bbb891d95e9ce4f582b X 7e38ec2884db4690826bca98f85f0517--7674c538e3874bbb891d95e9ce4f582b 7674c538e3874bbb891d95e9ce4f582b--c3cdfd3693024675b108ca0a60044dc7 9d0d6109a4474c18b0c48ee0756ad363 X 7674c538e3874bbb891d95e9ce4f582b--9d0d6109a4474c18b0c48ee0756ad363 9d0d6109a4474c18b0c48ee0756ad363--842b9bba963c40bd816093732ca0f748 be47549039ab495294d7d798b7791c31 9d0d6109a4474c18b0c48ee0756ad363--be47549039ab495294d7d798b7791c31 15068c1754754a4db403b4f85dccc641 be47549039ab495294d7d798b7791c31--15068c1754754a4db403b4f85dccc641 2077c893e3f74e0cbbc9ba19460a06ad 15068c1754754a4db403b4f85dccc641--2077c893e3f74e0cbbc9ba19460a06ad 974874744b5e4d7e86ede61a7f4288f7 2077c893e3f74e0cbbc9ba19460a06ad--974874744b5e4d7e86ede61a7f4288f7 ef9c79be67ad405ebeab84bcf8c03d39 974874744b5e4d7e86ede61a7f4288f7--ef9c79be67ad405ebeab84bcf8c03d39 015a25701d7d414d9831cf891205d411 ef9c79be67ad405ebeab84bcf8c03d39--015a25701d7d414d9831cf891205d411 949a8f6ddaae49fe86feb61c07fcc73d 015a25701d7d414d9831cf891205d411--949a8f6ddaae49fe86feb61c07fcc73d 71d2c184eb5049fb82cd886164813dbe X 949a8f6ddaae49fe86feb61c07fcc73d--71d2c184eb5049fb82cd886164813dbe 71d2c184eb5049fb82cd886164813dbe--e7dee56e37b44de38e20969c7660bf3e 8ac011eaf5c341798a09fd8dfd42431b 71d2c184eb5049fb82cd886164813dbe--8ac011eaf5c341798a09fd8dfd42431b 5a9f856d356d4b9b9ea81b29281f477d 8ac011eaf5c341798a09fd8dfd42431b--5a9f856d356d4b9b9ea81b29281f477d 53bde98dc4ef4d0691783077263f4bad 5a9f856d356d4b9b9ea81b29281f477d--53bde98dc4ef4d0691783077263f4bad b15d6c4023a64aff8c40a5f74e433604 53bde98dc4ef4d0691783077263f4bad--b15d6c4023a64aff8c40a5f74e433604 33a755d870444495ab065b0dc1c11343 b15d6c4023a64aff8c40a5f74e433604--33a755d870444495ab065b0dc1c11343 0b8f409195314264ae84bc56ca961489 33a755d870444495ab065b0dc1c11343--0b8f409195314264ae84bc56ca961489 2567d8bc49cc45a98018a55b54b7bacd 0b8f409195314264ae84bc56ca961489--2567d8bc49cc45a98018a55b54b7bacd 53641e539a0945a59ac98256a61247e2 2567d8bc49cc45a98018a55b54b7bacd--53641e539a0945a59ac98256a61247e2 667aa9c87ab247198701a730a25becf0 53641e539a0945a59ac98256a61247e2--667aa9c87ab247198701a730a25becf0 bbbd489e8d6d4150916a16d187ae870f 667aa9c87ab247198701a730a25becf0--bbbd489e8d6d4150916a16d187ae870f bc42c2cf004a4a4ba58b108a38ce2141 bbbd489e8d6d4150916a16d187ae870f--bc42c2cf004a4a4ba58b108a38ce2141 a4a69ea003064e9698d0a43359d07f29 bc42c2cf004a4a4ba58b108a38ce2141--a4a69ea003064e9698d0a43359d07f29 523e4cefe2954db09e97d0f22293d0a0 a4a69ea003064e9698d0a43359d07f29--523e4cefe2954db09e97d0f22293d0a0 dfd76e44e793419eacf98f1eb4d722d1 523e4cefe2954db09e97d0f22293d0a0--dfd76e44e793419eacf98f1eb4d722d1 d3a8e78c6ee64ee7bbf7c5a4bb1f7e67 dfd76e44e793419eacf98f1eb4d722d1--d3a8e78c6ee64ee7bbf7c5a4bb1f7e67 ed316d898e964e8bb59af731833a6203 d3a8e78c6ee64ee7bbf7c5a4bb1f7e67--ed316d898e964e8bb59af731833a6203 521b84a2f308445cbebb80d0ff5a4765 RX(b04) ed316d898e964e8bb59af731833a6203--521b84a2f308445cbebb80d0ff5a4765 691b867042b94132a3e30a921b2d49e0 521b84a2f308445cbebb80d0ff5a4765--691b867042b94132a3e30a921b2d49e0 9accc1ec43ab4345b69ffb806d59a840 691b867042b94132a3e30a921b2d49e0--9accc1ec43ab4345b69ffb806d59a840 0dfa64e4e21b4975b965c0f2a06fa45a 9accc1ec43ab4345b69ffb806d59a840--0dfa64e4e21b4975b965c0f2a06fa45a fe5025ac7c974c82ae446faae3b1d56f X 0dfa64e4e21b4975b965c0f2a06fa45a--fe5025ac7c974c82ae446faae3b1d56f fe5025ac7c974c82ae446faae3b1d56f--9a586d1320494d1cb32ebcb46ec726e9 d7d0257a8f704e8086e84e21edd23c49 fe5025ac7c974c82ae446faae3b1d56f--d7d0257a8f704e8086e84e21edd23c49 701743b3b54d41ac842e2b43c01aebfd d7d0257a8f704e8086e84e21edd23c49--701743b3b54d41ac842e2b43c01aebfd e2455c9e93144fcabad7135450f9d58a 701743b3b54d41ac842e2b43c01aebfd--e2455c9e93144fcabad7135450f9d58a e45b49c8ebbd423d8f1d53c87f514932 e2455c9e93144fcabad7135450f9d58a--e45b49c8ebbd423d8f1d53c87f514932 64d3827d0ea5490fa36088f40d1f313d e45b49c8ebbd423d8f1d53c87f514932--64d3827d0ea5490fa36088f40d1f313d c33c3f0d03154f8a9bc0e9ec09eb0755 64d3827d0ea5490fa36088f40d1f313d--c33c3f0d03154f8a9bc0e9ec09eb0755 77ab84a92bce450e8085c976c607ec39 c33c3f0d03154f8a9bc0e9ec09eb0755--77ab84a92bce450e8085c976c607ec39 6839035011244b45ad2c890f76b65ea8 X 77ab84a92bce450e8085c976c607ec39--6839035011244b45ad2c890f76b65ea8 6839035011244b45ad2c890f76b65ea8--0bc4527884d74e9198210c4e5ca16813 f339c6f7fbd14e6580426d2d16e6873d 6839035011244b45ad2c890f76b65ea8--f339c6f7fbd14e6580426d2d16e6873d a8f7aeb66a90460584910c95eba233bd f339c6f7fbd14e6580426d2d16e6873d--a8f7aeb66a90460584910c95eba233bd 8313eaaaf57e4ea0802e3fa398014da3 a8f7aeb66a90460584910c95eba233bd--8313eaaaf57e4ea0802e3fa398014da3 3df86293165c4fd187a996db4d9bf31e 8313eaaaf57e4ea0802e3fa398014da3--3df86293165c4fd187a996db4d9bf31e 9af38179819c48bdae352a759b3baf6e 3df86293165c4fd187a996db4d9bf31e--9af38179819c48bdae352a759b3baf6e 573cf488c21f44b88bcfe2df7f60bccd 9af38179819c48bdae352a759b3baf6e--573cf488c21f44b88bcfe2df7f60bccd c8e39ea460eb4ab792e108ee83d943c1 573cf488c21f44b88bcfe2df7f60bccd--c8e39ea460eb4ab792e108ee83d943c1 f3bc870113f245d5b31aa92ff6f7ffe3 c8e39ea460eb4ab792e108ee83d943c1--f3bc870113f245d5b31aa92ff6f7ffe3 fb936b62c7254a14b0b38f8ecae4bd9e f3bc870113f245d5b31aa92ff6f7ffe3--fb936b62c7254a14b0b38f8ecae4bd9e 5aa54ff2c65b4c2ba9de3b46edb3fff8 fb936b62c7254a14b0b38f8ecae4bd9e--5aa54ff2c65b4c2ba9de3b46edb3fff8 0296455edf4e4890a6653bd7a987b83e 5aa54ff2c65b4c2ba9de3b46edb3fff8--0296455edf4e4890a6653bd7a987b83e 1dcf2c9fc73b4e888315e1d301629147 0296455edf4e4890a6653bd7a987b83e--1dcf2c9fc73b4e888315e1d301629147 e11ac70837254f01811c3a9025aea6c4 1dcf2c9fc73b4e888315e1d301629147--e11ac70837254f01811c3a9025aea6c4 357cff7cbfe34a4eb5a350a8afde5ce8 e11ac70837254f01811c3a9025aea6c4--357cff7cbfe34a4eb5a350a8afde5ce8 e2a3ddd700a046c08d442541776884eb X 357cff7cbfe34a4eb5a350a8afde5ce8--e2a3ddd700a046c08d442541776884eb e2a3ddd700a046c08d442541776884eb--f0b53fa76ea440deb12ca1933222f6da 6f2257dce1ba405b88054e8d6a9fe4fa RZ(-1.0*g1) e2a3ddd700a046c08d442541776884eb--6f2257dce1ba405b88054e8d6a9fe4fa 8e7f48ef63344ad188ed5c19ddd8d79d X 6f2257dce1ba405b88054e8d6a9fe4fa--8e7f48ef63344ad188ed5c19ddd8d79d 8e7f48ef63344ad188ed5c19ddd8d79d--403630e9ee024ec1a6a6ed2aa2e7907b 7ce2be5ae3814589b0a4e6449a1ed261 8e7f48ef63344ad188ed5c19ddd8d79d--7ce2be5ae3814589b0a4e6449a1ed261 f5728f5b3b3d47de9719010a43ba9281 7ce2be5ae3814589b0a4e6449a1ed261--f5728f5b3b3d47de9719010a43ba9281 950590dc3de246f180aa127f282afb90 f5728f5b3b3d47de9719010a43ba9281--950590dc3de246f180aa127f282afb90 12ba6a9e5ee349f5b28f995981489040 950590dc3de246f180aa127f282afb90--12ba6a9e5ee349f5b28f995981489040 87e78bf2f0dc45d58cf733622d5e2199 12ba6a9e5ee349f5b28f995981489040--87e78bf2f0dc45d58cf733622d5e2199 889982ffe6e84db480949dca940b0285 87e78bf2f0dc45d58cf733622d5e2199--889982ffe6e84db480949dca940b0285 9fc54b65eb0248c6964ed81a32ad5d5d X 889982ffe6e84db480949dca940b0285--9fc54b65eb0248c6964ed81a32ad5d5d 9fc54b65eb0248c6964ed81a32ad5d5d--fac3dc98937344639b3d96f617a6e20f 7e48ac960e5f46ef8e82e04211bc6923 9fc54b65eb0248c6964ed81a32ad5d5d--7e48ac960e5f46ef8e82e04211bc6923 00dbde9ebb8240bfafe893a0eec0497f 7e48ac960e5f46ef8e82e04211bc6923--00dbde9ebb8240bfafe893a0eec0497f 09c2184e3eb84f51bea3a12bece49115 00dbde9ebb8240bfafe893a0eec0497f--09c2184e3eb84f51bea3a12bece49115 c6aa7e0d6b65425b86cbb91e437ab690 09c2184e3eb84f51bea3a12bece49115--c6aa7e0d6b65425b86cbb91e437ab690 f1b449e4e24f46cea1c9b2be4f0ac156 c6aa7e0d6b65425b86cbb91e437ab690--f1b449e4e24f46cea1c9b2be4f0ac156 f7ed0a4fd07c41e78b4e4b65616f28bb f1b449e4e24f46cea1c9b2be4f0ac156--f7ed0a4fd07c41e78b4e4b65616f28bb 6a3418b7217b4c499bc034d5111e658b f7ed0a4fd07c41e78b4e4b65616f28bb--6a3418b7217b4c499bc034d5111e658b 31ac4f22181b4209b09520e5d5e2cba4 X 6a3418b7217b4c499bc034d5111e658b--31ac4f22181b4209b09520e5d5e2cba4 31ac4f22181b4209b09520e5d5e2cba4--f4b6dc384fe14d4c998a4d1ec710aceb 47cf7257e7f04194a7f8b22cb92656fe 31ac4f22181b4209b09520e5d5e2cba4--47cf7257e7f04194a7f8b22cb92656fe 53b436c95c7b4ccd8d74e95d3e17d3a3 47cf7257e7f04194a7f8b22cb92656fe--53b436c95c7b4ccd8d74e95d3e17d3a3 86b38470271749c48ea5e4ca6996f40b 53b436c95c7b4ccd8d74e95d3e17d3a3--86b38470271749c48ea5e4ca6996f40b 4f7e916f5527419a9d8866ef70b919e1 86b38470271749c48ea5e4ca6996f40b--4f7e916f5527419a9d8866ef70b919e1 f12bb3fe143e4021b24650c3b0e49a52 4f7e916f5527419a9d8866ef70b919e1--f12bb3fe143e4021b24650c3b0e49a52 8e1b745bddba49f0abea5391e904449f X f12bb3fe143e4021b24650c3b0e49a52--8e1b745bddba49f0abea5391e904449f 8e1b745bddba49f0abea5391e904449f--3d5e5579bb334e1ba0b7ea123e8da8d3 c7bbad91fff94f2eacb16171b82b55aa 8e1b745bddba49f0abea5391e904449f--c7bbad91fff94f2eacb16171b82b55aa 113083c7e4a644d6880ac7362e657a84 c7bbad91fff94f2eacb16171b82b55aa--113083c7e4a644d6880ac7362e657a84 c785a002f0f24b23b9418d2c1fafa1e6 113083c7e4a644d6880ac7362e657a84--c785a002f0f24b23b9418d2c1fafa1e6 907dc55083a543ce9b5d01fe7e44f5b2 X c785a002f0f24b23b9418d2c1fafa1e6--907dc55083a543ce9b5d01fe7e44f5b2 907dc55083a543ce9b5d01fe7e44f5b2--51318c5f3b08460e8e5d1e624f94c41d 277a99e7755e4b28ba07607ef43c21fd 907dc55083a543ce9b5d01fe7e44f5b2--277a99e7755e4b28ba07607ef43c21fd 023488d01ca647c7ab45cf79389a5dc7 277a99e7755e4b28ba07607ef43c21fd--023488d01ca647c7ab45cf79389a5dc7 c9e750bdf3864bc59794059de4951146 023488d01ca647c7ab45cf79389a5dc7--c9e750bdf3864bc59794059de4951146 3c622e6895e940a58653f1f4408296c1 c9e750bdf3864bc59794059de4951146--3c622e6895e940a58653f1f4408296c1 442f8968e04f45b7b0c9017920ed8feb X 3c622e6895e940a58653f1f4408296c1--442f8968e04f45b7b0c9017920ed8feb 442f8968e04f45b7b0c9017920ed8feb--2de5567e2dac4af1a131bb89dfc589ac 35d4169fcbe547ae8074773da7083f4f 442f8968e04f45b7b0c9017920ed8feb--35d4169fcbe547ae8074773da7083f4f eb699475db4e4e5e917fb27d1197c9e9 35d4169fcbe547ae8074773da7083f4f--eb699475db4e4e5e917fb27d1197c9e9 93eba5efa30c41d8a9d4be946be5d302 eb699475db4e4e5e917fb27d1197c9e9--93eba5efa30c41d8a9d4be946be5d302 6387b8437ed046b1b27c1ea23c0cf04c 93eba5efa30c41d8a9d4be946be5d302--6387b8437ed046b1b27c1ea23c0cf04c 1688828f6de54f7fadcc0d41f99ca5de 6387b8437ed046b1b27c1ea23c0cf04c--1688828f6de54f7fadcc0d41f99ca5de dc4d2ba3ab484b3cb545a2013c36943b X 1688828f6de54f7fadcc0d41f99ca5de--dc4d2ba3ab484b3cb545a2013c36943b dc4d2ba3ab484b3cb545a2013c36943b--c75a1341c56943e2bdf4b04a6be7ea64 21ab14e7b56b42a7a7ce6d73c3eadbee dc4d2ba3ab484b3cb545a2013c36943b--21ab14e7b56b42a7a7ce6d73c3eadbee 62adf1bfb5b0421e9feeb014c00443c6 21ab14e7b56b42a7a7ce6d73c3eadbee--62adf1bfb5b0421e9feeb014c00443c6 bcec0199df084990b551c8210101f913 62adf1bfb5b0421e9feeb014c00443c6--bcec0199df084990b551c8210101f913 a1a27faced974398a034126ff06073fe bcec0199df084990b551c8210101f913--a1a27faced974398a034126ff06073fe 88e261b1f0ed499eb09f23965a2373ff X a1a27faced974398a034126ff06073fe--88e261b1f0ed499eb09f23965a2373ff 88e261b1f0ed499eb09f23965a2373ff--8baa7325ba8c4703ac372b869ad2e563 07d2ea8bf34d4a06aec34b95079f9b39 88e261b1f0ed499eb09f23965a2373ff--07d2ea8bf34d4a06aec34b95079f9b39 fd52d508bb3a41ec874f7bc3545fdda6 07d2ea8bf34d4a06aec34b95079f9b39--fd52d508bb3a41ec874f7bc3545fdda6 731b68d0dce24c4eade72f803976d927 fd52d508bb3a41ec874f7bc3545fdda6--731b68d0dce24c4eade72f803976d927 346438c79aac4ee6b7f17fed5cab8bc6 731b68d0dce24c4eade72f803976d927--346438c79aac4ee6b7f17fed5cab8bc6 d8ec2ee50c7d4e4fbb581e716d579434 346438c79aac4ee6b7f17fed5cab8bc6--d8ec2ee50c7d4e4fbb581e716d579434 c2edbe5069504ca9904be50099be44dc d8ec2ee50c7d4e4fbb581e716d579434--c2edbe5069504ca9904be50099be44dc 8f1817609d5c46bebf17ca5864492c64 c2edbe5069504ca9904be50099be44dc--8f1817609d5c46bebf17ca5864492c64 eb0d201dfa254012bae8f55349387c96 X 8f1817609d5c46bebf17ca5864492c64--eb0d201dfa254012bae8f55349387c96 eb0d201dfa254012bae8f55349387c96--a8ead24298dd452f8356efebe305c978 34618ee8154b451192bcb4e449062565 eb0d201dfa254012bae8f55349387c96--34618ee8154b451192bcb4e449062565 66199ca8e3cc46868ba9745bc4ed5c9b 34618ee8154b451192bcb4e449062565--66199ca8e3cc46868ba9745bc4ed5c9b 6a3243f0aff1467ba667660514c8e0b7 66199ca8e3cc46868ba9745bc4ed5c9b--6a3243f0aff1467ba667660514c8e0b7 527b3ee1a77d4cbbb0ae817d31812421 X 6a3243f0aff1467ba667660514c8e0b7--527b3ee1a77d4cbbb0ae817d31812421 527b3ee1a77d4cbbb0ae817d31812421--23f59c6f96f34ba9a6460215a79b0e68 99696da9f5984f9c9116c7a1ced88658 RZ(-1.0*g1) 527b3ee1a77d4cbbb0ae817d31812421--99696da9f5984f9c9116c7a1ced88658 ee98fab0342e4795ad22f45bd03a92d4 X 99696da9f5984f9c9116c7a1ced88658--ee98fab0342e4795ad22f45bd03a92d4 ee98fab0342e4795ad22f45bd03a92d4--c5bb463b61a443c7bb26af0c42962358 23c89c3e4ee7422d9fb466ec1aa0c900 ee98fab0342e4795ad22f45bd03a92d4--23c89c3e4ee7422d9fb466ec1aa0c900 c957c21283d14ac69695ea0b474414d9 23c89c3e4ee7422d9fb466ec1aa0c900--c957c21283d14ac69695ea0b474414d9 d006eef634544bd5859e156bd2cf2389 X c957c21283d14ac69695ea0b474414d9--d006eef634544bd5859e156bd2cf2389 d006eef634544bd5859e156bd2cf2389--6d300eef7440446ca1a575a40a131fa1 bd74aee485274dddae616d1bc28edc93 d006eef634544bd5859e156bd2cf2389--bd74aee485274dddae616d1bc28edc93 e9f64c92ce9d40aabf0046a5817ebae1 bd74aee485274dddae616d1bc28edc93--e9f64c92ce9d40aabf0046a5817ebae1 4905271a5fcf4e2ebdc49f259ed42d06 e9f64c92ce9d40aabf0046a5817ebae1--4905271a5fcf4e2ebdc49f259ed42d06 2b1fb8e8468f48feb1ad628c8514b116 X 4905271a5fcf4e2ebdc49f259ed42d06--2b1fb8e8468f48feb1ad628c8514b116 2b1fb8e8468f48feb1ad628c8514b116--3210d6d90e894389bf1667cad9746f07 a458fc6c21e5444aaecde87bf6d2453e 2b1fb8e8468f48feb1ad628c8514b116--a458fc6c21e5444aaecde87bf6d2453e cf83372f441e435093e1aa7834ae668f a458fc6c21e5444aaecde87bf6d2453e--cf83372f441e435093e1aa7834ae668f b37dce47ca734afbbd1d40eba8ffa5ad X cf83372f441e435093e1aa7834ae668f--b37dce47ca734afbbd1d40eba8ffa5ad b37dce47ca734afbbd1d40eba8ffa5ad--6670837784414f5cb2426f64440a605f 7a040b921aff413da97cf56ac6e31c24 b37dce47ca734afbbd1d40eba8ffa5ad--7a040b921aff413da97cf56ac6e31c24 e6d1100d5ea64fd3a8b41132a1941374 7a040b921aff413da97cf56ac6e31c24--e6d1100d5ea64fd3a8b41132a1941374 ff1f2a3a861844e2a009052cf40bae10 e6d1100d5ea64fd3a8b41132a1941374--ff1f2a3a861844e2a009052cf40bae10 99ab88f6ed924a78969ba77661774605 ff1f2a3a861844e2a009052cf40bae10--99ab88f6ed924a78969ba77661774605 0e7ed5f685694f48b6a6bde090b5fda6 99ab88f6ed924a78969ba77661774605--0e7ed5f685694f48b6a6bde090b5fda6 ee92423002f44eccb6274b3af8bf331b 0e7ed5f685694f48b6a6bde090b5fda6--ee92423002f44eccb6274b3af8bf331b 4ac43726411e48cba7fd696db126b8fe ee92423002f44eccb6274b3af8bf331b--4ac43726411e48cba7fd696db126b8fe 6b82c8c7a9f34671b0f7d4d648c7af44 X 4ac43726411e48cba7fd696db126b8fe--6b82c8c7a9f34671b0f7d4d648c7af44 6b82c8c7a9f34671b0f7d4d648c7af44--8f555c53d7804f568c713035e107a2c7 575171dd10a942e689946ff83abf4d51 6b82c8c7a9f34671b0f7d4d648c7af44--575171dd10a942e689946ff83abf4d51 0134504362654a79a8091b20b0d7fbac X 575171dd10a942e689946ff83abf4d51--0134504362654a79a8091b20b0d7fbac 0134504362654a79a8091b20b0d7fbac--1d7a7e4851ab4f9f9267fd35e4a58286 2853759fb0b34c4ca95b9b39c1832c5f RZ(-1.0*g1) 0134504362654a79a8091b20b0d7fbac--2853759fb0b34c4ca95b9b39c1832c5f e836768b509c4f29b73c326fc1ed4c03 X 2853759fb0b34c4ca95b9b39c1832c5f--e836768b509c4f29b73c326fc1ed4c03 e836768b509c4f29b73c326fc1ed4c03--516f8005c73640158ca22acbd7b226a2 2de5563b1aa14818ac82a81141ba8e2b X e836768b509c4f29b73c326fc1ed4c03--2de5563b1aa14818ac82a81141ba8e2b 2de5563b1aa14818ac82a81141ba8e2b--4b078e90d0844d02a9c4096bfb054d4b 9debd5afe8484cfc88a33ceddefbfba8 2de5563b1aa14818ac82a81141ba8e2b--9debd5afe8484cfc88a33ceddefbfba8 5758c151346a4ea2b93c47e5316d2894 9debd5afe8484cfc88a33ceddefbfba8--5758c151346a4ea2b93c47e5316d2894 55bf4b1c9936428a8f487871d3518cfe 5758c151346a4ea2b93c47e5316d2894--55bf4b1c9936428a8f487871d3518cfe 94cdff45a99c485b8a72a1407371212a 55bf4b1c9936428a8f487871d3518cfe--94cdff45a99c485b8a72a1407371212a 6bf43fea28ff459e8e6163f8b101179b 94cdff45a99c485b8a72a1407371212a--6bf43fea28ff459e8e6163f8b101179b 5f66e13de96943c4915c9ad7a80c735a X 6bf43fea28ff459e8e6163f8b101179b--5f66e13de96943c4915c9ad7a80c735a 5f66e13de96943c4915c9ad7a80c735a--828f2ceb54b0442a96be4aea68a11a5a 51c4e447b0b44fc4ac96bc2ec1e43fd2 X 5f66e13de96943c4915c9ad7a80c735a--51c4e447b0b44fc4ac96bc2ec1e43fd2 51c4e447b0b44fc4ac96bc2ec1e43fd2--da1f48b45d8341828b783aee118a4d89 6cd5409197b44b08b94e03ef696e03dc 51c4e447b0b44fc4ac96bc2ec1e43fd2--6cd5409197b44b08b94e03ef696e03dc 4c77ed5963234f54834a5807c89febd0 6cd5409197b44b08b94e03ef696e03dc--4c77ed5963234f54834a5807c89febd0 9510f983d7164624af84298a3ef0b85e 4c77ed5963234f54834a5807c89febd0--9510f983d7164624af84298a3ef0b85e 8095ecb8917441c79bf0df682e377a48 9510f983d7164624af84298a3ef0b85e--8095ecb8917441c79bf0df682e377a48 53f0bf8741264c059bf92dc0b0db2b6d 8095ecb8917441c79bf0df682e377a48--53f0bf8741264c059bf92dc0b0db2b6d 16d21e1b0587445f80ed978ff22f94fc 53f0bf8741264c059bf92dc0b0db2b6d--16d21e1b0587445f80ed978ff22f94fc ac3fa92dde7e4159b383f2b4b1f5ca83 16d21e1b0587445f80ed978ff22f94fc--ac3fa92dde7e4159b383f2b4b1f5ca83 d6616323d952400586dbc357e20c2833 X ac3fa92dde7e4159b383f2b4b1f5ca83--d6616323d952400586dbc357e20c2833 d6616323d952400586dbc357e20c2833--c66279f986ee4787bf3db463f2c9071f 2f7102f0b61b4df7a3d092444e1a0fc4 d6616323d952400586dbc357e20c2833--2f7102f0b61b4df7a3d092444e1a0fc4 5725f8f15f724b11b7832d7d042567c4 2f7102f0b61b4df7a3d092444e1a0fc4--5725f8f15f724b11b7832d7d042567c4 7b36cfe7297b4fb485392690d06fc0e6 5725f8f15f724b11b7832d7d042567c4--7b36cfe7297b4fb485392690d06fc0e6 cc13d45efb934f4d82dd4b4d5acb4653 7b36cfe7297b4fb485392690d06fc0e6--cc13d45efb934f4d82dd4b4d5acb4653 b221f411c5b14b17ac993a57a0457f0a cc13d45efb934f4d82dd4b4d5acb4653--b221f411c5b14b17ac993a57a0457f0a 9db9951d02f34004b374a1b0f5324ce4 b221f411c5b14b17ac993a57a0457f0a--9db9951d02f34004b374a1b0f5324ce4 ee108411f343480c86b0a576afa0c5b7 9db9951d02f34004b374a1b0f5324ce4--ee108411f343480c86b0a576afa0c5b7 cabcb38d85e44e1f9e4520d03607fb8d ee108411f343480c86b0a576afa0c5b7--cabcb38d85e44e1f9e4520d03607fb8d b984d36b2e2141c78f2a4b4b90c18bcc cabcb38d85e44e1f9e4520d03607fb8d--b984d36b2e2141c78f2a4b4b90c18bcc 60e42b3c419f4bb4aa9db27438f86f21 b984d36b2e2141c78f2a4b4b90c18bcc--60e42b3c419f4bb4aa9db27438f86f21 0a147fb5960a4de088eb456e09db64f2 60e42b3c419f4bb4aa9db27438f86f21--0a147fb5960a4de088eb456e09db64f2 b46c2b7a365749c0a843a9cad2ebe965 0a147fb5960a4de088eb456e09db64f2--b46c2b7a365749c0a843a9cad2ebe965 51632d90e93946a3909a7ca87959e9d3 b46c2b7a365749c0a843a9cad2ebe965--51632d90e93946a3909a7ca87959e9d3 67a789fa07cd42db945ae2f09cfa28bc 51632d90e93946a3909a7ca87959e9d3--67a789fa07cd42db945ae2f09cfa28bc f04b0137645f4081b33263d6408e46d7 67a789fa07cd42db945ae2f09cfa28bc--f04b0137645f4081b33263d6408e46d7 8a3eb91c5bf04339982a1a52cbdb3c7b f04b0137645f4081b33263d6408e46d7--8a3eb91c5bf04339982a1a52cbdb3c7b df1ac438500649ddbbbbae3b04b818c5 RX(b14) 8a3eb91c5bf04339982a1a52cbdb3c7b--df1ac438500649ddbbbbae3b04b818c5 df1ac438500649ddbbbbae3b04b818c5--e84e9435dd8a4e3b884364e7c6fdb1c1 bbe8b965cefc4efc91d49eda7f2b32d0 e66fdee3573f4545a4a6a0690a271065 d9a4648933c34c6086534819cd48d1e6--e66fdee3573f4545a4a6a0690a271065 a44c71d7c6be4b3e9ca76fdd718ccab5 6 b949be0239134941a32c4a6f7cbb2438 e66fdee3573f4545a4a6a0690a271065--b949be0239134941a32c4a6f7cbb2438 09e11a7da9c14c709c204a45aaf4537f b949be0239134941a32c4a6f7cbb2438--09e11a7da9c14c709c204a45aaf4537f fbdd3f1390b8486b8daf07fe1618b70b 09e11a7da9c14c709c204a45aaf4537f--fbdd3f1390b8486b8daf07fe1618b70b f795e6eccae447fe9066125c58987291 X fbdd3f1390b8486b8daf07fe1618b70b--f795e6eccae447fe9066125c58987291 f795e6eccae447fe9066125c58987291--d45c1b94b6df450c9f81b071efab3478 43ff2f6ba97a4e10baf600645a200c42 f795e6eccae447fe9066125c58987291--43ff2f6ba97a4e10baf600645a200c42 483d509dffa94b00ab7c838f76303ac0 43ff2f6ba97a4e10baf600645a200c42--483d509dffa94b00ab7c838f76303ac0 d5576bac0975485cbcdfb060837d78ee 483d509dffa94b00ab7c838f76303ac0--d5576bac0975485cbcdfb060837d78ee 41422be2813046b499aa502aa6d62067 d5576bac0975485cbcdfb060837d78ee--41422be2813046b499aa502aa6d62067 4394815e13db4348b105aea1bf5e0668 41422be2813046b499aa502aa6d62067--4394815e13db4348b105aea1bf5e0668 a14ebe60f36245149437d0e351ae6f54 X 4394815e13db4348b105aea1bf5e0668--a14ebe60f36245149437d0e351ae6f54 a14ebe60f36245149437d0e351ae6f54--2776ca7add3a41f4bbefc0427e251c28 732de6dae64348ac83d91f309b424791 a14ebe60f36245149437d0e351ae6f54--732de6dae64348ac83d91f309b424791 0dfb19c7ddeb4f64a61d0c3f531bb27e 732de6dae64348ac83d91f309b424791--0dfb19c7ddeb4f64a61d0c3f531bb27e 6347bce18f1944c5ac18df4470a4d56d 0dfb19c7ddeb4f64a61d0c3f531bb27e--6347bce18f1944c5ac18df4470a4d56d 947884ada1e640c4ac572bdeee8d2e6e 6347bce18f1944c5ac18df4470a4d56d--947884ada1e640c4ac572bdeee8d2e6e 699ea2151982487298d4b5cf02fd0393 947884ada1e640c4ac572bdeee8d2e6e--699ea2151982487298d4b5cf02fd0393 a2a7b3e3817b4794a060fbb0528ce15a 699ea2151982487298d4b5cf02fd0393--a2a7b3e3817b4794a060fbb0528ce15a 16d457f4a9774ed783b9e18644f1399f a2a7b3e3817b4794a060fbb0528ce15a--16d457f4a9774ed783b9e18644f1399f 8b412114a3414ec798a3a3313bdfdee5 16d457f4a9774ed783b9e18644f1399f--8b412114a3414ec798a3a3313bdfdee5 0523ac2aff474b9ba5299af191f4e4dc 8b412114a3414ec798a3a3313bdfdee5--0523ac2aff474b9ba5299af191f4e4dc 40ddd6169c0e442d88fc40d8dc01e8a7 0523ac2aff474b9ba5299af191f4e4dc--40ddd6169c0e442d88fc40d8dc01e8a7 59e26488a5724142bfdd4702854ed1a9 40ddd6169c0e442d88fc40d8dc01e8a7--59e26488a5724142bfdd4702854ed1a9 9acf08dbf30c40ff80c7c0bd23c846e9 59e26488a5724142bfdd4702854ed1a9--9acf08dbf30c40ff80c7c0bd23c846e9 84a71800304f4343902b032827c0bab9 9acf08dbf30c40ff80c7c0bd23c846e9--84a71800304f4343902b032827c0bab9 cf5be612840b4cc0ad5f3af116baf2b0 84a71800304f4343902b032827c0bab9--cf5be612840b4cc0ad5f3af116baf2b0 57b91ec34a7040aeafbc00b501b7a77b cf5be612840b4cc0ad5f3af116baf2b0--57b91ec34a7040aeafbc00b501b7a77b 7f370de781554588b37c0b02424f534b 57b91ec34a7040aeafbc00b501b7a77b--7f370de781554588b37c0b02424f534b f5837120fa994d1082be86af08f5400d 7f370de781554588b37c0b02424f534b--f5837120fa994d1082be86af08f5400d 6fc6ba482e904bbfbedfb50ae7d83bbe f5837120fa994d1082be86af08f5400d--6fc6ba482e904bbfbedfb50ae7d83bbe 3ff7f91d55ff40f9a52de75c2d77ef75 6fc6ba482e904bbfbedfb50ae7d83bbe--3ff7f91d55ff40f9a52de75c2d77ef75 343a3bc4ac5346849de265e7c7e25356 3ff7f91d55ff40f9a52de75c2d77ef75--343a3bc4ac5346849de265e7c7e25356 6fcb738018eb4bf799b63bf1b699d88e 343a3bc4ac5346849de265e7c7e25356--6fcb738018eb4bf799b63bf1b699d88e 7ddbea53af464fc7a35cb7c0c9d8fbea 6fcb738018eb4bf799b63bf1b699d88e--7ddbea53af464fc7a35cb7c0c9d8fbea 761e1c2fc07a44c8bfca83806927c409 7ddbea53af464fc7a35cb7c0c9d8fbea--761e1c2fc07a44c8bfca83806927c409 3d7d4d4318534b9aa87b2cd5122b3074 761e1c2fc07a44c8bfca83806927c409--3d7d4d4318534b9aa87b2cd5122b3074 dd737b847da0443f91b2a599b61d9813 3d7d4d4318534b9aa87b2cd5122b3074--dd737b847da0443f91b2a599b61d9813 9bf542237abc4b58a141dbb95c902bdb X dd737b847da0443f91b2a599b61d9813--9bf542237abc4b58a141dbb95c902bdb 9bf542237abc4b58a141dbb95c902bdb--b35e64ae111740e39a53bd119e1b5d09 750db135a802453e985b6caf6594aaa3 9bf542237abc4b58a141dbb95c902bdb--750db135a802453e985b6caf6594aaa3 91ef401ee74c4ca5881c5f9745a344b4 750db135a802453e985b6caf6594aaa3--91ef401ee74c4ca5881c5f9745a344b4 a9b4a45a33cf4d0ebc752162aad97ec6 91ef401ee74c4ca5881c5f9745a344b4--a9b4a45a33cf4d0ebc752162aad97ec6 1b7581a2f5d24f2d96fa3892e4b11f79 a9b4a45a33cf4d0ebc752162aad97ec6--1b7581a2f5d24f2d96fa3892e4b11f79 b7a650dc27f44740b5d1c48be72ecba5 1b7581a2f5d24f2d96fa3892e4b11f79--b7a650dc27f44740b5d1c48be72ecba5 1b5c115bb833476e9772c065d7d7ce16 X b7a650dc27f44740b5d1c48be72ecba5--1b5c115bb833476e9772c065d7d7ce16 1b5c115bb833476e9772c065d7d7ce16--b83d97b37c1e41e29d1a84ef33d9a404 6bc5c57c4ac442b38c075663ac9da115 1b5c115bb833476e9772c065d7d7ce16--6bc5c57c4ac442b38c075663ac9da115 8eaed879846f47c5898b7e1d04031914 6bc5c57c4ac442b38c075663ac9da115--8eaed879846f47c5898b7e1d04031914 619679ee337a47bab786f2e02f8882e5 8eaed879846f47c5898b7e1d04031914--619679ee337a47bab786f2e02f8882e5 6124146ea9fa411db94d9c5c464edec2 619679ee337a47bab786f2e02f8882e5--6124146ea9fa411db94d9c5c464edec2 e259a7aa63b749dd9e6d79124353d786 6124146ea9fa411db94d9c5c464edec2--e259a7aa63b749dd9e6d79124353d786 a846cc50a79f45838d71ee0a6d4079f9 e259a7aa63b749dd9e6d79124353d786--a846cc50a79f45838d71ee0a6d4079f9 16e2d8f135eb46eca95f478d3d9caa40 a846cc50a79f45838d71ee0a6d4079f9--16e2d8f135eb46eca95f478d3d9caa40 e81b28d6a601439bb3a4945b8fe44abf X 16e2d8f135eb46eca95f478d3d9caa40--e81b28d6a601439bb3a4945b8fe44abf e81b28d6a601439bb3a4945b8fe44abf--c53568013cad46b691e0b1f8ef5c7c2f 466ed6c144744624af737691466dfd3c RZ(-1.0*g0) e81b28d6a601439bb3a4945b8fe44abf--466ed6c144744624af737691466dfd3c b056fbbcdd3347b386940db748ab2edb X 466ed6c144744624af737691466dfd3c--b056fbbcdd3347b386940db748ab2edb b056fbbcdd3347b386940db748ab2edb--add25c5829ce4fca9828a0f1918a0817 47fdb7c0abff4df1a4e35bdbe12c0f07 b056fbbcdd3347b386940db748ab2edb--47fdb7c0abff4df1a4e35bdbe12c0f07 95ad5071b98441d6a5313d74778968c1 47fdb7c0abff4df1a4e35bdbe12c0f07--95ad5071b98441d6a5313d74778968c1 4000866f74564603ab21f579c2a5fea5 95ad5071b98441d6a5313d74778968c1--4000866f74564603ab21f579c2a5fea5 f16a24cb2e96402595a6365b7fd1d201 4000866f74564603ab21f579c2a5fea5--f16a24cb2e96402595a6365b7fd1d201 b8112e9594ad4e318d3683ac48e98722 f16a24cb2e96402595a6365b7fd1d201--b8112e9594ad4e318d3683ac48e98722 a212fcc486f04d07a6fcc377db2ce588 b8112e9594ad4e318d3683ac48e98722--a212fcc486f04d07a6fcc377db2ce588 1be06d19be0642d882003d694170f116 X a212fcc486f04d07a6fcc377db2ce588--1be06d19be0642d882003d694170f116 1be06d19be0642d882003d694170f116--8bfe0783de544399a3fabf9b28d1331d bb982d7e3f6048f980afed1ae804077d 1be06d19be0642d882003d694170f116--bb982d7e3f6048f980afed1ae804077d 54ecf6fc477b468da4e2c0cc38a666ac bb982d7e3f6048f980afed1ae804077d--54ecf6fc477b468da4e2c0cc38a666ac ab638c62ee664a23a13b2e4101e896de 54ecf6fc477b468da4e2c0cc38a666ac--ab638c62ee664a23a13b2e4101e896de b25b10d3f391470fb7a9d7d11496c342 X ab638c62ee664a23a13b2e4101e896de--b25b10d3f391470fb7a9d7d11496c342 b25b10d3f391470fb7a9d7d11496c342--0e66496baf944460a28a4c4a90ceb0d7 ce3985ade53a4e5fa287e2d220cfe729 b25b10d3f391470fb7a9d7d11496c342--ce3985ade53a4e5fa287e2d220cfe729 4cf42814bf7b498794c277fdcfc28267 ce3985ade53a4e5fa287e2d220cfe729--4cf42814bf7b498794c277fdcfc28267 5139f0acb8a54ed8b52006a676ddd4b1 4cf42814bf7b498794c277fdcfc28267--5139f0acb8a54ed8b52006a676ddd4b1 86fd3e3431954ef6b1b638af1cfbc62d 5139f0acb8a54ed8b52006a676ddd4b1--86fd3e3431954ef6b1b638af1cfbc62d 825029b5a5ce415b8649478c2f1ef755 86fd3e3431954ef6b1b638af1cfbc62d--825029b5a5ce415b8649478c2f1ef755 dc25269df2b84e97b8f60ca73025b123 825029b5a5ce415b8649478c2f1ef755--dc25269df2b84e97b8f60ca73025b123 e33a0d5afdea4836b116a09d1d2762f4 X dc25269df2b84e97b8f60ca73025b123--e33a0d5afdea4836b116a09d1d2762f4 e33a0d5afdea4836b116a09d1d2762f4--a2378ac82db84747ae99cc2194da153c e87dbfa7d672408589933e51aa690c20 e33a0d5afdea4836b116a09d1d2762f4--e87dbfa7d672408589933e51aa690c20 c9b8d597c643467ca0ac9017c3bccbd7 e87dbfa7d672408589933e51aa690c20--c9b8d597c643467ca0ac9017c3bccbd7 ca1051cb9d3344e18e4b8e93e245f10d c9b8d597c643467ca0ac9017c3bccbd7--ca1051cb9d3344e18e4b8e93e245f10d f492e0e490e24e55a30724afc7fc27d8 ca1051cb9d3344e18e4b8e93e245f10d--f492e0e490e24e55a30724afc7fc27d8 6e446aa8e0d14c059acce13e7144fb0d f492e0e490e24e55a30724afc7fc27d8--6e446aa8e0d14c059acce13e7144fb0d cf1f5dc1aca34ae49670c2b7fff722da X 6e446aa8e0d14c059acce13e7144fb0d--cf1f5dc1aca34ae49670c2b7fff722da cf1f5dc1aca34ae49670c2b7fff722da--cb4d97a5c45f4505936ac8b2d50d9866 54c722502b804ce2901cb2707b0b5bef cf1f5dc1aca34ae49670c2b7fff722da--54c722502b804ce2901cb2707b0b5bef 9a211b1998ed43f5bc6a9bb5e5e5eb44 54c722502b804ce2901cb2707b0b5bef--9a211b1998ed43f5bc6a9bb5e5e5eb44 babcbe6518044761991d79b9432525d2 9a211b1998ed43f5bc6a9bb5e5e5eb44--babcbe6518044761991d79b9432525d2 06eaea9782ec4d11a5458da1d51b347f babcbe6518044761991d79b9432525d2--06eaea9782ec4d11a5458da1d51b347f 7d14cd6892f842e78c16a002be435623 06eaea9782ec4d11a5458da1d51b347f--7d14cd6892f842e78c16a002be435623 433b34f69f0d428a9138ebbfb2a635cd 7d14cd6892f842e78c16a002be435623--433b34f69f0d428a9138ebbfb2a635cd 2855b75f732e4afda1b3dfba75891bf4 433b34f69f0d428a9138ebbfb2a635cd--2855b75f732e4afda1b3dfba75891bf4 3ca3f36beb78470a97492662b3de7cc3 2855b75f732e4afda1b3dfba75891bf4--3ca3f36beb78470a97492662b3de7cc3 f0d9e5a5fbe94deda23c9eabb954879a 3ca3f36beb78470a97492662b3de7cc3--f0d9e5a5fbe94deda23c9eabb954879a 52d2adf0417e419692e5cd06d02a6345 f0d9e5a5fbe94deda23c9eabb954879a--52d2adf0417e419692e5cd06d02a6345 cdea3a57d18d48798b4baa9f18c645e8 X 52d2adf0417e419692e5cd06d02a6345--cdea3a57d18d48798b4baa9f18c645e8 cdea3a57d18d48798b4baa9f18c645e8--da20cb20af024017889229ad50db04a1 2999be85fb5b4333b802ea9e2b760071 RZ(-1.0*g0) cdea3a57d18d48798b4baa9f18c645e8--2999be85fb5b4333b802ea9e2b760071 e27e5133f12c4babb21f92f012147ed2 X 2999be85fb5b4333b802ea9e2b760071--e27e5133f12c4babb21f92f012147ed2 e27e5133f12c4babb21f92f012147ed2--98ce551d1948498e9105e69ed23aa9ef c5a352ddaab14c11b59d59b757407fec e27e5133f12c4babb21f92f012147ed2--c5a352ddaab14c11b59d59b757407fec 81bd10bc4bc94d87be3165deb4af48ef c5a352ddaab14c11b59d59b757407fec--81bd10bc4bc94d87be3165deb4af48ef 45624daf146743a080141d64caff844e 81bd10bc4bc94d87be3165deb4af48ef--45624daf146743a080141d64caff844e d74a25654b3f4d16bfc2c6323dfa8c93 45624daf146743a080141d64caff844e--d74a25654b3f4d16bfc2c6323dfa8c93 ad3e96b96c7647449bcae35ec7d51475 X d74a25654b3f4d16bfc2c6323dfa8c93--ad3e96b96c7647449bcae35ec7d51475 ad3e96b96c7647449bcae35ec7d51475--838dc8d0c46142d99292dba3c8e0cba1 1cb6677e77554b08a98ac5fe37828887 ad3e96b96c7647449bcae35ec7d51475--1cb6677e77554b08a98ac5fe37828887 bde41e6e4616491a959b009317a0c980 1cb6677e77554b08a98ac5fe37828887--bde41e6e4616491a959b009317a0c980 bdc4c0ebba1b407891d3a97f59b37af9 bde41e6e4616491a959b009317a0c980--bdc4c0ebba1b407891d3a97f59b37af9 0be3815c28b34d2494b45b2371082cb2 bdc4c0ebba1b407891d3a97f59b37af9--0be3815c28b34d2494b45b2371082cb2 4d781b279f70444fb88eeb8958610679 0be3815c28b34d2494b45b2371082cb2--4d781b279f70444fb88eeb8958610679 1c683d71c4454db79e4185e286b55495 X 4d781b279f70444fb88eeb8958610679--1c683d71c4454db79e4185e286b55495 1c683d71c4454db79e4185e286b55495--e89991410dcb4e0e8ce06fd072879dcd a0a32c3c956b4c31b707149733821626 1c683d71c4454db79e4185e286b55495--a0a32c3c956b4c31b707149733821626 90c5fee2118c4a0ba4c58e6e140d5116 a0a32c3c956b4c31b707149733821626--90c5fee2118c4a0ba4c58e6e140d5116 788c82bf6b8441eda9b92e1adbd99f6f 90c5fee2118c4a0ba4c58e6e140d5116--788c82bf6b8441eda9b92e1adbd99f6f fcccd6c144284ede8a9bcdfed90f1333 788c82bf6b8441eda9b92e1adbd99f6f--fcccd6c144284ede8a9bcdfed90f1333 5f7a2b3ee19e450eb6a9cb930f8a7c0d fcccd6c144284ede8a9bcdfed90f1333--5f7a2b3ee19e450eb6a9cb930f8a7c0d 85dc86b946f940b2a80cd390b5c6476e 5f7a2b3ee19e450eb6a9cb930f8a7c0d--85dc86b946f940b2a80cd390b5c6476e f135ee623a114019bd9112c4946aa5ce X 85dc86b946f940b2a80cd390b5c6476e--f135ee623a114019bd9112c4946aa5ce f135ee623a114019bd9112c4946aa5ce--595706937caa4498bf623510cd0b7c73 c6cd9e65090b4f63a4fc7f4e1f3e30b0 f135ee623a114019bd9112c4946aa5ce--c6cd9e65090b4f63a4fc7f4e1f3e30b0 dfe4a6c430eb4fdcad8b7fe507a2e15b c6cd9e65090b4f63a4fc7f4e1f3e30b0--dfe4a6c430eb4fdcad8b7fe507a2e15b af2ea2fe8178447c8bf055ddab384067 dfe4a6c430eb4fdcad8b7fe507a2e15b--af2ea2fe8178447c8bf055ddab384067 8f7723e4b8874014bda830472b9ef37e X af2ea2fe8178447c8bf055ddab384067--8f7723e4b8874014bda830472b9ef37e 8f7723e4b8874014bda830472b9ef37e--7e38ec2884db4690826bca98f85f0517 9793db1672184caca1cc8323f949a1c0 8f7723e4b8874014bda830472b9ef37e--9793db1672184caca1cc8323f949a1c0 ad6a294afd544772a7694fad915c4ca5 9793db1672184caca1cc8323f949a1c0--ad6a294afd544772a7694fad915c4ca5 1df80736779748d896a3b9922e7c4a5a X ad6a294afd544772a7694fad915c4ca5--1df80736779748d896a3b9922e7c4a5a 1df80736779748d896a3b9922e7c4a5a--be47549039ab495294d7d798b7791c31 c3d0b57a887844d68d7538472f3ed5d3 1df80736779748d896a3b9922e7c4a5a--c3d0b57a887844d68d7538472f3ed5d3 7d0095bc995f4c86bc3e6e0ecb6689ba c3d0b57a887844d68d7538472f3ed5d3--7d0095bc995f4c86bc3e6e0ecb6689ba 0292d8329ec14059aaadd64f0ab1f2d2 7d0095bc995f4c86bc3e6e0ecb6689ba--0292d8329ec14059aaadd64f0ab1f2d2 7c78b502c9e34403812196b23f62f29e 0292d8329ec14059aaadd64f0ab1f2d2--7c78b502c9e34403812196b23f62f29e 38cce7e5d8ac4c25bf3ce36ba770b91e 7c78b502c9e34403812196b23f62f29e--38cce7e5d8ac4c25bf3ce36ba770b91e 8186a727c8d64a73bef8436d248ca020 X 38cce7e5d8ac4c25bf3ce36ba770b91e--8186a727c8d64a73bef8436d248ca020 8186a727c8d64a73bef8436d248ca020--949a8f6ddaae49fe86feb61c07fcc73d 775a1e21a1524ec7a240c5da1f49ebfc 8186a727c8d64a73bef8436d248ca020--775a1e21a1524ec7a240c5da1f49ebfc 3aee1d5eb2b948c8842fa7620d3f425f X 775a1e21a1524ec7a240c5da1f49ebfc--3aee1d5eb2b948c8842fa7620d3f425f 3aee1d5eb2b948c8842fa7620d3f425f--8ac011eaf5c341798a09fd8dfd42431b 6741457419e84a6d98e2f6efe8c52c95 RZ(-1.0*g0) 3aee1d5eb2b948c8842fa7620d3f425f--6741457419e84a6d98e2f6efe8c52c95 6f02378a6bd5470bb8c9cb2a245e2b97 X 6741457419e84a6d98e2f6efe8c52c95--6f02378a6bd5470bb8c9cb2a245e2b97 6f02378a6bd5470bb8c9cb2a245e2b97--53bde98dc4ef4d0691783077263f4bad 52301e272fb94cb5bc341690d7d0be1a X 6f02378a6bd5470bb8c9cb2a245e2b97--52301e272fb94cb5bc341690d7d0be1a 52301e272fb94cb5bc341690d7d0be1a--b15d6c4023a64aff8c40a5f74e433604 74f654e55b4943e8980a2b85a7e44bd6 52301e272fb94cb5bc341690d7d0be1a--74f654e55b4943e8980a2b85a7e44bd6 2c16c0bf0a55404b953b3ceeb2afe2d7 74f654e55b4943e8980a2b85a7e44bd6--2c16c0bf0a55404b953b3ceeb2afe2d7 a0b97b7cec6347288d4306ec913d5534 2c16c0bf0a55404b953b3ceeb2afe2d7--a0b97b7cec6347288d4306ec913d5534 7bbaaca37f9b4ebfb2b2eedf977abe91 X a0b97b7cec6347288d4306ec913d5534--7bbaaca37f9b4ebfb2b2eedf977abe91 7bbaaca37f9b4ebfb2b2eedf977abe91--53641e539a0945a59ac98256a61247e2 03dd547dac274ce8897512b67d8edd20 7bbaaca37f9b4ebfb2b2eedf977abe91--03dd547dac274ce8897512b67d8edd20 66c5612afd8542a797e6f4d159234e77 03dd547dac274ce8897512b67d8edd20--66c5612afd8542a797e6f4d159234e77 b17d33a28774420085e6a2c42b0efa62 66c5612afd8542a797e6f4d159234e77--b17d33a28774420085e6a2c42b0efa62 fe2d655c03ce4e6d8e149d585a572b84 b17d33a28774420085e6a2c42b0efa62--fe2d655c03ce4e6d8e149d585a572b84 1e36b2d898a6441da2ea53064cec455b fe2d655c03ce4e6d8e149d585a572b84--1e36b2d898a6441da2ea53064cec455b e0aea55c8f8d4ae4aa9de231bddfb7e1 1e36b2d898a6441da2ea53064cec455b--e0aea55c8f8d4ae4aa9de231bddfb7e1 8dfcbbf4f8b7471aad45a093be2af889 e0aea55c8f8d4ae4aa9de231bddfb7e1--8dfcbbf4f8b7471aad45a093be2af889 02fb6b56b5bc4e93a26cf4cad10a848b 8dfcbbf4f8b7471aad45a093be2af889--02fb6b56b5bc4e93a26cf4cad10a848b 0dfaf4abdaf14b5d9836551938ad4f43 RX(b05) 02fb6b56b5bc4e93a26cf4cad10a848b--0dfaf4abdaf14b5d9836551938ad4f43 d09cbfe9bd694bd98d394eb796252219 0dfaf4abdaf14b5d9836551938ad4f43--d09cbfe9bd694bd98d394eb796252219 8c9517db37bc4ba9863cac808a68dc0b d09cbfe9bd694bd98d394eb796252219--8c9517db37bc4ba9863cac808a68dc0b 1cdfd86ff5484db5aaa37b9c66007650 8c9517db37bc4ba9863cac808a68dc0b--1cdfd86ff5484db5aaa37b9c66007650 2dc63ed7991e47c4b3c33abb24e68527 1cdfd86ff5484db5aaa37b9c66007650--2dc63ed7991e47c4b3c33abb24e68527 8a6f245c8eca4e268fdae9907096c51f X 2dc63ed7991e47c4b3c33abb24e68527--8a6f245c8eca4e268fdae9907096c51f 8a6f245c8eca4e268fdae9907096c51f--d7d0257a8f704e8086e84e21edd23c49 6f3544ec32f648e68497f3524afb0dea 8a6f245c8eca4e268fdae9907096c51f--6f3544ec32f648e68497f3524afb0dea e47d73c30db64c2ca8b840800d0fe66d 6f3544ec32f648e68497f3524afb0dea--e47d73c30db64c2ca8b840800d0fe66d 2c8e88c24cdb4448b8c476c3207a5773 e47d73c30db64c2ca8b840800d0fe66d--2c8e88c24cdb4448b8c476c3207a5773 825073d744414796a22a49921c978511 2c8e88c24cdb4448b8c476c3207a5773--825073d744414796a22a49921c978511 41d1cc56d0c44ab59e1fe8c19ef876e9 825073d744414796a22a49921c978511--41d1cc56d0c44ab59e1fe8c19ef876e9 344da50d179548b6b81fc714ec1dab78 X 41d1cc56d0c44ab59e1fe8c19ef876e9--344da50d179548b6b81fc714ec1dab78 344da50d179548b6b81fc714ec1dab78--77ab84a92bce450e8085c976c607ec39 341431226c9e4a85886f529bd16706eb 344da50d179548b6b81fc714ec1dab78--341431226c9e4a85886f529bd16706eb c0ed0454bc154d7e912d5d80e8fff15a 341431226c9e4a85886f529bd16706eb--c0ed0454bc154d7e912d5d80e8fff15a 74360859700940d29afd64f8ea46bf8d c0ed0454bc154d7e912d5d80e8fff15a--74360859700940d29afd64f8ea46bf8d 9537eeb9604d4858897c786d33cc46cc 74360859700940d29afd64f8ea46bf8d--9537eeb9604d4858897c786d33cc46cc 9967b68e8cbc4a7a81e4f32ac990a40a 9537eeb9604d4858897c786d33cc46cc--9967b68e8cbc4a7a81e4f32ac990a40a 22f2fb171df24d94abc99909c04e88d2 9967b68e8cbc4a7a81e4f32ac990a40a--22f2fb171df24d94abc99909c04e88d2 0c74a658b4764d4e9811f97edf3ebd5f 22f2fb171df24d94abc99909c04e88d2--0c74a658b4764d4e9811f97edf3ebd5f b3fb8917e52544c3bd6d3ecb402f28e4 0c74a658b4764d4e9811f97edf3ebd5f--b3fb8917e52544c3bd6d3ecb402f28e4 e829762dcfb749ac8d4488015ffd24b7 b3fb8917e52544c3bd6d3ecb402f28e4--e829762dcfb749ac8d4488015ffd24b7 3dd34c3a5c6e4528aad329bdbecbd81e e829762dcfb749ac8d4488015ffd24b7--3dd34c3a5c6e4528aad329bdbecbd81e acfde0904ff040659d284a121c37dd05 3dd34c3a5c6e4528aad329bdbecbd81e--acfde0904ff040659d284a121c37dd05 f25442e8d4eb43148682580ab3fa3caa acfde0904ff040659d284a121c37dd05--f25442e8d4eb43148682580ab3fa3caa 9dbbf58bd0374c83a569fed9d2644420 f25442e8d4eb43148682580ab3fa3caa--9dbbf58bd0374c83a569fed9d2644420 91a22ac24fa547dd8a11e332b04eb35f 9dbbf58bd0374c83a569fed9d2644420--91a22ac24fa547dd8a11e332b04eb35f 2f952eadafac4a63aa18eddde411f3c8 91a22ac24fa547dd8a11e332b04eb35f--2f952eadafac4a63aa18eddde411f3c8 316f52e1dcbe41d48bb34d80fc86abb4 2f952eadafac4a63aa18eddde411f3c8--316f52e1dcbe41d48bb34d80fc86abb4 26f1a9b0a0f143998fc6358af1e4c7e1 316f52e1dcbe41d48bb34d80fc86abb4--26f1a9b0a0f143998fc6358af1e4c7e1 8ba36adbccdb458b972050a1ba99b1da 26f1a9b0a0f143998fc6358af1e4c7e1--8ba36adbccdb458b972050a1ba99b1da 69deb1aa6b12433cb53c0503a521734c 8ba36adbccdb458b972050a1ba99b1da--69deb1aa6b12433cb53c0503a521734c c1cc569c3b494dbe9c9db3ba67f54198 69deb1aa6b12433cb53c0503a521734c--c1cc569c3b494dbe9c9db3ba67f54198 f1e8b78ab0934f9084828bad0c67ce92 c1cc569c3b494dbe9c9db3ba67f54198--f1e8b78ab0934f9084828bad0c67ce92 616883d21ae548289811c4fb05252749 f1e8b78ab0934f9084828bad0c67ce92--616883d21ae548289811c4fb05252749 191175b5f7d34233b826e080a763f7a3 616883d21ae548289811c4fb05252749--191175b5f7d34233b826e080a763f7a3 4c98f1c95faa486cbd0cba98db50fdfe 191175b5f7d34233b826e080a763f7a3--4c98f1c95faa486cbd0cba98db50fdfe 6a0d17849df842399ceac5019e2d5719 4c98f1c95faa486cbd0cba98db50fdfe--6a0d17849df842399ceac5019e2d5719 5f36702c194d4308b3d2aec3822b7c42 X 6a0d17849df842399ceac5019e2d5719--5f36702c194d4308b3d2aec3822b7c42 5f36702c194d4308b3d2aec3822b7c42--7e48ac960e5f46ef8e82e04211bc6923 edd62ac7ebef4d49b3f3761536270580 5f36702c194d4308b3d2aec3822b7c42--edd62ac7ebef4d49b3f3761536270580 93128d5e6a29455db1250cdc470822da edd62ac7ebef4d49b3f3761536270580--93128d5e6a29455db1250cdc470822da bb33d6b6f3a44762a4d919a570b5ac84 93128d5e6a29455db1250cdc470822da--bb33d6b6f3a44762a4d919a570b5ac84 c75c32a49ecb47039738e73995fc39e4 bb33d6b6f3a44762a4d919a570b5ac84--c75c32a49ecb47039738e73995fc39e4 d4842cc0471b4bcaa2aa5e75028ce9ae c75c32a49ecb47039738e73995fc39e4--d4842cc0471b4bcaa2aa5e75028ce9ae da0ef3eb401b49418c6df3f11dd3a428 X d4842cc0471b4bcaa2aa5e75028ce9ae--da0ef3eb401b49418c6df3f11dd3a428 da0ef3eb401b49418c6df3f11dd3a428--6a3418b7217b4c499bc034d5111e658b 1a042875c5ce4f5caff97cf49689fb79 da0ef3eb401b49418c6df3f11dd3a428--1a042875c5ce4f5caff97cf49689fb79 69d3c97545384a89b71be4815d74e8c5 1a042875c5ce4f5caff97cf49689fb79--69d3c97545384a89b71be4815d74e8c5 0e0411d926364cf7be1aaceb925acc05 69d3c97545384a89b71be4815d74e8c5--0e0411d926364cf7be1aaceb925acc05 fb533d688ece4441bd5074e2b077fde8 0e0411d926364cf7be1aaceb925acc05--fb533d688ece4441bd5074e2b077fde8 d36e8d80ac8748b3b3ecaae77b1e30d5 fb533d688ece4441bd5074e2b077fde8--d36e8d80ac8748b3b3ecaae77b1e30d5 2d208070683c46288bf538332f1e0f82 d36e8d80ac8748b3b3ecaae77b1e30d5--2d208070683c46288bf538332f1e0f82 408d4d81227e488187412568be77faac 2d208070683c46288bf538332f1e0f82--408d4d81227e488187412568be77faac 8d723dd460934266a32d923b4245b457 X 408d4d81227e488187412568be77faac--8d723dd460934266a32d923b4245b457 8d723dd460934266a32d923b4245b457--c7bbad91fff94f2eacb16171b82b55aa 5e7d3da96e3b4ba9b5de5d9a5683d7c8 RZ(-1.0*g1) 8d723dd460934266a32d923b4245b457--5e7d3da96e3b4ba9b5de5d9a5683d7c8 44f952dca9f742faa45871622e5089d7 X 5e7d3da96e3b4ba9b5de5d9a5683d7c8--44f952dca9f742faa45871622e5089d7 44f952dca9f742faa45871622e5089d7--c785a002f0f24b23b9418d2c1fafa1e6 e078d24e4933434088a76e1cb79aa589 44f952dca9f742faa45871622e5089d7--e078d24e4933434088a76e1cb79aa589 d7ae45d9fdda4191bc88449fdfbbcb4e e078d24e4933434088a76e1cb79aa589--d7ae45d9fdda4191bc88449fdfbbcb4e 9f723e855a534156ae75abe3d077d7a7 d7ae45d9fdda4191bc88449fdfbbcb4e--9f723e855a534156ae75abe3d077d7a7 d3e96d8e1b1a4f60958baa692497830c 9f723e855a534156ae75abe3d077d7a7--d3e96d8e1b1a4f60958baa692497830c 9b573ee622ba4ba084518669e8791da8 d3e96d8e1b1a4f60958baa692497830c--9b573ee622ba4ba084518669e8791da8 51f2bb5125234da0ae48076900f06db3 9b573ee622ba4ba084518669e8791da8--51f2bb5125234da0ae48076900f06db3 661b68c6c02348619fb54a21a7f69ba6 X 51f2bb5125234da0ae48076900f06db3--661b68c6c02348619fb54a21a7f69ba6 661b68c6c02348619fb54a21a7f69ba6--35d4169fcbe547ae8074773da7083f4f b02406014b574959887df0ed7d6d492b 661b68c6c02348619fb54a21a7f69ba6--b02406014b574959887df0ed7d6d492b f1a54975591b436eb9bdbdc249310399 b02406014b574959887df0ed7d6d492b--f1a54975591b436eb9bdbdc249310399 1679e98c1a404b309fbcc85644fafeae f1a54975591b436eb9bdbdc249310399--1679e98c1a404b309fbcc85644fafeae 6ffe696b9e5f49f9ad291df3602c70e3 X 1679e98c1a404b309fbcc85644fafeae--6ffe696b9e5f49f9ad291df3602c70e3 6ffe696b9e5f49f9ad291df3602c70e3--1688828f6de54f7fadcc0d41f99ca5de 49b13ffd279a489ba258e0668a0af7a7 6ffe696b9e5f49f9ad291df3602c70e3--49b13ffd279a489ba258e0668a0af7a7 0d479bc75820402299d5988d9269031c 49b13ffd279a489ba258e0668a0af7a7--0d479bc75820402299d5988d9269031c a7bdd3a17c054dda97c371ce4c043386 0d479bc75820402299d5988d9269031c--a7bdd3a17c054dda97c371ce4c043386 1ca54b4c1e2144cdae4d4ba1d2c3b0b7 a7bdd3a17c054dda97c371ce4c043386--1ca54b4c1e2144cdae4d4ba1d2c3b0b7 7c31a7fcae944cd884c86080e8d2d7e4 1ca54b4c1e2144cdae4d4ba1d2c3b0b7--7c31a7fcae944cd884c86080e8d2d7e4 d18c3f3830ae4fccb73a3f22aa70aa86 7c31a7fcae944cd884c86080e8d2d7e4--d18c3f3830ae4fccb73a3f22aa70aa86 4d023778382a4f1695361be6ac7753de X d18c3f3830ae4fccb73a3f22aa70aa86--4d023778382a4f1695361be6ac7753de 4d023778382a4f1695361be6ac7753de--07d2ea8bf34d4a06aec34b95079f9b39 c308645ff1e04b1b8a621ca5a82ac75b 4d023778382a4f1695361be6ac7753de--c308645ff1e04b1b8a621ca5a82ac75b 110fddea68cc4320a64e588e5ae606b4 c308645ff1e04b1b8a621ca5a82ac75b--110fddea68cc4320a64e588e5ae606b4 37f5fcc0795042b6959a84815e3f920e 110fddea68cc4320a64e588e5ae606b4--37f5fcc0795042b6959a84815e3f920e dd56da71edd14056855897b4707f9d23 37f5fcc0795042b6959a84815e3f920e--dd56da71edd14056855897b4707f9d23 bd60b166d0cb4897bbdac2556237db28 dd56da71edd14056855897b4707f9d23--bd60b166d0cb4897bbdac2556237db28 0e836221454b469eae11d2bcadb27359 X bd60b166d0cb4897bbdac2556237db28--0e836221454b469eae11d2bcadb27359 0e836221454b469eae11d2bcadb27359--8f1817609d5c46bebf17ca5864492c64 8ec998c677ff4a8fb6adde424bef046a 0e836221454b469eae11d2bcadb27359--8ec998c677ff4a8fb6adde424bef046a 95693c210a2942808bd9d2123bd2ccdd 8ec998c677ff4a8fb6adde424bef046a--95693c210a2942808bd9d2123bd2ccdd 724a2d25e017494f89b049346c36261d 95693c210a2942808bd9d2123bd2ccdd--724a2d25e017494f89b049346c36261d cd666877affd455a942ac5517f58f7a5 724a2d25e017494f89b049346c36261d--cd666877affd455a942ac5517f58f7a5 d0ac83edeb764fa996430b939a32cdc8 cd666877affd455a942ac5517f58f7a5--d0ac83edeb764fa996430b939a32cdc8 cf89e58ddce543d98b414cbddea697a7 d0ac83edeb764fa996430b939a32cdc8--cf89e58ddce543d98b414cbddea697a7 9c07b9e5530348d5825422817fec5272 cf89e58ddce543d98b414cbddea697a7--9c07b9e5530348d5825422817fec5272 0015e8c43aa0467a9ca1ccba9747577f 9c07b9e5530348d5825422817fec5272--0015e8c43aa0467a9ca1ccba9747577f a9b8b4eaf68743d383d836d5fecb1ba6 0015e8c43aa0467a9ca1ccba9747577f--a9b8b4eaf68743d383d836d5fecb1ba6 2078e7d3298841b4bb78b8ba38a403ec a9b8b4eaf68743d383d836d5fecb1ba6--2078e7d3298841b4bb78b8ba38a403ec be83653b96f34dd7a8c645f6ea03b80f X 2078e7d3298841b4bb78b8ba38a403ec--be83653b96f34dd7a8c645f6ea03b80f be83653b96f34dd7a8c645f6ea03b80f--bd74aee485274dddae616d1bc28edc93 62e301395f694e8e9f256874aeb0a2ea RZ(-1.0*g1) be83653b96f34dd7a8c645f6ea03b80f--62e301395f694e8e9f256874aeb0a2ea a549313ce9684c669bb4b5cf19d65e22 X 62e301395f694e8e9f256874aeb0a2ea--a549313ce9684c669bb4b5cf19d65e22 a549313ce9684c669bb4b5cf19d65e22--4905271a5fcf4e2ebdc49f259ed42d06 3dec1b5a6f5a459eaf8306debf9fe3ce a549313ce9684c669bb4b5cf19d65e22--3dec1b5a6f5a459eaf8306debf9fe3ce 81013b96f92840c7ae654f03e0001925 3dec1b5a6f5a459eaf8306debf9fe3ce--81013b96f92840c7ae654f03e0001925 a0fa0830e08a4fbfb0385f8804ef364f 81013b96f92840c7ae654f03e0001925--a0fa0830e08a4fbfb0385f8804ef364f a88b877e9bfe4ef4962a531af3847366 a0fa0830e08a4fbfb0385f8804ef364f--a88b877e9bfe4ef4962a531af3847366 92ac8463fb2f4508b1ae8eee6481d8a8 X a88b877e9bfe4ef4962a531af3847366--92ac8463fb2f4508b1ae8eee6481d8a8 92ac8463fb2f4508b1ae8eee6481d8a8--7a040b921aff413da97cf56ac6e31c24 10f01e735ed54c24b31f289e3bdd6fdb 92ac8463fb2f4508b1ae8eee6481d8a8--10f01e735ed54c24b31f289e3bdd6fdb c7d662be3a75482bb91f6cd61b8c7981 10f01e735ed54c24b31f289e3bdd6fdb--c7d662be3a75482bb91f6cd61b8c7981 b9258a2c091042568db65193a82309f6 c7d662be3a75482bb91f6cd61b8c7981--b9258a2c091042568db65193a82309f6 83c4bb980bfd468dae8e60638687e49f b9258a2c091042568db65193a82309f6--83c4bb980bfd468dae8e60638687e49f dff8e83b03a84b9ab9df2bf3a022b823 83c4bb980bfd468dae8e60638687e49f--dff8e83b03a84b9ab9df2bf3a022b823 97a08155cad143d4b1183d5cc91eb003 X dff8e83b03a84b9ab9df2bf3a022b823--97a08155cad143d4b1183d5cc91eb003 97a08155cad143d4b1183d5cc91eb003--4ac43726411e48cba7fd696db126b8fe 5aace1d6c2cf401db5da7792ac34ed59 97a08155cad143d4b1183d5cc91eb003--5aace1d6c2cf401db5da7792ac34ed59 d6374deb21f74f539b51570f8bd20123 5aace1d6c2cf401db5da7792ac34ed59--d6374deb21f74f539b51570f8bd20123 23578866f5474d95a6ac2cab0cde7b0f d6374deb21f74f539b51570f8bd20123--23578866f5474d95a6ac2cab0cde7b0f 45e94e3e3bdb44f28250daa947cc6f59 23578866f5474d95a6ac2cab0cde7b0f--45e94e3e3bdb44f28250daa947cc6f59 6aeaa25596324ba8a92fc84e0431be5d 45e94e3e3bdb44f28250daa947cc6f59--6aeaa25596324ba8a92fc84e0431be5d dbea1fd0850849ea8d83ada87cedcbf9 6aeaa25596324ba8a92fc84e0431be5d--dbea1fd0850849ea8d83ada87cedcbf9 20afa33fc1af4fbe9093e07b925df2c5 X dbea1fd0850849ea8d83ada87cedcbf9--20afa33fc1af4fbe9093e07b925df2c5 20afa33fc1af4fbe9093e07b925df2c5--9debd5afe8484cfc88a33ceddefbfba8 e0dc1510bdb246aa98a012b2137a241e 20afa33fc1af4fbe9093e07b925df2c5--e0dc1510bdb246aa98a012b2137a241e 3148a7d0c872427a8de7b9d321213b31 e0dc1510bdb246aa98a012b2137a241e--3148a7d0c872427a8de7b9d321213b31 be11d5d685cb4e9da6f25b918c5e44c5 3148a7d0c872427a8de7b9d321213b31--be11d5d685cb4e9da6f25b918c5e44c5 428be81e255847199a505413df1602e9 X be11d5d685cb4e9da6f25b918c5e44c5--428be81e255847199a505413df1602e9 428be81e255847199a505413df1602e9--6bf43fea28ff459e8e6163f8b101179b 940626ca1fe14edc8721bc7ba1a6620d 428be81e255847199a505413df1602e9--940626ca1fe14edc8721bc7ba1a6620d 5e41954a0bad4660b4f47fee0407310b 940626ca1fe14edc8721bc7ba1a6620d--5e41954a0bad4660b4f47fee0407310b c40213c7787948bc82ef8d022f8ef05c X 5e41954a0bad4660b4f47fee0407310b--c40213c7787948bc82ef8d022f8ef05c c40213c7787948bc82ef8d022f8ef05c--6cd5409197b44b08b94e03ef696e03dc b8da04d0c1fc4d6489eeae1683eb124e c40213c7787948bc82ef8d022f8ef05c--b8da04d0c1fc4d6489eeae1683eb124e 882ca1f69915428d973f22254626567e b8da04d0c1fc4d6489eeae1683eb124e--882ca1f69915428d973f22254626567e c610164959b243afbd040829cdeb4005 882ca1f69915428d973f22254626567e--c610164959b243afbd040829cdeb4005 86fed7a0ab4e438abe5069e391ff6754 c610164959b243afbd040829cdeb4005--86fed7a0ab4e438abe5069e391ff6754 8cbb393a2b3f4e5e9c983157e1c3ba6d 86fed7a0ab4e438abe5069e391ff6754--8cbb393a2b3f4e5e9c983157e1c3ba6d 3d980c1ba20b4847a2356502eb473322 X 8cbb393a2b3f4e5e9c983157e1c3ba6d--3d980c1ba20b4847a2356502eb473322 3d980c1ba20b4847a2356502eb473322--ac3fa92dde7e4159b383f2b4b1f5ca83 c61ff54873a149058e8cdf5dbb19a7d0 3d980c1ba20b4847a2356502eb473322--c61ff54873a149058e8cdf5dbb19a7d0 9f92b5b659a543178dc7950c4ac86301 X c61ff54873a149058e8cdf5dbb19a7d0--9f92b5b659a543178dc7950c4ac86301 9f92b5b659a543178dc7950c4ac86301--2f7102f0b61b4df7a3d092444e1a0fc4 6c4a67654b4f4ae4a278dbb57a512478 RZ(-1.0*g1) 9f92b5b659a543178dc7950c4ac86301--6c4a67654b4f4ae4a278dbb57a512478 78096c39ad564087b0cec3ba09d330e7 X 6c4a67654b4f4ae4a278dbb57a512478--78096c39ad564087b0cec3ba09d330e7 78096c39ad564087b0cec3ba09d330e7--7b36cfe7297b4fb485392690d06fc0e6 36510e3a05054f3280e0baaf29486a88 X 78096c39ad564087b0cec3ba09d330e7--36510e3a05054f3280e0baaf29486a88 36510e3a05054f3280e0baaf29486a88--cc13d45efb934f4d82dd4b4d5acb4653 983ad8c98f094e22afdef0e4fe5a05bd 36510e3a05054f3280e0baaf29486a88--983ad8c98f094e22afdef0e4fe5a05bd 1143331d5f2c4c61a54d11124566ad94 983ad8c98f094e22afdef0e4fe5a05bd--1143331d5f2c4c61a54d11124566ad94 a393b2f6c81f4fa8b3db94aae24a3532 1143331d5f2c4c61a54d11124566ad94--a393b2f6c81f4fa8b3db94aae24a3532 395d483ca0594b50bc1a151a19214900 X a393b2f6c81f4fa8b3db94aae24a3532--395d483ca0594b50bc1a151a19214900 395d483ca0594b50bc1a151a19214900--cabcb38d85e44e1f9e4520d03607fb8d 258d6727987843b6937f57a426d9c3f9 395d483ca0594b50bc1a151a19214900--258d6727987843b6937f57a426d9c3f9 0049cc2c5ef74cd4a6dbbac3510d944e 258d6727987843b6937f57a426d9c3f9--0049cc2c5ef74cd4a6dbbac3510d944e 9d8823d4157949cf907426e59dec8859 0049cc2c5ef74cd4a6dbbac3510d944e--9d8823d4157949cf907426e59dec8859 2e0723e7e6774d349d697612a688e40a 9d8823d4157949cf907426e59dec8859--2e0723e7e6774d349d697612a688e40a 6dffbdd9433243c6a22e37d9bdcf44d7 2e0723e7e6774d349d697612a688e40a--6dffbdd9433243c6a22e37d9bdcf44d7 6f5828d79e3e4a858206637b42e1b2c5 6dffbdd9433243c6a22e37d9bdcf44d7--6f5828d79e3e4a858206637b42e1b2c5 7f0c607f189345c2ac336a4bb62fcfd1 6f5828d79e3e4a858206637b42e1b2c5--7f0c607f189345c2ac336a4bb62fcfd1 6d65ad0420a041e88f2ce7b9081d41c4 7f0c607f189345c2ac336a4bb62fcfd1--6d65ad0420a041e88f2ce7b9081d41c4 d2952a91ae464637aaff54e9aad94393 RX(b15) 6d65ad0420a041e88f2ce7b9081d41c4--d2952a91ae464637aaff54e9aad94393 d2952a91ae464637aaff54e9aad94393--bbe8b965cefc4efc91d49eda7f2b32d0 df4a114fc031437a89efa9b4110fcd41 2e0e7d005df34def9c202a5c6aac003d a44c71d7c6be4b3e9ca76fdd718ccab5--2e0e7d005df34def9c202a5c6aac003d b9925083604d45f6a07670404f2f0a36 7 b49d6ec9575444d6bc8a76c8f7f57666 2e0e7d005df34def9c202a5c6aac003d--b49d6ec9575444d6bc8a76c8f7f57666 868ff038951c4e10ab3f2a2e6385594d b49d6ec9575444d6bc8a76c8f7f57666--868ff038951c4e10ab3f2a2e6385594d 30f5b60c5d514ad0b70754869918b2e8 868ff038951c4e10ab3f2a2e6385594d--30f5b60c5d514ad0b70754869918b2e8 c7a61ec372cf423f9632617c744807f5 30f5b60c5d514ad0b70754869918b2e8--c7a61ec372cf423f9632617c744807f5 6b1895fd14f64a09b256c91ad9776a9e X c7a61ec372cf423f9632617c744807f5--6b1895fd14f64a09b256c91ad9776a9e 6b1895fd14f64a09b256c91ad9776a9e--43ff2f6ba97a4e10baf600645a200c42 948b9d2787ca4429ba52294946fd2339 6b1895fd14f64a09b256c91ad9776a9e--948b9d2787ca4429ba52294946fd2339 493c18fd9b2e400d938c2999d471613e 948b9d2787ca4429ba52294946fd2339--493c18fd9b2e400d938c2999d471613e 38f957f5fdb145bb96898c045ef3194b 493c18fd9b2e400d938c2999d471613e--38f957f5fdb145bb96898c045ef3194b 49ce269054dd439abd02aa9f104f3d61 X 38f957f5fdb145bb96898c045ef3194b--49ce269054dd439abd02aa9f104f3d61 49ce269054dd439abd02aa9f104f3d61--4394815e13db4348b105aea1bf5e0668 1d49b1e2e5d94317b3f5a412df0b884e 49ce269054dd439abd02aa9f104f3d61--1d49b1e2e5d94317b3f5a412df0b884e 3a36045c615b44dbab4f172aba17abf0 1d49b1e2e5d94317b3f5a412df0b884e--3a36045c615b44dbab4f172aba17abf0 2afeec0c70b6427e9b80467a30d019b7 3a36045c615b44dbab4f172aba17abf0--2afeec0c70b6427e9b80467a30d019b7 28244131287f4f0495fa1a0d752a88d1 2afeec0c70b6427e9b80467a30d019b7--28244131287f4f0495fa1a0d752a88d1 7ffa77e612f64a21aed9e17bea54bf49 28244131287f4f0495fa1a0d752a88d1--7ffa77e612f64a21aed9e17bea54bf49 ce27f1c1d4e24d82ab40cada25054652 7ffa77e612f64a21aed9e17bea54bf49--ce27f1c1d4e24d82ab40cada25054652 d59201a987aa4e43b29455bc42f2178d ce27f1c1d4e24d82ab40cada25054652--d59201a987aa4e43b29455bc42f2178d 7a97927dd4604016b13aca579649269c d59201a987aa4e43b29455bc42f2178d--7a97927dd4604016b13aca579649269c 73f0068fa080479b881bb47de8d5c110 7a97927dd4604016b13aca579649269c--73f0068fa080479b881bb47de8d5c110 70ccb660b9724a2bb6980b79bef69169 73f0068fa080479b881bb47de8d5c110--70ccb660b9724a2bb6980b79bef69169 4a7a8f884da2442cb5089d0447bca143 70ccb660b9724a2bb6980b79bef69169--4a7a8f884da2442cb5089d0447bca143 915b9a60349c4114b01142618c40893a 4a7a8f884da2442cb5089d0447bca143--915b9a60349c4114b01142618c40893a 22e13d9e6a194e4384c52b142a3bde0c 915b9a60349c4114b01142618c40893a--22e13d9e6a194e4384c52b142a3bde0c 0ce3eea419d749a8ba0acee5aecdd071 22e13d9e6a194e4384c52b142a3bde0c--0ce3eea419d749a8ba0acee5aecdd071 6bda02df3b6e4e668f0c6e0aedbe1709 0ce3eea419d749a8ba0acee5aecdd071--6bda02df3b6e4e668f0c6e0aedbe1709 2a0001dbcaec4062831dfcf6bdf88134 6bda02df3b6e4e668f0c6e0aedbe1709--2a0001dbcaec4062831dfcf6bdf88134 54ade9cf1b3f4f9db3e943b2f9df54b6 2a0001dbcaec4062831dfcf6bdf88134--54ade9cf1b3f4f9db3e943b2f9df54b6 1975e0c51ba240a68065c4b03657d578 54ade9cf1b3f4f9db3e943b2f9df54b6--1975e0c51ba240a68065c4b03657d578 7fc1cc63e1c441489d43ff9f91e7b7ce 1975e0c51ba240a68065c4b03657d578--7fc1cc63e1c441489d43ff9f91e7b7ce d0082a03ec0f479ab034e306a4f8c49a 7fc1cc63e1c441489d43ff9f91e7b7ce--d0082a03ec0f479ab034e306a4f8c49a 033e05a714484f348449a052896a4a7f d0082a03ec0f479ab034e306a4f8c49a--033e05a714484f348449a052896a4a7f a62d4b7bf89d45428ab771c016d30cdb 033e05a714484f348449a052896a4a7f--a62d4b7bf89d45428ab771c016d30cdb e25198258e4840dbb49a079a072bbd77 a62d4b7bf89d45428ab771c016d30cdb--e25198258e4840dbb49a079a072bbd77 d079a59c7f8d435aae3211b7c7fffc70 e25198258e4840dbb49a079a072bbd77--d079a59c7f8d435aae3211b7c7fffc70 dc2cf612de8441429572f5ec5f8c7baf d079a59c7f8d435aae3211b7c7fffc70--dc2cf612de8441429572f5ec5f8c7baf d84e57c2b2b647649feb1893fd637c9c dc2cf612de8441429572f5ec5f8c7baf--d84e57c2b2b647649feb1893fd637c9c a8508a2c6b6d4dee914b08c77bf08e43 d84e57c2b2b647649feb1893fd637c9c--a8508a2c6b6d4dee914b08c77bf08e43 b14ac1d6f12342729fcd872b576b8ff0 X a8508a2c6b6d4dee914b08c77bf08e43--b14ac1d6f12342729fcd872b576b8ff0 b14ac1d6f12342729fcd872b576b8ff0--750db135a802453e985b6caf6594aaa3 3a0e3948b72745168bf9dfd33b9d8ae2 b14ac1d6f12342729fcd872b576b8ff0--3a0e3948b72745168bf9dfd33b9d8ae2 0a5798a8ed914a6490988df654dcc4de 3a0e3948b72745168bf9dfd33b9d8ae2--0a5798a8ed914a6490988df654dcc4de ddbaed0493ce4583b104e880b25c4f8d 0a5798a8ed914a6490988df654dcc4de--ddbaed0493ce4583b104e880b25c4f8d e54bb9f7e90840e2adad8e5f8ec91a78 X ddbaed0493ce4583b104e880b25c4f8d--e54bb9f7e90840e2adad8e5f8ec91a78 e54bb9f7e90840e2adad8e5f8ec91a78--b7a650dc27f44740b5d1c48be72ecba5 e60c0371572240fdba5abf8ffa57ad57 e54bb9f7e90840e2adad8e5f8ec91a78--e60c0371572240fdba5abf8ffa57ad57 3b52052cf69a497bb33c4b8ccfb08829 e60c0371572240fdba5abf8ffa57ad57--3b52052cf69a497bb33c4b8ccfb08829 9ee7d013ba024ca1af729a0cb890cc63 3b52052cf69a497bb33c4b8ccfb08829--9ee7d013ba024ca1af729a0cb890cc63 8da6b461b8984bc9aadaca968e305b5b 9ee7d013ba024ca1af729a0cb890cc63--8da6b461b8984bc9aadaca968e305b5b eecf07b941194d9e90a82fce0ed2cea2 8da6b461b8984bc9aadaca968e305b5b--eecf07b941194d9e90a82fce0ed2cea2 fad8f59f31b64de78ea314d2f093123f eecf07b941194d9e90a82fce0ed2cea2--fad8f59f31b64de78ea314d2f093123f 4d741b5ad8d741d193e9f29b56247cd9 fad8f59f31b64de78ea314d2f093123f--4d741b5ad8d741d193e9f29b56247cd9 644d1ad64a5a4586a25ce1072f013193 4d741b5ad8d741d193e9f29b56247cd9--644d1ad64a5a4586a25ce1072f013193 6524ac177a404c858cc67aabd65e4a4c 644d1ad64a5a4586a25ce1072f013193--6524ac177a404c858cc67aabd65e4a4c 5b65f03f3c674a8abe165175bfd27d4f 6524ac177a404c858cc67aabd65e4a4c--5b65f03f3c674a8abe165175bfd27d4f b8a66f01f6574bfeacb22be71235fa21 5b65f03f3c674a8abe165175bfd27d4f--b8a66f01f6574bfeacb22be71235fa21 b1990417534c4a9bab7484f7b4830ec9 b8a66f01f6574bfeacb22be71235fa21--b1990417534c4a9bab7484f7b4830ec9 9c715fd1937845b7a9e1ad0e6192124c b1990417534c4a9bab7484f7b4830ec9--9c715fd1937845b7a9e1ad0e6192124c 29048cc9b1c74810a66c97b9c288c415 9c715fd1937845b7a9e1ad0e6192124c--29048cc9b1c74810a66c97b9c288c415 33b3f03b53384f90be443a3d9086cc85 29048cc9b1c74810a66c97b9c288c415--33b3f03b53384f90be443a3d9086cc85 9c73a41373a441d9b26c0eb4074178c6 33b3f03b53384f90be443a3d9086cc85--9c73a41373a441d9b26c0eb4074178c6 e656a642a3424d94909382b7758e03a5 9c73a41373a441d9b26c0eb4074178c6--e656a642a3424d94909382b7758e03a5 e8139e28bec144f89424155db2d748c1 e656a642a3424d94909382b7758e03a5--e8139e28bec144f89424155db2d748c1 6a24dcf883bd4f9c840455904f0c1c02 X e8139e28bec144f89424155db2d748c1--6a24dcf883bd4f9c840455904f0c1c02 6a24dcf883bd4f9c840455904f0c1c02--bb982d7e3f6048f980afed1ae804077d 76cdb54eddca44f0ae3cbc7b8424e17b RZ(-1.0*g0) 6a24dcf883bd4f9c840455904f0c1c02--76cdb54eddca44f0ae3cbc7b8424e17b 2c799bc3e3b942bab3d3d972491dcc26 X 76cdb54eddca44f0ae3cbc7b8424e17b--2c799bc3e3b942bab3d3d972491dcc26 2c799bc3e3b942bab3d3d972491dcc26--ab638c62ee664a23a13b2e4101e896de 1eccaaaf8ceb4c828a94c1e55d475c43 2c799bc3e3b942bab3d3d972491dcc26--1eccaaaf8ceb4c828a94c1e55d475c43 87492882dde5484a90810dc73816492a 1eccaaaf8ceb4c828a94c1e55d475c43--87492882dde5484a90810dc73816492a 9bb2ea0bdfd142ce872463e47ca944cb 87492882dde5484a90810dc73816492a--9bb2ea0bdfd142ce872463e47ca944cb 91aee18536624a8083a0e55b15d5ce53 9bb2ea0bdfd142ce872463e47ca944cb--91aee18536624a8083a0e55b15d5ce53 5fdfce22cf894ac18f107f81d60fdf4e 91aee18536624a8083a0e55b15d5ce53--5fdfce22cf894ac18f107f81d60fdf4e 22fe256ec2354a849f9d43561d6a063f 5fdfce22cf894ac18f107f81d60fdf4e--22fe256ec2354a849f9d43561d6a063f a3d93e7d181541cb9669ab84cbed5a81 22fe256ec2354a849f9d43561d6a063f--a3d93e7d181541cb9669ab84cbed5a81 a110cf1e627845be8325ca62668a01f5 a3d93e7d181541cb9669ab84cbed5a81--a110cf1e627845be8325ca62668a01f5 a2e06c3d44e0434d863a12496c981b5d X a110cf1e627845be8325ca62668a01f5--a2e06c3d44e0434d863a12496c981b5d a2e06c3d44e0434d863a12496c981b5d--e87dbfa7d672408589933e51aa690c20 3675daa959d440119bf056acc1c734c1 a2e06c3d44e0434d863a12496c981b5d--3675daa959d440119bf056acc1c734c1 04e1a44c3f3a48c9a5fac95a972d9af5 3675daa959d440119bf056acc1c734c1--04e1a44c3f3a48c9a5fac95a972d9af5 bb4a9be803f8490490d48eb5b2c66998 04e1a44c3f3a48c9a5fac95a972d9af5--bb4a9be803f8490490d48eb5b2c66998 07e349a1a1cf47cc836f014b4689f756 X bb4a9be803f8490490d48eb5b2c66998--07e349a1a1cf47cc836f014b4689f756 07e349a1a1cf47cc836f014b4689f756--6e446aa8e0d14c059acce13e7144fb0d 78ada111e8224b46add036eb1f134f66 07e349a1a1cf47cc836f014b4689f756--78ada111e8224b46add036eb1f134f66 aa3da78d58564a05bf1fd223d85052bc 78ada111e8224b46add036eb1f134f66--aa3da78d58564a05bf1fd223d85052bc 766f6beaa622452b8007f9f56d19bdc0 aa3da78d58564a05bf1fd223d85052bc--766f6beaa622452b8007f9f56d19bdc0 3970555afb214d1ca8935768f000a86e 766f6beaa622452b8007f9f56d19bdc0--3970555afb214d1ca8935768f000a86e fadd1cf637334cd0bf6ce8d6a212275f 3970555afb214d1ca8935768f000a86e--fadd1cf637334cd0bf6ce8d6a212275f c73d8d7569574a3282da2a24dba7faf4 fadd1cf637334cd0bf6ce8d6a212275f--c73d8d7569574a3282da2a24dba7faf4 9d1ddb352447436bbbb650ed35ba48c6 c73d8d7569574a3282da2a24dba7faf4--9d1ddb352447436bbbb650ed35ba48c6 2f7c9cd78bad4e6b8d58fc25a1f9dc62 9d1ddb352447436bbbb650ed35ba48c6--2f7c9cd78bad4e6b8d58fc25a1f9dc62 7813b36f2db4411c8fb97a49c125dca1 2f7c9cd78bad4e6b8d58fc25a1f9dc62--7813b36f2db4411c8fb97a49c125dca1 1d805eee4cfb4ec6931160374ee4832f 7813b36f2db4411c8fb97a49c125dca1--1d805eee4cfb4ec6931160374ee4832f 9c75cdba92a54c0bb0be691fbc173cf3 1d805eee4cfb4ec6931160374ee4832f--9c75cdba92a54c0bb0be691fbc173cf3 2a454821dee14c03a258924a1c437bcf 9c75cdba92a54c0bb0be691fbc173cf3--2a454821dee14c03a258924a1c437bcf d8ccc230308844b7bc1b14ca353cf4e0 2a454821dee14c03a258924a1c437bcf--d8ccc230308844b7bc1b14ca353cf4e0 755521c342e242899b9c89bd795ede20 d8ccc230308844b7bc1b14ca353cf4e0--755521c342e242899b9c89bd795ede20 4d506175ba054e81b2c996e76d822fcb 755521c342e242899b9c89bd795ede20--4d506175ba054e81b2c996e76d822fcb 801b1dd66ebe4fc78f156c022fc42507 4d506175ba054e81b2c996e76d822fcb--801b1dd66ebe4fc78f156c022fc42507 3ecae0165ae34b638ce97503c27508f7 801b1dd66ebe4fc78f156c022fc42507--3ecae0165ae34b638ce97503c27508f7 3b147bf1ed8941b1b0da639754208cd2 3ecae0165ae34b638ce97503c27508f7--3b147bf1ed8941b1b0da639754208cd2 9d0492ca51cd4172b6271649f8f0bb7e 3b147bf1ed8941b1b0da639754208cd2--9d0492ca51cd4172b6271649f8f0bb7e d9021cb2befe441fa8dc828ee2ffd447 X 9d0492ca51cd4172b6271649f8f0bb7e--d9021cb2befe441fa8dc828ee2ffd447 d9021cb2befe441fa8dc828ee2ffd447--1cb6677e77554b08a98ac5fe37828887 53060cd761684bf5bd0d63c2bb5ab106 d9021cb2befe441fa8dc828ee2ffd447--53060cd761684bf5bd0d63c2bb5ab106 bb0db454838d47d384293d326b8b219a 53060cd761684bf5bd0d63c2bb5ab106--bb0db454838d47d384293d326b8b219a 87c0bf5a37ec408e91b127d3ac6cb8c4 bb0db454838d47d384293d326b8b219a--87c0bf5a37ec408e91b127d3ac6cb8c4 af313b581a5f48798e7d59b266262bc6 X 87c0bf5a37ec408e91b127d3ac6cb8c4--af313b581a5f48798e7d59b266262bc6 af313b581a5f48798e7d59b266262bc6--4d781b279f70444fb88eeb8958610679 4f256f1a434c4175ae9b12b8bea552e1 af313b581a5f48798e7d59b266262bc6--4f256f1a434c4175ae9b12b8bea552e1 0202d11637c84f6db164776eb13ffd0a 4f256f1a434c4175ae9b12b8bea552e1--0202d11637c84f6db164776eb13ffd0a aba8bc202b4b460cadd1f12458ee5b0f 0202d11637c84f6db164776eb13ffd0a--aba8bc202b4b460cadd1f12458ee5b0f fa7514ba4127475a90d1cc3166d65e34 aba8bc202b4b460cadd1f12458ee5b0f--fa7514ba4127475a90d1cc3166d65e34 bb27161d567240b9a67733a07be6c47c fa7514ba4127475a90d1cc3166d65e34--bb27161d567240b9a67733a07be6c47c 9c1037f28cd747d99c0e4f64a9f4e266 bb27161d567240b9a67733a07be6c47c--9c1037f28cd747d99c0e4f64a9f4e266 2775d11a6abe4207acd918baf874591e 9c1037f28cd747d99c0e4f64a9f4e266--2775d11a6abe4207acd918baf874591e 7eefe21cd28f408b9f74f888b0522e21 2775d11a6abe4207acd918baf874591e--7eefe21cd28f408b9f74f888b0522e21 760f9c2020f44226b96ec217c5b8554a X 7eefe21cd28f408b9f74f888b0522e21--760f9c2020f44226b96ec217c5b8554a 760f9c2020f44226b96ec217c5b8554a--c6cd9e65090b4f63a4fc7f4e1f3e30b0 ea84fe4f3de64bf2bc01ca345f39c208 RZ(-1.0*g0) 760f9c2020f44226b96ec217c5b8554a--ea84fe4f3de64bf2bc01ca345f39c208 db73c49359c747a4a20e6605b28c80bd X ea84fe4f3de64bf2bc01ca345f39c208--db73c49359c747a4a20e6605b28c80bd db73c49359c747a4a20e6605b28c80bd--af2ea2fe8178447c8bf055ddab384067 b61aa022eeb84abeb1b37bdb4705af18 db73c49359c747a4a20e6605b28c80bd--b61aa022eeb84abeb1b37bdb4705af18 1f644b24280d48f99e7b3a5de3dc8179 b61aa022eeb84abeb1b37bdb4705af18--1f644b24280d48f99e7b3a5de3dc8179 8f0d32cd09f04c86a52cc9fce9c738b6 1f644b24280d48f99e7b3a5de3dc8179--8f0d32cd09f04c86a52cc9fce9c738b6 cc8a8fde8a2541fb9af31a660d0d474c 8f0d32cd09f04c86a52cc9fce9c738b6--cc8a8fde8a2541fb9af31a660d0d474c b8a2900cd3d34080a7028505766620e3 X cc8a8fde8a2541fb9af31a660d0d474c--b8a2900cd3d34080a7028505766620e3 b8a2900cd3d34080a7028505766620e3--c3d0b57a887844d68d7538472f3ed5d3 c5dba96a713a4973b84eb95af4c1a8ac b8a2900cd3d34080a7028505766620e3--c5dba96a713a4973b84eb95af4c1a8ac 72889859c87d4b349a72ea3e582daf35 c5dba96a713a4973b84eb95af4c1a8ac--72889859c87d4b349a72ea3e582daf35 3dcab24c05714c49b127df8b94945f3e 72889859c87d4b349a72ea3e582daf35--3dcab24c05714c49b127df8b94945f3e e572df6fbcf4480ea1d10f988c48eab0 X 3dcab24c05714c49b127df8b94945f3e--e572df6fbcf4480ea1d10f988c48eab0 e572df6fbcf4480ea1d10f988c48eab0--38cce7e5d8ac4c25bf3ce36ba770b91e 36c85d51870b4276ab0556b8fb568b0e e572df6fbcf4480ea1d10f988c48eab0--36c85d51870b4276ab0556b8fb568b0e 25dcc2868f614869a1e0882632dd19d2 36c85d51870b4276ab0556b8fb568b0e--25dcc2868f614869a1e0882632dd19d2 73f4a58fe9b44c7b8a0c1fd53933f42f 25dcc2868f614869a1e0882632dd19d2--73f4a58fe9b44c7b8a0c1fd53933f42f c565471946c14055b9ae4215aa79e54f 73f4a58fe9b44c7b8a0c1fd53933f42f--c565471946c14055b9ae4215aa79e54f e6bc01ac73b6441ab4ddaa32000f0665 c565471946c14055b9ae4215aa79e54f--e6bc01ac73b6441ab4ddaa32000f0665 f62924d041e6405fb88764767888955f e6bc01ac73b6441ab4ddaa32000f0665--f62924d041e6405fb88764767888955f d2c7792fa1f74d618ebb0eaf2897d596 X f62924d041e6405fb88764767888955f--d2c7792fa1f74d618ebb0eaf2897d596 d2c7792fa1f74d618ebb0eaf2897d596--74f654e55b4943e8980a2b85a7e44bd6 4b34bfd66a4048b6921287ea61a8bda4 RZ(-1.0*g0) d2c7792fa1f74d618ebb0eaf2897d596--4b34bfd66a4048b6921287ea61a8bda4 ab22edb067fd4e238fd74688060c469e X 4b34bfd66a4048b6921287ea61a8bda4--ab22edb067fd4e238fd74688060c469e ab22edb067fd4e238fd74688060c469e--a0b97b7cec6347288d4306ec913d5534 527a2d4e163e4e0c87467515ae709a43 ab22edb067fd4e238fd74688060c469e--527a2d4e163e4e0c87467515ae709a43 5af53fdc825941bc916f4934c6492b84 X 527a2d4e163e4e0c87467515ae709a43--5af53fdc825941bc916f4934c6492b84 5af53fdc825941bc916f4934c6492b84--03dd547dac274ce8897512b67d8edd20 d568b2f1637f4b6397bdd0ed39a01b6b RZ(-1.0*g0) 5af53fdc825941bc916f4934c6492b84--d568b2f1637f4b6397bdd0ed39a01b6b d568b1e29a11478cb72bcdc187524734 X d568b2f1637f4b6397bdd0ed39a01b6b--d568b1e29a11478cb72bcdc187524734 d568b1e29a11478cb72bcdc187524734--b17d33a28774420085e6a2c42b0efa62 c997a3ec769b4bb2b278c5f5df6bde21 X d568b1e29a11478cb72bcdc187524734--c997a3ec769b4bb2b278c5f5df6bde21 c997a3ec769b4bb2b278c5f5df6bde21--fe2d655c03ce4e6d8e149d585a572b84 4fb2e9f949a24ab0a092d92ec2b979ea c997a3ec769b4bb2b278c5f5df6bde21--4fb2e9f949a24ab0a092d92ec2b979ea bd30746e0275420f893c406a8c983abc 4fb2e9f949a24ab0a092d92ec2b979ea--bd30746e0275420f893c406a8c983abc cdc6b0ded425456fad6c202acde0d067 bd30746e0275420f893c406a8c983abc--cdc6b0ded425456fad6c202acde0d067 a61fe1385f044dc9901ac02ae7384a76 X cdc6b0ded425456fad6c202acde0d067--a61fe1385f044dc9901ac02ae7384a76 a61fe1385f044dc9901ac02ae7384a76--02fb6b56b5bc4e93a26cf4cad10a848b 971cf933a6574484aa96746c90328b15 RX(b06) a61fe1385f044dc9901ac02ae7384a76--971cf933a6574484aa96746c90328b15 e2fb6be75f9c4bce9f3107be9dc502ad 971cf933a6574484aa96746c90328b15--e2fb6be75f9c4bce9f3107be9dc502ad 0379889c9e454269942a002e37fbad8c e2fb6be75f9c4bce9f3107be9dc502ad--0379889c9e454269942a002e37fbad8c 9186721aaa1e4f7c8cc2204da798ac74 0379889c9e454269942a002e37fbad8c--9186721aaa1e4f7c8cc2204da798ac74 9167ee41d267478bb5b0723884f4356a 9186721aaa1e4f7c8cc2204da798ac74--9167ee41d267478bb5b0723884f4356a 8edf5a73e4684f2dba2bcbffed6d205c 9167ee41d267478bb5b0723884f4356a--8edf5a73e4684f2dba2bcbffed6d205c 041620aeceee4ff9920326c3f98192e2 X 8edf5a73e4684f2dba2bcbffed6d205c--041620aeceee4ff9920326c3f98192e2 041620aeceee4ff9920326c3f98192e2--6f3544ec32f648e68497f3524afb0dea e2a404aab0c5452baa94ce848414ec22 041620aeceee4ff9920326c3f98192e2--e2a404aab0c5452baa94ce848414ec22 8036087816ff404d8decf9ae19eb6876 e2a404aab0c5452baa94ce848414ec22--8036087816ff404d8decf9ae19eb6876 5c13f1c030734e09a812e0426eb57154 8036087816ff404d8decf9ae19eb6876--5c13f1c030734e09a812e0426eb57154 e9ae3026630d4a969ed4f766da86daac X 5c13f1c030734e09a812e0426eb57154--e9ae3026630d4a969ed4f766da86daac e9ae3026630d4a969ed4f766da86daac--41d1cc56d0c44ab59e1fe8c19ef876e9 522b81e764de4580be2664df237a4d32 e9ae3026630d4a969ed4f766da86daac--522b81e764de4580be2664df237a4d32 a9c0517d733e4dbea2db585c84ec52a8 522b81e764de4580be2664df237a4d32--a9c0517d733e4dbea2db585c84ec52a8 a7a4605de0694140b84f5af92acda961 a9c0517d733e4dbea2db585c84ec52a8--a7a4605de0694140b84f5af92acda961 0a4b3a0ba6034805afed758b81d502c1 a7a4605de0694140b84f5af92acda961--0a4b3a0ba6034805afed758b81d502c1 57ede8a5baa943bebc9b35c1c7652a9b 0a4b3a0ba6034805afed758b81d502c1--57ede8a5baa943bebc9b35c1c7652a9b 919708254016480a8f4784e81a3ed7d3 57ede8a5baa943bebc9b35c1c7652a9b--919708254016480a8f4784e81a3ed7d3 22c244e60d524740bb9d95504eee15a0 919708254016480a8f4784e81a3ed7d3--22c244e60d524740bb9d95504eee15a0 df02fc3216aa41c4b18e8a994cece868 22c244e60d524740bb9d95504eee15a0--df02fc3216aa41c4b18e8a994cece868 09dff3241cd04308a58d88f189bac262 df02fc3216aa41c4b18e8a994cece868--09dff3241cd04308a58d88f189bac262 f42f3dac52e94046a90e9b796990f768 09dff3241cd04308a58d88f189bac262--f42f3dac52e94046a90e9b796990f768 07a207f72e2844e78dfdb86c62ab9066 f42f3dac52e94046a90e9b796990f768--07a207f72e2844e78dfdb86c62ab9066 fc0a0e3aee4d4548b26ad1ed4209899f 07a207f72e2844e78dfdb86c62ab9066--fc0a0e3aee4d4548b26ad1ed4209899f 785dbbb211474dfcb00c79c7c6e417b4 fc0a0e3aee4d4548b26ad1ed4209899f--785dbbb211474dfcb00c79c7c6e417b4 17e156fd0ca540b3bc1cb74c59d53ad2 785dbbb211474dfcb00c79c7c6e417b4--17e156fd0ca540b3bc1cb74c59d53ad2 96d512ecd53e4fea817877b1b1aa3528 17e156fd0ca540b3bc1cb74c59d53ad2--96d512ecd53e4fea817877b1b1aa3528 2e38422b66ad4a2684c6e6ce0d6fa9d4 96d512ecd53e4fea817877b1b1aa3528--2e38422b66ad4a2684c6e6ce0d6fa9d4 79562fcc4f4b4052b92ab059d7d403f3 2e38422b66ad4a2684c6e6ce0d6fa9d4--79562fcc4f4b4052b92ab059d7d403f3 85337428fbf844d0af795ca473047e05 79562fcc4f4b4052b92ab059d7d403f3--85337428fbf844d0af795ca473047e05 0d233205fa2d466d8dbfd7e0e164974f 85337428fbf844d0af795ca473047e05--0d233205fa2d466d8dbfd7e0e164974f 93351c5d7e714ad2a5fe9600a5d993e5 0d233205fa2d466d8dbfd7e0e164974f--93351c5d7e714ad2a5fe9600a5d993e5 21d697cd3ade45009397e5fde9c6b055 93351c5d7e714ad2a5fe9600a5d993e5--21d697cd3ade45009397e5fde9c6b055 4fb7ba1cbc884780aea79d2a3dc1a1b0 21d697cd3ade45009397e5fde9c6b055--4fb7ba1cbc884780aea79d2a3dc1a1b0 94a3b00ba6a84492a6f51c33a24401c8 4fb7ba1cbc884780aea79d2a3dc1a1b0--94a3b00ba6a84492a6f51c33a24401c8 13ab4318e6ad44eea4a9639654e2b2f3 94a3b00ba6a84492a6f51c33a24401c8--13ab4318e6ad44eea4a9639654e2b2f3 d89296a5455d45559ebf31ad0f4abbab 13ab4318e6ad44eea4a9639654e2b2f3--d89296a5455d45559ebf31ad0f4abbab d700166ae62c413da86bd2bfd3acade9 d89296a5455d45559ebf31ad0f4abbab--d700166ae62c413da86bd2bfd3acade9 34d0082adc814b6a9f3beb09d6049e62 d700166ae62c413da86bd2bfd3acade9--34d0082adc814b6a9f3beb09d6049e62 e732a889ec964e4c8b43993e8f6186c8 X 34d0082adc814b6a9f3beb09d6049e62--e732a889ec964e4c8b43993e8f6186c8 e732a889ec964e4c8b43993e8f6186c8--edd62ac7ebef4d49b3f3761536270580 bce805dd53604c4d9899b612612df22e e732a889ec964e4c8b43993e8f6186c8--bce805dd53604c4d9899b612612df22e 79e01ab7149f43969f718d711d27fdc3 bce805dd53604c4d9899b612612df22e--79e01ab7149f43969f718d711d27fdc3 9cc1ab9ba8974b06af78a76b8d769803 79e01ab7149f43969f718d711d27fdc3--9cc1ab9ba8974b06af78a76b8d769803 3c500ae1cdee4f80b761d54a1d79768e X 9cc1ab9ba8974b06af78a76b8d769803--3c500ae1cdee4f80b761d54a1d79768e 3c500ae1cdee4f80b761d54a1d79768e--d4842cc0471b4bcaa2aa5e75028ce9ae b04afdd3b0914b18a810c8d7b4da384d 3c500ae1cdee4f80b761d54a1d79768e--b04afdd3b0914b18a810c8d7b4da384d 6c0f3813ad534c91adaf88ec7f62ce0f b04afdd3b0914b18a810c8d7b4da384d--6c0f3813ad534c91adaf88ec7f62ce0f 66dca8d710f24d9096c4ea1fc068c421 6c0f3813ad534c91adaf88ec7f62ce0f--66dca8d710f24d9096c4ea1fc068c421 eb533bacb3bd412c8aac95d6563779dd 66dca8d710f24d9096c4ea1fc068c421--eb533bacb3bd412c8aac95d6563779dd 817f34f9d4294ff78d0d4335e18d254b eb533bacb3bd412c8aac95d6563779dd--817f34f9d4294ff78d0d4335e18d254b 93de946352fa4e60bbe426c860775d12 817f34f9d4294ff78d0d4335e18d254b--93de946352fa4e60bbe426c860775d12 c53c1580ff144164bfb5fd3b9cb26b0c 93de946352fa4e60bbe426c860775d12--c53c1580ff144164bfb5fd3b9cb26b0c e93bbfe7002c4d228cfdfb9c99468019 c53c1580ff144164bfb5fd3b9cb26b0c--e93bbfe7002c4d228cfdfb9c99468019 bf0516f7ea9847808d5f74e6fbb30248 e93bbfe7002c4d228cfdfb9c99468019--bf0516f7ea9847808d5f74e6fbb30248 97a47a90f6544130b71e9d2e98fafb0a bf0516f7ea9847808d5f74e6fbb30248--97a47a90f6544130b71e9d2e98fafb0a 197f92000390433584f806de336cec25 97a47a90f6544130b71e9d2e98fafb0a--197f92000390433584f806de336cec25 13d88c49c370401586e121e44709ce21 197f92000390433584f806de336cec25--13d88c49c370401586e121e44709ce21 3a4726ea80dc45cf9867b87bdb435a99 13d88c49c370401586e121e44709ce21--3a4726ea80dc45cf9867b87bdb435a99 7fc6bc4e28a848fc96759e0486d7bf4c 3a4726ea80dc45cf9867b87bdb435a99--7fc6bc4e28a848fc96759e0486d7bf4c 04b67d03c42c41f884c808070d26a9dd 7fc6bc4e28a848fc96759e0486d7bf4c--04b67d03c42c41f884c808070d26a9dd 41ee7159b65e4518af3b2e0d8441529a 04b67d03c42c41f884c808070d26a9dd--41ee7159b65e4518af3b2e0d8441529a d6c3da189e1c4a209cc0aa5af2d54957 41ee7159b65e4518af3b2e0d8441529a--d6c3da189e1c4a209cc0aa5af2d54957 105c46155a1a45aa8109f828941735ec d6c3da189e1c4a209cc0aa5af2d54957--105c46155a1a45aa8109f828941735ec 93029cf20d7648789df87596b3d9ddb4 X 105c46155a1a45aa8109f828941735ec--93029cf20d7648789df87596b3d9ddb4 93029cf20d7648789df87596b3d9ddb4--b02406014b574959887df0ed7d6d492b 000dc0f6a36b49b49cbeb0533fffd760 RZ(-1.0*g1) 93029cf20d7648789df87596b3d9ddb4--000dc0f6a36b49b49cbeb0533fffd760 7a99b2419f9d4b0091584bff92ec3635 X 000dc0f6a36b49b49cbeb0533fffd760--7a99b2419f9d4b0091584bff92ec3635 7a99b2419f9d4b0091584bff92ec3635--1679e98c1a404b309fbcc85644fafeae eafb9386c4644878ab959b74acb74b66 7a99b2419f9d4b0091584bff92ec3635--eafb9386c4644878ab959b74acb74b66 67e1cba0a1f944d18bcb386bb39cca3b eafb9386c4644878ab959b74acb74b66--67e1cba0a1f944d18bcb386bb39cca3b f29aa7200b8545889c299b29df504516 67e1cba0a1f944d18bcb386bb39cca3b--f29aa7200b8545889c299b29df504516 22a9d0effd90479db3fda2c07ac16c31 f29aa7200b8545889c299b29df504516--22a9d0effd90479db3fda2c07ac16c31 31f1194871f4402ab71ab770c90d8f8b 22a9d0effd90479db3fda2c07ac16c31--31f1194871f4402ab71ab770c90d8f8b c563006a712e4354bb49cf866563d2f1 31f1194871f4402ab71ab770c90d8f8b--c563006a712e4354bb49cf866563d2f1 4a94f032b35049f9bb10bb1ece8c25f4 c563006a712e4354bb49cf866563d2f1--4a94f032b35049f9bb10bb1ece8c25f4 81b2aa03140841f5a85f859a6d6c61b9 4a94f032b35049f9bb10bb1ece8c25f4--81b2aa03140841f5a85f859a6d6c61b9 8b8706935e1342879309ec76a2db3f02 X 81b2aa03140841f5a85f859a6d6c61b9--8b8706935e1342879309ec76a2db3f02 8b8706935e1342879309ec76a2db3f02--c308645ff1e04b1b8a621ca5a82ac75b 1a21f0e7f9b64744834f3622d9d3df69 8b8706935e1342879309ec76a2db3f02--1a21f0e7f9b64744834f3622d9d3df69 243696ed84e24122931437c673396956 1a21f0e7f9b64744834f3622d9d3df69--243696ed84e24122931437c673396956 005637093ddd4af3bb374ca9897c3b71 243696ed84e24122931437c673396956--005637093ddd4af3bb374ca9897c3b71 fa485094acd14f199a33a39359ad9a72 X 005637093ddd4af3bb374ca9897c3b71--fa485094acd14f199a33a39359ad9a72 fa485094acd14f199a33a39359ad9a72--bd60b166d0cb4897bbdac2556237db28 7f5fe3b81f1f4419ba0e62025ff27adc fa485094acd14f199a33a39359ad9a72--7f5fe3b81f1f4419ba0e62025ff27adc 13120452847e40bf8399548f33c08533 7f5fe3b81f1f4419ba0e62025ff27adc--13120452847e40bf8399548f33c08533 f65f024b114248fdb4942b42be5b3dce 13120452847e40bf8399548f33c08533--f65f024b114248fdb4942b42be5b3dce 3c8a312fec72439b99d6a612c3e68b21 f65f024b114248fdb4942b42be5b3dce--3c8a312fec72439b99d6a612c3e68b21 1f2c2b45bda44af2a45a30ef378574e7 3c8a312fec72439b99d6a612c3e68b21--1f2c2b45bda44af2a45a30ef378574e7 b76af4f5af044c11b792b0874e6f9fec 1f2c2b45bda44af2a45a30ef378574e7--b76af4f5af044c11b792b0874e6f9fec 11d17582c2c14f31814535221ff0171f b76af4f5af044c11b792b0874e6f9fec--11d17582c2c14f31814535221ff0171f 2fd8c578523246a286d4dd6245dda61f 11d17582c2c14f31814535221ff0171f--2fd8c578523246a286d4dd6245dda61f c8e605eefe2c43ab94de03ea44bb1678 2fd8c578523246a286d4dd6245dda61f--c8e605eefe2c43ab94de03ea44bb1678 2bbe3425e0d94263b125744bb4672fd4 c8e605eefe2c43ab94de03ea44bb1678--2bbe3425e0d94263b125744bb4672fd4 14a3c4b4060b470683e2ed9a97681c50 2bbe3425e0d94263b125744bb4672fd4--14a3c4b4060b470683e2ed9a97681c50 a88487a0c9604e158afd284461fc6185 14a3c4b4060b470683e2ed9a97681c50--a88487a0c9604e158afd284461fc6185 e1b8096d8a4a492fa0a49e8044f3e762 a88487a0c9604e158afd284461fc6185--e1b8096d8a4a492fa0a49e8044f3e762 55727f218d224030b6214549620b599a e1b8096d8a4a492fa0a49e8044f3e762--55727f218d224030b6214549620b599a d503d94eecec417c8d9d6a982f5252fa 55727f218d224030b6214549620b599a--d503d94eecec417c8d9d6a982f5252fa 18c1169f4a744d7998858aea49846cc4 d503d94eecec417c8d9d6a982f5252fa--18c1169f4a744d7998858aea49846cc4 f54b6e0f4c56401c9c7f0fa5790c5fe9 18c1169f4a744d7998858aea49846cc4--f54b6e0f4c56401c9c7f0fa5790c5fe9 21ac04f6b4bf438cbb723580aea82ba2 f54b6e0f4c56401c9c7f0fa5790c5fe9--21ac04f6b4bf438cbb723580aea82ba2 ff190ef6735b44e998c1dd632ee1d063 21ac04f6b4bf438cbb723580aea82ba2--ff190ef6735b44e998c1dd632ee1d063 da868ff2a93543108ad56773935ab4ed X ff190ef6735b44e998c1dd632ee1d063--da868ff2a93543108ad56773935ab4ed da868ff2a93543108ad56773935ab4ed--10f01e735ed54c24b31f289e3bdd6fdb 6b0966747cce464c99cd004c2f57f4bf da868ff2a93543108ad56773935ab4ed--6b0966747cce464c99cd004c2f57f4bf c9d17a589f8149c0bb05acb38eb97d40 6b0966747cce464c99cd004c2f57f4bf--c9d17a589f8149c0bb05acb38eb97d40 d6a476b136de49c29c1af74e327a87ac c9d17a589f8149c0bb05acb38eb97d40--d6a476b136de49c29c1af74e327a87ac 677e49bb66af4c498509895736f9e43c X d6a476b136de49c29c1af74e327a87ac--677e49bb66af4c498509895736f9e43c 677e49bb66af4c498509895736f9e43c--dff8e83b03a84b9ab9df2bf3a022b823 55d72df03e16460a99736abae976b8e7 677e49bb66af4c498509895736f9e43c--55d72df03e16460a99736abae976b8e7 b0e9e1e873eb4f949a70439cf23f5987 55d72df03e16460a99736abae976b8e7--b0e9e1e873eb4f949a70439cf23f5987 f7b56e3bee904439818561d82335a677 b0e9e1e873eb4f949a70439cf23f5987--f7b56e3bee904439818561d82335a677 de76fe52b725447a91f40327d9130242 f7b56e3bee904439818561d82335a677--de76fe52b725447a91f40327d9130242 e1f734ca249f40278d1b2e14731087bc de76fe52b725447a91f40327d9130242--e1f734ca249f40278d1b2e14731087bc 523bbd54f8c849f899b861b06f575705 e1f734ca249f40278d1b2e14731087bc--523bbd54f8c849f899b861b06f575705 58d63b43b59548e298f6de9c83ee3ca2 523bbd54f8c849f899b861b06f575705--58d63b43b59548e298f6de9c83ee3ca2 7600f968550748f8a67036c8ab3406e5 58d63b43b59548e298f6de9c83ee3ca2--7600f968550748f8a67036c8ab3406e5 fa7cc08f99c64856b993f1efcdd08c4e X 7600f968550748f8a67036c8ab3406e5--fa7cc08f99c64856b993f1efcdd08c4e fa7cc08f99c64856b993f1efcdd08c4e--e0dc1510bdb246aa98a012b2137a241e 86d2694198124f24a7e46049ab1ea0d7 RZ(-1.0*g1) fa7cc08f99c64856b993f1efcdd08c4e--86d2694198124f24a7e46049ab1ea0d7 786a23bb197242f5b7f728182a8070da X 86d2694198124f24a7e46049ab1ea0d7--786a23bb197242f5b7f728182a8070da 786a23bb197242f5b7f728182a8070da--be11d5d685cb4e9da6f25b918c5e44c5 9052ab0c495b4714b304bc823c060660 786a23bb197242f5b7f728182a8070da--9052ab0c495b4714b304bc823c060660 e5c8eee39b7b44d6b8b57f79ea2082cf 9052ab0c495b4714b304bc823c060660--e5c8eee39b7b44d6b8b57f79ea2082cf 95112ed085264ef38345905c7522472e e5c8eee39b7b44d6b8b57f79ea2082cf--95112ed085264ef38345905c7522472e 9cc8b2c03e9d4c3ab87d2fcedf7dae6a 95112ed085264ef38345905c7522472e--9cc8b2c03e9d4c3ab87d2fcedf7dae6a 1fe07e120a464607828ab0f130fa7a92 X 9cc8b2c03e9d4c3ab87d2fcedf7dae6a--1fe07e120a464607828ab0f130fa7a92 1fe07e120a464607828ab0f130fa7a92--b8da04d0c1fc4d6489eeae1683eb124e b68c564137ae4408bf5df46b3cbff3df 1fe07e120a464607828ab0f130fa7a92--b68c564137ae4408bf5df46b3cbff3df db8eb7af6884431c92f846d3429902e0 b68c564137ae4408bf5df46b3cbff3df--db8eb7af6884431c92f846d3429902e0 1b46baf8e6844e4ab97c3abd340ce710 db8eb7af6884431c92f846d3429902e0--1b46baf8e6844e4ab97c3abd340ce710 fded482a3f24441d940f9ed5d1e540aa X 1b46baf8e6844e4ab97c3abd340ce710--fded482a3f24441d940f9ed5d1e540aa fded482a3f24441d940f9ed5d1e540aa--8cbb393a2b3f4e5e9c983157e1c3ba6d 6e1b5b2c31574e7782804f20436628c8 fded482a3f24441d940f9ed5d1e540aa--6e1b5b2c31574e7782804f20436628c8 34b9554924ad464fad611f0f2e586360 6e1b5b2c31574e7782804f20436628c8--34b9554924ad464fad611f0f2e586360 866291a07c2840bfac90bafcdb87beea 34b9554924ad464fad611f0f2e586360--866291a07c2840bfac90bafcdb87beea 546e4c127d0846cf9d69bf9e4550e0cb 866291a07c2840bfac90bafcdb87beea--546e4c127d0846cf9d69bf9e4550e0cb 29f060582939461e98ac7b53b66ec142 546e4c127d0846cf9d69bf9e4550e0cb--29f060582939461e98ac7b53b66ec142 e145c16866f744e19e6cc83cbd529b7b 29f060582939461e98ac7b53b66ec142--e145c16866f744e19e6cc83cbd529b7b 3526b3d320ca4b12bf916465574dc247 X e145c16866f744e19e6cc83cbd529b7b--3526b3d320ca4b12bf916465574dc247 3526b3d320ca4b12bf916465574dc247--983ad8c98f094e22afdef0e4fe5a05bd 0d64715208654d6e8011ec1543aed2e0 RZ(-1.0*g1) 3526b3d320ca4b12bf916465574dc247--0d64715208654d6e8011ec1543aed2e0 ab824f3bdb4f4ff698b6653d8ee7e416 X 0d64715208654d6e8011ec1543aed2e0--ab824f3bdb4f4ff698b6653d8ee7e416 ab824f3bdb4f4ff698b6653d8ee7e416--a393b2f6c81f4fa8b3db94aae24a3532 feeff4661e3e4976ac2868ce47011b9c ab824f3bdb4f4ff698b6653d8ee7e416--feeff4661e3e4976ac2868ce47011b9c 7df75c54639f4e0ba7751112def92490 X feeff4661e3e4976ac2868ce47011b9c--7df75c54639f4e0ba7751112def92490 7df75c54639f4e0ba7751112def92490--258d6727987843b6937f57a426d9c3f9 cc838ee6ffa04e3e875bd5dd45f9cb9f RZ(-1.0*g1) 7df75c54639f4e0ba7751112def92490--cc838ee6ffa04e3e875bd5dd45f9cb9f af65f0bcf63140f8ba6c81a021b5a916 X cc838ee6ffa04e3e875bd5dd45f9cb9f--af65f0bcf63140f8ba6c81a021b5a916 af65f0bcf63140f8ba6c81a021b5a916--9d8823d4157949cf907426e59dec8859 5b6adab542ac47f7884ecf3bba406532 X af65f0bcf63140f8ba6c81a021b5a916--5b6adab542ac47f7884ecf3bba406532 5b6adab542ac47f7884ecf3bba406532--2e0723e7e6774d349d697612a688e40a b1499de61914416f93a4e2e800c7755e 5b6adab542ac47f7884ecf3bba406532--b1499de61914416f93a4e2e800c7755e 7825e2d4e8404f9bae5ff736077a1fe3 b1499de61914416f93a4e2e800c7755e--7825e2d4e8404f9bae5ff736077a1fe3 8f63b669f2404e2aaa14e80da3f2ff5e 7825e2d4e8404f9bae5ff736077a1fe3--8f63b669f2404e2aaa14e80da3f2ff5e a5e0d7c203734843bccfbefdd0c03de1 X 8f63b669f2404e2aaa14e80da3f2ff5e--a5e0d7c203734843bccfbefdd0c03de1 a5e0d7c203734843bccfbefdd0c03de1--6d65ad0420a041e88f2ce7b9081d41c4 2c6e8306cfdd42b5a8e3e08d0584a532 RX(b16) a5e0d7c203734843bccfbefdd0c03de1--2c6e8306cfdd42b5a8e3e08d0584a532 2c6e8306cfdd42b5a8e3e08d0584a532--df4a114fc031437a89efa9b4110fcd41 9c2e3188c0f34d9687378d9c75f1dd72 5d974669bd7b4bd4ba0923febcb34520 b9925083604d45f6a07670404f2f0a36--5d974669bd7b4bd4ba0923febcb34520 ff017842620a450e994307c9e9020daa 5d974669bd7b4bd4ba0923febcb34520--ff017842620a450e994307c9e9020daa 8d0675423a2840f19a25f7cc40202a36 ff017842620a450e994307c9e9020daa--8d0675423a2840f19a25f7cc40202a36 823e375a404a4b4090513c4ac70dc097 8d0675423a2840f19a25f7cc40202a36--823e375a404a4b4090513c4ac70dc097 ba83a802c8814224828e9d69970048d2 823e375a404a4b4090513c4ac70dc097--ba83a802c8814224828e9d69970048d2 bb6ff4d0aad04a31926fda5af7d6a7c6 ba83a802c8814224828e9d69970048d2--bb6ff4d0aad04a31926fda5af7d6a7c6 b52bea31ea6c402e87cc625dcb347ee1 X bb6ff4d0aad04a31926fda5af7d6a7c6--b52bea31ea6c402e87cc625dcb347ee1 b52bea31ea6c402e87cc625dcb347ee1--948b9d2787ca4429ba52294946fd2339 6cc350e1744747a3a28cc70f4cfb3719 RZ(1.0*g0) b52bea31ea6c402e87cc625dcb347ee1--6cc350e1744747a3a28cc70f4cfb3719 70dfce51a54e44a9a434ffec02015eef X 6cc350e1744747a3a28cc70f4cfb3719--70dfce51a54e44a9a434ffec02015eef 70dfce51a54e44a9a434ffec02015eef--38f957f5fdb145bb96898c045ef3194b af9823e84c84488db2abcf370af0da92 70dfce51a54e44a9a434ffec02015eef--af9823e84c84488db2abcf370af0da92 89c4bf082ed44c4198fd8b3b6b69d0cf af9823e84c84488db2abcf370af0da92--89c4bf082ed44c4198fd8b3b6b69d0cf 9c65836b6de249d289b8477764bfc5fa 89c4bf082ed44c4198fd8b3b6b69d0cf--9c65836b6de249d289b8477764bfc5fa 53f58646fa7040e188982a3d812db14c 9c65836b6de249d289b8477764bfc5fa--53f58646fa7040e188982a3d812db14c 0eca8a6089d347a98a825b26c71a2c94 53f58646fa7040e188982a3d812db14c--0eca8a6089d347a98a825b26c71a2c94 f0ab854592a944acae7ebe83d0dd8f90 0eca8a6089d347a98a825b26c71a2c94--f0ab854592a944acae7ebe83d0dd8f90 0d4e054d5e5845898818e802067c1754 f0ab854592a944acae7ebe83d0dd8f90--0d4e054d5e5845898818e802067c1754 231374a331924cd7831e9d1d8da55740 0d4e054d5e5845898818e802067c1754--231374a331924cd7831e9d1d8da55740 7919fc03497c40e7a6ae42c732fb9909 231374a331924cd7831e9d1d8da55740--7919fc03497c40e7a6ae42c732fb9909 d785ef14359f4e1b9e571d354e514a5a 7919fc03497c40e7a6ae42c732fb9909--d785ef14359f4e1b9e571d354e514a5a 3ca7134ae23b47e9ad5a73e16656a343 d785ef14359f4e1b9e571d354e514a5a--3ca7134ae23b47e9ad5a73e16656a343 68af4840293f4438805613541ce61d8d 3ca7134ae23b47e9ad5a73e16656a343--68af4840293f4438805613541ce61d8d fd724cb1eb8e454799bccd6304bfd1e6 68af4840293f4438805613541ce61d8d--fd724cb1eb8e454799bccd6304bfd1e6 9e97bbc7ad464ac284dbc8a5bdd9f18e fd724cb1eb8e454799bccd6304bfd1e6--9e97bbc7ad464ac284dbc8a5bdd9f18e 94296a90ca5f4774b740d8a230256859 9e97bbc7ad464ac284dbc8a5bdd9f18e--94296a90ca5f4774b740d8a230256859 b254fb3a604c49928e60b3bab641d186 94296a90ca5f4774b740d8a230256859--b254fb3a604c49928e60b3bab641d186 d02f660b9c7d44ef8610ecac16606a00 b254fb3a604c49928e60b3bab641d186--d02f660b9c7d44ef8610ecac16606a00 989ccd7b5e9c4b0bbd7796be60a107be d02f660b9c7d44ef8610ecac16606a00--989ccd7b5e9c4b0bbd7796be60a107be 83ab16473bbb4e3c86da395c91481d52 989ccd7b5e9c4b0bbd7796be60a107be--83ab16473bbb4e3c86da395c91481d52 710e3406798c467fb67f6260d6b69877 83ab16473bbb4e3c86da395c91481d52--710e3406798c467fb67f6260d6b69877 56be22ad16304ec293dd1841a37a63aa 710e3406798c467fb67f6260d6b69877--56be22ad16304ec293dd1841a37a63aa 414f60e9d9a34527af79e34d5ef4a0c0 56be22ad16304ec293dd1841a37a63aa--414f60e9d9a34527af79e34d5ef4a0c0 50e016252c8e4b4aa810ba9a5867ac8a 414f60e9d9a34527af79e34d5ef4a0c0--50e016252c8e4b4aa810ba9a5867ac8a cafeee4e231b4e20bfb102b4e6346dcc 50e016252c8e4b4aa810ba9a5867ac8a--cafeee4e231b4e20bfb102b4e6346dcc ac60d68410894819817dee56d65f875f cafeee4e231b4e20bfb102b4e6346dcc--ac60d68410894819817dee56d65f875f 75c49ffe7c754ed5948756e2086ec262 ac60d68410894819817dee56d65f875f--75c49ffe7c754ed5948756e2086ec262 72b43a4ae97e4d1cadee54a05f734c88 75c49ffe7c754ed5948756e2086ec262--72b43a4ae97e4d1cadee54a05f734c88 d01025e9840c43b7b115c6960f3f82c6 72b43a4ae97e4d1cadee54a05f734c88--d01025e9840c43b7b115c6960f3f82c6 08b4987da20d4fbb9ace6f588d07a834 d01025e9840c43b7b115c6960f3f82c6--08b4987da20d4fbb9ace6f588d07a834 02131592f60d4dfab604ac6d92404aa6 X 08b4987da20d4fbb9ace6f588d07a834--02131592f60d4dfab604ac6d92404aa6 02131592f60d4dfab604ac6d92404aa6--3a0e3948b72745168bf9dfd33b9d8ae2 6714cc51706f4cbba9fab26994f24801 RZ(-1.0*g0) 02131592f60d4dfab604ac6d92404aa6--6714cc51706f4cbba9fab26994f24801 f5dfb0a5b50344b4a4cb8ae1841b125d X 6714cc51706f4cbba9fab26994f24801--f5dfb0a5b50344b4a4cb8ae1841b125d f5dfb0a5b50344b4a4cb8ae1841b125d--ddbaed0493ce4583b104e880b25c4f8d 5b330b9331f0438fb0476da6e99ddce1 f5dfb0a5b50344b4a4cb8ae1841b125d--5b330b9331f0438fb0476da6e99ddce1 5330f4b76f414eda8b6b1cc25b7d4bfe 5b330b9331f0438fb0476da6e99ddce1--5330f4b76f414eda8b6b1cc25b7d4bfe 7fd40755215c47c690a35ddfa1d3dbba 5330f4b76f414eda8b6b1cc25b7d4bfe--7fd40755215c47c690a35ddfa1d3dbba 04a2110d33fe4967aff6d1903ac62c18 7fd40755215c47c690a35ddfa1d3dbba--04a2110d33fe4967aff6d1903ac62c18 2c6b54d2a416485e82497b651ef84851 04a2110d33fe4967aff6d1903ac62c18--2c6b54d2a416485e82497b651ef84851 b6421a2e1e6846829a81256332bc729c 2c6b54d2a416485e82497b651ef84851--b6421a2e1e6846829a81256332bc729c 9c6515c9f5704479a3417651fbe59417 b6421a2e1e6846829a81256332bc729c--9c6515c9f5704479a3417651fbe59417 5bd697a4c9d44dd4ab450280177534ec 9c6515c9f5704479a3417651fbe59417--5bd697a4c9d44dd4ab450280177534ec 47285bd93e2d4c4fa71c12735ab3dbe3 5bd697a4c9d44dd4ab450280177534ec--47285bd93e2d4c4fa71c12735ab3dbe3 5c95c1ff968d42e8b98e8eb289f20963 47285bd93e2d4c4fa71c12735ab3dbe3--5c95c1ff968d42e8b98e8eb289f20963 cf33701ef8154c99b978b3a5a0b87500 5c95c1ff968d42e8b98e8eb289f20963--cf33701ef8154c99b978b3a5a0b87500 e94b837a79174d5a8f3181c63c6d9e52 cf33701ef8154c99b978b3a5a0b87500--e94b837a79174d5a8f3181c63c6d9e52 1cb0ea5ad59a497089cc03341bb28dd5 e94b837a79174d5a8f3181c63c6d9e52--1cb0ea5ad59a497089cc03341bb28dd5 5be0be4a681a4ba0a4216d05fc5875b7 1cb0ea5ad59a497089cc03341bb28dd5--5be0be4a681a4ba0a4216d05fc5875b7 0be5050b2b91489fa839db352bba08b5 5be0be4a681a4ba0a4216d05fc5875b7--0be5050b2b91489fa839db352bba08b5 daccf5a5db734e17990e7a1b1e0d5bce 0be5050b2b91489fa839db352bba08b5--daccf5a5db734e17990e7a1b1e0d5bce d5dfab1ac7f347ed938dd1347d08fc1a daccf5a5db734e17990e7a1b1e0d5bce--d5dfab1ac7f347ed938dd1347d08fc1a 9f071c79b3d04156b8a1f4097480c28a d5dfab1ac7f347ed938dd1347d08fc1a--9f071c79b3d04156b8a1f4097480c28a a1854d9679f8451aace21b5100c8176c 9f071c79b3d04156b8a1f4097480c28a--a1854d9679f8451aace21b5100c8176c e56a53a785a34e5c9f28408c5f6deced a1854d9679f8451aace21b5100c8176c--e56a53a785a34e5c9f28408c5f6deced 2ae3ef4df83e4c09b021bdb902670ea5 e56a53a785a34e5c9f28408c5f6deced--2ae3ef4df83e4c09b021bdb902670ea5 4d89aacb6d7f454a9010585e3611130f 2ae3ef4df83e4c09b021bdb902670ea5--4d89aacb6d7f454a9010585e3611130f 0b311d0180c5445884af217af329a1d3 4d89aacb6d7f454a9010585e3611130f--0b311d0180c5445884af217af329a1d3 0abaa65b345b49168ea0287b42ce7617 0b311d0180c5445884af217af329a1d3--0abaa65b345b49168ea0287b42ce7617 834fe37153224f88bf7b5d96eadcff62 0abaa65b345b49168ea0287b42ce7617--834fe37153224f88bf7b5d96eadcff62 1a02823ec83d4936bd307c5735583470 834fe37153224f88bf7b5d96eadcff62--1a02823ec83d4936bd307c5735583470 11fd74430d814da19089f1f20b792617 1a02823ec83d4936bd307c5735583470--11fd74430d814da19089f1f20b792617 224bc44d102c48e786544e4433a42bf7 11fd74430d814da19089f1f20b792617--224bc44d102c48e786544e4433a42bf7 d5ac3cc6c36b45ebb9c4a64bce0f83ab 224bc44d102c48e786544e4433a42bf7--d5ac3cc6c36b45ebb9c4a64bce0f83ab c58808a3046f4b8e89ff74121bcb6237 d5ac3cc6c36b45ebb9c4a64bce0f83ab--c58808a3046f4b8e89ff74121bcb6237 a7607c47d58d40f6a62095b67895c2b6 c58808a3046f4b8e89ff74121bcb6237--a7607c47d58d40f6a62095b67895c2b6 a5d1f1f0954b4e148c5842b4a9400287 X a7607c47d58d40f6a62095b67895c2b6--a5d1f1f0954b4e148c5842b4a9400287 a5d1f1f0954b4e148c5842b4a9400287--3675daa959d440119bf056acc1c734c1 21c07c11cebb47fda3dcf2acc59699f7 RZ(-1.0*g0) a5d1f1f0954b4e148c5842b4a9400287--21c07c11cebb47fda3dcf2acc59699f7 723bd21968d94a41aba6d7f7457c001f X 21c07c11cebb47fda3dcf2acc59699f7--723bd21968d94a41aba6d7f7457c001f 723bd21968d94a41aba6d7f7457c001f--bb4a9be803f8490490d48eb5b2c66998 ffd5fd38acc54076a4b65e0e90ff6d63 723bd21968d94a41aba6d7f7457c001f--ffd5fd38acc54076a4b65e0e90ff6d63 45cfb4d88b53469f8a5914ac89c8bf48 ffd5fd38acc54076a4b65e0e90ff6d63--45cfb4d88b53469f8a5914ac89c8bf48 cdb20e6cf1f64d14987f854ff4fa6818 45cfb4d88b53469f8a5914ac89c8bf48--cdb20e6cf1f64d14987f854ff4fa6818 9d26e29cdfc048ad84aaead45bfee305 cdb20e6cf1f64d14987f854ff4fa6818--9d26e29cdfc048ad84aaead45bfee305 fd3971f5a47a4a988b9f8ae102bf0347 9d26e29cdfc048ad84aaead45bfee305--fd3971f5a47a4a988b9f8ae102bf0347 bc4441a42fd84507b937dd36490ee240 fd3971f5a47a4a988b9f8ae102bf0347--bc4441a42fd84507b937dd36490ee240 86c406225c244641a021c744c6559485 bc4441a42fd84507b937dd36490ee240--86c406225c244641a021c744c6559485 b2db93cbd4c44a80976434ef7f6d2842 86c406225c244641a021c744c6559485--b2db93cbd4c44a80976434ef7f6d2842 72438a0c125f4351892ee7cf154612b6 b2db93cbd4c44a80976434ef7f6d2842--72438a0c125f4351892ee7cf154612b6 bf8ddd15a840485288bc7ecb03f962aa 72438a0c125f4351892ee7cf154612b6--bf8ddd15a840485288bc7ecb03f962aa f17692793c2b4db9b4fb7d86ae2e7d35 bf8ddd15a840485288bc7ecb03f962aa--f17692793c2b4db9b4fb7d86ae2e7d35 cc956b99939841cb8c4734d619539e5a f17692793c2b4db9b4fb7d86ae2e7d35--cc956b99939841cb8c4734d619539e5a d2b43cdd498f4b14901420e325a464e1 cc956b99939841cb8c4734d619539e5a--d2b43cdd498f4b14901420e325a464e1 2511c52f355f45f0925384d054145823 d2b43cdd498f4b14901420e325a464e1--2511c52f355f45f0925384d054145823 395af96e006f4f4b991f5938a0983f07 2511c52f355f45f0925384d054145823--395af96e006f4f4b991f5938a0983f07 933ef85e05234d77ae37ff3f298bf864 395af96e006f4f4b991f5938a0983f07--933ef85e05234d77ae37ff3f298bf864 52c98cceb98e422ab0c24ef05527d98a 933ef85e05234d77ae37ff3f298bf864--52c98cceb98e422ab0c24ef05527d98a c96c128528eb49e8b02614e91e5b6ce0 52c98cceb98e422ab0c24ef05527d98a--c96c128528eb49e8b02614e91e5b6ce0 d998fab90d0e4418b6553ea1241e0e1c c96c128528eb49e8b02614e91e5b6ce0--d998fab90d0e4418b6553ea1241e0e1c 90918d5f25904e93a379adc73b465c9b d998fab90d0e4418b6553ea1241e0e1c--90918d5f25904e93a379adc73b465c9b faf799214db647cd931e62a2c39b7db9 90918d5f25904e93a379adc73b465c9b--faf799214db647cd931e62a2c39b7db9 4b62efa45de442aea9ae5d7a9e73de48 X faf799214db647cd931e62a2c39b7db9--4b62efa45de442aea9ae5d7a9e73de48 4b62efa45de442aea9ae5d7a9e73de48--53060cd761684bf5bd0d63c2bb5ab106 b4130377e7344450810b38e298330d8d RZ(-1.0*g0) 4b62efa45de442aea9ae5d7a9e73de48--b4130377e7344450810b38e298330d8d e316971d7994430587f1a2dc7e9860e9 X b4130377e7344450810b38e298330d8d--e316971d7994430587f1a2dc7e9860e9 e316971d7994430587f1a2dc7e9860e9--87c0bf5a37ec408e91b127d3ac6cb8c4 d5157050da534059a430debbf9be2e2c e316971d7994430587f1a2dc7e9860e9--d5157050da534059a430debbf9be2e2c 90355c3775754d9fb8227878caa77580 d5157050da534059a430debbf9be2e2c--90355c3775754d9fb8227878caa77580 bfa5e1773f1246279c844477156d8c57 90355c3775754d9fb8227878caa77580--bfa5e1773f1246279c844477156d8c57 eb1614b2e8634c85862316ea132ed0d8 bfa5e1773f1246279c844477156d8c57--eb1614b2e8634c85862316ea132ed0d8 890d3d0653fd4f6f9ffbdbad4a8b179d eb1614b2e8634c85862316ea132ed0d8--890d3d0653fd4f6f9ffbdbad4a8b179d 816a6500e9ea4865936bfeea948895e3 890d3d0653fd4f6f9ffbdbad4a8b179d--816a6500e9ea4865936bfeea948895e3 f60f41283a534c04a2593cd5e8c14c0e 816a6500e9ea4865936bfeea948895e3--f60f41283a534c04a2593cd5e8c14c0e 1f1db7090a404d21a00b432ff3a710bb f60f41283a534c04a2593cd5e8c14c0e--1f1db7090a404d21a00b432ff3a710bb b3d942fa3d4e4fce87ed06826a8d515d 1f1db7090a404d21a00b432ff3a710bb--b3d942fa3d4e4fce87ed06826a8d515d b55b053fcf1742b0a49e2a6e4e031094 b3d942fa3d4e4fce87ed06826a8d515d--b55b053fcf1742b0a49e2a6e4e031094 d78fe93b1c174caf812fddbea1a3aa58 b55b053fcf1742b0a49e2a6e4e031094--d78fe93b1c174caf812fddbea1a3aa58 2fbf07826e37438ca153d09d40193b4e d78fe93b1c174caf812fddbea1a3aa58--2fbf07826e37438ca153d09d40193b4e 89ab8e0537f245f290d5785d958f1215 2fbf07826e37438ca153d09d40193b4e--89ab8e0537f245f290d5785d958f1215 46c8afd3b3e340089fb1b69314a91cc8 89ab8e0537f245f290d5785d958f1215--46c8afd3b3e340089fb1b69314a91cc8 64c3a317a01b4092a5d2cd79c198839a 46c8afd3b3e340089fb1b69314a91cc8--64c3a317a01b4092a5d2cd79c198839a 98e4feb874aa413f813b699e3d716cbc 64c3a317a01b4092a5d2cd79c198839a--98e4feb874aa413f813b699e3d716cbc c7fec4d0189b4c0487027dac7b3ba657 98e4feb874aa413f813b699e3d716cbc--c7fec4d0189b4c0487027dac7b3ba657 232fb55ec56147d099c13fcb92b2268a X c7fec4d0189b4c0487027dac7b3ba657--232fb55ec56147d099c13fcb92b2268a 232fb55ec56147d099c13fcb92b2268a--c5dba96a713a4973b84eb95af4c1a8ac 0a8a948662274892a59aab20a4e752fe RZ(-1.0*g0) 232fb55ec56147d099c13fcb92b2268a--0a8a948662274892a59aab20a4e752fe 2028470a83b24a7fb1e0b33850e02af0 X 0a8a948662274892a59aab20a4e752fe--2028470a83b24a7fb1e0b33850e02af0 2028470a83b24a7fb1e0b33850e02af0--3dcab24c05714c49b127df8b94945f3e 16f1051aa4f24d4ab5f12de727fc242b 2028470a83b24a7fb1e0b33850e02af0--16f1051aa4f24d4ab5f12de727fc242b 08db4107eb454a938512c967009ecccc 16f1051aa4f24d4ab5f12de727fc242b--08db4107eb454a938512c967009ecccc 749ac6d541484caabf963c36f09d0f4d 08db4107eb454a938512c967009ecccc--749ac6d541484caabf963c36f09d0f4d 135d87e09d3f4acb9d91db21bf8e026b 749ac6d541484caabf963c36f09d0f4d--135d87e09d3f4acb9d91db21bf8e026b 5a169d0f1dbf482db7c61f8aab8bac52 135d87e09d3f4acb9d91db21bf8e026b--5a169d0f1dbf482db7c61f8aab8bac52 9981fbffe52e4d9e987068ad7dfa8dca 5a169d0f1dbf482db7c61f8aab8bac52--9981fbffe52e4d9e987068ad7dfa8dca 8757fcf5778d4d688540e85a1d2d852d 9981fbffe52e4d9e987068ad7dfa8dca--8757fcf5778d4d688540e85a1d2d852d 49989502cf37493fa9aacae2d227c00b 8757fcf5778d4d688540e85a1d2d852d--49989502cf37493fa9aacae2d227c00b f81eb9fd91fb41ea8e0be7eb1f93d892 49989502cf37493fa9aacae2d227c00b--f81eb9fd91fb41ea8e0be7eb1f93d892 1984ce5dbf0848a5b9961361f50e8a83 f81eb9fd91fb41ea8e0be7eb1f93d892--1984ce5dbf0848a5b9961361f50e8a83 814aa5f4ba194fb2a5ef7633679822dd 1984ce5dbf0848a5b9961361f50e8a83--814aa5f4ba194fb2a5ef7633679822dd 299d0b0ff2f140da98fa64b1ddb6d961 814aa5f4ba194fb2a5ef7633679822dd--299d0b0ff2f140da98fa64b1ddb6d961 9da7d4c87c8b4d198c284fc67964d156 299d0b0ff2f140da98fa64b1ddb6d961--9da7d4c87c8b4d198c284fc67964d156 91123587f4c84049b11599757148a39e 9da7d4c87c8b4d198c284fc67964d156--91123587f4c84049b11599757148a39e 783951216a34429e8b4fba888c4e2905 91123587f4c84049b11599757148a39e--783951216a34429e8b4fba888c4e2905 60c50a07e34a4704a042e734bf65d504 X 783951216a34429e8b4fba888c4e2905--60c50a07e34a4704a042e734bf65d504 60c50a07e34a4704a042e734bf65d504--4fb2e9f949a24ab0a092d92ec2b979ea c8f5557f3259442699fa3e7546599450 RZ(-1.0*g0) 60c50a07e34a4704a042e734bf65d504--c8f5557f3259442699fa3e7546599450 b51968290e9a4701905ffff2fe8e7887 X c8f5557f3259442699fa3e7546599450--b51968290e9a4701905ffff2fe8e7887 b51968290e9a4701905ffff2fe8e7887--cdc6b0ded425456fad6c202acde0d067 e0710237ecfa46e1b7fbd7741ae2a555 b51968290e9a4701905ffff2fe8e7887--e0710237ecfa46e1b7fbd7741ae2a555 dabba817c1ca46a68ba5d6ac7b6da0e8 RX(b07) e0710237ecfa46e1b7fbd7741ae2a555--dabba817c1ca46a68ba5d6ac7b6da0e8 eeb8157f7783430885e2bda53f7da7fa dabba817c1ca46a68ba5d6ac7b6da0e8--eeb8157f7783430885e2bda53f7da7fa 05547f0689de493f8f037a630f8406b4 eeb8157f7783430885e2bda53f7da7fa--05547f0689de493f8f037a630f8406b4 7316eb97ad1c4f2d9e291ec05189224c 05547f0689de493f8f037a630f8406b4--7316eb97ad1c4f2d9e291ec05189224c 34d36105988d4b05a9995ef5542fda3f 7316eb97ad1c4f2d9e291ec05189224c--34d36105988d4b05a9995ef5542fda3f c0a379b8d09740a2b306ac66122e8ce4 34d36105988d4b05a9995ef5542fda3f--c0a379b8d09740a2b306ac66122e8ce4 8da6ac74c1a74fa385ebb3c568d4f617 c0a379b8d09740a2b306ac66122e8ce4--8da6ac74c1a74fa385ebb3c568d4f617 c219c9dd828a4ae6bb75579b737efe37 X 8da6ac74c1a74fa385ebb3c568d4f617--c219c9dd828a4ae6bb75579b737efe37 c219c9dd828a4ae6bb75579b737efe37--e2a404aab0c5452baa94ce848414ec22 8629775fc1224a9e9e7d0e94c58638b4 RZ(1.0*g1) c219c9dd828a4ae6bb75579b737efe37--8629775fc1224a9e9e7d0e94c58638b4 9b452e334716428bbd5014333b041f08 X 8629775fc1224a9e9e7d0e94c58638b4--9b452e334716428bbd5014333b041f08 9b452e334716428bbd5014333b041f08--5c13f1c030734e09a812e0426eb57154 577a83a4585c4c368a50e8e0aab01731 9b452e334716428bbd5014333b041f08--577a83a4585c4c368a50e8e0aab01731 a7047c8b3ee24a57bd34c3f4eb0eb6e0 577a83a4585c4c368a50e8e0aab01731--a7047c8b3ee24a57bd34c3f4eb0eb6e0 8b861d4096814273abf19f7d370499ff a7047c8b3ee24a57bd34c3f4eb0eb6e0--8b861d4096814273abf19f7d370499ff a9aa044fb3504abca2bd5e7c6fa2569d 8b861d4096814273abf19f7d370499ff--a9aa044fb3504abca2bd5e7c6fa2569d eb574ac8cbfc46a4a28ffa6d285d0f7d a9aa044fb3504abca2bd5e7c6fa2569d--eb574ac8cbfc46a4a28ffa6d285d0f7d 14e69e31c23c4ce69ce6268a20bda704 eb574ac8cbfc46a4a28ffa6d285d0f7d--14e69e31c23c4ce69ce6268a20bda704 4bfaaaae1f3a4c36a8e7d3fdc77f37f9 14e69e31c23c4ce69ce6268a20bda704--4bfaaaae1f3a4c36a8e7d3fdc77f37f9 0bcf130b34a84cf28a919c233b5d753e 4bfaaaae1f3a4c36a8e7d3fdc77f37f9--0bcf130b34a84cf28a919c233b5d753e dfb3937e48e2478cbd4618fb30bfdd30 0bcf130b34a84cf28a919c233b5d753e--dfb3937e48e2478cbd4618fb30bfdd30 33b7dc054cec4e29aedfa3312ad9b7c7 dfb3937e48e2478cbd4618fb30bfdd30--33b7dc054cec4e29aedfa3312ad9b7c7 18c2a38d79604cd0b051275dfc3ff09e 33b7dc054cec4e29aedfa3312ad9b7c7--18c2a38d79604cd0b051275dfc3ff09e 80e349775a5f4cca99622aecbe865c40 18c2a38d79604cd0b051275dfc3ff09e--80e349775a5f4cca99622aecbe865c40 11ab9b85171e47cfb3cfd4c72b320ca5 80e349775a5f4cca99622aecbe865c40--11ab9b85171e47cfb3cfd4c72b320ca5 50803832a7f94d128c0a4c3c52409e61 11ab9b85171e47cfb3cfd4c72b320ca5--50803832a7f94d128c0a4c3c52409e61 4c6747d6ca1d4489aa5caee74ec3b84e 50803832a7f94d128c0a4c3c52409e61--4c6747d6ca1d4489aa5caee74ec3b84e cbea03b01cd2485a9896607884c57d1d 4c6747d6ca1d4489aa5caee74ec3b84e--cbea03b01cd2485a9896607884c57d1d 41dc9bfb2f204b6982fd078d5cf9620f cbea03b01cd2485a9896607884c57d1d--41dc9bfb2f204b6982fd078d5cf9620f 54d65a1dc14747cab357a62597bd2386 41dc9bfb2f204b6982fd078d5cf9620f--54d65a1dc14747cab357a62597bd2386 67b390ac7cd14bae9fd6a1b9b37fa514 54d65a1dc14747cab357a62597bd2386--67b390ac7cd14bae9fd6a1b9b37fa514 72b9babd99794e9dacc12e328e1e5f4a 67b390ac7cd14bae9fd6a1b9b37fa514--72b9babd99794e9dacc12e328e1e5f4a 3dd73e050e6c45c1858a587b14912e41 72b9babd99794e9dacc12e328e1e5f4a--3dd73e050e6c45c1858a587b14912e41 9fc97f0dfb9548b699e00ba596bc275f 3dd73e050e6c45c1858a587b14912e41--9fc97f0dfb9548b699e00ba596bc275f fbf021ae92e34875a2efb68480fa094b 9fc97f0dfb9548b699e00ba596bc275f--fbf021ae92e34875a2efb68480fa094b f28fe14100be47e597dae1739fedb5fa fbf021ae92e34875a2efb68480fa094b--f28fe14100be47e597dae1739fedb5fa 4db0fbd01d464770af85f507e234b5a6 f28fe14100be47e597dae1739fedb5fa--4db0fbd01d464770af85f507e234b5a6 5b698822ffed4a7e8c6c9ba3e5720c88 4db0fbd01d464770af85f507e234b5a6--5b698822ffed4a7e8c6c9ba3e5720c88 c938a93d12434ac387e8ded718c81f1c 5b698822ffed4a7e8c6c9ba3e5720c88--c938a93d12434ac387e8ded718c81f1c d546a7c76f0c45b1a89031691a5ffffb c938a93d12434ac387e8ded718c81f1c--d546a7c76f0c45b1a89031691a5ffffb 1f5faa3e632b407e82346565a068458b d546a7c76f0c45b1a89031691a5ffffb--1f5faa3e632b407e82346565a068458b 35ea1fe26c3649959bc9233f061a8981 X 1f5faa3e632b407e82346565a068458b--35ea1fe26c3649959bc9233f061a8981 35ea1fe26c3649959bc9233f061a8981--bce805dd53604c4d9899b612612df22e f0ed19c01717455eb6055dc33f193202 RZ(-1.0*g1) 35ea1fe26c3649959bc9233f061a8981--f0ed19c01717455eb6055dc33f193202 46bbca192a964c6a866f48f824582f55 X f0ed19c01717455eb6055dc33f193202--46bbca192a964c6a866f48f824582f55 46bbca192a964c6a866f48f824582f55--9cc1ab9ba8974b06af78a76b8d769803 a173560ee2414fd292a643d585add3af 46bbca192a964c6a866f48f824582f55--a173560ee2414fd292a643d585add3af 06249216de134a5884503174fc99f249 a173560ee2414fd292a643d585add3af--06249216de134a5884503174fc99f249 277a9833d6204039b55517524fabce0e 06249216de134a5884503174fc99f249--277a9833d6204039b55517524fabce0e 61af4a6677bc4141957544810bc15a57 277a9833d6204039b55517524fabce0e--61af4a6677bc4141957544810bc15a57 2ef0ffc42cb64352948a330de4e90d45 61af4a6677bc4141957544810bc15a57--2ef0ffc42cb64352948a330de4e90d45 9ffbc604b62847d38e498e42b10a9eee 2ef0ffc42cb64352948a330de4e90d45--9ffbc604b62847d38e498e42b10a9eee c5d957e6a8a34ce086a54ee4e07dbb30 9ffbc604b62847d38e498e42b10a9eee--c5d957e6a8a34ce086a54ee4e07dbb30 fb1dff4f8b464e4b9604da9846d97f7a c5d957e6a8a34ce086a54ee4e07dbb30--fb1dff4f8b464e4b9604da9846d97f7a b2f9c3b8fe314952b3045e6e2507228d fb1dff4f8b464e4b9604da9846d97f7a--b2f9c3b8fe314952b3045e6e2507228d 99faefc2162543e2bc1adb49de1e3263 b2f9c3b8fe314952b3045e6e2507228d--99faefc2162543e2bc1adb49de1e3263 bcc2b74408854070b658969dbcb73b57 99faefc2162543e2bc1adb49de1e3263--bcc2b74408854070b658969dbcb73b57 baaeb7cced274172a4a6a805d2f8674e bcc2b74408854070b658969dbcb73b57--baaeb7cced274172a4a6a805d2f8674e 0697e3bcc4694486b436971d961d46b3 baaeb7cced274172a4a6a805d2f8674e--0697e3bcc4694486b436971d961d46b3 dd2fc1dfda824833b6d3af07babf72ef 0697e3bcc4694486b436971d961d46b3--dd2fc1dfda824833b6d3af07babf72ef b62c50311bfa4516a0435b944cb189ab dd2fc1dfda824833b6d3af07babf72ef--b62c50311bfa4516a0435b944cb189ab 87482e8d012446039d2785f7e9d1f63a b62c50311bfa4516a0435b944cb189ab--87482e8d012446039d2785f7e9d1f63a 3b9862a1eb294bf09c219e546dcf3e40 87482e8d012446039d2785f7e9d1f63a--3b9862a1eb294bf09c219e546dcf3e40 d1f2041432184fab9c2ed03c9057d0a8 3b9862a1eb294bf09c219e546dcf3e40--d1f2041432184fab9c2ed03c9057d0a8 33f75da3bd5f4460b57076056e7aac65 d1f2041432184fab9c2ed03c9057d0a8--33f75da3bd5f4460b57076056e7aac65 c75ce438ff774bf989cb2c86e1a7c2a9 33f75da3bd5f4460b57076056e7aac65--c75ce438ff774bf989cb2c86e1a7c2a9 e69b26b53e3c456a8b0c82051fa1a505 c75ce438ff774bf989cb2c86e1a7c2a9--e69b26b53e3c456a8b0c82051fa1a505 55bd3243f70e46e8a586256670d979ad e69b26b53e3c456a8b0c82051fa1a505--55bd3243f70e46e8a586256670d979ad 5f9ce5626298434c87bea46dc8f6d491 55bd3243f70e46e8a586256670d979ad--5f9ce5626298434c87bea46dc8f6d491 0211373e819d486f8b620235bbdac7a8 5f9ce5626298434c87bea46dc8f6d491--0211373e819d486f8b620235bbdac7a8 e5a72eb2a81a4551843fe99c802a244b 0211373e819d486f8b620235bbdac7a8--e5a72eb2a81a4551843fe99c802a244b 19bf3d0a2d514caf99421f3b1d610ff5 e5a72eb2a81a4551843fe99c802a244b--19bf3d0a2d514caf99421f3b1d610ff5 10e479c9761941588d1fe3180521c19a 19bf3d0a2d514caf99421f3b1d610ff5--10e479c9761941588d1fe3180521c19a 0326a89270b744aaa6365febf6b33189 10e479c9761941588d1fe3180521c19a--0326a89270b744aaa6365febf6b33189 9fe681ef9b474c909bacccb50bfa1541 0326a89270b744aaa6365febf6b33189--9fe681ef9b474c909bacccb50bfa1541 0b6b8117cef34d6bbf6eb2487fe1fa7e 9fe681ef9b474c909bacccb50bfa1541--0b6b8117cef34d6bbf6eb2487fe1fa7e ef8f3331fbc54b3ba69460d81da91fcb 0b6b8117cef34d6bbf6eb2487fe1fa7e--ef8f3331fbc54b3ba69460d81da91fcb a3da422171524361be2d04a817f97a91 X ef8f3331fbc54b3ba69460d81da91fcb--a3da422171524361be2d04a817f97a91 a3da422171524361be2d04a817f97a91--1a21f0e7f9b64744834f3622d9d3df69 af833e9474a94472946d1905b5a06829 RZ(-1.0*g1) a3da422171524361be2d04a817f97a91--af833e9474a94472946d1905b5a06829 e08bbea201c44a7e961f9f569a4fc139 X af833e9474a94472946d1905b5a06829--e08bbea201c44a7e961f9f569a4fc139 e08bbea201c44a7e961f9f569a4fc139--005637093ddd4af3bb374ca9897c3b71 f6aed97147b44f01af51a24ec3a48c73 e08bbea201c44a7e961f9f569a4fc139--f6aed97147b44f01af51a24ec3a48c73 e470c7dc44b94927a391e64dc4264ca8 f6aed97147b44f01af51a24ec3a48c73--e470c7dc44b94927a391e64dc4264ca8 273d6e66111042a7af91159553011100 e470c7dc44b94927a391e64dc4264ca8--273d6e66111042a7af91159553011100 417314f0ef0e44b28ca4bdf0ed3bc7c0 273d6e66111042a7af91159553011100--417314f0ef0e44b28ca4bdf0ed3bc7c0 c59830c69d344534bb24a9f3a02e9bf5 417314f0ef0e44b28ca4bdf0ed3bc7c0--c59830c69d344534bb24a9f3a02e9bf5 6e07862a6b424279bf57a361cbbe0195 c59830c69d344534bb24a9f3a02e9bf5--6e07862a6b424279bf57a361cbbe0195 5fcdeb40ebe9460cbe303c720ddc5ad8 6e07862a6b424279bf57a361cbbe0195--5fcdeb40ebe9460cbe303c720ddc5ad8 c6796ef072934370a96fca835078ae45 5fcdeb40ebe9460cbe303c720ddc5ad8--c6796ef072934370a96fca835078ae45 7746859f20484dd2965bf1031273a65d c6796ef072934370a96fca835078ae45--7746859f20484dd2965bf1031273a65d 8a031a32a7d3443d83322cd98071f148 7746859f20484dd2965bf1031273a65d--8a031a32a7d3443d83322cd98071f148 ca22651579c34f04abacf533766bce1c 8a031a32a7d3443d83322cd98071f148--ca22651579c34f04abacf533766bce1c 7ebd3edacc2d4c0ea5aa9714332c4f03 ca22651579c34f04abacf533766bce1c--7ebd3edacc2d4c0ea5aa9714332c4f03 9b60e9444f3d4cad844bb76c57bf4bba 7ebd3edacc2d4c0ea5aa9714332c4f03--9b60e9444f3d4cad844bb76c57bf4bba 08d4c44de0684432870d0ee0fa2fc819 9b60e9444f3d4cad844bb76c57bf4bba--08d4c44de0684432870d0ee0fa2fc819 31ebce7c1a1e4a009424065d5fac9250 08d4c44de0684432870d0ee0fa2fc819--31ebce7c1a1e4a009424065d5fac9250 9e4e414f2cf749f0a1421b36509a23ec 31ebce7c1a1e4a009424065d5fac9250--9e4e414f2cf749f0a1421b36509a23ec 5b555247208842b7963f5f550fc2229f 9e4e414f2cf749f0a1421b36509a23ec--5b555247208842b7963f5f550fc2229f 293dd77054634113bf3a2826cd210aa1 5b555247208842b7963f5f550fc2229f--293dd77054634113bf3a2826cd210aa1 64024e835ece497dae5acb70dd5849a8 293dd77054634113bf3a2826cd210aa1--64024e835ece497dae5acb70dd5849a8 b9a2a5c52fdc41f4aee4274865962495 64024e835ece497dae5acb70dd5849a8--b9a2a5c52fdc41f4aee4274865962495 851a001f4e78425ca5c78372a2d2eb79 b9a2a5c52fdc41f4aee4274865962495--851a001f4e78425ca5c78372a2d2eb79 5da58cad51af4eaab5694acf5a3a0710 X 851a001f4e78425ca5c78372a2d2eb79--5da58cad51af4eaab5694acf5a3a0710 5da58cad51af4eaab5694acf5a3a0710--6b0966747cce464c99cd004c2f57f4bf 63185feaebe645d4906bc9df58fdfdd9 RZ(-1.0*g1) 5da58cad51af4eaab5694acf5a3a0710--63185feaebe645d4906bc9df58fdfdd9 c3834d8e2433402caec321ba673d8e7a X 63185feaebe645d4906bc9df58fdfdd9--c3834d8e2433402caec321ba673d8e7a c3834d8e2433402caec321ba673d8e7a--d6a476b136de49c29c1af74e327a87ac 47caac1858ed4b519d484e37dafb12f2 c3834d8e2433402caec321ba673d8e7a--47caac1858ed4b519d484e37dafb12f2 2369e15ebc4749ff97b5b24042b98a0b 47caac1858ed4b519d484e37dafb12f2--2369e15ebc4749ff97b5b24042b98a0b 53bbb25bf6a14bcc89eef9f901900a4a 2369e15ebc4749ff97b5b24042b98a0b--53bbb25bf6a14bcc89eef9f901900a4a e72126f64a2b49daa872dd02f9db40c5 53bbb25bf6a14bcc89eef9f901900a4a--e72126f64a2b49daa872dd02f9db40c5 e086b63351df4624aa1177e58e0a7878 e72126f64a2b49daa872dd02f9db40c5--e086b63351df4624aa1177e58e0a7878 cb222116f5e14f04835e22844269e3a3 e086b63351df4624aa1177e58e0a7878--cb222116f5e14f04835e22844269e3a3 f0d1b80fb48e44deb345a2437201149f cb222116f5e14f04835e22844269e3a3--f0d1b80fb48e44deb345a2437201149f 67ef9b9451134f749abbefd60584d4ca f0d1b80fb48e44deb345a2437201149f--67ef9b9451134f749abbefd60584d4ca 92d9660765e941b4b977112475d1cad2 67ef9b9451134f749abbefd60584d4ca--92d9660765e941b4b977112475d1cad2 b6d397db14d440e3a37ee49c2cb834db 92d9660765e941b4b977112475d1cad2--b6d397db14d440e3a37ee49c2cb834db 95cf54c8de76404098882ea2354deb48 b6d397db14d440e3a37ee49c2cb834db--95cf54c8de76404098882ea2354deb48 93888b68dd0d490a92601550cbdd02e5 95cf54c8de76404098882ea2354deb48--93888b68dd0d490a92601550cbdd02e5 02158d790b954b6f84fa466ab117e6bb 93888b68dd0d490a92601550cbdd02e5--02158d790b954b6f84fa466ab117e6bb da23f5790e2c443dbcebe7d5016af985 02158d790b954b6f84fa466ab117e6bb--da23f5790e2c443dbcebe7d5016af985 e19bec364448474caa81f1515014b42e da23f5790e2c443dbcebe7d5016af985--e19bec364448474caa81f1515014b42e 8c59680692aa4654acc97ac152bf7432 e19bec364448474caa81f1515014b42e--8c59680692aa4654acc97ac152bf7432 b49f5cf72c0341f683eef00cc3f9f02a 8c59680692aa4654acc97ac152bf7432--b49f5cf72c0341f683eef00cc3f9f02a 3e59fc304eda41089def316f9beae6bf X b49f5cf72c0341f683eef00cc3f9f02a--3e59fc304eda41089def316f9beae6bf 3e59fc304eda41089def316f9beae6bf--b68c564137ae4408bf5df46b3cbff3df 286882ba2fd648d394f2f6bb6ce5a322 RZ(-1.0*g1) 3e59fc304eda41089def316f9beae6bf--286882ba2fd648d394f2f6bb6ce5a322 2a1c3e961e6b4455ba2f72fb9901dee1 X 286882ba2fd648d394f2f6bb6ce5a322--2a1c3e961e6b4455ba2f72fb9901dee1 2a1c3e961e6b4455ba2f72fb9901dee1--1b46baf8e6844e4ab97c3abd340ce710 6cfcc7518a4448e3b274f1a42b0d8ff5 2a1c3e961e6b4455ba2f72fb9901dee1--6cfcc7518a4448e3b274f1a42b0d8ff5 6607d3d7206f4ed0ba37c4031861566a 6cfcc7518a4448e3b274f1a42b0d8ff5--6607d3d7206f4ed0ba37c4031861566a a52df36446154ab8bf2790831912e05f 6607d3d7206f4ed0ba37c4031861566a--a52df36446154ab8bf2790831912e05f 7edb3e5fbc304ff8b42dc9eaf09dc775 a52df36446154ab8bf2790831912e05f--7edb3e5fbc304ff8b42dc9eaf09dc775 0486e54df5a54d3d86562b74c098832d 7edb3e5fbc304ff8b42dc9eaf09dc775--0486e54df5a54d3d86562b74c098832d a60416fe9085494b820ed116cebc5a95 0486e54df5a54d3d86562b74c098832d--a60416fe9085494b820ed116cebc5a95 cca51d2556a44e7c88a441bf511e4a59 a60416fe9085494b820ed116cebc5a95--cca51d2556a44e7c88a441bf511e4a59 3e9bc3bf1049464e97fa3a34fbab228c cca51d2556a44e7c88a441bf511e4a59--3e9bc3bf1049464e97fa3a34fbab228c c8b5a4737d224cb982e065946f8f4f8e 3e9bc3bf1049464e97fa3a34fbab228c--c8b5a4737d224cb982e065946f8f4f8e 6703798f501a4dbd897ad1c05372d836 c8b5a4737d224cb982e065946f8f4f8e--6703798f501a4dbd897ad1c05372d836 f561b4039a9f438a8d70e0cfa5e83c25 6703798f501a4dbd897ad1c05372d836--f561b4039a9f438a8d70e0cfa5e83c25 fc1da5533b5b46a29bad90ba35ac204b f561b4039a9f438a8d70e0cfa5e83c25--fc1da5533b5b46a29bad90ba35ac204b fe83b2a5305f4fb6973d1dd70aed048b fc1da5533b5b46a29bad90ba35ac204b--fe83b2a5305f4fb6973d1dd70aed048b 661fea5a680c41dd919f5140c98479e6 fe83b2a5305f4fb6973d1dd70aed048b--661fea5a680c41dd919f5140c98479e6 9fb4f5550e6749269e4c26a2fabfdac5 661fea5a680c41dd919f5140c98479e6--9fb4f5550e6749269e4c26a2fabfdac5 53d8d3228f3f4533837f26753e0bad38 X 9fb4f5550e6749269e4c26a2fabfdac5--53d8d3228f3f4533837f26753e0bad38 53d8d3228f3f4533837f26753e0bad38--b1499de61914416f93a4e2e800c7755e 838040abce1c4553865529ed7af2c743 RZ(-1.0*g1) 53d8d3228f3f4533837f26753e0bad38--838040abce1c4553865529ed7af2c743 47d1f82475984b4e801b080c1897f22e X 838040abce1c4553865529ed7af2c743--47d1f82475984b4e801b080c1897f22e 47d1f82475984b4e801b080c1897f22e--8f63b669f2404e2aaa14e80da3f2ff5e 0349f5a9a6c9407787f78cfb2d7cf5c3 47d1f82475984b4e801b080c1897f22e--0349f5a9a6c9407787f78cfb2d7cf5c3 a36508d03862424f8ab1e376eb5e714e RX(b17) 0349f5a9a6c9407787f78cfb2d7cf5c3--a36508d03862424f8ab1e376eb5e714e a36508d03862424f8ab1e376eb5e714e--9c2e3188c0f34d9687378d9c75f1dd72"},{"location":"qml/qaoa/#train-the-qaoa-circuit-to-solve-maxcut","title":"Train the QAOA circuit to solve MaxCut","text":"<p>Given the QAOA circuit above, one can construct the associated Qadence <code>QuantumModel</code> and train it using standard gradient based optimization.</p> <p>The loss function to be minimized reads:</p> \\[\\mathcal{L} = \\sum_{i,j}^{N_{\\mathcal{E}}} \\frac{1}{2} \\left(1 - \\langle \\psi | \\sigma_i^z \\sigma_j^z | \\psi \\rangle \\right)\\] <p>where \\(\\psi(\\beta, \\gamma)\\) is the wavefunction obtained by propagating the QAQA quantum circuit and the sum runs over the edges of the graph \\(N_{\\mathcal{E}}\\).</p> <pre><code>import torch\nfrom qadence import QuantumModel\ntorch.manual_seed(seed)\ndef loss_function(_model: QuantumModel):\nexpval_ops = _model.expectation().squeeze()\n# this corresponds to the MaxCut cost by definition\n# with negative sign in front to perform maximization\nexpval = 0.0\nfor val in expval_ops:\nexpval += 0.5 * (1 - val)\nreturn -1.0 * expval\n# initialize the parameters to random values\nmodel = QuantumModel(circuit, observable=zz_ops)\nmodel.reset_vparams(torch.rand(model.num_vparams))\ninitial_loss = loss_function(model)\nprint(f\"Initial loss: {initial_loss}\")\n# train the model\nn_epochs = 100\nlr = 1.0\noptimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\nfor i in range(n_epochs):\noptimizer.zero_grad()\nloss = loss_function(model)\nloss.backward()\noptimizer.step()\nif (i+1) % (n_epochs // 10) == 0:\nprint(f\"MaxCut cost at iteration {i+1}: {-loss.item()}\")\n</code></pre> <pre><code>Initial loss: -4.681647700642611\nMaxCut cost at iteration 10: 10.518617010924668\nMaxCut cost at iteration 20: 11.578338474666992\nMaxCut cost at iteration 30: 11.99992485936314\nMaxCut cost at iteration 40: 11.999999449414494\nMaxCut cost at iteration 50: 11.99999995586088\nMaxCut cost at iteration 60: 11.999999995965586\nMaxCut cost at iteration 70: 11.999999999630278\nMaxCut cost at iteration 80: 11.999999999966121\nMaxCut cost at iteration 90: 11.999999999996888\nMaxCut cost at iteration 100: 11.999999999999709\n</code></pre> <p>Qadence offers some convenience functions to implement this training loop with advanced logging and metrics track features. You can refer to this for more details.</p>"},{"location":"qml/qaoa/#results","title":"Results","text":"<p>Given the trained quantum model, one needs to sample the resulting quantum state to recover the bitstring with the highest probability which corresponds to the maximum cut of the graph.</p> <pre><code>samples = model.sample(n_shots=100)[0]\nmost_frequent = max(samples, key=samples.get)\nprint(f\"Most frequently sampled bitstring corresponding to the maximum cut: {most_frequent}\")\n# let's now draw the cut obtained with the QAOA procedure\ncolors = []\nlabels = {}\nfor node, b in zip(graph.nodes(), most_frequent):\ncolors.append(\"green\") if int(b) == 0 else colors.append(\"red\")\nlabels[node] = \"A\" if int(b) == 0 else \"B\"\nnx.draw_networkx(graph, node_color=colors, with_labels=True, labels=labels)\n</code></pre>   Most frequently sampled bitstring corresponding to the maximum cut: 00101011  2023-10-12T16:59:46.689205 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"qml/qaoa/#references","title":"References","text":"<ol> <li> <p>Farhi et al. - A Quantum Approximate Optimization Algorithm\u00a0\u21a9</p> </li> </ol>"},{"location":"qml/qcl/","title":"Quantum circuit learning","text":"<p>This tutorial shows how to apply <code>qadence</code> for solving a basic quantum machine learning application: fitting a simple function with the quantum circuit learning<sup>1</sup> (QCL) algorithm.</p> <p>QCL is a supervised quantum machine learning algorithm that uses a parametrized quantum neural network to learn the behavior of an arbitrary mathematical function using a set of function values as training data. This tutorial shows how to fit the \\(\\sin(x)\\) function in the \\([-1, 1]\\) domain.</p> <p>In the following, train and test data are defined.</p> <pre><code>import torch\nfrom torch.utils.data import random_split\n# make sure all tensors are kept on the same device\n# only available from PyTorch 2.0\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.set_default_device(device)\ndef qcl_training_data(\ndomain: tuple = (0, 2*torch.pi), n_points: int = 200\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\nstart, end = domain\nx_rand, _ = torch.sort(torch.DoubleTensor(n_points).uniform_(start, end))\ny_rand = torch.sin(x_rand)\nreturn x_rand, y_rand\nx, y = qcl_training_data()\n# random train/test split of the dataset\ntrain_subset, test_subset = random_split(x, [0.75, 0.25])\ntrain_ind = sorted(train_subset.indices)\ntest_ind = sorted(test_subset.indices)\nx_train, y_train = x[train_ind], y[train_ind]\nx_test, y_test = x[test_ind], y[test_ind]\n</code></pre>"},{"location":"qml/qcl/#train-the-qcl-model","title":"Train the QCL model","text":"<p>Qadence provides the <code>QNN</code> convenience constructor to build a quantum neural network. The <code>QNN</code> class needs a circuit and a list of observables; the number of feature parameters in the input circuit determines the number of input features (i.e. the dimensionality of the classical data given as input) whereas the number of observables determines the number of outputs of the quantum neural network.</p> <p>Total qubit magnetization is used as observable:</p> \\[ \\hat{O} = \\sum_i^N \\hat{\\sigma}_i^z \\] <p>In the following the observable, quantum circuit and corresponding QNN model are constructed.</p> <pre><code>import qadence as qd\nn_qubits = 4\n# create a simple feature map to encode the input data\nfeature_param = qd.FeatureParameter(\"phi\")\nfeature_map = qd.kron(qd.RX(i, feature_param) for i in range(n_qubits))\nfeature_map = qd.tag(feature_map, \"feature_map\")\n# create a digital-analog variational ansatz using Qadence convenience constructors\nansatz = qd.hea(n_qubits, depth=n_qubits)\nansatz = qd.tag(ansatz, \"ansatz\")\n# total qubit magnetization observable\nobservable = qd.hamiltonian_factory(n_qubits, detuning=qd.Z)\ncircuit = qd.QuantumCircuit(n_qubits, feature_map, ansatz)\nmodel = qd.QNN(circuit, [observable])\nexpval = model(values=torch.rand(10))\n</code></pre> <pre><code>tensor([[0.2025],\n[0.1315],\n[0.2424],\n[0.1552],\n[0.1592],\n[0.2063],\n[0.1899],\n[0.2208],\n[0.2472],\n[0.1580]], grad_fn=&lt;CatBackward0&gt;)\n</code></pre> <p>The QCL algorithm uses the output of the quantum neural network as a tunable universal function approximator. Standard PyTorch code is used for training the QNN using a mean-square error loss, Adam optimizer. Training is performend on the GPU if available:</p> <pre><code>n_epochs = 100\nlr = 0.25\ninput_values = {\"phi\": x_train}\nmse_loss = torch.nn.MSELoss()  # standard PyTorch loss function\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)  # standard PyTorch Adam optimizer\nprint(f\"Initial loss: {mse_loss(model(values=x_train), y_train)}\")\ny_pred_initial = model(values=x_test)\nfor i in range(n_epochs):\noptimizer.zero_grad()\n# given a `n_batch` number of input points and a `n_observables`\n# number of input observables to measure, the QNN returns\n# an output of the following shape: [n_batch x n_observables]\n# given that there is only one observable, a squeeze is applied to get\n# a 1-dimensional tensor\nloss = mse_loss(model(values=x_train).squeeze(), y_train)\nloss.backward()\noptimizer.step()\nif (i+1) % 20 == 0:\nprint(f\"Epoch {i+1} - Loss: {loss.item()}\")\nassert loss.item() &lt; 1e-3\n</code></pre> <pre><code>Initial loss: 0.6533070454755132\nEpoch 20 - Loss: 0.006756732932883166\nEpoch 40 - Loss: 0.0013178262682413558\nEpoch 60 - Loss: 0.00024411275385784526\nEpoch 80 - Loss: 1.8109270091472735e-05\nEpoch 100 - Loss: 3.3443547512265775e-06\n</code></pre> <p>Qadence offers some convenience functions to implement this training loop with advanced logging and metrics track features. You can refer to this for more details.</p> <p>The quantum model is now trained on the training data points. To determine the quality of the results, one can check to see how well it fits the function on the test set.</p> <pre><code>import matplotlib.pyplot as plt\ny_pred = model({\"phi\": x_test})\n# convert all the results to numpy arrays for plotting\nx_train_np = x_train.cpu().detach().numpy().flatten()\ny_train_np = y_train.cpu().detach().numpy().flatten()\nx_test_np = x_test.cpu().detach().numpy().flatten()\ny_test_np = y_test.cpu().detach().numpy().flatten()\ny_pred_initial_np = y_pred_initial.cpu().detach().numpy().flatten()\ny_pred_np = y_pred.cpu().detach().numpy().flatten()\nfig, _ = plt.subplots()\nplt.scatter(x_test_np, y_test_np, label=\"Test points\", marker=\"o\", color=\"orange\")\nplt.plot(x_test_np, y_pred_initial_np, label=\"Initial prediction\", color=\"green\", alpha=0.5)\nplt.plot(x_test_np, y_pred_np, label=\"Final prediction\")\nplt.legend()\n</code></pre> 2023-10-12T16:59:48.923218 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"qml/qcl/#references","title":"References","text":"<ol> <li> <p>Mitarai et al., Quantum Circuit Learning \u21a9</p> </li> </ol>"},{"location":"qml/qml_tools/","title":"Tools for quantum machine learning","text":"<p>Qadence offers a wide range of utilities for helping building and researching quantum machine learning algorithms, including:</p> <ul> <li>a set of constructors for circuits commonly used in quantum machine learning</li> <li>a set of tools for optimizing quantum neural networks and loading classical data into a QML algorithm</li> </ul>"},{"location":"qml/qml_tools/#quantum-machine-learning-constructors","title":"Quantum machine learning constructors","text":"<p>Besides the arbitrary Hamiltonian constructors, Qadence also provides a complete set of program constructors useful for digital-analog quantum machine learning programs.</p>"},{"location":"qml/qml_tools/#feature-maps","title":"Feature maps","text":"<p>A few feature maps are directly available for loading classical data into quantum circuits by encoding them into gate rotation angles.</p> <pre><code>from qadence import feature_map\nn_qubits = 3\nfm = feature_map(n_qubits, fm_type=\"fourier\")\nfm = feature_map(n_qubits, fm_type=\"chebyshev\")\nfm = feature_map(n_qubits, fm_type=\"tower\")\n</code></pre> <pre><code>Fourier = KronBlock(0,1,2) [tag: FM]\n\u251c\u2500\u2500 RX(0) [params: ['phi']]\n\u251c\u2500\u2500 RX(1) [params: ['phi']]\n\u2514\u2500\u2500 RX(2) [params: ['phi']]\nChebyshev KronBlock(0,1,2) [tag: FM]\n\u251c\u2500\u2500 RX(0) [params: ['2*acos(phi)']]\n\u251c\u2500\u2500 RX(1) [params: ['2*acos(phi)']]\n\u2514\u2500\u2500 RX(2) [params: ['2*acos(phi)']]\nTower KronBlock(0,1,2) [tag: FM]\n\u251c\u2500\u2500 RX(0) [params: ['2*acos(phi)']]\n\u251c\u2500\u2500 RX(1) [params: ['4*acos(phi)']]\n\u2514\u2500\u2500 RX(2) [params: ['6*acos(phi)']]\n</code></pre>"},{"location":"qml/qml_tools/#hardware-efficient-ansatz","title":"Hardware-efficient ansatz","text":"<p>Ansatze blocks for quantum machine-learning are typically built following the Hardware-Efficient Ansatz formalism (HEA). Both fully digital and digital-analog HEAs can easily be built with the <code>hea</code> function. By default, the digital version is returned:</p> <pre><code>from qadence import hea\nfrom qadence.draw import display\nn_qubits = 3\ndepth = 2\nansatz = hea(n_qubits, depth)\n</code></pre> 77c022c6cca045e89efb412391e32633 0 fbe8d9894dda428481487f836d57a8e3 RX(theta\u2080) 77c022c6cca045e89efb412391e32633--fbe8d9894dda428481487f836d57a8e3 e8d2a5e8a4274398adaff5e527a288b5 1 f3f918d8fa514fd6aca89cfead554f5a RY(theta\u2083) fbe8d9894dda428481487f836d57a8e3--f3f918d8fa514fd6aca89cfead554f5a ce5a71ad34ea4fe2a82aad0ba0949ee5 RX(theta\u2086) f3f918d8fa514fd6aca89cfead554f5a--ce5a71ad34ea4fe2a82aad0ba0949ee5 02246cdb81d74b4495b669ad0ee87394 ce5a71ad34ea4fe2a82aad0ba0949ee5--02246cdb81d74b4495b669ad0ee87394 1b2b38b903584b11a43242f39f4abf89 02246cdb81d74b4495b669ad0ee87394--1b2b38b903584b11a43242f39f4abf89 992201da41fc4bfb94b77396452bf684 RX(theta\u2089) 1b2b38b903584b11a43242f39f4abf89--992201da41fc4bfb94b77396452bf684 52672517af314b0399d9e12f2d0fb409 RY(theta\u2081\u2082) 992201da41fc4bfb94b77396452bf684--52672517af314b0399d9e12f2d0fb409 04b099f1834f4e9cb22cab611bc2fc81 RX(theta\u2081\u2085) 52672517af314b0399d9e12f2d0fb409--04b099f1834f4e9cb22cab611bc2fc81 b63bfc46e77143f3bead5224e849d4e7 04b099f1834f4e9cb22cab611bc2fc81--b63bfc46e77143f3bead5224e849d4e7 e657b0ed88ad482684cfee16d4b3b066 b63bfc46e77143f3bead5224e849d4e7--e657b0ed88ad482684cfee16d4b3b066 ef0d70238bf8417b9a99b3fcd4de34c1 e657b0ed88ad482684cfee16d4b3b066--ef0d70238bf8417b9a99b3fcd4de34c1 5d50ac6392b74e4498048a1e93140de8 79177c1af93d4cf4bdf9b24890a64f07 RX(theta\u2081) e8d2a5e8a4274398adaff5e527a288b5--79177c1af93d4cf4bdf9b24890a64f07 02cbf9c1b97a43d6bd1945757a066517 2 5438e3f8910443da9f154c05175fa145 RY(theta\u2084) 79177c1af93d4cf4bdf9b24890a64f07--5438e3f8910443da9f154c05175fa145 d9500264785c450bbb3d2fefa191080a RX(theta\u2087) 5438e3f8910443da9f154c05175fa145--d9500264785c450bbb3d2fefa191080a d2bba31b44c34878841f22234237dba2 X d9500264785c450bbb3d2fefa191080a--d2bba31b44c34878841f22234237dba2 d2bba31b44c34878841f22234237dba2--02246cdb81d74b4495b669ad0ee87394 9d22145487c141f2aaa1ca3cdd2fa0e5 d2bba31b44c34878841f22234237dba2--9d22145487c141f2aaa1ca3cdd2fa0e5 ab0941d716814b068b1f735c74b00627 RX(theta\u2081\u2080) 9d22145487c141f2aaa1ca3cdd2fa0e5--ab0941d716814b068b1f735c74b00627 2f4b3d02a01b41df966ee968c7c70fb0 RY(theta\u2081\u2083) ab0941d716814b068b1f735c74b00627--2f4b3d02a01b41df966ee968c7c70fb0 a460474b488c4c0a9f25940679f4df20 RX(theta\u2081\u2086) 2f4b3d02a01b41df966ee968c7c70fb0--a460474b488c4c0a9f25940679f4df20 31cabed5f65c4a16aee58b6c4fd05fbf X a460474b488c4c0a9f25940679f4df20--31cabed5f65c4a16aee58b6c4fd05fbf 31cabed5f65c4a16aee58b6c4fd05fbf--b63bfc46e77143f3bead5224e849d4e7 ead998a3a6914c5599aa307ab6c16e8e 31cabed5f65c4a16aee58b6c4fd05fbf--ead998a3a6914c5599aa307ab6c16e8e ead998a3a6914c5599aa307ab6c16e8e--5d50ac6392b74e4498048a1e93140de8 963d17cf4459412f9a7d87ba28b8910d 8a0991e0a59f424d95bccbf40937ab13 RX(theta\u2082) 02cbf9c1b97a43d6bd1945757a066517--8a0991e0a59f424d95bccbf40937ab13 7b3e70ab1a754e56aeb64fae7427ada1 RY(theta\u2085) 8a0991e0a59f424d95bccbf40937ab13--7b3e70ab1a754e56aeb64fae7427ada1 1c516c92ad9f4e768ab0cd1ac4306b9c RX(theta\u2088) 7b3e70ab1a754e56aeb64fae7427ada1--1c516c92ad9f4e768ab0cd1ac4306b9c 70ab7d40c2ea42d887dbd02fa665d76c 1c516c92ad9f4e768ab0cd1ac4306b9c--70ab7d40c2ea42d887dbd02fa665d76c d2e4d57ebe424dbfa7804c5c405fe019 X 70ab7d40c2ea42d887dbd02fa665d76c--d2e4d57ebe424dbfa7804c5c405fe019 d2e4d57ebe424dbfa7804c5c405fe019--9d22145487c141f2aaa1ca3cdd2fa0e5 5be0e9a87eca40c0bb6b9d74058cdd03 RX(theta\u2081\u2081) d2e4d57ebe424dbfa7804c5c405fe019--5be0e9a87eca40c0bb6b9d74058cdd03 a44d6ebc2dcc478c89a9ac46dd85e83c RY(theta\u2081\u2084) 5be0e9a87eca40c0bb6b9d74058cdd03--a44d6ebc2dcc478c89a9ac46dd85e83c 973b846694f64befaf457dd38a35dfdd RX(theta\u2081\u2087) a44d6ebc2dcc478c89a9ac46dd85e83c--973b846694f64befaf457dd38a35dfdd 38b12c64eb9a4370ba1b87bb760e9784 973b846694f64befaf457dd38a35dfdd--38b12c64eb9a4370ba1b87bb760e9784 82e27103226b429baa491bdc6a3f8f71 X 38b12c64eb9a4370ba1b87bb760e9784--82e27103226b429baa491bdc6a3f8f71 82e27103226b429baa491bdc6a3f8f71--ead998a3a6914c5599aa307ab6c16e8e 82e27103226b429baa491bdc6a3f8f71--963d17cf4459412f9a7d87ba28b8910d <p>As seen above, the rotation layers are automatically parameterized, and the prefix <code>\"theta\"</code> can be changed with the <code>param_prefix</code> argument.</p> <p>Furthermore, both the single-qubit rotations and the two-qubit entangler can be customized with the <code>operations</code> and <code>entangler</code> argument. The operations can be passed as a list of single-qubit rotations, while the entangler should be either <code>CNOT</code>, <code>CZ</code>, <code>CRX</code>, <code>CRY</code>, <code>CRZ</code> or <code>CPHASE</code>.</p> <pre><code>from qadence import RX, RY, CPHASE\nansatz = hea(\nn_qubits=n_qubits,\ndepth=depth,\nparam_prefix=\"phi\",\noperations=[RX, RY, RX],\nentangler=CPHASE\n)\n</code></pre> ebb1a98fceef44b58867b39502e38334 0 c489a6f3b5004c5ca97646947fced9da RX(phi\u2080) ebb1a98fceef44b58867b39502e38334--c489a6f3b5004c5ca97646947fced9da 6e936ac98326437dbba9a041ec6e469f 1 6954c6462a474aceb6270d88e435fd00 RY(phi\u2083) c489a6f3b5004c5ca97646947fced9da--6954c6462a474aceb6270d88e435fd00 9958d1a79218429288560fbb02faf88f RX(phi\u2086) 6954c6462a474aceb6270d88e435fd00--9958d1a79218429288560fbb02faf88f bbf52663b5bb4282b24f9996b3aac7ab 9958d1a79218429288560fbb02faf88f--bbf52663b5bb4282b24f9996b3aac7ab 071d27d8bb6749f3a4aeaaf248aff401 bbf52663b5bb4282b24f9996b3aac7ab--071d27d8bb6749f3a4aeaaf248aff401 16d39ed82e3a4c9a9857ed991fa21ce5 RX(phi\u2089) 071d27d8bb6749f3a4aeaaf248aff401--16d39ed82e3a4c9a9857ed991fa21ce5 636b7910c3e648028c20af137a7812f4 RY(phi\u2081\u2082) 16d39ed82e3a4c9a9857ed991fa21ce5--636b7910c3e648028c20af137a7812f4 28e236dbaaa245e7abec6f284ed91ebf RX(phi\u2081\u2085) 636b7910c3e648028c20af137a7812f4--28e236dbaaa245e7abec6f284ed91ebf c227aa28867a4439b95c59be84d2d065 28e236dbaaa245e7abec6f284ed91ebf--c227aa28867a4439b95c59be84d2d065 cb980b9fd520495399f389fc8119da3d c227aa28867a4439b95c59be84d2d065--cb980b9fd520495399f389fc8119da3d 1cd6300f49914ba4a25949f974b4d30f cb980b9fd520495399f389fc8119da3d--1cd6300f49914ba4a25949f974b4d30f fd681b9945284e5eb4f0b3cd98581d0f 089145f7178f49ef9fdd26559f968789 RX(phi\u2081) 6e936ac98326437dbba9a041ec6e469f--089145f7178f49ef9fdd26559f968789 b107870afbbb49bca76b55ef1b17060f 2 fe9d0c1be6b8446f8d29a9a7485c52fb RY(phi\u2084) 089145f7178f49ef9fdd26559f968789--fe9d0c1be6b8446f8d29a9a7485c52fb acdaae8c514541baae04c6c72040e37c RX(phi\u2087) fe9d0c1be6b8446f8d29a9a7485c52fb--acdaae8c514541baae04c6c72040e37c dd0cfa9f75b84c74a64b2924114f6276 PHASE(phi_ent\u2080) acdaae8c514541baae04c6c72040e37c--dd0cfa9f75b84c74a64b2924114f6276 dd0cfa9f75b84c74a64b2924114f6276--bbf52663b5bb4282b24f9996b3aac7ab 59f636305c924df592715fc6781afd15 dd0cfa9f75b84c74a64b2924114f6276--59f636305c924df592715fc6781afd15 510ec103352e49f4b34c5a9927637178 RX(phi\u2081\u2080) 59f636305c924df592715fc6781afd15--510ec103352e49f4b34c5a9927637178 5f5acf5206d647f28130ee1bdd7b2d2d RY(phi\u2081\u2083) 510ec103352e49f4b34c5a9927637178--5f5acf5206d647f28130ee1bdd7b2d2d db567d5967b546f3be09bd5aba2e36c1 RX(phi\u2081\u2086) 5f5acf5206d647f28130ee1bdd7b2d2d--db567d5967b546f3be09bd5aba2e36c1 cb20519c49ce4e579931366c682be1fe PHASE(phi_ent\u2082) db567d5967b546f3be09bd5aba2e36c1--cb20519c49ce4e579931366c682be1fe cb20519c49ce4e579931366c682be1fe--c227aa28867a4439b95c59be84d2d065 763978c301ea4de2898d841839d0c17c cb20519c49ce4e579931366c682be1fe--763978c301ea4de2898d841839d0c17c 763978c301ea4de2898d841839d0c17c--fd681b9945284e5eb4f0b3cd98581d0f e3530b8ccb274c75a25e2c2eec98e636 e788e043d33842769adde9605c7d0754 RX(phi\u2082) b107870afbbb49bca76b55ef1b17060f--e788e043d33842769adde9605c7d0754 6179065384ba4cd3a3a3048c4db95eac RY(phi\u2085) e788e043d33842769adde9605c7d0754--6179065384ba4cd3a3a3048c4db95eac 929a8a81074143949ce6f5f84ce9ad02 RX(phi\u2088) 6179065384ba4cd3a3a3048c4db95eac--929a8a81074143949ce6f5f84ce9ad02 1fa8559abfd845e0a58d9ccc65f36148 929a8a81074143949ce6f5f84ce9ad02--1fa8559abfd845e0a58d9ccc65f36148 d4eb4c3c51fa456e9218d1bdc2774642 PHASE(phi_ent\u2081) 1fa8559abfd845e0a58d9ccc65f36148--d4eb4c3c51fa456e9218d1bdc2774642 d4eb4c3c51fa456e9218d1bdc2774642--59f636305c924df592715fc6781afd15 25467fbf2d954d0198436e8224475149 RX(phi\u2081\u2081) d4eb4c3c51fa456e9218d1bdc2774642--25467fbf2d954d0198436e8224475149 ffddbe4f7dc0477a9238cbc5b2cac61b RY(phi\u2081\u2084) 25467fbf2d954d0198436e8224475149--ffddbe4f7dc0477a9238cbc5b2cac61b 54fa1f5137ed4865a8a13152c3fd2cd9 RX(phi\u2081\u2087) ffddbe4f7dc0477a9238cbc5b2cac61b--54fa1f5137ed4865a8a13152c3fd2cd9 3cef26a559f341aa8890e81731f8ed32 54fa1f5137ed4865a8a13152c3fd2cd9--3cef26a559f341aa8890e81731f8ed32 895046eb77d24517a45134dcffef6944 PHASE(phi_ent\u2083) 3cef26a559f341aa8890e81731f8ed32--895046eb77d24517a45134dcffef6944 895046eb77d24517a45134dcffef6944--763978c301ea4de2898d841839d0c17c 895046eb77d24517a45134dcffef6944--e3530b8ccb274c75a25e2c2eec98e636 <p>Having a truly hardware-efficient ansatz means that the entangling operation can be chosen according to each device's native interactions. Besides digital operations, in Qadence it is also possible to build digital-analog HEAs with the entanglement produced by the natural evolution of a set of interacting qubits, as natively implemented in neutral atom devices. As with other digital-analog functions, this can be controlled with the <code>strategy</code> argument which can be chosen from the <code>Strategy</code> enum type. Currently, only <code>Strategy.DIGITAL</code> and <code>Strategy.SDAQC</code> are available. By default, calling <code>strategy = Strategy.SDAQC</code> will use a global entangling Hamiltonian with Ising-like NN interactions and constant interaction strength,</p> <pre><code>from qadence import Strategy\nansatz = hea(\nn_qubits,\ndepth=depth,\nstrategy=Strategy.SDAQC\n)\n</code></pre> cluster_9c932f5e6a15453b95eb0b7b7f3c2ceb cluster_4ce1ad0aea9744d488dd2097b669debe 7fc153eb9bce452194a9139fc763af4e 0 2533b151bd45412191da602caace34ce RX(theta\u2080) 7fc153eb9bce452194a9139fc763af4e--2533b151bd45412191da602caace34ce 41592c8d66de4b23a4e31cb71febfa50 1 5ab3d76f00954f029fca6e85f20f2bba RY(theta\u2083) 2533b151bd45412191da602caace34ce--5ab3d76f00954f029fca6e85f20f2bba c3bb80583b3746449a4f1b5cdc918347 RX(theta\u2086) 5ab3d76f00954f029fca6e85f20f2bba--c3bb80583b3746449a4f1b5cdc918347 c530142e9776459aa3266274243ef956 HamEvo c3bb80583b3746449a4f1b5cdc918347--c530142e9776459aa3266274243ef956 6ad844a3c616456e89023361efeba089 RX(theta\u2089) c530142e9776459aa3266274243ef956--6ad844a3c616456e89023361efeba089 fd50804ae29e459998f65d210dcdaef0 RY(theta\u2081\u2082) 6ad844a3c616456e89023361efeba089--fd50804ae29e459998f65d210dcdaef0 2b2d9fcacc694b65820bf466d58bd922 RX(theta\u2081\u2085) fd50804ae29e459998f65d210dcdaef0--2b2d9fcacc694b65820bf466d58bd922 66499a33e9284106808a0c31b45e7fe3 HamEvo 2b2d9fcacc694b65820bf466d58bd922--66499a33e9284106808a0c31b45e7fe3 b6ef2c6b542f42159e7e599e33c19567 66499a33e9284106808a0c31b45e7fe3--b6ef2c6b542f42159e7e599e33c19567 b76334e614d149f7bf9e61adc56edd4f edd374abe7874a7c9ba6b0fc913b10ab RX(theta\u2081) 41592c8d66de4b23a4e31cb71febfa50--edd374abe7874a7c9ba6b0fc913b10ab 790fd35757aa4ffe842355fad81c1947 2 458976dd83434f80be30ae4d7f9684e2 RY(theta\u2084) edd374abe7874a7c9ba6b0fc913b10ab--458976dd83434f80be30ae4d7f9684e2 9aeb5f17432e487486d17116e5778a5d RX(theta\u2087) 458976dd83434f80be30ae4d7f9684e2--9aeb5f17432e487486d17116e5778a5d 7b579a8a8ea244d38d3dc6d6f6861bb9 t = theta_t\u2080 9aeb5f17432e487486d17116e5778a5d--7b579a8a8ea244d38d3dc6d6f6861bb9 872ee149b4ff402d97c27204cc5d12a8 RX(theta\u2081\u2080) 7b579a8a8ea244d38d3dc6d6f6861bb9--872ee149b4ff402d97c27204cc5d12a8 46d9543b9fd64c97a4a19e1cdad7e2fb RY(theta\u2081\u2083) 872ee149b4ff402d97c27204cc5d12a8--46d9543b9fd64c97a4a19e1cdad7e2fb 263d3147637e40a4b8e6349b626c4bc3 RX(theta\u2081\u2086) 46d9543b9fd64c97a4a19e1cdad7e2fb--263d3147637e40a4b8e6349b626c4bc3 80bb843a7f8f47beaccb7648ae8425fd t = theta_t\u2081 263d3147637e40a4b8e6349b626c4bc3--80bb843a7f8f47beaccb7648ae8425fd 80bb843a7f8f47beaccb7648ae8425fd--b76334e614d149f7bf9e61adc56edd4f fb329cef125e4102b764ab2319ba6735 b32ceb195b9d4208809859a7cc18c234 RX(theta\u2082) 790fd35757aa4ffe842355fad81c1947--b32ceb195b9d4208809859a7cc18c234 9d39f371deb44c2e817a23d979cbdfd6 RY(theta\u2085) b32ceb195b9d4208809859a7cc18c234--9d39f371deb44c2e817a23d979cbdfd6 aa67137c40a7416884cab7536e252e4a RX(theta\u2088) 9d39f371deb44c2e817a23d979cbdfd6--aa67137c40a7416884cab7536e252e4a f240d5d723d3446c9d848452ca0fa7d1 aa67137c40a7416884cab7536e252e4a--f240d5d723d3446c9d848452ca0fa7d1 43f0f445b3bd4235bc435b08950f2a80 RX(theta\u2081\u2081) f240d5d723d3446c9d848452ca0fa7d1--43f0f445b3bd4235bc435b08950f2a80 e8b490dc799c4dcd9e07768159521da4 RY(theta\u2081\u2084) 43f0f445b3bd4235bc435b08950f2a80--e8b490dc799c4dcd9e07768159521da4 ea0c2a31dbcd4e1989d604288507d9d1 RX(theta\u2081\u2087) e8b490dc799c4dcd9e07768159521da4--ea0c2a31dbcd4e1989d604288507d9d1 418cb67d40044ac69a195c1c151e7cd5 ea0c2a31dbcd4e1989d604288507d9d1--418cb67d40044ac69a195c1c151e7cd5 418cb67d40044ac69a195c1c151e7cd5--fb329cef125e4102b764ab2319ba6735 <p>Note that, by default, only the time-parameter is automatically parameterized when building a digital-analog HEA. However, as described in the Hamiltonians tutorial, arbitrary interaction Hamiltonians can be easily built with the <code>hamiltonian_factory</code> function, with both customized or fully parameterized interactions, and these can be directly passed as the <code>entangler</code> for a customizable digital-analog HEA.</p> <pre><code>from qadence import hamiltonian_factory, Interaction, N, Register, hea\n# Build a parameterized neutral-atom Hamiltonian following a honeycomb_lattice:\nregister = Register.honeycomb_lattice(1, 1)\nentangler = hamiltonian_factory(\nregister,\ninteraction=Interaction.NN,\ndetuning=N,\ninteraction_strength=\"e\",\ndetuning_strength=\"n\"\n)\n# Build a fully parameterized Digital-Analog HEA:\nn_qubits = register.n_qubits\ndepth = 2\nansatz = hea(\nn_qubits=register.n_qubits,\ndepth=depth,\noperations=[RX, RY, RX],\nentangler=entangler,\nstrategy=Strategy.SDAQC\n)\n</code></pre> cluster_7dd7a1917cef49e8a0d790343eb66b8b cluster_abfdb51528cc40679f7b511d162d7c4b a86c9d2fd33444f8bbff30216c9f3716 0 1b0b6fbf26f94ec4ab807e8c1094877a RX(theta\u2080) a86c9d2fd33444f8bbff30216c9f3716--1b0b6fbf26f94ec4ab807e8c1094877a eb7cae4665064bfab0dcb422942594f9 1 51e168ee4c204d139135f87984b675f0 RY(theta\u2086) 1b0b6fbf26f94ec4ab807e8c1094877a--51e168ee4c204d139135f87984b675f0 a4e34ce0a86043a1ae0e649d6285e68b RX(theta\u2081\u2082) 51e168ee4c204d139135f87984b675f0--a4e34ce0a86043a1ae0e649d6285e68b e54e42a0c0e74bfcad9ac396e9b793c1 a4e34ce0a86043a1ae0e649d6285e68b--e54e42a0c0e74bfcad9ac396e9b793c1 8726f09e32714718b21747d731533f80 RX(theta\u2081\u2088) e54e42a0c0e74bfcad9ac396e9b793c1--8726f09e32714718b21747d731533f80 d70e5a4fabb84f36ba601fe2bc9c903f RY(theta\u2082\u2084) 8726f09e32714718b21747d731533f80--d70e5a4fabb84f36ba601fe2bc9c903f aaf7168c871b48da907c60493fe19463 RX(theta\u2083\u2080) d70e5a4fabb84f36ba601fe2bc9c903f--aaf7168c871b48da907c60493fe19463 c26ea7855fd64f6ba7546b2a892b71d2 aaf7168c871b48da907c60493fe19463--c26ea7855fd64f6ba7546b2a892b71d2 e35b4088ea7a4f5a837b58b0df17631c c26ea7855fd64f6ba7546b2a892b71d2--e35b4088ea7a4f5a837b58b0df17631c 6618ff70cd954053aff68b681887e741 87f03baadd884fedbdf80c2a15e58396 RX(theta\u2081) eb7cae4665064bfab0dcb422942594f9--87f03baadd884fedbdf80c2a15e58396 c0da84ba582e47498464efd6a187f7a2 2 c232824625374add926d4fc5187f1be9 RY(theta\u2087) 87f03baadd884fedbdf80c2a15e58396--c232824625374add926d4fc5187f1be9 58afff123db64aa89b216960c2635fae RX(theta\u2081\u2083) c232824625374add926d4fc5187f1be9--58afff123db64aa89b216960c2635fae 31fc06879c654d72b92f3e925f6d4a32 58afff123db64aa89b216960c2635fae--31fc06879c654d72b92f3e925f6d4a32 2c3e23fb1abc490e82764c32b11d4186 RX(theta\u2081\u2089) 31fc06879c654d72b92f3e925f6d4a32--2c3e23fb1abc490e82764c32b11d4186 4bdf22764c2b436ea5472d3b0cfd2ff3 RY(theta\u2082\u2085) 2c3e23fb1abc490e82764c32b11d4186--4bdf22764c2b436ea5472d3b0cfd2ff3 d3459d4a346d4b5cb4aec00cdfc945fa RX(theta\u2083\u2081) 4bdf22764c2b436ea5472d3b0cfd2ff3--d3459d4a346d4b5cb4aec00cdfc945fa a31dbd0be9334e6eae3699be712e20aa d3459d4a346d4b5cb4aec00cdfc945fa--a31dbd0be9334e6eae3699be712e20aa a31dbd0be9334e6eae3699be712e20aa--6618ff70cd954053aff68b681887e741 8f8b2cb5e072434d8bb90e0bf907ad9b 92ed4ead4fbc4c7893574aa3156a2294 RX(theta\u2082) c0da84ba582e47498464efd6a187f7a2--92ed4ead4fbc4c7893574aa3156a2294 1a2304df4432486e8dcaa9e327a526f1 3 c1b46addc6414db6ad71a6a41d84b228 RY(theta\u2088) 92ed4ead4fbc4c7893574aa3156a2294--c1b46addc6414db6ad71a6a41d84b228 1047960f8a7447fc9475641b7a2d014c RX(theta\u2081\u2084) c1b46addc6414db6ad71a6a41d84b228--1047960f8a7447fc9475641b7a2d014c b3cf5484baaa4fa4a72b9e7bc346c3da HamEvo 1047960f8a7447fc9475641b7a2d014c--b3cf5484baaa4fa4a72b9e7bc346c3da 591d1ca8eb204e63b90adfd3a5e1dfff RX(theta\u2082\u2080) b3cf5484baaa4fa4a72b9e7bc346c3da--591d1ca8eb204e63b90adfd3a5e1dfff 456fdbf23c6c4ed89a0c83523d10a5eb RY(theta\u2082\u2086) 591d1ca8eb204e63b90adfd3a5e1dfff--456fdbf23c6c4ed89a0c83523d10a5eb aa0ae2b414e1476697ab91a36a51159a RX(theta\u2083\u2082) 456fdbf23c6c4ed89a0c83523d10a5eb--aa0ae2b414e1476697ab91a36a51159a 27cf6f88cfaa4abea40ae5125f99aa6c HamEvo aa0ae2b414e1476697ab91a36a51159a--27cf6f88cfaa4abea40ae5125f99aa6c 27cf6f88cfaa4abea40ae5125f99aa6c--8f8b2cb5e072434d8bb90e0bf907ad9b a90c452becaa4b5098c65b59b906b1a6 8a69863ae4aa442489d7fe7b0da4942b RX(theta\u2083) 1a2304df4432486e8dcaa9e327a526f1--8a69863ae4aa442489d7fe7b0da4942b 12da88d681cd46dbaa54afe5dbe5d297 4 c3e63119eb4a487aa121ac2d7be91078 RY(theta\u2089) 8a69863ae4aa442489d7fe7b0da4942b--c3e63119eb4a487aa121ac2d7be91078 913887c280644d85b6ca4b7f2a3d9024 RX(theta\u2081\u2085) c3e63119eb4a487aa121ac2d7be91078--913887c280644d85b6ca4b7f2a3d9024 1ff78d91d87c4e3190a0a1168efc5cfe t = theta_t\u2080 913887c280644d85b6ca4b7f2a3d9024--1ff78d91d87c4e3190a0a1168efc5cfe 504323d62d07495f80cd3e0bf148dce0 RX(theta\u2082\u2081) 1ff78d91d87c4e3190a0a1168efc5cfe--504323d62d07495f80cd3e0bf148dce0 4c2b4f744b2648fbb914b7f2a8eabf02 RY(theta\u2082\u2087) 504323d62d07495f80cd3e0bf148dce0--4c2b4f744b2648fbb914b7f2a8eabf02 1aecabee7f1344f3a3abd4308d7ad18e RX(theta\u2083\u2083) 4c2b4f744b2648fbb914b7f2a8eabf02--1aecabee7f1344f3a3abd4308d7ad18e de00d7e68716405c9c57eecee9b77020 t = theta_t\u2081 1aecabee7f1344f3a3abd4308d7ad18e--de00d7e68716405c9c57eecee9b77020 de00d7e68716405c9c57eecee9b77020--a90c452becaa4b5098c65b59b906b1a6 0797aae9543c4f318c060e748b19e271 8b191704038a4c328fc43760606f330f RX(theta\u2084) 12da88d681cd46dbaa54afe5dbe5d297--8b191704038a4c328fc43760606f330f e707f84ca1a24d6084cf55a4d83db1b4 5 1e98d05f58dc430dbb5edbb80fe62b42 RY(theta\u2081\u2080) 8b191704038a4c328fc43760606f330f--1e98d05f58dc430dbb5edbb80fe62b42 3272caac7fc64e48a311728173f1a1cd RX(theta\u2081\u2086) 1e98d05f58dc430dbb5edbb80fe62b42--3272caac7fc64e48a311728173f1a1cd 65cb0e33c5cd4d24b9e95ae6b770b9c3 3272caac7fc64e48a311728173f1a1cd--65cb0e33c5cd4d24b9e95ae6b770b9c3 c97dabf227ca443a8a6008aba9d63e42 RX(theta\u2082\u2082) 65cb0e33c5cd4d24b9e95ae6b770b9c3--c97dabf227ca443a8a6008aba9d63e42 7775dcd50d954ddfabf8ecacc308951e RY(theta\u2082\u2088) c97dabf227ca443a8a6008aba9d63e42--7775dcd50d954ddfabf8ecacc308951e bc96107f8ed04475892c8b19ae6e14db RX(theta\u2083\u2084) 7775dcd50d954ddfabf8ecacc308951e--bc96107f8ed04475892c8b19ae6e14db bab894754c7b47deb50a82683e39c687 bc96107f8ed04475892c8b19ae6e14db--bab894754c7b47deb50a82683e39c687 bab894754c7b47deb50a82683e39c687--0797aae9543c4f318c060e748b19e271 f8b279312f2c40b19ae8db947523cc3d 7e26fa00caeb4e6c90395dd0560aea68 RX(theta\u2085) e707f84ca1a24d6084cf55a4d83db1b4--7e26fa00caeb4e6c90395dd0560aea68 d598a8b4566e473887aca6f53d6a38a0 RY(theta\u2081\u2081) 7e26fa00caeb4e6c90395dd0560aea68--d598a8b4566e473887aca6f53d6a38a0 e2a496e6f46b49e2b595f9047d1a8c4c RX(theta\u2081\u2087) d598a8b4566e473887aca6f53d6a38a0--e2a496e6f46b49e2b595f9047d1a8c4c 20eec7df860e46cbb1d452936a2d51c8 e2a496e6f46b49e2b595f9047d1a8c4c--20eec7df860e46cbb1d452936a2d51c8 bf71e6a49ae84db8ac447d470e2f2d57 RX(theta\u2082\u2083) 20eec7df860e46cbb1d452936a2d51c8--bf71e6a49ae84db8ac447d470e2f2d57 f2d94c21a9f547948d39a63e03b5ba8e RY(theta\u2082\u2089) bf71e6a49ae84db8ac447d470e2f2d57--f2d94c21a9f547948d39a63e03b5ba8e e21d2ceccd7b429ea8ed1af84d102a36 RX(theta\u2083\u2085) f2d94c21a9f547948d39a63e03b5ba8e--e21d2ceccd7b429ea8ed1af84d102a36 de279d7613c0426286957c0a3f1eafe4 e21d2ceccd7b429ea8ed1af84d102a36--de279d7613c0426286957c0a3f1eafe4 de279d7613c0426286957c0a3f1eafe4--f8b279312f2c40b19ae8db947523cc3d"},{"location":"qml/qml_tools/#machine-learning-tools","title":"Machine Learning Tools","text":""},{"location":"qml/qml_tools/#dataloaders","title":"Dataloaders","text":"<p>When using <code>qadence</code>, you can supply classical data to a quantum machine learning algorithm by using a standard PyTorch <code>DataLoader</code> instance. Qadence also provides the <code>DictDataLoader</code> convenience class which allows to build dictionaries of <code>DataLoader</code>s instances and easily iterate over them.</p> <pre><code>import torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom qadence.ml_tools import DictDataLoader\ndef dataloader() -&gt; DataLoader:\nbatch_size = 5\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\ndataset = TensorDataset(x, y)\nreturn DataLoader(dataset, batch_size=batch_size)\ndef dictdataloader() -&gt; DictDataLoader:\nbatch_size = 5\nkeys = [\"y1\", \"y2\"]\ndls = {}\nfor k in keys:\nx = torch.rand(batch_size, 1)\ny = torch.sin(x)\ndataset = TensorDataset(x, y)\ndataloader = DataLoader(dataset, batch_size=batch_size)\ndls[k] = dataloader\nreturn DictDataLoader(dls)\nn_epochs = 2\n# iterate standard DataLoader\ndl = dataloader()\nfor i in range(n_epochs):\ndata = next(iter(dl))\n# iterate DictDataLoader\nddl = dictdataloader()\nfor i in range(n_epochs):\ndata = next(iter(ddl))\n</code></pre> <pre><code>\n</code></pre>"},{"location":"qml/qml_tools/#optimization-routines","title":"Optimization routines","text":"<p>For training QML models, <code>qadence</code> also offers a few out-of-the-box routines for optimizing differentiable models like <code>QNN</code>s and <code>QuantumModel</code>s containing either trainable and/or non-trainable parameters (you can refer to this for a refresh about different parameter types):</p> <ul> <li><code>train_with_grad</code> for gradient-based optimization using PyTorch native optimizers</li> <li><code>train_gradient_free</code> for gradient-free optimization using the Nevergrad library.</li> </ul> <p>These routines performs training, logging/printing loss metrics and storing intermediate checkpoints of models. In the following, we use <code>train_with_grad</code> as example but the code can be used directly with the gradient-free routine.</p> <p>As every other training routine commonly used in Machine Learning, it requires <code>model</code>, <code>data</code> and an <code>optimizer</code> as input arguments. However, in addition, it requires a <code>loss_fn</code> and a <code>TrainConfig</code>. A <code>loss_fn</code> is required to be a function which expects both a model and data and returns a tuple of (loss, metrics: <code>&lt;dict&gt;</code>), where <code>metrics</code> is a dict of scalars which can be customized too.</p> <pre><code>import torch\nfrom itertools import count\ncnt = count()\ncriterion = torch.nn.MSELoss()\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\nnext(cnt)\nx, y = data[0], data[1]\nout = model(x)\nloss = criterion(out, y)\nreturn loss, {}\n</code></pre> <pre><code>\n</code></pre> <p>The <code>TrainConfig</code> tells <code>train_with_grad</code> what batch_size should be used, how many epochs to train, in which intervals to print/log metrics and how often to store intermediate checkpoints.</p> <pre><code>from qadence.ml_tools import TrainConfig\nbatch_size = 5\nn_epochs = 100\nconfig = TrainConfig(\nfolder=\"some_path/\",\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\n</code></pre> <pre><code>\n</code></pre> <p>Let's see it in action with a simple example.</p>"},{"location":"qml/qml_tools/#fitting-a-funtion-with-a-qnn-using-ml_tools","title":"Fitting a funtion with a QNN using <code>ml_tools</code>","text":"<p>Let's look at a complete example of how to use <code>train_with_grad</code> now.</p> <pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence.models import QNN\nfrom qadence.ml_tools import train_with_grad, TrainConfig\nimport matplotlib.pyplot as plt\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\ncnt = count()\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\ndef loss_fn(model: torch.nn.Module, data: torch.Tensor) -&gt; tuple[torch.Tensor, dict]:\nnext(cnt)\nx, y = data[0], data[1]\nout = model(x)\nloss = criterion(out, y)\nreturn loss, {}\ntmp_path = Path(\"/tmp\")\nn_epochs = 5\nconfig = TrainConfig(\nfolder=tmp_path,\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\nbatch_size = 25\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\ntrain_with_grad(model, (x, y), optimizer, config, loss_fn=loss_fn)\nplt.plot(y.numpy())\nplt.plot(model(input_values).detach().numpy())\n</code></pre> <pre><code>\n</code></pre> <p>For users who want to use the low-level API of <code>qadence</code>, here is the example from above written without <code>train_with_grad</code>.</p>"},{"location":"qml/qml_tools/#fitting-a-function-low-level-api","title":"Fitting a function - Low-level API","text":"<pre><code>from pathlib import Path\nimport torch\nfrom itertools import count\nfrom qadence.constructors import hamiltonian_factory, hea, feature_map\nfrom qadence import chain, Parameter, QuantumCircuit, Z\nfrom qadence.models import QNN\nfrom qadence.ml_tools import train_with_grad, TrainConfig\nn_qubits = 2\nfm = feature_map(n_qubits)\nansatz = hea(n_qubits=n_qubits, depth=3)\nobservable = hamiltonian_factory(n_qubits, detuning=Z)\ncircuit = QuantumCircuit(n_qubits, fm, ansatz)\nmodel = QNN(circuit, observable, backend=\"pyqtorch\", diff_mode=\"ad\")\nbatch_size = 1\ninput_values = {\"phi\": torch.rand(batch_size, requires_grad=True)}\npred = model(input_values)\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\nn_epochs=50\ncnt = count()\ntmp_path = Path(\"/tmp\")\nconfig = TrainConfig(\nfolder=tmp_path,\nmax_iter=n_epochs,\ncheckpoint_every=100,\nwrite_every=100,\nbatch_size=batch_size,\n)\nx = torch.linspace(0, 1, batch_size).reshape(-1, 1)\ny = torch.sin(x)\nfor i in range(n_epochs):\nout = model(x)\nloss = criterion(out, y)\nloss.backward()\noptimizer.step()\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/backends/","title":"Backends","text":"<p>Backends allow execution of Qadence abstract quantum circuits. They could be chosen from a variety of simulators, emulators and hardware and can enable circuit differentiability. The primary way to interact and configure a backend is via the high-level API <code>QuantumModel</code>.</p> <p>Not all backends are equivalent</p> <p>Not all backends support the same set of operations, especially while executing analog blocks. Qadence will throw descriptive errors in such cases.</p>"},{"location":"tutorials/backends/#execution-backends","title":"Execution backends","text":"<p>PyQTorch: An efficient, large-scale simulator designed for quantum machine learning, seamlessly integrated with the popular PyTorch deep learning framework for automatic differentiability. It also offers analog computing for time-independent pulses. See <code>PyQTorchBackend</code>.</p> <p>Pulser: A Python library for pulse-level/analog control of neutral atom devices. Execution via QuTiP. See <code>PulserBackend</code>.</p> <p>Braket: A Python SDK for interacting with quantum devices on Amazon Braket. Currently, only the devices with the digital interface of Amazon Braket are supported and execution is performed using the local simulator. Execution on remote simulators and quantum processing units will be available soon. See <code>BraketBackend</code></p> <p>More: Proprietary Qadence extensions provide more high-performance backends based on tensor networks or differentiation engines. For more enquiries, please contact: <code>info@pasqal.com</code>.</p>"},{"location":"tutorials/backends/#differentiation-backend","title":"Differentiation backend","text":"<p>The <code>DifferentiableBackend</code> class enables different differentiation modes for the given backend. This can be chosen from two types:</p> <ul> <li>Automatic differentiation (AD): available for PyTorch based backends (PyQTorch).</li> <li>Parameter Shift Rules (PSR): available for all backends. See this section for more information on differentiability and PSR.</li> </ul> <p>In practice, only a <code>diff_mode</code> should be provided in the <code>QuantumModel</code>. Please note that <code>diff_mode</code> defaults to <code>None</code>:</p> <pre><code>import sympy\nimport torch\nfrom qadence import Parameter, RX, RZ, Z, CNOT, QuantumCircuit, QuantumModel, chain, BackendName, DiffMode\nx = Parameter(\"x\", trainable=False)\ny = Parameter(\"y\", trainable=False)\nfm = chain(\nRX(0, 3 * x),\nRX(0, x),\nRZ(1, sympy.exp(y)),\nRX(0, 3.14),\nRZ(1, \"theta\")\n)\nansatz = CNOT(0, 1)\nblock = chain(fm, ansatz)\ncircuit = QuantumCircuit(2, block)\nobservable = Z(0)\n# DiffMode.GPSR is available for any backend.\n# DiffMode.AD is only available for natively differentiable backends.\nmodel = QuantumModel(circuit, observable, backend=BackendName.PYQTORCH, diff_mode=DiffMode.GPSR)\n# Get some values for the feature parameters.\nvalues = {\"x\": (x := torch.tensor([0.5], requires_grad=True)), \"y\": torch.tensor([0.1])}\n# Compute expectation.\nexp = model.expectation(values)\n# Differentiate the expectation wrt x.\ndexp_dx = torch.autograd.grad(exp, x, torch.ones_like(exp))\n</code></pre> <pre><code>dexp_dx = (tensor([3.6398]),)\n</code></pre>"},{"location":"tutorials/backends/#low-level-backend_factory-interface","title":"Low-level <code>backend_factory</code> interface","text":"<p>Every backend in Qadence inherits from the abstract <code>Backend</code> class: <code>Backend</code> and implement the following methods:</p> <ul> <li><code>run</code>: propagate the initial state according to the quantum circuit and return the final wavefunction object.</li> <li><code>sample</code>: sample from a circuit.</li> <li><code>expectation</code>: computes the expectation of a circuit given an observable.</li> <li><code>convert</code>: convert the abstract <code>QuantumCircuit</code> object to its backend-native representation including a backend specific parameter embedding function.</li> </ul> <p>Backends are purely functional objects which take as input the values for the circuit parameters and return the desired output from a call to a method. In order to use a backend directly, embedded parameters must be supplied as they are returned by the backend specific embedding function.</p> <p>Here is a simple demonstration of the use of the Braket backend to execute a circuit in non-differentiable mode:</p> <pre><code>from qadence import QuantumCircuit, FeatureParameter, RX, RZ, CNOT, hea, chain\n# Construct a feature map.\nx = FeatureParameter(\"x\")\nz = FeatureParameter(\"y\")\nfm = chain(RX(0, 3 * x), RZ(1, z), CNOT(0, 1))\n# Construct a circuit with an hardware-efficient ansatz.\ncircuit = QuantumCircuit(3, fm, hea(3,1))\n</code></pre> <p>The abstract <code>QuantumCircuit</code> can now be converted to its native representation via the Braket backend.</p> <pre><code>from qadence import backend_factory\n# Use only Braket in non-differentiable mode:\nbackend = backend_factory(\"braket\")\n# The `Converted` object\n# (contains a `ConvertedCircuit` with the original and native representation)\nconv = backend.convert(circuit)\n</code></pre> <pre><code>conv.circuit.original = ChainBlock(0,1,2)\n\u251c\u2500\u2500 ChainBlock(0,1)\n\u2502   \u251c\u2500\u2500 RX(0) [params: ['3*x']]\n\u2502   \u251c\u2500\u2500 RZ(1) [params: ['y']]\n\u2502   \u2514\u2500\u2500 CNOT(0,1)\n\u2514\u2500\u2500 ChainBlock(0,1,2) [tag: HEA]\n\u251c\u2500\u2500 ChainBlock(0,1,2)\n\u2502   \u251c\u2500\u2500 KronBlock(0,1,2)\n\u2502   \u2502   \u251c\u2500\u2500 RX(0) [params: ['theta_0']]\n\u2502   \u2502   \u251c\u2500\u2500 RX(1) [params: ['theta_1']]\n\u2502   \u2502   \u2514\u2500\u2500 RX(2) [params: ['theta_2']]\n\u2502   \u251c\u2500\u2500 KronBlock(0,1,2)\n\u2502   \u2502   \u251c\u2500\u2500 RY(0) [params: ['theta_3']]\n\u2502   \u2502   \u251c\u2500\u2500 RY(1) [params: ['theta_4']]\n\u2502   \u2502   \u2514\u2500\u2500 RY(2) [params: ['theta_5']]\n\u2502   \u2514\u2500\u2500 KronBlock(0,1,2)\n\u2502       \u251c\u2500\u2500 RX(0) [params: ['theta_6']]\n\u2502       \u251c\u2500\u2500 RX(1) [params: ['theta_7']]\n\u2502       \u2514\u2500\u2500 RX(2) [params: ['theta_8']]\n\u2514\u2500\u2500 ChainBlock(0,1,2)\n\u251c\u2500\u2500 KronBlock(0,1)\n\u2502   \u2514\u2500\u2500 CNOT(0,1)\n\u2514\u2500\u2500 KronBlock(1,2)\n\u2514\u2500\u2500 CNOT(1,2)\nconv.circuit.native = Circuit('instructions': [Instruction('operator': Rx('angle': e9624b0f-2646-440b-99e2-7c7ba5053163, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rz('angle': b3c5290b-837b-4199-98e9-560cdf105ba6, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(0), Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': eb75c60c-95f4-49b2-a1c8-20dde398725a, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 8fcfb179-8033-40ae-9f6a-d58d824de1f9, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 1fe1cf4e-5a67-4df6-8582-faed50f79d77, 'qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Ry('angle': 6c54279c-4c65-49d4-bfa0-e7efb68791d6, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Ry('angle': f99735a2-b74e-4574-9c83-311ab066faf2, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Ry('angle': 4006c4a2-8b01-4d4a-bc9e-e18ab07d3844, 'qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': 857cc200-194e-4988-8290-7adc727cb315, 'qubit_count': 1), 'target': QubitSet([Qubit(0)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': bc6484d1-3aee-4fde-8d22-266ef98894e2, 'qubit_count': 1), 'target': QubitSet([Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': Rx('angle': a848e792-38a9-43b3-aa87-d1396601486e, 'qubit_count': 1), 'target': QubitSet([Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(0), Qubit(1)]), 'control': QubitSet([]), 'control_state': (), 'power': 1), Instruction('operator': CNot('qubit_count': 2), 'target': QubitSet([Qubit(1), Qubit(2)]), 'control': QubitSet([]), 'control_state': (), 'power': 1)])\n</code></pre> <p>Additionally, <code>Converted</code> contains all fixed and variational parameters, as well as an embedding function which accepts feature parameters to construct a dictionary of circuit native parameters. These are needed as each backend uses a different representation of the circuit parameters:</p> <pre><code>import torch\n# Contains fixed parameters and variational (from the HEA)\nconv.params\ninputs = {\"x\": torch.tensor([1., 1.]), \"y\":torch.tensor([2., 2.])}\n# get all circuit parameters (including feature params)\nembedded = conv.embedding_fn(conv.params, inputs)\n</code></pre> <pre><code>conv.params = {\ntheta_5: tensor([0.3829], requires_grad=True)\ntheta_8: tensor([0.1922], requires_grad=True)\ntheta_1: tensor([0.9099], requires_grad=True)\ntheta_3: tensor([0.4370], requires_grad=True)\ntheta_0: tensor([0.7224], requires_grad=True)\ntheta_7: tensor([0.8215], requires_grad=True)\ntheta_4: tensor([0.0779], requires_grad=True)\ntheta_6: tensor([0.5825], requires_grad=True)\ntheta_2: tensor([0.8681], requires_grad=True)\n}\nembedded = {\ne9624b0f-2646-440b-99e2-7c7ba5053163: tensor([3., 3.])\nb3c5290b-837b-4199-98e9-560cdf105ba6: tensor([2., 2.])\neb75c60c-95f4-49b2-a1c8-20dde398725a: tensor([0.7224], grad_fn=&lt;ViewBackward0&gt;)\n8fcfb179-8033-40ae-9f6a-d58d824de1f9: tensor([0.9099], grad_fn=&lt;ViewBackward0&gt;)\n1fe1cf4e-5a67-4df6-8582-faed50f79d77: tensor([0.8681], grad_fn=&lt;ViewBackward0&gt;)\n6c54279c-4c65-49d4-bfa0-e7efb68791d6: tensor([0.4370], grad_fn=&lt;ViewBackward0&gt;)\nf99735a2-b74e-4574-9c83-311ab066faf2: tensor([0.0779], grad_fn=&lt;ViewBackward0&gt;)\n4006c4a2-8b01-4d4a-bc9e-e18ab07d3844: tensor([0.3829], grad_fn=&lt;ViewBackward0&gt;)\n857cc200-194e-4988-8290-7adc727cb315: tensor([0.5825], grad_fn=&lt;ViewBackward0&gt;)\nbc6484d1-3aee-4fde-8d22-266ef98894e2: tensor([0.8215], grad_fn=&lt;ViewBackward0&gt;)\na848e792-38a9-43b3-aa87-d1396601486e: tensor([0.1922], grad_fn=&lt;ViewBackward0&gt;)\n}\n</code></pre> <p>Note that above the parameters keys have changed as they now address the keys on the Braket device. A more readable embedding is provided by the PyQTorch backend:</p> <pre><code>from qadence import BackendName, DiffMode\npyq_backend = backend_factory(backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD)\n# the `Converted` object\n# (contains a `ConvertedCircuit` wiht the original and native representation)\npyq_conv = pyq_backend.convert(circuit)\nembedded = pyq_conv.embedding_fn(pyq_conv.params, inputs)\n</code></pre> <pre><code>embedded = {\ny: tensor([2., 2.])\ntheta_5: tensor([0.3829], grad_fn=&lt;ViewBackward0&gt;)\ntheta_8: tensor([0.1922], grad_fn=&lt;ViewBackward0&gt;)\ntheta_1: tensor([0.9099], grad_fn=&lt;ViewBackward0&gt;)\ntheta_3: tensor([0.4370], grad_fn=&lt;ViewBackward0&gt;)\ntheta_0: tensor([0.7224], grad_fn=&lt;ViewBackward0&gt;)\n3*x: tensor([3., 3.])\ntheta_7: tensor([0.8215], grad_fn=&lt;ViewBackward0&gt;)\ntheta_4: tensor([0.0779], grad_fn=&lt;ViewBackward0&gt;)\ntheta_6: tensor([0.5825], grad_fn=&lt;ViewBackward0&gt;)\ntheta_2: tensor([0.8681], grad_fn=&lt;ViewBackward0&gt;)\n}\n</code></pre> <p>With the embedded parameters, <code>QuantumModel</code> methods are accessible:</p> <pre><code>embedded = conv.embedding_fn(conv.params, inputs)\nsamples = backend.run(conv.circuit, embedded)\nprint(f\"{samples = }\")\n</code></pre> <pre><code>samples = tensor([[ 0.4139+0.0748j,  0.1140-0.2352j,  0.1632+0.1274j, -0.1267+0.3081j,\n-0.3707-0.2339j, -0.2020+0.1828j,  0.1915+0.2378j, -0.2855+0.3998j],\n[ 0.4139+0.0748j,  0.1140-0.2352j,  0.1632+0.1274j, -0.1267+0.3081j,\n-0.3707-0.2339j, -0.2020+0.1828j,  0.1915+0.2378j, -0.2855+0.3998j]])\n</code></pre>"},{"location":"tutorials/backends/#lower-level-the-backend-representation","title":"Lower-level: the <code>Backend</code> representation","text":"<p>If there is a requirement to work with a specific backend, it is possible to access directly the native circuit. For example, Braket noise features can be imported which are not exposed directly by Qadence.</p> <pre><code>from braket.circuits import Noise\n# Get the native Braket circuit with the given parameters\ninputs = {\"x\": torch.rand(1), \"y\":torch.rand(1)}\nembedded = conv.embedding_fn(conv.params, inputs)\nnative = backend.assign_parameters(conv.circuit, embedded)\n# Define a noise channel\nnoise = Noise.Depolarizing(probability=0.1)\n# Add noise to every gate in the circuit\nnative.apply_gate_noise(noise)\n</code></pre> <p>In order to run this noisy circuit, the density matrix simulator is needed in Braket:</p> <p><pre><code>from braket.devices import LocalSimulator\ndevice = LocalSimulator(\"braket_dm\")\nresult = device.run(native, shots=1000).result().measurement_counts\nprint(result)\n</code></pre> <pre><code>Counter({'000': 175, '011': 143, '100': 142, '111': 123, '010': 118, '001': 106, '101': 98, '110': 95})\n</code></pre> <pre><code>print(conv.circuit.native.diagram())\n</code></pre> <pre><code>T  : |                   0                    |                   1                    |                   2                    |                   3                    |                   4                    |5|6|\nq0 : -Rx(e9624b0f-2646-440b-99e2-7c7ba5053163)-C----------------------------------------Rx(eb75c60c-95f4-49b2-a1c8-20dde398725a)-Ry(6c54279c-4c65-49d4-bfa0-e7efb68791d6)-Rx(857cc200-194e-4988-8290-7adc727cb315)-C---\n|                                                                                                                                                                   |   q1 : -Rz(b3c5290b-837b-4199-98e9-560cdf105ba6)-X----------------------------------------Rx(8fcfb179-8033-40ae-9f6a-d58d824de1f9)-Ry(f99735a2-b74e-4574-9c83-311ab066faf2)-Rx(bc6484d1-3aee-4fde-8d22-266ef98894e2)-X-C-\n| q2 : -Rx(1fe1cf4e-5a67-4df6-8582-faed50f79d77)-Ry(4006c4a2-8b01-4d4a-bc9e-e18ab07d3844)-Rx(a848e792-38a9-43b3-aa87-d1396601486e)-------------------------------------------------------------------------------------X-\nT  : |                   0                    |                   1                    |                   2                    |                   3                    |                   4                    |5|6|\nUnassigned parameters: [1fe1cf4e-5a67-4df6-8582-faed50f79d77, 4006c4a2-8b01-4d4a-bc9e-e18ab07d3844, 6c54279c-4c65-49d4-bfa0-e7efb68791d6, 857cc200-194e-4988-8290-7adc727cb315, 8fcfb179-8033-40ae-9f6a-d58d824de1f9, a848e792-38a9-43b3-aa87-d1396601486e, b3c5290b-837b-4199-98e9-560cdf105ba6, bc6484d1-3aee-4fde-8d22-266ef98894e2, e9624b0f-2646-440b-99e2-7c7ba5053163, eb75c60c-95f4-49b2-a1c8-20dde398725a, f99735a2-b74e-4574-9c83-311ab066faf2].\n</code></pre> <pre><code>print(native.diagram())\n</code></pre> <pre><code>T  : |        0         |        1         |        2         |        3         |        4         |     5     |     6     |\nq0 : -Rx(0.73)-DEPO(0.1)-C--------DEPO(0.1)-Rx(0.72)-DEPO(0.1)-Ry(0.44)-DEPO(0.1)-Rx(0.58)-DEPO(0.1)-C-DEPO(0.1)-------------\n|                                                                           |                       q1 : -Rz(0.96)-DEPO(0.1)-X--------DEPO(0.1)-Rx(0.91)-DEPO(0.1)-Ry(0.08)-DEPO(0.1)-Rx(0.82)-DEPO(0.1)-X-DEPO(0.1)-C-DEPO(0.1)-\n|           q2 : -Rx(0.87)-DEPO(0.1)-Ry(0.38)-DEPO(0.1)-Rx(0.19)-DEPO(0.1)---------------------------------------------------X-DEPO(0.1)-\nT  : |        0         |        1         |        2         |        3         |        4         |     5     |     6     |\n</code></pre> </p>"},{"location":"tutorials/getting_started/","title":"Getting started","text":"<p>Quantum programs in Qadence are constructed via a block-system, with an emphasis on composability of primitive blocks to obtain larger, composite blocks. This functional approach is different from other frameworks which follow a more object-oriented way to construct circuits and express programs.</p> How to visualize blocks <p>There are two ways to display blocks in a Python interpreter: either as a tree in ASCII format using <code>print</code>:</p> <p><pre><code>from qadence import X, Y, kron\nkron_block = kron(X(0), Y(1))\nprint(kron_block)\n</code></pre> <pre><code>KronBlock(0,1)\n\u251c\u2500\u2500 X(0)\n\u2514\u2500\u2500 Y(1)\n</code></pre> </p> <p>Or using the visualization package:</p> <p><pre><code>from qadence import X, Y, kron\nfrom qadence.draw import display\nkron_block = kron(X(0), Y(1))\n# display(kron_block)  # un-comment this line\n</code></pre> ca883f0b98f54a8cbe222697b97856a0 0 f92c9cb543134dddb4e21d7b2d8d45db X ca883f0b98f54a8cbe222697b97856a0--f92c9cb543134dddb4e21d7b2d8d45db f0fb65e3c6d94d1c8e20faa89cfda6d3 1 0ea7dcc25752466b9922bb937e820b6e f92c9cb543134dddb4e21d7b2d8d45db--0ea7dcc25752466b9922bb937e820b6e ad4e7f44b1594d688e18d19c508bd2d1 27cc0a260e16451abdc1d0e389cccbfe Y f0fb65e3c6d94d1c8e20faa89cfda6d3--27cc0a260e16451abdc1d0e389cccbfe 27cc0a260e16451abdc1d0e389cccbfe--ad4e7f44b1594d688e18d19c508bd2d1 </p>"},{"location":"tutorials/getting_started/#primitive-blocks","title":"Primitive blocks","text":"<p>A <code>PrimitiveBlock</code> represents a digital or an analog time-evolution quantum operation applied to a qubit support. Programs can always be decomposed down into a sequence of <code>PrimitiveBlock</code> elements.</p> <p>Two canonical examples of digital primitive blocks are the parametrized <code>RX</code> and the <code>CNOT</code> gates:</p> <pre><code>from qadence import RX\n# A rotation gate on qubit 0 with a fixed numerical parameter.\nrx_gate = RX(0, 0.5)\n</code></pre> a77831f5d3284f7587b1ff8206ca2fa5 0 9ceea081d8d640f1bf7dab9f08ccbd93 RX(0.5) a77831f5d3284f7587b1ff8206ca2fa5--9ceea081d8d640f1bf7dab9f08ccbd93 82a5244821954ff6bd5df73fc53cd21a 9ceea081d8d640f1bf7dab9f08ccbd93--82a5244821954ff6bd5df73fc53cd21a <pre><code>from qadence import CNOT\n# A CNOT gate with control on qubit 0 and target on qubit 1.\ncnot_gate = CNOT(0, 1)\n</code></pre> aaeba58428dc4918805eec6c2d927273 0 838d15d7d5014fa892cbaed8758efb35 aaeba58428dc4918805eec6c2d927273--838d15d7d5014fa892cbaed8758efb35 2e898ef917cf40048e0381b9c4cadf34 1 422f94152eb146f0a4b070e4ff8bcd9a 838d15d7d5014fa892cbaed8758efb35--422f94152eb146f0a4b070e4ff8bcd9a 2dc4951d365d4c28b05f796a9e7ef17d 4671945b20d64745941fe1c25ce0a85e X 2e898ef917cf40048e0381b9c4cadf34--4671945b20d64745941fe1c25ce0a85e 4671945b20d64745941fe1c25ce0a85e--838d15d7d5014fa892cbaed8758efb35 4671945b20d64745941fe1c25ce0a85e--2dc4951d365d4c28b05f796a9e7ef17d <p>A list of all instances of primitive blocks (also referred to as operations) can be found here.</p>"},{"location":"tutorials/getting_started/#composite-blocks","title":"Composite Blocks","text":"<p>Programs can be expressed by composing blocks to result in a larger <code>CompositeBlock</code> using three fundamental operations: chain, kron, and add.</p> <ul> <li>chain applies a set of blocks in sequence on the same or overlapping qubit supports and results in a <code>ChainBlock</code> type. It is akin to applying a matrix product of the sub-blocks with the <code>*</code> operator.</li> </ul> <p><pre><code>from qadence import X, chain\n# Chaining on the same qubit using a call to the function.\nchain_x = chain(X(0), X(0))\n</code></pre> 2c49e588341a4ab9b4d525649240cc3f 0 f420cdb132e3465a96d66273b8217ca1 X 2c49e588341a4ab9b4d525649240cc3f--f420cdb132e3465a96d66273b8217ca1 79d2ff433a964cf496b9de63eee2bf46 X f420cdb132e3465a96d66273b8217ca1--79d2ff433a964cf496b9de63eee2bf46 162053ce32ef4248897c4d84c281b1e3 79d2ff433a964cf496b9de63eee2bf46--162053ce32ef4248897c4d84c281b1e3 <pre><code># Chaining on different qubits using the operator overload.\n# Identical to the kron operation.\nchain_xx = X(0) * X(1)\n</code></pre> 577b59f15391451ead0631dc115866fe 0 74d63e7551974e4f8a5a380080c4b3b0 X 577b59f15391451ead0631dc115866fe--74d63e7551974e4f8a5a380080c4b3b0 7d65beee476b42f69cd170c8b8eab3a5 1 54f90cf3ab0a45c3ae7a3f8a1b3fdcf9 74d63e7551974e4f8a5a380080c4b3b0--54f90cf3ab0a45c3ae7a3f8a1b3fdcf9 dde9e56456314c6196a9957b00f285be 54f90cf3ab0a45c3ae7a3f8a1b3fdcf9--dde9e56456314c6196a9957b00f285be 4404679eb94e4346b1dd8c0b8f06e31a 073fda3c125649189b39d57fc31c2a9d 7d65beee476b42f69cd170c8b8eab3a5--073fda3c125649189b39d57fc31c2a9d 2ae8e04db1794307bb8fc076b096f781 X 073fda3c125649189b39d57fc31c2a9d--2ae8e04db1794307bb8fc076b096f781 2ae8e04db1794307bb8fc076b096f781--4404679eb94e4346b1dd8c0b8f06e31a </p> <ul> <li>kron applies a set of blocks in parallel (simultaneously) on disjoint qubit support and results in a <code>KronBlock</code> type. This is akin to applying a tensor product of the sub-blocks with the <code>@</code> operator.</li> </ul> <pre><code>from qadence import X, kron\nkron_xx = kron(X(0), X(1))  # Equivalent to X(0) @ X(1)\n</code></pre> e44e02c14de748fbbed7f5aa6a7de370 0 a8bcd7dbe2d048e48afef3ed14f903dc X e44e02c14de748fbbed7f5aa6a7de370--a8bcd7dbe2d048e48afef3ed14f903dc a4d411ed1aeb4eca9e4ae9caa5c6f9fe 1 371112712ac54c47b9640e474a90c4c5 a8bcd7dbe2d048e48afef3ed14f903dc--371112712ac54c47b9640e474a90c4c5 d72618c287fb440f9a448ce07fee2350 acd9f93800f747baadf3907f6d68ce3e X a4d411ed1aeb4eca9e4ae9caa5c6f9fe--acd9f93800f747baadf3907f6d68ce3e acd9f93800f747baadf3907f6d68ce3e--d72618c287fb440f9a448ce07fee2350 <p>For the digital case, it should be noted that <code>kron</code> and <code>chain</code> are semantically equivalent up to the diagrammatic representation as <code>chain</code> implicitly fills blank wires with identities. However, Qadence also supports analog blocks, for which composing sequentially or in parallel becomes non-equivalent. More about analog blocks can be found in the digital-analog section.</p> <ul> <li>add sums the corresponding matrix of each sub-block and results in a <code>AddBlock</code> type which can be used to construct Pauli operators. Please note that <code>AddBlock</code> can give rise to non-unitary computations that might not be supported by all backends.</li> </ul> Get the matrix of a block <p>It is always possible to retrieve the matrix representation of a block by calling the <code>block.tensor()</code> method. Please note that the returned tensor contains a batch dimension for the purposes of block parametrization.</p> <p><pre><code>\n</code></pre> <pre><code>X(0) * X(0) tensor = tensor([[[1.+0.j, 0.+0.j],\n[0.+0.j, 1.+0.j]]])\nX(0) @ X(1) tensor = tensor([[[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]]])\n</code></pre> </p> <pre><code>from qadence import X, Z\nxz = X(0) + Z(0)\nprint(xz.tensor())\n</code></pre> <pre><code>tensor([[[ 1.+0.j,  1.+0.j],\n[ 1.+0.j, -1.+0.j]]])\n</code></pre> <p>Finally, it is possible to tag blocks with human-readable names:</p> <pre><code>from qadence import X, Y, CNOT, kron, chain, tag\nxy = kron(X(0), Y(1))\ntag(xy, \"subblock\")\ncomposite_block = kron(xy, CNOT(3,4))\nfinal_block = chain(composite_block, composite_block)\n</code></pre> cluster_9be8079ef9464f8ab9ecd7158527fc5a subblock cluster_1b0d1f016f794cf6a8440f8904d8f563 subblock 168c9d0791194f08af80af1bbd5fee1b 0 902fc40886cc45d6ac4dfe5344e2301b X 168c9d0791194f08af80af1bbd5fee1b--902fc40886cc45d6ac4dfe5344e2301b d0219e076b3a4e8fae280b9cea4f083a 1 2ac7a9bf794d494dab0d221991fe062c X 902fc40886cc45d6ac4dfe5344e2301b--2ac7a9bf794d494dab0d221991fe062c bf950b96a7644ac2b15bb834f065cd62 2ac7a9bf794d494dab0d221991fe062c--bf950b96a7644ac2b15bb834f065cd62 99b92aa55bd54d8bacdd0b8a63b1bd06 6ebf13369322444284ae81ffe6dfc824 Y d0219e076b3a4e8fae280b9cea4f083a--6ebf13369322444284ae81ffe6dfc824 caa062fecc0d4000852bef3cf43aee5a 2 68451366b38f4b7da3b163e47a4bb955 Y 6ebf13369322444284ae81ffe6dfc824--68451366b38f4b7da3b163e47a4bb955 68451366b38f4b7da3b163e47a4bb955--99b92aa55bd54d8bacdd0b8a63b1bd06 6f703fe8d46f49c5836a4bdedfddb388 483476d6c70842a2889530e1b8e05f74 caa062fecc0d4000852bef3cf43aee5a--483476d6c70842a2889530e1b8e05f74 72200e1f626b4e2ea65b010d41654322 3 546a0c0404724272aed8e30656635c83 483476d6c70842a2889530e1b8e05f74--546a0c0404724272aed8e30656635c83 546a0c0404724272aed8e30656635c83--6f703fe8d46f49c5836a4bdedfddb388 9ab835bca80140049a527a10e92d504f aa3af235df1c4352a5fe9b1dcd2e2f11 72200e1f626b4e2ea65b010d41654322--aa3af235df1c4352a5fe9b1dcd2e2f11 ba854c969b8742f9b3d58f95d1356661 4 cea210430d814326b14723015c71341b aa3af235df1c4352a5fe9b1dcd2e2f11--cea210430d814326b14723015c71341b cea210430d814326b14723015c71341b--9ab835bca80140049a527a10e92d504f 7f206d3351aa4f4ca7c006bb37bd9059 fec9d6cfffa74de9bc48e1c422ff7d86 X ba854c969b8742f9b3d58f95d1356661--fec9d6cfffa74de9bc48e1c422ff7d86 fec9d6cfffa74de9bc48e1c422ff7d86--aa3af235df1c4352a5fe9b1dcd2e2f11 fe948f8efa444e46a26bfdb3a41b97ae X fec9d6cfffa74de9bc48e1c422ff7d86--fe948f8efa444e46a26bfdb3a41b97ae fe948f8efa444e46a26bfdb3a41b97ae--cea210430d814326b14723015c71341b fe948f8efa444e46a26bfdb3a41b97ae--7f206d3351aa4f4ca7c006bb37bd9059"},{"location":"tutorials/getting_started/#block-execution","title":"Block execution","text":"<p>To quickly run quantum operations and access wavefunctions, samples or expectation values of observables, one can use the convenience functions <code>run</code>, <code>sample</code> and <code>expectation</code>. The following example shows an execution workflow with the natively available <code>PyQTorch</code> backend:</p> <pre><code>from qadence import chain, add, H, Z, run, sample, expectation\nn_qubits = 2\nblock = chain(H(0), H(1))\n# Compute the wavefunction.\n# Please check the documentation for other available backends.\nwf = run(block)\n# Sample the resulting wavefunction with a given number of shots.\nxs = sample(block, n_shots=1000)\n# Compute an expectation based on an observable of Pauli-Z operators.\nobs = add(Z(i) for i in range(n_qubits))\nex = expectation(block, obs)\n</code></pre> <pre><code>wf = tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\nxs = [Counter({'00': 271, '10': 252, '01': 247, '11': 230})]\nex = tensor([[0.]])\n</code></pre> <p>More fine-grained control and better performance is provided via the high-level <code>QuantumModel</code> abstraction.</p>"},{"location":"tutorials/getting_started/#execution-via-quantumcircuit-and-quantummodel","title":"Execution via <code>QuantumCircuit</code> and <code>QuantumModel</code>","text":"<p>Quantum programs in Qadence are constructed in two steps:</p> <ol> <li>Build a <code>QuantumCircuit</code> which ties together a composite block and a register.</li> <li>Define a <code>QuantumModel</code> which differentiates, compiles and executes the circuit.</li> </ol> <p><code>QuantumCircuit</code> is a central class in Qadence and circuits are abstract objects from the actual hardware/simulator that they are expected to be executed on. They require to specify the <code>Register</code> of resources to execute your program on. Previous examples were already using <code>QuantumCircuit</code> with a <code>Register</code> that fits the qubit support for the given block.</p> <pre><code>from qadence import QuantumCircuit, Register, H, chain\n# NOTE: Run a block which supports two qubits\n# on a register of three qubits.\nregister = Register(3)\ncircuit = QuantumCircuit(register, chain(H(0), H(1)))\n</code></pre> <pre><code>circuit = ChainBlock(0,1)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 H(1)\n</code></pre> <p>Registers and qubit supports</p> <p>Registers can also be constructed from qubit coordinates to create arbitrary register topologies. See details in the digital-analog section. Qubit supports are subsets of the circuit register tied to blocks.</p> <p><code>QuantumModel</code> is another central class in Qadence. It specifies a Backend for the differentiation, compilation and execution of the abstract circuit.</p> <pre><code>from qadence import BackendName, DiffMode, QuantumCircuit, QuantumModel, Register, H, chain\nreg = Register(3)\ncirc = QuantumCircuit(reg, chain(H(0), H(1)))\nmodel = QuantumModel(circ, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD)\nxs = model.sample(n_shots=100)\n</code></pre> <pre><code>xs = [Counter({'110': 30, '100': 28, '000': 27, '010': 15})]\n</code></pre> <p>For more details on <code>QuantumModel</code>, see here.</p>"},{"location":"tutorials/hamiltonians/","title":"Constructing arbitrary Hamiltonians","text":"<p>At the heart of digital-analog quantum computing is the description and execution of analog blocks, which represent a set of interacting qubits under some interaction Hamiltonian. For this purpose, Qadence relies on the <code>hamiltonian_factory</code> function to create arbitrary Hamiltonian blocks to be used as generators of <code>HamEvo</code> or as observables to be measured.</p>"},{"location":"tutorials/hamiltonians/#arbitrary-all-to-all-hamiltonians","title":"Arbitrary all-to-all Hamiltonians","text":"<p>Arbitrary all-to-all interaction Hamiltonians can be easily created by passing the number of qubits in the first argument. The type of <code>interaction</code> can be chosen from the available ones in the <code>Interaction</code> enum type.</p> <pre><code>from qadence import hamiltonian_factory\nfrom qadence import N, X, Y, Z\nfrom qadence import Interaction\nn_qubits = 3\nhamilt = hamiltonian_factory(n_qubits, interaction=Interaction.ZZ)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(2)\n\u2514\u2500\u2500 [mul: 1.00000000000000] \u2514\u2500\u2500 KronBlock(1,2)\n\u251c\u2500\u2500 Z(1)\n\u2514\u2500\u2500 Z(2)\n</code></pre> <p>Single-qubit terms can also be added by passing the respective operator directly to the <code>detuning</code> argument. For example, the total magnetization is commonly used as an observable to be measured:</p> <pre><code>total_mag = hamiltonian_factory(n_qubits, detuning = Z)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 Z(0)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 Z(1)\n\u2514\u2500\u2500 [mul: 1.00000000000000] \u2514\u2500\u2500 Z(2)\n</code></pre> <p>For further customization, arbitrary coefficients can be passed as arrays to the <code>interaction_strength</code> and <code>detuning_strength</code> arguments for the two-qubits and single-qubit terms respectively.</p> <pre><code>n_qubits = 3\nhamilt = hamiltonian_factory(\nn_qubits,\ninteraction=Interaction.ZZ,\ndetuning=Z,\ninteraction_strength=[0.5, 0.2, 0.1],\ndetuning_strength=[0.1, 0.5, -0.3]\n)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: 0.100] \u2502   \u2514\u2500\u2500 Z(0)\n\u251c\u2500\u2500 [mul: 0.500] \u2502   \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: -0.300] \u2502   \u2514\u2500\u2500 Z(2)\n\u251c\u2500\u2500 [mul: 0.500] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(1)\n\u251c\u2500\u2500 [mul: 0.200] \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 Z(0)\n\u2502       \u2514\u2500\u2500 Z(2)\n\u2514\u2500\u2500 [mul: 0.100] \u2514\u2500\u2500 KronBlock(1,2)\n\u251c\u2500\u2500 Z(1)\n\u2514\u2500\u2500 Z(2)\n</code></pre> <p>Ordering interaction strengths matters</p> <p>When passing interaction strengths as an array, the ordering must be indentical to the one obtained from the <code>edge</code> property of a Qadence <code>Register</code>:</p> <p><pre><code>from qadence import Register\nprint(Register(n_qubits).edges)\n</code></pre> <pre><code>[(0, 1), (0, 2), (1, 2)]\n</code></pre> </p> <p>For one more example, let's create a transverse-field Ising model,</p> <pre><code>n_qubits = 4\nn_edges = int(0.5 * n_qubits * (n_qubits - 1))\nz_terms = [1.0] * n_qubits\nzz_terms = [2.0] * n_edges\nzz_ham = hamiltonian_factory(\nn_qubits,\ninteraction=Interaction.ZZ,\ndetuning=Z,\ninteraction_strength=zz_terms,\ndetuning_strength=z_terms\n)\nx_terms = [-1.0] * n_qubits\nx_ham = hamiltonian_factory(n_qubits, detuning = X, detuning_strength = x_terms)\ntransverse_ising = zz_ham + x_ham\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 AddBlock(0,1,2,3)\n\u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 Z(0)\n\u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 Z(1)\n\u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 Z(3)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(1)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502   \u2502       \u251c\u2500\u2500 Z(0)\n\u2502   \u2502       \u2514\u2500\u2500 Z(3)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502   \u2502       \u251c\u2500\u2500 Z(1)\n\u2502   \u2502       \u2514\u2500\u2500 Z(2)\n\u2502   \u251c\u2500\u2500 [mul: 2.00000000000000] \u2502   \u2502   \u2514\u2500\u2500 KronBlock(1,3)\n\u2502   \u2502       \u251c\u2500\u2500 Z(1)\n\u2502   \u2502       \u2514\u2500\u2500 Z(3)\n\u2502   \u2514\u2500\u2500 [mul: 2.00000000000000] \u2502       \u2514\u2500\u2500 KronBlock(2,3)\n\u2502           \u251c\u2500\u2500 Z(2)\n\u2502           \u2514\u2500\u2500 Z(3)\n\u2514\u2500\u2500 AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: -1.00000000000000] \u2502   \u2514\u2500\u2500 X(0)\n\u251c\u2500\u2500 [mul: -1.00000000000000] \u2502   \u2514\u2500\u2500 X(1)\n\u251c\u2500\u2500 [mul: -1.00000000000000] \u2502   \u2514\u2500\u2500 X(2)\n\u2514\u2500\u2500 [mul: -1.00000000000000] \u2514\u2500\u2500 X(3)\n</code></pre> <p>Random interaction coefficients</p> <p>Random interaction coefficients can be chosen between -1 and 1 by simply passing <code>random_strength = True</code> instead of <code>detuning_strength</code> and <code>interaction_strength</code>.</p>"},{"location":"tutorials/hamiltonians/#arbitrary-hamiltonian-topologies","title":"Arbitrary Hamiltonian topologies","text":"<p>Arbitrary interaction topologies can be created using the Qadence <code>Register</code>. Simply pass the register with the desired topology as the first argument to the <code>hamiltonian_factory</code>:</p> <pre><code>from qadence import Register\nreg = Register.square(qubits_side=2)\nsquare_hamilt = hamiltonian_factory(reg, interaction=Interaction.NN)\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(3)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: 1.00000000000000] \u2514\u2500\u2500 KronBlock(2,3)\n\u251c\u2500\u2500 N(2)\n\u2514\u2500\u2500 N(3)\n</code></pre> <p>Custom Hamiltonian coefficients can also be added to the register beforehand using the <code>\"strength\"</code> key.</p> <pre><code>reg = Register.square(qubits_side = 2)\nfor i, edge in enumerate(reg.edges):\nreg.edges[edge][\"strength\"] = (0.5 * i) ** 2\nsquare_hamilt = hamiltonian_factory(reg, interaction=Interaction.NN)\n</code></pre> <pre><code>AddBlock(0,1,2,3)\n\u251c\u2500\u2500 [mul: 0.0] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: 0.250] \u2502   \u2514\u2500\u2500 KronBlock(0,3)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(3)\n\u251c\u2500\u2500 [mul: 1.00000000000000] \u2502   \u2514\u2500\u2500 KronBlock(1,2)\n\u2502       \u251c\u2500\u2500 N(1)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: 2.250] \u2514\u2500\u2500 KronBlock(2,3)\n\u251c\u2500\u2500 N(2)\n\u2514\u2500\u2500 N(3)\n</code></pre> <p>Alternatively, if the register already stores interaction or detuning strengths, it is possible to override them in the Hamiltonian creation by using <code>force_update = True</code>.</p>"},{"location":"tutorials/hamiltonians/#adding-variational-parameters","title":"Adding variational parameters","text":"<p>Finally, fully parameterized Hamiltonians can be created by passing a string to the strength arguments:</p> <pre><code>n_qubits = 3\nnn_ham = hamiltonian_factory(\nn_qubits,\ninteraction=Interaction.NN,\ndetuning=N,\ninteraction_strength=\"c\",\ndetuning_strength=\"d\"\n)\n</code></pre> <pre><code>AddBlock(0,1,2)\n\u251c\u2500\u2500 [mul: d_0] \u2502   \u2514\u2500\u2500 N(0)\n\u251c\u2500\u2500 [mul: d_1] \u2502   \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: d_2] \u2502   \u2514\u2500\u2500 N(2)\n\u251c\u2500\u2500 [mul: c_01] \u2502   \u2514\u2500\u2500 KronBlock(0,1)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(1)\n\u251c\u2500\u2500 [mul: c_02] \u2502   \u2514\u2500\u2500 KronBlock(0,2)\n\u2502       \u251c\u2500\u2500 N(0)\n\u2502       \u2514\u2500\u2500 N(2)\n\u2514\u2500\u2500 [mul: c_12] \u2514\u2500\u2500 KronBlock(1,2)\n\u251c\u2500\u2500 N(1)\n\u2514\u2500\u2500 N(2)\n</code></pre>"},{"location":"tutorials/overlap/","title":"Wavefunction overlaps","text":"<p>Qadence offers convenience functions for computing the overlap between the wavefunctions generated by two quantum circuits \\(U\\) and \\(W\\) as:</p> \\[ S = |\\langle \\psi_U | \\psi_W \\rangle|^2 \\quad \\textrm{where} \\quad \\psi_U = U|\\psi_0\\rangle \\] <p>Here is an example on how to compute the overlap between two very simple parametric circuits consisting of a single <code>RX</code> rotation on different qubits. The overlap is expected to be non-zero only when the rotation angle is different from \\(\\pi \\; \\textrm{mod}\\; 2\\pi\\) for both rotations:</p> <pre><code>import torch\nimport numpy as np\nfrom qadence import Overlap, OverlapMethod, QuantumCircuit, H, RX, X, FeatureParameter, hea\n# Create two quantum circuits\n# with a single qubit rotation on two random qubits\nn_qubits = 4\nqubits = np.random.choice(list(range(n_qubits)), n_qubits, replace=True)\nphi = FeatureParameter(\"phi\")\ncircuit_bra = QuantumCircuit(n_qubits, RX(qubits[0], phi))\npsi = FeatureParameter(\"psi\")\ncircuit_ket = QuantumCircuit(n_qubits, RX(qubits[1], psi))\n# Values for the feature parameters\nvalues_bra = {\"phi\": torch.Tensor([torch.pi / 2, torch.pi])}\nvalues_ket = {\"psi\": torch.Tensor([torch.pi / 2, torch.pi])}\n# Calculate overlap by assigning values to the given bra and ket circuits\novrlp = Overlap(circuit_bra, circuit_ket)\novrlp = ovrlp(bra_param_values=values_bra, ket_param_values=values_ket)\n</code></pre> <pre><code>Overlap with exact method:\ntensor([[2.5000e-01, 1.8747e-33],\n[1.8747e-33, 1.4058e-65]])\n</code></pre> <p>The <code>Overlap</code> class above inherits from <code>QuantumModel</code> and is executed through its inherited forward method for the given input parameter values. By default, the overlap is computed exactly by performing the dot product of the wavefunction propagated from bra and ket circuits.</p> <p>However, it is possible to choose a different method from the <code>OverlapMethod</code> enumeration to be passed via the <code>overlap_method</code> argument in the <code>Overlap</code> initializer. Currently, one can choose from:</p> <ul> <li><code>EXACT</code>: exact computation using the wavefunction matrix representation. Does not work with real devices since it assumes access to the complete qubit system wavefunction.</li> <li><code>COMPUTE_UNCOMPUTE</code>: exact or sampling-based computation using bra \\(U\\) and ket \\(W^{\\dagger}\\) unitaries.</li> <li><code>SWAP_TEST</code>: exact or sampling-based computation using the SWAP test method.</li> <li><code>HADAMARD_TEST</code>: exact or sampling-based computation using the Hadamard test method.</li> <li><code>JENSEN_SHANNON</code>: compute the overlap using the Jensen-Shannon divergence of the two probability distributions obtained by sampling the propagated circuits. This will yield a different result than the other methods.</li> </ul> <p>All methods (except for the <code>EXACT</code> method) take an optional <code>n_shots</code> argument which can be used to perform shot-based calculations.</p> <p>Warning</p> <p>If you select a finite number of shots, the overlap is not differentiable. Therefore, it cannot be used as output of a quantum model if gradients are required.</p> <pre><code># Calculate overlap with SWAP test\novrlp = Overlap(circuit_bra, circuit_ket, method=OverlapMethod.SWAP_TEST)\novrlp_ha = ovrlp(values_bra, values_ket)\n# Calculate overlap with SWAP test\n# using a finite number of shots\novrlp = Overlap(circuit_bra, circuit_ket, method=OverlapMethod.SWAP_TEST)\novrlp_ha = ovrlp(values_bra, values_ket, n_shots=10_000)\n</code></pre> <pre><code>Overlap with SWAP test:\ntensor([[ 2.5000e-01, -3.3307e-16],\n[-3.3307e-16, -4.4409e-16]])\nOverlap with SWAP test with finite number of shots:\ntensor([[ 0.2540, -0.0092],\n[-0.0006, -0.0004]])\n</code></pre>"},{"location":"tutorials/parameters/","title":"Parametric programs","text":"<p>Qadence base <code>Parameter</code> type is a subtype of <code>sympy.Symbol</code>. There are three kinds of parameter subtypes used:</p> <ul> <li>Fixed Parameter: A constant with a fixed, non-trainable value (e.g. \\(\\dfrac{\\pi}{2}\\)).</li> <li>Variational Parameter: A trainable parameter which can be be optimized.</li> <li>Feature Parameter: A non-trainable parameter which can be used to encode classical data into a quantum state.</li> </ul>"},{"location":"tutorials/parameters/#fixed-parameters","title":"Fixed Parameters","text":"<p>To pass a fixed parameter to a gate (or any parametrizable block), one can simply use either Python numeric types or wrapped in a <code>torch.Tensor</code>.</p> <pre><code>from torch import pi\nfrom qadence import RX, run\n# Let's use a torch type.\nblock = RX(0, pi)\nwf = run(block)\n# Let's pass a simple float.\nblock = RX(0, 1.)\nwf = run(block)\n</code></pre> <pre><code>wf = tensor([[6.1232e-17+0.j, 0.0000e+00-1.j]])\nwf = tensor([[0.8776+0.0000j, 0.0000-0.4794j]])\n</code></pre>"},{"location":"tutorials/parameters/#variational-parameters","title":"Variational Parameters","text":"<p>To parametrize a block by an angle <code>theta</code>, either a Python <code>string</code> or an instance of  <code>VariationalParameter</code> can be passed instead of a numeric type to the gate constructor:</p> <pre><code>from qadence import RX, run, VariationalParameter\nblock = RX(0, \"theta\")\n# This is equivalent to:\nblock = RX(0, VariationalParameter(\"theta\"))\nwf = run(block)\n</code></pre> <pre><code>wf = tensor([[0.9868+0.0000j, 0.0000-0.1621j]])\n</code></pre> <p>In the first case in the above example, <code>theta</code> is automatically inferred as a <code>VariationalParameter</code> (i.e. trainable). It is initialized to a random value for the purposes of execution. In the context of a <code>QuantumModel</code>, there is no need to pass a value for <code>theta</code> to the <code>run</code> method since it is stored within the underlying model parameter dictionary.</p>"},{"location":"tutorials/parameters/#feature-parameters","title":"Feature Parameters","text":"<p><code>FeatureParameter</code> types (i.e. inputs), always need to be provided with a value or a batch of values as a dictionary:</p> <pre><code>from torch import tensor\nfrom qadence import RX, run, FeatureParameter\nblock = RX(0, FeatureParameter(\"phi\"))\nwf = run(block, values={\"phi\": tensor([1., 2.])})\n</code></pre> <pre><code>wf = tensor([[0.8776+0.0000j, 0.0000-0.4794j],\n[0.5403+0.0000j, 0.0000-0.8415j]])\n</code></pre> <p>Now, <code>run</code> returns a batch of states, one for every provided angle which coincides with the value of the particular <code>FeatureParameter</code>.</p>"},{"location":"tutorials/parameters/#multiparameter-expressions","title":"Multiparameter Expressions","text":"<p>However, an angle can itself be an expression <code>Parameter</code> types of any kind. As such, any sympy expression <code>expr: sympy.Basic</code> consisting of a combination of free symbols (i.e. <code>sympy</code> types) and Qadence <code>Parameter</code> can be passed to a block, including trigonometric functions.</p> <pre><code>from torch import tensor\nfrom qadence import RX, Parameter, run, FeatureParameter\nfrom sympy import sin\ntheta, phi = Parameter(\"theta\"), FeatureParameter(\"phi\")\nblock = RX(0, sin(theta+phi))\n# Remember, to run the block, only FeatureParameter values have to be provided:\nvalues = {\"phi\": tensor([1.0, 2.0])}\nwf = run(block, values=values)\n</code></pre> <pre><code>wf = tensor([[0.8778+0.0000j, 0.0000-0.4791j],\n[0.9593+0.0000j, 0.0000-0.2825j]])\n</code></pre>"},{"location":"tutorials/parameters/#parameters-redundancy","title":"Parameters Redundancy","text":"<p>Parameters are uniquely defined by their name and redundancy is allowed in composite blocks to assign the same value to different blocks.</p> <pre><code>import torch\nfrom qadence import RX, RY, run, chain, kron\nblock = chain(\nkron(RX(0, \"phi\"), RY(1, \"theta\")),\nkron(RX(0, \"phi\"), RY(1, \"theta\")),\n)\nwf = run(block)  # Same random initialization for all instances of phi and theta.\n</code></pre> <pre><code>wf = tensor([[0.5086+0.0000j, 0.6844+0.0000j, 0.0000-0.3116j, 0.0000-0.4194j]])\n</code></pre>"},{"location":"tutorials/parameters/#parametrized-circuits","title":"Parametrized Circuits","text":"<p>Now, let's have a look at the construction of a variational ansatz which composes <code>FeatureParameter</code> and <code>VariationalParameter</code> types:</p> <pre><code>import sympy\nfrom qadence import RX, RY, RZ, CNOT, Z, run, chain, kron, FeatureParameter, VariationalParameter\nphi = FeatureParameter(\"phi\")\ntheta = VariationalParameter(\"theta\")\nblock = chain(\nkron(\nRX(0, phi/theta),\nRY(1, theta*2),\nRZ(2, sympy.cos(phi)),\n),\nkron(\nRX(0, phi),\nRY(1, theta),\nRZ(2, phi),\n),\nkron(\nRX(0, phi),\nRY(1, theta),\nRZ(2, phi),\n),\nkron(\nRX(0, phi + theta),\nRY(1, theta**2),\nRZ(2, sympy.cos(phi)),\n),\nchain(CNOT(0,1), CNOT(1,2))\n)\nblock.tag = \"Rotations\"\nobs = 2*kron(*map(Z, range(3)))\nblock = chain(block, obs)\n</code></pre> cluster_99aaecddd5bd4e149b9fc612fa5031fe [* 2] cluster_0db3700bb25347939dba49b6a78200c7 Rotations f09ef6a63afc41d1878134a77515d5ac 0 be3a4deeb56c4121bd17d4abfaada3d0 RX(phi/theta) f09ef6a63afc41d1878134a77515d5ac--be3a4deeb56c4121bd17d4abfaada3d0 79a9b2a81dca4affaa7c151f8b292070 1 3b0f274e358943039679f31c2f29ba34 RX(phi) be3a4deeb56c4121bd17d4abfaada3d0--3b0f274e358943039679f31c2f29ba34 562d61ea5b6f40d6b06067a01561b233 RX(phi) 3b0f274e358943039679f31c2f29ba34--562d61ea5b6f40d6b06067a01561b233 5705c2bdbefc43018a371629c4d063f5 RX(phi + theta) 562d61ea5b6f40d6b06067a01561b233--5705c2bdbefc43018a371629c4d063f5 7d0c21da5e294077b9a082d8f666cc02 5705c2bdbefc43018a371629c4d063f5--7d0c21da5e294077b9a082d8f666cc02 4b96064205ab4393ad8019719358be49 7d0c21da5e294077b9a082d8f666cc02--4b96064205ab4393ad8019719358be49 dac053bc7d3b4cdb9bf92f40d8a63336 Z 4b96064205ab4393ad8019719358be49--dac053bc7d3b4cdb9bf92f40d8a63336 b3bbf8d696dc4616a81d71110c1fff88 dac053bc7d3b4cdb9bf92f40d8a63336--b3bbf8d696dc4616a81d71110c1fff88 a75d7bb5a3ac42db8c809168a808b2fc 7cfc56fe43af45a4b593f593e0cd1ea6 RY(2*theta) 79a9b2a81dca4affaa7c151f8b292070--7cfc56fe43af45a4b593f593e0cd1ea6 631b31a53fd24a768befcb1877ab74bc 2 752f753dc14a426ea4be1fe9afce3385 RY(theta) 7cfc56fe43af45a4b593f593e0cd1ea6--752f753dc14a426ea4be1fe9afce3385 ea221eed2ea44ddb83c176c04add31ba RY(theta) 752f753dc14a426ea4be1fe9afce3385--ea221eed2ea44ddb83c176c04add31ba e77f77efe147404ca449a49c9423181e RY(theta**2) ea221eed2ea44ddb83c176c04add31ba--e77f77efe147404ca449a49c9423181e f1cf5c87eeb54a688f8822397b711b55 X e77f77efe147404ca449a49c9423181e--f1cf5c87eeb54a688f8822397b711b55 f1cf5c87eeb54a688f8822397b711b55--7d0c21da5e294077b9a082d8f666cc02 fb4db1b7fa6f4883b6fefdc5c841433b f1cf5c87eeb54a688f8822397b711b55--fb4db1b7fa6f4883b6fefdc5c841433b 2a22301f8dc8483c93cb6014af8f2147 Z fb4db1b7fa6f4883b6fefdc5c841433b--2a22301f8dc8483c93cb6014af8f2147 2a22301f8dc8483c93cb6014af8f2147--a75d7bb5a3ac42db8c809168a808b2fc f1db3c0afc9b4150a4e29a4de03e2d0e 6734b9d5d5924179bdeec6bf6c4e3a16 RZ(cos(phi)) 631b31a53fd24a768befcb1877ab74bc--6734b9d5d5924179bdeec6bf6c4e3a16 4fabe40377d3405b871dcb28812428bc RZ(phi) 6734b9d5d5924179bdeec6bf6c4e3a16--4fabe40377d3405b871dcb28812428bc c41f56445d584fabb0b788c2a5b5892c RZ(phi) 4fabe40377d3405b871dcb28812428bc--c41f56445d584fabb0b788c2a5b5892c 811a91aafc3b4ebdbd31341c003a3b0d RZ(cos(phi)) c41f56445d584fabb0b788c2a5b5892c--811a91aafc3b4ebdbd31341c003a3b0d d571793471f14a2085d98814d0e24b69 811a91aafc3b4ebdbd31341c003a3b0d--d571793471f14a2085d98814d0e24b69 36213d9f7b604db78239ab86aa3020bd X d571793471f14a2085d98814d0e24b69--36213d9f7b604db78239ab86aa3020bd 36213d9f7b604db78239ab86aa3020bd--fb4db1b7fa6f4883b6fefdc5c841433b 9109e3a4f13c4e1fbd0aeb90521ad657 Z 36213d9f7b604db78239ab86aa3020bd--9109e3a4f13c4e1fbd0aeb90521ad657 9109e3a4f13c4e1fbd0aeb90521ad657--f1db3c0afc9b4150a4e29a4de03e2d0e <p>Please note the different colors for the parametrization with different types. The default palette assigns light blue for <code>VariationalParameter</code>, light green for <code>FeatureParameter</code> and shaded red for observables.</p>"},{"location":"tutorials/parameters/#parametrized-quantummodels","title":"Parametrized QuantumModels","text":"<p>As a quick reminder: <code>FeatureParameter</code> are used for data input and data encoding into a quantum state. <code>VariationalParameter</code> are trainable parameters in a variational ansatz. When used within a <code>QuantumModel</code>, an abstract quantum circuit is made differentiable with respect to both variational and feature parameters which are uniquely identified by their name.</p> <pre><code>from qadence import FeatureParameter, Parameter, VariationalParameter\n# Feature parameters are non-trainable parameters.\n# Their primary use is input data encoding.\nfp = FeatureParameter(\"x\")\nassert fp == Parameter(\"x\", trainable=False)\n# Variational parameters are trainable parameters.\n# Their primary use is for optimization.\nvp = VariationalParameter(\"y\")\nassert vp == Parameter(\"y\", trainable=True)\n</code></pre> <p>Let's construct a parametric quantum circuit.</p> <pre><code>from qadence import QuantumCircuit, RX, RY, chain, kron\ntheta = VariationalParameter(\"theta\")\nphi = FeatureParameter(\"phi\")\nblock = chain(\nkron(RX(0, theta), RY(1, theta)),\nkron(RX(0, phi), RY(1, phi)),\n)\ncircuit = QuantumCircuit(2, block)\nunique_params = circuit.unique_parameters\n</code></pre> <pre><code>unique_params = [theta, phi]\n</code></pre> <p>In the circuit above, four parameters are defined but only two unique names. Therefore, there will be only one variational parameter to be optimized.</p> <p>The <code>QuantumModel</code> class also provides convenience methods to manipulate parameters.</p> <pre><code>from qadence import QuantumModel, BackendName, DiffMode\nmodel = QuantumModel(circuit, backend=BackendName.PYQTORCH, diff_mode=DiffMode.AD)\nnum_vparams = model.num_vparams\nvparams_values = model.vparams\n</code></pre> <pre><code>num_vparams = 1\nvparams_values = OrderedDict([('theta', tensor([0.6171]))])\n</code></pre> <p>Only provide feature parameter values to the quantum model</p> <p>In order to <code>run</code> the variational circuit only feature parameter values have to be provided. Variational parameters are stored in the model itself. If multiple feature parameters are present, values must be provided in batches of same length.</p> <p><pre><code>import torch\nvalues = {\"phi\": torch.rand(3)} # theta does not appear here\nwf = model.run(values)\n</code></pre> <pre><code>wf = tensor([[0.5703+0.0000j, 0.4950+0.0000j, 0.0000-0.4950j, 0.0000-0.4297j],\n[0.8421+0.0000j, 0.3647+0.0000j, 0.0000-0.3647j, 0.0000-0.1579j],\n[0.8410+0.0000j, 0.3656+0.0000j, 0.0000-0.3656j, 0.0000-0.1590j]],\ngrad_fn=&lt;TBackward0&gt;)\n</code></pre> </p>"},{"location":"tutorials/parameters/#standard-constructors","title":"Standard constructors","text":"<p>The unique parameter identification is relevant when using built-in Qadence block constructors in the <code>qadence.constructors</code> module such as feature maps and hardware efficient ansatze (HEA).</p> <p><pre><code>from qadence import QuantumCircuit, hea\nn_qubits = 4\ndepth = 2\nhea1 = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, hea1)\nnum_unique_parameters = circuit.num_unique_parameters\n</code></pre> <pre><code>Unique parameters with a single HEA: 24\n</code></pre> aeaa4c668fb844e2a2215b789cb75f85 0 2b52428bb4e04a07b0e174a514729521 RX(theta\u2080) aeaa4c668fb844e2a2215b789cb75f85--2b52428bb4e04a07b0e174a514729521 dcb9d6ca8acc406d93d3f4a6ea9e0be0 1 476fd8fe81c14af5b13687529162f8de RY(theta\u2084) 2b52428bb4e04a07b0e174a514729521--476fd8fe81c14af5b13687529162f8de 01b516e51bbd428a9e5b71de22dae93f RX(theta\u2088) 476fd8fe81c14af5b13687529162f8de--01b516e51bbd428a9e5b71de22dae93f 5ad0be2fdaad4214adea763746428f6d 01b516e51bbd428a9e5b71de22dae93f--5ad0be2fdaad4214adea763746428f6d b11b977cd95443888c467ac474d4e693 5ad0be2fdaad4214adea763746428f6d--b11b977cd95443888c467ac474d4e693 7b8bccddbb574c0c9c0b5f81a33790f6 RX(theta\u2081\u2082) b11b977cd95443888c467ac474d4e693--7b8bccddbb574c0c9c0b5f81a33790f6 5d2808aeff3944508ae77f11ab2d79aa RY(theta\u2081\u2086) 7b8bccddbb574c0c9c0b5f81a33790f6--5d2808aeff3944508ae77f11ab2d79aa f01b56163b4f4a6da373a66b5d8adef4 RX(theta\u2082\u2080) 5d2808aeff3944508ae77f11ab2d79aa--f01b56163b4f4a6da373a66b5d8adef4 f2e23e930ff347e7a733f27272d23323 f01b56163b4f4a6da373a66b5d8adef4--f2e23e930ff347e7a733f27272d23323 e586398740f3488c8f6877ffaef00cf8 f2e23e930ff347e7a733f27272d23323--e586398740f3488c8f6877ffaef00cf8 1b9f8586e4d64208923d3cc4633185c8 e586398740f3488c8f6877ffaef00cf8--1b9f8586e4d64208923d3cc4633185c8 74c900b21ba34b4fb1cbaa97f79a8055 ad8995601425439f8912cc53b3e410c4 RX(theta\u2081) dcb9d6ca8acc406d93d3f4a6ea9e0be0--ad8995601425439f8912cc53b3e410c4 63fb0f8d65944e3283bc6590fdf2bfcc 2 4c8953cb9b1f4f33a312a94f3353d9a2 RY(theta\u2085) ad8995601425439f8912cc53b3e410c4--4c8953cb9b1f4f33a312a94f3353d9a2 6f1a794b9f5f4c6293052592cf34a67e RX(theta\u2089) 4c8953cb9b1f4f33a312a94f3353d9a2--6f1a794b9f5f4c6293052592cf34a67e f429c9d7ce2b445cba5102ed32389a07 X 6f1a794b9f5f4c6293052592cf34a67e--f429c9d7ce2b445cba5102ed32389a07 f429c9d7ce2b445cba5102ed32389a07--5ad0be2fdaad4214adea763746428f6d 0f563795fa6c4b2b919de7bf0a85af27 f429c9d7ce2b445cba5102ed32389a07--0f563795fa6c4b2b919de7bf0a85af27 f0ae37dea4b0428189c5c9d93f05eda8 RX(theta\u2081\u2083) 0f563795fa6c4b2b919de7bf0a85af27--f0ae37dea4b0428189c5c9d93f05eda8 0f735ba3155740bf8d73a97dfb481c01 RY(theta\u2081\u2087) f0ae37dea4b0428189c5c9d93f05eda8--0f735ba3155740bf8d73a97dfb481c01 8bf582907a1c4a6688fb8f1adb6c56a5 RX(theta\u2082\u2081) 0f735ba3155740bf8d73a97dfb481c01--8bf582907a1c4a6688fb8f1adb6c56a5 838c73f9074449c0a209cce5b7e94b89 X 8bf582907a1c4a6688fb8f1adb6c56a5--838c73f9074449c0a209cce5b7e94b89 838c73f9074449c0a209cce5b7e94b89--f2e23e930ff347e7a733f27272d23323 d438b811957c445ba9f2bc44033e293b 838c73f9074449c0a209cce5b7e94b89--d438b811957c445ba9f2bc44033e293b d438b811957c445ba9f2bc44033e293b--74c900b21ba34b4fb1cbaa97f79a8055 3007e8419d104508ae7813555d12db54 e6e5a28007ed40bcb5dc50c4738951d8 RX(theta\u2082) 63fb0f8d65944e3283bc6590fdf2bfcc--e6e5a28007ed40bcb5dc50c4738951d8 35f8697a1e37428cb522ff68f14b9fe3 3 3ccab30bc08b4eacb962be344a811766 RY(theta\u2086) e6e5a28007ed40bcb5dc50c4738951d8--3ccab30bc08b4eacb962be344a811766 5fc6d83a29864bb699c1577abf3dad21 RX(theta\u2081\u2080) 3ccab30bc08b4eacb962be344a811766--5fc6d83a29864bb699c1577abf3dad21 16fb360171864b17987a421a4e3055bd 5fc6d83a29864bb699c1577abf3dad21--16fb360171864b17987a421a4e3055bd 9b39b13ea0ae4fa6b9fd3871bd607451 X 16fb360171864b17987a421a4e3055bd--9b39b13ea0ae4fa6b9fd3871bd607451 9b39b13ea0ae4fa6b9fd3871bd607451--0f563795fa6c4b2b919de7bf0a85af27 491ebabebc064114a9043b16a60cc486 RX(theta\u2081\u2084) 9b39b13ea0ae4fa6b9fd3871bd607451--491ebabebc064114a9043b16a60cc486 2f91c971801c4672874db87cb29df063 RY(theta\u2081\u2088) 491ebabebc064114a9043b16a60cc486--2f91c971801c4672874db87cb29df063 300d5a25e8d746ae8d1535139322e6bf RX(theta\u2082\u2082) 2f91c971801c4672874db87cb29df063--300d5a25e8d746ae8d1535139322e6bf db14b8ac4eb5430892f3c6e7df92f37a 300d5a25e8d746ae8d1535139322e6bf--db14b8ac4eb5430892f3c6e7df92f37a dbb5aecbaa7e4b6a88ae76a962c0f822 X db14b8ac4eb5430892f3c6e7df92f37a--dbb5aecbaa7e4b6a88ae76a962c0f822 dbb5aecbaa7e4b6a88ae76a962c0f822--d438b811957c445ba9f2bc44033e293b dbb5aecbaa7e4b6a88ae76a962c0f822--3007e8419d104508ae7813555d12db54 3a0feacb52794f3abf15a53d3df79b2c 5c155c3547b648e09a8f68e16974deff RX(theta\u2083) 35f8697a1e37428cb522ff68f14b9fe3--5c155c3547b648e09a8f68e16974deff 7553b607fb8346c9a9dd6e55214e9186 RY(theta\u2087) 5c155c3547b648e09a8f68e16974deff--7553b607fb8346c9a9dd6e55214e9186 900aedd86482401ab85fdb46229db396 RX(theta\u2081\u2081) 7553b607fb8346c9a9dd6e55214e9186--900aedd86482401ab85fdb46229db396 173e05d0855243a2a22643626a9ed9bc X 900aedd86482401ab85fdb46229db396--173e05d0855243a2a22643626a9ed9bc 173e05d0855243a2a22643626a9ed9bc--16fb360171864b17987a421a4e3055bd 931f51e3fde242c99af9e2f08bdb295c 173e05d0855243a2a22643626a9ed9bc--931f51e3fde242c99af9e2f08bdb295c 19fb4365b57841e9ae2fe9d7783d18f1 RX(theta\u2081\u2085) 931f51e3fde242c99af9e2f08bdb295c--19fb4365b57841e9ae2fe9d7783d18f1 91c150879a4941ccbc41e2db68db8afc RY(theta\u2081\u2089) 19fb4365b57841e9ae2fe9d7783d18f1--91c150879a4941ccbc41e2db68db8afc 221fc74a2d2f4338b8340ff357d65267 RX(theta\u2082\u2083) 91c150879a4941ccbc41e2db68db8afc--221fc74a2d2f4338b8340ff357d65267 19dd917a5d174a62b56db6eb33d19592 X 221fc74a2d2f4338b8340ff357d65267--19dd917a5d174a62b56db6eb33d19592 19dd917a5d174a62b56db6eb33d19592--db14b8ac4eb5430892f3c6e7df92f37a b4a635a42635453bb893372c36a5b57f 19dd917a5d174a62b56db6eb33d19592--b4a635a42635453bb893372c36a5b57f b4a635a42635453bb893372c36a5b57f--3a0feacb52794f3abf15a53d3df79b2c </p> <p>A new circuit can be created by adding another identical HEA. As expected, the number of unique parameters is the same.</p> <p><pre><code>hea2 = hea(n_qubits=n_qubits, depth=depth)\ncircuit = QuantumCircuit(n_qubits, hea1, hea2)\nnum_unique_params_two_heas = circuit.num_unique_parameters\n</code></pre> <pre><code>Unique parameters with two stacked HEAs: 24\n</code></pre> cluster_8f37830d26d74223a9c4617a0383761c HEA cluster_1e012beeb7e34cf29c93d0775bdcb736 HEA 5a8df5fff42344d7b7cbc38a9dcaa2b4 0 390154e2affb4475969a2adc14b39e28 RX(theta\u2080) 5a8df5fff42344d7b7cbc38a9dcaa2b4--390154e2affb4475969a2adc14b39e28 a5d05120b58649008040c99f4b625942 1 3fdd43e62b87489c99cb773de48e79b6 RY(theta\u2084) 390154e2affb4475969a2adc14b39e28--3fdd43e62b87489c99cb773de48e79b6 d7c94be98805417f95f3b8072a0ea704 RX(theta\u2088) 3fdd43e62b87489c99cb773de48e79b6--d7c94be98805417f95f3b8072a0ea704 525804271b5f4014babb91c61c13599d d7c94be98805417f95f3b8072a0ea704--525804271b5f4014babb91c61c13599d 644d885b472e499c85cb28f5362f6cc0 525804271b5f4014babb91c61c13599d--644d885b472e499c85cb28f5362f6cc0 ee60866518b24b5c94793e6481311216 RX(theta\u2081\u2082) 644d885b472e499c85cb28f5362f6cc0--ee60866518b24b5c94793e6481311216 de223fc870bd43d2b7cd31870506b9a0 RY(theta\u2081\u2086) ee60866518b24b5c94793e6481311216--de223fc870bd43d2b7cd31870506b9a0 894db6a9ea86450186db14a9e47fdc65 RX(theta\u2082\u2080) de223fc870bd43d2b7cd31870506b9a0--894db6a9ea86450186db14a9e47fdc65 cc32b2ea530341d6a3210d991cce01b5 894db6a9ea86450186db14a9e47fdc65--cc32b2ea530341d6a3210d991cce01b5 8eafda4718d94590ba080127f2550fbf cc32b2ea530341d6a3210d991cce01b5--8eafda4718d94590ba080127f2550fbf 70202423b9dc44899b052f9d7118d7b0 RX(theta\u2080) 8eafda4718d94590ba080127f2550fbf--70202423b9dc44899b052f9d7118d7b0 c8bf60511fba4cdb9a537813c4ff4c14 RY(theta\u2084) 70202423b9dc44899b052f9d7118d7b0--c8bf60511fba4cdb9a537813c4ff4c14 2287d8db87714b18a7bc23d1e44b977b RX(theta\u2088) c8bf60511fba4cdb9a537813c4ff4c14--2287d8db87714b18a7bc23d1e44b977b 74f5e83d74aa4aeba6fbf14785df254d 2287d8db87714b18a7bc23d1e44b977b--74f5e83d74aa4aeba6fbf14785df254d 6cae0422df4446b5990f1c1fa9f337ff 74f5e83d74aa4aeba6fbf14785df254d--6cae0422df4446b5990f1c1fa9f337ff b51b5df4091b4affbdfc3b0bc39ed3b1 RX(theta\u2081\u2082) 6cae0422df4446b5990f1c1fa9f337ff--b51b5df4091b4affbdfc3b0bc39ed3b1 f0983c153e994c3993177ac92a1df3f8 RY(theta\u2081\u2086) b51b5df4091b4affbdfc3b0bc39ed3b1--f0983c153e994c3993177ac92a1df3f8 1a3399c3c126459ea0c03ece7ba30be3 RX(theta\u2082\u2080) f0983c153e994c3993177ac92a1df3f8--1a3399c3c126459ea0c03ece7ba30be3 32e989a001bd43029b63aab7d84920af 1a3399c3c126459ea0c03ece7ba30be3--32e989a001bd43029b63aab7d84920af 7597494ded6148c587dc4fd6bf0e6eee 32e989a001bd43029b63aab7d84920af--7597494ded6148c587dc4fd6bf0e6eee 6be44098c2c74038b338cee499120460 7597494ded6148c587dc4fd6bf0e6eee--6be44098c2c74038b338cee499120460 899494bf07a44859a42d7187aaf948c8 3f352e9ad1c8404da24f52392796253a RX(theta\u2081) a5d05120b58649008040c99f4b625942--3f352e9ad1c8404da24f52392796253a 60c283f03d004368a7df0afa7e0b460f 2 d95a06dd04b7471db206e31efe30baa9 RY(theta\u2085) 3f352e9ad1c8404da24f52392796253a--d95a06dd04b7471db206e31efe30baa9 6ed922bdd4f843408e0f3eabc53f7f64 RX(theta\u2089) d95a06dd04b7471db206e31efe30baa9--6ed922bdd4f843408e0f3eabc53f7f64 e56ef7b9bec1405bbc812a12ba64791f X 6ed922bdd4f843408e0f3eabc53f7f64--e56ef7b9bec1405bbc812a12ba64791f e56ef7b9bec1405bbc812a12ba64791f--525804271b5f4014babb91c61c13599d b0a5e41869af44209c5668ba779e1fd5 e56ef7b9bec1405bbc812a12ba64791f--b0a5e41869af44209c5668ba779e1fd5 2635ea4bea1d4c56831a28e41199f614 RX(theta\u2081\u2083) b0a5e41869af44209c5668ba779e1fd5--2635ea4bea1d4c56831a28e41199f614 39fb78836c5b471fb1690faa493277db RY(theta\u2081\u2087) 2635ea4bea1d4c56831a28e41199f614--39fb78836c5b471fb1690faa493277db ccf1e23b750540ea81f9e9e47d3402b9 RX(theta\u2082\u2081) 39fb78836c5b471fb1690faa493277db--ccf1e23b750540ea81f9e9e47d3402b9 c38e6ee606314368a1405e6b2be96a26 X ccf1e23b750540ea81f9e9e47d3402b9--c38e6ee606314368a1405e6b2be96a26 c38e6ee606314368a1405e6b2be96a26--cc32b2ea530341d6a3210d991cce01b5 7264d52155a14575aab81f0ffb84268f c38e6ee606314368a1405e6b2be96a26--7264d52155a14575aab81f0ffb84268f de23358d8a2d4212b313d567debbb7c1 RX(theta\u2081) 7264d52155a14575aab81f0ffb84268f--de23358d8a2d4212b313d567debbb7c1 9785a619e9954fdf93013d343814299e RY(theta\u2085) de23358d8a2d4212b313d567debbb7c1--9785a619e9954fdf93013d343814299e 00bee544129a47f997018181ecfc21dc RX(theta\u2089) 9785a619e9954fdf93013d343814299e--00bee544129a47f997018181ecfc21dc e426469b6cce42e094d567f848de87e0 X 00bee544129a47f997018181ecfc21dc--e426469b6cce42e094d567f848de87e0 e426469b6cce42e094d567f848de87e0--74f5e83d74aa4aeba6fbf14785df254d dff2125846694565b675dd21f583cac6 e426469b6cce42e094d567f848de87e0--dff2125846694565b675dd21f583cac6 4e92ccd4a8934c318ebb65c2358b8d51 RX(theta\u2081\u2083) dff2125846694565b675dd21f583cac6--4e92ccd4a8934c318ebb65c2358b8d51 30edcf1fc1964286b26d8862386006b8 RY(theta\u2081\u2087) 4e92ccd4a8934c318ebb65c2358b8d51--30edcf1fc1964286b26d8862386006b8 550bc9ad21224eeaafd21aa883d37160 RX(theta\u2082\u2081) 30edcf1fc1964286b26d8862386006b8--550bc9ad21224eeaafd21aa883d37160 0ff43e59cf6b4d199801bde036f0262d X 550bc9ad21224eeaafd21aa883d37160--0ff43e59cf6b4d199801bde036f0262d 0ff43e59cf6b4d199801bde036f0262d--32e989a001bd43029b63aab7d84920af bbdec8c229914c64bc656c67ecc050fe 0ff43e59cf6b4d199801bde036f0262d--bbdec8c229914c64bc656c67ecc050fe bbdec8c229914c64bc656c67ecc050fe--899494bf07a44859a42d7187aaf948c8 645adbf4b55c4b5b9b7d2d59f92c9254 60e2b3a7d6f940b389244b9217f877d8 RX(theta\u2082) 60c283f03d004368a7df0afa7e0b460f--60e2b3a7d6f940b389244b9217f877d8 89e2af1da7454b9d87fba90e124bc865 3 b464ab5e49ee45db8c090b5b939ab60f RY(theta\u2086) 60e2b3a7d6f940b389244b9217f877d8--b464ab5e49ee45db8c090b5b939ab60f f5377638559d45a4baea4258b3aef445 RX(theta\u2081\u2080) b464ab5e49ee45db8c090b5b939ab60f--f5377638559d45a4baea4258b3aef445 ff0f05f3ea1b4e1bb8287ab1b11934b7 f5377638559d45a4baea4258b3aef445--ff0f05f3ea1b4e1bb8287ab1b11934b7 5cfe19f3794242b8b2b2ad36aeb3b35d X ff0f05f3ea1b4e1bb8287ab1b11934b7--5cfe19f3794242b8b2b2ad36aeb3b35d 5cfe19f3794242b8b2b2ad36aeb3b35d--b0a5e41869af44209c5668ba779e1fd5 7aec19bc590a44e4997512474721ffb3 RX(theta\u2081\u2084) 5cfe19f3794242b8b2b2ad36aeb3b35d--7aec19bc590a44e4997512474721ffb3 39655b86c5104b039be60a49b5aeb787 RY(theta\u2081\u2088) 7aec19bc590a44e4997512474721ffb3--39655b86c5104b039be60a49b5aeb787 779670df53b443cbb85c186f33dc8b9a RX(theta\u2082\u2082) 39655b86c5104b039be60a49b5aeb787--779670df53b443cbb85c186f33dc8b9a ac7cf61e92d3450ca7e769cb96704e52 779670df53b443cbb85c186f33dc8b9a--ac7cf61e92d3450ca7e769cb96704e52 2caf8ed4185b456baf131322afef0084 X ac7cf61e92d3450ca7e769cb96704e52--2caf8ed4185b456baf131322afef0084 2caf8ed4185b456baf131322afef0084--7264d52155a14575aab81f0ffb84268f 62b844a4dd5747d1b4ee1c1b7be8ad32 RX(theta\u2082) 2caf8ed4185b456baf131322afef0084--62b844a4dd5747d1b4ee1c1b7be8ad32 b3a4dcddfc08467c833c5d1782b4ffd9 RY(theta\u2086) 62b844a4dd5747d1b4ee1c1b7be8ad32--b3a4dcddfc08467c833c5d1782b4ffd9 0347414682ee4775ba1a5d6ca5215a73 RX(theta\u2081\u2080) b3a4dcddfc08467c833c5d1782b4ffd9--0347414682ee4775ba1a5d6ca5215a73 be133ba05bc44a3bb8fb38b41af21c37 0347414682ee4775ba1a5d6ca5215a73--be133ba05bc44a3bb8fb38b41af21c37 4b728a0a1a174d128614b3e42d650684 X be133ba05bc44a3bb8fb38b41af21c37--4b728a0a1a174d128614b3e42d650684 4b728a0a1a174d128614b3e42d650684--dff2125846694565b675dd21f583cac6 b827fcbbfa7744f2a3fcc1cce19f3f83 RX(theta\u2081\u2084) 4b728a0a1a174d128614b3e42d650684--b827fcbbfa7744f2a3fcc1cce19f3f83 27b2e4c08f504a91902c131cc2dc7502 RY(theta\u2081\u2088) b827fcbbfa7744f2a3fcc1cce19f3f83--27b2e4c08f504a91902c131cc2dc7502 68c69a3e6c14489099919d50779183bd RX(theta\u2082\u2082) 27b2e4c08f504a91902c131cc2dc7502--68c69a3e6c14489099919d50779183bd 72f623ef5a844188b2fb41cbd82d6f33 68c69a3e6c14489099919d50779183bd--72f623ef5a844188b2fb41cbd82d6f33 74fb8e92ee324cc98985d710b5b94d12 X 72f623ef5a844188b2fb41cbd82d6f33--74fb8e92ee324cc98985d710b5b94d12 74fb8e92ee324cc98985d710b5b94d12--bbdec8c229914c64bc656c67ecc050fe 74fb8e92ee324cc98985d710b5b94d12--645adbf4b55c4b5b9b7d2d59f92c9254 ab726b34eec247fe9e5aa3e31741648f 135f9814b6da4138b6a34707296abdbb RX(theta\u2083) 89e2af1da7454b9d87fba90e124bc865--135f9814b6da4138b6a34707296abdbb 19be41532705408e9a47259869a0b5b3 RY(theta\u2087) 135f9814b6da4138b6a34707296abdbb--19be41532705408e9a47259869a0b5b3 b16e7a31d02142068d706a75c4deb9e6 RX(theta\u2081\u2081) 19be41532705408e9a47259869a0b5b3--b16e7a31d02142068d706a75c4deb9e6 5635e8fac8f042dab4ac690dd496acc9 X b16e7a31d02142068d706a75c4deb9e6--5635e8fac8f042dab4ac690dd496acc9 5635e8fac8f042dab4ac690dd496acc9--ff0f05f3ea1b4e1bb8287ab1b11934b7 c6c9d4bd1c7e4b6db743967596fef5d8 5635e8fac8f042dab4ac690dd496acc9--c6c9d4bd1c7e4b6db743967596fef5d8 d43e3203b7dc4272baedd2d4a636d2ff RX(theta\u2081\u2085) c6c9d4bd1c7e4b6db743967596fef5d8--d43e3203b7dc4272baedd2d4a636d2ff 9f336a35a4f84c1e834c9d5366ae3dd0 RY(theta\u2081\u2089) d43e3203b7dc4272baedd2d4a636d2ff--9f336a35a4f84c1e834c9d5366ae3dd0 5d1b0d67d4ba455d9f69acf970c0a2bc RX(theta\u2082\u2083) 9f336a35a4f84c1e834c9d5366ae3dd0--5d1b0d67d4ba455d9f69acf970c0a2bc a4da4620451b4b1faf76bec84a4ea3cf X 5d1b0d67d4ba455d9f69acf970c0a2bc--a4da4620451b4b1faf76bec84a4ea3cf a4da4620451b4b1faf76bec84a4ea3cf--ac7cf61e92d3450ca7e769cb96704e52 7672613c89454e32aec833c0c3cbc290 a4da4620451b4b1faf76bec84a4ea3cf--7672613c89454e32aec833c0c3cbc290 c8af3609b2914ec3bcbeeaa82d875c77 RX(theta\u2083) 7672613c89454e32aec833c0c3cbc290--c8af3609b2914ec3bcbeeaa82d875c77 42eaf27b424f4b29bdd4d318b5920520 RY(theta\u2087) c8af3609b2914ec3bcbeeaa82d875c77--42eaf27b424f4b29bdd4d318b5920520 248c975e9cd14319b09bd99d67026cf5 RX(theta\u2081\u2081) 42eaf27b424f4b29bdd4d318b5920520--248c975e9cd14319b09bd99d67026cf5 f444e4674c8f485abcc31ddd34358a80 X 248c975e9cd14319b09bd99d67026cf5--f444e4674c8f485abcc31ddd34358a80 f444e4674c8f485abcc31ddd34358a80--be133ba05bc44a3bb8fb38b41af21c37 fbe77defaff0420ab30e30915c543e69 f444e4674c8f485abcc31ddd34358a80--fbe77defaff0420ab30e30915c543e69 4e8664abadb340d6b433d12f4de97ac0 RX(theta\u2081\u2085) fbe77defaff0420ab30e30915c543e69--4e8664abadb340d6b433d12f4de97ac0 d65e733419cf47a8bad686be526c7e3f RY(theta\u2081\u2089) 4e8664abadb340d6b433d12f4de97ac0--d65e733419cf47a8bad686be526c7e3f bfed754888654032a2d0e2ccc0db71bd RX(theta\u2082\u2083) d65e733419cf47a8bad686be526c7e3f--bfed754888654032a2d0e2ccc0db71bd 22d3e87c43c6423eb0810e409828c096 X bfed754888654032a2d0e2ccc0db71bd--22d3e87c43c6423eb0810e409828c096 22d3e87c43c6423eb0810e409828c096--72f623ef5a844188b2fb41cbd82d6f33 6a316ba1bed449ff86ec3d8331a42263 22d3e87c43c6423eb0810e409828c096--6a316ba1bed449ff86ec3d8331a42263 6a316ba1bed449ff86ec3d8331a42263--ab726b34eec247fe9e5aa3e31741648f </p> <p>Avoid non-unique names by prefixing</p> <p>A parameter prefix for each HEA can be passed as follows:</p> <p><pre><code>hea1 = hea(n_qubits=n_qubits, depth=depth, param_prefix=\"p1\")\nhea2 = hea(n_qubits=n_qubits, depth=depth, param_prefix=\"p2\")\ncircuit = QuantumCircuit(n_qubits, hea1, hea2)\nn_params_two_heas = circuit.num_unique_parameters\n</code></pre> <pre><code>Unique parameters with two stacked HEAs: 48\n</code></pre> cluster_69f86f22212d4797927ec66131328fca HEA cluster_abe05a78703049d098226c5431eea1ff HEA 52f986352cba48dab557970375696c6f 0 17947f0300154b28bd88e9b617259961 RX(p1\u2080) 52f986352cba48dab557970375696c6f--17947f0300154b28bd88e9b617259961 a0c363f8cc9940d3bd878aa5cbee67b0 1 942d5837622d4aeb8f2ef168d524b2c7 RY(p1\u2084) 17947f0300154b28bd88e9b617259961--942d5837622d4aeb8f2ef168d524b2c7 3ab7f8be581d4903bc589bd92633651f RX(p1\u2088) 942d5837622d4aeb8f2ef168d524b2c7--3ab7f8be581d4903bc589bd92633651f dd74e5862e0a40558e470b3529be9dd9 3ab7f8be581d4903bc589bd92633651f--dd74e5862e0a40558e470b3529be9dd9 b9a34b2925f54191bc5e0937a37b047d dd74e5862e0a40558e470b3529be9dd9--b9a34b2925f54191bc5e0937a37b047d 1808a45901f643ddaba6d3bd19309a99 RX(p1\u2081\u2082) b9a34b2925f54191bc5e0937a37b047d--1808a45901f643ddaba6d3bd19309a99 9b4b6b8e7d974cbf846a19af56a5b48f RY(p1\u2081\u2086) 1808a45901f643ddaba6d3bd19309a99--9b4b6b8e7d974cbf846a19af56a5b48f b207801139904731ad898113aa41de81 RX(p1\u2082\u2080) 9b4b6b8e7d974cbf846a19af56a5b48f--b207801139904731ad898113aa41de81 594e6cf13a90476a85355e4a9728a524 b207801139904731ad898113aa41de81--594e6cf13a90476a85355e4a9728a524 6b617f76d1cc4457b59907fac2ab9543 594e6cf13a90476a85355e4a9728a524--6b617f76d1cc4457b59907fac2ab9543 c945a2fe68bc4aa7912135acb7d2ef0a RX(p2\u2080) 6b617f76d1cc4457b59907fac2ab9543--c945a2fe68bc4aa7912135acb7d2ef0a 6321dc8852fa43b6a7e23f6d89941d68 RY(p2\u2084) c945a2fe68bc4aa7912135acb7d2ef0a--6321dc8852fa43b6a7e23f6d89941d68 e10789c31a774298851df7f8068b063a RX(p2\u2088) 6321dc8852fa43b6a7e23f6d89941d68--e10789c31a774298851df7f8068b063a 5a2adcc527724771ac450152aea94d47 e10789c31a774298851df7f8068b063a--5a2adcc527724771ac450152aea94d47 ee100cf2f4d94110a375f64d3db9b29a 5a2adcc527724771ac450152aea94d47--ee100cf2f4d94110a375f64d3db9b29a 4d2fabf811144f4b865d3dbbc0256b8c RX(p2\u2081\u2082) ee100cf2f4d94110a375f64d3db9b29a--4d2fabf811144f4b865d3dbbc0256b8c 60e65682cdc1452a9f6b33f0f9f4e77f RY(p2\u2081\u2086) 4d2fabf811144f4b865d3dbbc0256b8c--60e65682cdc1452a9f6b33f0f9f4e77f 817bbfd051b8424e88b99ac90eabc67a RX(p2\u2082\u2080) 60e65682cdc1452a9f6b33f0f9f4e77f--817bbfd051b8424e88b99ac90eabc67a 03604f77ba02492c9608ee27df0dd5e8 817bbfd051b8424e88b99ac90eabc67a--03604f77ba02492c9608ee27df0dd5e8 501fc03c13174294811e7124cbd26791 03604f77ba02492c9608ee27df0dd5e8--501fc03c13174294811e7124cbd26791 14a73ba71ca54c60ab063f1c6bf1c791 501fc03c13174294811e7124cbd26791--14a73ba71ca54c60ab063f1c6bf1c791 eb6f6e14ecdc4e51b3697cdb356d7ac4 89cb0e967e7142b8bd40ec117f157e41 RX(p1\u2081) a0c363f8cc9940d3bd878aa5cbee67b0--89cb0e967e7142b8bd40ec117f157e41 139891b52f1c41f6a4035141af5034c3 2 0bbd50dde10540f9aaa4d6aaa704f2d9 RY(p1\u2085) 89cb0e967e7142b8bd40ec117f157e41--0bbd50dde10540f9aaa4d6aaa704f2d9 9185d861df644239abd50287b7f53583 RX(p1\u2089) 0bbd50dde10540f9aaa4d6aaa704f2d9--9185d861df644239abd50287b7f53583 33e98d187e414ba0bd28bed4f1c4c551 X 9185d861df644239abd50287b7f53583--33e98d187e414ba0bd28bed4f1c4c551 33e98d187e414ba0bd28bed4f1c4c551--dd74e5862e0a40558e470b3529be9dd9 b212708309ed4d02a594d48dd13ce783 33e98d187e414ba0bd28bed4f1c4c551--b212708309ed4d02a594d48dd13ce783 fe39933004f44260aa30a968b5657d10 RX(p1\u2081\u2083) b212708309ed4d02a594d48dd13ce783--fe39933004f44260aa30a968b5657d10 2ab7ddbfad894b309b23ec81de10f8c9 RY(p1\u2081\u2087) fe39933004f44260aa30a968b5657d10--2ab7ddbfad894b309b23ec81de10f8c9 b1d5bcb7716544a3b40211bd2a895c94 RX(p1\u2082\u2081) 2ab7ddbfad894b309b23ec81de10f8c9--b1d5bcb7716544a3b40211bd2a895c94 ce404566d6bf4a08b509c2ff6765b5df X b1d5bcb7716544a3b40211bd2a895c94--ce404566d6bf4a08b509c2ff6765b5df ce404566d6bf4a08b509c2ff6765b5df--594e6cf13a90476a85355e4a9728a524 6687f7bc46bd439493c855af59cb5c03 ce404566d6bf4a08b509c2ff6765b5df--6687f7bc46bd439493c855af59cb5c03 7fe4dac1f1d3413cab98cda1ea19c532 RX(p2\u2081) 6687f7bc46bd439493c855af59cb5c03--7fe4dac1f1d3413cab98cda1ea19c532 a30288b21b804c74b0f64687efa94af4 RY(p2\u2085) 7fe4dac1f1d3413cab98cda1ea19c532--a30288b21b804c74b0f64687efa94af4 863ec96bfd3a4f6cbcb167955e4c1ffd RX(p2\u2089) a30288b21b804c74b0f64687efa94af4--863ec96bfd3a4f6cbcb167955e4c1ffd e1ef2440c5b747a195ccf15f9b938d5c X 863ec96bfd3a4f6cbcb167955e4c1ffd--e1ef2440c5b747a195ccf15f9b938d5c e1ef2440c5b747a195ccf15f9b938d5c--5a2adcc527724771ac450152aea94d47 5567d57bac3f45d6956565a24de42dbe e1ef2440c5b747a195ccf15f9b938d5c--5567d57bac3f45d6956565a24de42dbe 134e3d774dbe4faf8247ef49f64aaa24 RX(p2\u2081\u2083) 5567d57bac3f45d6956565a24de42dbe--134e3d774dbe4faf8247ef49f64aaa24 db49f5af183f4489b1ee85adbf40d1f6 RY(p2\u2081\u2087) 134e3d774dbe4faf8247ef49f64aaa24--db49f5af183f4489b1ee85adbf40d1f6 b09aef300580430a8ec6aa305a57c076 RX(p2\u2082\u2081) db49f5af183f4489b1ee85adbf40d1f6--b09aef300580430a8ec6aa305a57c076 7c1c6d7b587f40f7b03d61084c96d035 X b09aef300580430a8ec6aa305a57c076--7c1c6d7b587f40f7b03d61084c96d035 7c1c6d7b587f40f7b03d61084c96d035--03604f77ba02492c9608ee27df0dd5e8 d6c42323b268401c98391bf4186bbe77 7c1c6d7b587f40f7b03d61084c96d035--d6c42323b268401c98391bf4186bbe77 d6c42323b268401c98391bf4186bbe77--eb6f6e14ecdc4e51b3697cdb356d7ac4 8a2e06265f7d4ff8a3337bda86f055f3 3d61685b4a764b009fdfd1cf797bc741 RX(p1\u2082) 139891b52f1c41f6a4035141af5034c3--3d61685b4a764b009fdfd1cf797bc741 911377a667954acf8bdd1f0454016b0b 3 86994143dc6b498d87be7f7aca8135eb RY(p1\u2086) 3d61685b4a764b009fdfd1cf797bc741--86994143dc6b498d87be7f7aca8135eb 3179eef41b944fb18d87e91b2767f76f RX(p1\u2081\u2080) 86994143dc6b498d87be7f7aca8135eb--3179eef41b944fb18d87e91b2767f76f f61a04782b7d46949070e97501bfde5a 3179eef41b944fb18d87e91b2767f76f--f61a04782b7d46949070e97501bfde5a e837d408dffc49cbb29b567217104780 X f61a04782b7d46949070e97501bfde5a--e837d408dffc49cbb29b567217104780 e837d408dffc49cbb29b567217104780--b212708309ed4d02a594d48dd13ce783 e67a35df7c134794b6fded82c9426c29 RX(p1\u2081\u2084) e837d408dffc49cbb29b567217104780--e67a35df7c134794b6fded82c9426c29 0f2adf4727a94331a1e9948bdd183c85 RY(p1\u2081\u2088) e67a35df7c134794b6fded82c9426c29--0f2adf4727a94331a1e9948bdd183c85 446f4031604947b8b388dfb2d9024af2 RX(p1\u2082\u2082) 0f2adf4727a94331a1e9948bdd183c85--446f4031604947b8b388dfb2d9024af2 8108288ddf8448a0a681e73df61cd188 446f4031604947b8b388dfb2d9024af2--8108288ddf8448a0a681e73df61cd188 0a745da6ef3440c1bd8519cb029e46e6 X 8108288ddf8448a0a681e73df61cd188--0a745da6ef3440c1bd8519cb029e46e6 0a745da6ef3440c1bd8519cb029e46e6--6687f7bc46bd439493c855af59cb5c03 57ccab9a329947678d3a4a0764beffb7 RX(p2\u2082) 0a745da6ef3440c1bd8519cb029e46e6--57ccab9a329947678d3a4a0764beffb7 3e336a1983094d82b1d073ab5b93ed1e RY(p2\u2086) 57ccab9a329947678d3a4a0764beffb7--3e336a1983094d82b1d073ab5b93ed1e 78dcfa418db4468bb9a8d2fee2cfabbc RX(p2\u2081\u2080) 3e336a1983094d82b1d073ab5b93ed1e--78dcfa418db4468bb9a8d2fee2cfabbc 5453e7353924450d8942840fbd2fc046 78dcfa418db4468bb9a8d2fee2cfabbc--5453e7353924450d8942840fbd2fc046 af5c81aefb1c4ec9b8329f1699cadf41 X 5453e7353924450d8942840fbd2fc046--af5c81aefb1c4ec9b8329f1699cadf41 af5c81aefb1c4ec9b8329f1699cadf41--5567d57bac3f45d6956565a24de42dbe ee79f6129e31495aa3111b74435301b7 RX(p2\u2081\u2084) af5c81aefb1c4ec9b8329f1699cadf41--ee79f6129e31495aa3111b74435301b7 171643a408354718b25b031214fca184 RY(p2\u2081\u2088) ee79f6129e31495aa3111b74435301b7--171643a408354718b25b031214fca184 1f3be1b596484a648461fc36263b8866 RX(p2\u2082\u2082) 171643a408354718b25b031214fca184--1f3be1b596484a648461fc36263b8866 31f2636fa1274a63a34a735228aa12f7 1f3be1b596484a648461fc36263b8866--31f2636fa1274a63a34a735228aa12f7 95347c3f2a184e8aafa231cdbd55d8de X 31f2636fa1274a63a34a735228aa12f7--95347c3f2a184e8aafa231cdbd55d8de 95347c3f2a184e8aafa231cdbd55d8de--d6c42323b268401c98391bf4186bbe77 95347c3f2a184e8aafa231cdbd55d8de--8a2e06265f7d4ff8a3337bda86f055f3 14d0f738a5fd44c4b76d84c0bfdf6b6d 32d47e46222341ada86b216a02831e25 RX(p1\u2083) 911377a667954acf8bdd1f0454016b0b--32d47e46222341ada86b216a02831e25 733cb78d09ce46d2bd2e6e46bd9e32f1 RY(p1\u2087) 32d47e46222341ada86b216a02831e25--733cb78d09ce46d2bd2e6e46bd9e32f1 fdaa026fed7c43ef94e5c8c887ddedd7 RX(p1\u2081\u2081) 733cb78d09ce46d2bd2e6e46bd9e32f1--fdaa026fed7c43ef94e5c8c887ddedd7 5bea149a93c74ed9848f36f24b2fdd9e X fdaa026fed7c43ef94e5c8c887ddedd7--5bea149a93c74ed9848f36f24b2fdd9e 5bea149a93c74ed9848f36f24b2fdd9e--f61a04782b7d46949070e97501bfde5a 3db7897a564c4a66b3cede4d19f755af 5bea149a93c74ed9848f36f24b2fdd9e--3db7897a564c4a66b3cede4d19f755af 0965b1507de24a32845ce6ac2d0f60db RX(p1\u2081\u2085) 3db7897a564c4a66b3cede4d19f755af--0965b1507de24a32845ce6ac2d0f60db c29eabe3e67a4f708cb3d5641656d12f RY(p1\u2081\u2089) 0965b1507de24a32845ce6ac2d0f60db--c29eabe3e67a4f708cb3d5641656d12f 653ea8046e6d4ad89e91ecd61f30c5c2 RX(p1\u2082\u2083) c29eabe3e67a4f708cb3d5641656d12f--653ea8046e6d4ad89e91ecd61f30c5c2 4828009ed1cd4534a871a28e7f9e2c7d X 653ea8046e6d4ad89e91ecd61f30c5c2--4828009ed1cd4534a871a28e7f9e2c7d 4828009ed1cd4534a871a28e7f9e2c7d--8108288ddf8448a0a681e73df61cd188 102aebf7b34f453e957e30ef5eb053aa 4828009ed1cd4534a871a28e7f9e2c7d--102aebf7b34f453e957e30ef5eb053aa b47dbe0ccaf747b18fe1ea9f7d81f563 RX(p2\u2083) 102aebf7b34f453e957e30ef5eb053aa--b47dbe0ccaf747b18fe1ea9f7d81f563 99a12e13d8164976bf8bb5cc69e05ef1 RY(p2\u2087) b47dbe0ccaf747b18fe1ea9f7d81f563--99a12e13d8164976bf8bb5cc69e05ef1 c6ac43fe30894668ae42c76afef058bc RX(p2\u2081\u2081) 99a12e13d8164976bf8bb5cc69e05ef1--c6ac43fe30894668ae42c76afef058bc 80eb16f3d94943c0a3699f842ed5fcf7 X c6ac43fe30894668ae42c76afef058bc--80eb16f3d94943c0a3699f842ed5fcf7 80eb16f3d94943c0a3699f842ed5fcf7--5453e7353924450d8942840fbd2fc046 8fbd69eb7ab44f90b8cbf1a3e3f603d3 80eb16f3d94943c0a3699f842ed5fcf7--8fbd69eb7ab44f90b8cbf1a3e3f603d3 20f9fe41567d49cb86c56ada19516873 RX(p2\u2081\u2085) 8fbd69eb7ab44f90b8cbf1a3e3f603d3--20f9fe41567d49cb86c56ada19516873 3635376399af4ac881eb76fc35304527 RY(p2\u2081\u2089) 20f9fe41567d49cb86c56ada19516873--3635376399af4ac881eb76fc35304527 1b203e3534a24318bcdbfedf038a37c8 RX(p2\u2082\u2083) 3635376399af4ac881eb76fc35304527--1b203e3534a24318bcdbfedf038a37c8 79f057b213bf4fce9afcdce4d0b91bf1 X 1b203e3534a24318bcdbfedf038a37c8--79f057b213bf4fce9afcdce4d0b91bf1 79f057b213bf4fce9afcdce4d0b91bf1--31f2636fa1274a63a34a735228aa12f7 a6ade26e39404fe584a17ed0450006c2 79f057b213bf4fce9afcdce4d0b91bf1--a6ade26e39404fe584a17ed0450006c2 a6ade26e39404fe584a17ed0450006c2--14d0f738a5fd44c4b76d84c0bfdf6b6d </p> <p>The <code>hea</code> function will be further explored in the QML Constructors tutorial.</p>"},{"location":"tutorials/parameters/#parametric-observables","title":"Parametric observables","text":"<p>In Qadence, one can define quantum observables with classical optimizable parameters to improve the convergence of QML calculations. This is particularly useful for differentiable quantum circuits.</p> <pre><code>from qadence import VariationalParameter, Z, add, tag\ns = VariationalParameter(\"s\")\nobservable = add(s * Z(i) for i in range(n_qubits))\n</code></pre> <p>Now, a quantum model can be created with the parametric observable. The observable variational parameters are included among the model ones.</p> <pre><code>from qadence import QuantumModel, QuantumCircuit\ncircuit = QuantumCircuit(n_qubits, hea(n_qubits, depth))\nmodel = QuantumModel(circuit, observable=observable)\n</code></pre> <pre><code>Variational parameters = OrderedDict([('s', tensor([0.9406])), ('theta_0', tensor([0.7951])), ('theta_1', tensor([0.3345])), ('theta_10', tensor([0.8927])), ('theta_11', tensor([0.3210])), ('theta_12', tensor([0.3358])), ('theta_13', tensor([0.6445])), ('theta_14', tensor([0.1183])), ('theta_15', tensor([0.8274])), ('theta_16', tensor([0.6881])), ('theta_17', tensor([0.5928])), ('theta_18', tensor([0.2551])), ('theta_19', tensor([0.3500])), ('theta_2', tensor([0.3125])), ('theta_20', tensor([0.5327])), ('theta_21', tensor([0.0981])), ('theta_22', tensor([0.1385])), ('theta_23', tensor([0.6408])), ('theta_3', tensor([0.4979])), ('theta_4', tensor([0.4264])), ('theta_5', tensor([0.5154])), ('theta_6', tensor([0.6589])), ('theta_7', tensor([0.1994])), ('theta_8', tensor([0.9758])), ('theta_9', tensor([0.9689]))])\n</code></pre> <p>One optimization step (forward and backward pass) can be performed using built-in <code>torch</code> functionalities. Variational parameters can be checked to have been updated accordingly:</p> <pre><code>import torch\nmse_loss = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters())\n# Compute forward &amp; backward pass\noptimizer.zero_grad()\nloss = mse_loss(model.expectation({}), torch.zeros(1))\nloss.backward()\n# Update the parameters and check the parameters.\noptimizer.step()\n</code></pre> <pre><code>Variational parameters = OrderedDict([('s', tensor([0.9396])), ('theta_0', tensor([0.7941])), ('theta_1', tensor([0.3335])), ('theta_10', tensor([0.8937])), ('theta_11', tensor([0.3200])), ('theta_12', tensor([0.3348])), ('theta_13', tensor([0.6435])), ('theta_14', tensor([0.1193])), ('theta_15', tensor([0.8264])), ('theta_16', tensor([0.6891])), ('theta_17', tensor([0.5918])), ('theta_18', tensor([0.2561])), ('theta_19', tensor([0.3510])), ('theta_2', tensor([0.3135])), ('theta_20', tensor([0.5317])), ('theta_21', tensor([0.0971])), ('theta_22', tensor([0.1395])), ('theta_23', tensor([0.6398])), ('theta_3', tensor([0.4969])), ('theta_4', tensor([0.4254])), ('theta_5', tensor([0.5144])), ('theta_6', tensor([0.6579])), ('theta_7', tensor([0.2004])), ('theta_8', tensor([0.9748])), ('theta_9', tensor([0.9679]))])\n</code></pre>"},{"location":"tutorials/parameters/#non-unitary-circuits","title":"Non-unitary circuits","text":"<p>Qadence allows to compose with non-unitary blocks. Here is an example of a non-unitary block as a sum of Pauli operators with complex coefficients.</p> <p>Currently, only the <code>PyQTorch</code> backend fully supports execution with non-unitary circuits.</p> <pre><code>from qadence import QuantumModel, QuantumCircuit, Z, X\nc1 = 2.0\nc2 = 2.0 + 2.0j\nblock = c1 * Z(0) + c2 * X(1) + c1 * c2 * (Z(2) + X(3))\ncircuit = QuantumCircuit(4, block)\nmodel = QuantumModel(circuit)  # BackendName.PYQTORCH and DiffMode.AD by default.\n</code></pre> <pre><code>wf = tensor([[6.+4.j, 4.+4.j, 0.+0.j, 0.+0.j, 2.+2.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre>"},{"location":"tutorials/quantummodels/","title":"Quantum models","text":"<p>A quantum program can be expressed and executed using the <code>QuantumModel</code> type. It serves three primary purposes:</p> <p>Parameter handling: by conveniently handling and embedding the two parameter types that Qadence supports: feature and variational (see more details in the next section).</p> <p>Differentiability: by enabling a differentiable backend that supports two differentiable modes: automated differentiation (AD) and parameter shift rule (PSR). The former is used to differentiate non-gate parameters and enabled for PyTorch-based simulators only. The latter is used to differentiate gate parameters and is enabled for all backends.</p> <p>Execution: by defining which backend the program is expected to be executed on. Qadence supports circuit compilation to the native backend representation.</p> <p>Backends</p> <p>Quantum models can execute on a number of different purpose backends: simulators, emulators or real hardware. By default, Qadence executes on the PyQTorch backend which implements a state vector simulator. Other choices include the Pulser backend (pulse sequences on programmable neutral atom arrays).  For more information see the backend section.</p> <p>The base <code>QuantumModel</code> exposes the following methods:</p> <ul> <li><code>QuantumModel.run()</code>: To extract the wavefunction after circuit execution. Not supported by all backends.</li> <li><code>QuantumModel.sample()</code>: Sample a bitstring from the resulting quantum state after circuit execution. Supported by all backends.</li> <li><code>QuantumModel.expectation()</code>: Compute the expectation value of an observable.</li> </ul> <p>Every <code>QuantumModel</code> is an instance of a <code>torch.nn.Module</code> that enables differentiability for its <code>expectation</code> method.</p> <p>Upon construction of the model, a compiled version of the abstract <code>QuantumCircuit</code> is created:</p> <pre><code>from qadence import QuantumCircuit, QuantumModel, RX, Z, chain, BackendName, Parameter\n# Construct a parametrized abstract circuit.\n# At this point we cannot run anything yet.\nx = Parameter(\"x\")\nn_qubits = 2\nblock = chain(RX(0, x), RX(1, x))\ncircuit = QuantumCircuit(n_qubits, block)\nobservable = Z(0)\n# Construct a QuantumModel which will compile\n# the abstract circuit to targetted backend.\n# By default, diff_mode=DiffMode.AD.\nmodel = QuantumModel(circuit, observable, backend=BackendName.PYQTORCH)\n# The converted circuit is a private attribute and should not\n# manually be tampered with, but we can at least verify its there\n# by printing it.\n</code></pre> <pre><code>model._circuit.native = QuantumCircuit(\n(operations): ModuleList(\n(0): QuantumCircuit(\n(operations): ModuleList(\n(0): ParametricPyQOperation(\n(operation): RX(qubits=(0,), n_qubits=2)\n)\n(1): ParametricPyQOperation(\n(operation): RX(qubits=(1,), n_qubits=2)\n)\n)\n)\n)\n)\n</code></pre> <p>Now, the wavefunction, sample, or expectation value are computable by passing a batch of values :</p> <pre><code>import torch\n# Set a batch of random parameter values.\nvalues = {\"x\": torch.rand(3)}\nwf = model.run(values)\nxs = model.sample(values, n_shots=100)\nex = model.expectation(values)\n</code></pre> <pre><code>wf = tensor([[ 0.9940+0.0000j,  0.0000-0.0774j,  0.0000-0.0774j, -0.0060+0.0000j],\n[ 0.8271+0.0000j,  0.0000-0.3781j,  0.0000-0.3781j, -0.1729+0.0000j],\n[ 0.9494+0.0000j,  0.0000-0.2191j,  0.0000-0.2191j, -0.0506+0.0000j]])\nxs = [Counter({'00': 98, '01': 1, '10': 1}), Counter({'00': 67, '01': 18, '10': 13, '11': 2}), Counter({'00': 86, '01': 7, '10': 6, '11': 1})]\nex = tensor([[0.9879],\n[0.6543],\n[0.8988]], requires_grad=True)\n</code></pre> <p>You can also measure multiple observables by passing a list of blocks.</p> <pre><code># By default, backend=BackendName.PYQTORCH.\nmodel = QuantumModel(circuit, [Z(0), Z(1)])\nex = model.expectation(values)\n</code></pre> <pre><code>ex = tensor([[0.9879, 0.9879],\n[0.6543, 0.6543],\n[0.8988, 0.8988]], requires_grad=True)\n</code></pre>"},{"location":"tutorials/quantummodels/#quantum-neural-network-qnn","title":"Quantum Neural Network (QNN)","text":"<p>The <code>QNN</code> is a subclass of the <code>QuantumModel</code> geared towards quantum machine learning and parameter optimisation. See the machine learning tools section or the <code>QNN</code> API reference for more detailed information, and the parametric program tutorial for parameterization.</p>"},{"location":"tutorials/register/","title":"Quantum registers","text":"<p>In Qadence, quantum programs can be executed by specifying the layout of a register of resources as a lattice. Built-in <code>Register</code> types can be used or constructed for arbitrary topologies. Common register topologies are available and illustrated in the plot below.</p> 2023-10-12T16:59:53.907028 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/"},{"location":"tutorials/register/#building-and-drawing-registers","title":"Building and drawing registers","text":"<p>Built-in topologies are directly accessible in the <code>Register</code>:</p> <pre><code>from qadence import Register\nreg = Register.honeycomb_lattice(2, 3)\nreg.draw(show=False)\n</code></pre> 2023-10-12T16:59:54.056234 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ <p>Arbitrarily shaped registers can be constructed by providing coordinates.</p> <p>Registers defined from coordinates</p> <p><code>Register</code> constructed via the <code>from_coordinates</code> method do not define edges in the connectivity graph.</p> <pre><code>import numpy as np\nfrom qadence import Register\nreg = Register.from_coordinates(\n[(x, np.sin(x)) for x in np.linspace(0, 2*np.pi, 10)]\n)\nreg.draw(show=False)\n</code></pre> 2023-10-12T16:59:54.094481 image/svg+xml Matplotlib v3.7.3, https://matplotlib.org/ <p>Units for qubit coordinates</p> <p>Qubits coordinates in Qadence are dimensionless but converted to the required unit when executed on a backend. For instance, Pulser uses \\(\\mu \\textrm{m}\\).</p>"},{"location":"tutorials/register/#connectivity-graphs","title":"Connectivity graphs","text":"<p>Register topology is often asssumed in simulations to be an all-to-all qubit connectivity. When running on real devices that enable the digital-analog computing paradigm, qubit interaction must be specified either by specifying distances between qubits, or by defining edges in the register connectivity graph.</p> <p>It is possible to access the abstract graph nodes and edges to work with if needed as in the perfect state transfer example.</p> <pre><code>from qadence import Register\nreg = Register.rectangular_lattice(2,3)\n</code></pre> <pre><code>reg.nodes = NodeView((0, 1, 2, 3, 4, 5))\nreg.edges = EdgeView([(0, 2), (0, 1), (1, 3), (2, 4), (2, 3), (3, 5), (4, 5)])\n</code></pre> <p>It is possible to customize qubit interaction through the <code>add_interaction</code> method. In that case, <code>Register.coords</code> are accessible from the concrete graph:</p> <pre><code>print(f\"{reg.coords = }\")\n</code></pre> <pre><code>reg.coords = {0: (0.0, 0.0), 1: (0.0, 1.0), 2: (1.0, 0.0), 3: (1.0, 1.0), 4: (2.0, 0.0), 5: (2.0, 1.0)}\n</code></pre> <p>More details about their usage in the digital-analog paradigm can be found in the digital-analog basics section.</p>"},{"location":"tutorials/serializ_and_prep/","title":"Serialization","text":"<p>Qadence offers convenience functions for serializing and deserializing any quantum program. This is useful for storing quantum programs and sending them for execution over the network via an API.</p> <p>Note</p> <p>Qadence currently uses a custom JSON serialization as interchange format. Support for QASM format for digital quantum programs is currently under consideration.</p> <ul> <li><code>serialize/deserialize</code>: serialize and deserialize a Qadence object into a dictionary</li> <li><code>save/load</code>: save and load a Qadence object to a file with one of the supported   formats. Currently, these are <code>.json</code> and the PyTorch-compatible <code>.pt</code> format.</li> </ul> <p>Let's start with serialization into a dictionary.</p> <pre><code>import torch\nfrom qadence import QuantumCircuit, QuantumModel, DiffMode\nfrom qadence import chain, hamiltonian_factory, feature_map, hea, Z\nfrom qadence.serialization import serialize, deserialize\nn_qubits = 4\nmy_block = chain(feature_map(n_qubits, param=\"x\"), hea(n_qubits, depth=2))\nobs = hamiltonian_factory(n_qubits, detuning=Z)\n# Use the block defined above to create a quantum circuit\n# serialize/deserialize it\nqc = QuantumCircuit(n_qubits, my_block)\nqc_dict = serialize(qc)\nqc_deserialized = deserialize(qc_dict)\nassert qc == qc_deserialized\n# Let's wrap it in a QuantumModel\n# and serialize it\nqm = QuantumModel(qc, obs, diff_mode=DiffMode.AD)\nqm_dict = serialize(qm)\nqm_deserialized = deserialize(qm_dict)\n# Check if the loaded QuantumModel returns the same expectation\nvalues = {\"x\": torch.rand(10)}\nassert torch.allclose(qm.expectation(values=values), qm_deserialized.expectation(values=values))\n</code></pre> <p>Finally, we can save the quantum circuit and the model with the two supported formats.</p> <pre><code>from qadence.serialization import serialize, deserialize, save, load, SerializationFormat\nqc_fname = \"circuit\"\nsave(qc, folder=\".\", file_name=qc_fname, format=SerializationFormat.PT)\nloaded_qc = load(f\"{qc_fname}.pt\")\nassert qc == loaded_qc\nqm_fname = \"model\"\nsave(qm, folder=\".\", file_name=qm_fname, format=SerializationFormat.JSON)\nmodel = load(f\"{qm_fname}.json\")\nassert isinstance(model, QuantumModel)\n</code></pre>"},{"location":"tutorials/state_conventions/","title":"State Conventions","text":"<p>Here is an overview of the state conventions used in Qadence together with practical examples.</p>"},{"location":"tutorials/state_conventions/#qubit-register-order","title":"Qubit register order","text":"<p>Qubit registers in quantum computing are often indexed in increasing or decreasing order from left to right. In Qadence, the convention is qubit indexation in increasing order. For example, a register of four qubits in bra-ket notation reads:</p> \\[|q_0, q_1, q_2, q_3\\rangle\\] <p>Furthermore, when displaying a quantum circuit, qubits are ordered from top to bottom.</p>"},{"location":"tutorials/state_conventions/#basis-state-order","title":"Basis state order","text":"<p>Basis state ordering refers to how basis states are ordered when considering the conversion from bra-ket notation to the standard linear algebra basis. In Qadence, basis states are ordered in the following manner:</p> \\[ \\begin{align} |00\\rangle = [1, 0, 0, 0]^T\\\\ |01\\rangle = [0, 1, 0, 0]^T\\\\ |10\\rangle = [0, 0, 1, 0]^T\\\\ |11\\rangle = [0, 0, 0, 1]^T \\end{align} \\]"},{"location":"tutorials/state_conventions/#endianness","title":"Endianness","text":"<p>Endianness refers to the storage convention for binary information (in bytes) in a classical memory register. In quantum computing, information is either stored in bits or in qubits. The most commonly used conventions are:</p> <ul> <li>A big-endian system stores the most significant bit of a binary word at the smallest memory address.</li> <li>A little-endian system stores the least significant bit of a binary word at the smallest memory address.</li> </ul> <p>Given the register convention in Qadence, the integer \\(2\\) written in binary big-endian as \\(10\\) can be encoded in a qubit register in both big-endian as \\(|10\\rangle\\) or little-endian as \\(|01\\rangle\\).</p> <p>The convention for Qadence is big-endian.</p>"},{"location":"tutorials/state_conventions/#quantum-states","title":"Quantum states","text":"<p>In practical scenarios, conventions regarding register order, basis state order and endianness are very much intertwined, and identical results can be obtained by fixing or varying any of them. In Qadence, we assume that qubit ordering and basis state ordering is fixed, and allow an <code>endianness</code> argument that can be passed to control the expected result. Here are a few examples:</p> <p>A simple and direct way to exemplify the endianness convention is using convenience functions for state preparation.</p> <p>Bitstring convention as inputs</p> <p>When a bitstring is passed as input to a function for state preparation, it has to be understood in big-endian convention.</p> <pre><code>from qadence import Endianness, product_state\n# The state |10&gt;, the 3rd basis state.\nstate_big = product_state(\"10\", endianness=Endianness.BIG) # or just \"Big\"\n# The state |01&gt;, the 2nd basis state.\nstate_little = product_state(\"10\", endianness=Endianness.LITTLE) # or just \"Little\"\n</code></pre> <pre><code>State in big endian = tensor([[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]])\nState in little endian = tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> <p>Here, a bitword expressed as a Python string to encode the integer 2 in big-endian is used to create the respective basis state in both conventions. However, note that the same results can be obtained by fixing the endianness convention as big-endian (thus creating the state \\(|10\\rangle\\) in both cases), and changing the basis state ordering. A similar argument holds for fixing both endianness and basis state ordering and simply changing the qubit index order.</p> <p>Another example where endianness directly comes into play is when measuring a register. A big- or little-endian measurement will choose the first or the last qubit, respectively, as the most significant bit. Let's see this in an example:</p> <pre><code>from qadence import I, H, sample\n# Create superposition state: |00&gt; + |01&gt; (normalized)\nblock = I(0) @ H(1)  # Identity on qubit 0, Hadamard on qubit 1\n# Generate bitword samples following both conventions\n# Samples \"00\" and \"01\"\nresult_big = sample(block, endianness=Endianness.BIG)\n# Samples \"00\" and \"10\"\nresult_little = sample(block, endianness=Endianness.LITTLE)\n</code></pre> <pre><code>Sample in big endian = [Counter({'01': 58, '00': 42})]\nSample in little endian = [Counter({'00': 52, '10': 48})]\n</code></pre> <p>In Qadence, endianness can be flipped for many relevant objects:</p> <pre><code>from qadence import invert_endianness\n# Equivalent to sampling in little-endian.\nflip_big_sample = invert_endianness(result_big)\n# Equivalent to a state created in little-endian.\nflip_big_state = invert_endianness(state_big)\n</code></pre> <pre><code>Flipped sample = [Counter({'10': 58, '00': 42})]\nFlipped state = tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre>"},{"location":"tutorials/state_conventions/#quantum-operations","title":"Quantum operations","text":"<p>When looking at the matricial form of quantum operations, the usage of the term endianness becomes slightly abusive. To exemplify, we may consider the <code>CNOT</code> operation with <code>control = 0</code> and <code>target = 1</code>. This operation is often described with two different matrices:</p> \\[ \\text{CNOT(0, 1)} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ \\end{bmatrix} \\qquad \\text{or} \\qquad \\text{CNOT(0, 1)} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ \\end{bmatrix} \\] <p>The difference can be easily explained either by considering a different ordering of the qubit indices, or a different ordering of the basis states. In Qadence, both can be retrieved through the <code>endianness</code> argument:</p> <pre><code>from qadence import block_to_tensor, CNOT\nmatrix_big = block_to_tensor(CNOT(0, 1), endianness=Endianness.BIG)\nmatrix_little = block_to_tensor(CNOT(0, 1), endianness=Endianness.LITTLE)\n</code></pre> <pre><code>CNOT matrix in big endian =\ntensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]]])\nCNOT matrix in little endian =\ntensor([[[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n[0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j],\n[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j]]])\n</code></pre>"},{"location":"tutorials/state_conventions/#backends","title":"Backends","text":"<p>An important part of having clear state conventions is that we need to make sure our results are consistent accross different computational backends, which may have their own conventions. In Qadence, this is taken care for automatically: by calling operations for different backends, the result is expected to be equivalent up to qubit ordering.</p> <pre><code>from qadence import BackendName, RX, run, sample\nimport torch\n# RX(pi/4) on qubit 1\nn_qubits = 2\nop = RX(1, torch.pi/4)\n</code></pre> <pre><code>Same sampling order in big endian:\nOn PyQTorch = [Counter({'00': 87, '01': 13})]\nOn Braket = [Counter({'00': 80, '01': 20})]\nOn Pulser = [Counter({'00': 87, '01': 13})]\nSame wavefunction order:\nOn PyQTorch = tensor([[0.9239+0.0000j, 0.0000-0.3827j, 0.0000+0.0000j, 0.0000+0.0000j]])\nOn Braket = tensor([[0.9239+0.0000j, 0.0000-0.3827j, 0.0000+0.0000j, 0.0000+0.0000j]])\nOn Pulser = tensor([[0.9223+0.0000j, 0.0000-0.3865j, 0.0000+0.0000j, 0.0000+0.0000j]])\n</code></pre>"},{"location":"tutorials/state_init/","title":"State initialization","text":"<p>Qadence offers convenience routines for preparing initial quantum states. These routines are divided into two approaches:</p> <ul> <li>As a dense matrix.</li> <li>From a suitable quantum circuit. This is available for every backend and it should be added in front of the desired quantum circuit to simulate.</li> </ul> <p>Let's illustrate the usage of the state preparation routine.</p> <pre><code>from qadence import random_state, product_state, is_normalized, StateGeneratorType\n# Random initial state.\n# the default `type` is StateGeneratorType.HaarMeasureFast\nstate = random_state(n_qubits=2, type=StateGeneratorType.RANDOM_ROTATIONS)\n# Check the normalization.\nassert is_normalized(state)\n# Product state from a given bitstring.\n# NB: Qadence follows the big endian convention.\nstate = product_state(\"01\")\n</code></pre> <pre><code>Random initial state generated with rotations:\nstate = [0.47370904+0.73135331j 0.        +0.j         0.41179854-0.26672839j\n0.        +0.j        ]\nProduct state corresponding to bitstring '01':\nstate = [0.+0.j 1.+0.j 0.+0.j 0.+0.j]\n</code></pre> <p>Now we see how to generate the product state corresponding to the one above with a suitable quantum circuit.</p> <p><pre><code>from qadence import product_block, tag, hea, QuantumCircuit\nfrom qadence.draw import display\nstate_prep_block = product_block(\"01\")\n# display(state_prep_block)\n# Let's now prepare a circuit.\nn_qubits = 4\nstate_prep_block = product_block(\"0001\")\ntag(state_prep_block, \"Prep block\")\ncircuit_block = tag(hea(n_qubits, depth = 2), \"Circuit block\")\nqc_with_state_prep = QuantumCircuit(n_qubits, state_prep_block, circuit_block)\n</code></pre> cluster_e80626f3a0244ea289b3292a63f69d56 Circuit block cluster_0db1387d4deb4b03805111e58ea1f256 Prep block b3842d47123a4535bef0792177816629 0 ac9201d9c63c4cc6b37e3976686b1cbd b3842d47123a4535bef0792177816629--ac9201d9c63c4cc6b37e3976686b1cbd b4d810f94cb54af38da406a5364138c8 1 080bf43bfd1d474f924a2a00ba4a50fd RX(theta\u2080) ac9201d9c63c4cc6b37e3976686b1cbd--080bf43bfd1d474f924a2a00ba4a50fd c35e19eb875441bd8c3f522d181d5ff0 RY(theta\u2084) 080bf43bfd1d474f924a2a00ba4a50fd--c35e19eb875441bd8c3f522d181d5ff0 554db76895544b5b8ded96ef682776b4 RX(theta\u2088) c35e19eb875441bd8c3f522d181d5ff0--554db76895544b5b8ded96ef682776b4 c446c4424964442aa168a6a053c8e757 554db76895544b5b8ded96ef682776b4--c446c4424964442aa168a6a053c8e757 d77ff14b0180426f821569c2d1258c1c c446c4424964442aa168a6a053c8e757--d77ff14b0180426f821569c2d1258c1c b2a17fecb2494251a695e25ed9377f1b RX(theta\u2081\u2082) d77ff14b0180426f821569c2d1258c1c--b2a17fecb2494251a695e25ed9377f1b 411b5c6d6df74c26814dbaeb3132e118 RY(theta\u2081\u2086) b2a17fecb2494251a695e25ed9377f1b--411b5c6d6df74c26814dbaeb3132e118 2c81cecdd0484ac2bea1eb00e384c4cc RX(theta\u2082\u2080) 411b5c6d6df74c26814dbaeb3132e118--2c81cecdd0484ac2bea1eb00e384c4cc 6425fa38341a4fe6b78a1bcdc61d4bfb 2c81cecdd0484ac2bea1eb00e384c4cc--6425fa38341a4fe6b78a1bcdc61d4bfb 8a945089301f48caa1f9f050da277ee1 6425fa38341a4fe6b78a1bcdc61d4bfb--8a945089301f48caa1f9f050da277ee1 a436de94d5b040f4a408f394acb54752 8a945089301f48caa1f9f050da277ee1--a436de94d5b040f4a408f394acb54752 73ae5545dd3941769adae5c555de15ec 2fa0f10bf5f7466daf2b2dd3d9cd23af b4d810f94cb54af38da406a5364138c8--2fa0f10bf5f7466daf2b2dd3d9cd23af b4d8a7ab9d8e4daabaabe794e5fc94ed 2 5f92379b7b204ed7a8fafbd6bae927de RX(theta\u2081) 2fa0f10bf5f7466daf2b2dd3d9cd23af--5f92379b7b204ed7a8fafbd6bae927de c368399907d54dba9779a7959e5f8edf RY(theta\u2085) 5f92379b7b204ed7a8fafbd6bae927de--c368399907d54dba9779a7959e5f8edf d8cd01f906394b45b824540af1b54c6e RX(theta\u2089) c368399907d54dba9779a7959e5f8edf--d8cd01f906394b45b824540af1b54c6e e3eb4932474d4548b4f020d62f178ce2 X d8cd01f906394b45b824540af1b54c6e--e3eb4932474d4548b4f020d62f178ce2 e3eb4932474d4548b4f020d62f178ce2--c446c4424964442aa168a6a053c8e757 a297da90945945b19d63f42fa2dbacb7 e3eb4932474d4548b4f020d62f178ce2--a297da90945945b19d63f42fa2dbacb7 6c5c5838884f4475b7c9c3e638e032ce RX(theta\u2081\u2083) a297da90945945b19d63f42fa2dbacb7--6c5c5838884f4475b7c9c3e638e032ce dd60c9be1ce24ba2bf5d4dab18f0bdfb RY(theta\u2081\u2087) 6c5c5838884f4475b7c9c3e638e032ce--dd60c9be1ce24ba2bf5d4dab18f0bdfb 60e0cb76c10f4a97a24577c18a4bbe6e RX(theta\u2082\u2081) dd60c9be1ce24ba2bf5d4dab18f0bdfb--60e0cb76c10f4a97a24577c18a4bbe6e 3e241a9b710c49758a2c13ab2ebcbf1f X 60e0cb76c10f4a97a24577c18a4bbe6e--3e241a9b710c49758a2c13ab2ebcbf1f 3e241a9b710c49758a2c13ab2ebcbf1f--6425fa38341a4fe6b78a1bcdc61d4bfb 0d1129ab64a449dbb6746348307f4ee4 3e241a9b710c49758a2c13ab2ebcbf1f--0d1129ab64a449dbb6746348307f4ee4 0d1129ab64a449dbb6746348307f4ee4--73ae5545dd3941769adae5c555de15ec 517e6746e52b4472b2a33cb815f7fe82 d328a6671c8341f5bb4426def3040629 b4d8a7ab9d8e4daabaabe794e5fc94ed--d328a6671c8341f5bb4426def3040629 0678edd70e394964970d9c973917d152 3 fd8d8e3b82294ed7b4e8d8c9c227c0ac RX(theta\u2082) d328a6671c8341f5bb4426def3040629--fd8d8e3b82294ed7b4e8d8c9c227c0ac 7d0f06f99dcf4488861fa337f0b9dc59 RY(theta\u2086) fd8d8e3b82294ed7b4e8d8c9c227c0ac--7d0f06f99dcf4488861fa337f0b9dc59 47900e8fdfba40ccb8844b9d78320f5b RX(theta\u2081\u2080) 7d0f06f99dcf4488861fa337f0b9dc59--47900e8fdfba40ccb8844b9d78320f5b 39dd6b8831ae4e92bf00ca1910b583c8 47900e8fdfba40ccb8844b9d78320f5b--39dd6b8831ae4e92bf00ca1910b583c8 c0ceecbd0305458d8a017c9ad9ee3e14 X 39dd6b8831ae4e92bf00ca1910b583c8--c0ceecbd0305458d8a017c9ad9ee3e14 c0ceecbd0305458d8a017c9ad9ee3e14--a297da90945945b19d63f42fa2dbacb7 57af4fc24a674e51a44fd113d1849caa RX(theta\u2081\u2084) c0ceecbd0305458d8a017c9ad9ee3e14--57af4fc24a674e51a44fd113d1849caa 44c17698ee0e40a3bd2c01e2b2b51898 RY(theta\u2081\u2088) 57af4fc24a674e51a44fd113d1849caa--44c17698ee0e40a3bd2c01e2b2b51898 8dc667c9c0a9411ba33d85bd84b12ed5 RX(theta\u2082\u2082) 44c17698ee0e40a3bd2c01e2b2b51898--8dc667c9c0a9411ba33d85bd84b12ed5 637dee6e8bd543c2ae3d0462b4c8095e 8dc667c9c0a9411ba33d85bd84b12ed5--637dee6e8bd543c2ae3d0462b4c8095e 1cc9afbe8e9a43ccbbc096a5024f3c34 X 637dee6e8bd543c2ae3d0462b4c8095e--1cc9afbe8e9a43ccbbc096a5024f3c34 1cc9afbe8e9a43ccbbc096a5024f3c34--0d1129ab64a449dbb6746348307f4ee4 1cc9afbe8e9a43ccbbc096a5024f3c34--517e6746e52b4472b2a33cb815f7fe82 92799f0d18fb4ed7bf328526882ce692 deaf184af7fb45a1993ce69ba49d8078 X 0678edd70e394964970d9c973917d152--deaf184af7fb45a1993ce69ba49d8078 fa5363e3e73f4cb08dc5ff6309826eac RX(theta\u2083) deaf184af7fb45a1993ce69ba49d8078--fa5363e3e73f4cb08dc5ff6309826eac 442862eb32e54d66891c894f73d19824 RY(theta\u2087) fa5363e3e73f4cb08dc5ff6309826eac--442862eb32e54d66891c894f73d19824 f31cf84093804324b275ec2d5fc5c23b RX(theta\u2081\u2081) 442862eb32e54d66891c894f73d19824--f31cf84093804324b275ec2d5fc5c23b 7abbcb48b9c04963ae245ed0359fd9ec X f31cf84093804324b275ec2d5fc5c23b--7abbcb48b9c04963ae245ed0359fd9ec 7abbcb48b9c04963ae245ed0359fd9ec--39dd6b8831ae4e92bf00ca1910b583c8 c24384f6d032433ea742164bd84ff1ce 7abbcb48b9c04963ae245ed0359fd9ec--c24384f6d032433ea742164bd84ff1ce bf91f58315064f7cb60e5056005a14e1 RX(theta\u2081\u2085) c24384f6d032433ea742164bd84ff1ce--bf91f58315064f7cb60e5056005a14e1 74cb2639bd6a4efaab65ede2e2ea66b5 RY(theta\u2081\u2089) bf91f58315064f7cb60e5056005a14e1--74cb2639bd6a4efaab65ede2e2ea66b5 1f9718c0e3da4663b226253082ce2aa5 RX(theta\u2082\u2083) 74cb2639bd6a4efaab65ede2e2ea66b5--1f9718c0e3da4663b226253082ce2aa5 dfd0d57a9fab408abc66a9e031f392b4 X 1f9718c0e3da4663b226253082ce2aa5--dfd0d57a9fab408abc66a9e031f392b4 dfd0d57a9fab408abc66a9e031f392b4--637dee6e8bd543c2ae3d0462b4c8095e 9aa8edabd3ec4313ab379b5348b91b48 dfd0d57a9fab408abc66a9e031f392b4--9aa8edabd3ec4313ab379b5348b91b48 9aa8edabd3ec4313ab379b5348b91b48--92799f0d18fb4ed7bf328526882ce692  Several standard quantum states can be conveniently initialized in Qadence, both in statevector form as well as in block form as shown in following.</p>"},{"location":"tutorials/state_init/#state-vector-initialization","title":"State vector initialization","text":"<p>Qadence offers a number of constructor functions for state vector preparation.</p> <pre><code>from qadence import uniform_state, zero_state, one_state\nn_qubits = 3\nbatch_size = 2\nuniform_state = uniform_state(n_qubits, batch_size)\nzero_state = zero_state(n_qubits, batch_size)\none_state = one_state(n_qubits, batch_size)\n</code></pre> <pre><code>Uniform state = tensor([[0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j,\n0.3536+0.j],\n[0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j,\n0.3536+0.j]])\nZero state = tensor([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\nOne state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre> <p>As already seen, product states can be easily created, even in batches:</p> <pre><code>from qadence import product_state, rand_product_state\n# From a bitsring \"100\"\nprod_state = product_state(\"100\", batch_size)\n# Or a random product state\nrand_state = rand_product_state(n_qubits, batch_size)\n</code></pre> <pre><code>Product state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\nRandom state = tensor([[0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])\n</code></pre> <p>Creating a GHZ state:</p> <pre><code>from qadence import ghz_state\nghz = ghz_state(n_qubits, batch_size)\n</code></pre> <pre><code>GHZ state = tensor([[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n0.7071+0.j],\n[0.7071+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j, 0.0000+0.j,\n0.7071+0.j]])\n</code></pre> <p>Creating a random state uniformly sampled from a Haar measure:</p> <pre><code>from qadence import random_state\nrand_haar_state = random_state(n_qubits, batch_size)\n</code></pre> <pre><code>Random state from Haar = tensor([[-0.4733+0.0588j, -0.3286+0.0288j, -0.0680+0.3754j, -0.3299-0.1679j,\n0.0818+0.2296j, -0.2771-0.2593j, -0.0508+0.0349j,  0.1995-0.3662j],\n[-0.2293+0.0824j, -0.0980-0.0311j, -0.0049-0.1667j,  0.5866+0.3335j,\n0.1787+0.1656j,  0.0792-0.1512j, -0.5753+0.0789j,  0.1434-0.0244j]])\n</code></pre> <p>Custom initial states can then be passed to either <code>run</code>, <code>sample</code> and <code>expectation</code> through the <code>state</code> argument</p> <pre><code>from qadence import random_state, product_state, CNOT, run\ninit_state = product_state(\"10\")\nfinal_state = run(CNOT(0, 1), state=init_state)\n</code></pre> <pre><code>Final state = tensor([[0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j]])\n</code></pre>"},{"location":"tutorials/state_init/#block-initialization","title":"Block initialization","text":"<p>Not all backends support custom statevector initialization, however previous utility functions have their counterparts to initialize the respective blocks:</p> <pre><code>from qadence import uniform_block, one_block\nn_qubits = 3\nuniform_block = uniform_block(n_qubits)\none_block = one_block(n_qubits)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 H(0)\n\u251c\u2500\u2500 H(1)\n\u2514\u2500\u2500 H(2)\nKronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 X(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> <p>Similarly, for product states:</p> <pre><code>from qadence import product_block, rand_product_block\nproduct_block = product_block(\"100\")\nrand_product_block = rand_product_block(n_qubits)\n</code></pre> <pre><code>KronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 I(1)\n\u2514\u2500\u2500 I(2)\nKronBlock(0,1,2)\n\u251c\u2500\u2500 X(0)\n\u251c\u2500\u2500 I(1)\n\u2514\u2500\u2500 X(2)\n</code></pre> <p>And GHZ states:</p> <pre><code>from qadence import ghz_block\nghz_block = ghz_block(n_qubits)\n</code></pre> <pre><code>ChainBlock(0,1,2)\n\u251c\u2500\u2500 H(0)\n\u2514\u2500\u2500 ChainBlock(0,1,2)\n\u251c\u2500\u2500 CNOT(0,1)\n\u2514\u2500\u2500 CNOT(1,2)\n</code></pre> <p>Initial state blocks can simply be chained at the start of a given circuit.</p>"},{"location":"tutorials/state_init/#utility-functions","title":"Utility functions","text":"<p>Some state vector utility functions are also available. We can easily create the probability mass function of a given statevector using <code>torch.distributions.Categorical</code></p> <pre><code>from qadence import random_state, pmf\nn_qubits = 3\nstate = random_state(n_qubits)\ndistribution = pmf(state)\n</code></pre> <pre><code>Categorical(probs: torch.Size([1, 8]))\n</code></pre> <p>We can also check if a state is normalized:</p> <pre><code>from qadence import random_state, is_normalized\nstate = random_state(n_qubits)\nprint(is_normalized(state))\n</code></pre> <pre><code>True\n</code></pre> <p>Or normalize a state:</p> <pre><code>import torch\nfrom qadence import normalize, is_normalized\nstate = torch.tensor([[1, 1, 1, 1]], dtype = torch.cdouble)\nprint(normalize(state))\n</code></pre> <pre><code>tensor([[0.5000+0.j, 0.5000+0.j, 0.5000+0.j, 0.5000+0.j]])\n</code></pre>"}]}